{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()  # get directory for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7dd9d",
   "metadata": {},
   "source": [
    "# This file automates the entire pipeline for assertion generation with chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bc35b",
   "metadata": {},
   "source": [
    "## Step 1) Get Asserted Code From Github\n",
    "\n",
    "### Step 1.1) Clean and process the code\n",
    "### Step 1.2) Extract Ground-Truth Assertions & Relevant Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126af672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "def get_asserted_code(num=100000, ext=\"%.py\", verbose=True):\n",
    "    query_string = \"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT \"\"\" + str(num)\n",
    "    \n",
    "    if isinstance(num, int):\n",
    "        secret_dir = \"Data/secret/\"\n",
    "        api_key = cwd + \"/\" + secret_dir + os.listdir(secret_dir)[0]\n",
    "        assert api_key[-5:] == \".json\"  # confirm that it was found\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = api_key\n",
    "        query_string = query_string.replace(\"%.py\", ext)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"*Running Query:\")\n",
    "            print(query_string)\n",
    "            print()\n",
    "        client = bq.Client()\n",
    "        df = (\n",
    "            client.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(\n",
    "                create_bqstorage_client=True,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(num, str):\n",
    "        # load data from file\n",
    "        df = pd.read_csv(num)\n",
    "        print(\"Found data at\", num)\n",
    "    else:\n",
    "        print(\"first param type undefined, must be string signifying directory of csv or\\\n",
    "               int signifying number of records to scrib from bigquery...\")\n",
    "        assert False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"*Handling Duplicates...\")\n",
    "    init_len = len(df)\n",
    "    df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True)\n",
    "    if verbose:\n",
    "        print(\"#Non-duplicates / #Total Retrieved =\", (len(df)/init_len))\n",
    "    return df\n",
    "\n",
    "verilog_dir = cwd+\"/Data/BigQuery/VerilogAssertions-ALL.csv\"\n",
    "python_dir = cwd+\"/Data/BigQuery/PythonAssertions100k.csv\"\n",
    "# df = get_asserted_code(python_dir)  # 10\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857dd192",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]\n",
    "bad_statements = [\" or \", \" in \", \"isinstance\"]  # TODO: properly account for OR\n",
    "def parse_assertions(func, is_split=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \n",
    "    Exceptions to Handle:\n",
    "    - 'in'/'not in' keyword\n",
    "    - boolean functions - ex. isinstance(var, type)\n",
    "    - separation of attributes - ex. len(var), var[i]\n",
    "    \"\"\"\n",
    "#     if verbose:\n",
    "#         print(\"*Extracting Assertions...\")\n",
    "    out = []\n",
    "    asserted_lines = 0\n",
    "    lines = []\n",
    "    for temp in func.split('\\n'):  # find lines with assert in them\n",
    "        if \"assert\" in temp:\n",
    "            asserted_lines += 1\n",
    "            bad_flag = False\n",
    "            for bad in bad_statements:\n",
    "                if bad in temp:\n",
    "                    bad_flag = True\n",
    "            if not bad_flag:\n",
    "                lines.append(temp.strip())\n",
    "    # TODO: experiment with smaller content window for assertions\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        start = data.find('assert')\n",
    "        if start == -1:  # double checking that the assertion exists in this line\n",
    "            ind += 1\n",
    "            continue\n",
    "        # account for combination statements\n",
    "        for statement in compounding_statements:\n",
    "            add_statement = data.find(statement)\n",
    "            if add_statement != -1:\n",
    "                extra_line = data[add_statement+len(statement):]\n",
    "                lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                data = data[:add_statement].strip()\n",
    "\n",
    "        com = data.find(',')   # parsing out return_string\n",
    "        if com != -1:\n",
    "            data = data[:com]\n",
    "        com = data.find('#')\n",
    "        if com != -1:   # parsing out comments\n",
    "            if com < start:  # if the assertion itself is a comment\n",
    "                ind += 1\n",
    "                continue\n",
    "            else:\n",
    "                data = data[:com]\n",
    "\n",
    "        if is_split:  # splitting the assertion into components for analysis\n",
    "            data = [var.strip() for var in data.split(' ') if len(var.strip()) > 0]\n",
    "            \n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "                \n",
    "            if data[0] != \"assert\":  # edge case: something before the 'assert' statement\n",
    "                ind += 1\n",
    "#                 if verbose:\n",
    "#                     print(\"something was found before the assertion on this line:\\n\", data)\n",
    "                continue\n",
    "    \n",
    "            data = data[1:]  # from here on we only care about the content after the 'assert' keyword\n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "\n",
    "            condition = True  # assertion [variable] == condition by default\n",
    "            if data[0] == \"not\":  # accounting for 'not' keyword\n",
    "                condition = False\n",
    "                data = data[1:]\n",
    "            \n",
    "            if len(data) == 1:  # adding == to simlify\n",
    "                data = data + [\"==\", str(condition)]\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                if data[i] == \"is\":  # simplifying is to ==\n",
    "                    data[i] = \"==\"\n",
    "                if data[i] in conditionals.keys():  # parsing common conditionals\n",
    "                    data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                    break\n",
    "\n",
    "        if verbose and len(data) != 3:\n",
    "            print(\"Weird assertion found:\\n\", data, '\\n', lines[ind])\n",
    "            print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "        else:\n",
    "            out.append(data)\n",
    "        ind += 1\n",
    "    return out, asserted_lines\n",
    "\n",
    "def unassert(code, delim=''):\n",
    "    out = \"\"\n",
    "    counter = 1\n",
    "    for line in code.split('\\n'):\n",
    "        if \"assert\" not in line:\n",
    "            out += '\\n'+str(counter)+delim+line\n",
    "            counter += 1\n",
    "    return out\n",
    "\n",
    "def get_assertion(temp_df, verbose=False, unassert_col=True, add_stats=True):\n",
    "    \"\"\" run assertion generation \"\"\"\n",
    "    # tester_df[\"assertions\"] = tester_df[\"content\"].apply(lambda code: get_assertions(code))\n",
    "    \n",
    "    assertions = []  # list of parsed assertions\n",
    "    asserted_lines = []  # number of lines with 'assert' in them\n",
    "    parsed_lines = []  # number of assertions easily parsed\n",
    "    arr = []  # assertion recovery ratio\n",
    "    atl = []  # assertions to size\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        parsed, lines = parse_assertions(row[\"content\"], True, verbose)\n",
    "        assertions.append(parsed)\n",
    "        asserted_lines.append(lines)\n",
    "        parsed_lines.append(len(parsed))\n",
    "        arr.append(len(parsed)/lines)\n",
    "        atl.append(len(parsed)/len(row[\"content\"]))\n",
    "\n",
    "    if unassert_col:\n",
    "        temp_df[\"unasserted\"] = temp_df[\"content\"].apply(lambda code: unassert(code))\n",
    "    \n",
    "    if add_stats:\n",
    "        temp_df[\"assertions\"] = assertions\n",
    "        temp_df[\"asserted_lines\"] = asserted_lines\n",
    "        temp_df[\"parsed_lines\"] = parsed_lines\n",
    "        temp_df[\"arr\"] = arr\n",
    "        temp_df[\"atl\"] = atl\n",
    "    return temp_df\n",
    "\n",
    "# tester_df = df.copy()\n",
    "# tester_df = get_assertion(tester_df)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d8683",
   "metadata": {},
   "source": [
    "## Step 2) Generate LLM Prompt & Query a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4aeaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "banned_vars = ['', '*', 'self']\n",
    "# TODO: add variables from extracted assertions - duplicates\n",
    "def old_get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "\n",
    "# test\n",
    "import ast\n",
    "\n",
    "def get_variables(code):  # TODO: run a proper test\n",
    "    tree = ast.parse(code)\n",
    "    variables = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign):\n",
    "            for target in node.targets:\n",
    "                if isinstance(target, ast.Name):\n",
    "                    variables.append(target.id)\n",
    "    return variables\n",
    "\n",
    "# TODO find package that automatically gets variables\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "# get_vars = lambda code: get_variables(code)\n",
    "# tester_df[\"variables\"] = tester_df[\"content\"].apply(get_vars)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad8df4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "You are a helpful bot that adds assertions to pieces of Python code.\n",
       "You will be given a list of variables and a string of code presented in the format:\n",
       "*Variables:\n",
       "[...]\n",
       "*Code:\n",
       "...\n",
       "Generate assertions based on the following criteria:\n",
       "1) Assert that the function can take in all inputs necessary to complete the process\n",
       "2) Assert that all outputs are of the proper sizes.\n",
       "\n",
       "Your response should ONLY be a list of assertions in the format:\n",
       "[line_number, subject_variable, condition_type, target, reasoning]\n",
       " -line_number is an integer referencing the line after which the assertion should be inserted\n",
       " -subject_variable and target can ONLY be variables from the input list OR integers\n",
       " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
       " -reasoning is a short decription of why the assertion was made\n",
       "\n",
       "Here is an example of what your input will look like and what you should return:\n",
       "Example Input:\n",
       "*Variables:\n",
       "[n]\n",
       "*Code:\n",
       "1def fibonacci(n):\n",
       "2   if n <= 1:\n",
       "3       return n\n",
       "4   else:\n",
       "5       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "Example Output:\n",
       "[1, n, >=, 1, \"the fibonacci sequence can only be done on posative integers\"]\n",
       "\n",
       "Which would be the same as:\n",
       "1def fibonacci(n):\n",
       "2   assert n >= 1\n",
       "3   if n <= 1:\n",
       "4       return n\n",
       "5   else:\n",
       "6       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "\n",
       "\n",
       "Here is the actual input you should provide assertions for:\n",
       "*Variables:\n",
       "[flag, num, i]\n",
       "*Code:\n",
       "1num = int(input(\"Enter a number: \"))  # Program to check if a number is prime or not\n",
       "2flag = False  # define a flag variable\n",
       "3\n",
       "4if num == 1:\n",
       "5    print(num, \"is not a prime number\")\n",
       "6elif num > 1: # check for factors\n",
       "7    for i in range(2, num):\n",
       "8        if (num % i) == 0:\n",
       "9            flag = True  # if factor is found, set flag to True\n",
       "10            break  # break out of loop\n",
       "11    if flag:  # check if flag is True\n",
       "12        print(num, \"is not a prime number\")\n",
       "13    else:\n",
       "14        print(num, \"is a prime number\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipynb.fs.full.Data.GitHub-Assertions import get_variables\n",
    "class prompt_example:\n",
    "        def __init__(self, this_in=\"\", this_out=\"\"):\n",
    "            self.input = this_in\n",
    "            self.output = this_out\n",
    "            \n",
    "        def composite(self):\n",
    "            return \"Example Input:\\n\" + self.input + \"\\nExample Output:\\n\" + self.output\n",
    "        \n",
    "class LLM_prompt:       \n",
    "    def __init__(self, input_code=\"*Variables:\\n[flag, num, i]\\n*Code:\\n1num = int(input(\\\"Enter a number: \\\"))  # Program to check if a number is prime or not\\n2flag = False  # define a flag variable\\n3\\n4if num == 1:\\n5    print(num, \\\"is not a prime number\\\")\\n6elif num > 1: # check for factors\\n7    for i in range(2, num):\\n8        if (num % i) == 0:\\n9            flag = True  # if factor is found, set flag to True\\n10            break  # break out of loop\\n11    if flag:  # check if flag is True\\n12        print(num, \\\"is not a prime number\\\")\\n13    else:\\n14        print(num, \\\"is a prime number\\\")\",\n",
    "                 example_in=\"*Variables:\\n[n]\\n*Code:\\n1def fibonacci(n):\\n2   if n <= 1:\\n3       return n\\n4   else:\\n5       return(recur_fibo(n-1) + recur_fibo(n-2))\",\n",
    "                 example_out=\"[1, n, >=, 1, \\\"the fibonacci sequence can only be done on posative integers\\\"]\\n\\nWhich would be the same as:\\n1def fibonacci(n):\\n2   assert n >= 1\\n3   if n <= 1:\\n4       return n\\n5   else:\\n6       return(recur_fibo(n-1) + recur_fibo(n-2))\", \n",
    "                 criteria=[\"Assert that the function can take in all inputs necessary to complete the process\",\n",
    "                           \"Assert that all outputs are of the proper sizes.\"]\n",
    "                 ):\n",
    "        self.criteria = criteria\n",
    "        self.example = prompt_example(example_in, example_out)\n",
    "        self.input_code = input_code\n",
    "        \n",
    "        # default params that are less likely to change\n",
    "        self.intro = \"You are a helpful bot that adds assertions to pieces of Python code.\"  \n",
    "        self.input_format = \"You will be given a list of variables and a string of code presented in the format:\\n*Variables:\\n[...]\\n*Code:\\n...\"\n",
    "        self.criteria_transition = \"Generate assertions based on the following criteria:\"\n",
    "        self.output_format = \"Your response should ONLY be a list of assertions in the format:\\n[line_number, subject_variable, condition_type, target, reasoning]\"\n",
    "        self.output_format_description = [\"line_number is an integer referencing the line after which the assertion should be inserted\",\n",
    "                                          \"subject_variable and target can ONLY be variables from the input list, integers, booleans, or None\", # TODO retest bools\n",
    "                                          \"condition_type can only be a value in this list: [==, >=, <=, !=]\",\n",
    "                                          \"reasoning is a short decription of why the assertion was made\"]\n",
    "        self.example_transition = \"Here is an example of what your input will look like and what you should return:\"\n",
    "        self.input_transition = \"Here is the actual input you should provide assertions for:\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def composite_criteria(self):\n",
    "        \"\"\" return criteria as a single string\"\"\"\n",
    "        ret = \"\"\n",
    "        for i, crit in enumerate(self.criteria):\n",
    "            ret += str(i+1) + \") \" + crit\n",
    "            if i != len(self.criteria)-1:  # ignore last instance for formatting\n",
    "                ret += '\\n'\n",
    "        return ret\n",
    "    \n",
    "    def composite_output_formatting(self):\n",
    "        ret = self.output_format\n",
    "        for desc in self.output_format_description:\n",
    "            ret += \"\\n -\" + desc \n",
    "        return ret\n",
    "    \n",
    "    def prompt(self):\n",
    "        \"\"\" return entire prompt\"\"\"\n",
    "        return '\\n'.join([self.intro, self.input_format,\n",
    "                          self.criteria_transition, self.composite_criteria(), \"\",\n",
    "                          self.composite_output_formatting(), \"\",\n",
    "                          self.example_transition, self.example.composite(), \"\\n\",\n",
    "                          self.input_transition, self.input_code])\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\" return key prompt components as a list \"\"\"\n",
    "        return [self.intro, self.formatting, self.criteria, self.example, self.input_code, self.prompt()]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.prompt()\n",
    "    def __repr__(self):\n",
    "        return self.prompt()\n",
    "\n",
    "tester = LLM_prompt()\n",
    "print(len(str(tester)))\n",
    "tester\n",
    "\n",
    "# fib_input = \"def fibonacci(n):\\nassert n >= 1\\nif n <= 1:\\nreturn n\\nelse:\\nreturn(recur_fibo(n-1) + recur_fibo(n-2))\"\n",
    "# fib_output = \"[1, n, 1, 1, the fibonacci sequence can only be done on posative integers]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e44a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_prompts(temp_df):\n",
    "    prompts = []\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        # *Variables:\\n[flag, num, i]\\n*Code:\\n\n",
    "        prompt_param = \"*Variables:\\n\" + str(row[\"variables\"]) + \"\\n*Code:\\n\" + row[\"unasserted\"]\n",
    "        prompts.append(str(LLM_prompt(prompt_param)))\n",
    "    temp_df[\"prompt\"] = prompts\n",
    "    temp_df[\"prompt_len\"] = [len(p) for p in prompts]\n",
    "    return temp_df\n",
    "# tester_df = make_prompts(tester_df)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd866c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying\n",
    "import openai\n",
    "import altair as alt\n",
    "import json\n",
    "from vega_datasets import data\n",
    "\n",
    "OPENAI_API_KEY = \"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\" # os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "def run_gpt4(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# TODO: add coding language versatility\n",
    "def gpt_oneshot(input_prompt, directive=\"You are a helpful bot that adds assertions to pieces of Python code.\", verbose=False):\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]  # init\n",
    "    response = run_gpt4(message_hist)\n",
    "#     if verbose:\n",
    "#         print(\"chat_gpt: \", response, '\\n')\n",
    "#     message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "\n",
    "# print(\"\\n\\n\", gpt_oneshot(\"what do you do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c87903c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING CODE\n",
      "Found data at /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/BigQuery/PythonAssertions100k.csv\n",
      "\n",
      "EXTRACTING ASSERTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33793it [00:06, 5390.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping code with no parsed assertions => 89.8351729648152%\n",
      "\n",
      "EXTRACTING VARIABLES\n",
      "dropping code with no extracted variables => 98.94920614006193%\n",
      "\n",
      "GENERATING PROMPTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30039it [00:02, 13018.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping prompts over limit => 48.150737374746164%\n",
      "Data checkpoint saved...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def one_shot_prompts(my_dir=cwd+\"/Data/BigQuery/PythonAssertions100k.csv\", ext=\"%.py\"):\n",
    "    print(\"GETTING CODE\")\n",
    "    df = get_asserted_code(my_dir, ext, False)\n",
    "    \n",
    "    print(\"\\nEXTRACTING ASSERTIONS\")\n",
    "    df = get_assertion(df)\n",
    "    \n",
    "    all_prompts = len(df)\n",
    "    df = df[df[\"parsed_lines\"]!=0]\n",
    "    all_prompts = 100*len(df)/all_prompts\n",
    "    print(\"dropping code with no parsed assertions =>\", str(all_prompts)+'%')\n",
    "    \n",
    "    print(\"\\nEXTRACTING VARIABLES\")\n",
    "    get_vars = lambda code: get_variables(code)\n",
    "    df[\"variables\"] = df[\"content\"].apply(get_vars)\n",
    "    \n",
    "    df[\"num_vars\"] = df[\"variables\"].apply(lambda var: len(var))\n",
    "    all_prompts = len(df)\n",
    "    df = df[df[\"num_vars\"] > 0]\n",
    "    all_prompts = 100*len(df)/all_prompts\n",
    "    print(\"dropping code with no extracted variables =>\", str(all_prompts)+'%')\n",
    "    \n",
    "    print(\"\\nGENERATING PROMPTS\")\n",
    "    df = make_prompts(df)\n",
    "    \n",
    "    prompt_limit = 8192\n",
    "    all_prompts = len(df)\n",
    "    df = df[df[\"prompt_len\"] < prompt_limit]\n",
    "    all_prompts = 100*len(df)/all_prompts\n",
    "    print(\"dropping prompts over limit =>\", str(all_prompts)+'%')\n",
    "    \n",
    "    df.to_csv(cwd+\"/Data/python_prompts_noresponse.csv\") # saving data\n",
    "    print(\"Data checkpoint saved...\\n\")\n",
    "    \n",
    "#     print(\"GENERATING RESPONSES\")\n",
    "#     responses = []\n",
    "#     for prompt in tqdm(df[\"prompt\"]):\n",
    "#         responses.append(gpt_oneshot(prompt))\n",
    "#     df[\"prompt\"] = responses\n",
    "#     df.to_csv(cwd+\"/python_prompts_withresponse.csv\") # saving data\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = one_shot_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b270fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prompts for indexes 0 to 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 200/200 [1:15:15<00:00, 22.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/Testing/python_prompts_withresponse_part1.csv\n",
      "                                           repo_name  \\\n",
      "0                   lukas-hetzenecker/home-assistant   \n",
      "1                                  daveinnyc/various   \n",
      "2                                kirbyfan64/shedskin   \n",
      "3                               lordmauve/chopsticks   \n",
      "4                               allenta/splunk-stomp   \n",
      "..                                               ...   \n",
      "195                                oblique-labs/pyVM   \n",
      "196  benjaminsoellner/DAND_3_OSMDataWranglingMongoDB   \n",
      "197                    smmribeiro/intellij-community   \n",
      "198                                 GbalsaC/bitnamiP   \n",
      "199                                   dennisss/sympy   \n",
      "\n",
      "                                               content  \\\n",
      "0    \"\"\"The tests for the Pilight sensor platform.\"...   \n",
      "1    '''\\n  NOTE: The answer to this selenium quest...   \n",
      "2    #!/usr/bin/env python2\\n# I, Danny Milosavljev...   \n",
      "3    #!/usr/bin/env python\\n\\nimport perf\\n\\nfrom c...   \n",
      "4    import re\\nimport xml.dom\\n\\ntry:\\n    import ...   \n",
      "..                                                 ...   \n",
      "195  from rpython.jit.backend.llsupport.llmodel imp...   \n",
      "196  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
      "197  # Copyright 2016-present Facebook. All Rights ...   \n",
      "198  from sympy import symbols, oo\\nfrom sympy.core...   \n",
      "199  \"\"\"Test ideals.py code.\"\"\"\\n\\nfrom sympy.polys...   \n",
      "\n",
      "                                            unasserted  \\\n",
      "0    \\n1\"\"\"The tests for the Pilight sensor platfor...   \n",
      "1    \\n1'''\\n2  NOTE: The answer to this selenium q...   \n",
      "2    \\n1#!/usr/bin/env python2\\n2# I, Danny Milosav...   \n",
      "3    \\n1#!/usr/bin/env python\\n2\\n3import perf\\n4\\n...   \n",
      "4    \\n1import re\\n2import xml.dom\\n3\\n4try:\\n5    ...   \n",
      "..                                                 ...   \n",
      "195  \\n1from rpython.jit.backend.llsupport.llmodel ...   \n",
      "196  \\n1#!/usr/bin/env python\\n2# -*- coding: utf-8...   \n",
      "197  \\n1# Copyright 2016-present Facebook. All Righ...   \n",
      "198  \\n1from sympy import symbols, oo\\n2from sympy....   \n",
      "199  \\n1\"\"\"Test ideals.py code.\"\"\"\\n2\\n3from sympy....   \n",
      "\n",
      "                                            assertions  asserted_lines  \\\n",
      "0    [['await', 'async_setup_component('], ['state....              14   \n",
      "1    [['test_check_for_logo(browser)', '==', 'LOGO_...               1   \n",
      "2    [['len(part)', '<=', '4'], ['size', '>=', '0']...               8   \n",
      "3                 [['pdecode(pencode(v))', '==', 'v']]               1   \n",
      "4                           [['len(pair)', '==', '2']]               1   \n",
      "..                                                 ...             ...   \n",
      "195             [['self.assembler', '==', 'not None']]               1   \n",
      "196  [['data[\"eventvalidation\"]', '!=', '\"\"'], ['da...               3   \n",
      "197  [['annotated', '==', 'True'], ['contents', '==...               1   \n",
      "198  [['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], [...              59   \n",
      "199  [['(I', '==', 'J)'], ['I', '==', 'I'], ['I.uni...              57   \n",
      "\n",
      "     parsed_lines       arr       atl  \\\n",
      "0               9  0.642857  0.002150   \n",
      "1               1  1.000000  0.000749   \n",
      "2               3  0.375000  0.000616   \n",
      "3               1  1.000000  0.000754   \n",
      "4               1  1.000000  0.000277   \n",
      "..            ...       ...       ...   \n",
      "195             1  1.000000  0.000305   \n",
      "196             3  1.000000  0.001911   \n",
      "197             2  2.000000  0.000480   \n",
      "198            57  0.966102  0.023152   \n",
      "199            57  1.000000  0.015020   \n",
      "\n",
      "                                             variables  num_vars  \\\n",
      "0    ['hass', 'protocol', 'data', 'message', 'state...         8   \n",
      "1    ['BASE_URL', 'LOGO_URL', 'regex_parens', 'driv...         9   \n",
      "2    ['value', 'B_active', 'self.B_active', 'self.m...        25   \n",
      "3                                      ['runner', 'v']         2   \n",
      "4    ['HEADER_LINE_RE', 'lines', 'offset', 'headers...        30   \n",
      "..                                                 ...       ...   \n",
      "195  ['rtyper', 'stats', 'opts', 'translate_support...        29   \n",
      "196  ['html_page', 'page', 'data', 'soup', 'data[\"v...         9   \n",
      "197  ['repo', 'node', 'path', 'self._node', 'self._...        24   \n",
      "198                        ['x', 'y', 'z', 'e', 'res']         5   \n",
      "199                ['R', 'I', 'J', 'S', 'T', 'f', 'e']         7   \n",
      "\n",
      "                                                prompt  prompt_len  \\\n",
      "0    You are a helpful bot that adds assertions to ...        5295   \n",
      "1    You are a helpful bot that adds assertions to ...        2882   \n",
      "2    You are a helpful bot that adds assertions to ...        6314   \n",
      "3    You are a helpful bot that adds assertions to ...        2765   \n",
      "4    You are a helpful bot that adds assertions to ...        5571   \n",
      "..                                                 ...         ...   \n",
      "195  You are a helpful bot that adds assertions to ...        5267   \n",
      "196  You are a helpful bot that adds assertions to ...        2999   \n",
      "197  You are a helpful bot that adds assertions to ...        6079   \n",
      "198  You are a helpful bot that adds assertions to ...        2197   \n",
      "199  You are a helpful bot that adds assertions to ...        3023   \n",
      "\n",
      "                                                   gpt  \n",
      "0    [[13, \"hass\", '!=', None, \"The 'hass' object s...  \n",
      "1    [[17, 'driver', '!=', None, 'the webdriver.Fir...  \n",
      "2    [[30, 'value', '!=', None, \"value shouldn't be...  \n",
      "3    [[8, 'None', '==', 'None', 'Setup function doe...  \n",
      "4    [[15, 'lines', '!=', None, 'lines input is nec...  \n",
      "..                                                 ...  \n",
      "195  [[10, 'rtyper', '!=', None, 'rtyper should not...  \n",
      "196  [[14, 'page', '!=', '', 'page should not be an...  \n",
      "197  [[29, 'repo', '!=', None, \"Functions can't be ...  \n",
      "198  [[8, 'x', '!=', 'y', \"function 'test_rel_ne' e...  \n",
      "199  [[9, 'R', '!=', None, \"R should be initialized...  \n",
      "\n",
      "[200 rows x 13 columns]\n",
      "\n",
      "\n",
      "Generating prompts for indexes 200 to 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████▌                  | 120/200 [39:34<26:22, 19.79s/it]\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 13 Feb 2024 09:21:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '854c009eade719c3-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# df = partial_execution(1)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# up to 73\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpartial_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mpartial_execution\u001b[0;34m(part)\u001b[0m\n\u001b[1;32m     13\u001b[0m responses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 15\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgpt_oneshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m responses\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv((cwd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/Testing/python_prompts_withresponse_part\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(part)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# saving data\u001b[39;00m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mgpt_oneshot\u001b[0;34m(input_prompt, directive, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_oneshot\u001b[39m(input_prompt, directive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful bot that adds assertions to pieces of Python code.\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     message_hist \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: directive},\n\u001b[1;32m     20\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt}]  \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     if verbose:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         print(\"chat_gpt: \", response, '\\n')\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     message_hist.append({\"role\": \"system\", \"content\": response})\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mrun_gpt4\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_gpt4\u001b[39m(messages):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 13 Feb 2024 09:21:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '854c009eade719c3-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "part_size = 200  # should take about a bit under an hour\n",
    "current_size = 14464\n",
    "def partial_execution(part=1):  # slices of 10xt\n",
    "    start = (part-1)*part_size\n",
    "    end = start+part_size\n",
    "#     if start > current_size:\n",
    "#         return\n",
    "#     elif end > current_size:\n",
    "#         end = current_size+1\n",
    "    df = pd.read_csv(cwd+\"/Data/python_prompts_noresponse.csv\").iloc[start:end, 1:]\n",
    "    print(\"\\nGenerating prompts for indexes\", start, \"to\", end)\n",
    "    \n",
    "    responses = []\n",
    "    for prompt in tqdm(df[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    df[\"gpt\"] = responses\n",
    "    \n",
    "    df.to_csv((cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"), index=False) # saving data\n",
    "    print(\"Saved to:\", (cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"))\n",
    "    return df\n",
    "\n",
    "# df = partial_execution(1)\n",
    "for i in range(1, 10):  # up to 73\n",
    "    print(partial_execution(i))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65509b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Execution Notes:\n",
    "- somewhere around 320 instances I get various API errors:\n",
    "'APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 13 Feb 2024 09:21:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '854c009eade719c3-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34bf4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>variables</th>\n",
       "      <th>num_vars</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_len</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GbalsaC/bitnamiP</td>\n",
       "      <td>from sympy import symbols, oo\\nfrom sympy.core...</td>\n",
       "      <td>\\n1from sympy import symbols, oo\\n2from sympy....</td>\n",
       "      <td>[['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], [...</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>['x', 'y', 'z', 'e', 'res']</td>\n",
       "      <td>5</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>2197</td>\n",
       "      <td>[[8, 'x', '!=', 'y', \"function 'test_rel_ne' e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>dennisss/sympy</td>\n",
       "      <td>\"\"\"Test ideals.py code.\"\"\"\\n\\nfrom sympy.polys...</td>\n",
       "      <td>\\n1\"\"\"Test ideals.py code.\"\"\"\\n2\\n3from sympy....</td>\n",
       "      <td>[['(I', '==', 'J)'], ['I', '==', 'I'], ['I.uni...</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>['R', 'I', 'J', 'S', 'T', 'f', 'e']</td>\n",
       "      <td>7</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>3023</td>\n",
       "      <td>[[9, 'R', '!=', None, \"R should be initialized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stumoodie/SbgnPdNotationSubsystem</td>\n",
       "      <td>import antlr3\\nimport testbase\\nimport unittes...</td>\n",
       "      <td>\\n1import antlr3\\n2import testbase\\n3import un...</td>\n",
       "      <td>[['len(lexer.properties)', '==', '3'], ['text'...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>['stream', 'lexer', 'token', 'text', 'type', '...</td>\n",
       "      <td>11</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>2234</td>\n",
       "      <td>[[12, 'stream', '!=', None, \"stream should not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>hashamali/pyScss</td>\n",
       "      <td>\"\"\"Tests for the type system.\"\"\"\\nfrom __futur...</td>\n",
       "      <td>\\n1\"\"\"Tests for the type system.\"\"\"\\n2from __f...</td>\n",
       "      <td>[['Number(123) + Number(456)', '==', 'Number(5...</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>['ret', 'lo', 'hi', 'units', 'plain', 'ems', '...</td>\n",
       "      <td>10</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>4070</td>\n",
       "      <td>[[15, 'ret', '==', 'null', 'Ensure ret is prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>kumarkrishna/sympy</td>\n",
       "      <td>from sympy import Symbol, S, oo\\nfrom sympy.ca...</td>\n",
       "      <td>\\n1from sympy import Symbol, S, oo\\n2from symp...</td>\n",
       "      <td>[['codomain(x', '==', 'True'], ['codomain(x', ...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>['x']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1979</td>\n",
       "      <td>[[7, 'x', '!=', None, 'x is expected not to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Elandril/Sick-Beard</td>\n",
       "      <td>from lib.hachoir_core.tools import makeUnicode...</td>\n",
       "      <td>\\n1from lib.hachoir_core.tools import makeUnic...</td>\n",
       "      <td>[['MIN_PRIORITY', '&lt;=', 'priority &lt;= MAX_PRIOR...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>['MIN_PRIORITY', 'MAX_PRIORITY', 'QUALITY_FAST...</td>\n",
       "      <td>30</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>6895</td>\n",
       "      <td>[[16, 'value', '!=', 'None', \"value passed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>import glob\\nimport os\\nimport random\\nimport ...</td>\n",
       "      <td>\\n1import glob\\n2import os\\n3import random\\n4i...</td>\n",
       "      <td>[['os.path.isdir(dir)', '==', 'True']]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>['ansi_escape_re', 'control_character_re', 'co...</td>\n",
       "      <td>39</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7286</td>\n",
       "      <td>[17, 'dir', '!=', '', \"function 'walk_director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>bartvm/gensim</td>\n",
       "      <td>#!/usr/bin/env python\\n#\\n# Copyright (C) 2010...</td>\n",
       "      <td>\\n1#!/usr/bin/env python\\n2#\\n3# Copyright (C)...</td>\n",
       "      <td>[['len(input)', '==', 'len(corpus)']]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>['DRY_RUN', 'MIN_SCORE', 'MAX_SIMILAR', 'SAVE_...</td>\n",
       "      <td>25</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>6803</td>\n",
       "      <td>[[28, 'DRY_RUN', '==', False, \"similar.xml fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>mig42/gui2py</td>\n",
       "      <td>#!/usr/bin/python\\r\\n# -*- coding: utf-8 -*-\\r...</td>\n",
       "      <td>\\n1#!/usr/bin/python\\r\\n2# -*- coding: utf-8 -...</td>\n",
       "      <td>[['nb.get_count()', '==', '3']]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>['__author__', '__copyright__', '_wx_class', '...</td>\n",
       "      <td>30</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7272</td>\n",
       "      <td>[\\n[21, '_wx_class', '!=', None, \"Notebook cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>edmundgentle/schoolscript</td>\n",
       "      <td>from importlib import _bootstrap\\r\\nfrom impor...</td>\n",
       "      <td>\\n1from importlib import _bootstrap\\r\\n2from i...</td>\n",
       "      <td>[['os.path.exists(bad_path)', '==', 'False']]</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>['module', 'path', 'importer', 'loader', 'hook...</td>\n",
       "      <td>13</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>6237</td>\n",
       "      <td>[[18, 'module', '!=', '', \"Module name shouldn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             repo_name  \\\n",
       "198                   GbalsaC/bitnamiP   \n",
       "199                     dennisss/sympy   \n",
       "18   stumoodie/SbgnPdNotationSubsystem   \n",
       "181                   hashamali/pyScss   \n",
       "176                 kumarkrishna/sympy   \n",
       "..                                 ...   \n",
       "127                Elandril/Sick-Beard   \n",
       "92                 valohai/valohai-cli   \n",
       "84                       bartvm/gensim   \n",
       "175                       mig42/gui2py   \n",
       "138          edmundgentle/schoolscript   \n",
       "\n",
       "                                               content  \\\n",
       "198  from sympy import symbols, oo\\nfrom sympy.core...   \n",
       "199  \"\"\"Test ideals.py code.\"\"\"\\n\\nfrom sympy.polys...   \n",
       "18   import antlr3\\nimport testbase\\nimport unittes...   \n",
       "181  \"\"\"Tests for the type system.\"\"\"\\nfrom __futur...   \n",
       "176  from sympy import Symbol, S, oo\\nfrom sympy.ca...   \n",
       "..                                                 ...   \n",
       "127  from lib.hachoir_core.tools import makeUnicode...   \n",
       "92   import glob\\nimport os\\nimport random\\nimport ...   \n",
       "84   #!/usr/bin/env python\\n#\\n# Copyright (C) 2010...   \n",
       "175  #!/usr/bin/python\\r\\n# -*- coding: utf-8 -*-\\r...   \n",
       "138  from importlib import _bootstrap\\r\\nfrom impor...   \n",
       "\n",
       "                                            unasserted  \\\n",
       "198  \\n1from sympy import symbols, oo\\n2from sympy....   \n",
       "199  \\n1\"\"\"Test ideals.py code.\"\"\"\\n2\\n3from sympy....   \n",
       "18   \\n1import antlr3\\n2import testbase\\n3import un...   \n",
       "181  \\n1\"\"\"Tests for the type system.\"\"\"\\n2from __f...   \n",
       "176  \\n1from sympy import Symbol, S, oo\\n2from symp...   \n",
       "..                                                 ...   \n",
       "127  \\n1from lib.hachoir_core.tools import makeUnic...   \n",
       "92   \\n1import glob\\n2import os\\n3import random\\n4i...   \n",
       "84   \\n1#!/usr/bin/env python\\n2#\\n3# Copyright (C)...   \n",
       "175  \\n1#!/usr/bin/python\\r\\n2# -*- coding: utf-8 -...   \n",
       "138  \\n1from importlib import _bootstrap\\r\\n2from i...   \n",
       "\n",
       "                                            assertions  asserted_lines  \\\n",
       "198  [['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], [...              59   \n",
       "199  [['(I', '==', 'J)'], ['I', '==', 'I'], ['I.uni...              57   \n",
       "18   [['len(lexer.properties)', '==', '3'], ['text'...              25   \n",
       "181  [['Number(123) + Number(456)', '==', 'Number(5...              51   \n",
       "176  [['codomain(x', '==', 'True'], ['codomain(x', ...              35   \n",
       "..                                                 ...             ...   \n",
       "127  [['MIN_PRIORITY', '<=', 'priority <= MAX_PRIOR...               3   \n",
       "92              [['os.path.isdir(dir)', '==', 'True']]               1   \n",
       "84               [['len(input)', '==', 'len(corpus)']]               1   \n",
       "175                    [['nb.get_count()', '==', '3']]               1   \n",
       "138      [['os.path.exists(bad_path)', '==', 'False']]              16   \n",
       "\n",
       "     parsed_lines       arr       atl  \\\n",
       "198            57  0.966102  0.023152   \n",
       "199            57  1.000000  0.015020   \n",
       "18             25  1.000000  0.012201   \n",
       "181            51  1.000000  0.011762   \n",
       "176            35  1.000000  0.011412   \n",
       "..            ...       ...       ...   \n",
       "127             1  0.333333  0.000203   \n",
       "92              1  1.000000  0.000201   \n",
       "84              1  1.000000  0.000200   \n",
       "175             1  1.000000  0.000192   \n",
       "138             1  0.062500  0.000185   \n",
       "\n",
       "                                             variables  num_vars  \\\n",
       "198                        ['x', 'y', 'z', 'e', 'res']         5   \n",
       "199                ['R', 'I', 'J', 'S', 'T', 'f', 'e']         7   \n",
       "18   ['stream', 'lexer', 'token', 'text', 'type', '...        11   \n",
       "181  ['ret', 'lo', 'hi', 'units', 'plain', 'ems', '...        10   \n",
       "176                                              ['x']         1   \n",
       "..                                                 ...       ...   \n",
       "127  ['MIN_PRIORITY', 'MAX_PRIORITY', 'QUALITY_FAST...        30   \n",
       "92   ['ansi_escape_re', 'control_character_re', 'co...        39   \n",
       "84   ['DRY_RUN', 'MIN_SCORE', 'MAX_SIMILAR', 'SAVE_...        25   \n",
       "175  ['__author__', '__copyright__', '_wx_class', '...        30   \n",
       "138  ['module', 'path', 'importer', 'loader', 'hook...        13   \n",
       "\n",
       "                                                prompt  prompt_len  \\\n",
       "198  You are a helpful bot that adds assertions to ...        2197   \n",
       "199  You are a helpful bot that adds assertions to ...        3023   \n",
       "18   You are a helpful bot that adds assertions to ...        2234   \n",
       "181  You are a helpful bot that adds assertions to ...        4070   \n",
       "176  You are a helpful bot that adds assertions to ...        1979   \n",
       "..                                                 ...         ...   \n",
       "127  You are a helpful bot that adds assertions to ...        6895   \n",
       "92   You are a helpful bot that adds assertions to ...        7286   \n",
       "84   You are a helpful bot that adds assertions to ...        6803   \n",
       "175  You are a helpful bot that adds assertions to ...        7272   \n",
       "138  You are a helpful bot that adds assertions to ...        6237   \n",
       "\n",
       "                                                   gpt  \n",
       "198  [[8, 'x', '!=', 'y', \"function 'test_rel_ne' e...  \n",
       "199  [[9, 'R', '!=', None, \"R should be initialized...  \n",
       "18   [[12, 'stream', '!=', None, \"stream should not...  \n",
       "181  [[15, 'ret', '==', 'null', 'Ensure ret is prop...  \n",
       "176  [[7, 'x', '!=', None, 'x is expected not to be...  \n",
       "..                                                 ...  \n",
       "127  [[16, 'value', '!=', 'None', \"value passed to ...  \n",
       "92   [17, 'dir', '!=', '', \"function 'walk_director...  \n",
       "84   [[28, 'DRY_RUN', '==', False, \"similar.xml fil...  \n",
       "175  [\\n[21, '_wx_class', '!=', None, \"Notebook cla...  \n",
       "138  [[18, 'module', '!=', '', \"Module name shouldn...  \n",
       "\n",
       "[200 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(cwd+\"/Data/Testing/python_prompts_withresponse_part1.csv\")\n",
    "df = df.sort_values([\"atl\", \"num_vars\"], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2076b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>num_vars</th>\n",
       "      <th>prompt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.965000</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>0.849637</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>13.960000</td>\n",
       "      <td>4531.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.496921</td>\n",
       "      <td>13.600893</td>\n",
       "      <td>0.294534</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>9.514781</td>\n",
       "      <td>1732.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746528</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2944.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>4519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>6041.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       asserted_lines  parsed_lines         arr         atl    num_vars  \\\n",
       "count      200.000000    200.000000  200.000000  200.000000  200.000000   \n",
       "mean        10.965000      8.525000    0.849637    0.002552   13.960000   \n",
       "std         15.496921     13.600893    0.294534    0.002973    9.514781   \n",
       "min          1.000000      1.000000    0.037736    0.000185    1.000000   \n",
       "25%          2.000000      1.000000    0.746528    0.000588    6.000000   \n",
       "50%          4.000000      3.000000    1.000000    0.001417   11.500000   \n",
       "75%         14.000000      8.000000    1.000000    0.003679   20.250000   \n",
       "max         99.000000     95.000000    2.000000    0.023152   45.000000   \n",
       "\n",
       "        prompt_len  \n",
       "count   200.000000  \n",
       "mean   4531.530000  \n",
       "std    1732.097439  \n",
       "min    1517.000000  \n",
       "25%    2944.250000  \n",
       "50%    4519.000000  \n",
       "75%    6041.250000  \n",
       "max    8140.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d756ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from sympy import symbols, oo\n",
      "from sympy.core.relational import Relational, Equality, StrictInequality, \\\n",
      "    Rel, Eq, Lt, Le, Gt, Ge, Ne\n",
      "\n",
      "x,y,z = symbols('x,y,z')\n",
      "\n",
      "\n",
      "def test_rel_ne():\n",
      "    Relational(x, y, '!=')  # this used to raise\n",
      "\n",
      "\n",
      "def test_rel_subs():\n",
      "    e = Relational(x, y, '==')\n",
      "    e = e.subs(x,z)\n",
      "\n",
      "    assert isinstance(e, Equality)\n",
      "    assert e.lhs == z\n",
      "    assert e.rhs == y\n",
      "\n",
      "    e = Relational(x, y, '<')\n",
      "    e = e.subs(x,z)\n",
      "\n",
      "    assert isinstance(e, StrictInequality)\n",
      "    assert e.lhs == z\n",
      "    assert e.rhs == y\n",
      "\n",
      "    e = Eq(x,0)\n",
      "    assert e.subs(x,0) == True\n",
      "    assert e.subs(x,1) == False\n",
      "\n",
      "\n",
      "def test_wrappers():\n",
      "    e = x+x**2\n",
      "\n",
      "    res = Relational(y, e, '==')\n",
      "    assert Rel(y, x+x**2, '==') == res\n",
      "    assert Eq(y, x+x**2) == res\n",
      "\n",
      "    res = Relational(y, e, '<')\n",
      "    assert Lt(y, x+x**2) == res\n",
      "\n",
      "    res = Relational(y, e, '<=')\n",
      "    assert Le(y, x+x**2) == res\n",
      "\n",
      "    res = Relational(y, e, '>')\n",
      "    assert Gt(y, x+x**2) == res\n",
      "\n",
      "    res = Relational(y, e, '>=')\n",
      "    assert Ge(y, x+x**2) == res\n",
      "\n",
      "    res = Relational(y, e, '!=')\n",
      "    assert Ne(y, x+x**2) == res\n",
      "\n",
      "def test_Eq():\n",
      "\n",
      "    assert Eq(x**2) == Eq(x**2, 0)\n",
      "    assert Eq(x**2) != Eq(x**2, 1)\n",
      "\n",
      "def test_rel_Infinity():\n",
      "    assert (oo > oo) is False\n",
      "    assert (oo > -oo) is True\n",
      "    assert (oo > 1) is True\n",
      "    assert (oo < oo) is False\n",
      "    assert (oo < -oo) is False\n",
      "    assert (oo < 1) is False\n",
      "    assert (oo >= oo) is True\n",
      "    assert (oo >= -oo) is True\n",
      "    assert (oo >= 1) is True\n",
      "    assert (oo <= oo) is True\n",
      "    assert (oo <= -oo) is False\n",
      "    assert (oo <= 1) is False\n",
      "    assert (-oo > oo) is False\n",
      "    assert (-oo > -oo) is False\n",
      "    assert (-oo > 1) is False\n",
      "    assert (-oo < oo) is True\n",
      "    assert (-oo < -oo) is False\n",
      "    assert (-oo < 1) is True\n",
      "    assert (-oo >= oo) is False\n",
      "    assert (-oo >= -oo) is True\n",
      "    assert (-oo >= 1) is False\n",
      "    assert (-oo <= oo) is True\n",
      "    assert (-oo <= -oo) is True\n",
      "    assert (-oo <= 1) is True\n",
      "\n",
      "def test_bool():\n",
      "    assert Eq(0,0) is True\n",
      "    assert Eq(1,0) is False\n",
      "    assert Ne(0,0) is False\n",
      "    assert Ne(1,0) is True\n",
      "    assert Lt(0,1) is True\n",
      "    assert Lt(1,0) is False\n",
      "    assert Le(0,1) is True\n",
      "    assert Le(1,0) is False\n",
      "    assert Le(0,0) is True\n",
      "    assert Gt(1,0) is True\n",
      "    assert Gt(0,1) is False\n",
      "    assert Ge(1,0) is True\n",
      "    assert Ge(0,1) is False\n",
      "    assert Ge(1,1) is True\n",
      "\n",
      "def test_rich_cmp():\n",
      "    assert (x<y) == Lt(x,y)\n",
      "    assert (x<=y) == Le(x,y)\n",
      "    assert (x>y) == Gt(x,y)\n",
      "    assert (x>=y) == Ge(x,y)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "050633ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(\"prompt_len\", ascending=True)  # asserted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33101274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing Data for prompt_len sorted data in Part1 Ind42\n",
      "\n",
      "Extracted Assertion:\n",
      "[['res', '==', '[a]'], ['res', '==', '[]'], ['res', '==', '[a]'], ['False', '==', 'True'], ['res', '==', '[b]']]\n",
      "\n",
      "Variables:\n",
      "['self.conn', 'ms', 'pk', 'a_key', 'a', 'b_key', 'b', 'res']\n",
      "\n",
      "Code:\n",
      "# NOTE: make sure you run monogod first\n",
      "\n",
      "import pymongo\n",
      "import unittest\n",
      "\n",
      "from . import MongoDatastore\n",
      "from datastore.core.test.test_basic import TestDatastore\n",
      "from datastore.core import Key, Query\n",
      "\n",
      "\n",
      "class TestMongoDatastore(TestDatastore):\n",
      "\n",
      "  def setUp(self):\n",
      "    self.conn = pymongo.Connection()\n",
      "    self.conn.drop_database('datastore_testdb')\n",
      "\n",
      "  def tearDown(self):\n",
      "    self.conn.drop_database('datastore_testdb')\n",
      "    del self.conn\n",
      "\n",
      "  def test_mongo(self):\n",
      "    ms = MongoDatastore(self.conn.datastore_testdb)\n",
      "    self.subtest_simple([ms], numelems=500)\n",
      "\n",
      "  def test_query(self):\n",
      "    ms = MongoDatastore(self.conn.datastore_testdb)\n",
      "    pk = Key('/users')\n",
      "\n",
      "    a_key = pk.instance('a')\n",
      "    a = {'key': str(a_key), 'name': 'A', 'age': 35}\n",
      "    ms.put(a_key, a)\n",
      "\n",
      "    b_key = pk.instance('b')\n",
      "    b = {'key': str(b_key), 'name': 'B', 'age': 29}\n",
      "    ms.put(b_key, b)\n",
      "\n",
      "    res = list(ms.query(Query(pk).filter('age','>',30)))\n",
      "    assert res == [a]\n",
      "\n",
      "    res = list(ms.query(Query(pk).filter('age','>',30).filter('age','<',30)))\n",
      "    assert res == []\n",
      "\n",
      "    res = list(ms.query(Query(pk).filter('age','=',35)))\n",
      "    assert res == [a]\n",
      "\n",
      "    try:\n",
      "      res = list(ms.query(Query(pk).filter('age','>',30).filter('age','=',30)))\n",
      "      assert False\n",
      "    except ValueError:\n",
      "      pass\n",
      "\n",
      "    res = list(ms.query(Query(pk).filter('name','!=','A')))\n",
      "    assert res == [b]\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "  unittest.main()\n",
      "\n",
      "\n",
      "GPT Response:\n",
      "[[13, 'self.conn', '!=', None, 'Asserts that connection is established'],\n",
      "[22, 'ms', '!=', None, 'Asserts that MongoDB datastore is setup successfully'],\n",
      "[31, 'a', '==', dict, 'Asserts that the data is a dictionary'],\n",
      "[35, 'b', '==', dict, 'Asserts that the data is a dictionary'],\n",
      "[37, 'res', '==', list, 'Asserts that the result is a list'],\n",
      "[39, 'res', '==', list, 'Asserts that the result is a list'],\n",
      "[41, 'res', '==', list, 'Asserts that the result is a list'],\n",
      "[48, 'res', '==', list, 'Asserts that the result is a list']]\n"
     ]
    }
   ],
   "source": [
    "ind = 42\n",
    "print(\"Showing Data for prompt_len sorted data in Part1 Ind\"+str(ind))\n",
    "print(\"\\nExtracted Assertion:\")\n",
    "print(df.iloc[ind][\"assertions\"])\n",
    "print(\"\\nVariables:\")\n",
    "print(df.iloc[ind][\"variables\"])\n",
    "print(\"\\nCode:\")\n",
    "print(df.iloc[ind][\"content\"])\n",
    "\n",
    "print(\"\\nGPT Response:\")\n",
    "print(df.iloc[ind][\"gpt\"])\n",
    "\n",
    "# print(\"\\nPROMPT:\")\n",
    "# print(df.iloc[ind][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c3f48fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (798822789.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [107]\u001b[0;36m\u001b[0m\n\u001b[0;31m    to_find = assertion.replace('[','').replace(']'.'')\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    for assertion in row[\"assertions\"]:\n",
    "        to_find = assertion.replace('[','').replace(']'.'')\n",
    "        if to_find in row[\"gpt\"]:\n",
    "            print(\"Found a match!\")\n",
    "            print(assertion)\n",
    "            print(\"found at\")\n",
    "            print(row[\"gpt\"])\n",
    "print(\"\\nDONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927da6",
   "metadata": {},
   "source": [
    "## Step 3) Parse & Evaluate GPT's Response\n",
    "\n",
    "### Step 3.1) Restore the assertion(s) generated to code and evaluate\n",
    "> Metrics of evaluation, does it run? does it add to the code? is it ground-truth-like? human evaluator rank? gpt evaluator rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8a956fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [115]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parsed_code), asserts\n\u001b[1;32m     24\u001b[0m example_response \u001b[38;5;241m=\u001b[39m tester_df\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexample_response\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m temp_test \u001b[38;5;241m=\u001b[39m get_gpt_assertions(example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munasserted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'"
     ]
    }
   ],
   "source": [
    "def get_gpt_assertions(response, code):\n",
    "    \"\"\" takes in chat gpt's response and outputs its assertions as well as a string of code with said assertions in it \"\"\"\n",
    "    asserts = []\n",
    "    parsed_code = code.split('\\n')\n",
    "    for line in response.split('\\n'):\n",
    "        line.replace('[', '').replace(']', '')\n",
    "        separated = line.split(',')\n",
    "        full_assert = separated[1:-1] # ommit reasoning\n",
    "        \n",
    "        # TODO: handle case where there are other ints in the code\n",
    "        line_num = separated[0]\n",
    "        num_size = len(str(line_num))\n",
    "        has_found = False\n",
    "        for i, line in enumerate(parsed_code):\n",
    "            if line_num in line[:num_size+1]:\n",
    "                parsed_code.insert(i+1, full_assert)\n",
    "                asserts.append(full_assert)\n",
    "                has_found = True\n",
    "                break\n",
    "        if not has_found:\n",
    "            print(\"Could not find location of\\n\", full_assert, \"\\nin\\n\", code)\n",
    "    return '\\n'.join(parsed_code), asserts\n",
    "\n",
    "example_response = tester_df.sample()\n",
    "print(example_response[\"gpt\"].iloc[0])\n",
    "temp_test = get_gpt_assertions(example_response[\"gpt\"].iloc[0], example_response[\"unasserted\"].iloc[0])\n",
    "print(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_asserted_code = []  # snippets of code greated by the response assertions from gpt\n",
    "gpt_assertions = []  # the decoded assertions themselves\n",
    "gpt_num_assertions = []  # the number of assertions gpt generated\n",
    "gpt_ratio_assertions = []   # num_gen_assertions / num_parsed_assertions\n",
    "gpt_matched_assertions = []  # assertions that roughly equal ground-truth\n",
    "gpt_matched_assertions_ratio = []  # num_matched_assertions / num_ground_truth_assertions\n",
    "\n",
    "for i, row in tester_df.iterrows():\n",
    "    new_code, asserts = get_gpt_assertions(row[\"gpt\"], row[\"Unasserted\"])\n",
    "    gpt_asserted_code.append(new_code)\n",
    "    gpt_assertions.append(asserts)\n",
    "    gpt_num_assertions.append(len(asserts))\n",
    "    gpt_ratio_assertions.append(len(asserts)/row[\"parsed_lines\"])\n",
    "    # TODO get number of matching assertions\n",
    "    matched_num = ...\n",
    "    gpt_matched_assertions.append(matched_num)\n",
    "    gpt_matched_assertions_ratio.append(matched_num/len(asserts))\n",
    "tester_df[\"gpt_asserted_code\"] = gpt_asserted_code\n",
    "tester_df[\"gpt_assertions\"] = gpt_assertions\n",
    "tester_df[\"gpt_num_assertions\"] = gpt_num_assertions\n",
    "tester_df[\"gpt_ratio_assertions\"] = gpt_ratio_assertions\n",
    "tester_df[\"gpt_matched_assertions\"] = gpt_matched_assertions\n",
    "tester_df[\"gpt_matched_assertions_ratio\"] = gpt_matched_assertions_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefc5cd",
   "metadata": {},
   "source": [
    "## Step 4) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae2772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
