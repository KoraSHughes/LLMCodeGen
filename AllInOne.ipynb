{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()  # get directory for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7dd9d",
   "metadata": {},
   "source": [
    "# This file automates the entire pipeline for assertion generation with chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bc35b",
   "metadata": {},
   "source": [
    "## Step 1) Get Asserted Code From Github\n",
    "\n",
    "### Step 1.1) Clean and process the code\n",
    "### Step 1.2) Extract Ground-Truth Assertions & Relevant Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126af672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "def get_asserted_code(num=100000, ext=\"%.py\", verbose=True):\n",
    "    query_string = \"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT \"\"\" + str(num)\n",
    "    \n",
    "    if isinstance(num, int):\n",
    "        secret_dir = \"Data/secret/\"\n",
    "        api_key = cwd + \"/\" + secret_dir + os.listdir(secret_dir)[0]\n",
    "        assert api_key[-5:] == \".json\"  # confirm that it was found\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = api_key\n",
    "        query_string = query_string.replace(\"%.py\", ext)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"*Running Query:\")\n",
    "            print(query_string)\n",
    "            print()\n",
    "        client = bq.Client()\n",
    "        df = (\n",
    "            client.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(\n",
    "                create_bqstorage_client=True,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(num, str):\n",
    "        # load data from file\n",
    "        df = pd.read_csv(num)\n",
    "        print(\"Found data at\", num)\n",
    "    else:\n",
    "        print(\"first param type undefined, must be string signifying directory of csv or\\\n",
    "               int signifying number of records to scrib from bigquery...\")\n",
    "        assert False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"*Handling Duplicates...\")\n",
    "    init_len = len(df)\n",
    "    df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True)\n",
    "    if verbose:\n",
    "        print(\"#Non-duplicates / #Total Retrieved =\", (len(df)/init_len))\n",
    "    return df\n",
    "\n",
    "verilog_dir = cwd+\"/Data/BigQuery/VerilogAssertions-ALL.csv\"\n",
    "python_dir = cwd+\"/Data/BigQuery/PythonAssertions100k.csv\"\n",
    "# df = get_asserted_code(python_dir)  # 10\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857dd192",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]\n",
    "bad_statements = [\" or \", \" in \", \"isinstance\"]  # TODO: properly account for OR\n",
    "def parse_assertions(func, is_split=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \n",
    "    Exceptions to Handle:\n",
    "    - 'in'/'not in' keyword\n",
    "    - boolean functions - ex. isinstance(var, type)\n",
    "    - separation of attributes - ex. len(var), var[i]\n",
    "    \"\"\"\n",
    "#     if verbose:\n",
    "#         print(\"*Extracting Assertions...\")\n",
    "    out = []\n",
    "    asserted_lines = 0\n",
    "    lines = []\n",
    "    for temp in func.split('\\n'):  # find lines with assert in them\n",
    "        if \"assert\" in temp:\n",
    "            asserted_lines += 1\n",
    "            bad_flag = False\n",
    "            for bad in bad_statements:\n",
    "                if bad in temp:\n",
    "                    bad_flag = True\n",
    "            if not bad_flag:\n",
    "                lines.append(temp.strip())\n",
    "    # TODO: experiment with smaller content window for assertions\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        start = data.find('assert')\n",
    "        if start == -1:  # double checking that the assertion exists in this line\n",
    "            ind += 1\n",
    "            continue\n",
    "        # account for combination statements\n",
    "        for statement in compounding_statements:\n",
    "            add_statement = data.find(statement)\n",
    "            if add_statement != -1:\n",
    "                extra_line = data[add_statement+len(statement):]\n",
    "                lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                data = data[:add_statement].strip()\n",
    "\n",
    "        com = data.find(',')   # parsing out return_string\n",
    "        if com != -1:\n",
    "            data = data[:com]\n",
    "        com = data.find('#')\n",
    "        if com != -1:   # parsing out comments\n",
    "            if com < start:  # if the assertion itself is a comment\n",
    "                ind += 1\n",
    "                continue\n",
    "            else:\n",
    "                data = data[:com]\n",
    "\n",
    "        if is_split:  # splitting the assertion into components for analysis\n",
    "            data = [var.strip() for var in data.split(' ') if len(var.strip()) > 0]\n",
    "            \n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "                \n",
    "            if data[0] != \"assert\":  # edge case: something before the 'assert' statement\n",
    "                ind += 1\n",
    "#                 if verbose:\n",
    "#                     print(\"something was found before the assertion on this line:\\n\", data)\n",
    "                continue\n",
    "    \n",
    "            data = data[1:]  # from here on we only care about the content after the 'assert' keyword\n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "\n",
    "            condition = True  # assertion [variable] == condition by default\n",
    "            if data[0] == \"not\":  # accounting for 'not' keyword\n",
    "                condition = False\n",
    "                data = data[1:]\n",
    "            \n",
    "            if len(data) == 1:  # adding == to simlify\n",
    "                data = data + [\"==\", str(condition)]\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                if data[i] == \"is\":  # simplifying is to ==\n",
    "                    data[i] = \"==\"\n",
    "                if data[i] in conditionals.keys():  # parsing common conditionals\n",
    "                    data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                    break\n",
    "\n",
    "        if verbose and len(data) != 3:\n",
    "            print(\"Weird assertion found:\\n\", data, '\\n', lines[ind])\n",
    "            print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "        else:\n",
    "            out.append(data)\n",
    "        ind += 1\n",
    "    return out, asserted_lines\n",
    "\n",
    "def unassert(code, delim=''):\n",
    "    out = \"\"\n",
    "    counter = 1\n",
    "    for line in code.split('\\n'):\n",
    "        if \"assert\" not in line:\n",
    "            out += '\\n'+str(counter)+delim+line\n",
    "            counter += 1\n",
    "    return out\n",
    "\n",
    "def get_assertion(temp_df, verbose=False, unassert_col=True, add_stats=True):\n",
    "    \"\"\" run assertion generation \"\"\"\n",
    "    # tester_df[\"assertions\"] = tester_df[\"content\"].apply(lambda code: get_assertions(code))\n",
    "    \n",
    "    assertions = []  # list of parsed assertions\n",
    "    asserted_lines = []  # number of lines with 'assert' in them\n",
    "    parsed_lines = []  # number of assertions easily parsed\n",
    "    arr = []  # assertion recovery ratio\n",
    "    atl = []  # assertions to size\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        parsed, lines = parse_assertions(row[\"content\"], True, verbose)\n",
    "        assertions.append(parsed)\n",
    "        asserted_lines.append(lines)\n",
    "        parsed_lines.append(len(parsed))\n",
    "        arr.append(len(parsed)/lines)\n",
    "        atl.append(len(parsed)/len(row[\"content\"]))\n",
    "\n",
    "    if unassert_col:\n",
    "        temp_df[\"unasserted\"] = temp_df[\"content\"].apply(lambda code: unassert(code))\n",
    "    \n",
    "    if add_stats:\n",
    "        temp_df[\"assertions\"] = assertions\n",
    "        temp_df[\"asserted_lines\"] = asserted_lines\n",
    "        temp_df[\"parsed_lines\"] = parsed_lines\n",
    "        temp_df[\"arr\"] = arr\n",
    "        temp_df[\"atl\"] = atl\n",
    "    return temp_df\n",
    "\n",
    "# tester_df = df.copy()\n",
    "# tester_df = get_assertion(tester_df)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d8683",
   "metadata": {},
   "source": [
    "## Step 2) Generate LLM Prompt & Query a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4aeaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "banned_vars = ['', '*', 'self']\n",
    "def get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "# TODO find package that automatically gets variables\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "# get_vars = lambda code: get_variables(code)\n",
    "# tester_df[\"variables\"] = tester_df[\"content\"].apply(get_vars)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad8df4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "You are a helpful bot that adds assertions to pieces of Python code.\n",
       "You will be given a list of variables and a string of code presented in the format:\n",
       "*Variables:\n",
       "[...]\n",
       "*Code:\n",
       "...\n",
       "Generate assertions based on the following criteria:\n",
       "1) Assert that the function can take in all inputs necessary to complete the process\n",
       "2) Assert that all outputs are of the proper sizes.\n",
       "\n",
       "Your response should ONLY be a list of assertions in the format:\n",
       "[line_number, subject_variable, condition_type, target, reasoning]\n",
       " -line_number is an integer referencing the line after which the assertion should be inserted\n",
       " -subject_variable and target can ONLY be variables from the input list OR integers\n",
       " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
       " -reasoning is a short decription of why the assertion was made\n",
       "\n",
       "Here is an example of what your input will look like and what you should return:\n",
       "Example Input:\n",
       "*Variables:\n",
       "[n]\n",
       "*Code:\n",
       "1def fibonacci(n):\n",
       "2   if n <= 1:\n",
       "3       return n\n",
       "4   else:\n",
       "5       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "Example Output:\n",
       "[1, n, >=, 1, \"the fibonacci sequence can only be done on posative integers\"]\n",
       "\n",
       "Which would be the same as:\n",
       "1def fibonacci(n):\n",
       "2   assert n >= 1\n",
       "3   if n <= 1:\n",
       "4       return n\n",
       "5   else:\n",
       "6       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "\n",
       "\n",
       "Here is the actual input you should provide assertions for:\n",
       "*Variables:\n",
       "[flag, num, i]\n",
       "*Code:\n",
       "1num = int(input(\"Enter a number: \"))  # Program to check if a number is prime or not\n",
       "2flag = False  # define a flag variable\n",
       "3\n",
       "4if num == 1:\n",
       "5    print(num, \"is not a prime number\")\n",
       "6elif num > 1: # check for factors\n",
       "7    for i in range(2, num):\n",
       "8        if (num % i) == 0:\n",
       "9            flag = True  # if factor is found, set flag to True\n",
       "10            break  # break out of loop\n",
       "11    if flag:  # check if flag is True\n",
       "12        print(num, \"is not a prime number\")\n",
       "13    else:\n",
       "14        print(num, \"is a prime number\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipynb.fs.full.Data.GitHub-Assertions import get_variables\n",
    "class prompt_example:\n",
    "        def __init__(self, this_in=\"\", this_out=\"\"):\n",
    "            self.input = this_in\n",
    "            self.output = this_out\n",
    "            \n",
    "        def composite(self):\n",
    "            return \"Example Input:\\n\" + self.input + \"\\nExample Output:\\n\" + self.output\n",
    "        \n",
    "class LLM_prompt:       \n",
    "    def __init__(self, input_code=\"*Variables:\\n[flag, num, i]\\n*Code:\\n1num = int(input(\\\"Enter a number: \\\"))  # Program to check if a number is prime or not\\n2flag = False  # define a flag variable\\n3\\n4if num == 1:\\n5    print(num, \\\"is not a prime number\\\")\\n6elif num > 1: # check for factors\\n7    for i in range(2, num):\\n8        if (num % i) == 0:\\n9            flag = True  # if factor is found, set flag to True\\n10            break  # break out of loop\\n11    if flag:  # check if flag is True\\n12        print(num, \\\"is not a prime number\\\")\\n13    else:\\n14        print(num, \\\"is a prime number\\\")\",\n",
    "                 example_in=\"*Variables:\\n[n]\\n*Code:\\n1def fibonacci(n):\\n2   if n <= 1:\\n3       return n\\n4   else:\\n5       return(recur_fibo(n-1) + recur_fibo(n-2))\",\n",
    "                 example_out=\"[1, n, >=, 1, \\\"the fibonacci sequence can only be done on posative integers\\\"]\\n\\nWhich would be the same as:\\n1def fibonacci(n):\\n2   assert n >= 1\\n3   if n <= 1:\\n4       return n\\n5   else:\\n6       return(recur_fibo(n-1) + recur_fibo(n-2))\", \n",
    "                 criteria=[\"Assert that the function can take in all inputs necessary to complete the process\",\n",
    "                           \"Assert that all outputs are of the proper sizes.\"]\n",
    "                 ):\n",
    "        self.criteria = criteria\n",
    "        self.example = prompt_example(example_in, example_out)\n",
    "        self.input_code = input_code\n",
    "        \n",
    "        # default params that are less likely to change\n",
    "        self.intro = \"You are a helpful bot that adds assertions to pieces of Python code.\"  \n",
    "        self.input_format = \"You will be given a list of variables and a string of code presented in the format:\\n*Variables:\\n[...]\\n*Code:\\n...\"\n",
    "        self.criteria_transition = \"Generate assertions based on the following criteria:\"\n",
    "        self.output_format = \"Your response should ONLY be a list of assertions in the format:\\n[line_number, subject_variable, condition_type, target, reasoning]\"\n",
    "        self.output_format_description = [\"line_number is an integer referencing the line after which the assertion should be inserted\",\n",
    "                                          \"subject_variable and target can ONLY be variables from the input list OR integers\",\n",
    "                                          \"condition_type can only be a value in this list: [==, >=, <=, !=]\",\n",
    "                                          \"reasoning is a short decription of why the assertion was made\"]\n",
    "        self.example_transition = \"Here is an example of what your input will look like and what you should return:\"\n",
    "        self.input_transition = \"Here is the actual input you should provide assertions for:\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def composite_criteria(self):\n",
    "        \"\"\" return criteria as a single string\"\"\"\n",
    "        ret = \"\"\n",
    "        for i, crit in enumerate(self.criteria):\n",
    "            ret += str(i+1) + \") \" + crit\n",
    "            if i != len(self.criteria)-1:  # ignore last instance for formatting\n",
    "                ret += '\\n'\n",
    "        return ret\n",
    "    \n",
    "    def composite_output_formatting(self):\n",
    "        ret = self.output_format\n",
    "        for desc in self.output_format_description:\n",
    "            ret += \"\\n -\" + desc \n",
    "        return ret\n",
    "    \n",
    "    def prompt(self):\n",
    "        \"\"\" return entire prompt\"\"\"\n",
    "        return '\\n'.join([self.intro, self.input_format,\n",
    "                          self.criteria_transition, self.composite_criteria(), \"\",\n",
    "                          self.composite_output_formatting(), \"\",\n",
    "                          self.example_transition, self.example.composite(), \"\\n\",\n",
    "                          self.input_transition, self.input_code])\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\" return key prompt components as a list \"\"\"\n",
    "        return [self.intro, self.formatting, self.criteria, self.example, self.input_code, self.prompt()]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.prompt()\n",
    "    def __repr__(self):\n",
    "        return self.prompt()\n",
    "\n",
    "tester = LLM_prompt()\n",
    "print(len(str(tester)))\n",
    "tester\n",
    "\n",
    "# fib_input = \"def fibonacci(n):\\nassert n >= 1\\nif n <= 1:\\nreturn n\\nelse:\\nreturn(recur_fibo(n-1) + recur_fibo(n-2))\"\n",
    "# fib_output = \"[1, n, 1, 1, the fibonacci sequence can only be done on posative integers]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e44a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_prompts(temp_df):\n",
    "    prompts = []\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        # *Variables:\\n[flag, num, i]\\n*Code:\\n\n",
    "        prompt_param = \"*Variables:\\n\" + str(row[\"variables\"]) + \"\\n*Code:\\n\" + row[\"unasserted\"]\n",
    "        prompts.append(str(LLM_prompt(prompt_param)))\n",
    "    temp_df[\"prompt\"] = prompts\n",
    "    temp_df[\"prompt_len\"] = [len(p) for p in prompts]\n",
    "    return temp_df\n",
    "# tester_df = make_prompts(tester_df)\n",
    "# tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd866c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying\n",
    "import openai\n",
    "import altair as alt\n",
    "import json\n",
    "from vega_datasets import data\n",
    "\n",
    "OPENAI_API_KEY = \"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\" # os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "def run_gpt4(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# TODO: add coding language versatility\n",
    "def gpt_oneshot(input_prompt, directive=\"You are a helpful bot that adds assertions to pieces of Python code.\", verbose=False):\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]  # init\n",
    "    response = run_gpt4(message_hist)\n",
    "#     if verbose:\n",
    "#         print(\"chat_gpt: \", response, '\\n')\n",
    "#     message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "\n",
    "# print(\"\\n\\n\", gpt_oneshot(\"what do you do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87903c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING CODE\n",
      "Found data at /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/BigQuery/PythonAssertions100k.csv\n",
      "EXTRACTING ASSERTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33793it [00:06, 5371.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING VARIABLES\n",
      "GENERATING PROMPTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30358it [00:03, 9895.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING RESPONSES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 353/14782 [1:41:30<69:09:29, 17.25s/it]\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n} 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 13 Feb 2024 03:31:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '369', 'Connection': 'keep-alive', 'openai-processing-ms': '10638', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '80000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '79108', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '668ms', 'x-request-id': 'req_8e36b95806905ef5778168af3626807b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8549ff4dff3a7d1c-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(cwd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_prompts_withresponse.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# saving data\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 34\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mone_shot_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mone_shot_prompts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m responses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 28\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgpt_oneshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m responses\n\u001b[1;32m     30\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(cwd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_prompts_withresponse.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# saving data\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mgpt_oneshot\u001b[0;34m(input_prompt, directive, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_oneshot\u001b[39m(input_prompt, directive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful bot that adds assertions to pieces of Python code.\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     message_hist \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: directive},\n\u001b[1;32m     20\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt}]  \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     if verbose:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         print(\"chat_gpt: \", response, '\\n')\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     message_hist.append({\"role\": \"system\", \"content\": response})\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mrun_gpt4\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_gpt4\u001b[39m(messages):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n} 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_8e36b95806905ef5778168af3626807b in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 13 Feb 2024 03:31:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '369', 'Connection': 'keep-alive', 'openai-processing-ms': '10638', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '80000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '79108', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '668ms', 'x-request-id': 'req_8e36b95806905ef5778168af3626807b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8549ff4dff3a7d1c-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "def one_shot_prompts():\n",
    "    print(\"GETTING CODE\")\n",
    "    df = get_asserted_code(cwd+\"/Data/BigQuery/PythonAssertions100k.csv\", \"%.py\", False)\n",
    "    \n",
    "    print(\"EXTRACTING ASSERTIONS\")\n",
    "    df = get_assertion(df)\n",
    "    \n",
    "#     print(\"Dropping Data with No Parsed Lines:\")\n",
    "#     no_parsed = len(tester_df[tester_df[\"parsed_lines\"]==0])\n",
    "#     print(\"#UnParsed / Total =\", (no_parsed/len(tester_df)))\n",
    "    df = df[df[\"parsed_lines\"]!=0]\n",
    "    \n",
    "    print(\"EXTRACTING VARIABLES\")\n",
    "    get_vars = lambda code: get_variables(code)\n",
    "    df[\"variables\"] = df[\"content\"].apply(get_vars)\n",
    "    \n",
    "    print(\"GENERATING PROMPTS\")\n",
    "    df = make_prompts(df)\n",
    "    \n",
    "    df.to_csv(cwd+\"/python_prompts_noresponse.csv\") # saving data\n",
    "    print(\"data saved...\\n\")\n",
    "    \n",
    "    prompt_limit = 8192\n",
    "    df = df[df[\"prompt_len\"] <= prompt_limit]\n",
    "    \n",
    "    print(\"GENERATING RESPONSES\")\n",
    "    responses = []\n",
    "    for prompt in tqdm(df[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    df[\"prompt\"] = responses\n",
    "    df.to_csv(cwd+\"/python_prompts_withresponse.csv\") # saving data\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = one_shot_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a60129",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_limit = 8192\n",
    "df = pd.read_csv(cwd+\"/python_prompts_noresponse.csv\")\n",
    "df = df[df[\"prompt_len\"] <= prompt_limit]\n",
    "df.to_csv(cwd+\"/python_prompts_noresponse.csv\")\n",
    "print(\"dont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b270fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prompts for indexes 0 to 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▉                                      | 31/200 [13:49<1:15:22, 26.76s/it]\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 14067 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, (cwd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/Testing/python_prompts_withresponse_part\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(part)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mpartial_execution\u001b[0;34m(part)\u001b[0m\n\u001b[1;32m      8\u001b[0m responses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 10\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgpt_oneshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m responses\n\u001b[1;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv((cwd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/Testing/python_prompts_withresponse_part\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(part)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# saving data\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mgpt_oneshot\u001b[0;34m(input_prompt, directive, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_oneshot\u001b[39m(input_prompt, directive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful bot that adds assertions to pieces of Python code.\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     message_hist \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: directive},\n\u001b[1;32m     20\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt}]  \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     if verbose:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         print(\"chat_gpt: \", response, '\\n')\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     message_hist.append({\"role\": \"system\", \"content\": response})\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mrun_gpt4\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_gpt4\u001b[39m(messages):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 14067 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "part_size = 200\n",
    "def partial_execution(part=1):  # slices of 10xt\n",
    "    start = (part-1)*part_size\n",
    "    end = start+part_size\n",
    "    df = pd.read_csv(cwd+\"/python_prompts_noresponse.csv\").iloc[start:end]\n",
    "    print(\"Generating prompts for indexes\", start, \"to\", end)\n",
    "    \n",
    "    responses = []\n",
    "    for prompt in tqdm(df[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    df[\"prompt\"] = responses\n",
    "    \n",
    "    df.to_csv((cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"), index=False) # saving data\n",
    "    print(\"Saved to:\", (cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"))\n",
    "    return df\n",
    "\n",
    "df = partial_execution(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927da6",
   "metadata": {},
   "source": [
    "## Step 3) Parse & Evaluate GPT's Response\n",
    "\n",
    "### Step 3.1) Restore the assertion(s) generated to code and evaluate\n",
    "> Metrics of evaluation, does it run? does it add to the code? is it ground-truth-like? human evaluator rank? gpt evaluator rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8a956fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [115]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parsed_code), asserts\n\u001b[1;32m     24\u001b[0m example_response \u001b[38;5;241m=\u001b[39m tester_df\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexample_response\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m temp_test \u001b[38;5;241m=\u001b[39m get_gpt_assertions(example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munasserted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'"
     ]
    }
   ],
   "source": [
    "def get_gpt_assertions(response, code):\n",
    "    \"\"\" takes in chat gpt's response and outputs its assertions as well as a string of code with said assertions in it \"\"\"\n",
    "    asserts = []\n",
    "    parsed_code = code.split('\\n')\n",
    "    for line in response.split('\\n'):\n",
    "        line.replace('[', '').replace(']', '')\n",
    "        separated = line.split(',')\n",
    "        full_assert = separated[1:-1] # ommit reasoning\n",
    "        \n",
    "        # TODO: handle case where there are other ints in the code\n",
    "        line_num = separated[0]\n",
    "        num_size = len(str(line_num))\n",
    "        has_found = False\n",
    "        for i, line in enumerate(parsed_code):\n",
    "            if line_num in line[:num_size+1]:\n",
    "                parsed_code.insert(i+1, full_assert)\n",
    "                asserts.append(full_assert)\n",
    "                has_found = True\n",
    "                break\n",
    "        if not has_found:\n",
    "            print(\"Could not find location of\\n\", full_assert, \"\\nin\\n\", code)\n",
    "    return '\\n'.join(parsed_code), asserts\n",
    "\n",
    "example_response = tester_df.sample()\n",
    "print(example_response[\"gpt\"].iloc[0])\n",
    "temp_test = get_gpt_assertions(example_response[\"gpt\"].iloc[0], example_response[\"unasserted\"].iloc[0])\n",
    "print(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_asserted_code = []  # snippets of code greated by the response assertions from gpt\n",
    "gpt_assertions = []  # the decoded assertions themselves\n",
    "gpt_num_assertions = []  # the number of assertions gpt generated\n",
    "gpt_ratio_assertions = []   # num_gen_assertions / num_parsed_assertions\n",
    "gpt_matched_assertions = []  # assertions that roughly equal ground-truth\n",
    "gpt_matched_assertions_ratio = []  # num_matched_assertions / num_ground_truth_assertions\n",
    "\n",
    "for i, row in tester_df.iterrows():\n",
    "    new_code, asserts = get_gpt_assertions(row[\"gpt\"], row[\"Unasserted\"])\n",
    "    gpt_asserted_code.append(new_code)\n",
    "    gpt_assertions.append(asserts)\n",
    "    gpt_num_assertions.append(len(asserts))\n",
    "    gpt_ratio_assertions.append(len(asserts)/row[\"parsed_lines\"])\n",
    "    # TODO get number of matching assertions\n",
    "    matched_num = ...\n",
    "    gpt_matched_assertions.append(matched_num)\n",
    "    gpt_matched_assertions_ratio.append(matched_num/len(asserts))\n",
    "tester_df[\"gpt_asserted_code\"] = gpt_asserted_code\n",
    "tester_df[\"gpt_assertions\"] = gpt_assertions\n",
    "tester_df[\"gpt_num_assertions\"] = gpt_num_assertions\n",
    "tester_df[\"gpt_ratio_assertions\"] = gpt_ratio_assertions\n",
    "tester_df[\"gpt_matched_assertions\"] = gpt_matched_assertions\n",
    "tester_df[\"gpt_matched_assertions_ratio\"] = gpt_matched_assertions_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefc5cd",
   "metadata": {},
   "source": [
    "## Step 4) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae2772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
