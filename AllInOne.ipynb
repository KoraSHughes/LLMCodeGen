{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0e8fd",
   "metadata": {},
   "source": [
    "# This file automates the entire pipeline for assertion generation with chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05e28d",
   "metadata": {},
   "source": [
    "## Step 1) Get Asserted Code From Github\n",
    "\n",
    "### Step 1.1) Clean and process the code\n",
    "### Step 1.2) Extract Ground-Truth Assertions & Relevant Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string=\"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT \"\"\"\n",
    "\n",
    "def get_asserted_code(num=100000, verbose=True):\n",
    "    query_string += str(num)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"*Running Query:\")\n",
    "        print(query_string)\n",
    "        print()\n",
    "    client = bq.Client()\n",
    "    df = (\n",
    "        client.query(query_string)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            create_bqstorage_client=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # handling duplicates\n",
    "    init_len = len(df)\n",
    "    df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True)\n",
    "    if verbose:\n",
    "        print(\"Duplicate Ratio = \", (len(df)/init_len))\n",
    "        \n",
    "    # derive assertions\n",
    "    if verbose:\n",
    "        print(\"*Extracting Assertions\")\n",
    "    df[\"assertions\"] = df[\"content\"].apply(lambda code: get_assertions(code, True, verbose))\n",
    "    return df\n",
    "\n",
    "\n",
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]  # TODO: properly account for OR\n",
    "bad_statements = [\"or\"]  # TODO: check for more than just 1 index\n",
    "# TODO: experiment with smaller content window for assertions\n",
    "def get_assertions(func, is_split=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    lines = [temp.strip() for temp in func.split('\\n') if \"assert\" in temp and bad_statements[0] not in temp]\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        start = data.find('assert')\n",
    "        if start != -1:\n",
    "            # account for combination statements\n",
    "            for statement in compounding_statements:\n",
    "                add_statement = data.find(statement)\n",
    "                if add_statement != -1:\n",
    "                    extra_line = data[add_statement+len(statement):]\n",
    "                    lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                    data = data[:add_statement].strip()\n",
    "            \n",
    "            com = data.find(',')   # parsing out return_string\n",
    "            if com != -1:\n",
    "                data = data[:com]\n",
    "\n",
    "            if is_split:\n",
    "                data = [var.strip() for var in data.split()]\n",
    "                assert data[0] == \"assert\", \"something was found before the assertion in this line\"\n",
    "                data = data[1:]\n",
    "                \n",
    "                condition = True  # assertion [variable] == condition by default\n",
    "                if data[0] == \"not\":  # accounting for not\n",
    "                    condition = False\n",
    "                    data = data[1:]\n",
    "                    \n",
    "                assert len(data) >= 1, \"empty assertion found?: \" + data\n",
    "                if len(data) == 1:  # adding == to simlify\n",
    "                    data = data + [\"==\", str(condition)]\n",
    "                \n",
    "                for i in range(len(data)):\n",
    "                    if data[i] == \"is\":  # simplifying is to ==\n",
    "                        data[i] = \"==\"\n",
    "                    if data[i] in conditionals.keys():  # com\n",
    "                        data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                        break\n",
    "            \n",
    "            if verbose and len(data) != 3:\n",
    "                print(\"Weird assertion found:\\n\", data, '\\n', '\\n'.join(lines[ind-1:ind+2]))\n",
    "                print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "            else:\n",
    "                out.append(data)\n",
    "        ind += 1\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281ea80",
   "metadata": {},
   "source": [
    "## Step 2) Generate LLM Prompt & Query a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(asserted_code, verbose=True):\n",
    "    ...\n",
    "    \n",
    "    \n",
    "banned_vars = ['', '*', 'self']\n",
    "def get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "get_vars = lambda code: get_variables(code)\n",
    "df[\"variables\"] = df[\"content\"].apply(get_vars)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e16137",
   "metadata": {},
   "source": [
    "## Step 3) Parse & Evaluate GPT's Response\n",
    "\n",
    "### Step 3.1) Restore the assertion(s) generated to code and evaluate\n",
    "> Metrics of evaluation, does it run? does it add to the code? is it ground-truth-like? human evaluator rank? gpt evaluator rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9a8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
