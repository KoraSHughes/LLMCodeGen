{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()  # get directory for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7dd9d",
   "metadata": {},
   "source": [
    "# This file automates the entire pipeline for assertion generation with chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bc35b",
   "metadata": {},
   "source": [
    "## Step 1) Get Asserted Code From Github\n",
    "\n",
    "### Step 1.1) Clean and process the code\n",
    "### Step 1.2) Extract Ground-Truth Assertions & Relevant Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "126af672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data at /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/BigQuery/PythonAssertions100k.csv\n",
      "*Handling Duplicates...\n",
      "Duplicate Ratio =  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tqchen/tvm</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lujeni/ansible</td>\n",
       "      <td># (c) 2017 Red Hat Inc.\\n#\\n# This file is par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lukas-hetzenecker/home-assistant</td>\n",
       "      <td>\"\"\"The tests for the Pilight sensor platform.\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schnoebe/fedora-mock</td>\n",
       "      <td>import fcntl\\nimport glob\\nimport grp\\nimport ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samstav/fastfood</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33788</th>\n",
       "      <td>raphaelm/django-i18nfield</td>\n",
       "      <td>from i18nfield.admin import I18nModelAdmin\\nfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33789</th>\n",
       "      <td>fniephaus/alfred-rworkflow</td>\n",
       "      <td># The MIT License (MIT)\\n#\\n# Copyright (c) 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33790</th>\n",
       "      <td>bgris/ODL_bgris</td>\n",
       "      <td># -*- coding: utf-8 -*-\\r\\n#\\r\\n# Copyright © ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33791</th>\n",
       "      <td>chrsrds/scikit-learn</td>\n",
       "      <td>\"\"\"\\nTesting for the base module (sklearn.ense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33792</th>\n",
       "      <td>perimosocordiae/bigO</td>\n",
       "      <td>'''Symbolic manipulation of Big-O complexities...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo_name  \\\n",
       "0                            tqchen/tvm   \n",
       "1                        Lujeni/ansible   \n",
       "2      lukas-hetzenecker/home-assistant   \n",
       "3                  schnoebe/fedora-mock   \n",
       "4                      samstav/fastfood   \n",
       "...                                 ...   \n",
       "33788         raphaelm/django-i18nfield   \n",
       "33789        fniephaus/alfred-rworkflow   \n",
       "33790                   bgris/ODL_bgris   \n",
       "33791              chrsrds/scikit-learn   \n",
       "33792              perimosocordiae/bigO   \n",
       "\n",
       "                                                 content  \n",
       "0      # Licensed to the Apache Software Foundation (...  \n",
       "1      # (c) 2017 Red Hat Inc.\\n#\\n# This file is par...  \n",
       "2      \"\"\"The tests for the Pilight sensor platform.\"...  \n",
       "3      import fcntl\\nimport glob\\nimport grp\\nimport ...  \n",
       "4      # -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...  \n",
       "...                                                  ...  \n",
       "33788  from i18nfield.admin import I18nModelAdmin\\nfr...  \n",
       "33789  # The MIT License (MIT)\\n#\\n# Copyright (c) 20...  \n",
       "33790  # -*- coding: utf-8 -*-\\r\\n#\\r\\n# Copyright © ...  \n",
       "33791  \"\"\"\\nTesting for the base module (sklearn.ense...  \n",
       "33792  '''Symbolic manipulation of Big-O complexities...  \n",
       "\n",
       "[33793 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "def get_asserted_code(num=100000, ext=\"%.py\", verbose=True):\n",
    "    query_string = \"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT \"\"\" + str(num)\n",
    "    \n",
    "    if isinstance(num, int):\n",
    "        secret_dir = \"Data/secret/\"\n",
    "        api_key = cwd + \"/\" + secret_dir + os.listdir(secret_dir)[0]\n",
    "        assert api_key[-5:] == \".json\"  # confirm that it was found\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = api_key\n",
    "        query_string = query_string.replace(\"%.py\", ext)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"*Running Query:\")\n",
    "            print(query_string)\n",
    "            print()\n",
    "        client = bq.Client()\n",
    "        df = (\n",
    "            client.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(\n",
    "                create_bqstorage_client=True,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(num, str):\n",
    "        # load data from file\n",
    "        df = pd.read_csv(num)\n",
    "        print(\"Found data at\", num)\n",
    "    else:\n",
    "        print(\"first param type undefined, must be string signifying directory of csv or\\\n",
    "               int signifying number of records to scrib from bigquery...\")\n",
    "        assert False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"*Handling Duplicates...\")\n",
    "    init_len = len(df)\n",
    "    df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True)\n",
    "    if verbose:\n",
    "        print(\"#Non-duplicates / #Total Retrieved =\", (len(df)/init_len))\n",
    "    return df\n",
    "\n",
    "# small test\n",
    "verilog_dir = cwd+\"/Data/BigQuery/VerilogAssertions-ALL.csv\"\n",
    "python_dir = cwd+\"/Data/BigQuery/PythonAssertions100k.csv\"\n",
    "df = get_asserted_code(python_dir)  # 10\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "857dd192",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 2117.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>ajhager/copycat</td>\n",
       "      <td># --------------------------------------------...</td>\n",
       "      <td>\\n1# -----------------------------------------...</td>\n",
       "      <td>[[_debug('DirectSound, play')], [_debug('retur...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>CxAalto/gtfspy</td>\n",
       "      <td>import copy\\n\\nfrom gtfspy.routing.label impor...</td>\n",
       "      <td>\\n1import copy\\n2\\n3from gtfspy.routing.label ...</td>\n",
       "      <td>[[(hasattr(label, ==, True], [(hasattr(label, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>fmaguire/scripts</td>\n",
       "      <td>#!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...</td>\n",
       "      <td>\\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...</td>\n",
       "      <td>[[False, ==, True], [False, ==, True]]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>jazcollins/models</td>\n",
       "      <td># Copyright 2016 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2016 Google Inc. All Rights Res...</td>\n",
       "      <td>[[dataset.data_files(), ==, True]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fasbit/p2pool-dime</td>\n",
       "      <td># Copyright (c) 2003, The Regents of the Unive...</td>\n",
       "      <td>\\n1# Copyright (c) 2003, The Regents of the Un...</td>\n",
       "      <td>[[node.ownerDocument, ==, not newOwnerDocument]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>panmari/tensorflow</td>\n",
       "      <td># Copyright 2015 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2015 Google Inc. All Rights Res...</td>\n",
       "      <td>[[test_error, ==, 0.0]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>cfei18/incubator-airflow</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "      <td>\\n1# Licensed to the Apache Software Foundatio...</td>\n",
       "      <td>[[result, ==, mock_object.to_dict.return_value...</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17059</th>\n",
       "      <td>plum-umd/pasket</td>\n",
       "      <td>import operator as op\\nfrom functools import p...</td>\n",
       "      <td>\\n1import operator as op\\n2from functools impo...</td>\n",
       "      <td>[[{aux.subject}, !=, {aux.observer};], [subcls...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>HaraldWeber/client</td>\n",
       "      <td>\\nfrom PyQt4.QtCore import QIODevice, QDataStr...</td>\n",
       "      <td>\\n1\\n2from PyQt4.QtCore import QIODevice, QDat...</td>\n",
       "      <td>[[self._header_given, ==, False], [self._heade...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33136</th>\n",
       "      <td>glemaitre/scikit-learn</td>\n",
       "      <td>\"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...</td>\n",
       "      <td>\\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...</td>\n",
       "      <td>[[(self.is_clf, ==, False], [self.alpha_per_ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo_name  \\\n",
       "9017            ajhager/copycat   \n",
       "6276             CxAalto/gtfspy   \n",
       "27048          fmaguire/scripts   \n",
       "3421          jazcollins/models   \n",
       "188          fasbit/p2pool-dime   \n",
       "...                         ...   \n",
       "1407         panmari/tensorflow   \n",
       "8686   cfei18/incubator-airflow   \n",
       "17059           plum-umd/pasket   \n",
       "27455        HaraldWeber/client   \n",
       "33136    glemaitre/scikit-learn   \n",
       "\n",
       "                                                 content  \\\n",
       "9017   # --------------------------------------------...   \n",
       "6276   import copy\\n\\nfrom gtfspy.routing.label impor...   \n",
       "27048  #!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...   \n",
       "3421   # Copyright 2016 Google Inc. All Rights Reserv...   \n",
       "188    # Copyright (c) 2003, The Regents of the Unive...   \n",
       "...                                                  ...   \n",
       "1407   # Copyright 2015 Google Inc. All Rights Reserv...   \n",
       "8686   # Licensed to the Apache Software Foundation (...   \n",
       "17059  import operator as op\\nfrom functools import p...   \n",
       "27455  \\nfrom PyQt4.QtCore import QIODevice, QDataStr...   \n",
       "33136  \"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...   \n",
       "\n",
       "                                              unasserted  \\\n",
       "9017   \\n1# -----------------------------------------...   \n",
       "6276   \\n1import copy\\n2\\n3from gtfspy.routing.label ...   \n",
       "27048  \\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...   \n",
       "3421   \\n1# Copyright 2016 Google Inc. All Rights Res...   \n",
       "188    \\n1# Copyright (c) 2003, The Regents of the Un...   \n",
       "...                                                  ...   \n",
       "1407   \\n1# Copyright 2015 Google Inc. All Rights Res...   \n",
       "8686   \\n1# Licensed to the Apache Software Foundatio...   \n",
       "17059  \\n1import operator as op\\n2from functools impo...   \n",
       "27455  \\n1\\n2from PyQt4.QtCore import QIODevice, QDat...   \n",
       "33136  \\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...   \n",
       "\n",
       "                                              assertions  asserted_lines  \\\n",
       "9017   [[_debug('DirectSound, play')], [_debug('retur...              24   \n",
       "6276   [[(hasattr(label, ==, True], [(hasattr(label, ...               9   \n",
       "27048             [[False, ==, True], [False, ==, True]]               2   \n",
       "3421                  [[dataset.data_files(), ==, True]]               1   \n",
       "188     [[node.ownerDocument, ==, not newOwnerDocument]]               1   \n",
       "...                                                  ...             ...   \n",
       "1407                             [[test_error, ==, 0.0]]               1   \n",
       "8686   [[result, ==, mock_object.to_dict.return_value...              28   \n",
       "17059  [[{aux.subject}, !=, {aux.observer};], [subcls...              23   \n",
       "27455  [[self._header_given, ==, False], [self._heade...               6   \n",
       "33136  [[(self.is_clf, ==, False], [self.alpha_per_ta...               1   \n",
       "\n",
       "       parsed_lines       arr       atl  \n",
       "9017             24  1.000000  0.001402  \n",
       "6276              7  0.777778  0.000764  \n",
       "27048             2  1.000000  0.000383  \n",
       "3421              1  1.000000  0.000782  \n",
       "188               1  1.000000  0.000020  \n",
       "...             ...       ...       ...  \n",
       "1407              1  1.000000  0.000077  \n",
       "8686              8  0.285714  0.000608  \n",
       "17059            21  0.913043  0.000734  \n",
       "27455             4  0.666667  0.001055  \n",
       "33136             2  2.000000  0.000026  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]\n",
    "bad_statements = [\" or \", \" in \", \"isinstance\"]  # TODO: properly account for OR\n",
    "def parse_assertions(func, is_split=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \n",
    "    Exceptions to Handle:\n",
    "    - 'in'/'not in' keyword\n",
    "    - boolean functions - ex. isinstance(var, type)\n",
    "    - separation of attributes - ex. len(var), var[i]\n",
    "    \"\"\"\n",
    "#     if verbose:\n",
    "#         print(\"*Extracting Assertions...\")\n",
    "    out = []\n",
    "    asserted_lines = 0\n",
    "    lines = []\n",
    "    for temp in func.split('\\n'):  # find lines with assert in them\n",
    "        if \"assert\" in temp:\n",
    "            asserted_lines += 1\n",
    "            bad_flag = False\n",
    "            for bad in bad_statements:\n",
    "                if bad in temp:\n",
    "                    bad_flag = True\n",
    "            if not bad_flag:\n",
    "                lines.append(temp.strip())\n",
    "    # TODO: experiment with smaller content window for assertions\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        start = data.find('assert')\n",
    "        if start == -1:  # double checking that the assertion exists in this line\n",
    "            ind += 1\n",
    "            continue\n",
    "        # account for combination statements\n",
    "        for statement in compounding_statements:\n",
    "            add_statement = data.find(statement)\n",
    "            if add_statement != -1:\n",
    "                extra_line = data[add_statement+len(statement):]\n",
    "                lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                data = data[:add_statement].strip()\n",
    "\n",
    "        com = data.find(',')   # parsing out return_string\n",
    "        if com != -1:\n",
    "            data = data[:com]\n",
    "        com = data.find('#')\n",
    "        if com != -1:   # parsing out comments\n",
    "            if com < start:  # if the assertion itself is a comment\n",
    "                ind += 1\n",
    "                continue\n",
    "            else:\n",
    "                data = data[:com]\n",
    "\n",
    "        if is_split:  # splitting the assertion into components for analysis\n",
    "            data = [var.strip() for var in data.split(' ') if len(var.strip()) > 0]\n",
    "            \n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "                \n",
    "            if data[0] != \"assert\":  # edge case: something before the 'assert' statement\n",
    "                ind += 1\n",
    "#                 if verbose:\n",
    "#                     print(\"something was found before the assertion on this line:\\n\", data)\n",
    "                continue\n",
    "    \n",
    "            data = data[1:]  # from here on we only care about the content after the 'assert' keyword\n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "\n",
    "            condition = True  # assertion [variable] == condition by default\n",
    "            if data[0] == \"not\":  # accounting for 'not' keyword\n",
    "                condition = False\n",
    "                data = data[1:]\n",
    "            \n",
    "            if len(data) == 1:  # adding == to simlify\n",
    "                data = data + [\"==\", str(condition)]\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                if data[i] == \"is\":  # simplifying is to ==\n",
    "                    data[i] = \"==\"\n",
    "                if data[i] in conditionals.keys():  # parsing common conditionals\n",
    "                    data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                    break\n",
    "\n",
    "        if verbose and len(data) != 3:\n",
    "            print(\"Weird assertion found:\\n\", data, '\\n', lines[ind])\n",
    "            print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "        else:\n",
    "            out.append(data)\n",
    "        ind += 1\n",
    "    return out, asserted_lines\n",
    "\n",
    "def unassert(code, delim=''):\n",
    "    out = \"\"\n",
    "    counter = 1\n",
    "    for line in code.split('\\n'):\n",
    "        if \"assert\" not in line:\n",
    "            out += '\\n'+str(counter)+delim+line\n",
    "            counter += 1\n",
    "    return out\n",
    "\n",
    "def get_assertion(temp_df, verbose=False, unassert_col=True, add_stats=True):\n",
    "    \"\"\" run assertion generation \"\"\"\n",
    "    # tester_df[\"assertions\"] = tester_df[\"content\"].apply(lambda code: get_assertions(code))\n",
    "    \n",
    "    assertions = []  # list of parsed assertions\n",
    "    asserted_lines = []  # number of lines with 'assert' in them\n",
    "    parsed_lines = []  # number of assertions easily parsed\n",
    "    arr = []  # assertion recovery ratio\n",
    "    atl = []  # assertions to size\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        parsed, lines = parse_assertions(row[\"content\"], True, verbose)\n",
    "        assertions.append(parsed)\n",
    "        asserted_lines.append(lines)\n",
    "        parsed_lines.append(len(parsed))\n",
    "        arr.append(len(parsed)/lines)\n",
    "        atl.append(len(parsed)/len(row[\"content\"]))\n",
    "\n",
    "    if unassert_col:\n",
    "        temp_df[\"unasserted\"] = tester_df[\"content\"].apply(lambda code: unassert(code))\n",
    "    \n",
    "    if add_stats:\n",
    "        temp_df[\"assertions\"] = assertions\n",
    "        temp_df[\"asserted_lines\"] = asserted_lines\n",
    "        temp_df[\"parsed_lines\"] = parsed_lines\n",
    "        temp_df[\"arr\"] = arr\n",
    "        temp_df[\"atl\"] = atl\n",
    "    return temp_df\n",
    "\n",
    "tester_df = df.sample(200)\n",
    "tester_df = get_assertion(tester_df)\n",
    "tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45c88c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Data with No Parsed Lines:\n",
      "#UnParsed / Total = 0.155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.982249</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>0.827620</td>\n",
       "      <td>0.001812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.482537</td>\n",
       "      <td>25.584361</td>\n",
       "      <td>0.314285</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>451.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.014377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       asserted_lines  parsed_lines         arr         atl\n",
       "count      169.000000    169.000000  169.000000  169.000000\n",
       "mean        17.982249     11.384615    0.827620    0.001812\n",
       "std         44.482537     25.584361    0.314285    0.002584\n",
       "min          1.000000      1.000000    0.011364    0.000010\n",
       "25%          2.000000      1.000000    0.666667    0.000156\n",
       "50%          4.000000      3.000000    1.000000    0.000560\n",
       "75%         16.000000     11.000000    1.000000    0.002602\n",
       "max        451.000000    227.000000    2.000000    0.014377"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dropping Data with No Parsed Lines:\")\n",
    "no_parsed = len(tester_df[tester_df[\"parsed_lines\"]==0])\n",
    "print(\"#UnParsed / Total =\", (no_parsed/len(tester_df)))\n",
    "tester_df = tester_df[tester_df[\"parsed_lines\"]!=0]\n",
    "\n",
    "tester_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25d19f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2022 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#      http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "from faker import Faker\n",
      "\n",
      "from bms_app.models import (\n",
      "    Config, Label, Mapping, Operation, OperationDetails, OperationDetailsError,\n",
      "    Project, RestoreConfig, ScheduledTask, SourceDB, Wave, db\n",
      ")\n",
      "\n",
      "from .factories import (\n",
      "    BMSServerFactory, ConfigFactory, LabelFactory, MappingFactory,\n",
      "    OperationDetailsErrorFactory, OperationDetailsFactory, OperationFactory,\n",
      "    ProjectFactory, RestoreConfigFactory, ScheduledTaskFactory,\n",
      "    SourceDBFactory, WaveFactory\n",
      ")\n",
      "\n",
      "\n",
      "fk = Faker()\n",
      "\n",
      "\n",
      "add_project_data = {\n",
      "    'name': 'pr-1',\n",
      "    'description': 'desc-1',\n",
      "    'vpc': 'vpc',\n",
      "    'subnet': 'subnet',\n",
      "}\n",
      "\n",
      "edit_project_data = {\n",
      "    'name': fk.word(),\n",
      "    'description': fk.text(50),\n",
      "    'vpc': fk.word(),\n",
      "    'subnet': fk.word(),\n",
      "}\n",
      "\n",
      "\n",
      "def test_add_project(client):\n",
      "    \"\"\"Test adding project\"\"\"\n",
      "    req = client.post('/api/projects', json=add_project_data)\n",
      "    assert req.status_code == 201\n",
      "    assert 'id' in req.json\n",
      "\n",
      "    pr = Project.query.get(req.json['id'])\n",
      "    assert pr\n",
      "\n",
      "    assert pr.name == add_project_data['name']\n",
      "    assert pr.description == add_project_data['description']\n",
      "    assert pr.vpc == add_project_data['vpc']\n",
      "    assert pr.subnet == add_project_data['subnet']\n",
      "\n",
      "\n",
      "def test_add_project_unique_name_err(client):\n",
      "    pr = ProjectFactory()\n",
      "\n",
      "    add_project_data = {\n",
      "        'name': pr.name,\n",
      "        'description': 'desc-1',\n",
      "        'vpc': 'vpc',\n",
      "        'subnet': 'subnet',\n",
      "    }\n",
      "\n",
      "    req = client.post('/api/projects', json=add_project_data)\n",
      "\n",
      "    assert req.status_code == 400\n",
      "\n",
      "\n",
      "def test_get_all_projects(client):\n",
      "    \"\"\"Start with a blank database.\"\"\"\n",
      "    pr_1 = ProjectFactory.create()\n",
      "    pr_2 = ProjectFactory.create()\n",
      "\n",
      "    req = client.get('/api/projects')\n",
      "\n",
      "    assert req.status_code == 200\n",
      "    data = req.json.get('data')\n",
      "\n",
      "    assert data\n",
      "    assert isinstance(data, list)\n",
      "    assert len(data) == 2\n",
      "\n",
      "    assert {\n",
      "        'id': pr_1.id,\n",
      "        'name': pr_1.name,\n",
      "        'description': pr_1.description,\n",
      "        'vpc': pr_1.vpc,\n",
      "        'subnet': pr_1.subnet,\n",
      "    } in data\n",
      "\n",
      "    assert {\n",
      "        'id': pr_2.id,\n",
      "        'name': pr_2.name,\n",
      "        'description': pr_2.description,\n",
      "        'vpc': pr_2.vpc,\n",
      "        'subnet': pr_2.subnet,\n",
      "    } in data\n",
      "\n",
      "\n",
      "def test_get_a_project(client):\n",
      "    \"\"\"Start with a blank database.\"\"\"\n",
      "    pr_1 = ProjectFactory.create()\n",
      "    ProjectFactory.create()\n",
      "\n",
      "    req = client.get(f'/api/projects/{pr_1.id}')\n",
      "\n",
      "    assert req.status_code == 200\n",
      "    data = req.json\n",
      "\n",
      "    assert data\n",
      "    assert isinstance(data, dict)\n",
      "    assert data == {\n",
      "        'id': pr_1.id,\n",
      "        'name': pr_1.name,\n",
      "        'description': pr_1.description,\n",
      "        'vpc': pr_1.vpc,\n",
      "        'subnet': pr_1.subnet,\n",
      "    }\n",
      "\n",
      "\n",
      "def test_delete_a_project(client):\n",
      "    \"\"\"Start with a blank database.\"\"\"\n",
      "    pr_1 = ProjectFactory.create()\n",
      "    ProjectFactory.create()\n",
      "\n",
      "    req = client.delete(f'/api/projects/{pr_1.id}')\n",
      "\n",
      "    assert req.status_code == 204\n",
      "    assert db.session.query(Project).count() == 1\n",
      "    assert not db.session.query(Project).get(pr_1.id)\n",
      "\n",
      "\n",
      "def test_edit_a_project(client):\n",
      "    \"\"\"Start with a blank database.\"\"\"\n",
      "    pr_1 = ProjectFactory.create()\n",
      "\n",
      "    req = client.put(f'/api/projects/{pr_1.id}', json=edit_project_data)\n",
      "\n",
      "    assert req.status_code == 200\n",
      "    assert req.json\n",
      "    assert isinstance(req.json, dict)\n",
      "\n",
      "    db_pr = db.session.query(Project).get(pr_1.id)\n",
      "    assert db_pr.name == edit_project_data['name']\n",
      "    assert db_pr.description == edit_project_data['description']\n",
      "    assert db_pr.vpc == edit_project_data['vpc']\n",
      "    assert db_pr.subnet == edit_project_data['subnet']\n",
      "\n",
      "\n",
      "def test_edit_project_unique_name_err(client):\n",
      "    pr_1 = ProjectFactory()\n",
      "    pr_2 = ProjectFactory()\n",
      "\n",
      "    edit_project_data = {\n",
      "        'name': pr_2.name,\n",
      "        'description': pr_1.description,\n",
      "        'vpc': pr_1.vpc,\n",
      "        'subnet': pr_1.subnet,\n",
      "    }\n",
      "\n",
      "    req = client.put(f'/api/projects/{pr_1.id}', json=edit_project_data)\n",
      "\n",
      "    assert req.status_code == 400\n",
      "\n",
      "\n",
      "def test_edit_project_update_the_same_name(client):\n",
      "    pr_1 = ProjectFactory()\n",
      "\n",
      "    edit_project_data = {\n",
      "        'name': pr_1.name,\n",
      "        'description': pr_1.description,\n",
      "        'vpc': pr_1.vpc,\n",
      "        'subnet': pr_1.subnet,\n",
      "    }\n",
      "\n",
      "    req = client.put(f'/api/projects/{pr_1.id}', json=edit_project_data)\n",
      "\n",
      "    assert req.status_code == 200\n",
      "\n",
      "\n",
      "def test_not_delete_project_with_wave(client):\n",
      "    \"\"\"Porject containg wave can not be deleted.\"\"\"\n",
      "    pr = ProjectFactory.create()\n",
      "    WaveFactory(project=pr)\n",
      "\n",
      "    req = client.delete(f'/api/projects/{pr.id}')\n",
      "\n",
      "    assert req.status_code == 400\n",
      "    assert db.session.query(Project == pr.id).count() == 1\n",
      "\n",
      "\n",
      "def test_not_delete_project_with_source_db(client):\n",
      "    \"\"\"Porject containg source db can not be deleted.\"\"\"\n",
      "    pr = ProjectFactory.create()\n",
      "    SourceDBFactory(project=pr)\n",
      "\n",
      "    req = client.delete(f'/api/projects/{pr.id}')\n",
      "\n",
      "    assert req.status_code == 400\n",
      "    assert Project.query.filter(Project.id == pr.id).count() == 1\n",
      "\n",
      "\n",
      "def test_delete_testing_project(client):\n",
      "    \"\"\"Deleting test project and all related data.\"\"\"\n",
      "    pr = ProjectFactory.create()\n",
      "    wave_1 = WaveFactory(project=pr)\n",
      "    wave_2 = WaveFactory(project=pr)\n",
      "    sdb_1 = SourceDBFactory(project=pr, wave=wave_1)\n",
      "    sdb_2 = SourceDBFactory(project=pr, wave=None)\n",
      "    ConfigFactory(source_db=sdb_1)\n",
      "    ConfigFactory(source_db=sdb_2)\n",
      "    bms_1 = BMSServerFactory()\n",
      "    bms_2 = BMSServerFactory()\n",
      "    map_1 = MappingFactory(source_db=sdb_1, bms=bms_1)\n",
      "    map_2 = MappingFactory(source_db=sdb_2, bms=bms_2)\n",
      "    RestoreConfigFactory(source_db=sdb_1)\n",
      "    RestoreConfigFactory(source_db=sdb_2)\n",
      "    ScheduledTaskFactory(source_db=sdb_1)\n",
      "    ScheduledTaskFactory(source_db=sdb_2)\n",
      "    op_1 = OperationFactory(wave=wave_1)\n",
      "    op_2 = OperationFactory(wave=wave_2)\n",
      "    op_det_1 = OperationDetailsFactory(mapping=map_1, wave=wave_1, operation=op_1)\n",
      "    op_det_2 = OperationDetailsFactory(mapping=map_2, wave=wave_2, operation=op_2)\n",
      "    OperationDetailsErrorFactory(operation_details=op_det_1)\n",
      "    OperationDetailsErrorFactory(operation_details=op_det_2)\n",
      "    LabelFactory(project=pr, source_dbs=[sdb_1, sdb_2])\n",
      "    LabelFactory(project=pr, source_dbs=[sdb_1])\n",
      "\n",
      "\n",
      "    # records that should not be deleted\n",
      "    other_wave = WaveFactory()\n",
      "    other_db = SourceDBFactory(wave=other_wave)\n",
      "    other_mapping = MappingFactory(source_db=other_db)\n",
      "    other_operation = OperationFactory(wave=other_wave)\n",
      "    OperationDetailsFactory(\n",
      "        wave=other_wave,\n",
      "        operation=other_operation,\n",
      "        mapping=other_mapping\n",
      "    )\n",
      "\n",
      "    req = client.delete(f'/api/projects/{pr.id}?force=True')\n",
      "\n",
      "    assert req.status_code == 204\n",
      "    assert Wave.query.count() == 1\n",
      "    assert SourceDB.query.count() == 1\n",
      "    assert Operation.query.count() == 1\n",
      "    assert OperationDetails.query.count() == 1\n",
      "    assert Project.query.filter(Project.id == pr.id).count() == 0\n",
      "    assert Mapping.query.count() == 1\n",
      "    assert Config.query.count() == 0\n",
      "    assert RestoreConfig.query.count() == 0\n",
      "    assert ScheduledTask.query.count() == 0\n",
      "    assert OperationDetailsError.query.count() == 0\n",
      "    assert Label.query.count() == 0\n",
      "\n",
      "    # assert not db.session.query(Mapping).join(SourceDB).filter(SourceDB.project_id == pr.id).all()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester_df = tester_df.sort_values(\"atl\", ascending=False)\n",
    "print(tester_df[\"content\"].iloc[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_df[\"content\"].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "331cbd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo_name                                       4bic/scraper_Mozmbq\n",
       "content           import os\\nimport dataset\\n\\nDATABASE_URI = os...\n",
       "unasserted        [import os, import dataset, , DATABASE_URI = o...\n",
       "assertions        [[DATABASE_URI, ==, not None], [DATA_PATH, ==,...\n",
       "asserted_lines                                                    2\n",
       "parsed_lines                                                      2\n",
       "arr                                                             1.0\n",
       "atl                                                        0.006757\n",
       "Name: 18594, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b4e6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_df.to_csv(\"parsable data 1.csv\")\n",
    "# 10th row*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d8683",
   "metadata": {},
   "source": [
    "## Step 2) Generate LLM Prompt & Query a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4aeaaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>ajhager/copycat</td>\n",
       "      <td># --------------------------------------------...</td>\n",
       "      <td>\\n1# -----------------------------------------...</td>\n",
       "      <td>[[_debug('DirectSound, play')], [_debug('retur...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>[_debug, coordinates, x, y, z, gain, Power gai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>CxAalto/gtfspy</td>\n",
       "      <td>import copy\\n\\nfrom gtfspy.routing.label impor...</td>\n",
       "      <td>\\n1import copy\\n2\\n3from gtfspy.routing.label ...</td>\n",
       "      <td>[[(hasattr(label, ==, True], [(hasattr(label, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>[labels, start_time_dep, end_time_dep, walk_du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>fmaguire/scripts</td>\n",
       "      <td>#!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...</td>\n",
       "      <td>\\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...</td>\n",
       "      <td>[[False, ==, True], [False, ==, True]]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>[command_string, return_code, unparsed_blast_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>jazcollins/models</td>\n",
       "      <td># Copyright 2016 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2016 Google Inc. All Rights Res...</td>\n",
       "      <td>[[dataset.data_files(), ==, True]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>[FLAGS, _, dataset]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fasbit/p2pool-dime</td>\n",
       "      <td># Copyright (c) 2003, The Regents of the Unive...</td>\n",
       "      <td>\\n1# Copyright (c) 2003, The Regents of the Un...</td>\n",
       "      <td>[[node.ownerDocument, ==, not newOwnerDocument]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>[ident, pyobj, x, qname, l, basejoin, #basejoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>panmari/tensorflow</td>\n",
       "      <td># Copyright 2015 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2015 Google Inc. All Rights Res...</td>\n",
       "      <td>[[test_error, ==, 0.0]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>[SOURCE_URL, WORK_DIRECTORY, IMAGE_SIZE, NUM_C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>cfei18/incubator-airflow</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "      <td>\\n1# Licensed to the Apache Software Foundatio...</td>\n",
       "      <td>[[result, ==, mock_object.to_dict.return_value...</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>[BASE_PATH, LOCATION, WORKFLOW_ID, EXECUTION_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17059</th>\n",
       "      <td>plum-umd/pasket</td>\n",
       "      <td>import operator as op\\nfrom functools import p...</td>\n",
       "      <td>\\n1import operator as op\\n2from functools impo...</td>\n",
       "      <td>[[{aux.subject}, !=, {aux.observer};], [subcls...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>[cls, __cnt, cls.__cnt, suffix, smpls, obs_con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>HaraldWeber/client</td>\n",
       "      <td>\\nfrom PyQt4.QtCore import QIODevice, QDataStr...</td>\n",
       "      <td>\\n1\\n2from PyQt4.QtCore import QIODevice, QDat...</td>\n",
       "      <td>[[self._header_given, ==, False], [self._heade...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>[VERSION, byteArray, stream, r, byte, buf, nby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33136</th>\n",
       "      <td>glemaitre/scikit-learn</td>\n",
       "      <td>\"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...</td>\n",
       "      <td>\\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...</td>\n",
       "      <td>[[(self.is_clf, ==, False], [self.alpha_per_ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>[X, y, alpha, max_iter, tol, verbose, X_offset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo_name  \\\n",
       "9017            ajhager/copycat   \n",
       "6276             CxAalto/gtfspy   \n",
       "27048          fmaguire/scripts   \n",
       "3421          jazcollins/models   \n",
       "188          fasbit/p2pool-dime   \n",
       "...                         ...   \n",
       "1407         panmari/tensorflow   \n",
       "8686   cfei18/incubator-airflow   \n",
       "17059           plum-umd/pasket   \n",
       "27455        HaraldWeber/client   \n",
       "33136    glemaitre/scikit-learn   \n",
       "\n",
       "                                                 content  \\\n",
       "9017   # --------------------------------------------...   \n",
       "6276   import copy\\n\\nfrom gtfspy.routing.label impor...   \n",
       "27048  #!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...   \n",
       "3421   # Copyright 2016 Google Inc. All Rights Reserv...   \n",
       "188    # Copyright (c) 2003, The Regents of the Unive...   \n",
       "...                                                  ...   \n",
       "1407   # Copyright 2015 Google Inc. All Rights Reserv...   \n",
       "8686   # Licensed to the Apache Software Foundation (...   \n",
       "17059  import operator as op\\nfrom functools import p...   \n",
       "27455  \\nfrom PyQt4.QtCore import QIODevice, QDataStr...   \n",
       "33136  \"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...   \n",
       "\n",
       "                                              unasserted  \\\n",
       "9017   \\n1# -----------------------------------------...   \n",
       "6276   \\n1import copy\\n2\\n3from gtfspy.routing.label ...   \n",
       "27048  \\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...   \n",
       "3421   \\n1# Copyright 2016 Google Inc. All Rights Res...   \n",
       "188    \\n1# Copyright (c) 2003, The Regents of the Un...   \n",
       "...                                                  ...   \n",
       "1407   \\n1# Copyright 2015 Google Inc. All Rights Res...   \n",
       "8686   \\n1# Licensed to the Apache Software Foundatio...   \n",
       "17059  \\n1import operator as op\\n2from functools impo...   \n",
       "27455  \\n1\\n2from PyQt4.QtCore import QIODevice, QDat...   \n",
       "33136  \\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...   \n",
       "\n",
       "                                              assertions  asserted_lines  \\\n",
       "9017   [[_debug('DirectSound, play')], [_debug('retur...              24   \n",
       "6276   [[(hasattr(label, ==, True], [(hasattr(label, ...               9   \n",
       "27048             [[False, ==, True], [False, ==, True]]               2   \n",
       "3421                  [[dataset.data_files(), ==, True]]               1   \n",
       "188     [[node.ownerDocument, ==, not newOwnerDocument]]               1   \n",
       "...                                                  ...             ...   \n",
       "1407                             [[test_error, ==, 0.0]]               1   \n",
       "8686   [[result, ==, mock_object.to_dict.return_value...              28   \n",
       "17059  [[{aux.subject}, !=, {aux.observer};], [subcls...              23   \n",
       "27455  [[self._header_given, ==, False], [self._heade...               6   \n",
       "33136  [[(self.is_clf, ==, False], [self.alpha_per_ta...               1   \n",
       "\n",
       "       parsed_lines       arr       atl  \\\n",
       "9017             24  1.000000  0.001402   \n",
       "6276              7  0.777778  0.000764   \n",
       "27048             2  1.000000  0.000383   \n",
       "3421              1  1.000000  0.000782   \n",
       "188               1  1.000000  0.000020   \n",
       "...             ...       ...       ...   \n",
       "1407              1  1.000000  0.000077   \n",
       "8686              8  0.285714  0.000608   \n",
       "17059            21  0.913043  0.000734   \n",
       "27455             4  0.666667  0.001055   \n",
       "33136             2  2.000000  0.000026   \n",
       "\n",
       "                                               variables  \n",
       "9017   [_debug, coordinates, x, y, z, gain, Power gai...  \n",
       "6276   [labels, start_time_dep, end_time_dep, walk_du...  \n",
       "27048  [command_string, return_code, unparsed_blast_h...  \n",
       "3421                                 [FLAGS, _, dataset]  \n",
       "188    [ident, pyobj, x, qname, l, basejoin, #basejoi...  \n",
       "...                                                  ...  \n",
       "1407   [SOURCE_URL, WORK_DIRECTORY, IMAGE_SIZE, NUM_C...  \n",
       "8686   [BASE_PATH, LOCATION, WORKFLOW_ID, EXECUTION_I...  \n",
       "17059  [cls, __cnt, cls.__cnt, suffix, smpls, obs_con...  \n",
       "27455  [VERSION, byteArray, stream, r, byte, buf, nby...  \n",
       "33136  [X, y, alpha, max_iter, tol, verbose, X_offset...  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banned_vars = ['', '*', 'self']\n",
    "def get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "# TODO find package that automatically gets variables\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "get_vars = lambda code: get_variables(code)\n",
    "tester_df[\"variables\"] = tester_df[\"content\"].apply(get_vars)\n",
    "tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aef82fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "You are a helpful bot that adds assertions to pieces of Python code.\n",
       "You will be given a list of variables and a string of code presented in the format:\n",
       "*Variables:\n",
       "[...]\n",
       "*Code:\n",
       "...\n",
       "Generate assertions based on the following criteria:\n",
       "1) Assert that the function can take in all inputs necessary to complete the process\n",
       "2) Assert that all outputs are of the proper sizes.\n",
       "\n",
       "Your response should ONLY be a list of assertions in the format:\n",
       "[line_number, subject_variable, condition_type, target, reasoning]\n",
       " -line_number is an integer referencing the line after which the assertion should be inserted\n",
       " -subject_variable and target can ONLY be variables from the input list OR integers\n",
       " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
       " -reasoning is a short decription of why the assertion was made\n",
       "\n",
       "Here is an example of what your input will look like and what you should return:\n",
       "Example Input:\n",
       "*Variables:\n",
       "[n]\n",
       "*Code:\n",
       "1def fibonacci(n):\n",
       "2   if n <= 1:\n",
       "3       return n\n",
       "4   else:\n",
       "5       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "Example Output:\n",
       "[1, n, >=, 1, \"the fibonacci sequence can only be done on posative integers\"]\n",
       "\n",
       "Which would be the same as:\n",
       "1def fibonacci(n):\n",
       "2   assert n >= 1\n",
       "3   if n <= 1:\n",
       "4       return n\n",
       "5   else:\n",
       "6       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "\n",
       "\n",
       "Here is the actual input you should provide assertions for:\n",
       "*Variables:\n",
       "[flag, num, i]\n",
       "*Code:\n",
       "1num = int(input(\"Enter a number: \"))  # Program to check if a number is prime or not\n",
       "2flag = False  # define a flag variable\n",
       "3\n",
       "4if num == 1:\n",
       "5    print(num, \"is not a prime number\")\n",
       "6elif num > 1: # check for factors\n",
       "7    for i in range(2, num):\n",
       "8        if (num % i) == 0:\n",
       "9            flag = True  # if factor is found, set flag to True\n",
       "10            break  # break out of loop\n",
       "11    if flag:  # check if flag is True\n",
       "12        print(num, \"is not a prime number\")\n",
       "13    else:\n",
       "14        print(num, \"is a prime number\")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipynb.fs.full.Data.GitHub-Assertions import get_variables\n",
    "\n",
    "class prompt_example:\n",
    "        def __init__(self, this_in=\"\", this_out=\"\"):\n",
    "            self.input = this_in\n",
    "            self.output = this_out\n",
    "            \n",
    "        def composite(self):\n",
    "            return \"Example Input:\\n\" + self.input + \"\\nExample Output:\\n\" + self.output\n",
    "        \n",
    "class LLM_prompt:       \n",
    "    def __init__(self, input_code=\"*Variables:\\n[flag, num, i]\\n*Code:\\n1num = int(input(\\\"Enter a number: \\\"))  # Program to check if a number is prime or not\\n2flag = False  # define a flag variable\\n3\\n4if num == 1:\\n5    print(num, \\\"is not a prime number\\\")\\n6elif num > 1: # check for factors\\n7    for i in range(2, num):\\n8        if (num % i) == 0:\\n9            flag = True  # if factor is found, set flag to True\\n10            break  # break out of loop\\n11    if flag:  # check if flag is True\\n12        print(num, \\\"is not a prime number\\\")\\n13    else:\\n14        print(num, \\\"is a prime number\\\")\",\n",
    "                 example_in=\"*Variables:\\n[n]\\n*Code:\\n1def fibonacci(n):\\n2   if n <= 1:\\n3       return n\\n4   else:\\n5       return(recur_fibo(n-1) + recur_fibo(n-2))\",\n",
    "                 example_out=\"[1, n, >=, 1, \\\"the fibonacci sequence can only be done on posative integers\\\"]\\n\\nWhich would be the same as:\\n1def fibonacci(n):\\n2   assert n >= 1\\n3   if n <= 1:\\n4       return n\\n5   else:\\n6       return(recur_fibo(n-1) + recur_fibo(n-2))\", \n",
    "                 criteria=[\"Assert that the function can take in all inputs necessary to complete the process\",\n",
    "                           \"Assert that all outputs are of the proper sizes.\"]\n",
    "                 ):\n",
    "        self.criteria = criteria\n",
    "        self.example = prompt_example(example_in, example_out)\n",
    "        self.input_code = input_code\n",
    "        \n",
    "        # default params that are less likely to change\n",
    "        self.intro = \"You are a helpful bot that adds assertions to pieces of Python code.\"  \n",
    "        self.input_format = \"You will be given a list of variables and a string of code presented in the format:\\n*Variables:\\n[...]\\n*Code:\\n...\"\n",
    "        self.criteria_transition = \"Generate assertions based on the following criteria:\"\n",
    "        self.output_format = \"Your response should ONLY be a list of assertions in the format:\\n[line_number, subject_variable, condition_type, target, reasoning]\"\n",
    "        self.output_format_description = [\"line_number is an integer referencing the line after which the assertion should be inserted\",\n",
    "                                          \"subject_variable and target can ONLY be variables from the input list OR integers\",\n",
    "                                          \"condition_type can only be a value in this list: [==, >=, <=, !=]\",\n",
    "                                          \"reasoning is a short decription of why the assertion was made\"]\n",
    "        self.example_transition = \"Here is an example of what your input will look like and what you should return:\"\n",
    "        self.input_transition = \"Here is the actual input you should provide assertions for:\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def composite_criteria(self):\n",
    "        \"\"\" return criteria as a single string\"\"\"\n",
    "        ret = \"\"\n",
    "        for i, crit in enumerate(self.criteria):\n",
    "            ret += str(i+1) + \") \" + crit\n",
    "            if i != len(self.criteria)-1:  # ignore last instance for formatting\n",
    "                ret += '\\n'\n",
    "        return ret\n",
    "    \n",
    "    def composite_output_formatting(self):\n",
    "        ret = self.output_format\n",
    "        for desc in self.output_format_description:\n",
    "            ret += \"\\n -\" + desc \n",
    "        return ret\n",
    "    \n",
    "    def prompt(self):\n",
    "        \"\"\" return entire prompt\"\"\"\n",
    "        return '\\n'.join([self.intro, self.input_format,\n",
    "                          self.criteria_transition, self.composite_criteria(), \"\",\n",
    "                          self.composite_output_formatting(), \"\",\n",
    "                          self.example_transition, self.example.composite(), \"\\n\",\n",
    "                          self.input_transition, self.input_code])\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\" return key prompt components as a list \"\"\"\n",
    "        return [self.intro, self.formatting, self.criteria, self.example, self.input_code, self.prompt()]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.prompt()\n",
    "    def __repr__(self):\n",
    "        return self.prompt()\n",
    "\n",
    "tester = LLM_prompt()\n",
    "print(len(str(tester)))\n",
    "tester\n",
    "\n",
    "# fib_input = \"def fibonacci(n):\\nassert n >= 1\\nif n <= 1:\\nreturn n\\nelse:\\nreturn(recur_fibo(n-1) + recur_fibo(n-2))\"\n",
    "# fib_output = \"[1, n, 1, 1, the fibonacci sequence can only be done on posative integers]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "389646a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 8217.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>variables</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>ajhager/copycat</td>\n",
       "      <td># --------------------------------------------...</td>\n",
       "      <td>\\n1# -----------------------------------------...</td>\n",
       "      <td>[[_debug('DirectSound, play')], [_debug('retur...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>[_debug, coordinates, x, y, z, gain, Power gai...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>CxAalto/gtfspy</td>\n",
       "      <td>import copy\\n\\nfrom gtfspy.routing.label impor...</td>\n",
       "      <td>\\n1import copy\\n2\\n3from gtfspy.routing.label ...</td>\n",
       "      <td>[[(hasattr(label, ==, True], [(hasattr(label, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>[labels, start_time_dep, end_time_dep, walk_du...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>fmaguire/scripts</td>\n",
       "      <td>#!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...</td>\n",
       "      <td>\\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...</td>\n",
       "      <td>[[False, ==, True], [False, ==, True]]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>[command_string, return_code, unparsed_blast_h...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>jazcollins/models</td>\n",
       "      <td># Copyright 2016 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2016 Google Inc. All Rights Res...</td>\n",
       "      <td>[[dataset.data_files(), ==, True]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>[FLAGS, _, dataset]</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fasbit/p2pool-dime</td>\n",
       "      <td># Copyright (c) 2003, The Regents of the Unive...</td>\n",
       "      <td>\\n1# Copyright (c) 2003, The Regents of the Un...</td>\n",
       "      <td>[[node.ownerDocument, ==, not newOwnerDocument]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>[ident, pyobj, x, qname, l, basejoin, #basejoi...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>panmari/tensorflow</td>\n",
       "      <td># Copyright 2015 Google Inc. All Rights Reserv...</td>\n",
       "      <td>\\n1# Copyright 2015 Google Inc. All Rights Res...</td>\n",
       "      <td>[[test_error, ==, 0.0]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>[SOURCE_URL, WORK_DIRECTORY, IMAGE_SIZE, NUM_C...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>cfei18/incubator-airflow</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "      <td>\\n1# Licensed to the Apache Software Foundatio...</td>\n",
       "      <td>[[result, ==, mock_object.to_dict.return_value...</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>[BASE_PATH, LOCATION, WORKFLOW_ID, EXECUTION_I...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17059</th>\n",
       "      <td>plum-umd/pasket</td>\n",
       "      <td>import operator as op\\nfrom functools import p...</td>\n",
       "      <td>\\n1import operator as op\\n2from functools impo...</td>\n",
       "      <td>[[{aux.subject}, !=, {aux.observer};], [subcls...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>[cls, __cnt, cls.__cnt, suffix, smpls, obs_con...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>HaraldWeber/client</td>\n",
       "      <td>\\nfrom PyQt4.QtCore import QIODevice, QDataStr...</td>\n",
       "      <td>\\n1\\n2from PyQt4.QtCore import QIODevice, QDat...</td>\n",
       "      <td>[[self._header_given, ==, False], [self._heade...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>[VERSION, byteArray, stream, r, byte, buf, nby...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33136</th>\n",
       "      <td>glemaitre/scikit-learn</td>\n",
       "      <td>\"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...</td>\n",
       "      <td>\\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...</td>\n",
       "      <td>[[(self.is_clf, ==, False], [self.alpha_per_ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>[X, y, alpha, max_iter, tol, verbose, X_offset...</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo_name  \\\n",
       "9017            ajhager/copycat   \n",
       "6276             CxAalto/gtfspy   \n",
       "27048          fmaguire/scripts   \n",
       "3421          jazcollins/models   \n",
       "188          fasbit/p2pool-dime   \n",
       "...                         ...   \n",
       "1407         panmari/tensorflow   \n",
       "8686   cfei18/incubator-airflow   \n",
       "17059           plum-umd/pasket   \n",
       "27455        HaraldWeber/client   \n",
       "33136    glemaitre/scikit-learn   \n",
       "\n",
       "                                                 content  \\\n",
       "9017   # --------------------------------------------...   \n",
       "6276   import copy\\n\\nfrom gtfspy.routing.label impor...   \n",
       "27048  #!/opt/anaconda/bin\\n\\nimport glob\\nimport arg...   \n",
       "3421   # Copyright 2016 Google Inc. All Rights Reserv...   \n",
       "188    # Copyright (c) 2003, The Regents of the Unive...   \n",
       "...                                                  ...   \n",
       "1407   # Copyright 2015 Google Inc. All Rights Reserv...   \n",
       "8686   # Licensed to the Apache Software Foundation (...   \n",
       "17059  import operator as op\\nfrom functools import p...   \n",
       "27455  \\nfrom PyQt4.QtCore import QIODevice, QDataStr...   \n",
       "33136  \"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathie...   \n",
       "\n",
       "                                              unasserted  \\\n",
       "9017   \\n1# -----------------------------------------...   \n",
       "6276   \\n1import copy\\n2\\n3from gtfspy.routing.label ...   \n",
       "27048  \\n1#!/opt/anaconda/bin\\n2\\n3import glob\\n4impo...   \n",
       "3421   \\n1# Copyright 2016 Google Inc. All Rights Res...   \n",
       "188    \\n1# Copyright (c) 2003, The Regents of the Un...   \n",
       "...                                                  ...   \n",
       "1407   \\n1# Copyright 2015 Google Inc. All Rights Res...   \n",
       "8686   \\n1# Licensed to the Apache Software Foundatio...   \n",
       "17059  \\n1import operator as op\\n2from functools impo...   \n",
       "27455  \\n1\\n2from PyQt4.QtCore import QIODevice, QDat...   \n",
       "33136  \\n1\"\"\"\\n2Ridge regression\\n3\"\"\"\\n4\\n5# Author:...   \n",
       "\n",
       "                                              assertions  asserted_lines  \\\n",
       "9017   [[_debug('DirectSound, play')], [_debug('retur...              24   \n",
       "6276   [[(hasattr(label, ==, True], [(hasattr(label, ...               9   \n",
       "27048             [[False, ==, True], [False, ==, True]]               2   \n",
       "3421                  [[dataset.data_files(), ==, True]]               1   \n",
       "188     [[node.ownerDocument, ==, not newOwnerDocument]]               1   \n",
       "...                                                  ...             ...   \n",
       "1407                             [[test_error, ==, 0.0]]               1   \n",
       "8686   [[result, ==, mock_object.to_dict.return_value...              28   \n",
       "17059  [[{aux.subject}, !=, {aux.observer};], [subcls...              23   \n",
       "27455  [[self._header_given, ==, False], [self._heade...               6   \n",
       "33136  [[(self.is_clf, ==, False], [self.alpha_per_ta...               1   \n",
       "\n",
       "       parsed_lines       arr       atl  \\\n",
       "9017             24  1.000000  0.001402   \n",
       "6276              7  0.777778  0.000764   \n",
       "27048             2  1.000000  0.000383   \n",
       "3421              1  1.000000  0.000782   \n",
       "188               1  1.000000  0.000020   \n",
       "...             ...       ...       ...   \n",
       "1407              1  1.000000  0.000077   \n",
       "8686              8  0.285714  0.000608   \n",
       "17059            21  0.913043  0.000734   \n",
       "27455             4  0.666667  0.001055   \n",
       "33136             2  2.000000  0.000026   \n",
       "\n",
       "                                               variables  \\\n",
       "9017   [_debug, coordinates, x, y, z, gain, Power gai...   \n",
       "6276   [labels, start_time_dep, end_time_dep, walk_du...   \n",
       "27048  [command_string, return_code, unparsed_blast_h...   \n",
       "3421                                 [FLAGS, _, dataset]   \n",
       "188    [ident, pyobj, x, qname, l, basejoin, #basejoi...   \n",
       "...                                                  ...   \n",
       "1407   [SOURCE_URL, WORK_DIRECTORY, IMAGE_SIZE, NUM_C...   \n",
       "8686   [BASE_PATH, LOCATION, WORKFLOW_ID, EXECUTION_I...   \n",
       "17059  [cls, __cnt, cls.__cnt, suffix, smpls, obs_con...   \n",
       "27455  [VERSION, byteArray, stream, r, byte, buf, nby...   \n",
       "33136  [X, y, alpha, max_iter, tol, verbose, X_offset...   \n",
       "\n",
       "                                                  prompt  \n",
       "9017   You are a helpful bot that adds assertions to ...  \n",
       "6276   You are a helpful bot that adds assertions to ...  \n",
       "27048  You are a helpful bot that adds assertions to ...  \n",
       "3421   You are a helpful bot that adds assertions to ...  \n",
       "188    You are a helpful bot that adds assertions to ...  \n",
       "...                                                  ...  \n",
       "1407   You are a helpful bot that adds assertions to ...  \n",
       "8686   You are a helpful bot that adds assertions to ...  \n",
       "17059  You are a helpful bot that adds assertions to ...  \n",
       "27455  You are a helpful bot that adds assertions to ...  \n",
       "33136  You are a helpful bot that adds assertions to ...  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_prompts(temp_df):\n",
    "    prompts = []\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        # *Variables:\\n[flag, num, i]\\n*Code:\\n\n",
    "        prompt_param = \"*Variables:\\n\" + str(row[\"variables\"]) + \"\\n*Code:\\n\" + row[\"unasserted\"]\n",
    "        prompts.append(str(LLM_prompt(prompt_param)))\n",
    "    temp_df[\"prompt\"] = prompts\n",
    "    return temp_df\n",
    "\n",
    "tester_df = make_prompts(tester_df)\n",
    "tester_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7fd98ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful bot that adds assertions to pieces of Python code.\n",
      "You will be given a list of variables and a string of code presented in the format:\n",
      "*Variables:\n",
      "[...]\n",
      "*Code:\n",
      "...\n",
      "Generate assertions based on the following criteria:\n",
      "1) Assert that the function can take in all inputs necessary to complete the process\n",
      "2) Assert that all outputs are of the proper sizes.\n",
      "\n",
      "Your response should ONLY be a list of assertions in the format:\n",
      "[line_number, subject_variable, condition_type, target, reasoning]\n",
      " -line_number is an integer referencing the line after which the assertion should be inserted\n",
      " -subject_variable and target can ONLY be variables from the input list OR integers\n",
      " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
      " -reasoning is a short decription of why the assertion was made\n",
      "\n",
      "Here is an example of what your input will look like and what you should return:\n",
      "Example Input:\n",
      "*Variables:\n",
      "[n]\n",
      "*Code:\n",
      "1def fibonacci(n):\n",
      "2   if n <= 1:\n",
      "3       return n\n",
      "4   else:\n",
      "5       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
      "Example Output:\n",
      "[1, n, >=, 1, \"the fibonacci sequence can only be done on posative integers\"]\n",
      "\n",
      "Which would be the same as:\n",
      "1def fibonacci(n):\n",
      "2   assert n >= 1\n",
      "3   if n <= 1:\n",
      "4       return n\n",
      "5   else:\n",
      "6       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
      "\n",
      "\n",
      "Here is the actual input you should provide assertions for:\n",
      "*Variables:\n",
      "['_log', 'request', 'test_nodes', '_sucess_start', 'monkeypatch', 'iface', 'a', 'b', 'q', '*args', 'aa', 'd', 'c', 'servers', 'server', 'key', 'value', 'set_value', 'get_value', 'addrs', 'network', 'ip', 'port', '_sd', 'client', 'services']\n",
      "*Code:\n",
      "\n",
      "1# -*- coding: utf-8 -*-\n",
      "2\n",
      "3# Copyright (c) 2015 Ericsson AB\n",
      "4#\n",
      "5# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "6# you may not use this file except in compliance with the License.\n",
      "7# You may obtain a copy of the License at\n",
      "8#\n",
      "9#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "10#\n",
      "11# Unless required by applicable law or agreed to in writing, software\n",
      "12# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "13# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "14# See the License for the specific language governing permissions and\n",
      "15# limitations under the License.\n",
      "16\n",
      "17import pytest\n",
      "18import sys\n",
      "19import os\n",
      "20import traceback\n",
      "21\n",
      "22import twisted\n",
      "23\n",
      "24from calvin.utilities.calvin_callback import CalvinCB\n",
      "25from calvin.utilities import calvinlogger\n",
      "26\n",
      "27from calvin.runtime.south.plugins.storage.twistedimpl.dht.dht_server import *\n",
      "28from calvin.runtime.south.plugins.storage.twistedimpl.dht.service_discovery_ssdp import *\n",
      "29\n",
      "30from calvin.runtime.south.plugins.async import threads\n",
      "31\n",
      "32_log = calvinlogger.get_logger(__name__)\n",
      "33\n",
      "34@pytest.fixture(scope=\"session\", autouse=True)\n",
      "35def cleanup(request):\n",
      "36    def fin():\n",
      "37        reactor.callFromThread(reactor.stop)\n",
      "38    request.addfinalizer(fin)\n",
      "39\n",
      "40@pytest.mark.interactive\n",
      "41@pytest.mark.slow\n",
      "42class TestDHT(object):\n",
      "43    test_nodes = 2\n",
      "44    _sucess_start = (True,)\n",
      "45\n",
      "46    @pytest.inlineCallbacks\n",
      "47    def atest_dht_single(self, monkeypatch):\n",
      "48        from twisted.python import log\n",
      "49\n",
      "50        log.startLogging(sys.stdout)\n",
      "51        iface = \"0.0.0.0\"\n",
      "52        a = None\n",
      "53        b = None\n",
      "54        q = Queue.Queue()\n",
      "55\n",
      "56        defer.setDebugging(True)\n",
      "57\n",
      "58        def server_started(a, *args):\n",
      "59            for b in args:\n",
      "60                if isinstance(b, twisted.python.failure.Failure):\n",
      "61                    b.printTraceback()\n",
      "62                else:\n",
      "63                    _log.debug(\"** %s\" % b)\n",
      "64            q.put([a, args])\n",
      "65\n",
      "66        try:\n",
      "67            a = AutoDHTServer()\n",
      "68            a.start(iface, cb=CalvinCB(server_started, \"1\"))\n",
      "69\n",
      "70            # Wait for start\n",
      "71\n",
      "72\n",
      "73        except Exception as e:\n",
      "74            _log.exception(\"Failed\")\n",
      "75            pytest.fail(traceback.format_exc())\n",
      "76        finally:\n",
      "77            if a:\n",
      "78                yield threads.defer_to_thread(a.stop)\n",
      "79\n",
      "80    @pytest.inlineCallbacks\n",
      "81    def test_dht_multi(self, monkeypatch):\n",
      "82        iface = \"0.0.0.0\"\n",
      "83        a = None\n",
      "84        b = None\n",
      "85        q = Queue.Queue()\n",
      "86\n",
      "87        def server_started(aa, *args):\n",
      "88            for b in args:\n",
      "89                if isinstance(b, twisted.python.failure.Failure):\n",
      "90                    b.printTraceback()\n",
      "91                else:\n",
      "92                    _log.debug(\"** %s\" % b)\n",
      "93            q.put([aa,args])\n",
      "94\n",
      "95        try:\n",
      "96\n",
      "97            a = AutoDHTServer()\n",
      "98            d = a.start(iface, cb=CalvinCB(server_started, \"1\"))\n",
      "99\n",
      "100            b = AutoDHTServer()\n",
      "101            d = b.start(iface, cb=CalvinCB(server_started, \"2\"))\n",
      "102\n",
      "103            c = AutoDHTServer()\n",
      "104            c.start(iface, cb=CalvinCB(server_started, \"3\"))\n",
      "105\n",
      "106            # Wait for start\n",
      "107            servers = []\n",
      "108            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "109            servers.append(server)\n",
      "110            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "111            servers.append(server)\n",
      "112            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "113            servers.append(server)\n",
      "114\n",
      "115\n",
      "116\n",
      "117            yield threads.defer_to_thread(time.sleep, 1)\n",
      "118\n",
      "119            set_def = a.set(key=\"APA\", value=\"banan\")\n",
      "120            set_value = yield threads.defer_to_thread(set_def.wait)\n",
      "121\n",
      "122            get_def = a.get(key=\"APA\")\n",
      "123            get_value = yield threads.defer_to_thread(get_def.wait)\n",
      "124\n",
      "125            yield threads.defer_to_thread(time.sleep, .5)\n",
      "126\n",
      "127            get_def = b.get(key=\"APA\")\n",
      "128            get_value = yield threads.defer_to_thread(get_def.wait)\n",
      "129\n",
      "130        except Exception as e:\n",
      "131            traceback.print_exc()\n",
      "132            pytest.fail(traceback.format_exc())\n",
      "133        finally:\n",
      "134            if a:\n",
      "135                a.stop()\n",
      "136            if b:\n",
      "137                b.stop()\n",
      "138            if c:\n",
      "139                c.stop()\n",
      "140            yield threads.defer_to_thread(time.sleep, 1)\n",
      "141\n",
      "142    @pytest.inlineCallbacks\n",
      "143    def test_service_discovery(self, monkeypatch):\n",
      "144        q = Queue.Queue()\n",
      "145\n",
      "146        def callback(addrs):\n",
      "147            _log.debug(\"Callback discovery got %s\" % addrs)\n",
      "148            q.put(addrs)\n",
      "149\n",
      "150        iface = \"0.0.0.0\"\n",
      "151        network = \"test_super_network\"\n",
      "152\n",
      "153        ip = \"192.168.199.199\"\n",
      "154        port = 80\n",
      "155\n",
      "156        _sd = SSDPServiceDiscovery(iface, ignore_self=False)\n",
      "157        server, client = _sd.start()\n",
      "158\n",
      "159        _sd.register_service(network, ip, port)\n",
      "160\n",
      "161        yield threads.defer_to_thread(time.sleep, .2)\n",
      "162        _sd.start_search(callback, stop=True)\n",
      "163\n",
      "164        try:\n",
      "165            services = yield threads.defer_to_thread(q.get, timeout=4)\n",
      "166        except:\n",
      "167            traceback.print_exc()\n",
      "168\n",
      "169        _sd.stop()\n",
      "170        #yield threads.defer_to_thread(_sd.stop)\n",
      "171\n",
      "172    @pytest.inlineCallbacks\n",
      "173    def test_service_discovery_ignore(self, monkeypatch):\n",
      "174        q = Queue.Queue()\n",
      "175\n",
      "176        def callback(addrs):\n",
      "177            _log.debug(\"Callback discovery got %s\" % addrs)\n",
      "178            q.put(addrs)\n",
      "179\n",
      "180        iface = \"0.0.0.0\"\n",
      "181        network = \"test_super_network\"\n",
      "182\n",
      "183        ip = \"192.168.199.199\"\n",
      "184        port = 80\n",
      "185\n",
      "186        _sd = SSDPServiceDiscovery(iface)\n",
      "187        server, client = _sd.start()\n",
      "188\n",
      "189        _sd.register_service(network, ip, port)\n",
      "190\n",
      "191        yield threads.defer_to_thread(time.sleep, .2)\n",
      "192        _sd.start_search(callback, stop=True)\n",
      "193\n",
      "194        try:\n",
      "195            services = yield threads.defer_to_thread(q.get, timeout=4)\n",
      "196        except:\n",
      "197            pass\n",
      "198\n",
      "199        _sd.stop()\n",
      "200        #yield threads.defer_to_thread(_sd.stop)\n",
      "201\n",
      "202    @pytest.inlineCallbacks\n",
      "203    def test_service_discovery_filter(self, monkeypatch):\n",
      "204        q = Queue.Queue()\n",
      "205\n",
      "206        def callback_filter(addrs):\n",
      "207            _log.debug(\"Callback filter got %s\" % addrs)\n",
      "208            q.put(addrs)\n",
      "209\n",
      "210        iface = \"0.0.0.0\"\n",
      "211        network = \"test_super_network\"\n",
      "212        ip = \"192.168.199.200\"\n",
      "213        port = 80\n",
      "214\n",
      "215        _sd = SSDPServiceDiscovery(iface, ignore_self=False)\n",
      "216        _sd.start()\n",
      "217        _sd.register_service(\"APA\", ip, port)\n",
      "218        _sd.set_client_filter(\"BANAN\")\n",
      "219\n",
      "220        yield threads.defer_to_thread(time.sleep, .2)\n",
      "221\n",
      "222        _sd.start_search(callback_filter, stop=True)\n",
      "223\n",
      "224        try:\n",
      "225            services = yield threads.defer_to_thread(q.get, timeout=.5)\n",
      "226        except:\n",
      "227            pass\n",
      "228\n",
      "229        _sd.stop_search()\n",
      "230\n",
      "231        def callback_filter_get(addrs):\n",
      "232            _log.debug(\"Callback filter got %s\" % addrs)\n",
      "233            q.put(addrs)\n",
      "234\n",
      "235        _sd.set_client_filter(\"APA\")\n",
      "236        _sd.start_search(callback_filter_get, stop=True)\n",
      "237\n",
      "238        try:\n",
      "239            services = yield threads.defer_to_thread(q.get, timeout=4)\n",
      "240        except:\n",
      "241            traceback.print_exc()\n",
      "242\n",
      "243        _sd.stop()\n",
      "244        #yield threads.defer_to_thread(_sd.stop)\n",
      "245\n",
      "246    @pytest.inlineCallbacks\n",
      "247    def test_callback(self, monkeypatch):\n",
      "248        from twisted.python import log\n",
      "249        log.startLogging(sys.stdout)\n",
      "250\n",
      "251        iface = \"0.0.0.0\"\n",
      "252        a = None\n",
      "253        b = None\n",
      "254        q = Queue.Queue()\n",
      "255\n",
      "256        def server_started(aa, *args):\n",
      "257            for b in args:\n",
      "258                if isinstance(b, twisted.python.failure.Failure):\n",
      "259                    b.printTraceback()\n",
      "260                else:\n",
      "261                    _log.debug(\"** %s\" % b)\n",
      "262            q.put([aa,args])\n",
      "263\n",
      "264        def set_cb(*args):\n",
      "265            _log.debug(\"** %s\" % repr(args))\n",
      "266            q.put(args)\n",
      "267\n",
      "268        def get_cb(*args):\n",
      "269            _log.debug(\"** %s\" % repr(args))\n",
      "270            q.put(args)\n",
      "271\n",
      "272        try:\n",
      "273            a = AutoDHTServer()\n",
      "274            a.start(iface, cb=CalvinCB(server_started, \"1\"))\n",
      "275\n",
      "276            b = AutoDHTServer()\n",
      "277            b.start(iface, cb=CalvinCB(server_started, \"2\"))\n",
      "278\n",
      "279            c = AutoDHTServer()\n",
      "280            c.start(iface, cb=CalvinCB(server_started, \"3\"))\n",
      "281\n",
      "282\n",
      "283            # Wait for start\n",
      "284            servers = []\n",
      "285            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "286            servers.append(server)\n",
      "287            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "288            servers.append(server)\n",
      "289            server = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "290            servers.append(server)\n",
      "291\n",
      "292\n",
      "293\n",
      "294            yield threads.defer_to_thread(time.sleep, 1)\n",
      "295\n",
      "296            a.set(key=\"APA\", value=\"banan\", cb=CalvinCB(set_cb))\n",
      "297            set_value = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "298\n",
      "299            yield threads.defer_to_thread(time.sleep, 1)\n",
      "300\n",
      "301            a.get(key=\"APA\", cb=CalvinCB(get_cb))\n",
      "302            get_value = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "303\n",
      "304            yield threads.defer_to_thread(time.sleep, 1)\n",
      "305\n",
      "306            b.get(key=\"APA\", cb=CalvinCB(get_cb))\n",
      "307            get_value = yield threads.defer_to_thread(q.get, timeout=2)\n",
      "308\n",
      "309        except Exception as e:\n",
      "310            _log.exception(\"Failed\")\n",
      "311            pytest.fail(traceback.format_exc())\n",
      "312        finally:\n",
      "313            if a:\n",
      "314                a.stop()\n",
      "315            if b:\n",
      "316                b.stop()\n",
      "317            if c:\n",
      "318                c.stop()\n",
      "319            yield threads.defer_to_thread(time.sleep, 1)\n",
      "320\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "print(tester_df.sample()[\"prompt\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd866c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb7d9e910d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7fb7d9e910d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    812\u001b[0m     )\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    812\u001b[0m     )\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb7d9e910d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb7d9e910d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     message_hist.append({\"role\": \"system\", \"content\": response})\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mgpt_oneshot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat do you do?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36mgpt_oneshot\u001b[0;34m(input_prompt, directive, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_oneshot\u001b[39m(input_prompt, directive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful bot that adds assertions to pieces of Python code.\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     message_hist \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: directive},\n\u001b[1;32m     20\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt}]  \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_gpt: \u001b[39m\u001b[38;5;124m\"\u001b[39m, response, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36mrun_gpt4\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      8\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-yGHcJlcVv4St2WIhyp6jT3BlbkFJ1yCFTgYtxetGRwNhBBuR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# os.environ['OPENAI_API_KEY']\u001b[39;00m\n\u001b[1;32m      9\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m OPENAI_API_KEY\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:528\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError communicating with OpenAI: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)\n\u001b[1;32m    530\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    531\u001b[0m util\u001b[38;5;241m.\u001b[39mlog_debug(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API response\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    533\u001b[0m     path\u001b[38;5;241m=\u001b[39mabs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m     request_id\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Request-Id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    537\u001b[0m )\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb7d9e910d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))"
     ]
    }
   ],
   "source": [
    "# querying\n",
    "import openai\n",
    "import altair as alt\n",
    "import json\n",
    "from vega_datasets import data\n",
    "\n",
    "def run_gpt4(messages):\n",
    "    OPENAI_API_KEY = \"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\" # os.environ['OPENAI_API_KEY']\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# TODO: add coding language versatility\n",
    "def gpt_oneshot(input_prompt, directive=\"You are a helpful bot that adds assertions to pieces of Python code.\", verbose=False):\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]  # init\n",
    "    response = run_gpt4(message_hist)\n",
    "    if verbose:\n",
    "        print(\"chat_gpt: \", response, '\\n')\n",
    "#     message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "\n",
    "print(\"\\n\\n\", gpt_oneshot(\"what do you do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81099d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run testing\n",
    "tester_df[\"gpt\"] = tester_df[\"prompt_string\"].apply(lambda prompt: gpt_oneshot(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6985a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example of gpt's output\n",
    "print(tester_df.sample()[\"gpt\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927da6",
   "metadata": {},
   "source": [
    "## Step 3) Parse & Evaluate GPT's Response\n",
    "\n",
    "### Step 3.1) Restore the assertion(s) generated to code and evaluate\n",
    "> Metrics of evaluation, does it run? does it add to the code? is it ground-truth-like? human evaluator rank? gpt evaluator rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8a956fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [115]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parsed_code), asserts\n\u001b[1;32m     24\u001b[0m example_response \u001b[38;5;241m=\u001b[39m tester_df\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexample_response\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m temp_test \u001b[38;5;241m=\u001b[39m get_gpt_assertions(example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], example_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munasserted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt'"
     ]
    }
   ],
   "source": [
    "def get_gpt_assertions(response, code):\n",
    "    \"\"\" takes in chat gpt's response and outputs its assertions as well as a string of code with said assertions in it \"\"\"\n",
    "    asserts = []\n",
    "    parsed_code = code.split('\\n')\n",
    "    for line in response.split('\\n'):\n",
    "        line.replace('[', '').replace(']', '')\n",
    "        separated = line.split(',')\n",
    "        full_assert = separated[1:-1] # ommit reasoning\n",
    "        \n",
    "        # TODO: handle case where there are other ints in the code\n",
    "        line_num = separated[0]\n",
    "        num_size = len(str(line_num))\n",
    "        has_found = False\n",
    "        for i, line in enumerate(parsed_code):\n",
    "            if line_num in line[:num_size+1]:\n",
    "                parsed_code.insert(i+1, full_assert)\n",
    "                asserts.append(full_assert)\n",
    "                has_found = True\n",
    "                break\n",
    "        if not has_found:\n",
    "            print(\"Could not find location of\\n\", full_assert, \"\\nin\\n\", code)\n",
    "    return '\\n'.join(parsed_code), asserts\n",
    "\n",
    "example_response = tester_df.sample()\n",
    "print(example_response[\"gpt\"].iloc[0])\n",
    "temp_test = get_gpt_assertions(example_response[\"gpt\"].iloc[0], example_response[\"unasserted\"].iloc[0])\n",
    "print(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_asserted_code = []  # snippets of code greated by the response assertions from gpt\n",
    "gpt_assertions = []  # the decoded assertions themselves\n",
    "gpt_num_assertions = []  # the number of assertions gpt generated\n",
    "gpt_ratio_assertions = []   # num_gen_assertions / num_parsed_assertions\n",
    "gpt_matched_assertions = []  # assertions that roughly equal ground-truth\n",
    "gpt_matched_assertions_ratio = []  # num_matched_assertions / num_ground_truth_assertions\n",
    "\n",
    "for i, row in tester_df.iterrows():\n",
    "    new_code, asserts = get_gpt_assertions(row[\"gpt\"], row[\"Unasserted\"])\n",
    "    gpt_asserted_code.append(new_code)\n",
    "    gpt_assertions.append(asserts)\n",
    "    gpt_num_assertions.append(len(asserts))\n",
    "    gpt_ratio_assertions.append(len(asserts)/row[\"parsed_lines\"])\n",
    "    # TODO get number of matching assertions\n",
    "    matched_num = ...\n",
    "    gpt_matched_assertions.append(matched_num)\n",
    "    gpt_matched_assertions_ratio.append(matched_num/len(asserts))\n",
    "tester_df[\"gpt_asserted_code\"] = gpt_asserted_code\n",
    "tester_df[\"gpt_assertions\"] = gpt_assertions\n",
    "tester_df[\"gpt_num_assertions\"] = gpt_num_assertions\n",
    "tester_df[\"gpt_ratio_assertions\"] = gpt_ratio_assertions\n",
    "tester_df[\"gpt_matched_assertions\"] = gpt_matched_assertions\n",
    "tester_df[\"gpt_matched_assertions_ratio\"] = gpt_matched_assertions_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefc5cd",
   "metadata": {},
   "source": [
    "## Step 4) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae2772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
