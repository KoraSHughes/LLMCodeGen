{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a3bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()  # get directory for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7dd9d",
   "metadata": {},
   "source": [
    "# This file automates the entire pipeline for assertion generation with chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bc35b",
   "metadata": {},
   "source": [
    "## Step 1) Get Asserted Code From Github\n",
    "\n",
    "### Step 1.1) Clean and process the code\n",
    "### Step 1.2) Extract Ground-Truth Assertions & Relevant Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "126af672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "def get_asserted_code(num=100000, ext=\"%.py\", verbose=True):\n",
    "    query_string = \"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT \"\"\" + str(num)\n",
    "    \n",
    "    if isinstance(num, int):\n",
    "        secret_dir = \"Data/secret/\"\n",
    "        api_key = cwd + \"/\" + secret_dir + os.listdir(secret_dir)[0]\n",
    "        assert api_key[-5:] == \".json\"  # confirm that it was found\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = api_key\n",
    "        query_string = query_string.replace(\"%.py\", ext)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"*Running Query:\")\n",
    "            print(query_string)\n",
    "            print()\n",
    "        client = bq.Client()\n",
    "        df = (\n",
    "            client.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(\n",
    "                create_bqstorage_client=True,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(num, str):\n",
    "        # load data from file\n",
    "        df = pd.read_csv(num)\n",
    "        print(\"Found data at\", num)\n",
    "    else:\n",
    "        print(\"first param type undefined, must be string signifying directory of csv or\\\n",
    "               int signifying number of records to scrib from bigquery...\")\n",
    "        assert False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"*Handling Duplicates...\")\n",
    "    init_len = len(df)\n",
    "    df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True)\n",
    "    if verbose:\n",
    "        print(\"#Non-duplicates / #Total Retrieved =\", (len(df)/init_len))\n",
    "    return df\n",
    "\n",
    "verilog_dir = cwd+\"/Data/BigQuery/VerilogAssertions-ALL.csv\"\n",
    "python_dir = cwd+\"/Data/BigQuery/PythonAssertions100k.csv\"\n",
    "# df = get_asserted_code(python_dir)  # 10\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "857dd192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]\n",
    "bad_statements = [\" or \", \" in \", \"isinstance\"]  # TODO: properly account for OR\n",
    "def parse_assertions(func, is_split=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \n",
    "    Exceptions to Handle:\n",
    "    - 'in'/'not in' keyword\n",
    "    - boolean functions - ex. isinstance(var, type)\n",
    "    - separation of attributes - ex. len(var), var[i]\n",
    "    \"\"\"\n",
    "#     if verbose:\n",
    "#         print(\"*Extracting Assertions...\")\n",
    "    out = []\n",
    "    asserted_lines = 0\n",
    "    lines = []\n",
    "    for temp in func.split('\\n'):  # find lines with assert in them\n",
    "        if \"assert\" in temp:\n",
    "            asserted_lines += 1\n",
    "            bad_flag = False\n",
    "            for bad in bad_statements:\n",
    "                if bad in temp:\n",
    "                    bad_flag = True\n",
    "            if not bad_flag:\n",
    "                lines.append(temp.strip())\n",
    "    # TODO: experiment with smaller content window for assertions\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        start = data.find('assert')\n",
    "        if start == -1:  # double checking that the assertion exists in this line\n",
    "            ind += 1\n",
    "            continue\n",
    "        # account for combination statements\n",
    "        for statement in compounding_statements:\n",
    "            add_statement = data.find(statement)\n",
    "            if add_statement != -1:\n",
    "                extra_line = data[add_statement+len(statement):]\n",
    "                lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                data = data[:add_statement].strip()\n",
    "\n",
    "        com = data.find(',')   # parsing out return_string\n",
    "        if com != -1:\n",
    "            data = data[:com]\n",
    "        com = data.find('#')\n",
    "        if com != -1:   # parsing out comments\n",
    "            if com < start:  # if the assertion itself is a comment\n",
    "                ind += 1\n",
    "                continue\n",
    "            else:\n",
    "                data = data[:com]\n",
    "\n",
    "        if is_split:  # splitting the assertion into components for analysis\n",
    "            data = [var.strip() for var in data.split(' ') if len(var.strip()) > 0]\n",
    "            \n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "                \n",
    "            if data[0] != \"assert\":  # edge case: something before the 'assert' statement\n",
    "                ind += 1\n",
    "#                 if verbose:\n",
    "#                     print(\"something was found before the assertion on this line:\\n\", data)\n",
    "                continue\n",
    "    \n",
    "            data = data[1:]  # from here on we only care about the content after the 'assert' keyword\n",
    "            if len(data) < 1:  # edge case: nothing after 'assert' (likely typo)\n",
    "                if verbose:\n",
    "                    print(\"empty assertion found?: \", data, '\\n', lines[ind])\n",
    "                ind += 1\n",
    "                continue\n",
    "\n",
    "            condition = True  # assertion [variable] == condition by default\n",
    "            if data[0] == \"not\":  # accounting for 'not' keyword\n",
    "                condition = False\n",
    "                data = data[1:]\n",
    "            \n",
    "            if len(data) == 1:  # adding == to simlify\n",
    "                data = data + [\"==\", str(condition)]\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                if data[i] == \"is\":  # simplifying is to ==\n",
    "                    data[i] = \"==\"\n",
    "                if data[i] in conditionals.keys():  # parsing common conditionals\n",
    "                    data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                    break\n",
    "\n",
    "        if verbose and len(data) != 3:\n",
    "            print(\"Weird assertion found:\\n\", data, '\\n', lines[ind])\n",
    "            print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "        else:\n",
    "            out.append(data)\n",
    "        ind += 1\n",
    "    return out, asserted_lines\n",
    "\n",
    "def unassert(code, delim='', add_count=True):\n",
    "    out = \"\"\n",
    "    counter = 1\n",
    "    for line in code.split('\\n'):\n",
    "        if \"assert\" not in line:\n",
    "            out += '\\n'\n",
    "            if add_count:\n",
    "                out += str(counter)\n",
    "            out += delim+line\n",
    "            counter += 1\n",
    "    return out\n",
    "\n",
    "def get_assertion(temp_df, verbose=False, unassert_col=True, add_stats=True):\n",
    "    \"\"\" run assertion generation \"\"\"\n",
    "    # tester_df[\"assertions\"] = tester_df[\"content\"].apply(lambda code: get_assertions(code))\n",
    "    \n",
    "    assertions = []  # list of parsed assertions\n",
    "    asserted_lines = []  # number of lines with 'assert' in them\n",
    "    parsed_lines = []  # number of assertions easily parsed\n",
    "    arr = []  # assertion recovery ratio\n",
    "    atl = []  # assertions to size\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        parsed, lines = parse_assertions(row[\"content\"], True, verbose)\n",
    "        assertions.append(parsed)\n",
    "        asserted_lines.append(lines)\n",
    "        parsed_lines.append(len(parsed))\n",
    "        arr.append(len(parsed)/lines)\n",
    "        atl.append(len(parsed)/len(row[\"content\"]))\n",
    "\n",
    "    if unassert_col:\n",
    "        temp_df[\"unasserted\"] = temp_df[\"content\"].apply(lambda code: unassert(code))\n",
    "    \n",
    "    if add_stats:\n",
    "        temp_df[\"assertions\"] = assertions\n",
    "        temp_df[\"asserted_lines\"] = asserted_lines\n",
    "        temp_df[\"parsed_lines\"] = parsed_lines\n",
    "        temp_df[\"arr\"] = arr\n",
    "        temp_df[\"atl\"] = atl\n",
    "    return temp_df\n",
    "\n",
    "# df = get_assertion(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d8683",
   "metadata": {},
   "source": [
    "## Step 2) Generate LLM Prompt & Query a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4aeaaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "banned_vars = ['', '*', 'self']\n",
    "def old_get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "\n",
    "# test\n",
    "import ast\n",
    "\n",
    "def get_variables(code):  # TODO: run a proper test\n",
    "    tree = ast.parse(code)\n",
    "    variables = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign):\n",
    "            for target in node.targets:\n",
    "                if isinstance(target, ast.Name):\n",
    "                    variables.append(target.id)\n",
    "    return variables\n",
    "\n",
    "def get_all_variables(df, verbose=False):  # TODO test\n",
    "    ret = []\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        these_vars = []\n",
    "        try:\n",
    "            these_vars = get_variables(row[\"content\"])\n",
    "        except:\n",
    "            if verbose: print(\"get all variables was not able to use ast\")\n",
    "        add_vars = old_get_variables(row[\"content\"])\n",
    "        for new_var in add_vars:\n",
    "            if new_var not in these_vars:\n",
    "                these_vars.append(new_var)\n",
    "        \n",
    "        for statement in row[\"assertions\"]:  # add variables from already present assertions\n",
    "            if len(statement) > 0:\n",
    "                new_var = str(statement[0])\n",
    "                if new_var not in these_vars:\n",
    "                    these_vars.append(new_var)\n",
    "        ret.append(these_vars)\n",
    "    return ret\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "# tester_df[\"variables\"] = tester_df[\"variables\"].apply(lambda code: get_variables(code))\n",
    "\n",
    "# df[\"variables\"] = get_all_variables(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ad8df4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "You are a helpful bot that adds assertions to pieces of Python code.\n",
       "You will be given a list of variables and a string of code presented in the format:\n",
       "*Variables:\n",
       "[...]\n",
       "*Code:\n",
       "...\n",
       "Generate assertions based on the following criteria:\n",
       "1) Assert that the function can take in all inputs necessary to complete the process\n",
       "2) Assert that all outputs are of the proper sizes.\n",
       "\n",
       "Your response should ONLY be a list of assertions in the format:\n",
       "[line_number, subject_variable, condition_type, target, reasoning]\n",
       " -line_number is an integer referencing the line after which the assertion should be inserted\n",
       " -subject_variable and target can ONLY be variables from the input list, integers, booleans, or None\n",
       " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
       " -reasoning is a short decription of why the assertion was made\n",
       "\n",
       "Here is an example of what your input will look like and what you should return:\n",
       "Example Input:\n",
       "*Variables:\n",
       "[n]\n",
       "*Code:\n",
       "1def fibonacci(n):\n",
       "2   if n <= 1:\n",
       "3       return n\n",
       "4   else:\n",
       "5       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "Example Output:\n",
       "[1, n, >=, 1, \"the fibonacci sequence can only be done on posative integers\"]\n",
       "\n",
       "Which would be the same as:\n",
       "1def fibonacci(n):\n",
       "2   assert n >= 1\n",
       "3   if n <= 1:\n",
       "4       return n\n",
       "5   else:\n",
       "6       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
       "\n",
       "\n",
       "Here is the actual input you should provide assertions for:\n",
       "*Variables:\n",
       "[flag, num, i]\n",
       "*Code:\n",
       "1num = int(input(\"Enter a number: \"))  # Program to check if a number is prime or not\n",
       "2flag = False  # define a flag variable\n",
       "3\n",
       "4if num == 1:\n",
       "5    print(num, \"is not a prime number\")\n",
       "6elif num > 1: # check for factors\n",
       "7    for i in range(2, num):\n",
       "8        if (num % i) == 0:\n",
       "9            flag = True  # if factor is found, set flag to True\n",
       "10            break  # break out of loop\n",
       "11    if flag:  # check if flag is True\n",
       "12        print(num, \"is not a prime number\")\n",
       "13    else:\n",
       "14        print(num, \"is a prime number\")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipynb.fs.full.Data.GitHub-Assertions import get_variables\n",
    "class prompt_example:\n",
    "        def __init__(self, this_in=\"\", this_out=\"\"):\n",
    "            self.input = this_in\n",
    "            self.output = this_out\n",
    "            \n",
    "        def composite(self):\n",
    "            return \"Example Input:\\n\" + self.input + \"\\nExample Output:\\n\" + self.output\n",
    "        \n",
    "class LLM_prompt:       \n",
    "    def __init__(self, input_code=\"*Variables:\\n[flag, num, i]\\n*Code:\\n1num = int(input(\\\"Enter a number: \\\"))  # Program to check if a number is prime or not\\n2flag = False  # define a flag variable\\n3\\n4if num == 1:\\n5    print(num, \\\"is not a prime number\\\")\\n6elif num > 1: # check for factors\\n7    for i in range(2, num):\\n8        if (num % i) == 0:\\n9            flag = True  # if factor is found, set flag to True\\n10            break  # break out of loop\\n11    if flag:  # check if flag is True\\n12        print(num, \\\"is not a prime number\\\")\\n13    else:\\n14        print(num, \\\"is a prime number\\\")\",\n",
    "                 example_in=\"*Variables:\\n[n]\\n*Code:\\n1def fibonacci(n):\\n2   if n <= 1:\\n3       return n\\n4   else:\\n5       return(recur_fibo(n-1) + recur_fibo(n-2))\",\n",
    "                 example_out=\"[1, n, >=, 1, \\\"the fibonacci sequence can only be done on posative integers\\\"]\\n\\nWhich would be the same as:\\n1def fibonacci(n):\\n2   assert n >= 1\\n3   if n <= 1:\\n4       return n\\n5   else:\\n6       return(recur_fibo(n-1) + recur_fibo(n-2))\", \n",
    "                 criteria=[\"Assert that the function can take in all inputs necessary to complete the process\",\n",
    "                           \"Assert that all outputs are of the proper sizes.\"]\n",
    "                 ):\n",
    "        self.criteria = criteria\n",
    "        self.example = prompt_example(example_in, example_out)\n",
    "        self.input_code = input_code\n",
    "        \n",
    "        # default params that are less likely to change\n",
    "        self.intro = \"You are a helpful bot that adds assertions to pieces of Python code.\"  \n",
    "        self.input_format = \"You will be given a list of variables and a string of code presented in the format:\\n*Variables:\\n[...]\\n*Code:\\n...\"\n",
    "        self.criteria_transition = \"Generate assertions based on the following criteria:\"\n",
    "        self.output_format = \"Your response should ONLY be a list of assertions in the format:\\n[line_number, subject_variable, condition_type, target, reasoning]\"\n",
    "        self.output_format_description = [\"line_number is an integer referencing the line after which the assertion should be inserted\",\n",
    "                                          \"subject_variable and target can ONLY be variables from the input list, integers, booleans, or None\", # TODO retest bools\n",
    "                                          \"condition_type can only be a value in this list: [==, >=, <=, !=]\",\n",
    "                                          \"reasoning is a short decription of why the assertion was made\"]\n",
    "        self.example_transition = \"Here is an example of what your input will look like and what you should return:\"\n",
    "        self.input_transition = \"Here is the actual input you should provide assertions for:\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def composite_criteria(self):\n",
    "        \"\"\" return criteria as a single string\"\"\"\n",
    "        ret = \"\"\n",
    "        for i, crit in enumerate(self.criteria):\n",
    "            ret += str(i+1) + \") \" + crit\n",
    "            if i != len(self.criteria)-1:  # ignore last instance for formatting\n",
    "                ret += '\\n'\n",
    "        return ret\n",
    "    \n",
    "    def composite_output_formatting(self):\n",
    "        ret = self.output_format\n",
    "        for desc in self.output_format_description:\n",
    "            ret += \"\\n -\" + desc \n",
    "        return ret\n",
    "    \n",
    "    def prompt(self):\n",
    "        \"\"\" return entire prompt\"\"\"\n",
    "        return '\\n'.join([self.intro, self.input_format,\n",
    "                          self.criteria_transition, self.composite_criteria(), \"\",\n",
    "                          self.composite_output_formatting(), \"\",\n",
    "                          self.example_transition, self.example.composite(), \"\\n\",\n",
    "                          self.input_transition, self.input_code])\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\" return key prompt components as a list \"\"\"\n",
    "        return [self.intro, self.formatting, self.criteria, self.example, self.input_code, self.prompt()]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.prompt()\n",
    "    def __repr__(self):\n",
    "        return self.prompt()\n",
    "\n",
    "tester = LLM_prompt()\n",
    "tester\n",
    "\n",
    "# fib_input = \"def fibonacci(n):\\nassert n >= 1\\nif n <= 1:\\nreturn n\\nelse:\\nreturn(recur_fibo(n-1) + recur_fibo(n-2))\"\n",
    "# fib_output = \"[1, n, 1, 1, the fibonacci sequence can only be done on posative integers]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2e44a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_prompts(temp_df):\n",
    "    prompts = []\n",
    "    for i, row in tqdm(temp_df.iterrows()):\n",
    "        # *Variables:\\n[flag, num, i]\\n*Code:\\n\n",
    "        prompt_param = \"*Variables:\\n\" + str(row[\"variables\"]) + \"\\n*Code:\\n\" + row[\"unasserted\"]\n",
    "        prompts.append(str(LLM_prompt(prompt_param)))\n",
    "    temp_df[\"prompt\"] = prompts\n",
    "    temp_df[\"prompt_len\"] = [len(p) for p in prompts]\n",
    "    return temp_df\n",
    "# df = make_prompts(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd866c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying\n",
    "import openai\n",
    "import altair as alt\n",
    "import json\n",
    "from vega_datasets import data\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "def run_gpt4(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response  # [\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "def gpt_oneshot(input_prompt, directive=\"You are a helpful bot that adds assertions to pieces of code.\", verbose=False):\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},  # add directed\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]  # init\n",
    "    response = run_gpt4(message_hist)[\"choices\"][0][\"message\"][\"content\"]\n",
    "    if verbose:\n",
    "        print(\"chat_gpt: \", response, '\\n')\n",
    "#     message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "\n",
    "# tester = gpt_oneshot(\"Write python code to sort n numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66454237",
   "metadata": {},
   "source": [
    "# RUNNING 1SHOT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c87903c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING CODE\n",
      "Found data at /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/BigQuery/PythonAssertions100k.csv\n",
      "\n",
      "EXTRACTING ASSERTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33793it [00:06, 5279.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping code with no parsed assertions => 89.8351729648152%\n",
      "\n",
      "EXTRACTING VARIABLES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30358it [02:58, 169.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping code with no extracted variables => 100.0%\n",
      "\n",
      "GENERATING PROMPTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30358it [00:02, 12311.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping prompts over limit => 47.71065287568351%\n",
      "Data checkpoint saved...\n",
      "\n",
      "GENERATING RESPONSES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 148/14484 [37:29<60:31:50, 15.20s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def python_one_shot(my_dir=cwd+\"/Data/BigQuery/PythonAssertions100k.csv\", ext=\"%.py\", preprocessed=True):\n",
    "    if not preprocessed:\n",
    "        print(\"GETTING CODE\")\n",
    "        df = get_asserted_code(my_dir, ext, False)\n",
    "\n",
    "        print(\"\\nEXTRACTING ASSERTIONS\")\n",
    "        df = get_assertion(df)\n",
    "\n",
    "        all_prompts = len(df)\n",
    "        df = df[df[\"parsed_lines\"]>0]\n",
    "        all_prompts = 100*len(df)/all_prompts\n",
    "        print(\"dropping code with no parsed assertions =>\", str(all_prompts)+'%')\n",
    "\n",
    "        print(\"\\nEXTRACTING VARIABLES\")\n",
    "    #     get_vars = lambda code: get_variables(code)\n",
    "    #     df[\"variables\"] = df[\"content\"].apply(get_vars)\n",
    "        df[\"variables\"] = get_all_variables(df)\n",
    "\n",
    "        df[\"num_vars\"] = df[\"variables\"].apply(lambda var: len(var))\n",
    "        all_prompts = len(df)\n",
    "        df = df[df[\"num_vars\"] > 0]\n",
    "        all_prompts = 100*len(df)/all_prompts\n",
    "        print(\"dropping code with no extracted variables =>\", str(all_prompts)+'%')\n",
    "\n",
    "        print(\"\\nGENERATING PROMPTS\")\n",
    "        df = make_prompts(df)\n",
    "\n",
    "        prompt_limit = 8192\n",
    "        all_prompts = len(df)\n",
    "        df = df[df[\"prompt_len\"] < prompt_limit]\n",
    "        all_prompts = 100*len(df)/all_prompts\n",
    "        print(\"dropping prompts over limit =>\", str(all_prompts)+'%')\n",
    "\n",
    "        df.to_csv(cwd+\"/preprocessed_python_unsupervised.csv\") # saving data\n",
    "        print(\"Data checkpoint saved...\\n\")\n",
    "    else:\n",
    "        df = pd.read_csv(cwd+\"/preprocessed_python_unsupervised.csv\").head(10)\n",
    "        print(\"Data checkpoint restored...\\n\")\n",
    "    \n",
    "    print(\"GENERATING RESPONSES\")\n",
    "    responses = []\n",
    "    for prompt in tqdm(df[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    df[\"gpt\"] = responses\n",
    "    df.to_csv(cwd+\"/python_prompts_withresponse.csv\") # saving data\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = python_one_shot()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbaa9ce",
   "metadata": {},
   "source": [
    "## PARTIAL EXECUTION OF 1SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b270fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating prompts for indexes 200 to 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 200/200 [1:12:19<00:00, 21.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/korahughes/Documents/GitHub/LLMCodeGen/Data/Testing/python_prompts_withresponse_part2.csv\n"
     ]
    }
   ],
   "source": [
    "part_size = 200  # should take about a bit under an hour\n",
    "current_size = 14464\n",
    "def partial_execution(part=1):  # slices of 10xt\n",
    "    start = (part-1)*part_size\n",
    "    end = start+part_size\n",
    "#     if start > current_size:\n",
    "#         return\n",
    "#     elif end > current_size:\n",
    "#         end = current_size+1\n",
    "    df = pd.read_csv(cwd+\"/Data/python_prompts_noresponse.csv\").iloc[start:end, 1:]\n",
    "    print(\"\\nGenerating prompts for indexes\", start, \"to\", end)\n",
    "    \n",
    "    responses = []\n",
    "    for prompt in tqdm(df[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    df[\"gpt\"] = responses\n",
    "    \n",
    "    df.to_csv((cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"), index=False) # saving data\n",
    "    print(\"Saved to:\", (cwd+\"/Data/Testing/python_prompts_withresponse_part\"+str(part)+\".csv\"))\n",
    "    return df\n",
    "\n",
    "df = partial_execution(2)\n",
    "# for i in range(1, 10):  # up to 73\n",
    "#     print(partial_execution(i))\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65509b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Execution Notes:\n",
    "- somewhere around 320 instances I get various API errors:\n",
    "'APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 13 Feb 2024 09:21:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '854c009eade719c3-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bf4126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>variables</th>\n",
       "      <th>num_vars</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_len</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>weidenba/recovery_sort</td>\n",
       "      <td>from filter_system.rename import RenameFilterS...</td>\n",
       "      <td>\\n1from filter_system.rename import RenameFilt...</td>\n",
       "      <td>[['len(filter_system.filter_plugins.keys())', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>['filter_system']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1582</td>\n",
       "      <td>[[5, 'filter_system', '!=', None, \"Filter syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>algorythmic/bash-completion</td>\n",
       "      <td>import pytest\\n\\n\\nclass TestPydoc:\\n    @pyte...</td>\n",
       "      <td>\\n1import pytest\\n2\\n3\\n4class TestPydoc:\\n5  ...</td>\n",
       "      <td>[['completion', '==', 'True'], ['completion', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>['completion']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1618</td>\n",
       "      <td>[[6, 'completion', '!=', None, 'input variable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SBRG/ome</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\nfrom cobradb.models...</td>\n",
       "      <td>\\n1# -*- coding: utf-8 -*-\\n2\\n3from cobradb.m...</td>\n",
       "      <td>[['load_the_map(None', '==', 'True']]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>['test_db', 'session']</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1684</td>\n",
       "      <td>[[8, 'test_db', '!=', None, \"the test_db shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>totalgood/twote</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>\\n1#!/usr/bin/env python\\n2# -*- coding: utf-8...</td>\n",
       "      <td>[['fib(1)', '==', '1'], ['fib(2)', '==', '1'],...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>['__author__', '__copyright__', '__license__']</td>\n",
       "      <td>3</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1696</td>\n",
       "      <td>[14, '-10', &gt;=, 0, \"the fibonacci sequence can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AartGoossens/athletic_pandas</td>\n",
       "      <td>import pandas as pd\\nimport pytest\\n\\nfrom ath...</td>\n",
       "      <td>\\n1import pandas as pd\\n2import pytest\\n3\\n4fr...</td>\n",
       "      <td>[[\"model.params['hr_rest'].value\", '==', '0.00...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>['heartrate', 'power', 'model', 'predictions']</td>\n",
       "      <td>4</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1720</td>\n",
       "      <td>[[8, 'heartrate', '==', 50, \"heartrate should ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tbenthompson/cppimport</td>\n",
       "      <td>import contextlib\\nimport copy\\nimport logging...</td>\n",
       "      <td>\\n1import contextlib\\n2import copy\\n3import lo...</td>\n",
       "      <td>[['p.returncode', '==', 'returncode'], ['os.pa...</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>['root_logger', 'handler', 'formatter', 'filen...</td>\n",
       "      <td>27</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7725</td>\n",
       "      <td>[[39, 'test_code', '!=', '', 'Check that test_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mattwthompson/mdtraj</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>\\n1###########################################...</td>\n",
       "      <td>[['os.system(cmd)', '==', '0'], [\"atoms['charg...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>['get_fn', 'trj', 'ref_trj', 'ref_top', 'ref_b...</td>\n",
       "      <td>37</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7731</td>\n",
       "      <td>[[35, 'get_fn', '!=', None, \"Function get_fn m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dfred/concept-robot</td>\n",
       "      <td># PyVision License\\n#\\n# Copyright (c) 2006-20...</td>\n",
       "      <td>\\n1# PyVision License\\n2#\\n3# Copyright (c) 20...</td>\n",
       "      <td>[['len(tmp)', '&gt;', '0']]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>['*points', 'tmp', 'minx', 'miny', 'maxx', 'ma...</td>\n",
       "      <td>38</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7873</td>\n",
       "      <td>[40, '*points', '!=', 0, \"The function needs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nanalelfe/fofe-ner</td>\n",
       "      <td>#!/home/chwang/anaconda2/envs/tensorflow/bin/p...</td>\n",
       "      <td>\\n1#!/home/chwang/anaconda2/envs/tensorflow/bi...</td>\n",
       "      <td>[['len(offsets)', '==', 'len(sent)'], ['0', '&lt;...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>['logger', 'rspecifier', 'language', 'entity2c...</td>\n",
       "      <td>34</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7908</td>\n",
       "      <td>[[11, 'rspecifier', '!=', '', \"function LoadED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>infobip/oneapi-python</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\nimport pdb\\n\\nimpor...</td>\n",
       "      <td>\\n1# -*- coding: utf-8 -*-\\n2\\n3import pdb\\n4\\...</td>\n",
       "      <td>[['model_class', '==', 'True'], ['obj', '==', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>['json_field_name', 'self.json_field_name', 's...</td>\n",
       "      <td>26</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7999</td>\n",
       "      <td>Here are the assertions for the provided code:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        repo_name  \\\n",
       "135        weidenba/recovery_sort   \n",
       "28    algorythmic/bash-completion   \n",
       "72                       SBRG/ome   \n",
       "150               totalgood/twote   \n",
       "97   AartGoossens/athletic_pandas   \n",
       "..                            ...   \n",
       "177        tbenthompson/cppimport   \n",
       "29           mattwthompson/mdtraj   \n",
       "9             Dfred/concept-robot   \n",
       "33             nanalelfe/fofe-ner   \n",
       "128         infobip/oneapi-python   \n",
       "\n",
       "                                               content  \\\n",
       "135  from filter_system.rename import RenameFilterS...   \n",
       "28   import pytest\\n\\n\\nclass TestPydoc:\\n    @pyte...   \n",
       "72   # -*- coding: utf-8 -*-\\n\\nfrom cobradb.models...   \n",
       "150  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "97   import pandas as pd\\nimport pytest\\n\\nfrom ath...   \n",
       "..                                                 ...   \n",
       "177  import contextlib\\nimport copy\\nimport logging...   \n",
       "29   ##############################################...   \n",
       "9    # PyVision License\\n#\\n# Copyright (c) 2006-20...   \n",
       "33   #!/home/chwang/anaconda2/envs/tensorflow/bin/p...   \n",
       "128  # -*- coding: utf-8 -*-\\n\\nimport pdb\\n\\nimpor...   \n",
       "\n",
       "                                            unasserted  \\\n",
       "135  \\n1from filter_system.rename import RenameFilt...   \n",
       "28   \\n1import pytest\\n2\\n3\\n4class TestPydoc:\\n5  ...   \n",
       "72   \\n1# -*- coding: utf-8 -*-\\n2\\n3from cobradb.m...   \n",
       "150  \\n1#!/usr/bin/env python\\n2# -*- coding: utf-8...   \n",
       "97   \\n1import pandas as pd\\n2import pytest\\n3\\n4fr...   \n",
       "..                                                 ...   \n",
       "177  \\n1import contextlib\\n2import copy\\n3import lo...   \n",
       "29   \\n1###########################################...   \n",
       "9    \\n1# PyVision License\\n2#\\n3# Copyright (c) 20...   \n",
       "33   \\n1#!/home/chwang/anaconda2/envs/tensorflow/bi...   \n",
       "128  \\n1# -*- coding: utf-8 -*-\\n2\\n3import pdb\\n4\\...   \n",
       "\n",
       "                                            assertions  asserted_lines  \\\n",
       "135  [['len(filter_system.filter_plugins.keys())', ...               2   \n",
       "28   [['completion', '==', 'True'], ['completion', ...               2   \n",
       "72               [['load_the_map(None', '==', 'True']]               1   \n",
       "150  [['fib(1)', '==', '1'], ['fib(2)', '==', '1'],...               3   \n",
       "97   [[\"model.params['hr_rest'].value\", '==', '0.00...               7   \n",
       "..                                                 ...             ...   \n",
       "177  [['p.returncode', '==', 'returncode'], ['os.pa...              15   \n",
       "29   [['os.system(cmd)', '==', '0'], [\"atoms['charg...               6   \n",
       "9                             [['len(tmp)', '>', '0']]               1   \n",
       "33   [['len(offsets)', '==', 'len(sent)'], ['0', '<...               4   \n",
       "128  [['model_class', '==', 'True'], ['obj', '==', ...               7   \n",
       "\n",
       "     parsed_lines       arr       atl  \\\n",
       "135             2  1.000000  0.006780   \n",
       "28              2  1.000000  0.007576   \n",
       "72              1  1.000000  0.003086   \n",
       "150             3  1.000000  0.009434   \n",
       "97              7  1.000000  0.009986   \n",
       "..            ...       ...       ...   \n",
       "177            12  0.800000  0.001981   \n",
       "29              6  1.000000  0.001037   \n",
       "9               1  1.000000  0.000175   \n",
       "33              2  0.500000  0.000328   \n",
       "128             5  0.714286  0.000842   \n",
       "\n",
       "                                             variables  num_vars  \\\n",
       "135                                  ['filter_system']         1   \n",
       "28                                      ['completion']         1   \n",
       "72                              ['test_db', 'session']         2   \n",
       "150     ['__author__', '__copyright__', '__license__']         3   \n",
       "97      ['heartrate', 'power', 'model', 'predictions']         4   \n",
       "..                                                 ...       ...   \n",
       "177  ['root_logger', 'handler', 'formatter', 'filen...        27   \n",
       "29   ['get_fn', 'trj', 'ref_trj', 'ref_top', 'ref_b...        37   \n",
       "9    ['*points', 'tmp', 'minx', 'miny', 'maxx', 'ma...        38   \n",
       "33   ['logger', 'rspecifier', 'language', 'entity2c...        34   \n",
       "128  ['json_field_name', 'self.json_field_name', 's...        26   \n",
       "\n",
       "                                                prompt  prompt_len  \\\n",
       "135  You are a helpful bot that adds assertions to ...        1582   \n",
       "28   You are a helpful bot that adds assertions to ...        1618   \n",
       "72   You are a helpful bot that adds assertions to ...        1684   \n",
       "150  You are a helpful bot that adds assertions to ...        1696   \n",
       "97   You are a helpful bot that adds assertions to ...        1720   \n",
       "..                                                 ...         ...   \n",
       "177  You are a helpful bot that adds assertions to ...        7725   \n",
       "29   You are a helpful bot that adds assertions to ...        7731   \n",
       "9    You are a helpful bot that adds assertions to ...        7873   \n",
       "33   You are a helpful bot that adds assertions to ...        7908   \n",
       "128  You are a helpful bot that adds assertions to ...        7999   \n",
       "\n",
       "                                                   gpt  \n",
       "135  [[5, 'filter_system', '!=', None, \"Filter syst...  \n",
       "28   [[6, 'completion', '!=', None, 'input variable...  \n",
       "72   [[8, 'test_db', '!=', None, \"the test_db shoul...  \n",
       "150  [14, '-10', >=, 0, \"the fibonacci sequence can...  \n",
       "97   [[8, 'heartrate', '==', 50, \"heartrate should ...  \n",
       "..                                                 ...  \n",
       "177  [[39, 'test_code', '!=', '', 'Check that test_...  \n",
       "29   [[35, 'get_fn', '!=', None, \"Function get_fn m...  \n",
       "9    [40, '*points', '!=', 0, \"The function needs a...  \n",
       "33   [[11, 'rspecifier', '!=', '', \"function LoadED...  \n",
       "128  Here are the assertions for the provided code:...  \n",
       "\n",
       "[200 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(cwd+\"/Data/Testing/python_prompts_withresponse_part2.csv\").sort_values(\"prompt_len\", ascending=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2076b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asserted_lines</th>\n",
       "      <th>parsed_lines</th>\n",
       "      <th>arr</th>\n",
       "      <th>atl</th>\n",
       "      <th>num_vars</th>\n",
       "      <th>prompt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.965000</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>0.849637</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>13.960000</td>\n",
       "      <td>4531.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.496921</td>\n",
       "      <td>13.600893</td>\n",
       "      <td>0.294534</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>9.514781</td>\n",
       "      <td>1732.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746528</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2944.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>4519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>6041.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       asserted_lines  parsed_lines         arr         atl    num_vars  \\\n",
       "count      200.000000    200.000000  200.000000  200.000000  200.000000   \n",
       "mean        10.965000      8.525000    0.849637    0.002552   13.960000   \n",
       "std         15.496921     13.600893    0.294534    0.002973    9.514781   \n",
       "min          1.000000      1.000000    0.037736    0.000185    1.000000   \n",
       "25%          2.000000      1.000000    0.746528    0.000588    6.000000   \n",
       "50%          4.000000      3.000000    1.000000    0.001417   11.500000   \n",
       "75%         14.000000      8.000000    1.000000    0.003679   20.250000   \n",
       "max         99.000000     95.000000    2.000000    0.023152   45.000000   \n",
       "\n",
       "        prompt_len  \n",
       "count   200.000000  \n",
       "mean   4531.530000  \n",
       "std    1732.097439  \n",
       "min    1517.000000  \n",
       "25%    2944.250000  \n",
       "50%    4519.000000  \n",
       "75%    6041.250000  \n",
       "max    8140.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33101274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing Data for prompt_len sorted data in Part1 Ind11\n",
      "\n",
      "Extracted Assertion:\n",
      "[['completion', '==', 'True'], ['completion', '==', 'True']]\n",
      "\n",
      "Variables:\n",
      "['completion']\n",
      "\n",
      "Code:\n",
      "import pytest\n",
      "\n",
      "\n",
      "@pytest.mark.bashcomp(cmd=\"munin-node-configure\")\n",
      "class TestMuninNodeConfigure:\n",
      "    @pytest.mark.complete(\"munin-node-configure --libdir \")\n",
      "    def test_1(self, completion):\n",
      "        assert completion\n",
      "\n",
      "    @pytest.mark.complete(\n",
      "        \"munin-node-configure -\",\n",
      "        require_cmd=True,\n",
      "        xfail=(\n",
      "            \"! (munin-node-configure --help 2>&1 || :) \"\n",
      "            \"| command grep -q -- '[[:space:]]-'\"\n",
      "        ),\n",
      "    )\n",
      "    def test_2(self, completion):\n",
      "        assert completion\n",
      "\n",
      "\n",
      "Code:\n",
      "\n",
      "1import pytest\n",
      "2\n",
      "3\n",
      "4@pytest.mark.bashcomp(cmd=\"munin-node-configure\")\n",
      "5class TestMuninNodeConfigure:\n",
      "6    @pytest.mark.complete(\"munin-node-configure --libdir \")\n",
      "7    def test_1(self, completion):\n",
      "8\n",
      "9    @pytest.mark.complete(\n",
      "10        \"munin-node-configure -\",\n",
      "11        require_cmd=True,\n",
      "12        xfail=(\n",
      "13            \"! (munin-node-configure --help 2>&1 || :) \"\n",
      "14            \"| command grep -q -- '[[:space:]]-'\"\n",
      "15        ),\n",
      "16    )\n",
      "17    def test_2(self, completion):\n",
      "18\n",
      "\n",
      "GPT Response:\n",
      "[[7, 'completion', '!=', None, 'completion should not be None'],\n",
      "[17, 'completion', '!=', None, 'completion should not be None']]\n"
     ]
    }
   ],
   "source": [
    "ind = 11\n",
    "print(\"Showing Data for prompt_len sorted data in Part1 Ind\"+str(ind))\n",
    "print(\"\\nExtracted Assertion:\")\n",
    "print(df.iloc[ind][\"assertions\"])\n",
    "print(\"\\nVariables:\")\n",
    "print(df.iloc[ind][\"variables\"])\n",
    "print(\"\\nCode:\")\n",
    "print(df.iloc[ind][\"content\"])\n",
    "print(\"\\nCode:\")\n",
    "print(df.iloc[ind][\"unasserted\"])\n",
    "\n",
    "print(\"\\nGPT Response:\")\n",
    "print(df.iloc[ind][\"gpt\"])\n",
    "\n",
    "# print(\"\\nPROMPT:\")\n",
    "# print(df.iloc[ind][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c85a1",
   "metadata": {},
   "source": [
    "# Step 5) Replicating for Verilog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa305ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful bot that adds assertions to pieces of Verilog code.\n",
      "You will be given a string of code presented in the format:\n",
      "*Variables:\n",
      "...\n",
      "*Code:\n",
      "...\n",
      "Generate assertions based on the following criteria:\n",
      "1) Assert that the function can take in all inputs necessary to complete the process\n",
      "2) Assert that all outputs are of the proper sizes.\n",
      "\n",
      "Your response should ONLY be a list of assertions in the format:\n",
      "[timing, subject_variable, target, reasoning]\n",
      " -timing is the clock cycle(s) at which the assertion is checked relative to the present cycle\n",
      " -subject_variable and target can ONLY be variables present in the code, integers, booleans, or None\n",
      " -reasoning is a short decription of why the assertion was made\n",
      "\n",
      "Here is an example of what your input will look like and what you should return:\n",
      "Example Input:\n",
      "*Variables:\n",
      "[clkstart, pr1, cStart, sr1]\n",
      "*Code:\n",
      "assign clkstart = clk && gGate;\n",
      "sequence sr1;\n",
      "    req ##2 gnt;\n",
      "endsequence\n",
      "\n",
      "property pr1;\n",
      "    @(posedge clkstart) cStart |-> sr1;\n",
      "endproperty\n",
      "\n",
      "sequence sr1;\n",
      "    req ##2 gnt;\n",
      "endsequence\n",
      "\n",
      "property pr1;\n",
      "    @(posedge clk) cStart |-> sr1;\n",
      "endproperty\n",
      "Example Output:\n",
      "[clkstart, cStart, sr1, \"cStart should be equal to sr1 at the start of every clock cycle\"]\n",
      "Which would be the same as adding the assertion:\n",
      "assert @(posedge clkstart) cStart |-> sr1 else $display(\"cStart should be equal to sr1 at the start of every clock cycle\");\n",
      "\n",
      "\n",
      "Here is the actual input you should provide assertions for:\n",
      "*Variables:\n",
      "[flag, num, i]\n",
      "*Code:\n",
      "1num = int(input(\"Enter a number: \"))  # Program to check if a number is prime or not\n",
      "2flag = False  # define a flag variable\n",
      "3\n",
      "4if num == 1:\n",
      "5    print(num, \"is not a prime number\")\n",
      "6elif num > 1: # check for factors\n",
      "7    for i in range(2, num):\n",
      "8        if (num % i) == 0:\n",
      "9            flag = True  # if factor is found, set flag to True\n",
      "10            break  # break out of loop\n",
      "11    if flag:  # check if flag is True\n",
      "12        print(num, \"is not a prime number\")\n",
      "13    else:\n",
      "14        print(num, \"is a prime number\")\n"
     ]
    }
   ],
   "source": [
    "class VLLM_prompt:       \n",
    "    def __init__(self, input_code=\"*Variables:\\n[flag, num, i]\\n*Code:\\n1num = int(input(\\\"Enter a number: \\\"))  # Program to check if a number is prime or not\\n2flag = False  # define a flag variable\\n3\\n4if num == 1:\\n5    print(num, \\\"is not a prime number\\\")\\n6elif num > 1: # check for factors\\n7    for i in range(2, num):\\n8        if (num % i) == 0:\\n9            flag = True  # if factor is found, set flag to True\\n10            break  # break out of loop\\n11    if flag:  # check if flag is True\\n12        print(num, \\\"is not a prime number\\\")\\n13    else:\\n14        print(num, \\\"is a prime number\\\")\",\n",
    "                 example_in=\"*Variables:\\n[clkstart, pr1, cStart, sr1]\\n*Code:\\nassign clkstart = clk && gGate;\\nsequence sr1;\\n    req ##2 gnt;\\nendsequence\\n\\nproperty pr1;\\n    @(posedge clkstart) cStart |-> sr1;\\nendproperty\\n\\nsequence sr1;\\n    req ##2 gnt;\\nendsequence\\n\\nproperty pr1;\\n    @(posedge clk) cStart |-> sr1;\\nendproperty\",\n",
    "                 example_out=\"[clkstart, cStart, sr1, \\\"cStart should be equal to sr1 at the start of every clock cycle\\\"]\\nWhich would be the same as adding the assertion:\\nassert @(posedge clkstart) cStart |-> sr1 else $display(\\\"cStart should be equal to sr1 at the start of every clock cycle\\\");\", \n",
    "                 criteria=[\"Assert that the function can take in all inputs necessary to complete the process\",\n",
    "                           \"Assert that all outputs are of the proper sizes.\"]\n",
    "                 ):\n",
    "        self.criteria = criteria\n",
    "        self.example = prompt_example(example_in, example_out)\n",
    "        self.input_code = input_code\n",
    "        \n",
    "        # default params that are less likely to change\n",
    "        self.intro = \"You are a helpful bot that adds assertions to pieces of Verilog code.\"  \n",
    "        self.input_format = \"You will be given a string of code presented in the format:\\n*Variables:\\n...\\n*Code:\\n...\"\n",
    "        self.criteria_transition = \"Generate assertions based on the following criteria:\"\n",
    "        self.output_format = \"Your response should ONLY be a list of assertions in the format:\\n[timing, subject_variable, target, reasoning]\"\n",
    "        self.output_format_description = [\"timing is the clock cycle(s) at which the assertion is checked relative to the present cycle\",\n",
    "                                          \"subject_variable and target can ONLY be variables present in the code, integers, booleans, or None\",\n",
    "                                          \"reasoning is a short decription of why the assertion was made\"]\n",
    "        self.example_transition = \"Here is an example of what your input will look like and what you should return:\"\n",
    "        self.input_transition = \"Here is the actual input you should provide assertions for:\"\n",
    "        # \n",
    "    \n",
    "    \n",
    "    def composite_criteria(self):\n",
    "        \"\"\" return criteria as a single string\"\"\"\n",
    "        ret = \"\"\n",
    "        for i, crit in enumerate(self.criteria):\n",
    "            ret += str(i+1) + \") \" + crit\n",
    "            if i != len(self.criteria)-1:  # ignore last instance for formatting\n",
    "                ret += '\\n'\n",
    "        return ret\n",
    "    \n",
    "    def composite_output_formatting(self):\n",
    "        ret = self.output_format\n",
    "        for desc in self.output_format_description:\n",
    "            ret += \"\\n -\" + desc \n",
    "        return ret\n",
    "    \n",
    "    def prompt(self):\n",
    "        \"\"\" return entire prompt\"\"\"\n",
    "        return '\\n'.join([self.intro, self.input_format,\n",
    "                          self.criteria_transition, self.composite_criteria(), \"\",\n",
    "                          self.composite_output_formatting(), \"\",\n",
    "                          self.example_transition, self.example.composite(), \"\\n\",\n",
    "                          self.input_transition, self.input_code])\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\" return key prompt components as a list \"\"\"\n",
    "        return [self.intro, self.formatting, self.criteria, self.example, self.input_code, self.prompt()]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.prompt()\n",
    "    def __repr__(self):\n",
    "        return self.prompt()\n",
    "    \n",
    "def v_gen_prompt(df):\n",
    "    # TODO: make variable-less prompt\n",
    "    ret = []\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        my_vars = row[\"variables\"]\n",
    "        my_code = row[\"unasserted\"]\n",
    "        prompt_param = \"*Variables:\\n\" + str(row[\"variables\"]) + \"\\n*Code:\\n\" + row[\"unasserted\"]\n",
    "        ret.append(str(VLLM_prompt(prompt_param)))\n",
    "    return ret\n",
    "        \n",
    "        \n",
    "print(str(VLLM_prompt()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "target_vars = ['property', 'assign', 'variable', 'assert']\n",
    "def extract_variables(verilog_code):\n",
    "    # Regular expression to match Verilog variable declarations\n",
    "    variable_pattern = r'\\b(?:wire|reg|integer|real|time)\\s+(.*?)\\s*[,;]'\n",
    "\n",
    "    # Find all matches\n",
    "    matches = re.findall(variable_pattern, verilog_code, re.MULTILINE)\n",
    "    \n",
    "    variables = set()\n",
    "    # Remove extra whitespace and split on commas\n",
    "    for match in matches:\n",
    "        for var in match.split(','):\n",
    "            variables.add(var.strip())\n",
    "    \n",
    "    for line in verilog_code.split('\\n'):\n",
    "        for tvar in target_vars:\n",
    "            found = line.find(tvar)\n",
    "            if found != -1:\n",
    "                var = clean_var(line[found+8:])\n",
    "                if tvar == 'assert':\n",
    "                    var = var.replace('property', '').strip()\n",
    "                var = [val.strip() for val in var.split(' ')][0]\n",
    "                if len(var) > 0:\n",
    "                    variables.add(var)\n",
    "    return list(variables)\n",
    "\n",
    "dirt = ['(', ')', ':', ';']\n",
    "def clean_var(var):\n",
    "    for d in dirt:\n",
    "        var = var.replace(d, '')\n",
    "    return var.strip()\n",
    "\n",
    "def v_extract_assertions(verilog_code):\n",
    "    # Regular expression to match Verilog assertions\n",
    "#     assertion_pattern = r'\\bassert\\s*\\((.*?)\\)\\s*;'\n",
    "    \n",
    "    # Find all matches\n",
    "#     matches = re.findall(assertion_pattern, verilog_code, re.MULTILINE)\n",
    "    matches = []\n",
    "    for line in verilog_code.split('\\n'):\n",
    "        found = line.find('assert')\n",
    "        if found != -1:\n",
    "            info = line[found+6:]\n",
    "            found2 = info.find('else')\n",
    "            if found2 == -1:\n",
    "                found2 = len(info)\n",
    "            matches.append(info[:found2].strip())\n",
    "    return matches\n",
    "\n",
    "def old_v_get_assertions(code):\n",
    "    ret = []\n",
    "    for line in code.split('\\n'):\n",
    "        if 'assert' in line:  # property\n",
    "            ret.append(line.strip())\n",
    "    return ret\n",
    "\n",
    "# def v_get_variables(assertions):\n",
    "#     ret = []\n",
    "#     for statement in assertions:\n",
    "#         ret.append(statement.split(' ')[0].strip())\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def verilog_one_shot(my_dir=cwd+\"/Data/pages-gptresponse.csv\", preprocessed=True):\n",
    "    if not preprocessed:\n",
    "        print(\"GETTING CODE\")\n",
    "        vdf = pd.read_csv(my_dir)\n",
    "\n",
    "    #     vdf = vdf[~vdf[\"raw_code\"].isna()]\n",
    "        vdf = vdf.rename({'content': 'Code'}, axis='columns')\n",
    "\n",
    "        vdf[\"Code\"] = vdf[\"Code\"].apply(lambda x:str(x))\n",
    "        # vdf[\"content_len\"] = vdf[\"content\"].apply(lambda code: len(code))\n",
    "        # vdf = vdf.sort_values(\"content_len\", ascending=True)\n",
    "\n",
    "        print(\"\\nEXTRACTING ASSERTIONS\")\n",
    "        vdf[\"unasserted\"] = vdf[\"Code\"].apply(lambda code: unassert(code, '', False))\n",
    "\n",
    "        vdf[\"assertions\"] = vdf[\"Code\"].apply(lambda code: v_extract_assertions(code))\n",
    "        vdf[\"num_assertions\"] = vdf[\"assertions\"].apply(lambda code: len(code))\n",
    "\n",
    "        all_prompts = len(vdf)\n",
    "        vdf = vdf[vdf[\"num_assertions\"] > 0]\n",
    "        all_prompts = 100*len(vdf)/all_prompts\n",
    "        print(\"\\ndropping prompts with no exctracted assertions =>\", str(all_prompts)+'%')\n",
    "\n",
    "        print(\"\\nEXTRACTING VARIABLES\")\n",
    "        vdf[\"variables\"] = vdf[\"Code\"].apply(lambda code: extract_variables(code))\n",
    "        vdf[\"num_vars\"] = vdf[\"variables\"].apply(lambda code: len(code))\n",
    "\n",
    "        all_prompts = len(vdf)\n",
    "        vdf = vdf[vdf[\"num_vars\"] > 0]\n",
    "        all_prompts = 100*len(vdf)/all_prompts\n",
    "        print(\"\\ndropping prompts with no exctracted variables =>\", str(all_prompts)+'%')\n",
    "\n",
    "        print(\"\\nGENERATING PROMPTS\")\n",
    "        vdf[\"prompt\"] = v_gen_prompt(vdf)\n",
    "        vdf[\"prompt_len\"] = vdf[\"prompt\"].apply(lambda code: len(code))\n",
    "\n",
    "        prompt_limit = 8192\n",
    "        all_prompts = len(vdf)\n",
    "        vdf = vdf[vdf[\"prompt_len\"] < prompt_limit]\n",
    "        all_prompts = 100*len(vdf)/all_prompts\n",
    "        print(\"dropping prompts over limit =>\", str(all_prompts)+'%')\n",
    "\n",
    "        to_save = cwd+\"/Data/preprocessing/preprocessed_verilog_unsupervised.csv\"\n",
    "        vdf.to_csv(to_save) # saving data\n",
    "        print(\"Data checkpoint saved...\\n\")\n",
    "    else:\n",
    "        vdf = pd.read_csv(cwd+\"/Data/preprocessing/preprocessed_verilog_unsupervised.csv\").head(100)\n",
    "        print(\"Data checkpoint restored...\")\n",
    "    \n",
    "    print(\"GENERATING RESPONSES\")\n",
    "    responses = []\n",
    "    for prompt in tqdm(vdf[\"prompt\"]):\n",
    "        responses.append(gpt_oneshot(prompt))\n",
    "    vdf[\"gpt\"] = responses\n",
    "    vdf.to_csv(cwd+\"/Data/gpt-responses/verilog-code/unsupervised_verilog_responses.csv\") # saving data\n",
    "    return vdf\n",
    "\n",
    "vdf = verilog_one_shot(cwd+\"/Data/BigQuery/VerilogAssertions-ALL.csv\")\n",
    "# print(vdf.sample().iloc[0][\"Code\"])\n",
    "vdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e82c7b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library ieee;\r\n",
      "use ieee.std_logic_1164.all;\r\n",
      "\r\n",
      "entity noise_generator is\r\n",
      "generic (\r\n",
      "    g_type          : string := \"Fibonacci\"; -- can also be \"Galois\"\r\n",
      "    g_polynom       : std_logic_vector := X\"E10000\";\r\n",
      "    g_fixed_polynom : boolean := true;\r\n",
      "    g_seed          : std_logic_vector := X\"000001\" );\r\n",
      "port (\r\n",
      "    clock           : in  std_logic;\r\n",
      "    enable          : in  std_logic;\r\n",
      "    reset           : in  std_logic;\r\n",
      "    polynom         : in  std_logic_vector(g_polynom'length-1 downto 0) := (others => '0');\r\n",
      "    q               : out std_logic_vector(g_polynom'length-1 downto 0) );\r\n",
      "end noise_generator;\r\n",
      "\r\n",
      "architecture gideon of noise_generator is\r\n",
      "    signal c_poly   : std_logic_vector(g_polynom'length-1 downto 0);\r\n",
      "    signal reg      : std_logic_vector(g_polynom'length-1 downto 0);\r\n",
      "begin\r\n",
      "    assert (g_type = \"Fibonacci\") or (g_type = \"Galois\")\r\n",
      "        report \"Type of LFSR should be Fibonacci or Galois..\"\r\n",
      "        severity failure;\r\n",
      "    \r\n",
      "    c_poly <= g_polynom when g_fixed_polynom else polynom;    \r\n",
      "    \r\n",
      "    process(clock)\r\n",
      "        variable new_bit  : std_logic;\r\n",
      "    begin\r\n",
      "        if rising_edge(clock) then\r\n",
      "            if enable='1' then\r\n",
      "                if g_type = \"Fibonacci\" then\r\n",
      "                    new_bit := '0';\r\n",
      "                    for i in c_poly'range loop\r\n",
      "                        if c_poly(i)='1' then\r\n",
      "                            new_bit := new_bit xor reg(i);\r\n",
      "                        end if;\r\n",
      "                    end loop;\r\n",
      "                    reg <= reg(reg'high-1 downto 0) & new_bit;\r\n",
      "                else -- \"Galois\", enforced by assert\r\n",
      "                    if reg(reg'high)='1' then\r\n",
      "                        reg <= (reg(reg'high-1 downto 0) & '0') xor c_poly;\r\n",
      "                    else\r\n",
      "                        reg <=  reg(reg'high-1 downto 0) & '1';\r\n",
      "                    end if;\r\n",
      "                end if;\r\n",
      "            end if;\r\n",
      "            \r\n",
      "            if reset='1' then\r\n",
      "                reg <= g_seed;\r\n",
      "            end if;\r\n",
      "        end if;\r\n",
      "    end process;\r\n",
      "    q <= reg;\r\n",
      "end gideon;\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vdf.sample().iloc[0][\"Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0a484f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING RESPONSES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 70/70 [26:06<00:00, 22.38s/it]\n",
      "/var/folders/mv/k0krwyts3z5cfn3y2tltw0sc0000gn/T/ipykernel_38670/2562689721.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vdf[\"gpt\"] = responses\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATING RESPONSES\")\n",
    "responses = []\n",
    "for prompt in tqdm(vdf[\"prompt\"]):\n",
    "    responses.append(gpt_oneshot(prompt))\n",
    "vdf[\"gpt\"] = responses\n",
    "vdf.to_csv(cwd+\"/verilog_prompts_withresponse3.csv\") # saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6330cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "      <th>content_len</th>\n",
       "      <th>unasserted</th>\n",
       "      <th>assertions</th>\n",
       "      <th>num_assertions</th>\n",
       "      <th>variables</th>\n",
       "      <th>num_vars</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_len</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>module tb (input clock, a, b);\\n\\twire x, y;\\n...</td>\n",
       "      <td>250</td>\n",
       "      <td>\\n1module tb (input clock, a, b);\\n2\\twire x, ...</td>\n",
       "      <td>['x == ($past(a, 2) ^ $past(b, 2))', 'y == (!$...</td>\n",
       "      <td>2</td>\n",
       "      <td>['x', 'y']</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1768</td>\n",
       "      <td>[[2, '#0', 'x', '!=', None, \"Asserting that wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>swallat/yosys</td>\n",
       "      <td>module top (\\n  input clk, rst,\\n  output reg ...</td>\n",
       "      <td>272</td>\n",
       "      <td>\\n1module top (\\n2  input clk, rst,\\n3  output...</td>\n",
       "      <td>['cnt != 15']</td>\n",
       "      <td>1</td>\n",
       "      <td>['cnt']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>1868</td>\n",
       "      <td>[7, #1, cnt, \"==\", 0, \"checking if counter is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>YosysHQ/yosys</td>\n",
       "      <td>module top;\\n    reg [0:7] mem [0:2];\\n\\n    i...</td>\n",
       "      <td>584</td>\n",
       "      <td>\\n1module top;\\n2    reg [0:7] mem [0:2];\\n3\\n...</td>\n",
       "      <td>[\"$countbits(a, '0) == 24\", \"$countbits(a, '1)...</td>\n",
       "      <td>9</td>\n",
       "      <td>['$countbits(a,', '$countbits(a,', '$countbits...</td>\n",
       "      <td>9</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>[6, #0, 'a', '==', 'mem[1]', \"Ensuring 'mem[1]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>YosysHQ/yosys</td>\n",
       "      <td>// An example showing how parameters get infer...</td>\n",
       "      <td>617</td>\n",
       "      <td>\\n1// An example showing how parameters get in...</td>\n",
       "      <td>[\"w0 == '0\", 'w1 == u1 ^ v1']</td>\n",
       "      <td>2</td>\n",
       "      <td>['w0', 'w1']</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>2205</td>\n",
       "      <td>[[3, #0, 'a', '==', 'b', 'It is necessary to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>zachjs/sv2v</td>\n",
       "      <td>module Module(input clock, input clear, input ...</td>\n",
       "      <td>757</td>\n",
       "      <td>\\n1module Module(input clock, input clear, inp...</td>\n",
       "      <td>['1', '1', '1', '1']</td>\n",
       "      <td>4</td>\n",
       "      <td>['1', '1', '1', '1']</td>\n",
       "      <td>4</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>2169</td>\n",
       "      <td>[3, #0, 'y', '==', 'data', \"checking input 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>254</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>/**\\n *  Name:\\n *    bp_be_dcache_wbuf.sv\\n *...</td>\n",
       "      <td>5575</td>\n",
       "      <td>\\n1/**\\n2 *  Name:\\n3 *    bp_be_dcache_wbuf.s...</td>\n",
       "      <td>['~reset_i || num_els_r &lt; 2\\'d3) else $error(\"...</td>\n",
       "      <td>1</td>\n",
       "      <td>['~reset_i']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7535</td>\n",
       "      <td>[22, \"#0\", \"clk_i\", \"==\", 1, \"input clock (clk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>172</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>// Copyright 2018 ETH Zurich and University of...</td>\n",
       "      <td>5665</td>\n",
       "      <td>\\n1// Copyright 2018 ETH Zurich and University...</td>\n",
       "      <td>['tck_src &gt; 0', 'tck_dst &gt; 0']</td>\n",
       "      <td>2</td>\n",
       "      <td>['tck_src', 'tck_dst']</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7362</td>\n",
       "      <td>[[52, \"#0\", \"dst_mbox\", \"==\", None, \"checking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>146</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>// Copyright 2019 ETH Zurich and University of...</td>\n",
       "      <td>5699</td>\n",
       "      <td>\\n1// Copyright 2019 ETH Zurich and University...</td>\n",
       "      <td>[\"FALL_THROUGH == 1'b0\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>['FALL_THROUGH']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7229</td>\n",
       "      <td>Based on the given Verilog code and assertion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>162</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>// Copyright 2018 ETH Zurich and University of...</td>\n",
       "      <td>5806</td>\n",
       "      <td>\\n1// Copyright 2018 ETH Zurich and University...</td>\n",
       "      <td>['binary != \"\") else $error(\"We need a preload...</td>\n",
       "      <td>1</td>\n",
       "      <td>['binary']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>7069</td>\n",
       "      <td>Based on the given code, here are some asserti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>188</td>\n",
       "      <td>alainmarcel/Surelog</td>\n",
       "      <td>// Copyright 2018 ETH Zurich and University of...</td>\n",
       "      <td>6279</td>\n",
       "      <td>\\n1// Copyright 2018 ETH Zurich and University...</td>\n",
       "      <td>['DEPTH &gt; 0)             else $error(\"DEPTH mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>['DEPTH']</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a helpful bot that adds assertions to ...</td>\n",
       "      <td>8066</td>\n",
       "      <td>Based on the provided Verilog code, here are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0            repo_name  \\\n",
       "0          232  alainmarcel/Surelog   \n",
       "1            1        swallat/yosys   \n",
       "2          105        YosysHQ/yosys   \n",
       "3          108        YosysHQ/yosys   \n",
       "4           39          zachjs/sv2v   \n",
       "..         ...                  ...   \n",
       "65         254  alainmarcel/Surelog   \n",
       "66         172  alainmarcel/Surelog   \n",
       "67         146  alainmarcel/Surelog   \n",
       "68         162  alainmarcel/Surelog   \n",
       "69         188  alainmarcel/Surelog   \n",
       "\n",
       "                                              content  content_len  \\\n",
       "0   module tb (input clock, a, b);\\n\\twire x, y;\\n...          250   \n",
       "1   module top (\\n  input clk, rst,\\n  output reg ...          272   \n",
       "2   module top;\\n    reg [0:7] mem [0:2];\\n\\n    i...          584   \n",
       "3   // An example showing how parameters get infer...          617   \n",
       "4   module Module(input clock, input clear, input ...          757   \n",
       "..                                                ...          ...   \n",
       "65  /**\\n *  Name:\\n *    bp_be_dcache_wbuf.sv\\n *...         5575   \n",
       "66  // Copyright 2018 ETH Zurich and University of...         5665   \n",
       "67  // Copyright 2019 ETH Zurich and University of...         5699   \n",
       "68  // Copyright 2018 ETH Zurich and University of...         5806   \n",
       "69  // Copyright 2018 ETH Zurich and University of...         6279   \n",
       "\n",
       "                                           unasserted  \\\n",
       "0   \\n1module tb (input clock, a, b);\\n2\\twire x, ...   \n",
       "1   \\n1module top (\\n2  input clk, rst,\\n3  output...   \n",
       "2   \\n1module top;\\n2    reg [0:7] mem [0:2];\\n3\\n...   \n",
       "3   \\n1// An example showing how parameters get in...   \n",
       "4   \\n1module Module(input clock, input clear, inp...   \n",
       "..                                                ...   \n",
       "65  \\n1/**\\n2 *  Name:\\n3 *    bp_be_dcache_wbuf.s...   \n",
       "66  \\n1// Copyright 2018 ETH Zurich and University...   \n",
       "67  \\n1// Copyright 2019 ETH Zurich and University...   \n",
       "68  \\n1// Copyright 2018 ETH Zurich and University...   \n",
       "69  \\n1// Copyright 2018 ETH Zurich and University...   \n",
       "\n",
       "                                           assertions  num_assertions  \\\n",
       "0   ['x == ($past(a, 2) ^ $past(b, 2))', 'y == (!$...               2   \n",
       "1                                       ['cnt != 15']               1   \n",
       "2   [\"$countbits(a, '0) == 24\", \"$countbits(a, '1)...               9   \n",
       "3                       [\"w0 == '0\", 'w1 == u1 ^ v1']               2   \n",
       "4                                ['1', '1', '1', '1']               4   \n",
       "..                                                ...             ...   \n",
       "65  ['~reset_i || num_els_r < 2\\'d3) else $error(\"...               1   \n",
       "66                     ['tck_src > 0', 'tck_dst > 0']               2   \n",
       "67                           [\"FALL_THROUGH == 1'b0\"]               1   \n",
       "68  ['binary != \"\") else $error(\"We need a preload...               1   \n",
       "69  ['DEPTH > 0)             else $error(\"DEPTH mu...               1   \n",
       "\n",
       "                                            variables  num_vars  \\\n",
       "0                                          ['x', 'y']         2   \n",
       "1                                             ['cnt']         1   \n",
       "2   ['$countbits(a,', '$countbits(a,', '$countbits...         9   \n",
       "3                                        ['w0', 'w1']         2   \n",
       "4                                ['1', '1', '1', '1']         4   \n",
       "..                                                ...       ...   \n",
       "65                                       ['~reset_i']         1   \n",
       "66                             ['tck_src', 'tck_dst']         2   \n",
       "67                                   ['FALL_THROUGH']         1   \n",
       "68                                         ['binary']         1   \n",
       "69                                          ['DEPTH']         1   \n",
       "\n",
       "                                               prompt  prompt_len  \\\n",
       "0   You are a helpful bot that adds assertions to ...        1768   \n",
       "1   You are a helpful bot that adds assertions to ...        1868   \n",
       "2   You are a helpful bot that adds assertions to ...        2006   \n",
       "3   You are a helpful bot that adds assertions to ...        2205   \n",
       "4   You are a helpful bot that adds assertions to ...        2169   \n",
       "..                                                ...         ...   \n",
       "65  You are a helpful bot that adds assertions to ...        7535   \n",
       "66  You are a helpful bot that adds assertions to ...        7362   \n",
       "67  You are a helpful bot that adds assertions to ...        7229   \n",
       "68  You are a helpful bot that adds assertions to ...        7069   \n",
       "69  You are a helpful bot that adds assertions to ...        8066   \n",
       "\n",
       "                                                  gpt  \n",
       "0   [[2, '#0', 'x', '!=', None, \"Asserting that wi...  \n",
       "1   [7, #1, cnt, \"==\", 0, \"checking if counter is ...  \n",
       "2   [6, #0, 'a', '==', 'mem[1]', \"Ensuring 'mem[1]...  \n",
       "3   [[3, #0, 'a', '==', 'b', 'It is necessary to v...  \n",
       "4   [3, #0, 'y', '==', 'data', \"checking input 'da...  \n",
       "..                                                ...  \n",
       "65  [22, \"#0\", \"clk_i\", \"==\", 1, \"input clock (clk...  \n",
       "66  [[52, \"#0\", \"dst_mbox\", \"==\", None, \"checking ...  \n",
       "67  Based on the given Verilog code and assertion ...  \n",
       "68  Based on the given code, here are some asserti...  \n",
       "69  Based on the provided Verilog code, here are t...  \n",
       "\n",
       "[70 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdf = pd.read_csv(cwd+\"/verilog_prompts_withresponse3.csv\")\n",
    "vdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93626d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing Data for content_len sorted data Ind1\n",
      "\n",
      "Extracted Assertion:\n",
      "['cnt != 15']\n",
      "\n",
      "Variables:\n",
      "['cnt']\n",
      "\n",
      "GPT Response:\n",
      "[7, #1, cnt, \"==\", 0, \"checking if counter is reset to zero when 'rst' is true\"],\n",
      "[11, #1, cnt, \"<=\", 15, \"checking if counter 'cnt' does not exceed its maximum size\"]\n",
      "\n",
      "Code:\n",
      "module top (\n",
      "  input clk, rst,\n",
      "  output reg [3:0] cnt\n",
      ");\n",
      "  initial cnt = 0;\n",
      "\n",
      "  always @(posedge clk) begin\n",
      "    if (rst)\n",
      "      cnt <= 0;\n",
      "    else\n",
      "      cnt <= cnt + 4'd 1;\n",
      "  end\n",
      "\n",
      "  always @(posedge clk) begin\n",
      "    assume (cnt != 10);\n",
      "    assert (cnt != 15);\n",
      "  end\n",
      "endmodule\n",
      "\n",
      "\n",
      "PROMPT:\n",
      "You are a helpful bot that adds assertions to pieces of Verilog code.\n",
      "You will be given a string of code presented in the format:\n",
      "*Variables:\n",
      "...\n",
      "*Code:\n",
      "...\n",
      "Generate assertions based on the following criteria:\n",
      "1) Assert that the function can take in all inputs necessary to complete the process\n",
      "2) Assert that all outputs are of the proper sizes.\n",
      "\n",
      "Your response should ONLY be a list of assertions in the format:\n",
      "[line_number, timing, subject_variable, condition_type, target, reasoning]\n",
      " -line_number is an integer referencing the line after which the assertion should be inserted\n",
      " -timing is the clock cycle(s) at which the assertion is checked relative to the present cycle\n",
      " -subject_variable and target can ONLY be variables present in the code, integers, booleans, or None\n",
      " -condition_type can only be a value in this list: [==, >=, <=, !=]\n",
      " -reasoning is a short decription of why the assertion was made\n",
      "\n",
      "Here is an example of what your input will look like and what you should return:\n",
      "Example Input:\n",
      "\n",
      "*Variables:\n",
      "[a, b]\n",
      "*Code:\n",
      "1module m (\n",
      "2    input a,\n",
      "3    b\n",
      "4);\n",
      "5  a1 :\n",
      "6endmodule\n",
      "7module m (\n",
      "8    input a,\n",
      "9    b\n",
      "10);\n",
      "11  always_comb begin\n",
      "12  end\n",
      "13endmodule\n",
      "14\n",
      "Example Output:\n",
      "[5, #0, a, \"==\", b, \"checking input a and output b at ever 0th clock cycle is necessart for the code to function\"]\n",
      "\n",
      "Which would be the same as:\n",
      "module m (\n",
      "    input a,\n",
      "    b\n",
      ");\n",
      "  a1 :\n",
      "  assert #0 (a == b);\n",
      "endmodule\n",
      "module m (\n",
      "    input a,\n",
      "    b\n",
      ");\n",
      "  always_comb begin\n",
      "    a1 : assert #0 (a == b);\n",
      "  end\n",
      "endmodule\n",
      "\n",
      "\n",
      "Here is the actual input you should provide assertions for:\n",
      "*Variables:\n",
      "['cnt']\n",
      "*Code:\n",
      "\n",
      "1module top (\n",
      "2  input clk, rst,\n",
      "3  output reg [3:0] cnt\n",
      "4);\n",
      "5  initial cnt = 0;\n",
      "6\n",
      "7  always @(posedge clk) begin\n",
      "8    if (rst)\n",
      "9      cnt <= 0;\n",
      "10    else\n",
      "11      cnt <= cnt + 4'd 1;\n",
      "12  end\n",
      "13\n",
      "14  always @(posedge clk) begin\n",
      "15    assume (cnt != 10);\n",
      "16  end\n",
      "17endmodule\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "ind = 1\n",
    "print(\"Showing Data for content_len sorted data Ind\"+str(ind))\n",
    "print(\"\\nExtracted Assertion:\")\n",
    "print(vdf.iloc[ind][\"assertions\"])\n",
    "\n",
    "print(\"\\nVariables:\")\n",
    "print(vdf.iloc[ind][\"variables\"])\n",
    "\n",
    "print(\"\\nGPT Response:\")\n",
    "print(vdf.iloc[ind][\"gpt\"])\n",
    "\n",
    "print(\"\\nCode:\")\n",
    "print(vdf.iloc[ind][\"content\"])  # unasserted\n",
    "\n",
    "\n",
    "print(\"\\nPROMPT:\")\n",
    "print(vdf.iloc[ind][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927da6",
   "metadata": {},
   "source": [
    "## Step 3) Parse & Evaluate GPT's Response\n",
    "\n",
    "### Step 3.1) Restore the assertion(s) generated to code and evaluate\n",
    "> Metrics of evaluation, does it run? does it add to the code? is it ground-truth-like? human evaluator rank? gpt evaluator rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8a956fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gpt_assertions(response, code):\n",
    "    \"\"\" takes in chat gpt's response and outputs its assertions as well as a string of code with said assertions in it \"\"\"\n",
    "    asserts = []\n",
    "    parsed_code = code.split('\\n')\n",
    "    for line in response.split('\\n'):\n",
    "        line.replace('[', '').replace(']', '')\n",
    "        separated = line.split(',')\n",
    "        full_assert = separated[1:-1] # ommit reasoning\n",
    "        \n",
    "        # TODO: handle case where there are other ints in the code\n",
    "        line_num = separated[0]\n",
    "        num_size = len(str(line_num))\n",
    "        has_found = False\n",
    "        for i, line in enumerate(parsed_code):\n",
    "            if line_num in line[:num_size+1]:\n",
    "                parsed_code.insert(i+1, full_assert)\n",
    "                asserts.append(full_assert)\n",
    "                has_found = True\n",
    "                break\n",
    "        if not has_found:\n",
    "            print(\"Could not find location of\\n\", full_assert, \"\\nin\\n\", code)\n",
    "    return '\\n'.join(parsed_code), asserts\n",
    "\n",
    "example_response = tester_df.sample()\n",
    "print(example_response[\"gpt\"].iloc[0])\n",
    "temp_test = get_gpt_assertions(example_response[\"gpt\"].iloc[0], example_response[\"unasserted\"].iloc[0])\n",
    "print(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_asserted_code = []  # snippets of code greated by the response assertions from gpt\n",
    "gpt_assertions = []  # the decoded assertions themselves\n",
    "gpt_num_assertions = []  # the number of assertions gpt generated\n",
    "gpt_ratio_assertions = []   # num_gen_assertions / num_parsed_assertions\n",
    "gpt_matched_assertions = []  # assertions that roughly equal ground-truth\n",
    "gpt_matched_assertions_ratio = []  # num_matched_assertions / num_ground_truth_assertions\n",
    "\n",
    "for i, row in tester_df.iterrows():\n",
    "    new_code, asserts = get_gpt_assertions(row[\"gpt\"], row[\"Unasserted\"])\n",
    "    gpt_asserted_code.append(new_code)\n",
    "    gpt_assertions.append(asserts)\n",
    "    gpt_num_assertions.append(len(asserts))\n",
    "    gpt_ratio_assertions.append(len(asserts)/row[\"parsed_lines\"])\n",
    "    # TODO get number of matching assertions\n",
    "    matched_num = ...\n",
    "    gpt_matched_assertions.append(matched_num)\n",
    "    gpt_matched_assertions_ratio.append(matched_num/len(asserts))\n",
    "tester_df[\"gpt_asserted_code\"] = gpt_asserted_code\n",
    "tester_df[\"gpt_assertions\"] = gpt_assertions\n",
    "tester_df[\"gpt_num_assertions\"] = gpt_num_assertions\n",
    "tester_df[\"gpt_ratio_assertions\"] = gpt_ratio_assertions\n",
    "tester_df[\"gpt_matched_assertions\"] = gpt_matched_assertions\n",
    "tester_df[\"gpt_matched_assertions_ratio\"] = gpt_matched_assertions_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8562d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = df.iloc[ind][\"assertions\"][1:-1].split('], [')\n",
    "# print(tester)\n",
    "print(df.iloc[ind][\"assertions\"][1:-1])\n",
    "# def revive_assertion(my_list):\n",
    "#     my_list[1:-1]\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     for list(assertion) in row[\"assertions\"]:\n",
    "#         to_find = assertion.replace('[','').replace(']','')\n",
    "#         if to_find in row[\"gpt\"]:\n",
    "#             print(\"Found a match!\")\n",
    "#             print(assertion)\n",
    "#             print(\"found at\")\n",
    "#             print(row[\"gpt\"])\n",
    "# print(\"\\nDONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30741ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO: test word-mover's distance comparison? \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefc5cd",
   "metadata": {},
   "source": [
    "## Step 4) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae2772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
