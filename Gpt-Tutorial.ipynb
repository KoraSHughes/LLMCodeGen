{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f5728ec",
   "metadata": {},
   "source": [
    "# This is a tutorial for automatically querying chatgpt for code\n",
    "> If you need help you can reach me (the creator of this code) at khughes@nyu.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# Note: if you do not have this package please install it with your package manager of choice\n",
    "# Example: https://pypi.org/project/openai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ca976",
   "metadata": {},
   "source": [
    "## Step 1) set your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f366596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you dont have your api key you can generate one for free by following this tutorial here:\n",
    "https://gptforwork.com/help/gpt-for-docs/setup/create-openai-api-key\n",
    "\n",
    "For saftey, you can also set it up as an environmental variable via this tutorial:\n",
    "https://platform.openai.com/docs/quickstart?context=python\n",
    "\"\"\"\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf074878",
   "metadata": {},
   "source": [
    "## Step 2) Define your gpt call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba4bc278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gpt4(messages, text_only=True, this_model=\"gpt-4\"):\n",
    "    \"\"\" main function that query's chatgpt through openai's api \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=this_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    if text_only:  # main response you care about\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return response  # entire response structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395673c",
   "metadata": {},
   "source": [
    "## Step 3) Use call function in some context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6508773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: I'm a confused student, can you help me with some code?\n",
      "chat_gpt:  Of course, I'd be happy to help you with your code. Could you please provide me with more details about the specific problem or issue you're facing? \n",
      "\n",
      "user: I'm trying to make a bot to automatically query chatgpt\n",
      "chat_gpt:  In order to create a bot that interacts with the ChatGPT API, you'll have to use some sort of back-end language. Let's assume we're using Python. You would first need to install the OpenAI GPT-3 API using pip:\n",
      "\n",
      "```bash\n",
      "pip install openai\n",
      "```\n",
      "\n",
      "Then you could use the following Python code to make your query:\n",
      "\n",
      "```python\n",
      "import openai\n",
      "\n",
      "openai.api_key = 'your-api-key'\n",
      "\n",
      "response = openai.ChatCompletion.create(\n",
      "  model=\"gpt-3.5-turbo\",\n",
      "  messages=[\n",
      "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
      "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
      "    ]\n",
      ")\n",
      "\n",
      "print(response['choices'][0]['message']['content'])\n",
      "```\n",
      "\n",
      "Note that you need to replace `'your-api-key'` with your own API key.\n",
      "\n",
      "This is a simple example of initiating a conversation with the model, by playing two roles: your chatbot (the system) and the user. When you call the OpenAI API, this would return a response from the GPT-3 model to your user query. In this case, the question \"Who won the world series in 2020?\" is asked.\n",
      "\n",
      "Please remember when using this API: always review the AI's response and make sure it's appropriate. It's important to handle the data that is returned appropriately and apply any necessary safeguards and guidelines to ensure proper use. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# context 1: you just wana take input 1 by 1\n",
    "def chat_with_gpt(previous_hist=[]):\n",
    "    \"\"\" continuous conversation with chatgpt given user input \"\"\"\n",
    "    message_hist = []  # init\n",
    "    if len(previous_hist) == 0:\n",
    "        message_hist = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    else:\n",
    "        message_hist = previous_hist\n",
    "       \n",
    "    user_message = input(\"user: \")\n",
    "    while True:\n",
    "        try:\n",
    "            if user_message == \"exit\":\n",
    "                return message_hist\n",
    "            elif user_message[0] == \"\\\\\":  # add context to chat gpt with a backslash\n",
    "                message_hist.append({\"role\": \"system\", \"content\": user_message})\n",
    "                print(\"chat_gpt: \", user_message, '\\n')\n",
    "            else:\n",
    "                message_hist.append({\"role\": \"user\", \"content\": user_message})\n",
    "                response = run_gpt4(message_hist)\n",
    "                print(\"chat_gpt: \", response, '\\n')\n",
    "                message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "        except:  # Note: sometimes it will crash cuz the api is inconsistent, just try again\n",
    "            print(\"    ~encountered api error, retrying...\")\n",
    "        user_message = input(\"user: \")\n",
    "\n",
    "print(\"\\n\\n\", chat_with_gpt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a16b8bf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me a piece of python code that returns even numbers from 1 to i please. \n",
      " Sure, here's a simple Python function that will return a list of even numbers from 1 to i:\n",
      "\n",
      "```python\n",
      "def even_numbers(i):\n",
      "    return [num for num in range(1, i + 1) if num % 2 == 0]\n",
      "```\n",
      "\n",
      "To use the function, just call it with the number i you want:\n",
      "```python\n",
      "even_numbers(10)\n",
      "```\n",
      "\n",
      "This will return a list of even numbers from 1 to 10.\n",
      "\n",
      "\n",
      "give me a piece of python code that returns n numbers in the fibbonacci sequence please. \n",
      " Sure, here is a simple Python function to generate 'n' numbers in the Fibonacci sequence:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\n",
      "print(fibonacci(10))  # it will print: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "```\n",
      "\n",
      "The `fibonacci` function begins with a list containing the first two numbers of the Fibonacci sequence. It then enters a loop, which continues until the length of `fib_sequence` equals `n`. In each cycle of the loop, it appends the sum of the last two numbers of `fib_sequence` to `fib_sequence`. It finally returns the first `n` numbers from the sequence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# context 2: you want to 1shot a query for automation\n",
    "def single_query(input_prompt, directive=\"You are a helpful bot that assists students with their code.\", verbose=False):\n",
    "    \"\"\" ask a single query to chat gpt given an input directive \n",
    "    Note: feel free to change the directive\n",
    "    \"\"\"\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]\n",
    "    response = run_gpt4(message_hist)\n",
    "    if verbose:\n",
    "        print(\"chat_gpt: \", response, '\\n')\n",
    "    message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "\n",
    "\n",
    "examples = [\"give me a piece of python code that returns even numbers from 1 to i please.\",\n",
    "            \"give me a piece of python code that returns n numbers in the fibbonacci sequence please.\"]\n",
    "answers = [single_query(question, '') for question in examples]  # running queries\n",
    "\n",
    "for i in range(len(answers)): # showing queries\n",
    "    print(examples[i], '\\n', answers[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a3186",
   "metadata": {},
   "source": [
    "## Step 4) Parse Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d651fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Question 1 -->\n",
      "\n",
      "Code Found:\n",
      "def even_numbers(i):\n",
      "    return [num for num in range(1, i + 1) if num % 2 == 0]\n",
      "\n",
      "\n",
      "Code Found:\n",
      "even_numbers(10)\n",
      "\n",
      "\n",
      "\n",
      "For Question 2 -->\n",
      "\n",
      "Code Found:\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\n",
      "print(fibonacci(10))  # it will print: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coded_answers = []\n",
    "# for each answer, get a list of code chunks gpt returned\n",
    "for ans in answers:\n",
    "    print(\"For Question\", (len(coded_answers)+1), \"-->\")\n",
    "    this_code = []\n",
    "    for i, code_chunk in enumerate(ans.split('```')):  # pieces of code are denoted by ``` so we split\n",
    "        if i%2 == 1:  # every other chunk is a piece of code in this case\n",
    "            this_code.append(code_chunk[7:])  # Note: code declarations also have 'python\\n' denoting the language, since we dont need this, we omit the first 7 chars\n",
    "            print(\"\\nCode Found:\")\n",
    "            print(code_chunk[7:])\n",
    "    print('\\n')\n",
    "    coded_answers.append(this_code)\n",
    "\n",
    "# can do further cleaning like deleting blank lines or comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16804376",
   "metadata": {},
   "source": [
    "## Step 4: Run Parsed Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a5356b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing Answer #1 code...\n",
      "\n",
      "Executing Answer #2 code...\n",
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
     ]
    }
   ],
   "source": [
    "for i, ans in enumerate(coded_answers):\n",
    "    print(\"\\nExecuting Answer #\"+str(i+1), \"code...\")\n",
    "    exec('\\n'.join(ans))  # join code blocks to execute them all at once\n",
    "# Note: exec() is python specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d6805",
   "metadata": {},
   "source": [
    "> Food for thought; how can we properly evaluate these? what exceptions should we handle? how does the coding language affect the output? what other contexts can this be useful for?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
