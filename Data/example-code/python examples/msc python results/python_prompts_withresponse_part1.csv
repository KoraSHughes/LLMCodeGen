repo_name,content,unasserted,assertions,asserted_lines,parsed_lines,arr,atl,variables,num_vars,prompt,prompt_len,gpt
lukas-hetzenecker/home-assistant,"""""""The tests for the Pilight sensor platform.""""""
import logging

import pytest

from homeassistant.components import pilight
import homeassistant.components.sensor as sensor
from homeassistant.setup import async_setup_component

from tests.common import assert_setup_component, mock_component


@pytest.fixture(autouse=True)
def setup_comp(hass):
    """"""Initialize components.""""""
    mock_component(hass, ""pilight"")


def fire_pilight_message(hass, protocol, data):
    """"""Fire the fake Pilight message.""""""
    message = {pilight.CONF_PROTOCOL: protocol}
    message.update(data)

    hass.bus.async_fire(pilight.EVENT, message)


async def test_sensor_value_from_code(hass):
    """"""Test the setting of value via pilight.""""""
    with assert_setup_component(1):
        assert await async_setup_component(
            hass,
            sensor.DOMAIN,
            {
                sensor.DOMAIN: {
                    ""platform"": ""pilight"",
                    ""name"": ""test"",
                    ""variable"": ""test"",
                    ""payload"": {""protocol"": ""test-protocol""},
                    ""unit_of_measurement"": ""fav unit"",
                }
            },
        )
        await hass.async_block_till_done()

        state = hass.states.get(""sensor.test"")
        assert state.state == ""unknown""

        unit_of_measurement = state.attributes.get(""unit_of_measurement"")
        assert unit_of_measurement == ""fav unit""

        # Set value from data with correct payload
        fire_pilight_message(hass, protocol=""test-protocol"", data={""test"": 42})
        await hass.async_block_till_done()
        state = hass.states.get(""sensor.test"")
        assert state.state == ""42""


async def test_disregard_wrong_payload(hass):
    """"""Test omitting setting of value with wrong payload.""""""
    with assert_setup_component(1):
        assert await async_setup_component(
            hass,
            sensor.DOMAIN,
            {
                sensor.DOMAIN: {
                    ""platform"": ""pilight"",
                    ""name"": ""test_2"",
                    ""variable"": ""test"",
                    ""payload"": {""uuid"": ""1-2-3-4"", ""protocol"": ""test-protocol_2""},
                }
            },
        )
        await hass.async_block_till_done()

        # Try set value from data with incorrect payload
        fire_pilight_message(
            hass, protocol=""test-protocol_2"", data={""test"": ""data"", ""uuid"": ""0-0-0-0""}
        )
        await hass.async_block_till_done()
        state = hass.states.get(""sensor.test_2"")
        assert state.state == ""unknown""

        # Try set value from data with partially matched payload
        fire_pilight_message(
            hass, protocol=""wrong-protocol"", data={""test"": ""data"", ""uuid"": ""1-2-3-4""}
        )
        await hass.async_block_till_done()
        state = hass.states.get(""sensor.test_2"")
        assert state.state == ""unknown""

        # Try set value from data with fully matched payload
        fire_pilight_message(
            hass,
            protocol=""test-protocol_2"",
            data={""test"": ""data"", ""uuid"": ""1-2-3-4"", ""other_payload"": 3.141},
        )
        await hass.async_block_till_done()
        state = hass.states.get(""sensor.test_2"")
        assert state.state == ""data""


async def test_variable_missing(hass, caplog):
    """"""Check if error message when variable missing.""""""
    caplog.set_level(logging.ERROR)
    with assert_setup_component(1):
        assert await async_setup_component(
            hass,
            sensor.DOMAIN,
            {
                sensor.DOMAIN: {
                    ""platform"": ""pilight"",
                    ""name"": ""test_3"",
                    ""variable"": ""test"",
                    ""payload"": {""protocol"": ""test-protocol""},
                }
            },
        )
        await hass.async_block_till_done()

        # Create code without sensor variable
        fire_pilight_message(
            hass,
            protocol=""test-protocol"",
            data={""uuid"": ""1-2-3-4"", ""other_variable"": 3.141},
        )
        await hass.async_block_till_done()

        logs = caplog.text

        assert ""No variable test in received code"" in logs
","
1""""""The tests for the Pilight sensor platform.""""""
2import logging
3
4import pytest
5
6from homeassistant.components import pilight
7import homeassistant.components.sensor as sensor
8from homeassistant.setup import async_setup_component
9
10
11
12@pytest.fixture(autouse=True)
13def setup_comp(hass):
14    """"""Initialize components.""""""
15    mock_component(hass, ""pilight"")
16
17
18def fire_pilight_message(hass, protocol, data):
19    """"""Fire the fake Pilight message.""""""
20    message = {pilight.CONF_PROTOCOL: protocol}
21    message.update(data)
22
23    hass.bus.async_fire(pilight.EVENT, message)
24
25
26async def test_sensor_value_from_code(hass):
27    """"""Test the setting of value via pilight.""""""
28            hass,
29            sensor.DOMAIN,
30            {
31                sensor.DOMAIN: {
32                    ""platform"": ""pilight"",
33                    ""name"": ""test"",
34                    ""variable"": ""test"",
35                    ""payload"": {""protocol"": ""test-protocol""},
36                    ""unit_of_measurement"": ""fav unit"",
37                }
38            },
39        )
40        await hass.async_block_till_done()
41
42        state = hass.states.get(""sensor.test"")
43
44        unit_of_measurement = state.attributes.get(""unit_of_measurement"")
45
46        # Set value from data with correct payload
47        fire_pilight_message(hass, protocol=""test-protocol"", data={""test"": 42})
48        await hass.async_block_till_done()
49        state = hass.states.get(""sensor.test"")
50
51
52async def test_disregard_wrong_payload(hass):
53    """"""Test omitting setting of value with wrong payload.""""""
54            hass,
55            sensor.DOMAIN,
56            {
57                sensor.DOMAIN: {
58                    ""platform"": ""pilight"",
59                    ""name"": ""test_2"",
60                    ""variable"": ""test"",
61                    ""payload"": {""uuid"": ""1-2-3-4"", ""protocol"": ""test-protocol_2""},
62                }
63            },
64        )
65        await hass.async_block_till_done()
66
67        # Try set value from data with incorrect payload
68        fire_pilight_message(
69            hass, protocol=""test-protocol_2"", data={""test"": ""data"", ""uuid"": ""0-0-0-0""}
70        )
71        await hass.async_block_till_done()
72        state = hass.states.get(""sensor.test_2"")
73
74        # Try set value from data with partially matched payload
75        fire_pilight_message(
76            hass, protocol=""wrong-protocol"", data={""test"": ""data"", ""uuid"": ""1-2-3-4""}
77        )
78        await hass.async_block_till_done()
79        state = hass.states.get(""sensor.test_2"")
80
81        # Try set value from data with fully matched payload
82        fire_pilight_message(
83            hass,
84            protocol=""test-protocol_2"",
85            data={""test"": ""data"", ""uuid"": ""1-2-3-4"", ""other_payload"": 3.141},
86        )
87        await hass.async_block_till_done()
88        state = hass.states.get(""sensor.test_2"")
89
90
91async def test_variable_missing(hass, caplog):
92    """"""Check if error message when variable missing.""""""
93    caplog.set_level(logging.ERROR)
94            hass,
95            sensor.DOMAIN,
96            {
97                sensor.DOMAIN: {
98                    ""platform"": ""pilight"",
99                    ""name"": ""test_3"",
100                    ""variable"": ""test"",
101                    ""payload"": {""protocol"": ""test-protocol""},
102                }
103            },
104        )
105        await hass.async_block_till_done()
106
107        # Create code without sensor variable
108        fire_pilight_message(
109            hass,
110            protocol=""test-protocol"",
111            data={""uuid"": ""1-2-3-4"", ""other_variable"": 3.141},
112        )
113        await hass.async_block_till_done()
114
115        logs = caplog.text
116
117","[['await', 'async_setup_component('], ['state.state', '==', '""unknown""'], ['unit_of_measurement', '==', '""fav unit""'], ['state.state', '==', '""42""'], ['await', 'async_setup_component('], ['state.state', '==', '""unknown""'], ['state.state', '==', '""unknown""'], ['state.state', '==', '""data""'], ['await', 'async_setup_component(']]",14,9,0.6428571428571429,0.0021500238891543,"['hass', 'protocol', 'data', 'message', 'state', 'unit_of_measurement', 'caplog', 'logs']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'protocol', 'data', 'message', 'state', 'unit_of_measurement', 'caplog', 'logs']
*Code:

1""""""The tests for the Pilight sensor platform.""""""
2import logging
3
4import pytest
5
6from homeassistant.components import pilight
7import homeassistant.components.sensor as sensor
8from homeassistant.setup import async_setup_component
9
10
11
12@pytest.fixture(autouse=True)
13def setup_comp(hass):
14    """"""Initialize components.""""""
15    mock_component(hass, ""pilight"")
16
17
18def fire_pilight_message(hass, protocol, data):
19    """"""Fire the fake Pilight message.""""""
20    message = {pilight.CONF_PROTOCOL: protocol}
21    message.update(data)
22
23    hass.bus.async_fire(pilight.EVENT, message)
24
25
26async def test_sensor_value_from_code(hass):
27    """"""Test the setting of value via pilight.""""""
28            hass,
29            sensor.DOMAIN,
30            {
31                sensor.DOMAIN: {
32                    ""platform"": ""pilight"",
33                    ""name"": ""test"",
34                    ""variable"": ""test"",
35                    ""payload"": {""protocol"": ""test-protocol""},
36                    ""unit_of_measurement"": ""fav unit"",
37                }
38            },
39        )
40        await hass.async_block_till_done()
41
42        state = hass.states.get(""sensor.test"")
43
44        unit_of_measurement = state.attributes.get(""unit_of_measurement"")
45
46        # Set value from data with correct payload
47        fire_pilight_message(hass, protocol=""test-protocol"", data={""test"": 42})
48        await hass.async_block_till_done()
49        state = hass.states.get(""sensor.test"")
50
51
52async def test_disregard_wrong_payload(hass):
53    """"""Test omitting setting of value with wrong payload.""""""
54            hass,
55            sensor.DOMAIN,
56            {
57                sensor.DOMAIN: {
58                    ""platform"": ""pilight"",
59                    ""name"": ""test_2"",
60                    ""variable"": ""test"",
61                    ""payload"": {""uuid"": ""1-2-3-4"", ""protocol"": ""test-protocol_2""},
62                }
63            },
64        )
65        await hass.async_block_till_done()
66
67        # Try set value from data with incorrect payload
68        fire_pilight_message(
69            hass, protocol=""test-protocol_2"", data={""test"": ""data"", ""uuid"": ""0-0-0-0""}
70        )
71        await hass.async_block_till_done()
72        state = hass.states.get(""sensor.test_2"")
73
74        # Try set value from data with partially matched payload
75        fire_pilight_message(
76            hass, protocol=""wrong-protocol"", data={""test"": ""data"", ""uuid"": ""1-2-3-4""}
77        )
78        await hass.async_block_till_done()
79        state = hass.states.get(""sensor.test_2"")
80
81        # Try set value from data with fully matched payload
82        fire_pilight_message(
83            hass,
84            protocol=""test-protocol_2"",
85            data={""test"": ""data"", ""uuid"": ""1-2-3-4"", ""other_payload"": 3.141},
86        )
87        await hass.async_block_till_done()
88        state = hass.states.get(""sensor.test_2"")
89
90
91async def test_variable_missing(hass, caplog):
92    """"""Check if error message when variable missing.""""""
93    caplog.set_level(logging.ERROR)
94            hass,
95            sensor.DOMAIN,
96            {
97                sensor.DOMAIN: {
98                    ""platform"": ""pilight"",
99                    ""name"": ""test_3"",
100                    ""variable"": ""test"",
101                    ""payload"": {""protocol"": ""test-protocol""},
102                }
103            },
104        )
105        await hass.async_block_till_done()
106
107        # Create code without sensor variable
108        fire_pilight_message(
109            hass,
110            protocol=""test-protocol"",
111            data={""uuid"": ""1-2-3-4"", ""other_variable"": 3.141},
112        )
113        await hass.async_block_till_done()
114
115        logs = caplog.text
116
117",5295,"[[13, ""hass"", '!=', None, ""The 'hass' object should be initialized""],
 [18, ""hass"", '!=', None, ""The 'hass' object should be initialized""],
 [18, ""protocol"",'!=', None, ""'protocol' should not be None in order to send Pilight message""],
 [18, ""data"",'!=', None, ""'data' should not be filled with proper data in order to send Pilight message""],
 [26, ""hass"", '!=', None, ""The 'hass' object should be initialized""],
 [52, ""hass"",'!=', None, ""'hass' should be initialized to perform the test""],
 [91, ""hass"",'!=', None, ""'hass' should be initialized to perform the test""],
 [91, ""caplog"",'!=', None, ""'caplog' should be initialized to perform the logging""]]"
daveinnyc/various,"'''
  NOTE: The answer to this selenium question required examination of CSS 
  that was referenced by an element on the rendered page.
'''  
  
import re

from selenium import webdriver
from selenium.common.exceptions import NoSuchElementException        
from selenium.webdriver.common.keys import Keys

BASE_URL = ""https://testCompany.com"" 
LOGO_URL = ""https://cdn.testCompany.com/static/1DBa8k/images/frontend/onboarding/testCompany-small-orange-logo.png""

regex_parens = re.compile('\((.*?)\)')

def get_firefox_browser():
    driver = webdriver.Firefox()
    driver.set_window_size(1200,900)

    return driver


def value_in_parens(string_with_parens):
    # Returns an unquoted inner value
    m = re.search(regex_parens, string_with_parens)
    inner_string = m.group(1)
    inner_string = inner_string.strip('""')
    inner_string = inner_string.strip(""'"")

    return inner_string


def test_check_for_logo(driver):
    try:
        css_background = browser.find_element_by_css_selector(""div.header__logo"").value_of_css_property(""background-image"")
        css_background = value_in_parens(css_background)
    except NoSuchElementException:
        return False

    return css_background 


browser = get_firefox_browser()
browser.get(BASE_URL)

assert test_check_for_logo(browser) == LOGO_URL

browser.close()
print(""DONE"")
","
1'''
2  NOTE: The answer to this selenium question required examination of CSS 
3  that was referenced by an element on the rendered page.
4'''  
5  
6import re
7
8from selenium import webdriver
9from selenium.common.exceptions import NoSuchElementException        
10from selenium.webdriver.common.keys import Keys
11
12BASE_URL = ""https://testCompany.com"" 
13LOGO_URL = ""https://cdn.testCompany.com/static/1DBa8k/images/frontend/onboarding/testCompany-small-orange-logo.png""
14
15regex_parens = re.compile('\((.*?)\)')
16
17def get_firefox_browser():
18    driver = webdriver.Firefox()
19    driver.set_window_size(1200,900)
20
21    return driver
22
23
24def value_in_parens(string_with_parens):
25    # Returns an unquoted inner value
26    m = re.search(regex_parens, string_with_parens)
27    inner_string = m.group(1)
28    inner_string = inner_string.strip('""')
29    inner_string = inner_string.strip(""'"")
30
31    return inner_string
32
33
34def test_check_for_logo(driver):
35    try:
36        css_background = browser.find_element_by_css_selector(""div.header__logo"").value_of_css_property(""background-image"")
37        css_background = value_in_parens(css_background)
38    except NoSuchElementException:
39        return False
40
41    return css_background 
42
43
44browser = get_firefox_browser()
45browser.get(BASE_URL)
46
47
48browser.close()
49print(""DONE"")
50","[['test_check_for_logo(browser)', '==', 'LOGO_URL']]",1,1,1.0,0.0007485029940119,"['BASE_URL', 'LOGO_URL', 'regex_parens', 'driver', 'string_with_parens', 'm', 'inner_string', 'css_background', 'browser']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['BASE_URL', 'LOGO_URL', 'regex_parens', 'driver', 'string_with_parens', 'm', 'inner_string', 'css_background', 'browser']
*Code:

1'''
2  NOTE: The answer to this selenium question required examination of CSS 
3  that was referenced by an element on the rendered page.
4'''  
5  
6import re
7
8from selenium import webdriver
9from selenium.common.exceptions import NoSuchElementException        
10from selenium.webdriver.common.keys import Keys
11
12BASE_URL = ""https://testCompany.com"" 
13LOGO_URL = ""https://cdn.testCompany.com/static/1DBa8k/images/frontend/onboarding/testCompany-small-orange-logo.png""
14
15regex_parens = re.compile('\((.*?)\)')
16
17def get_firefox_browser():
18    driver = webdriver.Firefox()
19    driver.set_window_size(1200,900)
20
21    return driver
22
23
24def value_in_parens(string_with_parens):
25    # Returns an unquoted inner value
26    m = re.search(regex_parens, string_with_parens)
27    inner_string = m.group(1)
28    inner_string = inner_string.strip('""')
29    inner_string = inner_string.strip(""'"")
30
31    return inner_string
32
33
34def test_check_for_logo(driver):
35    try:
36        css_background = browser.find_element_by_css_selector(""div.header__logo"").value_of_css_property(""background-image"")
37        css_background = value_in_parens(css_background)
38    except NoSuchElementException:
39        return False
40
41    return css_background 
42
43
44browser = get_firefox_browser()
45browser.get(BASE_URL)
46
47
48browser.close()
49print(""DONE"")
50",2882,"[[17, 'driver', '!=', None, 'the webdriver.Firefox() function should instantiate a driver'],
 [25, 'string_with_parens', '!=', None, 'a string value needs to be inputted for the function to process'],
 [27, 'm', '!=', None, 're.search should successfully find a match in string_with_parens'],
 [35, 'driver', '!=', None, 'driver should be instantiated before used in this function'],
 [37, 'css_background', '!=', None, 'css property should be found and assigned successfully'],
 [41, 'css_background', '!=', None, 'css_background should have value after being processed'],
 [44, 'browser', '!=', None, 'should be successful in getting Firefox webdriver instance']]"
kirbyfan64/shedskin,"#!/usr/bin/env python2
# I, Danny Milosavljevic, hereby place this file into the public domain.

import sys
import memory

# TODO actually the memory is separated into pages of 256 bytes each on a real C64.

# $0000-$00FF, 0-256 zero page (without $0 and $1).
# $0100-$01FF, 256-511 processor stack.
# $0200-$02FF, buffers.
# $0300-$03FF, 768-1023 IRQ vectors.
# $0400-$07FF, 1024-2047 default screen memory.
# $0800-$9FFF, 2048-40959 basic area.
# $A000-$BFFF, 40960-49151 BASIC ROM
# $C000-$CFFF, 49152-53247 upper RAM area.
# $D000-$DFFF, 53248-57343 I/O Area
# $D000-$DFFF, 53248-57343 character ROM
# $D000-$D3FF, 53248-54271 VIC II
# $D400-$D7FF, 54272-55295 SID
# $D800-$DBFF, 55296-56319 Color RAM (only 4 bits per byte)!
# $DC00-$DCFF, 56320-56575 CIA#1 inputs
# $DD00-$DDFF, 56576-56831 CIA#2 serial, NMI
# $DE00-$DEFF, 56832-57087 external device memory maps.
# $DF00-$DFFF, 57088-57343 external device memory maps.
# $E000-$FFFF, 57344-65535 kernal ROM!!!
# $FFFA-$FFFF, 65530-65535 hardware vectors.

class ROM(memory.Memory):
    def __init__(self, value, B_active = True):
        self.B_active = B_active
        self.memory = []
        for i in range(len(value)): # for some reason, in ShedSkin ""for c in value: self.memory.append(ord(c))"" doesn't work.
            c = value[i]
            v = ord(c)
            self.memory.append(v)

        #self.memory = [ord(c) for c in value]
        self.B_can_write = False # in the instance because of ShedSkin

    def read_memory(self, address, size = 1):
        if size == 1:
            return self.memory[address]
        return one_big_value(self.memory[address : address + size])

    def write_memory(self, address, value, size):
        raise NotImplementedError(""cannot write to ROM"")

minimal_overlay_address = 0xA000

def one_big_value(part):
    assert len(part) <= 4, ""mmu.one_big_value: len(part)<=4""
    f = 0
    v = 0
    for c in part:
        v = v | (c << f)
        f += 8
    return v

class MMU(memory.Memory):
    def __init__(self):
        self.overlays = {}
        self.overlay_values = []
        self.memory = 65536 * [0]

    def set_overlay(self, name, overlay):
        self.overlays[name] = overlay
        self.overlay_values = self.overlays.values()

    def read_memory(self, address, size = 1):
        value = self.xread_memory(address, size)
        #if value is None:
        #    print(""memory at address $%X broken"" % address)
        #    assert(size == 1)
        #    return 0xFF
        #assert(value is not None)
        #print(""memory at $%X is %r=$%X"" % (address, value, value))
        return value

    def read_zero_page(self, address, size = 1):
        return self.read_memory(address, size)

    def xread_memory(self, address, size = 1):
        if address >= minimal_overlay_address or address < 2:
            for range_1, controller in self.overlay_values:
                if address >= range_1[0] and address < range_1[1] and controller.B_active:
                    return controller.read_memory(address - range_1[0], size)
        if size == 1:
            return (self.memory[address])
        assert size >= 0, ""MMU.read_memory: size>=0""
        v = one_big_value(self.memory[address : address + size])
        return v

    def write_memory(self, address, value, size):
        a = address
        if address >= minimal_overlay_address or address < 2:
            for range_1, controller in self.overlay_values:
                if address >= range_1[0] and address < range_1[1] and controller.B_active and controller.B_can_write: # FIXME and hasattr(controller, ""write_memory""):
                    # WTF assert(address != 0x1FC and address != 0x1FD)
                    #print(address, range_1, controller)
                    return controller.write_memory(address - range_1[0], value, size)

        assert isinstance(value, int), ""MMU.write_memory: value is an integer""
        for i in range(size):
            self.memory[address + i] = value & 0xFF
            value >>= 8

    def map_ROM(self, name, address, value, B_active):
        assert address >= minimal_overlay_address, ""MMU.map_ROM address >= minimal_overlay_address"" # ??  or range_1[1] == 2
        ROM_1 = ROM(value, B_active)
        self.set_overlay(name, (((address, address + len(value)), ROM_1)))
        return ROM_1

    def map_IO(self, name, range_1, IO):
        assert range_1[0] >= minimal_overlay_address or range_1[1] == 2, ""MMU.map_IO""
        self.set_overlay(name, (((range_1[0], range_1[1]), IO)))

    def set_overlay_active(self, name, value):
        #print(""setting overlay %r to %r"" % (name, value))
        self.overlays[name][1].B_active = value
        #self.overlay_values = self.overlays.values()
        #if value == False:
        #    for s in range(0xD1, 0xD1 + 4):
        #        sys.stdout.write(""%02X "" % (self.read_memory(s)))


","
1#!/usr/bin/env python2
2# I, Danny Milosavljevic, hereby place this file into the public domain.
3
4import sys
5import memory
6
7# TODO actually the memory is separated into pages of 256 bytes each on a real C64.
8
9# $0000-$00FF, 0-256 zero page (without $0 and $1).
10# $0100-$01FF, 256-511 processor stack.
11# $0200-$02FF, buffers.
12# $0300-$03FF, 768-1023 IRQ vectors.
13# $0400-$07FF, 1024-2047 default screen memory.
14# $0800-$9FFF, 2048-40959 basic area.
15# $A000-$BFFF, 40960-49151 BASIC ROM
16# $C000-$CFFF, 49152-53247 upper RAM area.
17# $D000-$DFFF, 53248-57343 I/O Area
18# $D000-$DFFF, 53248-57343 character ROM
19# $D000-$D3FF, 53248-54271 VIC II
20# $D400-$D7FF, 54272-55295 SID
21# $D800-$DBFF, 55296-56319 Color RAM (only 4 bits per byte)!
22# $DC00-$DCFF, 56320-56575 CIA#1 inputs
23# $DD00-$DDFF, 56576-56831 CIA#2 serial, NMI
24# $DE00-$DEFF, 56832-57087 external device memory maps.
25# $DF00-$DFFF, 57088-57343 external device memory maps.
26# $E000-$FFFF, 57344-65535 kernal ROM!!!
27# $FFFA-$FFFF, 65530-65535 hardware vectors.
28
29class ROM(memory.Memory):
30    def __init__(self, value, B_active = True):
31        self.B_active = B_active
32        self.memory = []
33        for i in range(len(value)): # for some reason, in ShedSkin ""for c in value: self.memory.append(ord(c))"" doesn't work.
34            c = value[i]
35            v = ord(c)
36            self.memory.append(v)
37
38        #self.memory = [ord(c) for c in value]
39        self.B_can_write = False # in the instance because of ShedSkin
40
41    def read_memory(self, address, size = 1):
42        if size == 1:
43            return self.memory[address]
44        return one_big_value(self.memory[address : address + size])
45
46    def write_memory(self, address, value, size):
47        raise NotImplementedError(""cannot write to ROM"")
48
49minimal_overlay_address = 0xA000
50
51def one_big_value(part):
52    f = 0
53    v = 0
54    for c in part:
55        v = v | (c << f)
56        f += 8
57    return v
58
59class MMU(memory.Memory):
60    def __init__(self):
61        self.overlays = {}
62        self.overlay_values = []
63        self.memory = 65536 * [0]
64
65    def set_overlay(self, name, overlay):
66        self.overlays[name] = overlay
67        self.overlay_values = self.overlays.values()
68
69    def read_memory(self, address, size = 1):
70        value = self.xread_memory(address, size)
71        #if value is None:
72        #    print(""memory at address $%X broken"" % address)
73        #    return 0xFF
74        #print(""memory at $%X is %r=$%X"" % (address, value, value))
75        return value
76
77    def read_zero_page(self, address, size = 1):
78        return self.read_memory(address, size)
79
80    def xread_memory(self, address, size = 1):
81        if address >= minimal_overlay_address or address < 2:
82            for range_1, controller in self.overlay_values:
83                if address >= range_1[0] and address < range_1[1] and controller.B_active:
84                    return controller.read_memory(address - range_1[0], size)
85        if size == 1:
86            return (self.memory[address])
87        v = one_big_value(self.memory[address : address + size])
88        return v
89
90    def write_memory(self, address, value, size):
91        a = address
92        if address >= minimal_overlay_address or address < 2:
93            for range_1, controller in self.overlay_values:
94                if address >= range_1[0] and address < range_1[1] and controller.B_active and controller.B_can_write: # FIXME and hasattr(controller, ""write_memory""):
95                    #print(address, range_1, controller)
96                    return controller.write_memory(address - range_1[0], value, size)
97
98        for i in range(size):
99            self.memory[address + i] = value & 0xFF
100            value >>= 8
101
102    def map_ROM(self, name, address, value, B_active):
103        ROM_1 = ROM(value, B_active)
104        self.set_overlay(name, (((address, address + len(value)), ROM_1)))
105        return ROM_1
106
107    def map_IO(self, name, range_1, IO):
108        self.set_overlay(name, (((range_1[0], range_1[1]), IO)))
109
110    def set_overlay_active(self, name, value):
111        #print(""setting overlay %r to %r"" % (name, value))
112        self.overlays[name][1].B_active = value
113        #self.overlay_values = self.overlays.values()
114        #if value == False:
115        #    for s in range(0xD1, 0xD1 + 4):
116        #        sys.stdout.write(""%02X "" % (self.read_memory(s)))
117
118
119","[['len(part)', '<=', '4'], ['size', '>=', '0'], ['address', '!=', '0x1FD)']]",8,3,0.375,0.0006162695152013,"['value', 'B_active', 'self.B_active', 'self.memory', 'c', 'v', '#self.memory', 'self.B_can_write', 'address', 'size', 'minimal_overlay_address', 'part', 'f', 'self.overlays', 'self.overlay_values', 'name', 'overlay', 'self.overlays[name]', 'a', 'self.memory[address + i]', 'ROM_1', 'range_1', 'IO', 'self.overlays[name][1].B_active', '#self.overlay_values']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['value', 'B_active', 'self.B_active', 'self.memory', 'c', 'v', '#self.memory', 'self.B_can_write', 'address', 'size', 'minimal_overlay_address', 'part', 'f', 'self.overlays', 'self.overlay_values', 'name', 'overlay', 'self.overlays[name]', 'a', 'self.memory[address + i]', 'ROM_1', 'range_1', 'IO', 'self.overlays[name][1].B_active', '#self.overlay_values']
*Code:

1#!/usr/bin/env python2
2# I, Danny Milosavljevic, hereby place this file into the public domain.
3
4import sys
5import memory
6
7# TODO actually the memory is separated into pages of 256 bytes each on a real C64.
8
9# $0000-$00FF, 0-256 zero page (without $0 and $1).
10# $0100-$01FF, 256-511 processor stack.
11# $0200-$02FF, buffers.
12# $0300-$03FF, 768-1023 IRQ vectors.
13# $0400-$07FF, 1024-2047 default screen memory.
14# $0800-$9FFF, 2048-40959 basic area.
15# $A000-$BFFF, 40960-49151 BASIC ROM
16# $C000-$CFFF, 49152-53247 upper RAM area.
17# $D000-$DFFF, 53248-57343 I/O Area
18# $D000-$DFFF, 53248-57343 character ROM
19# $D000-$D3FF, 53248-54271 VIC II
20# $D400-$D7FF, 54272-55295 SID
21# $D800-$DBFF, 55296-56319 Color RAM (only 4 bits per byte)!
22# $DC00-$DCFF, 56320-56575 CIA#1 inputs
23# $DD00-$DDFF, 56576-56831 CIA#2 serial, NMI
24# $DE00-$DEFF, 56832-57087 external device memory maps.
25# $DF00-$DFFF, 57088-57343 external device memory maps.
26# $E000-$FFFF, 57344-65535 kernal ROM!!!
27# $FFFA-$FFFF, 65530-65535 hardware vectors.
28
29class ROM(memory.Memory):
30    def __init__(self, value, B_active = True):
31        self.B_active = B_active
32        self.memory = []
33        for i in range(len(value)): # for some reason, in ShedSkin ""for c in value: self.memory.append(ord(c))"" doesn't work.
34            c = value[i]
35            v = ord(c)
36            self.memory.append(v)
37
38        #self.memory = [ord(c) for c in value]
39        self.B_can_write = False # in the instance because of ShedSkin
40
41    def read_memory(self, address, size = 1):
42        if size == 1:
43            return self.memory[address]
44        return one_big_value(self.memory[address : address + size])
45
46    def write_memory(self, address, value, size):
47        raise NotImplementedError(""cannot write to ROM"")
48
49minimal_overlay_address = 0xA000
50
51def one_big_value(part):
52    f = 0
53    v = 0
54    for c in part:
55        v = v | (c << f)
56        f += 8
57    return v
58
59class MMU(memory.Memory):
60    def __init__(self):
61        self.overlays = {}
62        self.overlay_values = []
63        self.memory = 65536 * [0]
64
65    def set_overlay(self, name, overlay):
66        self.overlays[name] = overlay
67        self.overlay_values = self.overlays.values()
68
69    def read_memory(self, address, size = 1):
70        value = self.xread_memory(address, size)
71        #if value is None:
72        #    print(""memory at address $%X broken"" % address)
73        #    return 0xFF
74        #print(""memory at $%X is %r=$%X"" % (address, value, value))
75        return value
76
77    def read_zero_page(self, address, size = 1):
78        return self.read_memory(address, size)
79
80    def xread_memory(self, address, size = 1):
81        if address >= minimal_overlay_address or address < 2:
82            for range_1, controller in self.overlay_values:
83                if address >= range_1[0] and address < range_1[1] and controller.B_active:
84                    return controller.read_memory(address - range_1[0], size)
85        if size == 1:
86            return (self.memory[address])
87        v = one_big_value(self.memory[address : address + size])
88        return v
89
90    def write_memory(self, address, value, size):
91        a = address
92        if address >= minimal_overlay_address or address < 2:
93            for range_1, controller in self.overlay_values:
94                if address >= range_1[0] and address < range_1[1] and controller.B_active and controller.B_can_write: # FIXME and hasattr(controller, ""write_memory""):
95                    #print(address, range_1, controller)
96                    return controller.write_memory(address - range_1[0], value, size)
97
98        for i in range(size):
99            self.memory[address + i] = value & 0xFF
100            value >>= 8
101
102    def map_ROM(self, name, address, value, B_active):
103        ROM_1 = ROM(value, B_active)
104        self.set_overlay(name, (((address, address + len(value)), ROM_1)))
105        return ROM_1
106
107    def map_IO(self, name, range_1, IO):
108        self.set_overlay(name, (((range_1[0], range_1[1]), IO)))
109
110    def set_overlay_active(self, name, value):
111        #print(""setting overlay %r to %r"" % (name, value))
112        self.overlays[name][1].B_active = value
113        #self.overlay_values = self.overlays.values()
114        #if value == False:
115        #    for s in range(0xD1, 0xD1 + 4):
116        #        sys.stdout.write(""%02X "" % (self.read_memory(s)))
117
118
119",6314,"[[30, 'value', '!=', None, ""value shouldn't be None""], 
 [31, 'B_active', '==', True, ""By default, B_active should be True""], 
 [33, 'value', '!=', [], ""value shouldn't be an empty list as we are iterating over it""], 
 [41, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [41, 'size', '>=', 1, ""size should be greater than or equal to 1""], 
 [46, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [46, 'size', '>=', 1, ""size should be a non-negative integer""], 
 [51, 'part', '!=', [], ""part shouldn't be an empty list as we are iterating over it""], 
 [65, 'name', '!=', None, ""name shouldn't be None""], 
 [65, 'overlay', '!=', None, ""overlay shouldn't be None""], 
 [69, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [69, 'size', '>=', 1, ""size should be greater than or equal to 1""], 
 [77, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [77, 'size', '>=', 1, ""size should be greater than or equal to 1""], 
 [80, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [80, 'size', '>=', 1, ""size should be greater than or equal to 1""], 
 [90, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [90, 'size', '>=', 1, ""size should be a non-negative integer""], 
 [90, 'value', '!=', None, ""value shouldn't be None""], 
 [95, 'value', '!=', None, ""value shouldn't be None""], 
 [95, 'size', '>=', 1, ""size should be greater than or equal to 1""], 
 [102, 'name', '!=', None, ""name shouldn't be None""], 
 [102, 'address', '>=', 0, ""address should be a non-negative integer""], 
 [102, 'value', '!=', None, ""value shouldn't be None""], 
 [102, 'B_active', '==', True, ""By default, B_active should be True""], 
 [107, 'name', '!=', None, ""name shouldn't be None""], 
 [107, 'range_1', '!=', None, ""range_1 shouldn't be None""], 
 [107, 'IO', '!=', None, ""IO shouldn't be None""], 
 [110, 'name', '!=', None, ""name shouldn't be None""], 
 [110, 'value', '!=', None, ""value shouldn't be None""]]"
lordmauve/chopsticks,"#!/usr/bin/env python

import perf

from chopsticks.pencode import pencode, pdecode


def setup():
    return [[
        1000+i,
        str(1000+i),
        42,
        42.0,
        10121071034790721094712093712037123,
        None,
        True,
        b'qwertyuiop',
        u'qwertyuiop',
        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'],
        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'),
        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'},
        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p']),
        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121},
        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i],
        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i),
        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i},
        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i]),
        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121, 'x': i},
    ] for i in range(1000)]

runner = perf.Runner()


if __name__ == '__main__':
    v = setup()
    assert pdecode(pencode(v)) == v
    #pencode(v)
    runner.timeit(
        name='pencode',
        stmt='pencode(v)',
        globals={'v': v, 'pencode': pencode},
    )
","
1#!/usr/bin/env python
2
3import perf
4
5from chopsticks.pencode import pencode, pdecode
6
7
8def setup():
9    return [[
10        1000+i,
11        str(1000+i),
12        42,
13        42.0,
14        10121071034790721094712093712037123,
15        None,
16        True,
17        b'qwertyuiop',
18        u'qwertyuiop',
19        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'],
20        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'),
21        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'},
22        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p']),
23        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
24         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121},
25        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i],
26        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i),
27        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i},
28        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i]),
29        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
30         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121, 'x': i},
31    ] for i in range(1000)]
32
33runner = perf.Runner()
34
35
36if __name__ == '__main__':
37    v = setup()
38    #pencode(v)
39    runner.timeit(
40        name='pencode',
41        stmt='pencode(v)',
42        globals={'v': v, 'pencode': pencode},
43    )
44","[['pdecode(pencode(v))', '==', 'v']]",1,1,1.0,0.0007541478129713,"['runner', 'v']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['runner', 'v']
*Code:

1#!/usr/bin/env python
2
3import perf
4
5from chopsticks.pencode import pencode, pdecode
6
7
8def setup():
9    return [[
10        1000+i,
11        str(1000+i),
12        42,
13        42.0,
14        10121071034790721094712093712037123,
15        None,
16        True,
17        b'qwertyuiop',
18        u'qwertyuiop',
19        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'],
20        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'),
21        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'},
22        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p']),
23        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
24         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121},
25        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i],
26        ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i),
27        {'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i},
28        frozenset(['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', i]),
29        {'e': 101, 'i': 105, 'o': 111, 'q': 113, 'p': 112,
30         'r': 114, 'u': 117, 't': 116, 'w': 119, 'y': 121, 'x': i},
31    ] for i in range(1000)]
32
33runner = perf.Runner()
34
35
36if __name__ == '__main__':
37    v = setup()
38    #pencode(v)
39    runner.timeit(
40        name='pencode',
41        stmt='pencode(v)',
42        globals={'v': v, 'pencode': pencode},
43    )
44",2765,"[[8, 'None', '==', 'None', 'Setup function does not have arguments'], [37, 'v', '!=', 'None', 'v needs to be assigned a value before it can be used'], [40, 'v', '!=', 'None', 'v needs to be defined for pencode'], [40, 'pencode', '!=', 'None', 'pencode function needs to be imported or defined']]"
allenta/splunk-stomp,"import re
import xml.dom

try:
    import hashlib
except ImportError:
    import md5 as hashlib

#
# Used to parse STOMP header lines in the format ""key:value"",
#
HEADER_LINE_RE = re.compile('(?P<key>[^:]+)[:](?P<value>.*)')


def parse_headers(lines, offset=0):
    headers = {}
    for header_line in lines[offset:]:
        header_match = HEADER_LINE_RE.match(header_line)
        if header_match:
            key = header_match.group('key')
            if key not in headers:
                headers[key] = header_match.group('value')
    return headers

def parse_frame(frame):
    """"""
    Parse a STOMP frame into a (frame_type, headers, body) tuple,
    where frame_type is the frame type as a string (e.g. MESSAGE),
    headers is a map containing all header key/value pairs, and
    body is a string containing the frame's payload.
    """"""
    if frame == '\x0a':
        return ('heartbeat', {}, None)
        
    preamble_end = frame.find('\n\n')
    if preamble_end == -1:
        preamble_end = len(frame)
    preamble = frame[0:preamble_end]
    preamble_lines = preamble.split('\n')
    body = frame[preamble_end + 2:]

    # Skip any leading newlines
    first_line = 0
    while first_line < len(preamble_lines) and len(preamble_lines[first_line]) == 0:
        first_line += 1

    # Extract frame type
    frame_type = preamble_lines[first_line]

    # Put headers into a key/value map
    headers = parse_headers(preamble_lines, first_line + 1)

    if 'transformation' in headers:
        body = transform(body, headers['transformation'])

    return (frame_type, headers, body)
    
def transform(body, trans_type):
    """"""
    Perform body transformation. Currently, the only supported transformation is
    'jms-map-xml', which converts a map into python dictionary. This can be extended
    to support other transformation types.

    The body has the following format: 
    <map>
      <entry>
        <string>name</string>
        <string>Dejan</string>
      </entry>
      <entry>
        <string>city</string>
        <string>Belgrade</string>
      </entry>
    </map>

    (see http://docs.codehaus.org/display/STOMP/Stomp+v1.1+Ideas)
    
    \param body the content of a message
    
    \param trans_type the type transformation
    """"""
    if trans_type != 'jms-map-xml':
        return body

    try:
        entries = {}
        doc = xml.dom.minidom.parseString(body)
        rootElem = doc.documentElement
        for entryElem in rootElem.getElementsByTagName(""entry""):
            pair = []
            for node in entryElem.childNodes:
                if not isinstance(node, xml.dom.minidom.Element): continue
                pair.append(node.firstChild.nodeValue)
            assert len(pair) == 2
            entries[pair[0]] = pair[1]
        return entries
    except Exception:
        #
        # unable to parse message. return original
        #
        return body
    
def merge_headers(header_map_list):
    """"""
    Helper function for combining multiple header maps into one.
    """"""
    headers = {}
    for header_map in header_map_list:
        for header_key in header_map.keys():
            headers[header_key] = header_map[header_key]
    return headers
    
def calculate_heartbeats(shb, chb):
    """"""
    Given a heartbeat string from the server, and a heartbeat tuple from the client,
    calculate what the actual heartbeat settings should be.
    """"""
    (sx, sy) = shb
    (cx, cy) = chb
    x = 0
    y = 0
    if cx != 0 and sy != '0':
        x = max(cx, int(sy))
    if cy != 0 and sx != '0':
        y = max(cy, int(sx))
    return (x, y)","
1import re
2import xml.dom
3
4try:
5    import hashlib
6except ImportError:
7    import md5 as hashlib
8
9#
10# Used to parse STOMP header lines in the format ""key:value"",
11#
12HEADER_LINE_RE = re.compile('(?P<key>[^:]+)[:](?P<value>.*)')
13
14
15def parse_headers(lines, offset=0):
16    headers = {}
17    for header_line in lines[offset:]:
18        header_match = HEADER_LINE_RE.match(header_line)
19        if header_match:
20            key = header_match.group('key')
21            if key not in headers:
22                headers[key] = header_match.group('value')
23    return headers
24
25def parse_frame(frame):
26    """"""
27    Parse a STOMP frame into a (frame_type, headers, body) tuple,
28    where frame_type is the frame type as a string (e.g. MESSAGE),
29    headers is a map containing all header key/value pairs, and
30    body is a string containing the frame's payload.
31    """"""
32    if frame == '\x0a':
33        return ('heartbeat', {}, None)
34        
35    preamble_end = frame.find('\n\n')
36    if preamble_end == -1:
37        preamble_end = len(frame)
38    preamble = frame[0:preamble_end]
39    preamble_lines = preamble.split('\n')
40    body = frame[preamble_end + 2:]
41
42    # Skip any leading newlines
43    first_line = 0
44    while first_line < len(preamble_lines) and len(preamble_lines[first_line]) == 0:
45        first_line += 1
46
47    # Extract frame type
48    frame_type = preamble_lines[first_line]
49
50    # Put headers into a key/value map
51    headers = parse_headers(preamble_lines, first_line + 1)
52
53    if 'transformation' in headers:
54        body = transform(body, headers['transformation'])
55
56    return (frame_type, headers, body)
57    
58def transform(body, trans_type):
59    """"""
60    Perform body transformation. Currently, the only supported transformation is
61    'jms-map-xml', which converts a map into python dictionary. This can be extended
62    to support other transformation types.
63
64    The body has the following format: 
65    <map>
66      <entry>
67        <string>name</string>
68        <string>Dejan</string>
69      </entry>
70      <entry>
71        <string>city</string>
72        <string>Belgrade</string>
73      </entry>
74    </map>
75
76    (see http://docs.codehaus.org/display/STOMP/Stomp+v1.1+Ideas)
77    
78    \param body the content of a message
79    
80    \param trans_type the type transformation
81    """"""
82    if trans_type != 'jms-map-xml':
83        return body
84
85    try:
86        entries = {}
87        doc = xml.dom.minidom.parseString(body)
88        rootElem = doc.documentElement
89        for entryElem in rootElem.getElementsByTagName(""entry""):
90            pair = []
91            for node in entryElem.childNodes:
92                if not isinstance(node, xml.dom.minidom.Element): continue
93                pair.append(node.firstChild.nodeValue)
94            entries[pair[0]] = pair[1]
95        return entries
96    except Exception:
97        #
98        # unable to parse message. return original
99        #
100        return body
101    
102def merge_headers(header_map_list):
103    """"""
104    Helper function for combining multiple header maps into one.
105    """"""
106    headers = {}
107    for header_map in header_map_list:
108        for header_key in header_map.keys():
109            headers[header_key] = header_map[header_key]
110    return headers
111    
112def calculate_heartbeats(shb, chb):
113    """"""
114    Given a heartbeat string from the server, and a heartbeat tuple from the client,
115    calculate what the actual heartbeat settings should be.
116    """"""
117    (sx, sy) = shb
118    (cx, cy) = chb
119    x = 0
120    y = 0
121    if cx != 0 and sy != '0':
122        x = max(cx, int(sy))
123    if cy != 0 and sx != '0':
124        y = max(cy, int(sx))
125    return (x, y)","[['len(pair)', '==', '2']]",1,1,1.0,0.0002767783005812,"['HEADER_LINE_RE', 'lines', 'offset', 'headers', 'header_match', 'key', 'headers[key]', 'frame', 'preamble_end', 'preamble', 'preamble_lines', 'body', 'first_line', 'frame_type', 'trans_type', 'entries', 'doc', 'rootElem', 'pair', 'entries[pair[0]]', 'header_map_list', 'headers[header_key]', 'shb', 'chb', '(sx', 'sy)', '(cx', 'cy)', 'x', 'y']",30,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['HEADER_LINE_RE', 'lines', 'offset', 'headers', 'header_match', 'key', 'headers[key]', 'frame', 'preamble_end', 'preamble', 'preamble_lines', 'body', 'first_line', 'frame_type', 'trans_type', 'entries', 'doc', 'rootElem', 'pair', 'entries[pair[0]]', 'header_map_list', 'headers[header_key]', 'shb', 'chb', '(sx', 'sy)', '(cx', 'cy)', 'x', 'y']
*Code:

1import re
2import xml.dom
3
4try:
5    import hashlib
6except ImportError:
7    import md5 as hashlib
8
9#
10# Used to parse STOMP header lines in the format ""key:value"",
11#
12HEADER_LINE_RE = re.compile('(?P<key>[^:]+)[:](?P<value>.*)')
13
14
15def parse_headers(lines, offset=0):
16    headers = {}
17    for header_line in lines[offset:]:
18        header_match = HEADER_LINE_RE.match(header_line)
19        if header_match:
20            key = header_match.group('key')
21            if key not in headers:
22                headers[key] = header_match.group('value')
23    return headers
24
25def parse_frame(frame):
26    """"""
27    Parse a STOMP frame into a (frame_type, headers, body) tuple,
28    where frame_type is the frame type as a string (e.g. MESSAGE),
29    headers is a map containing all header key/value pairs, and
30    body is a string containing the frame's payload.
31    """"""
32    if frame == '\x0a':
33        return ('heartbeat', {}, None)
34        
35    preamble_end = frame.find('\n\n')
36    if preamble_end == -1:
37        preamble_end = len(frame)
38    preamble = frame[0:preamble_end]
39    preamble_lines = preamble.split('\n')
40    body = frame[preamble_end + 2:]
41
42    # Skip any leading newlines
43    first_line = 0
44    while first_line < len(preamble_lines) and len(preamble_lines[first_line]) == 0:
45        first_line += 1
46
47    # Extract frame type
48    frame_type = preamble_lines[first_line]
49
50    # Put headers into a key/value map
51    headers = parse_headers(preamble_lines, first_line + 1)
52
53    if 'transformation' in headers:
54        body = transform(body, headers['transformation'])
55
56    return (frame_type, headers, body)
57    
58def transform(body, trans_type):
59    """"""
60    Perform body transformation. Currently, the only supported transformation is
61    'jms-map-xml', which converts a map into python dictionary. This can be extended
62    to support other transformation types.
63
64    The body has the following format: 
65    <map>
66      <entry>
67        <string>name</string>
68        <string>Dejan</string>
69      </entry>
70      <entry>
71        <string>city</string>
72        <string>Belgrade</string>
73      </entry>
74    </map>
75
76    (see http://docs.codehaus.org/display/STOMP/Stomp+v1.1+Ideas)
77    
78    \param body the content of a message
79    
80    \param trans_type the type transformation
81    """"""
82    if trans_type != 'jms-map-xml':
83        return body
84
85    try:
86        entries = {}
87        doc = xml.dom.minidom.parseString(body)
88        rootElem = doc.documentElement
89        for entryElem in rootElem.getElementsByTagName(""entry""):
90            pair = []
91            for node in entryElem.childNodes:
92                if not isinstance(node, xml.dom.minidom.Element): continue
93                pair.append(node.firstChild.nodeValue)
94            entries[pair[0]] = pair[1]
95        return entries
96    except Exception:
97        #
98        # unable to parse message. return original
99        #
100        return body
101    
102def merge_headers(header_map_list):
103    """"""
104    Helper function for combining multiple header maps into one.
105    """"""
106    headers = {}
107    for header_map in header_map_list:
108        for header_key in header_map.keys():
109            headers[header_key] = header_map[header_key]
110    return headers
111    
112def calculate_heartbeats(shb, chb):
113    """"""
114    Given a heartbeat string from the server, and a heartbeat tuple from the client,
115    calculate what the actual heartbeat settings should be.
116    """"""
117    (sx, sy) = shb
118    (cx, cy) = chb
119    x = 0
120    y = 0
121    if cx != 0 and sy != '0':
122        x = max(cx, int(sy))
123    if cy != 0 and sx != '0':
124        y = max(cy, int(sx))
125    return (x, y)",5571,"[[15, 'lines', '!=', None, 'lines input is necessary for function'],
[15, 'lines', '>=', 0, 'offset should be a non-negative integer'],
[23, 'headers', '!=', None, 'function should return headers dictionary'],
[25, 'frame', '!=', None, 'frame input is necessary for function'],
[36, 'preamble_end', '>=', 0, 'preamble_end should be a non-negative integer'],
[39, 'preamble', '!=', None, 'preamble should not be None'],
[40, 'body', '!=', None, 'body should not be None'],
[46, 'first_line', '>=', 0, 'first_line should be a non-negative integer'],
[46, 'first_line', '<', 'len(preamble_lines)', 'first_line index must be within range of preamble_lines'],
[48, 'frame_type', '!=', None, 'frame_type should not be None'],
[55, 'body', '!=', None, 'body should not be None after transformation'],
[58, 'body', '!=', None, 'body input is necessary for function'],
[58, 'trans_type', '!=', None, 'trans_type is necessary for function'],
[82, 'body', '!=', None, 'body should not be None after transformation'],
[95, 'entries', '!=', None, 'entries dictionary should be returned'],
[102, 'header_map_list', '!=', None, 'header_map_list is necessary for function'],
[109, 'headers', '!=', None, 'function should return headers dictionary'],
[112, 'shb', '!=', None, 'shb input is necessary for function'],
[112, 'chb', '!=', None, 'chb input is necessary for function'],
[123, 'x', '>=', 0, 'x should be a non-negative integer'],
[124, 'y', '>=', 0, 'y should be a non-negative integer']]"
jimberlage/servo,""""""" log machine-parseable test session result information in a plain
text file.
""""""
from __future__ import absolute_import, division, print_function

import py
import os


def pytest_addoption(parser):
    group = parser.getgroup(""terminal reporting"", ""resultlog plugin options"")
    group.addoption(
        ""--resultlog"",
        ""--result-log"",
        action=""store"",
        metavar=""path"",
        default=None,
        help=""DEPRECATED path for machine-readable result log."",
    )


def pytest_configure(config):
    resultlog = config.option.resultlog
    # prevent opening resultlog on slave nodes (xdist)
    if resultlog and not hasattr(config, ""slaveinput""):
        dirname = os.path.dirname(os.path.abspath(resultlog))
        if not os.path.isdir(dirname):
            os.makedirs(dirname)
        logfile = open(resultlog, ""w"", 1)  # line buffered
        config._resultlog = ResultLog(config, logfile)
        config.pluginmanager.register(config._resultlog)

        from _pytest.deprecated import RESULT_LOG

        config.warn(""C1"", RESULT_LOG)


def pytest_unconfigure(config):
    resultlog = getattr(config, ""_resultlog"", None)
    if resultlog:
        resultlog.logfile.close()
        del config._resultlog
        config.pluginmanager.unregister(resultlog)


def generic_path(item):
    chain = item.listchain()
    gpath = [chain[0].name]
    fspath = chain[0].fspath
    fspart = False
    for node in chain[1:]:
        newfspath = node.fspath
        if newfspath == fspath:
            if fspart:
                gpath.append("":"")
                fspart = False
            else:
                gpath.append(""."")
        else:
            gpath.append(""/"")
            fspart = True
        name = node.name
        if name[0] in ""(["":
            gpath.pop()
        gpath.append(name)
        fspath = newfspath
    return """".join(gpath)


class ResultLog(object):

    def __init__(self, config, logfile):
        self.config = config
        self.logfile = logfile  # preferably line buffered

    def write_log_entry(self, testpath, lettercode, longrepr):
        print(""%s %s"" % (lettercode, testpath), file=self.logfile)
        for line in longrepr.splitlines():
            print("" %s"" % line, file=self.logfile)

    def log_outcome(self, report, lettercode, longrepr):
        testpath = getattr(report, ""nodeid"", None)
        if testpath is None:
            testpath = report.fspath
        self.write_log_entry(testpath, lettercode, longrepr)

    def pytest_runtest_logreport(self, report):
        if report.when != ""call"" and report.passed:
            return
        res = self.config.hook.pytest_report_teststatus(report=report)
        code = res[1]
        if code == ""x"":
            longrepr = str(report.longrepr)
        elif code == ""X"":
            longrepr = """"
        elif report.passed:
            longrepr = """"
        elif report.failed:
            longrepr = str(report.longrepr)
        elif report.skipped:
            longrepr = str(report.longrepr[2])
        self.log_outcome(report, code, longrepr)

    def pytest_collectreport(self, report):
        if not report.passed:
            if report.failed:
                code = ""F""
                longrepr = str(report.longrepr)
            else:
                assert report.skipped
                code = ""S""
                longrepr = ""%s:%d: %s"" % report.longrepr
            self.log_outcome(report, code, longrepr)

    def pytest_internalerror(self, excrepr):
        reprcrash = getattr(excrepr, ""reprcrash"", None)
        path = getattr(reprcrash, ""path"", None)
        if path is None:
            path = ""cwd:%s"" % py.path.local()
        self.write_log_entry(path, ""!"", str(excrepr))
","
1"""""" log machine-parseable test session result information in a plain
2text file.
3""""""
4from __future__ import absolute_import, division, print_function
5
6import py
7import os
8
9
10def pytest_addoption(parser):
11    group = parser.getgroup(""terminal reporting"", ""resultlog plugin options"")
12    group.addoption(
13        ""--resultlog"",
14        ""--result-log"",
15        action=""store"",
16        metavar=""path"",
17        default=None,
18        help=""DEPRECATED path for machine-readable result log."",
19    )
20
21
22def pytest_configure(config):
23    resultlog = config.option.resultlog
24    # prevent opening resultlog on slave nodes (xdist)
25    if resultlog and not hasattr(config, ""slaveinput""):
26        dirname = os.path.dirname(os.path.abspath(resultlog))
27        if not os.path.isdir(dirname):
28            os.makedirs(dirname)
29        logfile = open(resultlog, ""w"", 1)  # line buffered
30        config._resultlog = ResultLog(config, logfile)
31        config.pluginmanager.register(config._resultlog)
32
33        from _pytest.deprecated import RESULT_LOG
34
35        config.warn(""C1"", RESULT_LOG)
36
37
38def pytest_unconfigure(config):
39    resultlog = getattr(config, ""_resultlog"", None)
40    if resultlog:
41        resultlog.logfile.close()
42        del config._resultlog
43        config.pluginmanager.unregister(resultlog)
44
45
46def generic_path(item):
47    chain = item.listchain()
48    gpath = [chain[0].name]
49    fspath = chain[0].fspath
50    fspart = False
51    for node in chain[1:]:
52        newfspath = node.fspath
53        if newfspath == fspath:
54            if fspart:
55                gpath.append("":"")
56                fspart = False
57            else:
58                gpath.append(""."")
59        else:
60            gpath.append(""/"")
61            fspart = True
62        name = node.name
63        if name[0] in ""(["":
64            gpath.pop()
65        gpath.append(name)
66        fspath = newfspath
67    return """".join(gpath)
68
69
70class ResultLog(object):
71
72    def __init__(self, config, logfile):
73        self.config = config
74        self.logfile = logfile  # preferably line buffered
75
76    def write_log_entry(self, testpath, lettercode, longrepr):
77        print(""%s %s"" % (lettercode, testpath), file=self.logfile)
78        for line in longrepr.splitlines():
79            print("" %s"" % line, file=self.logfile)
80
81    def log_outcome(self, report, lettercode, longrepr):
82        testpath = getattr(report, ""nodeid"", None)
83        if testpath is None:
84            testpath = report.fspath
85        self.write_log_entry(testpath, lettercode, longrepr)
86
87    def pytest_runtest_logreport(self, report):
88        if report.when != ""call"" and report.passed:
89            return
90        res = self.config.hook.pytest_report_teststatus(report=report)
91        code = res[1]
92        if code == ""x"":
93            longrepr = str(report.longrepr)
94        elif code == ""X"":
95            longrepr = """"
96        elif report.passed:
97            longrepr = """"
98        elif report.failed:
99            longrepr = str(report.longrepr)
100        elif report.skipped:
101            longrepr = str(report.longrepr[2])
102        self.log_outcome(report, code, longrepr)
103
104    def pytest_collectreport(self, report):
105        if not report.passed:
106            if report.failed:
107                code = ""F""
108                longrepr = str(report.longrepr)
109            else:
110                code = ""S""
111                longrepr = ""%s:%d: %s"" % report.longrepr
112            self.log_outcome(report, code, longrepr)
113
114    def pytest_internalerror(self, excrepr):
115        reprcrash = getattr(excrepr, ""reprcrash"", None)
116        path = getattr(reprcrash, ""path"", None)
117        if path is None:
118            path = ""cwd:%s"" % py.path.local()
119        self.write_log_entry(path, ""!"", str(excrepr))
120","[['report.skipped', '==', 'True']]",1,1,1.0,0.0002684563758389,"['parser', 'group', 'config', 'resultlog', 'dirname', 'logfile', 'config._resultlog', 'item', 'chain', 'gpath', 'fspath', 'fspart', 'newfspath', 'name', 'self.config', 'self.logfile', 'testpath', 'lettercode', 'longrepr', 'report', 'res', 'code', 'excrepr', 'reprcrash', 'path']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['parser', 'group', 'config', 'resultlog', 'dirname', 'logfile', 'config._resultlog', 'item', 'chain', 'gpath', 'fspath', 'fspart', 'newfspath', 'name', 'self.config', 'self.logfile', 'testpath', 'lettercode', 'longrepr', 'report', 'res', 'code', 'excrepr', 'reprcrash', 'path']
*Code:

1"""""" log machine-parseable test session result information in a plain
2text file.
3""""""
4from __future__ import absolute_import, division, print_function
5
6import py
7import os
8
9
10def pytest_addoption(parser):
11    group = parser.getgroup(""terminal reporting"", ""resultlog plugin options"")
12    group.addoption(
13        ""--resultlog"",
14        ""--result-log"",
15        action=""store"",
16        metavar=""path"",
17        default=None,
18        help=""DEPRECATED path for machine-readable result log."",
19    )
20
21
22def pytest_configure(config):
23    resultlog = config.option.resultlog
24    # prevent opening resultlog on slave nodes (xdist)
25    if resultlog and not hasattr(config, ""slaveinput""):
26        dirname = os.path.dirname(os.path.abspath(resultlog))
27        if not os.path.isdir(dirname):
28            os.makedirs(dirname)
29        logfile = open(resultlog, ""w"", 1)  # line buffered
30        config._resultlog = ResultLog(config, logfile)
31        config.pluginmanager.register(config._resultlog)
32
33        from _pytest.deprecated import RESULT_LOG
34
35        config.warn(""C1"", RESULT_LOG)
36
37
38def pytest_unconfigure(config):
39    resultlog = getattr(config, ""_resultlog"", None)
40    if resultlog:
41        resultlog.logfile.close()
42        del config._resultlog
43        config.pluginmanager.unregister(resultlog)
44
45
46def generic_path(item):
47    chain = item.listchain()
48    gpath = [chain[0].name]
49    fspath = chain[0].fspath
50    fspart = False
51    for node in chain[1:]:
52        newfspath = node.fspath
53        if newfspath == fspath:
54            if fspart:
55                gpath.append("":"")
56                fspart = False
57            else:
58                gpath.append(""."")
59        else:
60            gpath.append(""/"")
61            fspart = True
62        name = node.name
63        if name[0] in ""(["":
64            gpath.pop()
65        gpath.append(name)
66        fspath = newfspath
67    return """".join(gpath)
68
69
70class ResultLog(object):
71
72    def __init__(self, config, logfile):
73        self.config = config
74        self.logfile = logfile  # preferably line buffered
75
76    def write_log_entry(self, testpath, lettercode, longrepr):
77        print(""%s %s"" % (lettercode, testpath), file=self.logfile)
78        for line in longrepr.splitlines():
79            print("" %s"" % line, file=self.logfile)
80
81    def log_outcome(self, report, lettercode, longrepr):
82        testpath = getattr(report, ""nodeid"", None)
83        if testpath is None:
84            testpath = report.fspath
85        self.write_log_entry(testpath, lettercode, longrepr)
86
87    def pytest_runtest_logreport(self, report):
88        if report.when != ""call"" and report.passed:
89            return
90        res = self.config.hook.pytest_report_teststatus(report=report)
91        code = res[1]
92        if code == ""x"":
93            longrepr = str(report.longrepr)
94        elif code == ""X"":
95            longrepr = """"
96        elif report.passed:
97            longrepr = """"
98        elif report.failed:
99            longrepr = str(report.longrepr)
100        elif report.skipped:
101            longrepr = str(report.longrepr[2])
102        self.log_outcome(report, code, longrepr)
103
104    def pytest_collectreport(self, report):
105        if not report.passed:
106            if report.failed:
107                code = ""F""
108                longrepr = str(report.longrepr)
109            else:
110                code = ""S""
111                longrepr = ""%s:%d: %s"" % report.longrepr
112            self.log_outcome(report, code, longrepr)
113
114    def pytest_internalerror(self, excrepr):
115        reprcrash = getattr(excrepr, ""reprcrash"", None)
116        path = getattr(reprcrash, ""path"", None)
117        if path is None:
118            path = ""cwd:%s"" % py.path.local()
119        self.write_log_entry(path, ""!"", str(excrepr))
120",5598,"[[22, 'config', '!=', None, 'config should not be None'], 
 [22, 'resultlog', '!=', None, 'resultlog should not be None'], 
 [26, 'dirname', '!=', None, 'dirname should not be None'], 
 [29, 'logfile', '!=', None, 'logfile should not be None'], 
 [33, 'config', '!=', None, 'config should not be None'], 
 [38, 'config', '!=', None, 'config should not be None'], 
 [38, 'resultlog', '!=', None, 'resultlog should not be None'], 
 [46, 'item', '!=', None, 'item should not be None'], 
 [47, 'chain', '!=', None, 'chain should not be None'], 
 [48, 'gpath', '!=', None, 'gpath should not be None'], 
 [50, 'fspart', '==', False, 'fspart is initially False'],
 [52, 'newfspath', '!=', None, 'newfspath should not be None'],
 [67, 'gpath', '!=', '', 'gpath should not be empty'],
 [72, 'config', '!=', None, 'config should not be None'], 
 [72, 'logfile', '!=', None, 'logfile should not be None'], 
 [81, 'report', '!=', None, 'report should not be None'], 
 [88, 'report.when', '!=', None, 'report.when attribute should not be None'], 
 [90, 'res', '!=', None, 'res should not be None'], 
 [90, 'report', '!=', None, 'report should not be None'], 
 [96, 'report.passed', '!=', None, 'report.passed should not be None'],
 [104, 'report.passed', '!=', None, 'report.passed should not be None'],
 [113, 'excrepr', '!=', None, 'excrepr should not be None']]"
shiquanwang/pylearn2,"__author__ = ""Ian Goodfellow""

import logging
import numpy as np

from pylearn2.utils import serial


logger = logging.getLogger(__name__)


class Simulator(object):
    """"""
    .. todo::

        WRITEME : parameter list
    """"""
    def __init__(self, agent, environment, algorithm, save_path):
        self.__dict__.update(locals())
        del self.self

    def main_loop(self):
        self.algorithm.setup(agent=self.agent, environment=self.environment)
        i = 0
        for param in self.agent.get_params():
            assert not np.any(np.isnan(param.get_value())), (i, param.name)
            assert not np.any(np.isinf(param.get_value())), (i, param.name)
        while True:
            rval = self.algorithm.train()
            assert rval is None
            i += 1
            for param in self.agent.get_params():
                assert not np.any(np.isnan(param.get_value())), (i, param.name)
                assert not np.any(np.isinf(param.get_value())), (i, param.name)
            if i % 1000 == 0:
                serial.save(self.save_path, self.agent)
                logger.info('saved!')
","
1__author__ = ""Ian Goodfellow""
2
3import logging
4import numpy as np
5
6from pylearn2.utils import serial
7
8
9logger = logging.getLogger(__name__)
10
11
12class Simulator(object):
13    """"""
14    .. todo::
15
16        WRITEME : parameter list
17    """"""
18    def __init__(self, agent, environment, algorithm, save_path):
19        self.__dict__.update(locals())
20        del self.self
21
22    def main_loop(self):
23        self.algorithm.setup(agent=self.agent, environment=self.environment)
24        i = 0
25        for param in self.agent.get_params():
26        while True:
27            rval = self.algorithm.train()
28            i += 1
29            for param in self.agent.get_params():
30            if i % 1000 == 0:
31                serial.save(self.save_path, self.agent)
32                logger.info('saved!')
33","[['np.any(np.isnan(param.get_value()))', '==', 'False'], ['np.any(np.isinf(param.get_value()))', '==', 'False'], ['rval', '==', 'None'], ['np.any(np.isnan(param.get_value()))', '==', 'False'], ['np.any(np.isinf(param.get_value()))', '==', 'False']]",5,5,1.0,0.0044682752457551,"['__author__', 'logger', 'agent', 'environment', 'algorithm', 'save_path', 'i', 'rval']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'logger', 'agent', 'environment', 'algorithm', 'save_path', 'i', 'rval']
*Code:

1__author__ = ""Ian Goodfellow""
2
3import logging
4import numpy as np
5
6from pylearn2.utils import serial
7
8
9logger = logging.getLogger(__name__)
10
11
12class Simulator(object):
13    """"""
14    .. todo::
15
16        WRITEME : parameter list
17    """"""
18    def __init__(self, agent, environment, algorithm, save_path):
19        self.__dict__.update(locals())
20        del self.self
21
22    def main_loop(self):
23        self.algorithm.setup(agent=self.agent, environment=self.environment)
24        i = 0
25        for param in self.agent.get_params():
26        while True:
27            rval = self.algorithm.train()
28            i += 1
29            for param in self.agent.get_params():
30            if i % 1000 == 0:
31                serial.save(self.save_path, self.agent)
32                logger.info('saved!')
33",2300,"[[18, 'agent', '!=', None, ""Agent can't be None, it is required for the simulator""],
[18, 'environment', '!=', None, ""Environment can't be None, it is required for the simulator""],
[18, 'algorithm', '!=', None, ""Algorithm can't be None, it is required for the simulator""],
[18, 'save_path', '!=', None, ""Save path can't be None, it helps to save the state of the agent periodically""],
[25, 'param', '!=', None, ""If agent.get_params() returns None, it will cause a failure in the following iteration""],
[27, 'rval', '!=', None, ""algorithm.train should not return None, it will affect the main loop""]]"
qingying5810/thefuck,"import pytest
from subprocess import PIPE
from mock import Mock
from thefuck import main
from tests.utils import Command


class TestGetCommand(object):
    @pytest.fixture(autouse=True)
    def Popen(self, monkeypatch):
        Popen = Mock()
        Popen.return_value.stdout.read.return_value = b'stdout'
        Popen.return_value.stderr.read.return_value = b'stderr'
        monkeypatch.setattr('thefuck.main.Popen', Popen)
        return Popen

    @pytest.fixture(autouse=True)
    def prepare(self, monkeypatch):
        monkeypatch.setattr('thefuck.main.os.environ', {})
        monkeypatch.setattr('thefuck.main.wait_output', lambda *_: True)

    @pytest.fixture(autouse=True)
    def generic_shell(self, monkeypatch):
        monkeypatch.setattr('thefuck.shells.from_shell', lambda x: x)
        monkeypatch.setattr('thefuck.shells.to_shell', lambda x: x)

    def test_get_command_calls(self, Popen):
        assert main.get_command(Mock(env={}),
                                ['thefuck', 'apt-get', 'search', 'vim']) \
               == Command('apt-get search vim', 'stdout', 'stderr')
        Popen.assert_called_once_with('apt-get search vim',
                                      shell=True,
                                      stdout=PIPE,
                                      stderr=PIPE,
                                      env={})

    @pytest.mark.parametrize('args, result', [
        (['thefuck', 'ls', '-la'], 'ls -la'),
        (['thefuck', 'ls'], 'ls')])
    def test_get_command_script(self, args, result):
        if result:
            assert main.get_command(Mock(env={}), args).script == result
        else:
            assert main.get_command(Mock(env={}), args) is None
","
1import pytest
2from subprocess import PIPE
3from mock import Mock
4from thefuck import main
5from tests.utils import Command
6
7
8class TestGetCommand(object):
9    @pytest.fixture(autouse=True)
10    def Popen(self, monkeypatch):
11        Popen = Mock()
12        Popen.return_value.stdout.read.return_value = b'stdout'
13        Popen.return_value.stderr.read.return_value = b'stderr'
14        monkeypatch.setattr('thefuck.main.Popen', Popen)
15        return Popen
16
17    @pytest.fixture(autouse=True)
18    def prepare(self, monkeypatch):
19        monkeypatch.setattr('thefuck.main.os.environ', {})
20        monkeypatch.setattr('thefuck.main.wait_output', lambda *_: True)
21
22    @pytest.fixture(autouse=True)
23    def generic_shell(self, monkeypatch):
24        monkeypatch.setattr('thefuck.shells.from_shell', lambda x: x)
25        monkeypatch.setattr('thefuck.shells.to_shell', lambda x: x)
26
27    def test_get_command_calls(self, Popen):
28                                ['thefuck', 'apt-get', 'search', 'vim']) \
29               == Command('apt-get search vim', 'stdout', 'stderr')
30                                      shell=True,
31                                      stdout=PIPE,
32                                      stderr=PIPE,
33                                      env={})
34
35    @pytest.mark.parametrize('args, result', [
36        (['thefuck', 'ls', '-la'], 'ls -la'),
37        (['thefuck', 'ls'], 'ls')])
38    def test_get_command_script(self, args, result):
39        if result:
40        else:
41","[['main.get_comm', '==', 'True'], ['(Mock(env={})', '==', 'True'], ['main.get_comm', '==', 'True'], ['(Mock(env={})', '==', 'True'], ['main.get_comm', '==', 'True'], ['(Mock(env={})', '==', 'True']]",4,6,1.5,0.0035005834305717,"['monkeypatch', 'Popen', 'Popen.return_value.stdout.read.return_value', 'Popen.return_value.stderr.read.return_value', 'args', 'result']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['monkeypatch', 'Popen', 'Popen.return_value.stdout.read.return_value', 'Popen.return_value.stderr.read.return_value', 'args', 'result']
*Code:

1import pytest
2from subprocess import PIPE
3from mock import Mock
4from thefuck import main
5from tests.utils import Command
6
7
8class TestGetCommand(object):
9    @pytest.fixture(autouse=True)
10    def Popen(self, monkeypatch):
11        Popen = Mock()
12        Popen.return_value.stdout.read.return_value = b'stdout'
13        Popen.return_value.stderr.read.return_value = b'stderr'
14        monkeypatch.setattr('thefuck.main.Popen', Popen)
15        return Popen
16
17    @pytest.fixture(autouse=True)
18    def prepare(self, monkeypatch):
19        monkeypatch.setattr('thefuck.main.os.environ', {})
20        monkeypatch.setattr('thefuck.main.wait_output', lambda *_: True)
21
22    @pytest.fixture(autouse=True)
23    def generic_shell(self, monkeypatch):
24        monkeypatch.setattr('thefuck.shells.from_shell', lambda x: x)
25        monkeypatch.setattr('thefuck.shells.to_shell', lambda x: x)
26
27    def test_get_command_calls(self, Popen):
28                                ['thefuck', 'apt-get', 'search', 'vim']) \
29               == Command('apt-get search vim', 'stdout', 'stderr')
30                                      shell=True,
31                                      stdout=PIPE,
32                                      stderr=PIPE,
33                                      env={})
34
35    @pytest.mark.parametrize('args, result', [
36        (['thefuck', 'ls', '-la'], 'ls -la'),
37        (['thefuck', 'ls'], 'ls')])
38    def test_get_command_script(self, args, result):
39        if result:
40        else:
41",3061,"[10, 'monkeypatch', '!=', 'None', ""monkeypatch mustn't be None""],
[10, 'Popen', '!=', 'None', ""Popen mustn't be None""],
[28, 'Popen', '!=', 'None', ""Popen mustn't be None""],
[38, 'args', '!=', 'None', ""args mustn't be None""],
[38, 'result', '!=', 'None', ""result mustn't be None""]"
arthurdarcet/aiohttp,"from unittest import mock

import pytest

from aiohttp import streams


@pytest.fixture
def protocol():
    return mock.Mock(_reading_paused=False)


@pytest.fixture
def stream(loop, protocol):
    out = streams.StreamReader(protocol, limit=1, loop=loop)
    out._allow_pause = True
    return out


@pytest.fixture
def buffer(loop, protocol):
    out = streams.FlowControlDataQueue(protocol, limit=1, loop=loop)
    out._allow_pause = True
    return out


class TestFlowControlStreamReader:

    async def test_read(self, stream) -> None:
        stream.feed_data(b'da', 2)
        res = await stream.read(1)
        assert res == b'd'
        assert not stream._protocol.resume_reading.called

    async def test_read_resume_paused(self, stream) -> None:
        stream.feed_data(b'test', 4)
        stream._protocol._reading_paused = True

        res = await stream.read(1)
        assert res == b't'
        assert stream._protocol.pause_reading.called

    async def test_readline(self, stream) -> None:
        stream.feed_data(b'd\n', 5)
        res = await stream.readline()
        assert res == b'd\n'
        assert not stream._protocol.resume_reading.called

    async def test_readline_resume_paused(self, stream) -> None:
        stream._protocol._reading_paused = True
        stream.feed_data(b'd\n', 5)
        res = await stream.readline()
        assert res == b'd\n'
        assert stream._protocol.resume_reading.called

    async def test_readany(self, stream) -> None:
        stream.feed_data(b'data', 4)
        res = await stream.readany()
        assert res == b'data'
        assert not stream._protocol.resume_reading.called

    async def test_readany_resume_paused(self, stream) -> None:
        stream._protocol._reading_paused = True
        stream.feed_data(b'data', 4)
        res = await stream.readany()
        assert res == b'data'
        assert stream._protocol.resume_reading.called

    async def test_readchunk(self, stream) -> None:
        stream.feed_data(b'data', 4)
        res, end_of_http_chunk = await stream.readchunk()
        assert res == b'data'
        assert not end_of_http_chunk
        assert not stream._protocol.resume_reading.called

    async def test_readchunk_resume_paused(self, stream) -> None:
        stream._protocol._reading_paused = True
        stream.feed_data(b'data', 4)
        res, end_of_http_chunk = await stream.readchunk()
        assert res == b'data'
        assert not end_of_http_chunk
        assert stream._protocol.resume_reading.called

    async def test_readexactly(self, stream) -> None:
        stream.feed_data(b'data', 4)
        res = await stream.readexactly(3)
        assert res == b'dat'
        assert not stream._protocol.resume_reading.called

    async def test_feed_data(self, stream) -> None:
        stream._protocol._reading_paused = False
        stream.feed_data(b'datadata', 8)
        assert stream._protocol.pause_reading.called

    async def test_read_nowait(self, stream) -> None:
        stream._protocol._reading_paused = True
        stream.feed_data(b'data1', 5)
        stream.feed_data(b'data2', 5)
        stream.feed_data(b'data3', 5)
        res = await stream.read(5)
        assert res == b'data1'
        assert stream._protocol.resume_reading.call_count == 0

        res = stream.read_nowait(5)
        assert res == b'data2'
        assert stream._protocol.resume_reading.call_count == 0

        res = stream.read_nowait(5)
        assert res == b'data3'
        assert stream._protocol.resume_reading.call_count == 1

        stream._protocol._reading_paused = False
        res = stream.read_nowait(5)
        assert res == b''
        assert stream._protocol.resume_reading.call_count == 1


class TestFlowControlDataQueue:

    def test_feed_pause(self, buffer) -> None:
        buffer._protocol._reading_paused = False
        buffer.feed_data(object(), 100)

        assert buffer._protocol.pause_reading.called

    async def test_resume_on_read(self, buffer) -> None:
        buffer.feed_data(object(), 100)

        buffer._protocol._reading_paused = True
        await buffer.read()
        assert buffer._protocol.resume_reading.called
","
1from unittest import mock
2
3import pytest
4
5from aiohttp import streams
6
7
8@pytest.fixture
9def protocol():
10    return mock.Mock(_reading_paused=False)
11
12
13@pytest.fixture
14def stream(loop, protocol):
15    out = streams.StreamReader(protocol, limit=1, loop=loop)
16    out._allow_pause = True
17    return out
18
19
20@pytest.fixture
21def buffer(loop, protocol):
22    out = streams.FlowControlDataQueue(protocol, limit=1, loop=loop)
23    out._allow_pause = True
24    return out
25
26
27class TestFlowControlStreamReader:
28
29    async def test_read(self, stream) -> None:
30        stream.feed_data(b'da', 2)
31        res = await stream.read(1)
32
33    async def test_read_resume_paused(self, stream) -> None:
34        stream.feed_data(b'test', 4)
35        stream._protocol._reading_paused = True
36
37        res = await stream.read(1)
38
39    async def test_readline(self, stream) -> None:
40        stream.feed_data(b'd\n', 5)
41        res = await stream.readline()
42
43    async def test_readline_resume_paused(self, stream) -> None:
44        stream._protocol._reading_paused = True
45        stream.feed_data(b'd\n', 5)
46        res = await stream.readline()
47
48    async def test_readany(self, stream) -> None:
49        stream.feed_data(b'data', 4)
50        res = await stream.readany()
51
52    async def test_readany_resume_paused(self, stream) -> None:
53        stream._protocol._reading_paused = True
54        stream.feed_data(b'data', 4)
55        res = await stream.readany()
56
57    async def test_readchunk(self, stream) -> None:
58        stream.feed_data(b'data', 4)
59        res, end_of_http_chunk = await stream.readchunk()
60
61    async def test_readchunk_resume_paused(self, stream) -> None:
62        stream._protocol._reading_paused = True
63        stream.feed_data(b'data', 4)
64        res, end_of_http_chunk = await stream.readchunk()
65
66    async def test_readexactly(self, stream) -> None:
67        stream.feed_data(b'data', 4)
68        res = await stream.readexactly(3)
69
70    async def test_feed_data(self, stream) -> None:
71        stream._protocol._reading_paused = False
72        stream.feed_data(b'datadata', 8)
73
74    async def test_read_nowait(self, stream) -> None:
75        stream._protocol._reading_paused = True
76        stream.feed_data(b'data1', 5)
77        stream.feed_data(b'data2', 5)
78        stream.feed_data(b'data3', 5)
79        res = await stream.read(5)
80
81        res = stream.read_nowait(5)
82
83        res = stream.read_nowait(5)
84
85        stream._protocol._reading_paused = False
86        res = stream.read_nowait(5)
87
88
89class TestFlowControlDataQueue:
90
91    def test_feed_pause(self, buffer) -> None:
92        buffer._protocol._reading_paused = False
93        buffer.feed_data(object(), 100)
94
95
96    async def test_resume_on_read(self, buffer) -> None:
97        buffer.feed_data(object(), 100)
98
99        buffer._protocol._reading_paused = True
100        await buffer.read()
101","[['res', '==', ""b'd'""], ['stream._protocol.resume_reading.called', '==', 'False'], ['res', '==', ""b't'""], ['stream._protocol.pause_reading.called', '==', 'True'], ['res', '==', ""b'd\\n'""], ['stream._protocol.resume_reading.called', '==', 'False'], ['res', '==', ""b'd\\n'""], ['stream._protocol.resume_reading.called', '==', 'True'], ['res', '==', ""b'data'""], ['stream._protocol.resume_reading.called', '==', 'False'], ['res', '==', ""b'data'""], ['stream._protocol.resume_reading.called', '==', 'True'], ['res', '==', ""b'data'""], ['end_of_http_chunk', '==', 'False'], ['stream._protocol.resume_reading.called', '==', 'False'], ['res', '==', ""b'data'""], ['end_of_http_chunk', '==', 'False'], ['stream._protocol.resume_reading.called', '==', 'True'], ['res', '==', ""b'dat'""], ['stream._protocol.resume_reading.called', '==', 'False'], ['stream._protocol.pause_reading.called', '==', 'True'], ['res', '==', ""b'data1'""], ['stream._protocol.resume_reading.call_count', '==', '0'], ['res', '==', ""b'data2'""], ['stream._protocol.resume_reading.call_count', '==', '0'], ['res', '==', ""b'data3'""], ['stream._protocol.resume_reading.call_count', '==', '1'], ['res', '==', ""b''""], ['stream._protocol.resume_reading.call_count', '==', '1'], ['buffer._protocol.pause_reading.called', '==', 'True'], ['buffer._protocol.resume_reading.called', '==', 'True']]",31,31,1.0,0.0074074074074074,"['loop', 'protocol', 'out', 'out._allow_pause', 'stream', 'res', 'stream._protocol._reading_paused', 'end_of_http_chunk', 'buffer', 'buffer._protocol._reading_paused']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['loop', 'protocol', 'out', 'out._allow_pause', 'stream', 'res', 'stream._protocol._reading_paused', 'end_of_http_chunk', 'buffer', 'buffer._protocol._reading_paused']
*Code:

1from unittest import mock
2
3import pytest
4
5from aiohttp import streams
6
7
8@pytest.fixture
9def protocol():
10    return mock.Mock(_reading_paused=False)
11
12
13@pytest.fixture
14def stream(loop, protocol):
15    out = streams.StreamReader(protocol, limit=1, loop=loop)
16    out._allow_pause = True
17    return out
18
19
20@pytest.fixture
21def buffer(loop, protocol):
22    out = streams.FlowControlDataQueue(protocol, limit=1, loop=loop)
23    out._allow_pause = True
24    return out
25
26
27class TestFlowControlStreamReader:
28
29    async def test_read(self, stream) -> None:
30        stream.feed_data(b'da', 2)
31        res = await stream.read(1)
32
33    async def test_read_resume_paused(self, stream) -> None:
34        stream.feed_data(b'test', 4)
35        stream._protocol._reading_paused = True
36
37        res = await stream.read(1)
38
39    async def test_readline(self, stream) -> None:
40        stream.feed_data(b'd\n', 5)
41        res = await stream.readline()
42
43    async def test_readline_resume_paused(self, stream) -> None:
44        stream._protocol._reading_paused = True
45        stream.feed_data(b'd\n', 5)
46        res = await stream.readline()
47
48    async def test_readany(self, stream) -> None:
49        stream.feed_data(b'data', 4)
50        res = await stream.readany()
51
52    async def test_readany_resume_paused(self, stream) -> None:
53        stream._protocol._reading_paused = True
54        stream.feed_data(b'data', 4)
55        res = await stream.readany()
56
57    async def test_readchunk(self, stream) -> None:
58        stream.feed_data(b'data', 4)
59        res, end_of_http_chunk = await stream.readchunk()
60
61    async def test_readchunk_resume_paused(self, stream) -> None:
62        stream._protocol._reading_paused = True
63        stream.feed_data(b'data', 4)
64        res, end_of_http_chunk = await stream.readchunk()
65
66    async def test_readexactly(self, stream) -> None:
67        stream.feed_data(b'data', 4)
68        res = await stream.readexactly(3)
69
70    async def test_feed_data(self, stream) -> None:
71        stream._protocol._reading_paused = False
72        stream.feed_data(b'datadata', 8)
73
74    async def test_read_nowait(self, stream) -> None:
75        stream._protocol._reading_paused = True
76        stream.feed_data(b'data1', 5)
77        stream.feed_data(b'data2', 5)
78        stream.feed_data(b'data3', 5)
79        res = await stream.read(5)
80
81        res = stream.read_nowait(5)
82
83        res = stream.read_nowait(5)
84
85        stream._protocol._reading_paused = False
86        res = stream.read_nowait(5)
87
88
89class TestFlowControlDataQueue:
90
91    def test_feed_pause(self, buffer) -> None:
92        buffer._protocol._reading_paused = False
93        buffer.feed_data(object(), 100)
94
95
96    async def test_resume_on_read(self, buffer) -> None:
97        buffer.feed_data(object(), 100)
98
99        buffer._protocol._reading_paused = True
100        await buffer.read()
101",4557,"[[14, 'out', '!=', None, 'Ensure streams.StreamReader is properly instantiated'],
 [21, 'out', '!=', None, 'Ensure FlowControlDataQueue is properly instantiated'],
 [30, 'res', '!=', None, 'Ensure data is being read correctly from the stream'],
 [36, 'stream._protocol._reading_paused', '==', True, 'Ensuring reading is paused before reading from the stream'],
 [37, 'res', '!=', None, 'Ensure data is being read correctly even when paused'],
 [50, 'res', '!=', None, 'Ensure readany method is working correctly'],
 [54, 'stream._protocol._reading_paused', '==', True, 'Ensuring reading is paused before reading from the stream using readany'],
 [55, 'res', '!=', None, 'Ensure readany method is working correctly even when paused'],
 [59, 'res', '!=', None, 'Ensure readchunk method is working correctly'],
 [63, 'stream._protocol._reading_paused', '==', True, 'Ensuring reading is paused before reading from the stream using readchunk'],
 [64, 'res', '!=', None, 'Ensure readchunk method is working correctly even when paused'],
 [68, 'res', '!=', None, 'Ensure readexactly method is working correctly'],
 [80, 'res', '!=', None, 'Ensure read method is working correctly with multiple feed data'],
 [81, 'res', '!=', None, 'Ensure read_nowait method is working correctly'],
 [92, 'buffer._protocol._reading_paused', '==', False, 'Ensuring reading is not paused before feeding data into buffer'],
 [97, 'buffer._protocol._reading_paused', '==', True, 'Ensuring reading is paused before reading from the buffer']]"
greyhwndz/rethinkdb,"#!/usr/bin/env python
# Copyright 2014 RethinkDB, all rights reserved.

from __future__ import print_function

import os, pprint, sys, time, threading, traceback

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir, 'common')))
import driver, scenario_common, utils, vcoptparse

r = utils.import_python_driver()

""""""The `interface.system_changefeeds` test checks that changefeeds on system tables
correctly notify when changes occur.""""""

op = vcoptparse.OptParser()
scenario_common.prepare_option_parser_mode_flags(op)
opts = op.parse(sys.argv)

class AsyncChangefeed(object):
    def __init__(self, host, port, query):
        self.conn = r.connect(host, port)
        self.stopping = False
        self.err = None
        self.changes = []
        self.thr = threading.Thread(target = self.run, args = (query, ))
        self.thr.daemon = True
        self.thr.start()
        time.sleep(0.5)
    def run(self, query):
        try:
            for x in eval(query).changes().run(self.conn):
                # Throw away initial values
                if ""old_val"" in x:
                    self.changes.append(x)
        except Exception, e:
            self.err = sys.exc_info()
    def check(self):
        if self.err is not None:
            print(""Exception from other thread:"")
            traceback.print_exception(*self.err)
            sys.exit(1)

with driver.Metacluster() as metacluster:
    cluster1 = driver.Cluster(metacluster)
    _, command_prefix, serve_options = scenario_common.parse_mode_flags(opts)
    
    print(""Spinning up two processes..."")
    files1 = driver.Files(metacluster, console_output=""create-output-1"", server_name=""a"", server_tags=[""a_tag""], command_prefix=command_prefix)
    proc1 = driver.Process(cluster1, files1, console_output=""serve-output-1"", command_prefix=command_prefix, extra_options=serve_options)
    files2 = driver.Files(metacluster, console_output=""create-output-2"", server_name=""b"", server_tags=[""b_tag""], command_prefix=command_prefix)
    proc2 = driver.Process(cluster1, files2, console_output=""serve-output-2"", command_prefix=command_prefix, extra_options=serve_options)
    proc1.wait_until_started_up()
    proc2.wait_until_started_up()
    cluster1.check()

    # This is necessary because a few log messages may be printed even after
    # `wait_until_started_up()` returns.
    time.sleep(5.0)

    conn = r.connect(proc1.host, proc1.driver_port)
    tables = [""cluster_config"", ""db_config"", ""current_issues"", ""logs"", ""server_config"",
        ""server_status"", ""table_config"", ""table_status""]
    feeds = { }
    for name in tables:
        feeds[name] = AsyncChangefeed(proc1.host, proc1.driver_port,
            ""r.db('rethinkdb').table(%r)"" % name)

    def check(expected, timer):
        time.sleep(timer)
        for name, feed in feeds.iteritems():
            feed.check()
            if name in expected:
                assert len(feed.changes) > 0, \
                    ""Expected changes on %s, found none."" % name
                feed.changes = []
            else:
                assert len(feed.changes) == 0, \
                    ""Expected no changes on %s, found %s."" % (name, feed.changes)
    check([], 5.0)

    print(""Changing auth key..."")
    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
           .update({""auth_key"": ""foo""}).run(conn)
    assert res[""replaced""] == 1 and res[""errors""] == 0, res
    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
           .update({""auth_key"": None}).run(conn)
    check([""cluster_config""], 1.0)

    print(""Creating database..."")
    res = r.db_create(""test"").run(conn)
    assert res.get(""dbs_created"", 0) == 1, res
    check([""db_config""], 1.0)

    print(""Creating tables..."")
    res = r.table_create(""test"", replicas={""a_tag"": 1}, primary_replica_tag=""a_tag"").run(conn)
    assert res[""tables_created""] == 1, res
    res = r.table_create(""test2"", replicas={""b_tag"": 1}, primary_replica_tag=""b_tag"").run(conn)
    assert res[""tables_created""] == 1, res
    check([""table_config"", ""table_status"", ""logs""], 1.5)

    feeds[""test_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
        ""r.table('test').config()"")
    feeds[""test_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
        ""r.table('test').status()"")
    feeds[""test2_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
        ""r.table('test2').config()"")
    feeds[""test2_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
        ""r.table('test2').status()"")

    res = r.table(""test"").config() \
           .update({""shards"": [{""primary_replica"": ""a"", ""replicas"": [""a"", ""b""]}]}).run(conn)
    assert res[""errors""] == 0, res
    r.table(""test"").wait().run(conn)
    check([""table_config"", ""table_status"", ""test_config"", ""test_status"", ""logs""], 1.5)

    print(""Renaming server..."")
    res = r.db(""rethinkdb"").table(""server_config"").filter({""name"": ""b""}) \
           .update({""name"": ""c""}).run(conn)
    assert res[""replaced""] == 1 and res[""errors""] == 0, res
    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"",
        ""test_config"", ""test_status"", ""test2_config"", ""test2_status""], 1.5)

    print(""Killing one server..."")
    proc2.check_and_stop()
    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"", ""current_issues"",
        ""test_status"", ""test2_config"", ""test2_status""], 1.5)

    print(""Shutting everything down..."")
    cluster1.check_and_stop()
print(""Done."")
","
1#!/usr/bin/env python
2# Copyright 2014 RethinkDB, all rights reserved.
3
4from __future__ import print_function
5
6import os, pprint, sys, time, threading, traceback
7
8sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir, 'common')))
9import driver, scenario_common, utils, vcoptparse
10
11r = utils.import_python_driver()
12
13""""""The `interface.system_changefeeds` test checks that changefeeds on system tables
14correctly notify when changes occur.""""""
15
16op = vcoptparse.OptParser()
17scenario_common.prepare_option_parser_mode_flags(op)
18opts = op.parse(sys.argv)
19
20class AsyncChangefeed(object):
21    def __init__(self, host, port, query):
22        self.conn = r.connect(host, port)
23        self.stopping = False
24        self.err = None
25        self.changes = []
26        self.thr = threading.Thread(target = self.run, args = (query, ))
27        self.thr.daemon = True
28        self.thr.start()
29        time.sleep(0.5)
30    def run(self, query):
31        try:
32            for x in eval(query).changes().run(self.conn):
33                # Throw away initial values
34                if ""old_val"" in x:
35                    self.changes.append(x)
36        except Exception, e:
37            self.err = sys.exc_info()
38    def check(self):
39        if self.err is not None:
40            print(""Exception from other thread:"")
41            traceback.print_exception(*self.err)
42            sys.exit(1)
43
44with driver.Metacluster() as metacluster:
45    cluster1 = driver.Cluster(metacluster)
46    _, command_prefix, serve_options = scenario_common.parse_mode_flags(opts)
47    
48    print(""Spinning up two processes..."")
49    files1 = driver.Files(metacluster, console_output=""create-output-1"", server_name=""a"", server_tags=[""a_tag""], command_prefix=command_prefix)
50    proc1 = driver.Process(cluster1, files1, console_output=""serve-output-1"", command_prefix=command_prefix, extra_options=serve_options)
51    files2 = driver.Files(metacluster, console_output=""create-output-2"", server_name=""b"", server_tags=[""b_tag""], command_prefix=command_prefix)
52    proc2 = driver.Process(cluster1, files2, console_output=""serve-output-2"", command_prefix=command_prefix, extra_options=serve_options)
53    proc1.wait_until_started_up()
54    proc2.wait_until_started_up()
55    cluster1.check()
56
57    # This is necessary because a few log messages may be printed even after
58    # `wait_until_started_up()` returns.
59    time.sleep(5.0)
60
61    conn = r.connect(proc1.host, proc1.driver_port)
62    tables = [""cluster_config"", ""db_config"", ""current_issues"", ""logs"", ""server_config"",
63        ""server_status"", ""table_config"", ""table_status""]
64    feeds = { }
65    for name in tables:
66        feeds[name] = AsyncChangefeed(proc1.host, proc1.driver_port,
67            ""r.db('rethinkdb').table(%r)"" % name)
68
69    def check(expected, timer):
70        time.sleep(timer)
71        for name, feed in feeds.iteritems():
72            feed.check()
73            if name in expected:
74                    ""Expected changes on %s, found none."" % name
75                feed.changes = []
76            else:
77                    ""Expected no changes on %s, found %s."" % (name, feed.changes)
78    check([], 5.0)
79
80    print(""Changing auth key..."")
81    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
82           .update({""auth_key"": ""foo""}).run(conn)
83    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
84           .update({""auth_key"": None}).run(conn)
85    check([""cluster_config""], 1.0)
86
87    print(""Creating database..."")
88    res = r.db_create(""test"").run(conn)
89    check([""db_config""], 1.0)
90
91    print(""Creating tables..."")
92    res = r.table_create(""test"", replicas={""a_tag"": 1}, primary_replica_tag=""a_tag"").run(conn)
93    res = r.table_create(""test2"", replicas={""b_tag"": 1}, primary_replica_tag=""b_tag"").run(conn)
94    check([""table_config"", ""table_status"", ""logs""], 1.5)
95
96    feeds[""test_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
97        ""r.table('test').config()"")
98    feeds[""test_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
99        ""r.table('test').status()"")
100    feeds[""test2_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
101        ""r.table('test2').config()"")
102    feeds[""test2_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
103        ""r.table('test2').status()"")
104
105    res = r.table(""test"").config() \
106           .update({""shards"": [{""primary_replica"": ""a"", ""replicas"": [""a"", ""b""]}]}).run(conn)
107    r.table(""test"").wait().run(conn)
108    check([""table_config"", ""table_status"", ""test_config"", ""test_status"", ""logs""], 1.5)
109
110    print(""Renaming server..."")
111    res = r.db(""rethinkdb"").table(""server_config"").filter({""name"": ""b""}) \
112           .update({""name"": ""c""}).run(conn)
113    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"",
114        ""test_config"", ""test_status"", ""test2_config"", ""test2_status""], 1.5)
115
116    print(""Killing one server..."")
117    proc2.check_and_stop()
118    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"", ""current_issues"",
119        ""test_status"", ""test2_config"", ""test2_status""], 1.5)
120
121    print(""Shutting everything down..."")
122    cluster1.check_and_stop()
123print(""Done."")
124","[['len(feed.changes)', '>', '0'], ['len(feed.changes)', '==', '0'], ['res[""replaced""]', '==', '1'], ['res[""errors""]', '==', '0'], ['res.get(""dbs_created""', '==', 'True'], ['res[""tables_created""]', '==', '1'], ['res[""tables_created""]', '==', '1'], ['res[""errors""]', '==', '0'], ['res[""replaced""]', '==', '1'], ['res[""errors""]', '==', '0']]",8,10,1.25,0.0018073377914332,"['r', 'op', 'opts', 'host', 'port', 'query', 'self.conn', 'self.stopping', 'self.err', 'self.changes', 'self.thr', 'self.thr.daemon', 'cluster1', '_', 'command_prefix', 'serve_options', 'files1', 'proc1', 'files2', 'proc2', 'conn', 'tables', 'feeds', 'feeds[name]', 'expected', 'timer', 'feed.changes', 'res', 'feeds[""test_config""]', 'feeds[""test_status""]', 'feeds[""test2_config""]', 'feeds[""test2_status""]']",32,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['r', 'op', 'opts', 'host', 'port', 'query', 'self.conn', 'self.stopping', 'self.err', 'self.changes', 'self.thr', 'self.thr.daemon', 'cluster1', '_', 'command_prefix', 'serve_options', 'files1', 'proc1', 'files2', 'proc2', 'conn', 'tables', 'feeds', 'feeds[name]', 'expected', 'timer', 'feed.changes', 'res', 'feeds[""test_config""]', 'feeds[""test_status""]', 'feeds[""test2_config""]', 'feeds[""test2_status""]']
*Code:

1#!/usr/bin/env python
2# Copyright 2014 RethinkDB, all rights reserved.
3
4from __future__ import print_function
5
6import os, pprint, sys, time, threading, traceback
7
8sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir, 'common')))
9import driver, scenario_common, utils, vcoptparse
10
11r = utils.import_python_driver()
12
13""""""The `interface.system_changefeeds` test checks that changefeeds on system tables
14correctly notify when changes occur.""""""
15
16op = vcoptparse.OptParser()
17scenario_common.prepare_option_parser_mode_flags(op)
18opts = op.parse(sys.argv)
19
20class AsyncChangefeed(object):
21    def __init__(self, host, port, query):
22        self.conn = r.connect(host, port)
23        self.stopping = False
24        self.err = None
25        self.changes = []
26        self.thr = threading.Thread(target = self.run, args = (query, ))
27        self.thr.daemon = True
28        self.thr.start()
29        time.sleep(0.5)
30    def run(self, query):
31        try:
32            for x in eval(query).changes().run(self.conn):
33                # Throw away initial values
34                if ""old_val"" in x:
35                    self.changes.append(x)
36        except Exception, e:
37            self.err = sys.exc_info()
38    def check(self):
39        if self.err is not None:
40            print(""Exception from other thread:"")
41            traceback.print_exception(*self.err)
42            sys.exit(1)
43
44with driver.Metacluster() as metacluster:
45    cluster1 = driver.Cluster(metacluster)
46    _, command_prefix, serve_options = scenario_common.parse_mode_flags(opts)
47    
48    print(""Spinning up two processes..."")
49    files1 = driver.Files(metacluster, console_output=""create-output-1"", server_name=""a"", server_tags=[""a_tag""], command_prefix=command_prefix)
50    proc1 = driver.Process(cluster1, files1, console_output=""serve-output-1"", command_prefix=command_prefix, extra_options=serve_options)
51    files2 = driver.Files(metacluster, console_output=""create-output-2"", server_name=""b"", server_tags=[""b_tag""], command_prefix=command_prefix)
52    proc2 = driver.Process(cluster1, files2, console_output=""serve-output-2"", command_prefix=command_prefix, extra_options=serve_options)
53    proc1.wait_until_started_up()
54    proc2.wait_until_started_up()
55    cluster1.check()
56
57    # This is necessary because a few log messages may be printed even after
58    # `wait_until_started_up()` returns.
59    time.sleep(5.0)
60
61    conn = r.connect(proc1.host, proc1.driver_port)
62    tables = [""cluster_config"", ""db_config"", ""current_issues"", ""logs"", ""server_config"",
63        ""server_status"", ""table_config"", ""table_status""]
64    feeds = { }
65    for name in tables:
66        feeds[name] = AsyncChangefeed(proc1.host, proc1.driver_port,
67            ""r.db('rethinkdb').table(%r)"" % name)
68
69    def check(expected, timer):
70        time.sleep(timer)
71        for name, feed in feeds.iteritems():
72            feed.check()
73            if name in expected:
74                    ""Expected changes on %s, found none."" % name
75                feed.changes = []
76            else:
77                    ""Expected no changes on %s, found %s."" % (name, feed.changes)
78    check([], 5.0)
79
80    print(""Changing auth key..."")
81    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
82           .update({""auth_key"": ""foo""}).run(conn)
83    res = r.db(""rethinkdb"").table(""cluster_config"").get(""auth"") \
84           .update({""auth_key"": None}).run(conn)
85    check([""cluster_config""], 1.0)
86
87    print(""Creating database..."")
88    res = r.db_create(""test"").run(conn)
89    check([""db_config""], 1.0)
90
91    print(""Creating tables..."")
92    res = r.table_create(""test"", replicas={""a_tag"": 1}, primary_replica_tag=""a_tag"").run(conn)
93    res = r.table_create(""test2"", replicas={""b_tag"": 1}, primary_replica_tag=""b_tag"").run(conn)
94    check([""table_config"", ""table_status"", ""logs""], 1.5)
95
96    feeds[""test_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
97        ""r.table('test').config()"")
98    feeds[""test_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
99        ""r.table('test').status()"")
100    feeds[""test2_config""] = AsyncChangefeed(proc1.host, proc1.driver_port,
101        ""r.table('test2').config()"")
102    feeds[""test2_status""] = AsyncChangefeed(proc1.host, proc1.driver_port,
103        ""r.table('test2').status()"")
104
105    res = r.table(""test"").config() \
106           .update({""shards"": [{""primary_replica"": ""a"", ""replicas"": [""a"", ""b""]}]}).run(conn)
107    r.table(""test"").wait().run(conn)
108    check([""table_config"", ""table_status"", ""test_config"", ""test_status"", ""logs""], 1.5)
109
110    print(""Renaming server..."")
111    res = r.db(""rethinkdb"").table(""server_config"").filter({""name"": ""b""}) \
112           .update({""name"": ""c""}).run(conn)
113    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"",
114        ""test_config"", ""test_status"", ""test2_config"", ""test2_status""], 1.5)
115
116    print(""Killing one server..."")
117    proc2.check_and_stop()
118    check([""logs"", ""server_config"", ""server_status"", ""table_config"", ""table_status"", ""current_issues"",
119        ""test_status"", ""test2_config"", ""test2_status""], 1.5)
120
121    print(""Shutting everything down..."")
122    cluster1.check_and_stop()
123print(""Done."")
124",7200,"[[21, 'host', '!=', None, 'host must be specified for connection'],
 [21, 'port', '!=', None, 'port must be specified for connection'],
 [21, 'query', '!=', None, 'query must be specified for AsyncChangefeed object'],
 [49, 'files1', '!=', None, 'files1 is required for the Process initiation'],
 [50, 'proc1', '!=', None, 'proc1 must be successfully initialized'],
 [52, 'files2', '!=', None, 'files2 is required for the Process initiation'],
 [53, 'proc2', '!=', None, 'proc2 must be successfully initialized'],
 [61, 'conn', '!=', None, 'conn must be successfully initialized'],
 [65, 'tables', '!=', None, 'tables list should not be empty'],
 [84, 'res', '!=', None, 'the database update operation should not return None'],
 [92, 'res', '!=', None, 'the table creation operation should not return None'],
 [105, 'res', '!=', None, 'the config update operation should not return None'],
 [111, 'res', '!=', None, 'the server rename operation should not return None']]"
caesar2164/edx-platform,"""""""
This test tests that i18n extraction (`paver i18n_extract -v`) works properly.
""""""
from datetime import datetime, timedelta
import os
import random
import re
import sys
import string
import subprocess
from unittest import TestCase

from mock import patch
from polib import pofile
from pytz import UTC

from i18n import config
from i18n import dummy
from i18n import extract
from i18n import generate


class TestGenerate(TestCase):
    """"""
    Tests functionality of i18n/generate.py
    """"""
    generated_files = ('django-partial.po', 'djangojs-partial.po', 'mako.po')

    @classmethod
    def setUpClass(cls):
        super(TestGenerate, cls).setUpClass()

        sys.stderr.write(
            ""\nThis test tests that i18n extraction (`paver i18n_extract`) works properly. ""
            ""If you experience failures, please check that all instances of `gettext` and ""
            ""`ngettext` are used correctly. You can also try running `paver i18n_extract -v` ""
            ""locally for more detail.\n""
        )
        sys.stderr.write(
            ""\nExtracting i18n strings and generating dummy translations; ""
            ""this may take a few minutes\n""
        )
        sys.stderr.flush()
        extract.main(verbose=0)
        dummy.main(verbose=0)

    @classmethod
    def tearDownClass(cls):
        # Clear the Esperanto & RTL directories of any test artifacts
        cmd = ""git checkout conf/locale/eo conf/locale/rtl""
        sys.stderr.write(""Cleaning up dummy language directories: "" + cmd)
        sys.stderr.flush()
        returncode = subprocess.call(cmd, shell=True)
        assert returncode == 0
        super(TestGenerate, cls).tearDownClass()

    def setUp(self):
        super(TestGenerate, self).setUp()

        self.configuration = config.Configuration()

        # Subtract 1 second to help comparisons with file-modify time succeed,
        # since os.path.getmtime() is not millisecond-accurate
        self.start_time = datetime.now(UTC) - timedelta(seconds=1)

    def test_merge(self):
        """"""
        Tests merge script on English source files.
        """"""
        filename = os.path.join(self.configuration.source_messages_dir, random_name())
        generate.merge(self.configuration, self.configuration.source_locale, target=filename)
        self.assertTrue(os.path.exists(filename))
        os.remove(filename)

    def test_main(self):
        """"""
        Runs generate.main() which should merge source files,
        then compile all sources in all configured languages.
        Validates output by checking all .mo files in all configured languages.
        .mo files should exist, and be recently created (modified
        after start of test suite)
        """"""
        # Change dummy_locales to not have Esperanto present.
        self.configuration.dummy_locales = ['fake2']

        generate.main(verbosity=0, strict=False)
        for locale in self.configuration.translated_locales:
            for filename in ('django', 'djangojs'):
                mofile = filename + '.mo'
                path = os.path.join(self.configuration.get_messages_dir(locale), mofile)
                exists = os.path.exists(path)
                self.assertTrue(exists, msg='Missing file in locale %s: %s' % (locale, mofile))
                self.assertGreaterEqual(
                    datetime.fromtimestamp(os.path.getmtime(path), UTC),
                    self.start_time,
                    msg='File not recently modified: %s' % path
                )
            # Segmenting means that the merge headers don't work they way they
            # used to, so don't make this check for now. I'm not sure if we'll
            # get the merge header back eventually, or delete this code eventually.
            # self.assert_merge_headers(locale)

    def assert_merge_headers(self, locale):
        """"""
        This is invoked by test_main to ensure that it runs after
        calling generate.main().

        There should be exactly three merge comment headers
        in our merged .po file. This counts them to be sure.
        A merge comment looks like this:
        # #-#-#-#-#  django-partial.po (0.1a)  #-#-#-#-#

        """"""
        path = os.path.join(self.configuration.get_messages_dir(locale), 'django.po')
        pof = pofile(path)
        pattern = re.compile('^#-#-#-#-#', re.M)
        match = pattern.findall(pof.header)
        self.assertEqual(
            len(match),
            3,
            msg=""Found %s (should be 3) merge comments in the header for %s"" % (len(match), path)
        )


def random_name(size=6):
    """"""Returns random filename as string, like test-4BZ81W""""""
    chars = string.ascii_uppercase + string.digits
    return 'test-' + ''.join(random.choice(chars) for x in range(size))
","
1""""""
2This test tests that i18n extraction (`paver i18n_extract -v`) works properly.
3""""""
4from datetime import datetime, timedelta
5import os
6import random
7import re
8import sys
9import string
10import subprocess
11from unittest import TestCase
12
13from mock import patch
14from polib import pofile
15from pytz import UTC
16
17from i18n import config
18from i18n import dummy
19from i18n import extract
20from i18n import generate
21
22
23class TestGenerate(TestCase):
24    """"""
25    Tests functionality of i18n/generate.py
26    """"""
27    generated_files = ('django-partial.po', 'djangojs-partial.po', 'mako.po')
28
29    @classmethod
30    def setUpClass(cls):
31        super(TestGenerate, cls).setUpClass()
32
33        sys.stderr.write(
34            ""\nThis test tests that i18n extraction (`paver i18n_extract`) works properly. ""
35            ""If you experience failures, please check that all instances of `gettext` and ""
36            ""`ngettext` are used correctly. You can also try running `paver i18n_extract -v` ""
37            ""locally for more detail.\n""
38        )
39        sys.stderr.write(
40            ""\nExtracting i18n strings and generating dummy translations; ""
41            ""this may take a few minutes\n""
42        )
43        sys.stderr.flush()
44        extract.main(verbose=0)
45        dummy.main(verbose=0)
46
47    @classmethod
48    def tearDownClass(cls):
49        # Clear the Esperanto & RTL directories of any test artifacts
50        cmd = ""git checkout conf/locale/eo conf/locale/rtl""
51        sys.stderr.write(""Cleaning up dummy language directories: "" + cmd)
52        sys.stderr.flush()
53        returncode = subprocess.call(cmd, shell=True)
54        super(TestGenerate, cls).tearDownClass()
55
56    def setUp(self):
57        super(TestGenerate, self).setUp()
58
59        self.configuration = config.Configuration()
60
61        # Subtract 1 second to help comparisons with file-modify time succeed,
62        # since os.path.getmtime() is not millisecond-accurate
63        self.start_time = datetime.now(UTC) - timedelta(seconds=1)
64
65    def test_merge(self):
66        """"""
67        Tests merge script on English source files.
68        """"""
69        filename = os.path.join(self.configuration.source_messages_dir, random_name())
70        generate.merge(self.configuration, self.configuration.source_locale, target=filename)
71        os.remove(filename)
72
73    def test_main(self):
74        """"""
75        Runs generate.main() which should merge source files,
76        then compile all sources in all configured languages.
77        Validates output by checking all .mo files in all configured languages.
78        .mo files should exist, and be recently created (modified
79        after start of test suite)
80        """"""
81        # Change dummy_locales to not have Esperanto present.
82        self.configuration.dummy_locales = ['fake2']
83
84        generate.main(verbosity=0, strict=False)
85        for locale in self.configuration.translated_locales:
86            for filename in ('django', 'djangojs'):
87                mofile = filename + '.mo'
88                path = os.path.join(self.configuration.get_messages_dir(locale), mofile)
89                exists = os.path.exists(path)
90                    datetime.fromtimestamp(os.path.getmtime(path), UTC),
91                    self.start_time,
92                    msg='File not recently modified: %s' % path
93                )
94            # Segmenting means that the merge headers don't work they way they
95            # used to, so don't make this check for now. I'm not sure if we'll
96            # get the merge header back eventually, or delete this code eventually.
97
98        """"""
99        This is invoked by test_main to ensure that it runs after
100        calling generate.main().
101
102        There should be exactly three merge comment headers
103        in our merged .po file. This counts them to be sure.
104        A merge comment looks like this:
105        # #-#-#-#-#  django-partial.po (0.1a)  #-#-#-#-#
106
107        """"""
108        path = os.path.join(self.configuration.get_messages_dir(locale), 'django.po')
109        pof = pofile(path)
110        pattern = re.compile('^#-#-#-#-#', re.M)
111        match = pattern.findall(pof.header)
112            len(match),
113            3,
114            msg=""Found %s (should be 3) merge comments in the header for %s"" % (len(match), path)
115        )
116
117
118def random_name(size=6):
119    """"""Returns random filename as string, like test-4BZ81W""""""
120    chars = string.ascii_uppercase + string.digits
121    return 'test-' + ''.join(random.choice(chars) for x in range(size))
122","[['returncode', '==', '0']]",7,1,0.1428571428571428,0.0002093802345058,"['generated_files', 'cls', 'cmd', 'returncode', 'self.configuration', 'self.start_time', 'filename', 'self.configuration.dummy_locales', 'mofile', 'path', 'exists', 'locale', 'pof', 'pattern', 'match', 'size', 'chars']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['generated_files', 'cls', 'cmd', 'returncode', 'self.configuration', 'self.start_time', 'filename', 'self.configuration.dummy_locales', 'mofile', 'path', 'exists', 'locale', 'pof', 'pattern', 'match', 'size', 'chars']
*Code:

1""""""
2This test tests that i18n extraction (`paver i18n_extract -v`) works properly.
3""""""
4from datetime import datetime, timedelta
5import os
6import random
7import re
8import sys
9import string
10import subprocess
11from unittest import TestCase
12
13from mock import patch
14from polib import pofile
15from pytz import UTC
16
17from i18n import config
18from i18n import dummy
19from i18n import extract
20from i18n import generate
21
22
23class TestGenerate(TestCase):
24    """"""
25    Tests functionality of i18n/generate.py
26    """"""
27    generated_files = ('django-partial.po', 'djangojs-partial.po', 'mako.po')
28
29    @classmethod
30    def setUpClass(cls):
31        super(TestGenerate, cls).setUpClass()
32
33        sys.stderr.write(
34            ""\nThis test tests that i18n extraction (`paver i18n_extract`) works properly. ""
35            ""If you experience failures, please check that all instances of `gettext` and ""
36            ""`ngettext` are used correctly. You can also try running `paver i18n_extract -v` ""
37            ""locally for more detail.\n""
38        )
39        sys.stderr.write(
40            ""\nExtracting i18n strings and generating dummy translations; ""
41            ""this may take a few minutes\n""
42        )
43        sys.stderr.flush()
44        extract.main(verbose=0)
45        dummy.main(verbose=0)
46
47    @classmethod
48    def tearDownClass(cls):
49        # Clear the Esperanto & RTL directories of any test artifacts
50        cmd = ""git checkout conf/locale/eo conf/locale/rtl""
51        sys.stderr.write(""Cleaning up dummy language directories: "" + cmd)
52        sys.stderr.flush()
53        returncode = subprocess.call(cmd, shell=True)
54        super(TestGenerate, cls).tearDownClass()
55
56    def setUp(self):
57        super(TestGenerate, self).setUp()
58
59        self.configuration = config.Configuration()
60
61        # Subtract 1 second to help comparisons with file-modify time succeed,
62        # since os.path.getmtime() is not millisecond-accurate
63        self.start_time = datetime.now(UTC) - timedelta(seconds=1)
64
65    def test_merge(self):
66        """"""
67        Tests merge script on English source files.
68        """"""
69        filename = os.path.join(self.configuration.source_messages_dir, random_name())
70        generate.merge(self.configuration, self.configuration.source_locale, target=filename)
71        os.remove(filename)
72
73    def test_main(self):
74        """"""
75        Runs generate.main() which should merge source files,
76        then compile all sources in all configured languages.
77        Validates output by checking all .mo files in all configured languages.
78        .mo files should exist, and be recently created (modified
79        after start of test suite)
80        """"""
81        # Change dummy_locales to not have Esperanto present.
82        self.configuration.dummy_locales = ['fake2']
83
84        generate.main(verbosity=0, strict=False)
85        for locale in self.configuration.translated_locales:
86            for filename in ('django', 'djangojs'):
87                mofile = filename + '.mo'
88                path = os.path.join(self.configuration.get_messages_dir(locale), mofile)
89                exists = os.path.exists(path)
90                    datetime.fromtimestamp(os.path.getmtime(path), UTC),
91                    self.start_time,
92                    msg='File not recently modified: %s' % path
93                )
94            # Segmenting means that the merge headers don't work they way they
95            # used to, so don't make this check for now. I'm not sure if we'll
96            # get the merge header back eventually, or delete this code eventually.
97
98        """"""
99        This is invoked by test_main to ensure that it runs after
100        calling generate.main().
101
102        There should be exactly three merge comment headers
103        in our merged .po file. This counts them to be sure.
104        A merge comment looks like this:
105        # #-#-#-#-#  django-partial.po (0.1a)  #-#-#-#-#
106
107        """"""
108        path = os.path.join(self.configuration.get_messages_dir(locale), 'django.po')
109        pof = pofile(path)
110        pattern = re.compile('^#-#-#-#-#', re.M)
111        match = pattern.findall(pof.header)
112            len(match),
113            3,
114            msg=""Found %s (should be 3) merge comments in the header for %s"" % (len(match), path)
115        )
116
117
118def random_name(size=6):
119    """"""Returns random filename as string, like test-4BZ81W""""""
120    chars = string.ascii_uppercase + string.digits
121    return 'test-' + ''.join(random.choice(chars) for x in range(size))
122",6297,"[[28, 'generated_files', '==', 3, 'TestGenerate class has 3 generated_files'],
 [54, 'returncode', '==', 0, 'Successful command execution should return 0'],
 [64, 'self.start_time', '>=', 1, 'start_time should always be greater than 1 second'],
 [70, 'filename', '!=', '', 'filename should not be empty'],
 [83, 'self.configuration.dummy_locales', '==', 1, 'dummy_locales should have a single value'],
 [89, 'exists', '==', True, 'The path should exist'],
 [112, 'match', '==', 3, 'there should be exactly three merge comment headers'],
 [118, 'size', '>=', 1, 'size cannot be less than 1'],
 [121, 'chars', '!=', '', 'chars should not be an empty string']]"
FreekingDean/home-assistant,"""""""Test the MyQ config flow.""""""
from unittest.mock import patch

from pymyq.errors import InvalidCredentialsError, MyQError

from homeassistant import config_entries, setup
from homeassistant.components.myq.const import DOMAIN
from homeassistant.const import CONF_PASSWORD, CONF_USERNAME

from tests.common import MockConfigEntry


async def test_form_user(hass):
    """"""Test we get the user form.""""""
    await setup.async_setup_component(hass, ""persistent_notification"", {})
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    assert result[""type""] == ""form""
    assert result[""errors""] == {}

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        return_value=True,
    ), patch(
        ""homeassistant.components.myq.async_setup_entry"",
        return_value=True,
    ) as mock_setup_entry:
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {""username"": ""test-username"", ""password"": ""test-password""},
        )
        await hass.async_block_till_done()

    assert result2[""type""] == ""create_entry""
    assert result2[""title""] == ""test-username""
    assert result2[""data""] == {
        ""username"": ""test-username"",
        ""password"": ""test-password"",
    }
    assert len(mock_setup_entry.mock_calls) == 1


async def test_form_invalid_auth(hass):
    """"""Test we handle invalid auth.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        side_effect=InvalidCredentialsError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {""username"": ""test-username"", ""password"": ""test-password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""password"": ""invalid_auth""}


async def test_form_cannot_connect(hass):
    """"""Test we handle cannot connect error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        side_effect=MyQError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {""username"": ""test-username"", ""password"": ""test-password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""cannot_connect""}


async def test_form_unknown_exception(hass):
    """"""Test we handle unknown exceptions.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        side_effect=Exception,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {""username"": ""test-username"", ""password"": ""test-password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""unknown""}


async def test_reauth(hass):
    """"""Test we can reauth.""""""
    entry = MockConfigEntry(
        domain=DOMAIN,
        data={
            CONF_USERNAME: ""test@test.org"",
            CONF_PASSWORD: ""secret"",
        },
        unique_id=""test@test.org"",
    )
    entry.add_to_hass(hass)

    result = await hass.config_entries.flow.async_init(
        DOMAIN,
        context={""source"": config_entries.SOURCE_REAUTH, ""unique_id"": ""test@test.org""},
    )

    assert result[""type""] == ""form""
    assert result[""step_id""] == ""reauth_confirm""

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        side_effect=InvalidCredentialsError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                CONF_PASSWORD: ""test-password"",
            },
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""password"": ""invalid_auth""}

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        side_effect=MyQError,
    ):
        result3 = await hass.config_entries.flow.async_configure(
            result2[""flow_id""],
            {
                CONF_PASSWORD: ""test-password"",
            },
        )

    assert result3[""type""] == ""form""
    assert result3[""errors""] == {""base"": ""cannot_connect""}

    with patch(
        ""homeassistant.components.myq.config_flow.pymyq.login"",
        return_value=True,
    ), patch(
        ""homeassistant.components.myq.async_setup_entry"",
        return_value=True,
    ) as mock_setup_entry:
        result4 = await hass.config_entries.flow.async_configure(
            result3[""flow_id""],
            {
                CONF_PASSWORD: ""test-password"",
            },
        )

    assert mock_setup_entry.called
    assert result4[""type""] == ""abort""
    assert result4[""reason""] == ""reauth_successful""
","
1""""""Test the MyQ config flow.""""""
2from unittest.mock import patch
3
4from pymyq.errors import InvalidCredentialsError, MyQError
5
6from homeassistant import config_entries, setup
7from homeassistant.components.myq.const import DOMAIN
8from homeassistant.const import CONF_PASSWORD, CONF_USERNAME
9
10from tests.common import MockConfigEntry
11
12
13async def test_form_user(hass):
14    """"""Test we get the user form.""""""
15    await setup.async_setup_component(hass, ""persistent_notification"", {})
16    result = await hass.config_entries.flow.async_init(
17        DOMAIN, context={""source"": config_entries.SOURCE_USER}
18    )
19
20    with patch(
21        ""homeassistant.components.myq.config_flow.pymyq.login"",
22        return_value=True,
23    ), patch(
24        ""homeassistant.components.myq.async_setup_entry"",
25        return_value=True,
26    ) as mock_setup_entry:
27        result2 = await hass.config_entries.flow.async_configure(
28            result[""flow_id""],
29            {""username"": ""test-username"", ""password"": ""test-password""},
30        )
31        await hass.async_block_till_done()
32
33        ""username"": ""test-username"",
34        ""password"": ""test-password"",
35    }
36
37
38async def test_form_invalid_auth(hass):
39    """"""Test we handle invalid auth.""""""
40    result = await hass.config_entries.flow.async_init(
41        DOMAIN, context={""source"": config_entries.SOURCE_USER}
42    )
43
44    with patch(
45        ""homeassistant.components.myq.config_flow.pymyq.login"",
46        side_effect=InvalidCredentialsError,
47    ):
48        result2 = await hass.config_entries.flow.async_configure(
49            result[""flow_id""],
50            {""username"": ""test-username"", ""password"": ""test-password""},
51        )
52
53
54
55async def test_form_cannot_connect(hass):
56    """"""Test we handle cannot connect error.""""""
57    result = await hass.config_entries.flow.async_init(
58        DOMAIN, context={""source"": config_entries.SOURCE_USER}
59    )
60
61    with patch(
62        ""homeassistant.components.myq.config_flow.pymyq.login"",
63        side_effect=MyQError,
64    ):
65        result2 = await hass.config_entries.flow.async_configure(
66            result[""flow_id""],
67            {""username"": ""test-username"", ""password"": ""test-password""},
68        )
69
70
71
72async def test_form_unknown_exception(hass):
73    """"""Test we handle unknown exceptions.""""""
74    result = await hass.config_entries.flow.async_init(
75        DOMAIN, context={""source"": config_entries.SOURCE_USER}
76    )
77
78    with patch(
79        ""homeassistant.components.myq.config_flow.pymyq.login"",
80        side_effect=Exception,
81    ):
82        result2 = await hass.config_entries.flow.async_configure(
83            result[""flow_id""],
84            {""username"": ""test-username"", ""password"": ""test-password""},
85        )
86
87
88
89async def test_reauth(hass):
90    """"""Test we can reauth.""""""
91    entry = MockConfigEntry(
92        domain=DOMAIN,
93        data={
94            CONF_USERNAME: ""test@test.org"",
95            CONF_PASSWORD: ""secret"",
96        },
97        unique_id=""test@test.org"",
98    )
99    entry.add_to_hass(hass)
100
101    result = await hass.config_entries.flow.async_init(
102        DOMAIN,
103        context={""source"": config_entries.SOURCE_REAUTH, ""unique_id"": ""test@test.org""},
104    )
105
106
107    with patch(
108        ""homeassistant.components.myq.config_flow.pymyq.login"",
109        side_effect=InvalidCredentialsError,
110    ):
111        result2 = await hass.config_entries.flow.async_configure(
112            result[""flow_id""],
113            {
114                CONF_PASSWORD: ""test-password"",
115            },
116        )
117
118
119    with patch(
120        ""homeassistant.components.myq.config_flow.pymyq.login"",
121        side_effect=MyQError,
122    ):
123        result3 = await hass.config_entries.flow.async_configure(
124            result2[""flow_id""],
125            {
126                CONF_PASSWORD: ""test-password"",
127            },
128        )
129
130
131    with patch(
132        ""homeassistant.components.myq.config_flow.pymyq.login"",
133        return_value=True,
134    ), patch(
135        ""homeassistant.components.myq.async_setup_entry"",
136        return_value=True,
137    ) as mock_setup_entry:
138        result4 = await hass.config_entries.flow.async_configure(
139            result3[""flow_id""],
140            {
141                CONF_PASSWORD: ""test-password"",
142            },
143        )
144
145","[['result[""type""]', '==', '""form""'], ['result[""errors""]', '==', '{}'], ['result2[""type""]', '==', '""create_entry""'], ['result2[""title""]', '==', '""test-username""'], ['result2[""data""]', '==', '{'], ['len(mock_setup_entry.mock_calls)', '==', '1'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""password"": ""invalid_auth""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""unknown""}'], ['result[""type""]', '==', '""form""'], ['result[""step_id""]', '==', '""reauth_confirm""'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""password"": ""invalid_auth""}'], ['result3[""type""]', '==', '""form""'], ['result3[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['mock_setup_entry.called', '==', 'True'], ['result4[""type""]', '==', '""abort""'], ['result4[""reason""]', '==', '""reauth_successful""']]",21,21,1.0,0.0041047693510555,"['hass', 'result', 'result2', 'entry', 'result3', 'result4']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'result', 'result2', 'entry', 'result3', 'result4']
*Code:

1""""""Test the MyQ config flow.""""""
2from unittest.mock import patch
3
4from pymyq.errors import InvalidCredentialsError, MyQError
5
6from homeassistant import config_entries, setup
7from homeassistant.components.myq.const import DOMAIN
8from homeassistant.const import CONF_PASSWORD, CONF_USERNAME
9
10from tests.common import MockConfigEntry
11
12
13async def test_form_user(hass):
14    """"""Test we get the user form.""""""
15    await setup.async_setup_component(hass, ""persistent_notification"", {})
16    result = await hass.config_entries.flow.async_init(
17        DOMAIN, context={""source"": config_entries.SOURCE_USER}
18    )
19
20    with patch(
21        ""homeassistant.components.myq.config_flow.pymyq.login"",
22        return_value=True,
23    ), patch(
24        ""homeassistant.components.myq.async_setup_entry"",
25        return_value=True,
26    ) as mock_setup_entry:
27        result2 = await hass.config_entries.flow.async_configure(
28            result[""flow_id""],
29            {""username"": ""test-username"", ""password"": ""test-password""},
30        )
31        await hass.async_block_till_done()
32
33        ""username"": ""test-username"",
34        ""password"": ""test-password"",
35    }
36
37
38async def test_form_invalid_auth(hass):
39    """"""Test we handle invalid auth.""""""
40    result = await hass.config_entries.flow.async_init(
41        DOMAIN, context={""source"": config_entries.SOURCE_USER}
42    )
43
44    with patch(
45        ""homeassistant.components.myq.config_flow.pymyq.login"",
46        side_effect=InvalidCredentialsError,
47    ):
48        result2 = await hass.config_entries.flow.async_configure(
49            result[""flow_id""],
50            {""username"": ""test-username"", ""password"": ""test-password""},
51        )
52
53
54
55async def test_form_cannot_connect(hass):
56    """"""Test we handle cannot connect error.""""""
57    result = await hass.config_entries.flow.async_init(
58        DOMAIN, context={""source"": config_entries.SOURCE_USER}
59    )
60
61    with patch(
62        ""homeassistant.components.myq.config_flow.pymyq.login"",
63        side_effect=MyQError,
64    ):
65        result2 = await hass.config_entries.flow.async_configure(
66            result[""flow_id""],
67            {""username"": ""test-username"", ""password"": ""test-password""},
68        )
69
70
71
72async def test_form_unknown_exception(hass):
73    """"""Test we handle unknown exceptions.""""""
74    result = await hass.config_entries.flow.async_init(
75        DOMAIN, context={""source"": config_entries.SOURCE_USER}
76    )
77
78    with patch(
79        ""homeassistant.components.myq.config_flow.pymyq.login"",
80        side_effect=Exception,
81    ):
82        result2 = await hass.config_entries.flow.async_configure(
83            result[""flow_id""],
84            {""username"": ""test-username"", ""password"": ""test-password""},
85        )
86
87
88
89async def test_reauth(hass):
90    """"""Test we can reauth.""""""
91    entry = MockConfigEntry(
92        domain=DOMAIN,
93        data={
94            CONF_USERNAME: ""test@test.org"",
95            CONF_PASSWORD: ""secret"",
96        },
97        unique_id=""test@test.org"",
98    )
99    entry.add_to_hass(hass)
100
101    result = await hass.config_entries.flow.async_init(
102        DOMAIN,
103        context={""source"": config_entries.SOURCE_REAUTH, ""unique_id"": ""test@test.org""},
104    )
105
106
107    with patch(
108        ""homeassistant.components.myq.config_flow.pymyq.login"",
109        side_effect=InvalidCredentialsError,
110    ):
111        result2 = await hass.config_entries.flow.async_configure(
112            result[""flow_id""],
113            {
114                CONF_PASSWORD: ""test-password"",
115            },
116        )
117
118
119    with patch(
120        ""homeassistant.components.myq.config_flow.pymyq.login"",
121        side_effect=MyQError,
122    ):
123        result3 = await hass.config_entries.flow.async_configure(
124            result2[""flow_id""],
125            {
126                CONF_PASSWORD: ""test-password"",
127            },
128        )
129
130
131    with patch(
132        ""homeassistant.components.myq.config_flow.pymyq.login"",
133        return_value=True,
134    ), patch(
135        ""homeassistant.components.myq.async_setup_entry"",
136        return_value=True,
137    ) as mock_setup_entry:
138        result4 = await hass.config_entries.flow.async_configure(
139            result3[""flow_id""],
140            {
141                CONF_PASSWORD: ""test-password"",
142            },
143        )
144
145",5954,"[[13, 'hass', '!=', None, 'hass object must be initialized'],
[16, 'result', '!=', None, 'Result should be received after async init'],
[27, 'result2', '!=', None, 'Result2 should be received after async configure'],
[38, 'hass', '!=', None, 'hass object must be initialized'],
[40, 'result', '!=', None, 'Result should be received after async init'],
[48, 'result2', '!=', None, 'Result2 should be received after async configure'],
[55, 'hass', '!=', None, 'hass object must be initialized'],
[57, 'result', '!=', None, 'Result should be received after async init'],
[65, 'result2', '!=', None, 'Result2 should be received after async configure'],
[72, 'hass', '!=', None, 'hass object must be initialized'],
[74, 'result', '!=', None, 'Result should be received after async init'],
[82, 'result2', '!=', None, 'Result2 should be received after async configure'],
[89, 'hass', '!=', None, 'hass object must be initialized'],
[99, 'entry', '!=', None, 'Entry object should be initialized'],
[101, 'result', '!=', None, 'Result should be received after async init'],
[111, 'result2', '!=', None, 'Result2 should be received after async configure'],
[123, 'result3', '==', None, 'Result3 should be None in case of MyQError'],
[138, 'result4', '!=', None, 'Result4 should be received after async configure']]"
mesosphere-mergebot/dcos,"import subprocess

import pytest

__maintainer__ = 'vespian'
__contact__ = 'dcos-security@mesosphere.io'


def auth_enabled():
    out = subprocess.check_output([
        '/bin/bash', '-c',
        'source /opt/mesosphere/etc/adminrouter.env && echo $ADMINROUTER_ACTIVATE_AUTH_MODULE']).\
        decode().strip('\n')
    assert out in ['true', 'false'], 'Unknown ADMINROUTER_ACTIVATE_AUTH_MODULE state: {}'.format(out)
    return out == 'true'


def test_adminrouter_access_control_enforcement(dcos_api_session, noauth_api_session):
    reason = 'Can only test adminrouter enforcement if auth is enabled'
    if not auth_enabled():
        pytest.skip(reason)
    r = noauth_api_session.get('/acs/api/v1')
    assert r.status_code == 401
    assert r.headers['WWW-Authenticate'] in ('acsjwt', 'oauthjwt')
    # Make sure that this is UI's error page body,
    # including some JavaScript.
    assert '<html>' in r.text
    assert '</html>' in r.text
    assert 'window.location' in r.text
    # Verify that certain locations are forbidden to access
    # when not authed, but are reachable as superuser.
    for path in ('/mesos_dns/v1/config', '/service/marathon/', '/mesos/'):
        r = noauth_api_session.get(path)
        assert r.status_code == 401
        r = dcos_api_session.get(path)
        assert r.status_code == 200

    # Test authentication with auth cookie instead of Authorization header.
    authcookie = {
        'dcos-acs-auth-cookie': dcos_api_session.auth_user.auth_cookie}
    r = noauth_api_session.get(
        '/service/marathon/',
        cookies=authcookie)
    assert r.status_code == 200


@pytest.mark.supportedwindows
def test_logout(dcos_api_session):
    """"""Test logout endpoint. It's a soft logout, instructing
    the user agent to delete the authentication cookie, i.e. this test
    does not have side effects on other tests.
    """"""
    r = dcos_api_session.get('/acs/api/v1/auth/logout')
    cookieheader = r.headers['set-cookie']
    assert 'dcos-acs-auth-cookie=;' in cookieheader or 'dcos-acs-auth-cookie="""";' in cookieheader
    assert 'expires' in cookieheader.lower()
","
1import subprocess
2
3import pytest
4
5__maintainer__ = 'vespian'
6__contact__ = 'dcos-security@mesosphere.io'
7
8
9def auth_enabled():
10    out = subprocess.check_output([
11        '/bin/bash', '-c',
12        'source /opt/mesosphere/etc/adminrouter.env && echo $ADMINROUTER_ACTIVATE_AUTH_MODULE']).\
13        decode().strip('\n')
14    return out == 'true'
15
16
17def test_adminrouter_access_control_enforcement(dcos_api_session, noauth_api_session):
18    reason = 'Can only test adminrouter enforcement if auth is enabled'
19    if not auth_enabled():
20        pytest.skip(reason)
21    r = noauth_api_session.get('/acs/api/v1')
22    # Make sure that this is UI's error page body,
23    # including some JavaScript.
24    # Verify that certain locations are forbidden to access
25    # when not authed, but are reachable as superuser.
26    for path in ('/mesos_dns/v1/config', '/service/marathon/', '/mesos/'):
27        r = noauth_api_session.get(path)
28        r = dcos_api_session.get(path)
29
30    # Test authentication with auth cookie instead of Authorization header.
31    authcookie = {
32        'dcos-acs-auth-cookie': dcos_api_session.auth_user.auth_cookie}
33    r = noauth_api_session.get(
34        '/service/marathon/',
35        cookies=authcookie)
36
37
38@pytest.mark.supportedwindows
39def test_logout(dcos_api_session):
40    """"""Test logout endpoint. It's a soft logout, instructing
41    the user agent to delete the authentication cookie, i.e. this test
42    does not have side effects on other tests.
43    """"""
44    r = dcos_api_session.get('/acs/api/v1/auth/logout')
45    cookieheader = r.headers['set-cookie']
46","[['r.status_code', '==', '401'], ['r.status_code', '==', '401'], ['r.status_code', '==', '200'], ['r.status_code', '==', '200']]",11,4,0.3636363636363636,0.0018885741265344,"['__maintainer__', '__contact__', 'out', 'dcos_api_session', 'noauth_api_session', 'reason', 'r', 'authcookie', 'cookieheader']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__maintainer__', '__contact__', 'out', 'dcos_api_session', 'noauth_api_session', 'reason', 'r', 'authcookie', 'cookieheader']
*Code:

1import subprocess
2
3import pytest
4
5__maintainer__ = 'vespian'
6__contact__ = 'dcos-security@mesosphere.io'
7
8
9def auth_enabled():
10    out = subprocess.check_output([
11        '/bin/bash', '-c',
12        'source /opt/mesosphere/etc/adminrouter.env && echo $ADMINROUTER_ACTIVATE_AUTH_MODULE']).\
13        decode().strip('\n')
14    return out == 'true'
15
16
17def test_adminrouter_access_control_enforcement(dcos_api_session, noauth_api_session):
18    reason = 'Can only test adminrouter enforcement if auth is enabled'
19    if not auth_enabled():
20        pytest.skip(reason)
21    r = noauth_api_session.get('/acs/api/v1')
22    # Make sure that this is UI's error page body,
23    # including some JavaScript.
24    # Verify that certain locations are forbidden to access
25    # when not authed, but are reachable as superuser.
26    for path in ('/mesos_dns/v1/config', '/service/marathon/', '/mesos/'):
27        r = noauth_api_session.get(path)
28        r = dcos_api_session.get(path)
29
30    # Test authentication with auth cookie instead of Authorization header.
31    authcookie = {
32        'dcos-acs-auth-cookie': dcos_api_session.auth_user.auth_cookie}
33    r = noauth_api_session.get(
34        '/service/marathon/',
35        cookies=authcookie)
36
37
38@pytest.mark.supportedwindows
39def test_logout(dcos_api_session):
40    """"""Test logout endpoint. It's a soft logout, instructing
41    the user agent to delete the authentication cookie, i.e. this test
42    does not have side effects on other tests.
43    """"""
44    r = dcos_api_session.get('/acs/api/v1/auth/logout')
45    cookieheader = r.headers['set-cookie']
46",3161,"[[9, 'out', '==', 'true', ""auth_enabled() should only return 'true'""], 
[17, 'dcos_api_session', '!=', None, ""dcos_api_session parameter should not be None""],
[17, 'noauth_api_session', '!=', None, ""noauth_api_session parameter should not be None""], 
[26, 'r', '!=', None, ""'r' should always hold a value""], 
[31, 'authcookie', '!=', None, ""authcookie should not be None""], 
[39, 'dcos_api_session', '!=', None, ""dcos_api_session parameter should not be None""],
[45, 'cookieheader', '!=', None, ""cookieheader should be defined""]]"
Joergen/zamboni,"from mock import Mock
from nose.tools import eq_
from pyquery import PyQuery

import amo
import amo.tests
from addons.helpers import (statusflags, flag, contribution, performance_note,
                            mobile_persona_preview, mobile_persona_confirm)
from addons.models import Addon


class TestHelpers(amo.tests.TestCase):
    fixtures = ['base/addon_3615', 'base/users',
                'addons/featured', 'base/collections',
                'base/featured', 'bandwagon/featured_collections']

    def test_statusflags(self):
        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}

        # unreviewed
        a = Addon(status=amo.STATUS_UNREVIEWED)
        eq_(statusflags(ctx, a), 'unreviewed')

        # recommended
        featured = Addon.objects.get(pk=1003)
        eq_(statusflags(ctx, featured), 'featuredaddon')

        # category featured
        featured = Addon.objects.get(pk=1001)
        eq_(statusflags(ctx, featured), 'featuredaddon')

    def test_flags(self):
        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}

        # unreviewed
        a = Addon(status=amo.STATUS_UNREVIEWED)
        eq_(flag(ctx, a), '<h5 class=""flag"">Not Reviewed</h5>')

        # recommended
        featured = Addon.objects.get(pk=1003)
        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')

        # category featured
        featured = Addon.objects.get(pk=1001)
        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')

    def test_contribution_box(self):
        a = Addon.objects.get(pk=7661)
        a.suggested_amount = '12'

        settings = Mock()
        settings.MAX_CONTRIBUTION = 5

        request = Mock()
        request.GET = {'src': 'direct'}

        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
             'request': request}

        s = contribution(c, a)
        doc = PyQuery(s)
        # make sure input boxes are rendered correctly (bug 555867)
        assert doc('input[name=onetime-amount]').length == 1

    def test_src_retained(self):
        a = Addon.objects.get(pk=7661)
        a.suggested_amount = '12'

        settings = Mock()
        settings.MAX_CONTRIBUTION = 5

        request = Mock()

        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
             'request': request}

        s = contribution(c, a, contribution_src='browse')
        doc = PyQuery(s)
        eq_(doc('input[name=source]').attr('value'), 'browse')

    def test_mobile_persona_preview(self):
        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
        persona = Addon.objects.get(pk=15679).persona
        s = mobile_persona_preview(ctx, persona)
        doc = PyQuery(s)
        bt = doc('.persona-preview div[data-browsertheme]')
        assert bt
        assert persona.preview_url in bt.attr('style')
        eq_(persona.json_data, bt.attr('data-browsertheme'))
        assert bt.find('p')

    def _test_mobile_persona_ctx(self):
        request = Mock()
        request.APP = amo.FIREFOX
        request.GET = {}
        request.user.is_authenticated.return_value = False
        request.amo_user.mobile_addons = []
        return {'APP': amo.FIREFOX, 'LANG': 'en-US', 'request': request}

    def test_mobile_persona_confirm_large(self):
        persona = Addon.objects.get(id=15679).persona
        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona)
        doc = PyQuery(s)
        assert not doc('.persona-slider')
        assert doc('.preview')
        assert doc('.confirm-buttons .add')
        assert doc('.confirm-buttons .cancel')
        assert not doc('.more')

    def test_mobile_persona_confirm_small(self):
        persona = Addon.objects.get(id=15679).persona
        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona,
                                   size='small')
        doc = PyQuery(s)
        assert doc('.persona-slider')
        assert not doc('.persona-slider .preview')
        assert doc('.confirm-buttons .add')
        assert doc('.confirm-buttons .cancel')
        more = doc('.more')
        assert more
        eq_(more.attr('href'), persona.addon.get_url_path())


class TestPerformanceNote(amo.tests.TestCase):
    listing = '<div class=""performance-note"">'
    not_listing = '<div class=""notification performance-note"">'

    def setUp(self):
        request_mock = Mock()
        request_mock.APP = amo.FIREFOX
        self.ctx = {'request': request_mock, 'amo': amo}

    def test_show_listing(self):
        r = performance_note(self.ctx, 30, listing=True)
        assert self.listing in r, r

    def test_show_not_listing(self):
        r = performance_note(self.ctx, 30)
        assert self.not_listing in r, r

    def test_only_fx(self):
        self.ctx['request'].APP = amo.THUNDERBIRD
        r = performance_note(self.ctx, 30)
        eq_(r.strip(), '')
","
1from mock import Mock
2from nose.tools import eq_
3from pyquery import PyQuery
4
5import amo
6import amo.tests
7from addons.helpers import (statusflags, flag, contribution, performance_note,
8                            mobile_persona_preview, mobile_persona_confirm)
9from addons.models import Addon
10
11
12class TestHelpers(amo.tests.TestCase):
13    fixtures = ['base/addon_3615', 'base/users',
14                'addons/featured', 'base/collections',
15                'base/featured', 'bandwagon/featured_collections']
16
17    def test_statusflags(self):
18        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
19
20        # unreviewed
21        a = Addon(status=amo.STATUS_UNREVIEWED)
22        eq_(statusflags(ctx, a), 'unreviewed')
23
24        # recommended
25        featured = Addon.objects.get(pk=1003)
26        eq_(statusflags(ctx, featured), 'featuredaddon')
27
28        # category featured
29        featured = Addon.objects.get(pk=1001)
30        eq_(statusflags(ctx, featured), 'featuredaddon')
31
32    def test_flags(self):
33        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
34
35        # unreviewed
36        a = Addon(status=amo.STATUS_UNREVIEWED)
37        eq_(flag(ctx, a), '<h5 class=""flag"">Not Reviewed</h5>')
38
39        # recommended
40        featured = Addon.objects.get(pk=1003)
41        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')
42
43        # category featured
44        featured = Addon.objects.get(pk=1001)
45        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')
46
47    def test_contribution_box(self):
48        a = Addon.objects.get(pk=7661)
49        a.suggested_amount = '12'
50
51        settings = Mock()
52        settings.MAX_CONTRIBUTION = 5
53
54        request = Mock()
55        request.GET = {'src': 'direct'}
56
57        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
58             'request': request}
59
60        s = contribution(c, a)
61        doc = PyQuery(s)
62        # make sure input boxes are rendered correctly (bug 555867)
63
64    def test_src_retained(self):
65        a = Addon.objects.get(pk=7661)
66        a.suggested_amount = '12'
67
68        settings = Mock()
69        settings.MAX_CONTRIBUTION = 5
70
71        request = Mock()
72
73        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
74             'request': request}
75
76        s = contribution(c, a, contribution_src='browse')
77        doc = PyQuery(s)
78        eq_(doc('input[name=source]').attr('value'), 'browse')
79
80    def test_mobile_persona_preview(self):
81        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
82        persona = Addon.objects.get(pk=15679).persona
83        s = mobile_persona_preview(ctx, persona)
84        doc = PyQuery(s)
85        bt = doc('.persona-preview div[data-browsertheme]')
86        eq_(persona.json_data, bt.attr('data-browsertheme'))
87
88    def _test_mobile_persona_ctx(self):
89        request = Mock()
90        request.APP = amo.FIREFOX
91        request.GET = {}
92        request.user.is_authenticated.return_value = False
93        request.amo_user.mobile_addons = []
94        return {'APP': amo.FIREFOX, 'LANG': 'en-US', 'request': request}
95
96    def test_mobile_persona_confirm_large(self):
97        persona = Addon.objects.get(id=15679).persona
98        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona)
99        doc = PyQuery(s)
100
101    def test_mobile_persona_confirm_small(self):
102        persona = Addon.objects.get(id=15679).persona
103        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona,
104                                   size='small')
105        doc = PyQuery(s)
106        more = doc('.more')
107        eq_(more.attr('href'), persona.addon.get_url_path())
108
109
110class TestPerformanceNote(amo.tests.TestCase):
111    listing = '<div class=""performance-note"">'
112    not_listing = '<div class=""notification performance-note"">'
113
114    def setUp(self):
115        request_mock = Mock()
116        request_mock.APP = amo.FIREFOX
117        self.ctx = {'request': request_mock, 'amo': amo}
118
119    def test_show_listing(self):
120        r = performance_note(self.ctx, 30, listing=True)
121
122    def test_show_not_listing(self):
123        r = performance_note(self.ctx, 30)
124
125    def test_only_fx(self):
126        self.ctx['request'].APP = amo.THUNDERBIRD
127        r = performance_note(self.ctx, 30)
128        eq_(r.strip(), '')
129","[[""doc('input[name=onetime-amount]').length"", '==', '1'], ['bt', '==', 'True'], [""bt.find('p')"", '==', 'True'], [""doc('.persona-slider')"", '==', 'False'], [""doc('.preview')"", '==', 'True'], [""doc('.confirm-buttons"", "".add')""], [""doc('.confirm-buttons"", "".cancel')""], [""doc('.more')"", '==', 'False'], [""doc('.persona-slider')"", '==', 'True'], [""doc('.persona-slider"", "".preview')""], [""doc('.confirm-buttons"", "".add')""], [""doc('.confirm-buttons"", "".cancel')""], ['more', '==', 'True']]",16,13,0.8125,0.002686505476338,"['fixtures', 'ctx', 'a', 'featured', 'a.suggested_amount', 'settings', 'settings.MAX_CONTRIBUTION', 'request', 'request.GET', 'c', 's', 'doc', 'persona', 'bt', 'request.APP', 'request.user.is_authenticated.return_value', 'request.amo_user.mobile_addons', 'more', 'listing', 'not_listing', 'request_mock', 'request_mock.APP', 'self.ctx', 'r', ""self.ctx['request'].APP""]",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['fixtures', 'ctx', 'a', 'featured', 'a.suggested_amount', 'settings', 'settings.MAX_CONTRIBUTION', 'request', 'request.GET', 'c', 's', 'doc', 'persona', 'bt', 'request.APP', 'request.user.is_authenticated.return_value', 'request.amo_user.mobile_addons', 'more', 'listing', 'not_listing', 'request_mock', 'request_mock.APP', 'self.ctx', 'r', ""self.ctx['request'].APP""]
*Code:

1from mock import Mock
2from nose.tools import eq_
3from pyquery import PyQuery
4
5import amo
6import amo.tests
7from addons.helpers import (statusflags, flag, contribution, performance_note,
8                            mobile_persona_preview, mobile_persona_confirm)
9from addons.models import Addon
10
11
12class TestHelpers(amo.tests.TestCase):
13    fixtures = ['base/addon_3615', 'base/users',
14                'addons/featured', 'base/collections',
15                'base/featured', 'bandwagon/featured_collections']
16
17    def test_statusflags(self):
18        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
19
20        # unreviewed
21        a = Addon(status=amo.STATUS_UNREVIEWED)
22        eq_(statusflags(ctx, a), 'unreviewed')
23
24        # recommended
25        featured = Addon.objects.get(pk=1003)
26        eq_(statusflags(ctx, featured), 'featuredaddon')
27
28        # category featured
29        featured = Addon.objects.get(pk=1001)
30        eq_(statusflags(ctx, featured), 'featuredaddon')
31
32    def test_flags(self):
33        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
34
35        # unreviewed
36        a = Addon(status=amo.STATUS_UNREVIEWED)
37        eq_(flag(ctx, a), '<h5 class=""flag"">Not Reviewed</h5>')
38
39        # recommended
40        featured = Addon.objects.get(pk=1003)
41        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')
42
43        # category featured
44        featured = Addon.objects.get(pk=1001)
45        eq_(flag(ctx, featured), '<h5 class=""flag"">Featured</h5>')
46
47    def test_contribution_box(self):
48        a = Addon.objects.get(pk=7661)
49        a.suggested_amount = '12'
50
51        settings = Mock()
52        settings.MAX_CONTRIBUTION = 5
53
54        request = Mock()
55        request.GET = {'src': 'direct'}
56
57        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
58             'request': request}
59
60        s = contribution(c, a)
61        doc = PyQuery(s)
62        # make sure input boxes are rendered correctly (bug 555867)
63
64    def test_src_retained(self):
65        a = Addon.objects.get(pk=7661)
66        a.suggested_amount = '12'
67
68        settings = Mock()
69        settings.MAX_CONTRIBUTION = 5
70
71        request = Mock()
72
73        c = {'LANG': 'en-us', 'APP': amo.FIREFOX, 'settings': settings,
74             'request': request}
75
76        s = contribution(c, a, contribution_src='browse')
77        doc = PyQuery(s)
78        eq_(doc('input[name=source]').attr('value'), 'browse')
79
80    def test_mobile_persona_preview(self):
81        ctx = {'APP': amo.FIREFOX, 'LANG': 'en-US'}
82        persona = Addon.objects.get(pk=15679).persona
83        s = mobile_persona_preview(ctx, persona)
84        doc = PyQuery(s)
85        bt = doc('.persona-preview div[data-browsertheme]')
86        eq_(persona.json_data, bt.attr('data-browsertheme'))
87
88    def _test_mobile_persona_ctx(self):
89        request = Mock()
90        request.APP = amo.FIREFOX
91        request.GET = {}
92        request.user.is_authenticated.return_value = False
93        request.amo_user.mobile_addons = []
94        return {'APP': amo.FIREFOX, 'LANG': 'en-US', 'request': request}
95
96    def test_mobile_persona_confirm_large(self):
97        persona = Addon.objects.get(id=15679).persona
98        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona)
99        doc = PyQuery(s)
100
101    def test_mobile_persona_confirm_small(self):
102        persona = Addon.objects.get(id=15679).persona
103        s = mobile_persona_confirm(self._test_mobile_persona_ctx(), persona,
104                                   size='small')
105        doc = PyQuery(s)
106        more = doc('.more')
107        eq_(more.attr('href'), persona.addon.get_url_path())
108
109
110class TestPerformanceNote(amo.tests.TestCase):
111    listing = '<div class=""performance-note"">'
112    not_listing = '<div class=""notification performance-note"">'
113
114    def setUp(self):
115        request_mock = Mock()
116        request_mock.APP = amo.FIREFOX
117        self.ctx = {'request': request_mock, 'amo': amo}
118
119    def test_show_listing(self):
120        r = performance_note(self.ctx, 30, listing=True)
121
122    def test_show_not_listing(self):
123        r = performance_note(self.ctx, 30)
124
125    def test_only_fx(self):
126        self.ctx['request'].APP = amo.THUNDERBIRD
127        r = performance_note(self.ctx, 30)
128        eq_(r.strip(), '')
129",6233,"[[17, 'ctx', '!=', None, ""Context 'ctx' needs to be defined for function 'test_statusflags'""],
[21, 'a', '!=', None, ""Addon 'a' needs to be defined""],
[25, 'featured', '!=', None, ""'featured' Addon needs to be defined""],
[33, 'ctx', '!=', None, ""Context 'ctx' needs to be defined for function 'test_flags'""],
[36, 'a', '!=', None, ""Addon 'a' needs to be defined""],
[40, 'featured', '!=', None, ""'featured' Addon needs to be defined""],
[48, 'a', '!=', None, ""Addon 'a' needs to be defined for function 'test_contribution_box'""],
[51, 'settings', '!=', None, ""Settings needs to be defined""],
[54, 'request', '!=', None, ""Request needs to be defined""],
[81, 'ctx', '!=', None, ""Context 'ctx' needs to be defined for function 'test_mobile_persona_preview'""],
[82, 'persona', '!=', None, ""Persona needs to be defined""],
[89, 'request', '!=', None, ""Request needs to be defined for function '_test_mobile_persona_ctx'""],
[97, 'persona', '!=', None, ""Persona needs to be defined for function 'test_mobile_persona_confirm_large'""],
[102, 'persona', '!=', None, ""Persona needs to be defined for function 'test_mobile_persona_confirm_small'""],
[115, 'request_mock', '!=', None, ""'request_mock' needs to be defined for function 'setUp'""],
[117, 'self.ctx', '!=', None, ""Context needs to be defined""],
[120, 'r', '!=', None, ""'r' needs to be defined for function 'test_show_listing'""],
[123, 'r', '!=', None, ""'r' needs to be defined for function 'test_show_not_listing'""],
[127, 'r', '!=', None, ""'r' needs to be defined for function 'test_only_fx'""]]"
kaichogami/sympy,"# -*- coding: utf-8 -*-

from __future__ import division

from sympy.physics.unitsystems.quantities import Quantity
from sympy.physics.unitsystems.units import Unit
from sympy.physics.unitsystems.prefixes import PREFIXES
from sympy.physics.unitsystems.systems import mks
from sympy.utilities.pytest import raises

m, s, c = mks[""m""], mks[""s""], mks[""c""]
k = PREFIXES[""k""]


def test_definition():
    q = Quantity(10, s)

    assert q.factor == 10
    assert q.unit == s

    assert Quantity(10) == 10


def test_error_definition():
    raises(NotImplementedError, lambda: Quantity(""10 m""))
    raises(TypeError, lambda: Quantity(10, m.dim))


def test_str_repr():
    q = Quantity(10, m)

    assert str(q) == ""%g %s"" % (10, str(m))
    assert repr(q) == ""%g %s"" % (10, repr(m))


def test_eq():
    # stupid test
    assert (Quantity(10, m) == Quantity(10, m)) is True
    assert (Quantity(10, m) == Quantity(10, s)) is False


def test_operations():
    q = Quantity(10, m)
    p = Quantity(5, s)

    assert -q == Quantity(-10, m)

    assert q.add(Quantity(20, m)) == Quantity(30, m)
    assert q.add(Quantity(20, Unit(m.dim, 10))) == Quantity(30, Unit(m.dim, 11))

    assert q.sub(Quantity(20, m)) == Quantity(-10, m)
    assert q.sub(Quantity(20, Unit(m.dim, 10))) == Quantity(-10, Unit(m.dim, -9))

    assert q.pow(2) == Quantity(10**2, m.pow(2))

    assert q.mul(p) == Quantity(5*10, m.mul(s))

    assert q.div(p) == Quantity(10/5, m.div(s))


def test_error_operations():
    q = Quantity(10, m)
    p = Quantity(5, s)

    raises(ValueError, lambda: q.add(p))
    raises(TypeError, lambda: q.add(1))

    raises(ValueError, lambda: q.sub(p))
    raises(TypeError, lambda: q.sub(1))


def test_convert_to():
    q = Quantity(5, Unit(m.dim, prefix=k))
    assert q.convert_to(m) == Quantity(5000, m)
","
1# -*- coding: utf-8 -*-
2
3from __future__ import division
4
5from sympy.physics.unitsystems.quantities import Quantity
6from sympy.physics.unitsystems.units import Unit
7from sympy.physics.unitsystems.prefixes import PREFIXES
8from sympy.physics.unitsystems.systems import mks
9from sympy.utilities.pytest import raises
10
11m, s, c = mks[""m""], mks[""s""], mks[""c""]
12k = PREFIXES[""k""]
13
14
15def test_definition():
16    q = Quantity(10, s)
17
18
19
20
21def test_error_definition():
22    raises(NotImplementedError, lambda: Quantity(""10 m""))
23    raises(TypeError, lambda: Quantity(10, m.dim))
24
25
26def test_str_repr():
27    q = Quantity(10, m)
28
29
30
31def test_eq():
32    # stupid test
33
34
35def test_operations():
36    q = Quantity(10, m)
37    p = Quantity(5, s)
38
39
40
41
42
43
44
45
46def test_error_operations():
47    q = Quantity(10, m)
48    p = Quantity(5, s)
49
50    raises(ValueError, lambda: q.add(p))
51    raises(TypeError, lambda: q.add(1))
52
53    raises(ValueError, lambda: q.sub(p))
54    raises(TypeError, lambda: q.sub(1))
55
56
57def test_convert_to():
58    q = Quantity(5, Unit(m.dim, prefix=k))
59","[['q.factor', '==', '10'], ['q.unit', '==', 's'], ['Quantity(10)', '==', '10'], ['str(q)', '==', '""%g %s"" % (10'], ['repr(q)', '==', '""%g %s"" % (10'], ['(Quantity(10', '==', 'True'], ['(Quantity(10', '==', 'True'], ['-q', '==', 'Quantity(-10'], ['q.add(Quantity(20', '==', 'True'], ['q.add(Quantity(20', '==', 'True'], ['q.sub(Quantity(20', '==', 'True'], ['q.sub(Quantity(20', '==', 'True'], ['q.pow(2)', '==', 'Quantity(10**2'], ['q.mul(p)', '==', 'Quantity(5*10'], ['q.div(p)', '==', 'Quantity(10/5'], ['q.convert_to(m)', '==', 'Quantity(5000']]",16,16,1.0,0.0088300220750551,"['m', 's', 'c', 'k', 'q', 'p']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['m', 's', 'c', 'k', 'q', 'p']
*Code:

1# -*- coding: utf-8 -*-
2
3from __future__ import division
4
5from sympy.physics.unitsystems.quantities import Quantity
6from sympy.physics.unitsystems.units import Unit
7from sympy.physics.unitsystems.prefixes import PREFIXES
8from sympy.physics.unitsystems.systems import mks
9from sympy.utilities.pytest import raises
10
11m, s, c = mks[""m""], mks[""s""], mks[""c""]
12k = PREFIXES[""k""]
13
14
15def test_definition():
16    q = Quantity(10, s)
17
18
19
20
21def test_error_definition():
22    raises(NotImplementedError, lambda: Quantity(""10 m""))
23    raises(TypeError, lambda: Quantity(10, m.dim))
24
25
26def test_str_repr():
27    q = Quantity(10, m)
28
29
30
31def test_eq():
32    # stupid test
33
34
35def test_operations():
36    q = Quantity(10, m)
37    p = Quantity(5, s)
38
39
40
41
42
43
44
45
46def test_error_operations():
47    q = Quantity(10, m)
48    p = Quantity(5, s)
49
50    raises(ValueError, lambda: q.add(p))
51    raises(TypeError, lambda: q.add(1))
52
53    raises(ValueError, lambda: q.sub(p))
54    raises(TypeError, lambda: q.sub(1))
55
56
57def test_convert_to():
58    q = Quantity(5, Unit(m.dim, prefix=k))
59",2553,"[[11, 'm', '!=', None, ""m should not be None""],
 [11, 's', '!=', None, ""s should not be None""],
 [11, 'c', '!=', None, ""c should not be None""],
 [12, 'k', '!=', None, ""k should not be None""],
 [16, 'q', '!=', None, ""Quantity instance should be created""],
 [27, 'q', '!=', None, ""Quantity instance should be created""],
 [36, 'q', '!=', None, ""Quantity instance should be created""],
 [37, 'p', '!=', None, ""Quantity instance should be created""],
 [47, 'q', '!=', None, ""Quantity instance should be created""],
 [48, 'p', '!=', None, ""Quantity instance should be created""],
 [58, 'q', '!=', None, ""Quantity instance should be created""]]"
ximenesuk/openmicroscopy,"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#   $Id$
#
#   Copyright 2008-2013 Glencoe Software, Inc. All rights reserved.
#   Use is subject to license terms supplied in LICENSE.txt
#

import omero, omero.scripts as sc

client = sc.client(""script_1"", """"""
    This is a test script used to test the basic parsing functionality
    and attempts to interaction with the server
    """""",
    #sc.Int(""myint""),
    sc.Long(""mylong""),
    sc.Bool(""mybool""),
    sc.String(""mystring""),
    sc.String(""myoptional"",optional=True)
    )

import os, sys, types
assert type(client) == types.TupleType

self =  sys.argv[0]
cfg  = self.replace(""py"",""cfg"")

real_client = omero.client([""--Ice.Config=%s"" % cfg])
parse_only = real_client.getProperty(""omero.script.parse"")
assert parse_only == ""true""


","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3#
4#   $Id$
5#
6#   Copyright 2008-2013 Glencoe Software, Inc. All rights reserved.
7#   Use is subject to license terms supplied in LICENSE.txt
8#
9
10import omero, omero.scripts as sc
11
12client = sc.client(""script_1"", """"""
13    This is a test script used to test the basic parsing functionality
14    and attempts to interaction with the server
15    """""",
16    #sc.Int(""myint""),
17    sc.Long(""mylong""),
18    sc.Bool(""mybool""),
19    sc.String(""mystring""),
20    sc.String(""myoptional"",optional=True)
21    )
22
23import os, sys, types
24
25self =  sys.argv[0]
26cfg  = self.replace(""py"",""cfg"")
27
28real_client = omero.client([""--Ice.Config=%s"" % cfg])
29parse_only = real_client.getProperty(""omero.script.parse"")
30
31
32","[['type(client)', '==', 'types.TupleType'], ['parse_only', '==', '""true""']]",2,2,1.0,0.0025316455696202,"['client', 'cfg', 'real_client', 'parse_only']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['client', 'cfg', 'real_client', 'parse_only']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3#
4#   $Id$
5#
6#   Copyright 2008-2013 Glencoe Software, Inc. All rights reserved.
7#   Use is subject to license terms supplied in LICENSE.txt
8#
9
10import omero, omero.scripts as sc
11
12client = sc.client(""script_1"", """"""
13    This is a test script used to test the basic parsing functionality
14    and attempts to interaction with the server
15    """""",
16    #sc.Int(""myint""),
17    sc.Long(""mylong""),
18    sc.Bool(""mybool""),
19    sc.String(""mystring""),
20    sc.String(""myoptional"",optional=True)
21    )
22
23import os, sys, types
24
25self =  sys.argv[0]
26cfg  = self.replace(""py"",""cfg"")
27
28real_client = omero.client([""--Ice.Config=%s"" % cfg])
29parse_only = real_client.getProperty(""omero.script.parse"")
30
31
32",2205,"[[21, 'client', '!=', None, ""client object creation must be successful for script execution""],
 [28, 'real_client', '!=', None, ""real_client object creation must be successful for script execution""],
 [29, 'parse_only', '!=', None, ""omero script parse property must exist for script execution""]]"
nielsbuwen/ilastik,"###############################################################################
#   ilastik: interactive learning and segmentation toolkit
#
#       Copyright (C) 2011-2014, the ilastik developers
#                                <team@ilastik.org>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# In addition, as a special exception, the copyright holders of
# ilastik give you permission to combine ilastik with applets,
# workflows and plugins which are not covered under the GNU
# General Public License.
#
# See the LICENSE file for details. License information is also available
# on the ilastik web site at:
#		   http://ilastik.org/license.html
###############################################################################
class SingleToMultiGuiAdapter( object ):
    """"""
    Utility class used by the StandardApplet to wrap several single-image 
    GUIs into one multi-image GUI, which is what the shell/Applet API requires.
    """"""
    def __init__(self, parentApplet, singleImageGuiFactory, topLevelOperator):
        self.singleImageGuiFactory = singleImageGuiFactory
        self._imageLaneIndex = None
        self._guis = []
        self._tempDrawers = {}
        self.topLevelOperator = topLevelOperator
        self._enabled = False

    def currentGui(self):
        """"""
        Return the single-image GUI for the currently selected image lane.
        If it doesn't exist yet, create it.
        """"""
        if self._imageLaneIndex is None:
            return None

        # Create first if necessary
        if self._guis[self._imageLaneIndex] is None:
            self._guis[self._imageLaneIndex] = self.singleImageGuiFactory( self._imageLaneIndex )
        return self._guis[self._imageLaneIndex]

    def appletDrawer(self):
        """"""
        Return the applet drawer of the current single-image gui.
        """"""
        if self.currentGui() is not None:
            self._tempDrawers[ self._imageLaneIndex ] = self.currentGui().appletDrawer()
            return self.currentGui().appletDrawer()
        
        if self._imageLaneIndex not in self._tempDrawers:
            from PyQt4.QtGui import QWidget
            self._tempDrawers[ self._imageLaneIndex ] = QWidget()
        return self._tempDrawers[ self._imageLaneIndex ]

    def centralWidget( self ):
        """"""
        Return the central widget of the currently selected single-image gui.
        """"""
        if self.currentGui() is None:
            return None
        return self.currentGui().centralWidget()

    def menus(self):
        """"""
        Return the menus of the currently selected single-image gui.
        """"""
        if self.currentGui() is None:
            return None
        return self.currentGui().menus()
    
    def viewerControlWidget(self):
        """"""
        Return the viewer control widget for the currently selectd single-image gui.
        """"""
        if self.currentGui() is None:
            return None
        return self.currentGui().viewerControlWidget()
    
    def setImageIndex(self, imageIndex):
        """"""
        Called by the shell when the user has changed the currently selected image lane.
        """"""
        self._imageLaneIndex = imageIndex

    def stopAndCleanUp(self):
        """"""
        Called by the workflow when the project is closed and the GUIs are about to be discarded.
        """"""
        for gui in self._guis:
            if gui is not None:
                gui.stopAndCleanUp()
        # Discard all sub-guis.
        self._guis = []

    def imageLaneAdded(self, laneIndex):
        """"""
        Called by the workflow when a new image lane has been created.
        """"""
        assert len(self._guis) == laneIndex
        # We DELAY creating the GUI for this lane until the shell actually needs to view it.
        self._guis.append(None)

    def imageLaneRemoved(self, laneIndex, finalLength):
        """"""
        Called by the workflow when an image lane has been destroyed.
        """"""
        if len(self._guis) > finalLength:
            # Remove the GUI and clean it up.
            gui = self._guis.pop(laneIndex)
            if gui is not None:
                gui.stopAndCleanUp()
    
    def setEnabled(self, enabled):
        self._enabled = enabled
        for gui in filter(lambda x:x, self._guis):
            gui.setEnabled(enabled)
        for blank_drawer in self._tempDrawers.values():
            # Late import here to avoid importing sip in headless mode.
            import sip
            if not sip.isdeleted(blank_drawer):
                blank_drawer.setEnabled(enabled)
        ","
1###############################################################################
2#   ilastik: interactive learning and segmentation toolkit
3#
4#       Copyright (C) 2011-2014, the ilastik developers
5#                                <team@ilastik.org>
6#
7# This program is free software; you can redistribute it and/or
8# modify it under the terms of the GNU General Public License
9# as published by the Free Software Foundation; either version 2
10# of the License, or (at your option) any later version.
11#
12# In addition, as a special exception, the copyright holders of
13# ilastik give you permission to combine ilastik with applets,
14# workflows and plugins which are not covered under the GNU
15# General Public License.
16#
17# See the LICENSE file for details. License information is also available
18# on the ilastik web site at:
19#		   http://ilastik.org/license.html
20###############################################################################
21class SingleToMultiGuiAdapter( object ):
22    """"""
23    Utility class used by the StandardApplet to wrap several single-image 
24    GUIs into one multi-image GUI, which is what the shell/Applet API requires.
25    """"""
26    def __init__(self, parentApplet, singleImageGuiFactory, topLevelOperator):
27        self.singleImageGuiFactory = singleImageGuiFactory
28        self._imageLaneIndex = None
29        self._guis = []
30        self._tempDrawers = {}
31        self.topLevelOperator = topLevelOperator
32        self._enabled = False
33
34    def currentGui(self):
35        """"""
36        Return the single-image GUI for the currently selected image lane.
37        If it doesn't exist yet, create it.
38        """"""
39        if self._imageLaneIndex is None:
40            return None
41
42        # Create first if necessary
43        if self._guis[self._imageLaneIndex] is None:
44            self._guis[self._imageLaneIndex] = self.singleImageGuiFactory( self._imageLaneIndex )
45        return self._guis[self._imageLaneIndex]
46
47    def appletDrawer(self):
48        """"""
49        Return the applet drawer of the current single-image gui.
50        """"""
51        if self.currentGui() is not None:
52            self._tempDrawers[ self._imageLaneIndex ] = self.currentGui().appletDrawer()
53            return self.currentGui().appletDrawer()
54        
55        if self._imageLaneIndex not in self._tempDrawers:
56            from PyQt4.QtGui import QWidget
57            self._tempDrawers[ self._imageLaneIndex ] = QWidget()
58        return self._tempDrawers[ self._imageLaneIndex ]
59
60    def centralWidget( self ):
61        """"""
62        Return the central widget of the currently selected single-image gui.
63        """"""
64        if self.currentGui() is None:
65            return None
66        return self.currentGui().centralWidget()
67
68    def menus(self):
69        """"""
70        Return the menus of the currently selected single-image gui.
71        """"""
72        if self.currentGui() is None:
73            return None
74        return self.currentGui().menus()
75    
76    def viewerControlWidget(self):
77        """"""
78        Return the viewer control widget for the currently selectd single-image gui.
79        """"""
80        if self.currentGui() is None:
81            return None
82        return self.currentGui().viewerControlWidget()
83    
84    def setImageIndex(self, imageIndex):
85        """"""
86        Called by the shell when the user has changed the currently selected image lane.
87        """"""
88        self._imageLaneIndex = imageIndex
89
90    def stopAndCleanUp(self):
91        """"""
92        Called by the workflow when the project is closed and the GUIs are about to be discarded.
93        """"""
94        for gui in self._guis:
95            if gui is not None:
96                gui.stopAndCleanUp()
97        # Discard all sub-guis.
98        self._guis = []
99
100    def imageLaneAdded(self, laneIndex):
101        """"""
102        Called by the workflow when a new image lane has been created.
103        """"""
104        # We DELAY creating the GUI for this lane until the shell actually needs to view it.
105        self._guis.append(None)
106
107    def imageLaneRemoved(self, laneIndex, finalLength):
108        """"""
109        Called by the workflow when an image lane has been destroyed.
110        """"""
111        if len(self._guis) > finalLength:
112            # Remove the GUI and clean it up.
113            gui = self._guis.pop(laneIndex)
114            if gui is not None:
115                gui.stopAndCleanUp()
116    
117    def setEnabled(self, enabled):
118        self._enabled = enabled
119        for gui in filter(lambda x:x, self._guis):
120            gui.setEnabled(enabled)
121        for blank_drawer in self._tempDrawers.values():
122            # Late import here to avoid importing sip in headless mode.
123            import sip
124            if not sip.isdeleted(blank_drawer):
125                blank_drawer.setEnabled(enabled)
126        ","[['len(self._guis)', '==', 'laneIndex']]",1,1,1.0,0.0002093364036005,"['parentApplet', 'singleImageGuiFactory', 'topLevelOperator', 'self.singleImageGuiFactory', 'self._imageLaneIndex', 'self._guis', 'self._tempDrawers', 'self.topLevelOperator', 'self._enabled', 'self._guis[self._imageLaneIndex]', 'self._tempDrawers[ self._imageLaneIndex ]', 'imageIndex', 'laneIndex', 'finalLength', 'gui', 'enabled']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['parentApplet', 'singleImageGuiFactory', 'topLevelOperator', 'self.singleImageGuiFactory', 'self._imageLaneIndex', 'self._guis', 'self._tempDrawers', 'self.topLevelOperator', 'self._enabled', 'self._guis[self._imageLaneIndex]', 'self._tempDrawers[ self._imageLaneIndex ]', 'imageIndex', 'laneIndex', 'finalLength', 'gui', 'enabled']
*Code:

1###############################################################################
2#   ilastik: interactive learning and segmentation toolkit
3#
4#       Copyright (C) 2011-2014, the ilastik developers
5#                                <team@ilastik.org>
6#
7# This program is free software; you can redistribute it and/or
8# modify it under the terms of the GNU General Public License
9# as published by the Free Software Foundation; either version 2
10# of the License, or (at your option) any later version.
11#
12# In addition, as a special exception, the copyright holders of
13# ilastik give you permission to combine ilastik with applets,
14# workflows and plugins which are not covered under the GNU
15# General Public License.
16#
17# See the LICENSE file for details. License information is also available
18# on the ilastik web site at:
19#		   http://ilastik.org/license.html
20###############################################################################
21class SingleToMultiGuiAdapter( object ):
22    """"""
23    Utility class used by the StandardApplet to wrap several single-image 
24    GUIs into one multi-image GUI, which is what the shell/Applet API requires.
25    """"""
26    def __init__(self, parentApplet, singleImageGuiFactory, topLevelOperator):
27        self.singleImageGuiFactory = singleImageGuiFactory
28        self._imageLaneIndex = None
29        self._guis = []
30        self._tempDrawers = {}
31        self.topLevelOperator = topLevelOperator
32        self._enabled = False
33
34    def currentGui(self):
35        """"""
36        Return the single-image GUI for the currently selected image lane.
37        If it doesn't exist yet, create it.
38        """"""
39        if self._imageLaneIndex is None:
40            return None
41
42        # Create first if necessary
43        if self._guis[self._imageLaneIndex] is None:
44            self._guis[self._imageLaneIndex] = self.singleImageGuiFactory( self._imageLaneIndex )
45        return self._guis[self._imageLaneIndex]
46
47    def appletDrawer(self):
48        """"""
49        Return the applet drawer of the current single-image gui.
50        """"""
51        if self.currentGui() is not None:
52            self._tempDrawers[ self._imageLaneIndex ] = self.currentGui().appletDrawer()
53            return self.currentGui().appletDrawer()
54        
55        if self._imageLaneIndex not in self._tempDrawers:
56            from PyQt4.QtGui import QWidget
57            self._tempDrawers[ self._imageLaneIndex ] = QWidget()
58        return self._tempDrawers[ self._imageLaneIndex ]
59
60    def centralWidget( self ):
61        """"""
62        Return the central widget of the currently selected single-image gui.
63        """"""
64        if self.currentGui() is None:
65            return None
66        return self.currentGui().centralWidget()
67
68    def menus(self):
69        """"""
70        Return the menus of the currently selected single-image gui.
71        """"""
72        if self.currentGui() is None:
73            return None
74        return self.currentGui().menus()
75    
76    def viewerControlWidget(self):
77        """"""
78        Return the viewer control widget for the currently selectd single-image gui.
79        """"""
80        if self.currentGui() is None:
81            return None
82        return self.currentGui().viewerControlWidget()
83    
84    def setImageIndex(self, imageIndex):
85        """"""
86        Called by the shell when the user has changed the currently selected image lane.
87        """"""
88        self._imageLaneIndex = imageIndex
89
90    def stopAndCleanUp(self):
91        """"""
92        Called by the workflow when the project is closed and the GUIs are about to be discarded.
93        """"""
94        for gui in self._guis:
95            if gui is not None:
96                gui.stopAndCleanUp()
97        # Discard all sub-guis.
98        self._guis = []
99
100    def imageLaneAdded(self, laneIndex):
101        """"""
102        Called by the workflow when a new image lane has been created.
103        """"""
104        # We DELAY creating the GUI for this lane until the shell actually needs to view it.
105        self._guis.append(None)
106
107    def imageLaneRemoved(self, laneIndex, finalLength):
108        """"""
109        Called by the workflow when an image lane has been destroyed.
110        """"""
111        if len(self._guis) > finalLength:
112            # Remove the GUI and clean it up.
113            gui = self._guis.pop(laneIndex)
114            if gui is not None:
115                gui.stopAndCleanUp()
116    
117    def setEnabled(self, enabled):
118        self._enabled = enabled
119        for gui in filter(lambda x:x, self._guis):
120            gui.setEnabled(enabled)
121        for blank_drawer in self._tempDrawers.values():
122            # Late import here to avoid importing sip in headless mode.
123            import sip
124            if not sip.isdeleted(blank_drawer):
125                blank_drawer.setEnabled(enabled)
126        ",6717,"[[26, 'parentApplet', '!=', None, 'parentApplet is expected to be initialized for this class'], 
[26, 'singleImageGuiFactory', '!=', None, 'singleImageGuiFactory is expected to be initialized for this class'], 
[26, 'topLevelOperator', '!=', None, 'topLevelOperator is expected to be initialized for this class'], 
[43, 'self._guis[self._imageLaneIndex]', '==', None, 'Gui object at _imageLaneIndex must be None for initialization'], 
[84, 'imageIndex', '>=', 0, 'Image Index cannot be negative'], 
[107, 'laneIndex', '>=', 0, 'laneIndex is expected to be non-negative'], 
[111, 'finalLength', '>', 0, 'finalLength should be a positive integer'], 
[111, 'finalLength', '>=', 'laneIndex', 'finalLength should be larger than or equal to laneIndex'], 
[117, 'enabled', '!=', None, 'The setEnabled function expects boolean input']]"
HIIT/elfi,"import os

import numpy as np
import pytest

import elfi
import elfi.model.elfi_model as em
from elfi.examples import ma2 as ema2


@pytest.mark.usefixtures('with_all_clients')
def test_generate(ma2):
    n_gen = 10

    d = ma2.get_reference('d')
    res = d.generate(n_gen)

    assert res.shape[0] == n_gen
    assert res.ndim == 1


@pytest.mark.usefixtures('with_all_clients')
def test_observed():
    true_params = [.6, .2]
    m = ema2.get_model(100, true_params=true_params)
    y = m.observed['MA2']
    S1 = m.get_reference('S1')
    S2 = m.get_reference('S2')

    S1_observed = ema2.autocov(y)
    S2_observed = ema2.autocov(y, 2)

    assert np.array_equal(S1.observed, S1_observed)
    assert np.array_equal(S2.observed, S2_observed)


def euclidean_discrepancy(*simulated, observed):
    """"""Euclidean discrepancy between data.

    Parameters
    ----------
    *simulated
        simulated summaries
    observed : tuple of 1d or 2d np.arrays of length n

    Returns
    -------
    d : np.array of size (n,)
    """"""
    d = np.linalg.norm(np.column_stack(simulated) - np.column_stack(observed), ord=2, axis=1)
    return d


class TestElfiModel:
    def test_remove_node(self, ma2):
        ma2.remove_node('MA2')

        assert not ma2.has_node('MA2')
        assert ma2.has_node('t2')

        parents = ma2.get_parents('t2')
        # This needs to have at least 2 parents so that the test below makes sense
        assert len(parents) > 1

        ma2.remove_node('t2')
        for p in parents:
            if p[0] == '_':
                assert not ma2.has_node(p)
            else:
                assert ma2.has_node(p)

        assert 'MA2' not in ma2.observed

    def test_save_load(self, ma2):
        name = ma2.name
        ma2.save()
        ma2 = elfi.load_model(name)
        os.remove(name + '.pkl')

        # Same with a prefix
        prefix = 'models_dir'
        ma2.save(prefix)
        ma2 = elfi.load_model(name, prefix)
        os.remove(os.path.join(prefix, name + '.pkl'))
        os.removedirs(prefix)


class TestNodeReference:
    def test_name_argument(self):
        # This is important because it is used when passing NodeReferences as
        # InferenceMethod arguments
        em.set_default_model()
        ref = em.NodeReference(name='test')
        assert str(ref) == 'test'

    def test_name_determination(self):
        em.set_default_model()
        node = em.NodeReference()
        assert node.name == 'node'

        # Works without spaces
        node2 = em.NodeReference()
        assert node2.name == 'node2'

        # Does not give the same name
        node = em.NodeReference()
        assert node.name != 'node'

        # Works with sub classes
        pri = em.Prior('uniform')
        assert pri.name == 'pri'

        # Assigns random names when the name isn't self explanatory
        nodes = []
        for i in range(5):
            nodes.append(em.NodeReference())

        for i in range(1, 5):
            assert nodes[i - 1].name != nodes[i].name

    def test_positional_parents(self, ma2):
        true_positional_parents = ['S1', 'S2']
        # This tests that the order of the list is deterministic (no randomness resulting
        # from direct hash to list conversion)
        for i in range(100):
            assert [p.name for p in ma2['d'].parents] == true_positional_parents

    def test_become(self, ma2):
        state = np.random.get_state()
        dists = ma2.generate(100, 'd')['d']
        nodes = ma2.nodes
        np.random.set_state(state)

        ma2['d'].become(em.Discrepancy(euclidean_discrepancy, ma2['S1'], ma2['S2']))
        dists2 = ma2.generate(100, 'd')['d']
        nodes2 = ma2.nodes
        np.random.set_state(state)

        assert np.array_equal(dists, dists2)

        # Check that there are the same nodes in the graph
        assert set(nodes) == set(nodes2)

    def test_become_with_priors(self, ma2):
        parameters = ma2.parameter_names.copy()
        parent_names = ma2.get_parents('t1')

        ma2['t1'].become(elfi.Prior('uniform', 0, model=ma2))

        # Test that parameters are preserved
        assert parameters == ma2.parameter_names

        # Test that hidden nodes are removed
        for name in parent_names:
            assert not ma2.has_node(name)

        # Test that inference still works
        r = elfi.Rejection(ma2, 'd')
        r.sample(10)

    def test_become_with_simulators(self, ma2):
        y_obs = np.zeros(100)
        new_sim = elfi.Simulator(ema2.MA2, ma2['t1'], ma2['t2'], observed=y_obs)
        ma2['MA2'].become(new_sim)

        # Test that observed data is changed
        assert np.array_equal(ma2.observed['MA2'], y_obs)

        # Test that inference still works
        r = elfi.Rejection(ma2, 'd')
        r.sample(10)
","
1import os
2
3import numpy as np
4import pytest
5
6import elfi
7import elfi.model.elfi_model as em
8from elfi.examples import ma2 as ema2
9
10
11@pytest.mark.usefixtures('with_all_clients')
12def test_generate(ma2):
13    n_gen = 10
14
15    d = ma2.get_reference('d')
16    res = d.generate(n_gen)
17
18
19
20@pytest.mark.usefixtures('with_all_clients')
21def test_observed():
22    true_params = [.6, .2]
23    m = ema2.get_model(100, true_params=true_params)
24    y = m.observed['MA2']
25    S1 = m.get_reference('S1')
26    S2 = m.get_reference('S2')
27
28    S1_observed = ema2.autocov(y)
29    S2_observed = ema2.autocov(y, 2)
30
31
32
33def euclidean_discrepancy(*simulated, observed):
34    """"""Euclidean discrepancy between data.
35
36    Parameters
37    ----------
38    *simulated
39        simulated summaries
40    observed : tuple of 1d or 2d np.arrays of length n
41
42    Returns
43    -------
44    d : np.array of size (n,)
45    """"""
46    d = np.linalg.norm(np.column_stack(simulated) - np.column_stack(observed), ord=2, axis=1)
47    return d
48
49
50class TestElfiModel:
51    def test_remove_node(self, ma2):
52        ma2.remove_node('MA2')
53
54
55        parents = ma2.get_parents('t2')
56        # This needs to have at least 2 parents so that the test below makes sense
57
58        ma2.remove_node('t2')
59        for p in parents:
60            if p[0] == '_':
61            else:
62
63
64    def test_save_load(self, ma2):
65        name = ma2.name
66        ma2.save()
67        ma2 = elfi.load_model(name)
68        os.remove(name + '.pkl')
69
70        # Same with a prefix
71        prefix = 'models_dir'
72        ma2.save(prefix)
73        ma2 = elfi.load_model(name, prefix)
74        os.remove(os.path.join(prefix, name + '.pkl'))
75        os.removedirs(prefix)
76
77
78class TestNodeReference:
79    def test_name_argument(self):
80        # This is important because it is used when passing NodeReferences as
81        # InferenceMethod arguments
82        em.set_default_model()
83        ref = em.NodeReference(name='test')
84
85    def test_name_determination(self):
86        em.set_default_model()
87        node = em.NodeReference()
88
89        # Works without spaces
90        node2 = em.NodeReference()
91
92        # Does not give the same name
93        node = em.NodeReference()
94
95        # Works with sub classes
96        pri = em.Prior('uniform')
97
98        # Assigns random names when the name isn't self explanatory
99        nodes = []
100        for i in range(5):
101            nodes.append(em.NodeReference())
102
103        for i in range(1, 5):
104
105    def test_positional_parents(self, ma2):
106        true_positional_parents = ['S1', 'S2']
107        # This tests that the order of the list is deterministic (no randomness resulting
108        # from direct hash to list conversion)
109        for i in range(100):
110
111    def test_become(self, ma2):
112        state = np.random.get_state()
113        dists = ma2.generate(100, 'd')['d']
114        nodes = ma2.nodes
115        np.random.set_state(state)
116
117        ma2['d'].become(em.Discrepancy(euclidean_discrepancy, ma2['S1'], ma2['S2']))
118        dists2 = ma2.generate(100, 'd')['d']
119        nodes2 = ma2.nodes
120        np.random.set_state(state)
121
122
123        # Check that there are the same nodes in the graph
124
125    def test_become_with_priors(self, ma2):
126        parameters = ma2.parameter_names.copy()
127        parent_names = ma2.get_parents('t1')
128
129        ma2['t1'].become(elfi.Prior('uniform', 0, model=ma2))
130
131        # Test that parameters are preserved
132
133        # Test that hidden nodes are removed
134        for name in parent_names:
135
136        # Test that inference still works
137        r = elfi.Rejection(ma2, 'd')
138        r.sample(10)
139
140    def test_become_with_simulators(self, ma2):
141        y_obs = np.zeros(100)
142        new_sim = elfi.Simulator(ema2.MA2, ma2['t1'], ma2['t2'], observed=y_obs)
143        ma2['MA2'].become(new_sim)
144
145        # Test that observed data is changed
146
147        # Test that inference still works
148        r = elfi.Rejection(ma2, 'd')
149        r.sample(10)
150","[['res.shape[0]', '==', 'n_gen'], ['res.ndim', '==', '1'], ['np.array_equal(S1.observed', '==', 'True'], ['np.array_equal(S2.observed', '==', 'True'], [""ma2.has_node('MA2')"", '==', 'False'], [""ma2.has_node('t2')"", '==', 'True'], ['len(parents)', '>', '1'], ['ma2.has_node(p)', '==', 'False'], ['ma2.has_node(p)', '==', 'True'], ['str(ref)', '==', ""'test'""], ['node.name', '==', ""'node'""], ['node2.name', '==', ""'node2'""], ['node.name', '!=', ""'node'""], ['pri.name', '==', ""'pri'""], ['nodes[i - 1].name', '!=', 'nodes[i].name'], ['np.array_equal(dists', '==', 'True'], ['set(nodes)', '==', 'set(nodes2)'], ['parameters', '==', 'ma2.parameter_names'], ['ma2.has_node(name)', '==', 'False'], [""np.array_equal(ma2.observed['MA2']"", '==', 'True']]",22,20,0.9090909090909092,0.0041605991262741,"['ma2', 'n_gen', 'd', 'res', 'true_params', 'm', 'y', 'S1', 'S2', 'S1_observed', 'S2_observed', '*simulated', 'observed', 'parents', 'name', 'prefix', 'ref', 'node', 'node2', 'pri', 'nodes', 'true_positional_parents', 'state', 'dists', 'dists2', 'nodes2', 'parameters', 'parent_names', 'r', 'y_obs', 'new_sim']",31,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ma2', 'n_gen', 'd', 'res', 'true_params', 'm', 'y', 'S1', 'S2', 'S1_observed', 'S2_observed', '*simulated', 'observed', 'parents', 'name', 'prefix', 'ref', 'node', 'node2', 'pri', 'nodes', 'true_positional_parents', 'state', 'dists', 'dists2', 'nodes2', 'parameters', 'parent_names', 'r', 'y_obs', 'new_sim']
*Code:

1import os
2
3import numpy as np
4import pytest
5
6import elfi
7import elfi.model.elfi_model as em
8from elfi.examples import ma2 as ema2
9
10
11@pytest.mark.usefixtures('with_all_clients')
12def test_generate(ma2):
13    n_gen = 10
14
15    d = ma2.get_reference('d')
16    res = d.generate(n_gen)
17
18
19
20@pytest.mark.usefixtures('with_all_clients')
21def test_observed():
22    true_params = [.6, .2]
23    m = ema2.get_model(100, true_params=true_params)
24    y = m.observed['MA2']
25    S1 = m.get_reference('S1')
26    S2 = m.get_reference('S2')
27
28    S1_observed = ema2.autocov(y)
29    S2_observed = ema2.autocov(y, 2)
30
31
32
33def euclidean_discrepancy(*simulated, observed):
34    """"""Euclidean discrepancy between data.
35
36    Parameters
37    ----------
38    *simulated
39        simulated summaries
40    observed : tuple of 1d or 2d np.arrays of length n
41
42    Returns
43    -------
44    d : np.array of size (n,)
45    """"""
46    d = np.linalg.norm(np.column_stack(simulated) - np.column_stack(observed), ord=2, axis=1)
47    return d
48
49
50class TestElfiModel:
51    def test_remove_node(self, ma2):
52        ma2.remove_node('MA2')
53
54
55        parents = ma2.get_parents('t2')
56        # This needs to have at least 2 parents so that the test below makes sense
57
58        ma2.remove_node('t2')
59        for p in parents:
60            if p[0] == '_':
61            else:
62
63
64    def test_save_load(self, ma2):
65        name = ma2.name
66        ma2.save()
67        ma2 = elfi.load_model(name)
68        os.remove(name + '.pkl')
69
70        # Same with a prefix
71        prefix = 'models_dir'
72        ma2.save(prefix)
73        ma2 = elfi.load_model(name, prefix)
74        os.remove(os.path.join(prefix, name + '.pkl'))
75        os.removedirs(prefix)
76
77
78class TestNodeReference:
79    def test_name_argument(self):
80        # This is important because it is used when passing NodeReferences as
81        # InferenceMethod arguments
82        em.set_default_model()
83        ref = em.NodeReference(name='test')
84
85    def test_name_determination(self):
86        em.set_default_model()
87        node = em.NodeReference()
88
89        # Works without spaces
90        node2 = em.NodeReference()
91
92        # Does not give the same name
93        node = em.NodeReference()
94
95        # Works with sub classes
96        pri = em.Prior('uniform')
97
98        # Assigns random names when the name isn't self explanatory
99        nodes = []
100        for i in range(5):
101            nodes.append(em.NodeReference())
102
103        for i in range(1, 5):
104
105    def test_positional_parents(self, ma2):
106        true_positional_parents = ['S1', 'S2']
107        # This tests that the order of the list is deterministic (no randomness resulting
108        # from direct hash to list conversion)
109        for i in range(100):
110
111    def test_become(self, ma2):
112        state = np.random.get_state()
113        dists = ma2.generate(100, 'd')['d']
114        nodes = ma2.nodes
115        np.random.set_state(state)
116
117        ma2['d'].become(em.Discrepancy(euclidean_discrepancy, ma2['S1'], ma2['S2']))
118        dists2 = ma2.generate(100, 'd')['d']
119        nodes2 = ma2.nodes
120        np.random.set_state(state)
121
122
123        # Check that there are the same nodes in the graph
124
125    def test_become_with_priors(self, ma2):
126        parameters = ma2.parameter_names.copy()
127        parent_names = ma2.get_parents('t1')
128
129        ma2['t1'].become(elfi.Prior('uniform', 0, model=ma2))
130
131        # Test that parameters are preserved
132
133        # Test that hidden nodes are removed
134        for name in parent_names:
135
136        # Test that inference still works
137        r = elfi.Rejection(ma2, 'd')
138        r.sample(10)
139
140    def test_become_with_simulators(self, ma2):
141        y_obs = np.zeros(100)
142        new_sim = elfi.Simulator(ema2.MA2, ma2['t1'], ma2['t2'], observed=y_obs)
143        ma2['MA2'].become(new_sim)
144
145        # Test that observed data is changed
146
147        # Test that inference still works
148        r = elfi.Rejection(ma2, 'd')
149        r.sample(10)
150",5906,"[[13, 'n_gen', '>', 0, 'Number of generations cannot be less than 1'],
[22, 'true_params', '==', 2, 'true_params must contain exactly two elements'],
[23, 'm', '!=', None, 'm must be not None after getting the model'],
[24, 'y', '!=', None, 'y must be not None after initial assignment'],
[25, 'S1', '!=', None, 'S1 must be not None after getting the reference'],
[26, 'S2', '!=', None, 'S2 must be not None after getting the reference'],
[28, 'S1_observed', '!=', None, 'S1_observed must be not None after assigning value'],
[29, 'S2_observed', '!=', None, 'S2_observed must be not None after assigning value'],
[47, 'd', '!=', None, 'd must not be None after calculation'],
[52, 'ma2', '!=', None, 'ma2 must not be None after removing node'],
[58, 'ma2', '!=', None, 'ma2 must not be None after again removing node'],
[67, 'ma2', '!=', None, 'ma2 must not be None after loading model'],
[73, 'ma2', '!=', None, 'ma2 must not be None after loading model with prefix'],
[83, 'ref', '!=', None, 'ref must not be None after setting NodeReference'],
[87, 'node', '!=', None, 'node must not be None after setting NodeReference'],
[90, 'node2', '!=', None, 'node2 must not be None after setting NodeReference'],
[93, 'node', '!=', None, 'node must not be None after reassigning NodeReference'],
[97, 'pri', '!=', None, 'pri must not be None after setting Prior'],
[102, 'nodes', '!=', None, 'nodes list must not be None after appending NodeReference'],
[106, 'true_positional_parents', '==', 2, 'true_positional_parents must contain exactly two elements'],
[113, 'dists', '!=', None, 'dists must not be None after generating values'],
[114, 'nodes', '!=', None, 'nodes must not be None after getting all nodes in ma2'],
[118, 'dists2', '!=', None, 'dists2 must not be None after updating node in ma2 and regenerate values'],
[119, 'nodes2', '!=', None, 'nodes2 must not be None after updating graph'],
[138, 'r', '!=', None, 'r must not be None after setting elfi.Rejection'],
[142, 'new_sim', '!=', None, 'new_sim must not be None after setting Simulator'],
[148, 'r', '!=', None, 'r must not be None after setting elfi.Rejection']]"
stumoodie/SbgnPdNotationSubsystem,"import antlr3
import testbase
import unittest


class t025lexerRulePropertyRef(testbase.ANTLRTest):
    def setUp(self):
        self.compileGrammar()
        

    def testValid1(self):
        stream = antlr3.StringStream('foobar _Ab98 \n A12sdf')
        lexer = self.getLexer(stream)

        while True:
            token = lexer.nextToken()
            if token.type == antlr3.EOF:
                break

        assert len(lexer.properties) == 3, lexer.properties

        text, type, line, pos, index, channel, start, stop = lexer.properties[0]
        assert text == 'foobar', lexer.properties[0]
        assert type == self.lexerModule.IDENTIFIER, lexer.properties[0]
        assert line == 1, lexer.properties[0]
        assert pos == 0, lexer.properties[0]
        assert index == -1, lexer.properties[0]
        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[0]
        assert start == 0, lexer.properties[0]
        assert stop == 5, lexer.properties[0]

        text, type, line, pos, index, channel, start, stop = lexer.properties[1]
        assert text == '_Ab98', lexer.properties[1]
        assert type == self.lexerModule.IDENTIFIER, lexer.properties[1]
        assert line == 1, lexer.properties[1]
        assert pos == 7, lexer.properties[1]
        assert index == -1, lexer.properties[1]
        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[1]
        assert start == 7, lexer.properties[1]
        assert stop == 11, lexer.properties[1]

        text, type, line, pos, index, channel, start, stop = lexer.properties[2]
        assert text == 'A12sdf', lexer.properties[2]
        assert type == self.lexerModule.IDENTIFIER, lexer.properties[2]
        assert line == 2, lexer.properties[2]
        assert pos == 1, lexer.properties[2]
        assert index == -1, lexer.properties[2]
        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[2]
        assert start == 15, lexer.properties[2]
        assert stop == 20, lexer.properties[2]


if __name__ == '__main__':
    unittest.main()
","
1import antlr3
2import testbase
3import unittest
4
5
6class t025lexerRulePropertyRef(testbase.ANTLRTest):
7    def setUp(self):
8        self.compileGrammar()
9        
10
11    def testValid1(self):
12        stream = antlr3.StringStream('foobar _Ab98 \n A12sdf')
13        lexer = self.getLexer(stream)
14
15        while True:
16            token = lexer.nextToken()
17            if token.type == antlr3.EOF:
18                break
19
20
21        text, type, line, pos, index, channel, start, stop = lexer.properties[0]
22
23        text, type, line, pos, index, channel, start, stop = lexer.properties[1]
24
25        text, type, line, pos, index, channel, start, stop = lexer.properties[2]
26
27
28if __name__ == '__main__':
29    unittest.main()
30","[['len(lexer.properties)', '==', '3'], ['text', '==', ""'foobar'""], ['type', '==', 'self.lexerModule.IDENTIFIER'], ['line', '==', '1'], ['pos', '==', '0'], ['index', '==', '-1'], ['channel', '==', 'antlr3.DEFAULT_CHANNEL'], ['start', '==', '0'], ['stop', '==', '5'], ['text', '==', ""'_Ab98'""], ['type', '==', 'self.lexerModule.IDENTIFIER'], ['line', '==', '1'], ['pos', '==', '7'], ['index', '==', '-1'], ['channel', '==', 'antlr3.DEFAULT_CHANNEL'], ['start', '==', '7'], ['stop', '==', '11'], ['text', '==', ""'A12sdf'""], ['type', '==', 'self.lexerModule.IDENTIFIER'], ['line', '==', '2'], ['pos', '==', '1'], ['index', '==', '-1'], ['channel', '==', 'antlr3.DEFAULT_CHANNEL'], ['start', '==', '15'], ['stop', '==', '20']]",25,25,1.0,0.0122010736944851,"['stream', 'lexer', 'token', 'text', 'type', 'line', 'pos', 'index', 'channel', 'start', 'stop']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['stream', 'lexer', 'token', 'text', 'type', 'line', 'pos', 'index', 'channel', 'start', 'stop']
*Code:

1import antlr3
2import testbase
3import unittest
4
5
6class t025lexerRulePropertyRef(testbase.ANTLRTest):
7    def setUp(self):
8        self.compileGrammar()
9        
10
11    def testValid1(self):
12        stream = antlr3.StringStream('foobar _Ab98 \n A12sdf')
13        lexer = self.getLexer(stream)
14
15        while True:
16            token = lexer.nextToken()
17            if token.type == antlr3.EOF:
18                break
19
20
21        text, type, line, pos, index, channel, start, stop = lexer.properties[0]
22
23        text, type, line, pos, index, channel, start, stop = lexer.properties[1]
24
25        text, type, line, pos, index, channel, start, stop = lexer.properties[2]
26
27
28if __name__ == '__main__':
29    unittest.main()
30",2234,"[[12, 'stream', '!=', None, ""stream should not be None to ensure proper functioning""],
 [12, 'lexer', '!=', None, ""lexer should be initialized successfully""],
 [16, 'token', '!=', None, ""token fetched by lexer should not be None""],
 [21, ['text', 'type', 'line', 'pos', 'index', 'channel', 'start', 'stop'], '==', 7, ""each lexer property should contain 7 elements""],
 [23, ['text', 'type', 'line', 'pos', 'index', 'channel', 'start', 'stop'], '==', 7, ""each lexer property should contain 7 elements""],
 [25, ['text', 'type', 'line', 'pos', 'index', 'channel', 'start', 'stop'], '==', 7, ""each lexer property should contain 7 elements""]]"
testalt/electrum-dgc,"from util import print_error
import traceback, sys
from util import *
from i18n import _

plugins = []


def init_plugins(self):
    import imp, pkgutil, __builtin__, os
    global plugins

    if __builtin__.use_local_modules:
        fp, pathname, description = imp.find_module('plugins')
        plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
        plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
        imp.load_module('electrum_dgc_plugins', fp, pathname, description)
        plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
    else:
        import electrum_dgc_plugins
        plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
        plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_ltc_plugins']) for name in plugin_names]

    for name, p in zip(plugin_names, plugin_modules):
        try:
            plugins.append( p.Plugin(self, name) )
        except Exception:
            print_msg(_(""Error: cannot initialize plugin""),p)
            traceback.print_exc(file=sys.stdout)


#def init_plugins(config):
    #import imp, pkgutil, __builtin__, os
    #global plugins

    #if __builtin__.use_local_modules and False:
        #fp, pathname, description = imp.find_module('plugins')
        #plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
        #plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
        #imp.load_module('electrum_dgc_plugins', fp, pathname, description)
        #plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
    #else:
        #import electrum_dgc_plugins
        #plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
        #plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_dgc_plugins']) for name in plugin_names]

    #for name, p in zip(plugin_names, plugin_modules):
        #try:
            #plugins.append( p.Plugin(config, name) )
        #except Exception:
            #print_msg(_(""Error: cannot initialize plugin""),p)
            #traceback.print_exc(file=sys.stdout)


hook_names = set()
hooks = {}

def hook(func):
    n = func.func_name
    if n not in hook_names:
        hook_names.add(n)
    return func


def run_hook(name, *args):
    results = []
    f_list = hooks.get(name,[])
    for p, f in f_list:
        if name == 'load_wallet':
            p.wallet = args[0]
        if not p.is_enabled():
            continue
        try:
            r = f(*args)
        except Exception:
            print_error(""Plugin error"")
            traceback.print_exc(file=sys.stdout)
            r = False
        if r:
            results.append(r)

    if results:
        assert len(results) == 1, results
        return results[0]


class BasePlugin:

    def __init__(self, config, name):
        self.name = name
        self.config = config
        # add self to hooks
        for k in dir(self):
            if k in hook_names:
                l = hooks.get(k, [])
                l.append((self, getattr(self, k)))
                hooks[k] = l

    def fullname(self):
        return self.name

    def description(self):
        return 'undefined'

    def requires_settings(self):
        return False
    
    def enable(self):
        self.set_enabled(True)
        return True

    def disable(self):
        self.set_enabled(False)
        return True

    def init_qt(self, gui): pass

    def load_wallet(self, wallet): pass

    #def init(self): pass

    def close(self): pass

    def is_enabled(self):
        return self.is_available() and self.config.get('use_'+self.name) is True

    def is_available(self):
        return True

    def set_enabled(self, enabled):
        self.config.set_key('use_'+self.name, enabled, True)

    def settings_dialog(self):
        pass

","
1from util import print_error
2import traceback, sys
3from util import *
4from i18n import _
5
6plugins = []
7
8
9def init_plugins(self):
10    import imp, pkgutil, __builtin__, os
11    global plugins
12
13    if __builtin__.use_local_modules:
14        fp, pathname, description = imp.find_module('plugins')
15        plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
16        plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
17        imp.load_module('electrum_dgc_plugins', fp, pathname, description)
18        plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
19    else:
20        import electrum_dgc_plugins
21        plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
22        plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_ltc_plugins']) for name in plugin_names]
23
24    for name, p in zip(plugin_names, plugin_modules):
25        try:
26            plugins.append( p.Plugin(self, name) )
27        except Exception:
28            print_msg(_(""Error: cannot initialize plugin""),p)
29            traceback.print_exc(file=sys.stdout)
30
31
32#def init_plugins(config):
33    #import imp, pkgutil, __builtin__, os
34    #global plugins
35
36    #if __builtin__.use_local_modules and False:
37        #fp, pathname, description = imp.find_module('plugins')
38        #plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
39        #plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
40        #imp.load_module('electrum_dgc_plugins', fp, pathname, description)
41        #plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
42    #else:
43        #import electrum_dgc_plugins
44        #plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
45        #plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_dgc_plugins']) for name in plugin_names]
46
47    #for name, p in zip(plugin_names, plugin_modules):
48        #try:
49            #plugins.append( p.Plugin(config, name) )
50        #except Exception:
51            #print_msg(_(""Error: cannot initialize plugin""),p)
52            #traceback.print_exc(file=sys.stdout)
53
54
55hook_names = set()
56hooks = {}
57
58def hook(func):
59    n = func.func_name
60    if n not in hook_names:
61        hook_names.add(n)
62    return func
63
64
65def run_hook(name, *args):
66    results = []
67    f_list = hooks.get(name,[])
68    for p, f in f_list:
69        if name == 'load_wallet':
70            p.wallet = args[0]
71        if not p.is_enabled():
72            continue
73        try:
74            r = f(*args)
75        except Exception:
76            print_error(""Plugin error"")
77            traceback.print_exc(file=sys.stdout)
78            r = False
79        if r:
80            results.append(r)
81
82    if results:
83        return results[0]
84
85
86class BasePlugin:
87
88    def __init__(self, config, name):
89        self.name = name
90        self.config = config
91        # add self to hooks
92        for k in dir(self):
93            if k in hook_names:
94                l = hooks.get(k, [])
95                l.append((self, getattr(self, k)))
96                hooks[k] = l
97
98    def fullname(self):
99        return self.name
100
101    def description(self):
102        return 'undefined'
103
104    def requires_settings(self):
105        return False
106    
107    def enable(self):
108        self.set_enabled(True)
109        return True
110
111    def disable(self):
112        self.set_enabled(False)
113        return True
114
115    def init_qt(self, gui): pass
116
117    def load_wallet(self, wallet): pass
118
119    #def init(self): pass
120
121    def close(self): pass
122
123    def is_enabled(self):
124        return self.is_available() and self.config.get('use_'+self.name) is True
125
126    def is_available(self):
127        return True
128
129    def set_enabled(self, enabled):
130        self.config.set_key('use_'+self.name, enabled, True)
131
132    def settings_dialog(self):
133        pass
134
135","[['len(results)', '==', '1']]",1,1,1.0,0.0002434867299732,"['plugins', 'fp', 'pathname', 'description', 'plugin_names', 'plugin_modules', 'config', '#fp', '#plugin_names', '#plugin_modules', 'hook_names', 'hooks', 'func', 'n', 'name', '*args', 'results', 'f_list', 'p.wallet', 'r', 'self.name', 'self.config', 'l', 'hooks[k]', 'gui', 'wallet', 'enabled']",27,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['plugins', 'fp', 'pathname', 'description', 'plugin_names', 'plugin_modules', 'config', '#fp', '#plugin_names', '#plugin_modules', 'hook_names', 'hooks', 'func', 'n', 'name', '*args', 'results', 'f_list', 'p.wallet', 'r', 'self.name', 'self.config', 'l', 'hooks[k]', 'gui', 'wallet', 'enabled']
*Code:

1from util import print_error
2import traceback, sys
3from util import *
4from i18n import _
5
6plugins = []
7
8
9def init_plugins(self):
10    import imp, pkgutil, __builtin__, os
11    global plugins
12
13    if __builtin__.use_local_modules:
14        fp, pathname, description = imp.find_module('plugins')
15        plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
16        plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
17        imp.load_module('electrum_dgc_plugins', fp, pathname, description)
18        plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
19    else:
20        import electrum_dgc_plugins
21        plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
22        plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_ltc_plugins']) for name in plugin_names]
23
24    for name, p in zip(plugin_names, plugin_modules):
25        try:
26            plugins.append( p.Plugin(self, name) )
27        except Exception:
28            print_msg(_(""Error: cannot initialize plugin""),p)
29            traceback.print_exc(file=sys.stdout)
30
31
32#def init_plugins(config):
33    #import imp, pkgutil, __builtin__, os
34    #global plugins
35
36    #if __builtin__.use_local_modules and False:
37        #fp, pathname, description = imp.find_module('plugins')
38        #plugin_names = [name for a, name, b in pkgutil.iter_modules([pathname])]
39        #plugin_names = filter( lambda name: os.path.exists(os.path.join(pathname,name+'.py')), plugin_names)
40        #imp.load_module('electrum_dgc_plugins', fp, pathname, description)
41        #plugin_modules = map(lambda name: imp.load_source('electrum_dgc_plugins.'+name, os.path.join(pathname,name+'.py')), plugin_names)
42    #else:
43        #import electrum_dgc_plugins
44        #plugin_names = [name for a, name, b in pkgutil.iter_modules(electrum_dgc_plugins.__path__)]
45        #plugin_modules = [ __import__('electrum_dgc_plugins.'+name, fromlist=['electrum_dgc_plugins']) for name in plugin_names]
46
47    #for name, p in zip(plugin_names, plugin_modules):
48        #try:
49            #plugins.append( p.Plugin(config, name) )
50        #except Exception:
51            #print_msg(_(""Error: cannot initialize plugin""),p)
52            #traceback.print_exc(file=sys.stdout)
53
54
55hook_names = set()
56hooks = {}
57
58def hook(func):
59    n = func.func_name
60    if n not in hook_names:
61        hook_names.add(n)
62    return func
63
64
65def run_hook(name, *args):
66    results = []
67    f_list = hooks.get(name,[])
68    for p, f in f_list:
69        if name == 'load_wallet':
70            p.wallet = args[0]
71        if not p.is_enabled():
72            continue
73        try:
74            r = f(*args)
75        except Exception:
76            print_error(""Plugin error"")
77            traceback.print_exc(file=sys.stdout)
78            r = False
79        if r:
80            results.append(r)
81
82    if results:
83        return results[0]
84
85
86class BasePlugin:
87
88    def __init__(self, config, name):
89        self.name = name
90        self.config = config
91        # add self to hooks
92        for k in dir(self):
93            if k in hook_names:
94                l = hooks.get(k, [])
95                l.append((self, getattr(self, k)))
96                hooks[k] = l
97
98    def fullname(self):
99        return self.name
100
101    def description(self):
102        return 'undefined'
103
104    def requires_settings(self):
105        return False
106    
107    def enable(self):
108        self.set_enabled(True)
109        return True
110
111    def disable(self):
112        self.set_enabled(False)
113        return True
114
115    def init_qt(self, gui): pass
116
117    def load_wallet(self, wallet): pass
118
119    #def init(self): pass
120
121    def close(self): pass
122
123    def is_enabled(self):
124        return self.is_available() and self.config.get('use_'+self.name) is True
125
126    def is_available(self):
127        return True
128
129    def set_enabled(self, enabled):
130        self.config.set_key('use_'+self.name, enabled, True)
131
132    def settings_dialog(self):
133        pass
134
135",6038,"[[9, 'self', '!=', None, 'function init_plugins requires a non null argument'],
 [24, 'plugin_names', '==', 'plugin_modules', 'plugin_names and plugin_modules should have the same length'],
 [60, 'func', '!=', None, 'function hook requires a non null argument'],
 [65, 'name', '!=', None, 'function run_hook requires a non-null argument for variable name'],
 [88, 'config', '!=', None, 'BasePlugin __init__ function requires a non-null argument for variable config'],
 [88, 'name', '!=', None, 'BasePlugin __init__ function requires a non-null argument for variable name'],
 [130, 'enabled', '!=', None, 'method set_enabled in BasePlugin requires a non-null argument for variable enabled']]"
chouseknecht/ansible,"# -*- coding: utf-8 -*-
#
# Copyright: (c) 2018, F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
import sys

if sys.version_info < (2, 7):
    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")

from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigiq_device_info import Parameters
    from library.modules.bigiq_device_info import SystemInfoFactManager
    from library.modules.bigiq_device_info import ModuleManager
    from library.modules.bigiq_device_info import ArgumentSpec

    # In Ansible 2.8, Ansible changed import paths.
    from test.units.compat import unittest
    from test.units.compat.mock import Mock

    from test.units.modules.utils import set_module_args
except ImportError:
    from ansible.modules.network.f5.bigiq_device_info import Parameters
    from ansible.modules.network.f5.bigiq_device_info import SystemInfoFactManager
    from ansible.modules.network.f5.bigiq_device_info import ModuleManager
    from ansible.modules.network.f5.bigiq_device_info import ArgumentSpec

    # Ansible 2.8 imports
    from units.compat import unittest
    from units.compat.mock import Mock

    from units.modules.utils import set_module_args


fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            gather_subset=['system-info'],
        )
        p = Parameters(params=args)
        assert p.gather_subset == ['system-info']


class TestManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()

    def test_get_facts(self, *args):
        set_module_args(dict(
            gather_subset=['system-info'],
            provider=dict(
                server='localhost',
                password='password',
                user='admin'
            )
        ))

        fixture1 = load_fixture('load_shared_system_setup_1.json')

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )

        tm = SystemInfoFactManager(module=module)
        tm.read_collection_from_device = Mock(return_value=fixture1)

        # Override methods to force specific logic in the module to happen
        mm = ModuleManager(module=module)
        mm.get_manager = Mock(return_value=tm)

        results = mm.exec_module()

        assert results['changed'] is True
        assert 'system_info' in results
","
1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2018, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigiq_device_info import Parameters
21    from library.modules.bigiq_device_info import SystemInfoFactManager
22    from library.modules.bigiq_device_info import ModuleManager
23    from library.modules.bigiq_device_info import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28
29    from test.units.modules.utils import set_module_args
30except ImportError:
31    from ansible.modules.network.f5.bigiq_device_info import Parameters
32    from ansible.modules.network.f5.bigiq_device_info import SystemInfoFactManager
33    from ansible.modules.network.f5.bigiq_device_info import ModuleManager
34    from ansible.modules.network.f5.bigiq_device_info import ArgumentSpec
35
36    # Ansible 2.8 imports
37    from units.compat import unittest
38    from units.compat.mock import Mock
39
40    from units.modules.utils import set_module_args
41
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            gather_subset=['system-info'],
69        )
70        p = Parameters(params=args)
71
72
73class TestManager(unittest.TestCase):
74
75    def setUp(self):
76        self.spec = ArgumentSpec()
77
78    def test_get_facts(self, *args):
79        set_module_args(dict(
80            gather_subset=['system-info'],
81            provider=dict(
82                server='localhost',
83                password='password',
84                user='admin'
85            )
86        ))
87
88        fixture1 = load_fixture('load_shared_system_setup_1.json')
89
90        module = AnsibleModule(
91            argument_spec=self.spec.argument_spec,
92            supports_check_mode=self.spec.supports_check_mode
93        )
94
95        tm = SystemInfoFactManager(module=module)
96        tm.read_collection_from_device = Mock(return_value=fixture1)
97
98        # Override methods to force specific logic in the module to happen
99        mm = ModuleManager(module=module)
100        mm.get_manager = Mock(return_value=tm)
101
102        results = mm.exec_module()
103
104","[['p.gather_subset', '==', ""['system-info']""], [""results['changed']"", '==', 'True']]",3,2,0.6666666666666666,0.0006600660066006,"['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'fixture1', 'module', 'tm', 'tm.read_collection_from_device', 'mm', 'mm.get_manager', 'results']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'fixture1', 'module', 'tm', 'tm.read_collection_from_device', 'mm', 'mm.get_manager', 'results']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2018, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigiq_device_info import Parameters
21    from library.modules.bigiq_device_info import SystemInfoFactManager
22    from library.modules.bigiq_device_info import ModuleManager
23    from library.modules.bigiq_device_info import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28
29    from test.units.modules.utils import set_module_args
30except ImportError:
31    from ansible.modules.network.f5.bigiq_device_info import Parameters
32    from ansible.modules.network.f5.bigiq_device_info import SystemInfoFactManager
33    from ansible.modules.network.f5.bigiq_device_info import ModuleManager
34    from ansible.modules.network.f5.bigiq_device_info import ArgumentSpec
35
36    # Ansible 2.8 imports
37    from units.compat import unittest
38    from units.compat.mock import Mock
39
40    from units.modules.utils import set_module_args
41
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            gather_subset=['system-info'],
69        )
70        p = Parameters(params=args)
71
72
73class TestManager(unittest.TestCase):
74
75    def setUp(self):
76        self.spec = ArgumentSpec()
77
78    def test_get_facts(self, *args):
79        set_module_args(dict(
80            gather_subset=['system-info'],
81            provider=dict(
82                server='localhost',
83                password='password',
84                user='admin'
85            )
86        ))
87
88        fixture1 = load_fixture('load_shared_system_setup_1.json')
89
90        module = AnsibleModule(
91            argument_spec=self.spec.argument_spec,
92            supports_check_mode=self.spec.supports_check_mode
93        )
94
95        tm = SystemInfoFactManager(module=module)
96        tm.read_collection_from_device = Mock(return_value=fixture1)
97
98        # Override methods to force specific logic in the module to happen
99        mm = ModuleManager(module=module)
100        mm.get_manager = Mock(return_value=tm)
101
102        results = mm.exec_module()
103
104",4724,"[[14, 'sys.version_info', '>=', (2, 7), ""F5 Ansible modules require Python >= 2.7""],
 [48, 'os.path.join(fixture_path, name)', '!=', None, ""Ensures the constructed path is not None""],
 [54, 'f', '!=', None, ""File handle should not be None so data can be read""],
 [57, 'data', '!=', None, ""Ensure json data is loaded properly""],
 [71, 'args', '==', dict(gather_subset=['system_info']), ""Ensure proper arguments are set""],
 [95, 'module', '!=', None, ""Ensure module is set""],
 [97, 'tm.read_collection_from_device', '!=', None, ""Ensure that the mocking return value is set""],
 [100, 'mm.get_manager', '!=', None, ""Ensure mock return value is set""],
 [102, 'results', '!=', None, ""Ensure results are being set""]]"
ManageIQ/integration_tests,"""""""REST API specific automate tests.""""""
from datetime import datetime

import fauxfactory
import pytest
from dateparser import parse

from cfme import test_requirements
from cfme.utils.appliance.implementations.ui import navigate_to
from cfme.utils.blockers import BZ
from cfme.utils.rest import assert_response
from cfme.utils.rest import delete_resources_from_collection
from cfme.utils.rest import delete_resources_from_detail


pytestmark = [test_requirements.rest, pytest.mark.tier(3)]


@pytest.fixture(scope=""function"")
def domain_rest(appliance, domain):
    domain = appliance.collections.domains.create(
        name=fauxfactory.gen_alpha(), description=fauxfactory.gen_alpha(), enabled=True
    )
    yield appliance.rest_api.collections.automate_domains.get(name=domain.name)
    domain.delete_if_exists()


def test_rest_search_automate(appliance):
    """"""
    Polarion:
        assignee: pvala
        caseimportance: low
        casecomponent: Automate
        initialEstimate: 1/3h
    """"""
    rest_api = appliance.rest_api

    def _do_query(**kwargs):
        response = rest_api.collections.automate.query_string(**kwargs)
        assert rest_api.response.status_code == 200
        return response

    more_depth = _do_query(depth='2')
    full_depth = _do_query(depth='-1')
    filtered_depth = _do_query(depth='-1', search_options='state_machines')
    assert len(full_depth) > len(more_depth) > len(rest_api.collections.automate)
    assert len(full_depth) > len(filtered_depth) > 0


@pytest.mark.ignore_stream(""5.10"")
@pytest.mark.parametrize(""method"", [""POST"", ""DELETE""])
def test_delete_automate_domain_from_detail(domain_rest, method):
    """"""
    Polarion:
        assignee: pvala
        casecomponent: Automate
        initialEstimate: 1/10h
    """"""
    delete_resources_from_detail([domain_rest], method=method, num_sec=50)


@pytest.mark.ignore_stream(""5.10"")
def test_delete_automate_domain_from_collection(domain_rest):
    """"""
    Polarion:
        assignee: pvala
        casecomponent: Automate
        initialEstimate: 1/10h
    """"""
    delete_resources_from_collection([domain_rest], not_found=True, num_sec=50)


@pytest.mark.ignore_stream(""5.10"")
@pytest.mark.tier(2)
@pytest.mark.meta(
    automates=[1486765, 1740340],
    blockers=[BZ(1740340, unblock=lambda scheduler: scheduler != ""exact_time"")],
)
@pytest.mark.parametrize(""scheduler"", [""number_of_days"", ""exact_time""])
@test_requirements.rest
def test_schedule_automation_request(appliance, scheduler):
    """"""
    Bugzilla:
        1740340
        1486765

    Polarion:
        assignee: pvala
        caseimportance: high
        casecomponent: Rest
        initialEstimate: 1/4h
        testSteps:
            1. Send a request POST /api/automation_requests
                {
                    ""uri_parts"" : {
                        ""namespace"" : ""System"",
                        ""class""     : ""Request"",
                        ""instance""  : ""InspectME"",
                        ""message""   : ""create""
                    },
                    ""parameters"" : {
                        ""var1"" : ""value 1"",
                        ""var2"" : ""value 2"",
                        ""minimum_memory"" : 2048,
                        ""schedule_time"": scheduler
                    },
                    ""requester"" : {
                        ""auto_approve"" : true
                    }
                }
            2. Compare the `created_on` and `options::schedule_time` from the response.
        expectedResults:
            1. Request must be successful.
            2.Difference between the two dates must be equal to scheduler
    """"""
    schedule_time = ""2"" if scheduler == ""number_of_days"" else ""2019-08-14 17:41:06 UTC""
    automate_request_rest = appliance.rest_api.collections.automation_requests.action.create(
        {
            ""uri_parts"": {
                ""namespace"": ""System"",
                ""class"": ""Request"",
                ""instance"": ""InspectME"",
                ""message"": ""create"",
            },
            ""parameters"": {
                ""var1"": ""value 1"",
                ""var2"": ""value 2"",
                ""minimum_memory"": 2048,
                ""schedule_time"": schedule_time,
            },
            ""requester"": {""auto_approve"": True},
        }
    )[0]
    assert_response(appliance)

    automate_request = appliance.collections.automation_requests.instantiate(
        description=automate_request_rest.description
    )

    # This step tests another error that occurred when navigating to the Details page
    view = navigate_to(automate_request, ""Details"")
    assert view.is_displayed

    def _convert(date):
        # convert dates to a certain format for easy comparison
        date_format = ""%m/%d/%y %H:%M""
        return datetime.strptime(datetime.strftime(date, date_format), date_format)

    scheduled = _convert(parse(automate_request_rest.options[""schedule_time""]))

    if scheduler == ""number_of_days"":
        created_on = _convert(automate_request_rest.created_on)
        difference = scheduled - created_on
        assert str(difference.days) == schedule_time
    else:
        assert _convert(parse(schedule_time)) == scheduled
","
1""""""REST API specific automate tests.""""""
2from datetime import datetime
3
4import fauxfactory
5import pytest
6from dateparser import parse
7
8from cfme import test_requirements
9from cfme.utils.appliance.implementations.ui import navigate_to
10from cfme.utils.blockers import BZ
11from cfme.utils.rest import delete_resources_from_collection
12from cfme.utils.rest import delete_resources_from_detail
13
14
15pytestmark = [test_requirements.rest, pytest.mark.tier(3)]
16
17
18@pytest.fixture(scope=""function"")
19def domain_rest(appliance, domain):
20    domain = appliance.collections.domains.create(
21        name=fauxfactory.gen_alpha(), description=fauxfactory.gen_alpha(), enabled=True
22    )
23    yield appliance.rest_api.collections.automate_domains.get(name=domain.name)
24    domain.delete_if_exists()
25
26
27def test_rest_search_automate(appliance):
28    """"""
29    Polarion:
30        assignee: pvala
31        caseimportance: low
32        casecomponent: Automate
33        initialEstimate: 1/3h
34    """"""
35    rest_api = appliance.rest_api
36
37    def _do_query(**kwargs):
38        response = rest_api.collections.automate.query_string(**kwargs)
39        return response
40
41    more_depth = _do_query(depth='2')
42    full_depth = _do_query(depth='-1')
43    filtered_depth = _do_query(depth='-1', search_options='state_machines')
44
45
46@pytest.mark.ignore_stream(""5.10"")
47@pytest.mark.parametrize(""method"", [""POST"", ""DELETE""])
48def test_delete_automate_domain_from_detail(domain_rest, method):
49    """"""
50    Polarion:
51        assignee: pvala
52        casecomponent: Automate
53        initialEstimate: 1/10h
54    """"""
55    delete_resources_from_detail([domain_rest], method=method, num_sec=50)
56
57
58@pytest.mark.ignore_stream(""5.10"")
59def test_delete_automate_domain_from_collection(domain_rest):
60    """"""
61    Polarion:
62        assignee: pvala
63        casecomponent: Automate
64        initialEstimate: 1/10h
65    """"""
66    delete_resources_from_collection([domain_rest], not_found=True, num_sec=50)
67
68
69@pytest.mark.ignore_stream(""5.10"")
70@pytest.mark.tier(2)
71@pytest.mark.meta(
72    automates=[1486765, 1740340],
73    blockers=[BZ(1740340, unblock=lambda scheduler: scheduler != ""exact_time"")],
74)
75@pytest.mark.parametrize(""scheduler"", [""number_of_days"", ""exact_time""])
76@test_requirements.rest
77def test_schedule_automation_request(appliance, scheduler):
78    """"""
79    Bugzilla:
80        1740340
81        1486765
82
83    Polarion:
84        assignee: pvala
85        caseimportance: high
86        casecomponent: Rest
87        initialEstimate: 1/4h
88        testSteps:
89            1. Send a request POST /api/automation_requests
90                {
91                    ""uri_parts"" : {
92                        ""namespace"" : ""System"",
93                        ""class""     : ""Request"",
94                        ""instance""  : ""InspectME"",
95                        ""message""   : ""create""
96                    },
97                    ""parameters"" : {
98                        ""var1"" : ""value 1"",
99                        ""var2"" : ""value 2"",
100                        ""minimum_memory"" : 2048,
101                        ""schedule_time"": scheduler
102                    },
103                    ""requester"" : {
104                        ""auto_approve"" : true
105                    }
106                }
107            2. Compare the `created_on` and `options::schedule_time` from the response.
108        expectedResults:
109            1. Request must be successful.
110            2.Difference between the two dates must be equal to scheduler
111    """"""
112    schedule_time = ""2"" if scheduler == ""number_of_days"" else ""2019-08-14 17:41:06 UTC""
113    automate_request_rest = appliance.rest_api.collections.automation_requests.action.create(
114        {
115            ""uri_parts"": {
116                ""namespace"": ""System"",
117                ""class"": ""Request"",
118                ""instance"": ""InspectME"",
119                ""message"": ""create"",
120            },
121            ""parameters"": {
122                ""var1"": ""value 1"",
123                ""var2"": ""value 2"",
124                ""minimum_memory"": 2048,
125                ""schedule_time"": schedule_time,
126            },
127            ""requester"": {""auto_approve"": True},
128        }
129    )[0]
130
131    automate_request = appliance.collections.automation_requests.instantiate(
132        description=automate_request_rest.description
133    )
134
135    # This step tests another error that occurred when navigating to the Details page
136    view = navigate_to(automate_request, ""Details"")
137
138    def _convert(date):
139        # convert dates to a certain format for easy comparison
140        date_format = ""%m/%d/%y %H:%M""
141        return datetime.strptime(datetime.strftime(date, date_format), date_format)
142
143    scheduled = _convert(parse(automate_request_rest.options[""schedule_time""]))
144
145    if scheduler == ""number_of_days"":
146        created_on = _convert(automate_request_rest.created_on)
147        difference = scheduled - created_on
148    else:
149","[['rest_api.response.status_code', '==', '200'], ['len(full_depth)', '>', 'len(more_depth) > len(rest_api.collections.automate)'], ['len(full_depth)', '>', 'len(filtered_depth) > 0'], ['view.is_displayed', '==', 'True'], ['str(difference.days)', '==', 'schedule_time'], ['_convert(parse(schedule_time))', '==', 'scheduled']]",8,6,0.75,0.0011542901115813,"['pytestmark', 'appliance', 'domain', 'rest_api', '**kwargs', 'response', 'more_depth', 'full_depth', 'filtered_depth', 'domain_rest', 'method', 'scheduler', 'schedule_time', 'automate_request_rest', 'automate_request', 'view', 'date', 'date_format', 'scheduled', 'created_on', 'difference']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pytestmark', 'appliance', 'domain', 'rest_api', '**kwargs', 'response', 'more_depth', 'full_depth', 'filtered_depth', 'domain_rest', 'method', 'scheduler', 'schedule_time', 'automate_request_rest', 'automate_request', 'view', 'date', 'date_format', 'scheduled', 'created_on', 'difference']
*Code:

1""""""REST API specific automate tests.""""""
2from datetime import datetime
3
4import fauxfactory
5import pytest
6from dateparser import parse
7
8from cfme import test_requirements
9from cfme.utils.appliance.implementations.ui import navigate_to
10from cfme.utils.blockers import BZ
11from cfme.utils.rest import delete_resources_from_collection
12from cfme.utils.rest import delete_resources_from_detail
13
14
15pytestmark = [test_requirements.rest, pytest.mark.tier(3)]
16
17
18@pytest.fixture(scope=""function"")
19def domain_rest(appliance, domain):
20    domain = appliance.collections.domains.create(
21        name=fauxfactory.gen_alpha(), description=fauxfactory.gen_alpha(), enabled=True
22    )
23    yield appliance.rest_api.collections.automate_domains.get(name=domain.name)
24    domain.delete_if_exists()
25
26
27def test_rest_search_automate(appliance):
28    """"""
29    Polarion:
30        assignee: pvala
31        caseimportance: low
32        casecomponent: Automate
33        initialEstimate: 1/3h
34    """"""
35    rest_api = appliance.rest_api
36
37    def _do_query(**kwargs):
38        response = rest_api.collections.automate.query_string(**kwargs)
39        return response
40
41    more_depth = _do_query(depth='2')
42    full_depth = _do_query(depth='-1')
43    filtered_depth = _do_query(depth='-1', search_options='state_machines')
44
45
46@pytest.mark.ignore_stream(""5.10"")
47@pytest.mark.parametrize(""method"", [""POST"", ""DELETE""])
48def test_delete_automate_domain_from_detail(domain_rest, method):
49    """"""
50    Polarion:
51        assignee: pvala
52        casecomponent: Automate
53        initialEstimate: 1/10h
54    """"""
55    delete_resources_from_detail([domain_rest], method=method, num_sec=50)
56
57
58@pytest.mark.ignore_stream(""5.10"")
59def test_delete_automate_domain_from_collection(domain_rest):
60    """"""
61    Polarion:
62        assignee: pvala
63        casecomponent: Automate
64        initialEstimate: 1/10h
65    """"""
66    delete_resources_from_collection([domain_rest], not_found=True, num_sec=50)
67
68
69@pytest.mark.ignore_stream(""5.10"")
70@pytest.mark.tier(2)
71@pytest.mark.meta(
72    automates=[1486765, 1740340],
73    blockers=[BZ(1740340, unblock=lambda scheduler: scheduler != ""exact_time"")],
74)
75@pytest.mark.parametrize(""scheduler"", [""number_of_days"", ""exact_time""])
76@test_requirements.rest
77def test_schedule_automation_request(appliance, scheduler):
78    """"""
79    Bugzilla:
80        1740340
81        1486765
82
83    Polarion:
84        assignee: pvala
85        caseimportance: high
86        casecomponent: Rest
87        initialEstimate: 1/4h
88        testSteps:
89            1. Send a request POST /api/automation_requests
90                {
91                    ""uri_parts"" : {
92                        ""namespace"" : ""System"",
93                        ""class""     : ""Request"",
94                        ""instance""  : ""InspectME"",
95                        ""message""   : ""create""
96                    },
97                    ""parameters"" : {
98                        ""var1"" : ""value 1"",
99                        ""var2"" : ""value 2"",
100                        ""minimum_memory"" : 2048,
101                        ""schedule_time"": scheduler
102                    },
103                    ""requester"" : {
104                        ""auto_approve"" : true
105                    }
106                }
107            2. Compare the `created_on` and `options::schedule_time` from the response.
108        expectedResults:
109            1. Request must be successful.
110            2.Difference between the two dates must be equal to scheduler
111    """"""
112    schedule_time = ""2"" if scheduler == ""number_of_days"" else ""2019-08-14 17:41:06 UTC""
113    automate_request_rest = appliance.rest_api.collections.automation_requests.action.create(
114        {
115            ""uri_parts"": {
116                ""namespace"": ""System"",
117                ""class"": ""Request"",
118                ""instance"": ""InspectME"",
119                ""message"": ""create"",
120            },
121            ""parameters"": {
122                ""var1"": ""value 1"",
123                ""var2"": ""value 2"",
124                ""minimum_memory"": 2048,
125                ""schedule_time"": schedule_time,
126            },
127            ""requester"": {""auto_approve"": True},
128        }
129    )[0]
130
131    automate_request = appliance.collections.automation_requests.instantiate(
132        description=automate_request_rest.description
133    )
134
135    # This step tests another error that occurred when navigating to the Details page
136    view = navigate_to(automate_request, ""Details"")
137
138    def _convert(date):
139        # convert dates to a certain format for easy comparison
140        date_format = ""%m/%d/%y %H:%M""
141        return datetime.strptime(datetime.strftime(date, date_format), date_format)
142
143    scheduled = _convert(parse(automate_request_rest.options[""schedule_time""]))
144
145    if scheduler == ""number_of_days"":
146        created_on = _convert(automate_request_rest.created_on)
147        difference = scheduled - created_on
148    else:
149",6806,"[[19, 'domain', '!=', None, 'the domain object should not be None'],
[27, 'appliance', '!=', None, 'appliance object should not be None'],
[37, '**kwargs', '!=', None, 'Keyword arguments should not be None'],
[38, 'response', '!=', None, 'response should not be None'],
[41, 'more_depth', '!=', None, 'more_depth variable should not be None'],
[42, 'full_depth', '!=', None, 'full_depth variable should not be None'],
[43, 'filtered_depth', '!=', None, 'filtered_depth variable should not be None'],
[47, 'method', '!=', None, 'method variable should not be None'],
[59, 'domain_rest', '!=', None, 'domain_rest object should not be None'],
[77, 'scheduler', '!=', None, 'scheduler variable should not be None'],
[112, 'schedule_time', '!=', None, 'schedule_time variable should not be None'],
[113, 'automate_request_rest', '!=', None, 'automate_request_rest object should not be None'],
[131, 'automate_request', '!=', None, 'automate_request object should not be None'],
[135, 'view', '!=', None, 'view object should not be None'],
[140, 'date_format', '==', ""%m/%d/%y %H:%M"", 'date_format must be in ""%m/%d/%y %H:%M"" format'],
[143, 'scheduled', '!=', None, 'scheduled variable should not be None'],
[146, 'created_on', '!=', None, 'created_on variable should not be None']]"
thesuperzapper/tensorflow,"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Boston housing price regression dataset.
""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np

from tensorflow.contrib.keras.python.keras.utils.data_utils import get_file


def load_data(path='boston_housing.npz', seed=113, test_split=0.2):
  """"""Loads the Boston Housing dataset.

  Arguments:
      path: path where to cache the dataset locally
          (relative to ~/.keras/datasets).
      seed: Random seed for shuffling the data
          before computing the test split.
      test_split: fraction of the data to reserve as test set.

  Returns:
      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.
  """"""
  assert 0 <= test_split < 1
  path = get_file(
      path, origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz')
  f = np.load(path)
  x = f['x']
  y = f['y']
  f.close()

  np.random.seed(seed)
  np.random.shuffle(x)
  np.random.seed(seed)
  np.random.shuffle(y)

  x_train = np.array(x[:int(len(x) * (1 - test_split))])
  y_train = np.array(y[:int(len(x) * (1 - test_split))])
  x_test = np.array(x[int(len(x) * (1 - test_split)):])
  y_test = np.array(y[int(len(x) * (1 - test_split)):])
  return (x_train, y_train), (x_test, y_test)
","
1# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14# ==============================================================================
15""""""Boston housing price regression dataset.
16""""""
17from __future__ import absolute_import
18from __future__ import division
19from __future__ import print_function
20
21import numpy as np
22
23from tensorflow.contrib.keras.python.keras.utils.data_utils import get_file
24
25
26def load_data(path='boston_housing.npz', seed=113, test_split=0.2):
27  """"""Loads the Boston Housing dataset.
28
29  Arguments:
30      path: path where to cache the dataset locally
31          (relative to ~/.keras/datasets).
32      seed: Random seed for shuffling the data
33          before computing the test split.
34      test_split: fraction of the data to reserve as test set.
35
36  Returns:
37      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.
38  """"""
39  path = get_file(
40      path, origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz')
41  f = np.load(path)
42  x = f['x']
43  y = f['y']
44  f.close()
45
46  np.random.seed(seed)
47  np.random.shuffle(x)
48  np.random.seed(seed)
49  np.random.shuffle(y)
50
51  x_train = np.array(x[:int(len(x) * (1 - test_split))])
52  y_train = np.array(y[:int(len(x) * (1 - test_split))])
53  x_test = np.array(x[int(len(x) * (1 - test_split)):])
54  y_test = np.array(y[int(len(x) * (1 - test_split)):])
55  return (x_train, y_train), (x_test, y_test)
56","[['0', '<=', 'test_split < 1']]",1,1,1.0,0.0005117707267144,"['path', 'seed', 'test_split', 'f', 'x', 'y', 'x_train', 'y_train', 'x_test', 'y_test']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['path', 'seed', 'test_split', 'f', 'x', 'y', 'x_train', 'y_train', 'x_test', 'y_test']
*Code:

1# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14# ==============================================================================
15""""""Boston housing price regression dataset.
16""""""
17from __future__ import absolute_import
18from __future__ import division
19from __future__ import print_function
20
21import numpy as np
22
23from tensorflow.contrib.keras.python.keras.utils.data_utils import get_file
24
25
26def load_data(path='boston_housing.npz', seed=113, test_split=0.2):
27  """"""Loads the Boston Housing dataset.
28
29  Arguments:
30      path: path where to cache the dataset locally
31          (relative to ~/.keras/datasets).
32      seed: Random seed for shuffling the data
33          before computing the test split.
34      test_split: fraction of the data to reserve as test set.
35
36  Returns:
37      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.
38  """"""
39  path = get_file(
40      path, origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz')
41  f = np.load(path)
42  x = f['x']
43  y = f['y']
44  f.close()
45
46  np.random.seed(seed)
47  np.random.shuffle(x)
48  np.random.seed(seed)
49  np.random.shuffle(y)
50
51  x_train = np.array(x[:int(len(x) * (1 - test_split))])
52  y_train = np.array(y[:int(len(x) * (1 - test_split))])
53  x_test = np.array(x[int(len(x) * (1 - test_split)):])
54  y_test = np.array(y[int(len(x) * (1 - test_split)):])
55  return (x_train, y_train), (x_test, y_test)
56",3496,"[[26, 'path', '!=', '', 'assert that the path for the dataset is provided'],
[26, 'seed', '>=', 0, 'assert that the seed for random shuffling is a non-negative integer'],
[26, 'test_split', '>=', 0, 'assert that the fraction for test set splitting is non-negative'],
[26, 'test_split', '<=', 1, 'assert that the fraction for test set splitting is no greater than 1'],
[51, 'x_train', '==', 'y_train', 'assert that the length of x_train and y_train should be equal, since they should match one-to-one'],
[53, 'x_test', '==', 'y_test', 'assert that the length of x_test and y_test should be equal, since they should match one-to-one']]"
trishnaguha/ansible,"# -*- coding: utf-8 -*-
#
# Copyright: (c) 2017, F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
import sys

if sys.version_info < (2, 7):
    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")

from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigip_smtp import ApiParameters
    from library.modules.bigip_smtp import ModuleParameters
    from library.modules.bigip_smtp import ModuleManager
    from library.modules.bigip_smtp import ArgumentSpec

    # In Ansible 2.8, Ansible changed import paths.
    from test.units.compat import unittest
    from test.units.compat.mock import Mock
    from test.units.compat.mock import patch

    from test.units.modules.utils import set_module_args
except ImportError:
    from ansible.modules.network.f5.bigip_smtp import ApiParameters
    from ansible.modules.network.f5.bigip_smtp import ModuleParameters
    from ansible.modules.network.f5.bigip_smtp import ModuleManager
    from ansible.modules.network.f5.bigip_smtp import ArgumentSpec

    # Ansible 2.8 imports
    from units.compat import unittest
    from units.compat.mock import Mock
    from units.compat.mock import patch

    from units.modules.utils import set_module_args


fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            name='foo',
            smtp_server='1.1.1.1',
            smtp_server_port='25',
            smtp_server_username='admin',
            smtp_server_password='password',
            local_host_name='smtp.mydomain.com',
            encryption='tls',
            update_password='always',
            from_address='no-reply@mydomain.com',
            authentication=True,
        )

        p = ModuleParameters(params=args)
        assert p.name == 'foo'
        assert p.smtp_server == '1.1.1.1'
        assert p.smtp_server_port == 25
        assert p.smtp_server_username == 'admin'
        assert p.smtp_server_password == 'password'
        assert p.local_host_name == 'smtp.mydomain.com'
        assert p.encryption == 'tls'
        assert p.update_password == 'always'
        assert p.from_address == 'no-reply@mydomain.com'
        assert p.authentication_disabled is None
        assert p.authentication_enabled is True

    def test_api_parameters(self):
        p = ApiParameters(params=load_fixture('load_sys_smtp_server.json'))
        assert p.name == 'foo'
        assert p.smtp_server == 'mail.foo.bar'
        assert p.smtp_server_port == 465
        assert p.smtp_server_username == 'admin'
        assert p.smtp_server_password == '$M$Ch$this-is-encrypted=='
        assert p.local_host_name == 'mail-host.foo.bar'
        assert p.encryption == 'ssl'
        assert p.from_address == 'no-reply@foo.bar'
        assert p.authentication_disabled is None
        assert p.authentication_enabled is True


class TestManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()

    def test_create_monitor(self, *args):
        set_module_args(dict(
            name='foo',
            smtp_server='1.1.1.1',
            smtp_server_port='25',
            smtp_server_username='admin',
            smtp_server_password='password',
            local_host_name='smtp.mydomain.com',
            encryption='tls',
            update_password='always',
            from_address='no-reply@mydomain.com',
            authentication=True,
            partition='Common',
            server='localhost',
            password='password',
            user='admin'
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )

        # Override methods in the specific type of manager
        mm = ModuleManager(module=module)
        mm.exists = Mock(side_effect=[False, True])
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
        assert results['encryption'] == 'tls'
        assert results['smtp_server'] == '1.1.1.1'
        assert results['smtp_server_port'] == 25
        assert results['local_host_name'] == 'smtp.mydomain.com'
        assert results['authentication'] is True
        assert results['from_address'] == 'no-reply@mydomain.com'
        assert 'smtp_server_username' not in results
        assert 'smtp_server_password' not in results
","
1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_smtp import ApiParameters
21    from library.modules.bigip_smtp import ModuleParameters
22    from library.modules.bigip_smtp import ModuleManager
23    from library.modules.bigip_smtp import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    from ansible.modules.network.f5.bigip_smtp import ApiParameters
33    from ansible.modules.network.f5.bigip_smtp import ModuleParameters
34    from ansible.modules.network.f5.bigip_smtp import ModuleManager
35    from ansible.modules.network.f5.bigip_smtp import ArgumentSpec
36
37    # Ansible 2.8 imports
38    from units.compat import unittest
39    from units.compat.mock import Mock
40    from units.compat.mock import patch
41
42    from units.modules.utils import set_module_args
43
44
45fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
46fixture_data = {}
47
48
49def load_fixture(name):
50    path = os.path.join(fixture_path, name)
51
52    if path in fixture_data:
53        return fixture_data[path]
54
55    with open(path) as f:
56        data = f.read()
57
58    try:
59        data = json.loads(data)
60    except Exception:
61        pass
62
63    fixture_data[path] = data
64    return data
65
66
67class TestParameters(unittest.TestCase):
68    def test_module_parameters(self):
69        args = dict(
70            name='foo',
71            smtp_server='1.1.1.1',
72            smtp_server_port='25',
73            smtp_server_username='admin',
74            smtp_server_password='password',
75            local_host_name='smtp.mydomain.com',
76            encryption='tls',
77            update_password='always',
78            from_address='no-reply@mydomain.com',
79            authentication=True,
80        )
81
82        p = ModuleParameters(params=args)
83
84    def test_api_parameters(self):
85        p = ApiParameters(params=load_fixture('load_sys_smtp_server.json'))
86
87
88class TestManager(unittest.TestCase):
89
90    def setUp(self):
91        self.spec = ArgumentSpec()
92
93    def test_create_monitor(self, *args):
94        set_module_args(dict(
95            name='foo',
96            smtp_server='1.1.1.1',
97            smtp_server_port='25',
98            smtp_server_username='admin',
99            smtp_server_password='password',
100            local_host_name='smtp.mydomain.com',
101            encryption='tls',
102            update_password='always',
103            from_address='no-reply@mydomain.com',
104            authentication=True,
105            partition='Common',
106            server='localhost',
107            password='password',
108            user='admin'
109        ))
110
111        module = AnsibleModule(
112            argument_spec=self.spec.argument_spec,
113            supports_check_mode=self.spec.supports_check_mode
114        )
115
116        # Override methods in the specific type of manager
117        mm = ModuleManager(module=module)
118        mm.exists = Mock(side_effect=[False, True])
119        mm.create_on_device = Mock(return_value=True)
120
121        results = mm.exec_module()
122
123","[['p.name', '==', ""'foo'""], ['p.smtp_server', '==', ""'1.1.1.1'""], ['p.smtp_server_port', '==', '25'], ['p.smtp_server_username', '==', ""'admin'""], ['p.smtp_server_password', '==', ""'password'""], ['p.local_host_name', '==', ""'smtp.mydomain.com'""], ['p.encryption', '==', ""'tls'""], ['p.update_password', '==', ""'always'""], ['p.from_address', '==', ""'no-reply@mydomain.com'""], ['p.authentication_disabled', '==', 'None'], ['p.authentication_enabled', '==', 'True'], ['p.name', '==', ""'foo'""], ['p.smtp_server', '==', ""'mail.foo.bar'""], ['p.smtp_server_port', '==', '465'], ['p.smtp_server_username', '==', ""'admin'""], ['p.smtp_server_password', '==', ""'$M$Ch$this-is-encrypted=='""], ['p.local_host_name', '==', ""'mail-host.foo.bar'""], ['p.encryption', '==', ""'ssl'""], ['p.from_address', '==', ""'no-reply@foo.bar'""], ['p.authentication_disabled', '==', 'None'], ['p.authentication_enabled', '==', 'True'], [""results['changed']"", '==', 'True'], [""results['encryption']"", '==', ""'tls'""], [""results['smtp_server']"", '==', ""'1.1.1.1'""], [""results['smtp_server_port']"", '==', '25'], [""results['local_host_name']"", '==', ""'smtp.mydomain.com'""], [""results['authentication']"", '==', 'True'], [""results['from_address']"", '==', ""'no-reply@mydomain.com'""]]",30,28,0.9333333333333332,0.0055821371610845,"['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_smtp import ApiParameters
21    from library.modules.bigip_smtp import ModuleParameters
22    from library.modules.bigip_smtp import ModuleManager
23    from library.modules.bigip_smtp import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    from ansible.modules.network.f5.bigip_smtp import ApiParameters
33    from ansible.modules.network.f5.bigip_smtp import ModuleParameters
34    from ansible.modules.network.f5.bigip_smtp import ModuleManager
35    from ansible.modules.network.f5.bigip_smtp import ArgumentSpec
36
37    # Ansible 2.8 imports
38    from units.compat import unittest
39    from units.compat.mock import Mock
40    from units.compat.mock import patch
41
42    from units.modules.utils import set_module_args
43
44
45fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
46fixture_data = {}
47
48
49def load_fixture(name):
50    path = os.path.join(fixture_path, name)
51
52    if path in fixture_data:
53        return fixture_data[path]
54
55    with open(path) as f:
56        data = f.read()
57
58    try:
59        data = json.loads(data)
60    except Exception:
61        pass
62
63    fixture_data[path] = data
64    return data
65
66
67class TestParameters(unittest.TestCase):
68    def test_module_parameters(self):
69        args = dict(
70            name='foo',
71            smtp_server='1.1.1.1',
72            smtp_server_port='25',
73            smtp_server_username='admin',
74            smtp_server_password='password',
75            local_host_name='smtp.mydomain.com',
76            encryption='tls',
77            update_password='always',
78            from_address='no-reply@mydomain.com',
79            authentication=True,
80        )
81
82        p = ModuleParameters(params=args)
83
84    def test_api_parameters(self):
85        p = ApiParameters(params=load_fixture('load_sys_smtp_server.json'))
86
87
88class TestManager(unittest.TestCase):
89
90    def setUp(self):
91        self.spec = ArgumentSpec()
92
93    def test_create_monitor(self, *args):
94        set_module_args(dict(
95            name='foo',
96            smtp_server='1.1.1.1',
97            smtp_server_port='25',
98            smtp_server_username='admin',
99            smtp_server_password='password',
100            local_host_name='smtp.mydomain.com',
101            encryption='tls',
102            update_password='always',
103            from_address='no-reply@mydomain.com',
104            authentication=True,
105            partition='Common',
106            server='localhost',
107            password='password',
108            user='admin'
109        ))
110
111        module = AnsibleModule(
112            argument_spec=self.spec.argument_spec,
113            supports_check_mode=self.spec.supports_check_mode
114        )
115
116        # Override methods in the specific type of manager
117        mm = ModuleManager(module=module)
118        mm.exists = Mock(side_effect=[False, True])
119        mm.create_on_device = Mock(return_value=True)
120
121        results = mm.exec_module()
122
123",5406,"[[44, 'fixture_path', '!=', None, 'Path to the fixture should not be None'],
[44, 'fixture_path', '>=', 1, 'Path to the fixture should not be empty'],
[48, 'fixture_data', '==', {}, 'fixture_data should be an empty dictionary initially'],
[81, 'args', '!=', None, 'Arguments should not be None for module parameters'],
[101, 'args', '>=', 1, 'There should be at least one argument for module parameters'],
[115, 'self.spec', '!=', None, 'self.spec should not be None for the module'],
[119, 'mm.exists', '!=', None, 'Mock exists method should be set for the module manager'],
[120, 'mm.create_on_device', '!=', None, 'Mock create_on_device method should be set for the module manager'],
[122, 'results', '!=', None, 'The exec_module method should return some results']]"
argonemyth/sentry,"from __future__ import absolute_import

from mock import Mock

from sentry.auth import access
from sentry.models import AuthProvider
from sentry.testutils import TestCase


class FromUserTest(TestCase):
    def test_no_access(self):
        organization = self.create_organization()
        team = self.create_team(organization=organization)
        user = self.create_user()

        result = access.from_user(user, organization)
        assert not result.is_active
        assert result.sso_is_valid
        assert not result.scopes
        assert not result.has_team(team)

    def test_global_org_member_access(self):
        user = self.create_user()
        organization = self.create_organization(owner=user)
        member = organization.member_set.get(user=user)
        team = self.create_team(organization=organization)

        result = access.from_user(user, organization)
        assert result.is_active
        assert result.sso_is_valid
        assert result.scopes == member.get_scopes()
        assert result.has_team(team)

    def test_team_restricted_org_member_access(self):
        user = self.create_user()
        organization = self.create_organization()
        team = self.create_team(organization=organization)
        member = self.create_member(
            organization=organization,
            user=user,
            has_global_access=False,
            teams=[team],
        )

        result = access.from_user(user, organization)
        assert result.is_active
        assert result.sso_is_valid
        assert result.scopes == member.get_scopes()
        assert result.has_team(team)

    def test_unlinked_sso(self):
        user = self.create_user()
        organization = self.create_organization(owner=user)
        member = organization.member_set.get(user=user)
        team = self.create_team(organization=organization)
        AuthProvider.objects.create(
            organization=organization,
            provider='dummy',
        )

        result = access.from_user(user, organization)
        assert not result.sso_is_valid

    def test_sso_without_link_requirement(self):
        user = self.create_user()
        organization = self.create_organization(owner=user)
        member = organization.member_set.get(user=user)
        team = self.create_team(organization=organization)
        AuthProvider.objects.create(
            organization=organization,
            provider='dummy',
            flags=AuthProvider.flags.allow_unlinked,
        )

        result = access.from_user(user, organization)
        assert result.sso_is_valid

    def test_anonymous_user(self):
        from django.contrib.auth.models import AnonymousUser
        user = self.create_user()
        anon_user = AnonymousUser()
        organization = self.create_organization(owner=user)
        result = access.from_user(anon_user, organization)

        assert not result.is_active


class DefaultAccessTest(TestCase):
    def test_no_access(self):
        result = access.DEFAULT
        assert not result.is_active
        assert result.sso_is_valid
        assert not result.scopes
        assert not result.has_team(Mock())
","
1from __future__ import absolute_import
2
3from mock import Mock
4
5from sentry.auth import access
6from sentry.models import AuthProvider
7from sentry.testutils import TestCase
8
9
10class FromUserTest(TestCase):
11    def test_no_access(self):
12        organization = self.create_organization()
13        team = self.create_team(organization=organization)
14        user = self.create_user()
15
16        result = access.from_user(user, organization)
17
18    def test_global_org_member_access(self):
19        user = self.create_user()
20        organization = self.create_organization(owner=user)
21        member = organization.member_set.get(user=user)
22        team = self.create_team(organization=organization)
23
24        result = access.from_user(user, organization)
25
26    def test_team_restricted_org_member_access(self):
27        user = self.create_user()
28        organization = self.create_organization()
29        team = self.create_team(organization=organization)
30        member = self.create_member(
31            organization=organization,
32            user=user,
33            has_global_access=False,
34            teams=[team],
35        )
36
37        result = access.from_user(user, organization)
38
39    def test_unlinked_sso(self):
40        user = self.create_user()
41        organization = self.create_organization(owner=user)
42        member = organization.member_set.get(user=user)
43        team = self.create_team(organization=organization)
44        AuthProvider.objects.create(
45            organization=organization,
46            provider='dummy',
47        )
48
49        result = access.from_user(user, organization)
50
51    def test_sso_without_link_requirement(self):
52        user = self.create_user()
53        organization = self.create_organization(owner=user)
54        member = organization.member_set.get(user=user)
55        team = self.create_team(organization=organization)
56        AuthProvider.objects.create(
57            organization=organization,
58            provider='dummy',
59            flags=AuthProvider.flags.allow_unlinked,
60        )
61
62        result = access.from_user(user, organization)
63
64    def test_anonymous_user(self):
65        from django.contrib.auth.models import AnonymousUser
66        user = self.create_user()
67        anon_user = AnonymousUser()
68        organization = self.create_organization(owner=user)
69        result = access.from_user(anon_user, organization)
70
71
72
73class DefaultAccessTest(TestCase):
74    def test_no_access(self):
75        result = access.DEFAULT
76","[['result.is_active', '==', 'False'], ['result.sso_is_valid', '==', 'True'], ['result.scopes', '==', 'False'], ['result.has_team(team)', '==', 'False'], ['result.is_active', '==', 'True'], ['result.sso_is_valid', '==', 'True'], ['result.scopes', '==', 'member.get_scopes()'], ['result.has_team(team)', '==', 'True'], ['result.is_active', '==', 'True'], ['result.sso_is_valid', '==', 'True'], ['result.scopes', '==', 'member.get_scopes()'], ['result.has_team(team)', '==', 'True'], ['result.sso_is_valid', '==', 'False'], ['result.sso_is_valid', '==', 'True'], ['result.is_active', '==', 'False'], ['result.is_active', '==', 'False'], ['result.sso_is_valid', '==', 'True'], ['result.scopes', '==', 'False'], ['result.has_team(Mock())', '==', 'False']]",19,19,1.0,0.0060069554220676,"['organization', 'team', 'user', 'result', 'member', 'anon_user']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['organization', 'team', 'user', 'result', 'member', 'anon_user']
*Code:

1from __future__ import absolute_import
2
3from mock import Mock
4
5from sentry.auth import access
6from sentry.models import AuthProvider
7from sentry.testutils import TestCase
8
9
10class FromUserTest(TestCase):
11    def test_no_access(self):
12        organization = self.create_organization()
13        team = self.create_team(organization=organization)
14        user = self.create_user()
15
16        result = access.from_user(user, organization)
17
18    def test_global_org_member_access(self):
19        user = self.create_user()
20        organization = self.create_organization(owner=user)
21        member = organization.member_set.get(user=user)
22        team = self.create_team(organization=organization)
23
24        result = access.from_user(user, organization)
25
26    def test_team_restricted_org_member_access(self):
27        user = self.create_user()
28        organization = self.create_organization()
29        team = self.create_team(organization=organization)
30        member = self.create_member(
31            organization=organization,
32            user=user,
33            has_global_access=False,
34            teams=[team],
35        )
36
37        result = access.from_user(user, organization)
38
39    def test_unlinked_sso(self):
40        user = self.create_user()
41        organization = self.create_organization(owner=user)
42        member = organization.member_set.get(user=user)
43        team = self.create_team(organization=organization)
44        AuthProvider.objects.create(
45            organization=organization,
46            provider='dummy',
47        )
48
49        result = access.from_user(user, organization)
50
51    def test_sso_without_link_requirement(self):
52        user = self.create_user()
53        organization = self.create_organization(owner=user)
54        member = organization.member_set.get(user=user)
55        team = self.create_team(organization=organization)
56        AuthProvider.objects.create(
57            organization=organization,
58            provider='dummy',
59            flags=AuthProvider.flags.allow_unlinked,
60        )
61
62        result = access.from_user(user, organization)
63
64    def test_anonymous_user(self):
65        from django.contrib.auth.models import AnonymousUser
66        user = self.create_user()
67        anon_user = AnonymousUser()
68        organization = self.create_organization(owner=user)
69        result = access.from_user(anon_user, organization)
70
71
72
73class DefaultAccessTest(TestCase):
74    def test_no_access(self):
75        result = access.DEFAULT
76",4038,"[[12, 'organization', '!=', None, ""organization shouldn't be None""],
[14, 'user', '!=', None, ""user shouldn't be None""],
[16, 'result', '!=', None, ""access result shouldn't be None""],
[20, 'organization', '!=', None, ""organization shouldn't be None""],
[22, 'team', '!=', None, ""team shouldn't be None""],
[24, 'result', '!=', None, ""access result shouldn't be None""],
[28, 'organization', '!=', None, ""organization shouldn't be None""],
[30, 'member', '!=', None, ""member shouldn't be None""],
[37, 'result', '!=', None, ""access result shouldn't be None""],
[41, 'organization', '!=', None, ""organization shouldn't be None""],
[43, 'team', '!=', None, ""team shouldn't be None""],
[49, 'result', '!=', None, ""access result shouldn't be None""],
[53, 'organization', '!=', None, ""organization shouldn't be None""],
[55, 'team', '!=', None, ""team shouldn't be None""],
[62, 'result', '!=', None, ""access result shouldn't be None""],
[68, 'organization', '!=', None, ""organization shouldn't be None""],
[69, 'result', '!=', None, ""access result shouldn't be None""],
[75, 'result', '!=', None, ""access result shouldn't be None""]]"
r0k3/arctic,"from mock import patch
import pytest

from arctic.scripts import arctic_init_library as mil

from ...util import run_as_main

from arctic.scripts.arctic_init_library import Arctic as ar


def test_init_library():
    # Create the user agains the current mongo database
    with patch('pymongo.MongoClient') as MongoClient, \
         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')

    get_mongodb_uri.assert_called_once_with('hostname')
    MongoClient.assert_called_once_with(get_mongodb_uri.return_value)
    do_db_auth.assert_called_once_with('hostname', MongoClient.return_value, 'arctic_user')
    Arctic.assert_called_once_with(MongoClient.return_value)
    Arctic.return_value.initialize_library.assert_called_once_with('arctic_user.library', 'VersionStore', hashed=False)
    assert logger.warn.call_count == 0


def test_init_library_no_admin():
    # Create the user agains the current mongo database
    with patch('pymongo.MongoClient') as MongoClient, \
         patch('arctic.scripts.arctic_init_library.logger', autospec=True), \
         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')

    get_mongodb_uri.assert_called_once_with('hostname')
    MongoClient.assert_called_once_with(get_mongodb_uri.return_value)
    Arctic.assert_called_once_with(MongoClient.return_value)
    Arctic.return_value.initialize_library.assert_called_once_with('arctic_user.library', 'VersionStore', hashed=False)


def test_init_library_hashed():
    # Create the user agains the current mongo database
    with patch('pymongo.MongoClient') as MongoClient, \
         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore', '--hashed')

    get_mongodb_uri.assert_called_once_with('hostname')
    MongoClient.assert_called_once_with(get_mongodb_uri.return_value)
    do_db_auth.assert_called_once_with('hostname', MongoClient.return_value, 'arctic_user')
    Arctic.assert_called_once_with(MongoClient.return_value)
    Arctic.return_value.initialize_library.assert_called_once_with('arctic_user.library', 'VersionStore', hashed=True)
    assert logger.warn.call_count == 0


def test_init_library_no_admin_no_user_creds():
    with patch('pymongo.MongoClient') as MongoClient, \
         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
         patch('arctic.scripts.arctic_init_library.do_db_auth', return_value=False, autospec=True) as do_db_auth:

        MongoClient.return_value['arctic_user'].authenticate.return_value = False
        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')

    get_mongodb_uri.assert_called_once_with('hostname')
    MongoClient.assert_called_once_with(get_mongodb_uri.return_value)
    assert Arctic.call_count == 0


def test_bad_library_name():
    with pytest.raises(Exception):
        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
            run_as_main(mil.main, '--library', 'arctic_jblackburn')
    error.assert_called_once_with('Must specify the full path of the library e.g. user.library!')

    with pytest.raises(Exception):
        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
            run_as_main(mil.main)
    error.assert_called_once_with('Must specify the full path of the library e.g. user.library!')
","
1from mock import patch
2import pytest
3
4from arctic.scripts import arctic_init_library as mil
5
6from ...util import run_as_main
7
8from arctic.scripts.arctic_init_library import Arctic as ar
9
10
11def test_init_library():
12    # Create the user agains the current mongo database
13    with patch('pymongo.MongoClient') as MongoClient, \
14         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
15         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
16         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
17         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
18        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
19
20
21
22def test_init_library_no_admin():
23    # Create the user agains the current mongo database
24    with patch('pymongo.MongoClient') as MongoClient, \
25         patch('arctic.scripts.arctic_init_library.logger', autospec=True), \
26         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
27         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
28         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
29        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
30
31
32
33def test_init_library_hashed():
34    # Create the user agains the current mongo database
35    with patch('pymongo.MongoClient') as MongoClient, \
36         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
37         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
38         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
39         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
40        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore', '--hashed')
41
42
43
44def test_init_library_no_admin_no_user_creds():
45    with patch('pymongo.MongoClient') as MongoClient, \
46         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
47         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
48         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
49         patch('arctic.scripts.arctic_init_library.do_db_auth', return_value=False, autospec=True) as do_db_auth:
50
51        MongoClient.return_value['arctic_user'].authenticate.return_value = False
52        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
53
54
55
56def test_bad_library_name():
57    with pytest.raises(Exception):
58        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
59            run_as_main(mil.main, '--library', 'arctic_jblackburn')
60
61    with pytest.raises(Exception):
62        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
63            run_as_main(mil.main)
64","[['logger.warn.call_count', '==', '0'], ['logger.warn.call_count', '==', '0'], ['Arctic.call_count', '==', '0']]",21,3,0.1428571428571428,0.0006407518154634,"[""MongoClient.return_value['arctic_user'].authenticate.return_value""]",1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
[""MongoClient.return_value['arctic_user'].authenticate.return_value""]
*Code:

1from mock import patch
2import pytest
3
4from arctic.scripts import arctic_init_library as mil
5
6from ...util import run_as_main
7
8from arctic.scripts.arctic_init_library import Arctic as ar
9
10
11def test_init_library():
12    # Create the user agains the current mongo database
13    with patch('pymongo.MongoClient') as MongoClient, \
14         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
15         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
16         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
17         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
18        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
19
20
21
22def test_init_library_no_admin():
23    # Create the user agains the current mongo database
24    with patch('pymongo.MongoClient') as MongoClient, \
25         patch('arctic.scripts.arctic_init_library.logger', autospec=True), \
26         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
27         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
28         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
29        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
30
31
32
33def test_init_library_hashed():
34    # Create the user agains the current mongo database
35    with patch('pymongo.MongoClient') as MongoClient, \
36         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
37         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
38         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
39         patch('arctic.scripts.arctic_init_library.do_db_auth', autospec=True) as do_db_auth:
40        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore', '--hashed')
41
42
43
44def test_init_library_no_admin_no_user_creds():
45    with patch('pymongo.MongoClient') as MongoClient, \
46         patch('arctic.scripts.arctic_init_library.logger', autospec=True) as logger, \
47         patch('arctic.scripts.arctic_init_library.Arctic', spec=ar) as Arctic, \
48         patch('arctic.scripts.arctic_init_library.get_mongodb_uri', autospec=True) as get_mongodb_uri, \
49         patch('arctic.scripts.arctic_init_library.do_db_auth', return_value=False, autospec=True) as do_db_auth:
50
51        MongoClient.return_value['arctic_user'].authenticate.return_value = False
52        run_as_main(mil.main, '--host', 'hostname', '--library', 'arctic_user.library', '--type', 'VersionStore')
53
54
55
56def test_bad_library_name():
57    with pytest.raises(Exception):
58        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
59            run_as_main(mil.main, '--library', 'arctic_jblackburn')
60
61    with pytest.raises(Exception):
62        with patch('argparse.ArgumentParser.error', side_effect=Exception) as error:
63            run_as_main(mil.main)
64",4713,"[51, ""MongoClient.return_value['arctic_user'].authenticate.return_value"", '==', False, ""Authentication must return false to show failed authentication attempt""]"
seishei/multiprocess,"#
# This module shows how to use arbitrary callables with a subclass of
# `BaseManager`.
#

from multiprocess import freeze_support as freezeSupport
from multiprocess.managers import BaseManager, BaseProxy
xrange = range

##

class Foo(object):
    def f(self):
        print('you called Foo.f()')
    def g(self):
        print('you called Foo.g()')
    def _h(self):
        print('you called Foo._h()')

# A simple generator function
def baz():
    for i in xrange(10):
        yield i*i

# Proxy type for generator objects
class GeneratorProxy(BaseProxy):
    def __iter__(self):
        return self
    def next(self):
        return self._callmethod('next')

##

class MyManager(BaseManager): pass

# register the Foo class; make all public methods accessible via proxy
MyManager.register('Foo1', Foo)

# register the Foo class; make only `g()` and `_h()` accessible via proxy
MyManager.register('Foo2', Foo, exposed=('g', '_h'))

# register the generator function baz; use `GeneratorProxy` to make proxies
MyManager.register('baz', baz, proxytype=GeneratorProxy)

##

def test():
    manager = MyManager()
    manager.start()

    print('-' * 20)

    f1 = manager.Foo1()
    f1.f()
    f1.g()
    assert not hasattr(f1, '_h')

    print('-' * 20)

    f2 = manager.Foo2()
    f2.g()
    f2._h()
    assert not hasattr(f2, 'f')

    print('-' * 20)

    it = manager.baz()

    for i in it:
        print('<%d>' % i, end=' ')

    print()

##

if __name__ == '__main__':
    freezeSupport()
    test()
","
1#
2# This module shows how to use arbitrary callables with a subclass of
3# `BaseManager`.
4#
5
6from multiprocess import freeze_support as freezeSupport
7from multiprocess.managers import BaseManager, BaseProxy
8xrange = range
9
10##
11
12class Foo(object):
13    def f(self):
14        print('you called Foo.f()')
15    def g(self):
16        print('you called Foo.g()')
17    def _h(self):
18        print('you called Foo._h()')
19
20# A simple generator function
21def baz():
22    for i in xrange(10):
23        yield i*i
24
25# Proxy type for generator objects
26class GeneratorProxy(BaseProxy):
27    def __iter__(self):
28        return self
29    def next(self):
30        return self._callmethod('next')
31
32##
33
34class MyManager(BaseManager): pass
35
36# register the Foo class; make all public methods accessible via proxy
37MyManager.register('Foo1', Foo)
38
39# register the Foo class; make only `g()` and `_h()` accessible via proxy
40MyManager.register('Foo2', Foo, exposed=('g', '_h'))
41
42# register the generator function baz; use `GeneratorProxy` to make proxies
43MyManager.register('baz', baz, proxytype=GeneratorProxy)
44
45##
46
47def test():
48    manager = MyManager()
49    manager.start()
50
51    print('-' * 20)
52
53    f1 = manager.Foo1()
54    f1.f()
55    f1.g()
56
57    print('-' * 20)
58
59    f2 = manager.Foo2()
60    f2.g()
61    f2._h()
62
63    print('-' * 20)
64
65    it = manager.baz()
66
67    for i in it:
68        print('<%d>' % i, end=' ')
69
70    print()
71
72##
73
74if __name__ == '__main__':
75    freezeSupport()
76    test()
77","[['hasattr(f1', '==', 'False'], ['hasattr(f2', '==', 'False']]",2,2,1.0,0.0012602394454946,"['xrange', 'manager', 'f1', 'f2', 'it']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['xrange', 'manager', 'f1', 'f2', 'it']
*Code:

1#
2# This module shows how to use arbitrary callables with a subclass of
3# `BaseManager`.
4#
5
6from multiprocess import freeze_support as freezeSupport
7from multiprocess.managers import BaseManager, BaseProxy
8xrange = range
9
10##
11
12class Foo(object):
13    def f(self):
14        print('you called Foo.f()')
15    def g(self):
16        print('you called Foo.g()')
17    def _h(self):
18        print('you called Foo._h()')
19
20# A simple generator function
21def baz():
22    for i in xrange(10):
23        yield i*i
24
25# Proxy type for generator objects
26class GeneratorProxy(BaseProxy):
27    def __iter__(self):
28        return self
29    def next(self):
30        return self._callmethod('next')
31
32##
33
34class MyManager(BaseManager): pass
35
36# register the Foo class; make all public methods accessible via proxy
37MyManager.register('Foo1', Foo)
38
39# register the Foo class; make only `g()` and `_h()` accessible via proxy
40MyManager.register('Foo2', Foo, exposed=('g', '_h'))
41
42# register the generator function baz; use `GeneratorProxy` to make proxies
43MyManager.register('baz', baz, proxytype=GeneratorProxy)
44
45##
46
47def test():
48    manager = MyManager()
49    manager.start()
50
51    print('-' * 20)
52
53    f1 = manager.Foo1()
54    f1.f()
55    f1.g()
56
57    print('-' * 20)
58
59    f2 = manager.Foo2()
60    f2.g()
61    f2._h()
62
63    print('-' * 20)
64
65    it = manager.baz()
66
67    for i in it:
68        print('<%d>' % i, end=' ')
69
70    print()
71
72##
73
74if __name__ == '__main__':
75    freezeSupport()
76    test()
77",3085,"[7, 'xrange', '==', 'range', ""xrange should be an alias for built-in range function""],
[48, 'manager', '!=', None, ""'manager' should not be None after MyManager initialization""],
[53, 'f1', '!=', None, ""'f1' should not be None after calling Foo1()""],
[59, 'f2', '!=', None, ""'f2' should not be None after calling Foo2()""],
[65, 'it', '!=', None, ""'it' should not be None after calling baz()""],
[67, 'it', '==', 'manager.baz()', ""'it' should be equal to the result of the baz() function""]"
luotao1/Paddle,"#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np

import paddle
from paddle.io import Dataset
from paddle.dataset.common import _check_exists_and_download

__all__ = []

URL = 'http://paddlemodels.bj.bcebos.com/uci_housing/housing.data'
MD5 = 'd4accdce7a25600298819f8e28e8d593'
feature_names = [
    'CRIM',
    'ZN',
    'INDUS',
    'CHAS',
    'NOX',
    'RM',
    'AGE',
    'DIS',
    'RAD',
    'TAX',
    'PTRATIO',
    'B',
    'LSTAT',
]


class UCIHousing(Dataset):
    """"""
    Implementation of `UCI housing <https://archive.ics.uci.edu/ml/datasets/Housing>`_
    dataset

    Args:
        data_file(str): path to data file, can be set None if
            :attr:`download` is True. Default None
        mode(str): 'train' or 'test' mode. Default 'train'.
        download(bool): whether to download dataset automatically if
            :attr:`data_file` is not set. Default True

    Returns:
        Dataset: instance of UCI housing dataset.

    Examples:

        .. code-block:: python

            import paddle
            from paddle.text.datasets import UCIHousing

            class SimpleNet(paddle.nn.Layer):
                def __init__(self):
                    super().__init__()

                def forward(self, feature, target):
                    return paddle.sum(feature), target

            paddle.disable_static()

            uci_housing = UCIHousing(mode='train')

            for i in range(10):
                feature, target = uci_housing[i]
                feature = paddle.to_tensor(feature)
                target = paddle.to_tensor(target)

                model = SimpleNet()
                feature, target = model(feature, target)
                print(feature.numpy().shape, target.numpy())

    """"""

    def __init__(self, data_file=None, mode='train', download=True):
        assert mode.lower() in [
            'train',
            'test',
        ], ""mode should be 'train' or 'test', but got {}"".format(mode)
        self.mode = mode.lower()

        self.data_file = data_file
        if self.data_file is None:
            assert (
                download
            ), ""data_file is not set and downloading automatically is disabled""
            self.data_file = _check_exists_and_download(
                data_file, URL, MD5, 'uci_housing', download
            )

        # read dataset into memory
        self._load_data()

        self.dtype = paddle.get_default_dtype()

    def _load_data(self, feature_num=14, ratio=0.8):
        data = np.fromfile(self.data_file, sep=' ')
        data = data.reshape(data.shape[0] // feature_num, feature_num)
        maximums, minimums, avgs = (
            data.max(axis=0),
            data.min(axis=0),
            data.sum(axis=0) / data.shape[0],
        )
        for i in range(feature_num - 1):
            data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])
        offset = int(data.shape[0] * ratio)
        if self.mode == 'train':
            self.data = data[:offset]
        elif self.mode == 'test':
            self.data = data[offset:]

    def __getitem__(self, idx):
        data = self.data[idx]
        return np.array(data[:-1]).astype(self.dtype), np.array(
            data[-1:]
        ).astype(self.dtype)

    def __len__(self):
        return len(self.data)
","
1#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import numpy as np
16
17import paddle
18from paddle.io import Dataset
19from paddle.dataset.common import _check_exists_and_download
20
21__all__ = []
22
23URL = 'http://paddlemodels.bj.bcebos.com/uci_housing/housing.data'
24MD5 = 'd4accdce7a25600298819f8e28e8d593'
25feature_names = [
26    'CRIM',
27    'ZN',
28    'INDUS',
29    'CHAS',
30    'NOX',
31    'RM',
32    'AGE',
33    'DIS',
34    'RAD',
35    'TAX',
36    'PTRATIO',
37    'B',
38    'LSTAT',
39]
40
41
42class UCIHousing(Dataset):
43    """"""
44    Implementation of `UCI housing <https://archive.ics.uci.edu/ml/datasets/Housing>`_
45    dataset
46
47    Args:
48        data_file(str): path to data file, can be set None if
49            :attr:`download` is True. Default None
50        mode(str): 'train' or 'test' mode. Default 'train'.
51        download(bool): whether to download dataset automatically if
52            :attr:`data_file` is not set. Default True
53
54    Returns:
55        Dataset: instance of UCI housing dataset.
56
57    Examples:
58
59        .. code-block:: python
60
61            import paddle
62            from paddle.text.datasets import UCIHousing
63
64            class SimpleNet(paddle.nn.Layer):
65                def __init__(self):
66                    super().__init__()
67
68                def forward(self, feature, target):
69                    return paddle.sum(feature), target
70
71            paddle.disable_static()
72
73            uci_housing = UCIHousing(mode='train')
74
75            for i in range(10):
76                feature, target = uci_housing[i]
77                feature = paddle.to_tensor(feature)
78                target = paddle.to_tensor(target)
79
80                model = SimpleNet()
81                feature, target = model(feature, target)
82                print(feature.numpy().shape, target.numpy())
83
84    """"""
85
86    def __init__(self, data_file=None, mode='train', download=True):
87            'train',
88            'test',
89        ], ""mode should be 'train' or 'test', but got {}"".format(mode)
90        self.mode = mode.lower()
91
92        self.data_file = data_file
93        if self.data_file is None:
94                download
95            ), ""data_file is not set and downloading automatically is disabled""
96            self.data_file = _check_exists_and_download(
97                data_file, URL, MD5, 'uci_housing', download
98            )
99
100        # read dataset into memory
101        self._load_data()
102
103        self.dtype = paddle.get_default_dtype()
104
105    def _load_data(self, feature_num=14, ratio=0.8):
106        data = np.fromfile(self.data_file, sep=' ')
107        data = data.reshape(data.shape[0] // feature_num, feature_num)
108        maximums, minimums, avgs = (
109            data.max(axis=0),
110            data.min(axis=0),
111            data.sum(axis=0) / data.shape[0],
112        )
113        for i in range(feature_num - 1):
114            data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])
115        offset = int(data.shape[0] * ratio)
116        if self.mode == 'train':
117            self.data = data[:offset]
118        elif self.mode == 'test':
119            self.data = data[offset:]
120
121    def __getitem__(self, idx):
122        data = self.data[idx]
123        return np.array(data[:-1]).astype(self.dtype), np.array(
124            data[-1:]
125        ).astype(self.dtype)
126
127    def __len__(self):
128        return len(self.data)
129","[['(', '==', 'True']]",2,1,0.5,0.000256937307297,"['__all__', 'URL', 'MD5', 'feature_names', 'feature', 'target', 'uci_housing', 'model', 'data_file', 'mode', 'download', 'self.mode', 'self.data_file', 'self.dtype', 'feature_num', 'ratio', 'data', 'maximums', 'minimums', 'avgs', 'data[:', 'i]', 'offset', 'self.data', 'idx']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'URL', 'MD5', 'feature_names', 'feature', 'target', 'uci_housing', 'model', 'data_file', 'mode', 'download', 'self.mode', 'self.data_file', 'self.dtype', 'feature_num', 'ratio', 'data', 'maximums', 'minimums', 'avgs', 'data[:', 'i]', 'offset', 'self.data', 'idx']
*Code:

1#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import numpy as np
16
17import paddle
18from paddle.io import Dataset
19from paddle.dataset.common import _check_exists_and_download
20
21__all__ = []
22
23URL = 'http://paddlemodels.bj.bcebos.com/uci_housing/housing.data'
24MD5 = 'd4accdce7a25600298819f8e28e8d593'
25feature_names = [
26    'CRIM',
27    'ZN',
28    'INDUS',
29    'CHAS',
30    'NOX',
31    'RM',
32    'AGE',
33    'DIS',
34    'RAD',
35    'TAX',
36    'PTRATIO',
37    'B',
38    'LSTAT',
39]
40
41
42class UCIHousing(Dataset):
43    """"""
44    Implementation of `UCI housing <https://archive.ics.uci.edu/ml/datasets/Housing>`_
45    dataset
46
47    Args:
48        data_file(str): path to data file, can be set None if
49            :attr:`download` is True. Default None
50        mode(str): 'train' or 'test' mode. Default 'train'.
51        download(bool): whether to download dataset automatically if
52            :attr:`data_file` is not set. Default True
53
54    Returns:
55        Dataset: instance of UCI housing dataset.
56
57    Examples:
58
59        .. code-block:: python
60
61            import paddle
62            from paddle.text.datasets import UCIHousing
63
64            class SimpleNet(paddle.nn.Layer):
65                def __init__(self):
66                    super().__init__()
67
68                def forward(self, feature, target):
69                    return paddle.sum(feature), target
70
71            paddle.disable_static()
72
73            uci_housing = UCIHousing(mode='train')
74
75            for i in range(10):
76                feature, target = uci_housing[i]
77                feature = paddle.to_tensor(feature)
78                target = paddle.to_tensor(target)
79
80                model = SimpleNet()
81                feature, target = model(feature, target)
82                print(feature.numpy().shape, target.numpy())
83
84    """"""
85
86    def __init__(self, data_file=None, mode='train', download=True):
87            'train',
88            'test',
89        ], ""mode should be 'train' or 'test', but got {}"".format(mode)
90        self.mode = mode.lower()
91
92        self.data_file = data_file
93        if self.data_file is None:
94                download
95            ), ""data_file is not set and downloading automatically is disabled""
96            self.data_file = _check_exists_and_download(
97                data_file, URL, MD5, 'uci_housing', download
98            )
99
100        # read dataset into memory
101        self._load_data()
102
103        self.dtype = paddle.get_default_dtype()
104
105    def _load_data(self, feature_num=14, ratio=0.8):
106        data = np.fromfile(self.data_file, sep=' ')
107        data = data.reshape(data.shape[0] // feature_num, feature_num)
108        maximums, minimums, avgs = (
109            data.max(axis=0),
110            data.min(axis=0),
111            data.sum(axis=0) / data.shape[0],
112        )
113        for i in range(feature_num - 1):
114            data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])
115        offset = int(data.shape[0] * ratio)
116        if self.mode == 'train':
117            self.data = data[:offset]
118        elif self.mode == 'test':
119            self.data = data[offset:]
120
121    def __getitem__(self, idx):
122        data = self.data[idx]
123        return np.array(data[:-1]).astype(self.dtype), np.array(
124            data[-1:]
125        ).astype(self.dtype)
126
127    def __len__(self):
128        return len(self.data)
129",5773,"[[86, 'mode', '==', 'train', ""The mode should be 'train' when the process begins""],
[86, 'mode', '!=', 'test', ""The mode should not be 'test' when the process begins""],
[86, 'download', '==', True, ""Download should be True when the process begins""],
[105, 'feature_num', '==', 14, ""There should be 14 features""],
[105, 'ratio', '==', 0.8, ""The ratio should be 0.8 to split the data""],
[117, 'self.data', '>=', 1, ""Size of the data should be greater than or equal to 1 after loading""],
[119, 'self.data', '>=', 1, ""Size of the data should be greater than or equal to 1 after loading""],
[127, 'self.data', '>=', 1, ""Length of the data should be greater than or equal to 1""]]"
buffer/v8py,"import sys
import pytest
from v8py import Context

if sys.version_info.major < 3:
    params = ['new', 'old']
else:
    params = ['new']
@pytest.fixture(params=['new', 'old'])
def Global(request):
    if request.param == 'new':
        class Global(object):
            def method(self):
                return 'method'
            @property
            def property(self):
                return 'property'
        return Global
    else:
        class Global(object):
            def method(self):
                return 'method'
            @property
            def property(self):
                return 'property'
        return Global

@pytest.fixture
def context(Global):
    return Context(Global)

def test_global(context):
    assert context.eval('method()') == 'method'
    assert context.eval('this.method()') == 'method'

    assert context.eval('property') == 'property'
    assert context.eval('this.property') == 'property'
","
1import sys
2import pytest
3from v8py import Context
4
5if sys.version_info.major < 3:
6    params = ['new', 'old']
7else:
8    params = ['new']
9@pytest.fixture(params=['new', 'old'])
10def Global(request):
11    if request.param == 'new':
12        class Global(object):
13            def method(self):
14                return 'method'
15            @property
16            def property(self):
17                return 'property'
18        return Global
19    else:
20        class Global(object):
21            def method(self):
22                return 'method'
23            @property
24            def property(self):
25                return 'property'
26        return Global
27
28@pytest.fixture
29def context(Global):
30    return Context(Global)
31
32def test_global(context):
33
34","[[""context.eval('method()')"", '==', ""'method'""], [""context.eval('this.method()')"", '==', ""'method'""], [""context.eval('property')"", '==', ""'property'""], [""context.eval('this.property')"", '==', ""'property'""]]",4,4,1.0,0.004250797024442,"['params', 'request', 'Global', 'context']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['params', 'request', 'Global', 'context']
*Code:

1import sys
2import pytest
3from v8py import Context
4
5if sys.version_info.major < 3:
6    params = ['new', 'old']
7else:
8    params = ['new']
9@pytest.fixture(params=['new', 'old'])
10def Global(request):
11    if request.param == 'new':
12        class Global(object):
13            def method(self):
14                return 'method'
15            @property
16            def property(self):
17                return 'property'
18        return Global
19    else:
20        class Global(object):
21            def method(self):
22                return 'method'
23            @property
24            def property(self):
25                return 'property'
26        return Global
27
28@pytest.fixture
29def context(Global):
30    return Context(Global)
31
32def test_global(context):
33
34",2217,"[[9, 'params', '!=', [], ""params should not be empty as it is used as an argument for pytest.fixture""],
 [29, 'Global', '!=', None, ""Global must not be None as it is used as an input for the context""],
 [32, 'context', '!=', None, ""Context function requires a valid non-None input""]]"
franek/weboob,"# -*- coding: utf-8 -*-

# Copyright(C) 2012 Romain Bignon
#
# This file is part of weboob.
#
# weboob is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# weboob is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with weboob. If not, see <http://www.gnu.org/licenses/>.


import re
import urllib

from weboob.tools.browser import BaseBrowser, BrowserIncorrectPassword

from .pages import LoginPage, AccountsPage, ProAccountsPage, TransactionsPage, ProTransactionsPage


__all__ = ['CreditDuNordBrowser']


class CreditDuNordBrowser(BaseBrowser):
    PROTOCOL = 'https'
    ENCODING = 'UTF-8'
    PAGES = {'https://[^/]+/?':                                         LoginPage,
             'https://[^/]+/.*\?.*_pageLabel=page_erreur_connexion':    LoginPage,
             'https://[^/]+/vos-comptes/particuliers(\?.*)?':           AccountsPage,
             'https://[^/]+/vos-comptes/.*/transac/particuliers.*':     TransactionsPage,
             'https://[^/]+/vos-comptes/professionnels.*':              ProAccountsPage,
             'https://[^/]+/vos-comptes/.*/transac/professionnels.*':   ProTransactionsPage,
            }
    account_type = 'particuliers'

    def __init__(self, website, *args, **kwargs):
        self.DOMAIN = website
        BaseBrowser.__init__(self, *args, **kwargs)

    def is_logged(self):
        return self.page is not None and not self.is_on_page(LoginPage)

    def home(self):
        if self.is_logged():
            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
        else:
            self.login()

    def login(self):
        assert isinstance(self.username, basestring)
        assert isinstance(self.password, basestring)

        # not necessary (and very slow)
        #self.location('https://www.credit-du-nord.fr/', no_login=True)

        m = re.match('www.([^\.]+).fr', self.DOMAIN)
        if not m:
            bank_name = 'credit-du-nord'
            self.logger.error('Unable to find bank name for %s' % self.DOMAIN)
        else:
            bank_name = m.group(1)

        data = {'bank':         bank_name,
                'pagecible':    'vos-comptes',
                'password':     self.password.encode(self.ENCODING),
                'pwAuth':       'Authentification+mot+de+passe',
                'username':     self.username.encode(self.ENCODING),
               }

        self.location(self.buildurl('/saga/authentification'), urllib.urlencode(data), no_login=True)

        if not self.is_logged():
            raise BrowserIncorrectPassword()

        m = re.match('https://[^/]+/vos-comptes/(\w+).*', self.page.url)
        if m:
            self.account_type = m.group(1)

    def get_accounts_list(self):
        if not self.is_on_page(AccountsPage):
            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
        return self.page.get_list()

    def get_account(self, id):
        assert isinstance(id, basestring)

        l = self.get_accounts_list()
        for a in l:
            if a.id == id:
                return a

        return None

    def iter_transactions(self, link, args, is_coming=None):
        if args is None:
            return

        while args is not None:
            self.location(link, urllib.urlencode(args))

            assert self.is_on_page(TransactionsPage)

            self.page.is_coming = is_coming

            for tr in self.page.get_history():
                yield tr

            is_coming = self.page.is_coming
            args = self.page.get_next_args(args)

    def get_history(self, account):
        account = self.get_account(account.id)
        for tr in self.iter_transactions(account._link, account._args):
            yield tr

        for tr in self.get_card_operations(account):
            yield tr

    def get_card_operations(self, account):
        for link_args in account._card_ids:
            for tr in self.iter_transactions(account._link, link_args, True):
                yield tr
","
1# -*- coding: utf-8 -*-
2
3# Copyright(C) 2012 Romain Bignon
4#
5# This file is part of weboob.
6#
7# weboob is free software: you can redistribute it and/or modify
8# it under the terms of the GNU Affero General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# weboob is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
15# GNU Affero General Public License for more details.
16#
17# You should have received a copy of the GNU Affero General Public License
18# along with weboob. If not, see <http://www.gnu.org/licenses/>.
19
20
21import re
22import urllib
23
24from weboob.tools.browser import BaseBrowser, BrowserIncorrectPassword
25
26from .pages import LoginPage, AccountsPage, ProAccountsPage, TransactionsPage, ProTransactionsPage
27
28
29__all__ = ['CreditDuNordBrowser']
30
31
32class CreditDuNordBrowser(BaseBrowser):
33    PROTOCOL = 'https'
34    ENCODING = 'UTF-8'
35    PAGES = {'https://[^/]+/?':                                         LoginPage,
36             'https://[^/]+/.*\?.*_pageLabel=page_erreur_connexion':    LoginPage,
37             'https://[^/]+/vos-comptes/particuliers(\?.*)?':           AccountsPage,
38             'https://[^/]+/vos-comptes/.*/transac/particuliers.*':     TransactionsPage,
39             'https://[^/]+/vos-comptes/professionnels.*':              ProAccountsPage,
40             'https://[^/]+/vos-comptes/.*/transac/professionnels.*':   ProTransactionsPage,
41            }
42    account_type = 'particuliers'
43
44    def __init__(self, website, *args, **kwargs):
45        self.DOMAIN = website
46        BaseBrowser.__init__(self, *args, **kwargs)
47
48    def is_logged(self):
49        return self.page is not None and not self.is_on_page(LoginPage)
50
51    def home(self):
52        if self.is_logged():
53            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
54        else:
55            self.login()
56
57    def login(self):
58
59        # not necessary (and very slow)
60        #self.location('https://www.credit-du-nord.fr/', no_login=True)
61
62        m = re.match('www.([^\.]+).fr', self.DOMAIN)
63        if not m:
64            bank_name = 'credit-du-nord'
65            self.logger.error('Unable to find bank name for %s' % self.DOMAIN)
66        else:
67            bank_name = m.group(1)
68
69        data = {'bank':         bank_name,
70                'pagecible':    'vos-comptes',
71                'password':     self.password.encode(self.ENCODING),
72                'pwAuth':       'Authentification+mot+de+passe',
73                'username':     self.username.encode(self.ENCODING),
74               }
75
76        self.location(self.buildurl('/saga/authentification'), urllib.urlencode(data), no_login=True)
77
78        if not self.is_logged():
79            raise BrowserIncorrectPassword()
80
81        m = re.match('https://[^/]+/vos-comptes/(\w+).*', self.page.url)
82        if m:
83            self.account_type = m.group(1)
84
85    def get_accounts_list(self):
86        if not self.is_on_page(AccountsPage):
87            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
88        return self.page.get_list()
89
90    def get_account(self, id):
91
92        l = self.get_accounts_list()
93        for a in l:
94            if a.id == id:
95                return a
96
97        return None
98
99    def iter_transactions(self, link, args, is_coming=None):
100        if args is None:
101            return
102
103        while args is not None:
104            self.location(link, urllib.urlencode(args))
105
106
107            self.page.is_coming = is_coming
108
109            for tr in self.page.get_history():
110                yield tr
111
112            is_coming = self.page.is_coming
113            args = self.page.get_next_args(args)
114
115    def get_history(self, account):
116        account = self.get_account(account.id)
117        for tr in self.iter_transactions(account._link, account._args):
118            yield tr
119
120        for tr in self.get_card_operations(account):
121            yield tr
122
123    def get_card_operations(self, account):
124        for link_args in account._card_ids:
125            for tr in self.iter_transactions(account._link, link_args, True):
126                yield tr
127","[['self.is_on_page(TransactionsPage)', '==', 'True']]",4,1,0.25,0.0002254791431792,"['__all__', 'PROTOCOL', 'ENCODING', 'PAGES', 'account_type', 'website', '*args', '**kwargs', 'self.DOMAIN', 'm', 'bank_name', 'data', 'self.account_type', 'id', 'l', 'link', 'args', 'is_coming', 'self.page.is_coming', 'account']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'PROTOCOL', 'ENCODING', 'PAGES', 'account_type', 'website', '*args', '**kwargs', 'self.DOMAIN', 'm', 'bank_name', 'data', 'self.account_type', 'id', 'l', 'link', 'args', 'is_coming', 'self.page.is_coming', 'account']
*Code:

1# -*- coding: utf-8 -*-
2
3# Copyright(C) 2012 Romain Bignon
4#
5# This file is part of weboob.
6#
7# weboob is free software: you can redistribute it and/or modify
8# it under the terms of the GNU Affero General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# weboob is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
15# GNU Affero General Public License for more details.
16#
17# You should have received a copy of the GNU Affero General Public License
18# along with weboob. If not, see <http://www.gnu.org/licenses/>.
19
20
21import re
22import urllib
23
24from weboob.tools.browser import BaseBrowser, BrowserIncorrectPassword
25
26from .pages import LoginPage, AccountsPage, ProAccountsPage, TransactionsPage, ProTransactionsPage
27
28
29__all__ = ['CreditDuNordBrowser']
30
31
32class CreditDuNordBrowser(BaseBrowser):
33    PROTOCOL = 'https'
34    ENCODING = 'UTF-8'
35    PAGES = {'https://[^/]+/?':                                         LoginPage,
36             'https://[^/]+/.*\?.*_pageLabel=page_erreur_connexion':    LoginPage,
37             'https://[^/]+/vos-comptes/particuliers(\?.*)?':           AccountsPage,
38             'https://[^/]+/vos-comptes/.*/transac/particuliers.*':     TransactionsPage,
39             'https://[^/]+/vos-comptes/professionnels.*':              ProAccountsPage,
40             'https://[^/]+/vos-comptes/.*/transac/professionnels.*':   ProTransactionsPage,
41            }
42    account_type = 'particuliers'
43
44    def __init__(self, website, *args, **kwargs):
45        self.DOMAIN = website
46        BaseBrowser.__init__(self, *args, **kwargs)
47
48    def is_logged(self):
49        return self.page is not None and not self.is_on_page(LoginPage)
50
51    def home(self):
52        if self.is_logged():
53            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
54        else:
55            self.login()
56
57    def login(self):
58
59        # not necessary (and very slow)
60        #self.location('https://www.credit-du-nord.fr/', no_login=True)
61
62        m = re.match('www.([^\.]+).fr', self.DOMAIN)
63        if not m:
64            bank_name = 'credit-du-nord'
65            self.logger.error('Unable to find bank name for %s' % self.DOMAIN)
66        else:
67            bank_name = m.group(1)
68
69        data = {'bank':         bank_name,
70                'pagecible':    'vos-comptes',
71                'password':     self.password.encode(self.ENCODING),
72                'pwAuth':       'Authentification+mot+de+passe',
73                'username':     self.username.encode(self.ENCODING),
74               }
75
76        self.location(self.buildurl('/saga/authentification'), urllib.urlencode(data), no_login=True)
77
78        if not self.is_logged():
79            raise BrowserIncorrectPassword()
80
81        m = re.match('https://[^/]+/vos-comptes/(\w+).*', self.page.url)
82        if m:
83            self.account_type = m.group(1)
84
85    def get_accounts_list(self):
86        if not self.is_on_page(AccountsPage):
87            self.location(self.buildurl('/vos-comptes/%s' % self.account_type))
88        return self.page.get_list()
89
90    def get_account(self, id):
91
92        l = self.get_accounts_list()
93        for a in l:
94            if a.id == id:
95                return a
96
97        return None
98
99    def iter_transactions(self, link, args, is_coming=None):
100        if args is None:
101            return
102
103        while args is not None:
104            self.location(link, urllib.urlencode(args))
105
106
107            self.page.is_coming = is_coming
108
109            for tr in self.page.get_history():
110                yield tr
111
112            is_coming = self.page.is_coming
113            args = self.page.get_next_args(args)
114
115    def get_history(self, account):
116        account = self.get_account(account.id)
117        for tr in self.iter_transactions(account._link, account._args):
118            yield tr
119
120        for tr in self.get_card_operations(account):
121            yield tr
122
123    def get_card_operations(self, account):
124        for link_args in account._card_ids:
125            for tr in self.iter_transactions(account._link, link_args, True):
126                yield tr
127",6116,"[[32, 'PROTOCOL', '!=', '', 'PROTOCOL should not be empty'],
 [32, 'ENCODING', '!=', '', 'ENCODING should not be empty'],
 [32, 'PAGES', '!=', '', 'PAGES should not be empty'],
 [44, 'website', '!=', '', 'website should not be empty'],
 [44, '*args', '!=', '', '*args should not be empty'],
 [44, '**kwargs', '!=', '', '**kwargs should not be empty'],
 [62, 'self.DOMAIN', '!=', '', 'self.DOMAIN should not be empty'],
 [69, 'data', '==', {}, 'data must be a dictionary'],
 [85, 'self.account_type', '!=', '', 'self.account_type should not be empty'],
 [90, 'id', '!=', '', 'id should not be empty'],
 [99, 'link', '!=', '', 'link should not be empty'],
 [99, 'args', '!=', '', 'args should not be empty'],
 [99, 'is_coming', '==', None, 'is_coming may be None or not empty'],
 [115, 'account', '!=', '', 'account should not be empty'],
 [123, 'account', '!=', '', 'account should not be empty']]"
evernote/pootle,"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright 2014 Evernote Corporation
#
# This file is part of Pootle.
#
# Pootle is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/>.

import pytest

from django.contrib.auth import get_user_model

from pootle_app.models.permissions import get_matching_permissions
from pootle_store.util import FUZZY, TRANSLATED, UNTRANSLATED
from pootle_store.forms import unit_form_factory, UnitStateField


def _create_post_request(rf, directory, user, url='/', data=None):
    """"""Convenience function to create and setup fake POST requests.""""""
    if data is None:
        data = {}

    User = get_user_model()

    request = rf.post(url, data=data)
    request.user = user
    request.profile = User.get(user)
    request.permissions = get_matching_permissions(request.profile,
                                                   directory)
    return request


def _create_unit_form(request, language, unit):
    """"""Convenience function to create unit forms.""""""
    form_class = unit_form_factory(language, request=request)
    return form_class(request.POST, instance=unit, request=request)


def test_submit_no_source(rf, default, default_ps, af_tutorial_po):
    """"""Tests that the source string cannot be modified.""""""
    language = af_tutorial_po.translation_project.language
    unit = af_tutorial_po.getitem(0)
    source_string = unit.source_f
    directory = unit.store.parent
    post_dict = {
        'id': unit.id,
        'index': unit.index,
        'source_f_0': 'altered source string',
        'target_f_0': 'dummy',
    }

    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)

    assert form.is_valid()
    form.save()

    unit = af_tutorial_po.getitem(0)
    assert unit.source_f == source_string
    assert unit.target_f == 'dummy'


def test_submit_fuzzy(rf, admin, default, default_ps,
                      afrikaans, af_tutorial_po):
    """"""Tests that non-admin users can't set the fuzzy flag.""""""
    language = afrikaans
    unit = af_tutorial_po.getitem(0)
    directory = unit.store.parent
    post_dict = {
        'id': unit.id,
        'index': unit.index,
        'target_f_0': unit.target_f,
        'state': FUZZY,
    }

    request = _create_post_request(rf, directory, data=post_dict, user=admin)
    admin_form = _create_unit_form(request, language, unit)
    assert admin_form.is_valid()

    request = _create_post_request(rf, directory, data=post_dict, user=default)
    user_form = _create_unit_form(request, language, unit)
    assert not user_form.is_valid()
    assert 'state' in user_form.errors


def test_submit_similarity(rf, default, default_ps, afrikaans, af_tutorial_po):
    """"""Tests that similarities are within a particular range.""""""
    language = afrikaans
    unit = af_tutorial_po.getitem(0)
    directory = unit.store.parent
    post_dict = {
        'id': unit.id,
        'index': unit.index,
        'target_f_0': unit.target_f,
    }

    # Similarity should be optional
    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)
    assert form.is_valid()

    # Similarities, if passed, should be in the [0..1] range
    post_dict.update({
        'similarity': 9999,
        'mt_similarity': 'foo bar',
    })
    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)
    assert not form.is_valid()

    post_dict.update({
        'similarity': 1,
    })
    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)
    assert not form.is_valid()

    post_dict.update({
        'mt_similarity': 2,
    })
    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)
    assert not form.is_valid()

    post_dict.update({
        'mt_similarity': 0.69,
    })
    request = _create_post_request(rf, directory, data=post_dict, user=default)
    form = _create_unit_form(request, language, unit)
    assert form.is_valid()


def test_unit_state():
    """"""Tests how checkbox states (as strings) map to booleans.""""""
    field = UnitStateField(required=False)
    assert field.clean(str(FUZZY))
    assert field.clean(str(TRANSLATED))
    assert field.clean(str(UNTRANSLATED))
    assert field.clean(True)
    assert not field.clean('True')  # Unknown state value evaluates to False
    assert not field.clean(False)
    assert not field.clean('False')
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3#
4# Copyright 2014 Evernote Corporation
5#
6# This file is part of Pootle.
7#
8# Pootle is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License
19# along with this program; if not, see <http://www.gnu.org/licenses/>.
20
21import pytest
22
23from django.contrib.auth import get_user_model
24
25from pootle_app.models.permissions import get_matching_permissions
26from pootle_store.util import FUZZY, TRANSLATED, UNTRANSLATED
27from pootle_store.forms import unit_form_factory, UnitStateField
28
29
30def _create_post_request(rf, directory, user, url='/', data=None):
31    """"""Convenience function to create and setup fake POST requests.""""""
32    if data is None:
33        data = {}
34
35    User = get_user_model()
36
37    request = rf.post(url, data=data)
38    request.user = user
39    request.profile = User.get(user)
40    request.permissions = get_matching_permissions(request.profile,
41                                                   directory)
42    return request
43
44
45def _create_unit_form(request, language, unit):
46    """"""Convenience function to create unit forms.""""""
47    form_class = unit_form_factory(language, request=request)
48    return form_class(request.POST, instance=unit, request=request)
49
50
51def test_submit_no_source(rf, default, default_ps, af_tutorial_po):
52    """"""Tests that the source string cannot be modified.""""""
53    language = af_tutorial_po.translation_project.language
54    unit = af_tutorial_po.getitem(0)
55    source_string = unit.source_f
56    directory = unit.store.parent
57    post_dict = {
58        'id': unit.id,
59        'index': unit.index,
60        'source_f_0': 'altered source string',
61        'target_f_0': 'dummy',
62    }
63
64    request = _create_post_request(rf, directory, data=post_dict, user=default)
65    form = _create_unit_form(request, language, unit)
66
67    form.save()
68
69    unit = af_tutorial_po.getitem(0)
70
71
72def test_submit_fuzzy(rf, admin, default, default_ps,
73                      afrikaans, af_tutorial_po):
74    """"""Tests that non-admin users can't set the fuzzy flag.""""""
75    language = afrikaans
76    unit = af_tutorial_po.getitem(0)
77    directory = unit.store.parent
78    post_dict = {
79        'id': unit.id,
80        'index': unit.index,
81        'target_f_0': unit.target_f,
82        'state': FUZZY,
83    }
84
85    request = _create_post_request(rf, directory, data=post_dict, user=admin)
86    admin_form = _create_unit_form(request, language, unit)
87
88    request = _create_post_request(rf, directory, data=post_dict, user=default)
89    user_form = _create_unit_form(request, language, unit)
90
91
92def test_submit_similarity(rf, default, default_ps, afrikaans, af_tutorial_po):
93    """"""Tests that similarities are within a particular range.""""""
94    language = afrikaans
95    unit = af_tutorial_po.getitem(0)
96    directory = unit.store.parent
97    post_dict = {
98        'id': unit.id,
99        'index': unit.index,
100        'target_f_0': unit.target_f,
101    }
102
103    # Similarity should be optional
104    request = _create_post_request(rf, directory, data=post_dict, user=default)
105    form = _create_unit_form(request, language, unit)
106
107    # Similarities, if passed, should be in the [0..1] range
108    post_dict.update({
109        'similarity': 9999,
110        'mt_similarity': 'foo bar',
111    })
112    request = _create_post_request(rf, directory, data=post_dict, user=default)
113    form = _create_unit_form(request, language, unit)
114
115    post_dict.update({
116        'similarity': 1,
117    })
118    request = _create_post_request(rf, directory, data=post_dict, user=default)
119    form = _create_unit_form(request, language, unit)
120
121    post_dict.update({
122        'mt_similarity': 2,
123    })
124    request = _create_post_request(rf, directory, data=post_dict, user=default)
125    form = _create_unit_form(request, language, unit)
126
127    post_dict.update({
128        'mt_similarity': 0.69,
129    })
130    request = _create_post_request(rf, directory, data=post_dict, user=default)
131    form = _create_unit_form(request, language, unit)
132
133
134def test_unit_state():
135    """"""Tests how checkbox states (as strings) map to booleans.""""""
136    field = UnitStateField(required=False)
137","[['form.is_valid()', '==', 'True'], ['unit.source_f', '==', 'source_string'], ['unit.target_f', '==', ""'dummy'""], ['admin_form.is_valid()', '==', 'True'], ['user_form.is_valid()', '==', 'False'], ['form.is_valid()', '==', 'True'], ['form.is_valid()', '==', 'False'], ['form.is_valid()', '==', 'False'], ['form.is_valid()', '==', 'False'], ['form.is_valid()', '==', 'True'], ['field.clean(str(FUZZY))', '==', 'True'], ['field.clean(str(TRANSLATED))', '==', 'True'], ['field.clean(str(UNTRANSLATED))', '==', 'True'], ['field.clean(True)', '==', 'True'], [""field.clean('True')"", '==', 'False'], ['field.clean(False)', '==', 'False'], [""field.clean('False')"", '==', 'False']]",18,17,0.9444444444444444,0.0032711179526649,"['rf', 'directory', 'user', 'url', 'data', 'User', 'request', 'request.user', 'request.profile', 'request.permissions', 'language', 'unit', 'form_class', 'default', 'default_ps', 'af_tutorial_po', 'source_string', 'post_dict', 'form', 'admin', 'admin_form', 'user_form', 'afrikaans', 'field']",24,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['rf', 'directory', 'user', 'url', 'data', 'User', 'request', 'request.user', 'request.profile', 'request.permissions', 'language', 'unit', 'form_class', 'default', 'default_ps', 'af_tutorial_po', 'source_string', 'post_dict', 'form', 'admin', 'admin_form', 'user_form', 'afrikaans', 'field']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3#
4# Copyright 2014 Evernote Corporation
5#
6# This file is part of Pootle.
7#
8# Pootle is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License
19# along with this program; if not, see <http://www.gnu.org/licenses/>.
20
21import pytest
22
23from django.contrib.auth import get_user_model
24
25from pootle_app.models.permissions import get_matching_permissions
26from pootle_store.util import FUZZY, TRANSLATED, UNTRANSLATED
27from pootle_store.forms import unit_form_factory, UnitStateField
28
29
30def _create_post_request(rf, directory, user, url='/', data=None):
31    """"""Convenience function to create and setup fake POST requests.""""""
32    if data is None:
33        data = {}
34
35    User = get_user_model()
36
37    request = rf.post(url, data=data)
38    request.user = user
39    request.profile = User.get(user)
40    request.permissions = get_matching_permissions(request.profile,
41                                                   directory)
42    return request
43
44
45def _create_unit_form(request, language, unit):
46    """"""Convenience function to create unit forms.""""""
47    form_class = unit_form_factory(language, request=request)
48    return form_class(request.POST, instance=unit, request=request)
49
50
51def test_submit_no_source(rf, default, default_ps, af_tutorial_po):
52    """"""Tests that the source string cannot be modified.""""""
53    language = af_tutorial_po.translation_project.language
54    unit = af_tutorial_po.getitem(0)
55    source_string = unit.source_f
56    directory = unit.store.parent
57    post_dict = {
58        'id': unit.id,
59        'index': unit.index,
60        'source_f_0': 'altered source string',
61        'target_f_0': 'dummy',
62    }
63
64    request = _create_post_request(rf, directory, data=post_dict, user=default)
65    form = _create_unit_form(request, language, unit)
66
67    form.save()
68
69    unit = af_tutorial_po.getitem(0)
70
71
72def test_submit_fuzzy(rf, admin, default, default_ps,
73                      afrikaans, af_tutorial_po):
74    """"""Tests that non-admin users can't set the fuzzy flag.""""""
75    language = afrikaans
76    unit = af_tutorial_po.getitem(0)
77    directory = unit.store.parent
78    post_dict = {
79        'id': unit.id,
80        'index': unit.index,
81        'target_f_0': unit.target_f,
82        'state': FUZZY,
83    }
84
85    request = _create_post_request(rf, directory, data=post_dict, user=admin)
86    admin_form = _create_unit_form(request, language, unit)
87
88    request = _create_post_request(rf, directory, data=post_dict, user=default)
89    user_form = _create_unit_form(request, language, unit)
90
91
92def test_submit_similarity(rf, default, default_ps, afrikaans, af_tutorial_po):
93    """"""Tests that similarities are within a particular range.""""""
94    language = afrikaans
95    unit = af_tutorial_po.getitem(0)
96    directory = unit.store.parent
97    post_dict = {
98        'id': unit.id,
99        'index': unit.index,
100        'target_f_0': unit.target_f,
101    }
102
103    # Similarity should be optional
104    request = _create_post_request(rf, directory, data=post_dict, user=default)
105    form = _create_unit_form(request, language, unit)
106
107    # Similarities, if passed, should be in the [0..1] range
108    post_dict.update({
109        'similarity': 9999,
110        'mt_similarity': 'foo bar',
111    })
112    request = _create_post_request(rf, directory, data=post_dict, user=default)
113    form = _create_unit_form(request, language, unit)
114
115    post_dict.update({
116        'similarity': 1,
117    })
118    request = _create_post_request(rf, directory, data=post_dict, user=default)
119    form = _create_unit_form(request, language, unit)
120
121    post_dict.update({
122        'mt_similarity': 2,
123    })
124    request = _create_post_request(rf, directory, data=post_dict, user=default)
125    form = _create_unit_form(request, language, unit)
126
127    post_dict.update({
128        'mt_similarity': 0.69,
129    })
130    request = _create_post_request(rf, directory, data=post_dict, user=default)
131    form = _create_unit_form(request, language, unit)
132
133
134def test_unit_state():
135    """"""Tests how checkbox states (as strings) map to booleans.""""""
136    field = UnitStateField(required=False)
137",6520,"[[30, 'rf', '!=', None, 'rf parameter is required as it is used for post requests'],
 [30, 'directory', '!=', None, 'directory parameter is required for setting up request permissions'],
 [30, 'user', '!=', None, 'user parameter is required for setting up request.user and request.profile'],
 [30, 'url', '!=', None, 'url parameter is expected to be a string'],
 [30, 'data', '!=', None, 'data parameter is expected to be a dictionary'],
 [45, 'request', '!=', None, 'request parameter is required to create the form_class'],
 [45, 'language', '!=', None, 'language parameter is required to create the form_class'],
 [45, 'unit', '!=', None, 'unit parameter is required for creating the form_class instance'],
 [51, 'rf', '!=', None, 'rf parameter is required for creating a post request'],
 [51, 'default', '!=', None, 'default parameter is required for setting up the user'],
 [51, 'default_ps', '!=', None, 'default_ps parameter is required but not used in the function'],
 [51, 'af_tutorial_po', '!=', None, 'af_tutorial_po parameter is required to get language, unit, directory'],
 [72, 'rf', '!=', None, 'rf parameter is required for creating a post request'],
 [72, 'admin', '!=', None, 'admin parameter is required for setting up request user in admin_form'],
 [72, 'default', '!=', None, 'default parameter is required for setting up request user in user_form'],
 [72, 'default_ps', '!=', None, 'default_ps parameter is required but not used in the function'],
 [72, 'afrikaans', '!=', None, 'afrikaans parameter is required to set the language'],
 [72, 'af_tutorial_po', '!=', None, 'af_tutorial_po parameter is needed to get unit and directory'],
 [92, 'rf', '!=', None, 'rf parameter is required for creating a post request'],
 [92, 'default', '!=', None, 'default parameter is required for setting up request user'],
 [92, 'default_ps', '!=', None, 'default_ps parameter is required but not used in the function'],
 [92, 'afrikaans', '!=', None, 'afrikaans parameter is required to set the language'],
 [92, 'af_tutorial_po', '!=', None, 'af_tutorial_po parameter is needed to get unit and directory'],
 [134, 'UnitStateField', '!=', None, 'UnitStateField is required but not instantiated with arguments']]"
nesterione/problem-solving-and-algorithms,"__author__ = 'igor'
import math
import random

def integr(a,b,n, func):
    '''Метод правых прямоугольников'''
    h = (b - a)/n
    sm = 0
    for i in range(0,n):
        y = func(a+h*i)
        sm += y*h
    return sm

def integr_l(a,b,n, func):
    '''Метод левых прямоугольников'''
    h = (b - a)/n
    sm = 0
    for i in range(1,n+1):
        y = func(a+h*i)
        sm += y*h
    return sm

def integr_m(a,b,n, func):
    '''Метод центральных прямоугольников'''
    h = (b - a)/n
    sm = 0
    for i in range(0,n):
        xx = a+h*i + h/2
        y = func(xx)
        sm += y*h
    return sm

def integr_t(a,b,n, func):
    '''Метод тропеций прямоугольников'''
    h = (b - a)/n
    sm = 0
    for i in range(0,n):
        start = a + i*h
        end = a + (i+1)*h
        S = 0.5*(func(start)+func(end))*h
        sm += S
    return sm

def integr_sm(a,b,n, func):
    '''Метод парабол (Симсона)'''
    h = (b - a)/n
    sm = 0
    for i in range(0,n):
        start = a + i*h
        middle = a + i*h + h/2
        end = a + (i+1)*h
        S = h/3 * (func(start)+4*func(middle)+func(end))
        sm += S/2
    return sm

def integr_sm_v2(a,b,n, func):
    '''Метод парабол (Симсона) - другая реализация'''
    h = (b - a)/n
    sm = 0
    for i in range(0,n,2):
        start = a + i*h
        middle = a + (i+1)*h
        end = a + (i+2)*h
        S = h/3 * (func(start)+4*func(middle)+func(end))
        sm += S
    return sm

def count_enter(left, right,top, n, func, pred):
    '''Функция попавших точек в область, для метода Монтекарло'''
    count = 0
    for i in range(0,n):
        r_x = left + right*random.random()
        r_y = top*random.random()
        real_y = func(r_x)
        if(pred(real_y,r_y)):
            count+=1
    return count


def integr_monte(a,b,n,top, func):
    '''Метод вероятносный метод Монтекарло'''
    h = b - a
    count1 = count_enter(a,b, top, n, func, (lambda x, y: x>y))
    count2 = count_enter(a,b, -top, n, func, (lambda x, y: x<y))
    S1 = h*top * ((count1)/n)
    S2 = h*top * ((count2)/n)
    return S1-S2

def compare_double(double_value1, double_value2, eps):
    if(abs(double_value1-double_value2)<=eps):
        return True
    return False

if __name__ == '__main__':
    in_a = 0
    in_b = 10
    in_n = 1000
    in_func = math.sin
    eps = 0.1
    msg = ""Error value""
    expect = 1.8

    assert compare_double(expect, integr(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_l(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_m(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_t(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_sm(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_sm_v2(in_a,in_b,in_n,in_func), eps), msg 
    assert compare_double(expect, integr_monte(in_a,in_b,1000000,5,in_func), eps), msg
    print(""Success"")","
1__author__ = 'igor'
2import math
3import random
4
5def integr(a,b,n, func):
6    '''Метод правых прямоугольников'''
7    h = (b - a)/n
8    sm = 0
9    for i in range(0,n):
10        y = func(a+h*i)
11        sm += y*h
12    return sm
13
14def integr_l(a,b,n, func):
15    '''Метод левых прямоугольников'''
16    h = (b - a)/n
17    sm = 0
18    for i in range(1,n+1):
19        y = func(a+h*i)
20        sm += y*h
21    return sm
22
23def integr_m(a,b,n, func):
24    '''Метод центральных прямоугольников'''
25    h = (b - a)/n
26    sm = 0
27    for i in range(0,n):
28        xx = a+h*i + h/2
29        y = func(xx)
30        sm += y*h
31    return sm
32
33def integr_t(a,b,n, func):
34    '''Метод тропеций прямоугольников'''
35    h = (b - a)/n
36    sm = 0
37    for i in range(0,n):
38        start = a + i*h
39        end = a + (i+1)*h
40        S = 0.5*(func(start)+func(end))*h
41        sm += S
42    return sm
43
44def integr_sm(a,b,n, func):
45    '''Метод парабол (Симсона)'''
46    h = (b - a)/n
47    sm = 0
48    for i in range(0,n):
49        start = a + i*h
50        middle = a + i*h + h/2
51        end = a + (i+1)*h
52        S = h/3 * (func(start)+4*func(middle)+func(end))
53        sm += S/2
54    return sm
55
56def integr_sm_v2(a,b,n, func):
57    '''Метод парабол (Симсона) - другая реализация'''
58    h = (b - a)/n
59    sm = 0
60    for i in range(0,n,2):
61        start = a + i*h
62        middle = a + (i+1)*h
63        end = a + (i+2)*h
64        S = h/3 * (func(start)+4*func(middle)+func(end))
65        sm += S
66    return sm
67
68def count_enter(left, right,top, n, func, pred):
69    '''Функция попавших точек в область, для метода Монтекарло'''
70    count = 0
71    for i in range(0,n):
72        r_x = left + right*random.random()
73        r_y = top*random.random()
74        real_y = func(r_x)
75        if(pred(real_y,r_y)):
76            count+=1
77    return count
78
79
80def integr_monte(a,b,n,top, func):
81    '''Метод вероятносный метод Монтекарло'''
82    h = b - a
83    count1 = count_enter(a,b, top, n, func, (lambda x, y: x>y))
84    count2 = count_enter(a,b, -top, n, func, (lambda x, y: x<y))
85    S1 = h*top * ((count1)/n)
86    S2 = h*top * ((count2)/n)
87    return S1-S2
88
89def compare_double(double_value1, double_value2, eps):
90    if(abs(double_value1-double_value2)<=eps):
91        return True
92    return False
93
94if __name__ == '__main__':
95    in_a = 0
96    in_b = 10
97    in_n = 1000
98    in_func = math.sin
99    eps = 0.1
100    msg = ""Error value""
101    expect = 1.8
102
103    print(""Success"")","[['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True'], ['compare_double(expect', '==', 'True']]",8,8,1.0,0.0026455026455026,"['__author__', 'a', 'b', 'n', 'func', 'h', 'sm', 'y', 'xx', 'start', 'end', 'S', 'middle', 'left', 'right', 'top', 'pred', 'count', 'r_x', 'r_y', 'real_y', 'count1', 'count2', 'S1', 'S2', 'double_value1', 'double_value2', 'eps', 'in_a', 'in_b', 'in_n', 'in_func', 'msg', 'expect']",34,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'a', 'b', 'n', 'func', 'h', 'sm', 'y', 'xx', 'start', 'end', 'S', 'middle', 'left', 'right', 'top', 'pred', 'count', 'r_x', 'r_y', 'real_y', 'count1', 'count2', 'S1', 'S2', 'double_value1', 'double_value2', 'eps', 'in_a', 'in_b', 'in_n', 'in_func', 'msg', 'expect']
*Code:

1__author__ = 'igor'
2import math
3import random
4
5def integr(a,b,n, func):
6    '''Метод правых прямоугольников'''
7    h = (b - a)/n
8    sm = 0
9    for i in range(0,n):
10        y = func(a+h*i)
11        sm += y*h
12    return sm
13
14def integr_l(a,b,n, func):
15    '''Метод левых прямоугольников'''
16    h = (b - a)/n
17    sm = 0
18    for i in range(1,n+1):
19        y = func(a+h*i)
20        sm += y*h
21    return sm
22
23def integr_m(a,b,n, func):
24    '''Метод центральных прямоугольников'''
25    h = (b - a)/n
26    sm = 0
27    for i in range(0,n):
28        xx = a+h*i + h/2
29        y = func(xx)
30        sm += y*h
31    return sm
32
33def integr_t(a,b,n, func):
34    '''Метод тропеций прямоугольников'''
35    h = (b - a)/n
36    sm = 0
37    for i in range(0,n):
38        start = a + i*h
39        end = a + (i+1)*h
40        S = 0.5*(func(start)+func(end))*h
41        sm += S
42    return sm
43
44def integr_sm(a,b,n, func):
45    '''Метод парабол (Симсона)'''
46    h = (b - a)/n
47    sm = 0
48    for i in range(0,n):
49        start = a + i*h
50        middle = a + i*h + h/2
51        end = a + (i+1)*h
52        S = h/3 * (func(start)+4*func(middle)+func(end))
53        sm += S/2
54    return sm
55
56def integr_sm_v2(a,b,n, func):
57    '''Метод парабол (Симсона) - другая реализация'''
58    h = (b - a)/n
59    sm = 0
60    for i in range(0,n,2):
61        start = a + i*h
62        middle = a + (i+1)*h
63        end = a + (i+2)*h
64        S = h/3 * (func(start)+4*func(middle)+func(end))
65        sm += S
66    return sm
67
68def count_enter(left, right,top, n, func, pred):
69    '''Функция попавших точек в область, для метода Монтекарло'''
70    count = 0
71    for i in range(0,n):
72        r_x = left + right*random.random()
73        r_y = top*random.random()
74        real_y = func(r_x)
75        if(pred(real_y,r_y)):
76            count+=1
77    return count
78
79
80def integr_monte(a,b,n,top, func):
81    '''Метод вероятносный метод Монтекарло'''
82    h = b - a
83    count1 = count_enter(a,b, top, n, func, (lambda x, y: x>y))
84    count2 = count_enter(a,b, -top, n, func, (lambda x, y: x<y))
85    S1 = h*top * ((count1)/n)
86    S2 = h*top * ((count2)/n)
87    return S1-S2
88
89def compare_double(double_value1, double_value2, eps):
90    if(abs(double_value1-double_value2)<=eps):
91        return True
92    return False
93
94if __name__ == '__main__':
95    in_a = 0
96    in_b = 10
97    in_n = 1000
98    in_func = math.sin
99    eps = 0.1
100    msg = ""Error value""
101    expect = 1.8
102
103    print(""Success"")",4245,"[[5, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [5, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [5, 'n', '>', 0, ""'n' should be greater than 0""],
 [14, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [14, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [14, 'n', '>', 0, ""'n' should be greater than 0""],
 [23, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [23, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [23, 'n', '>', 0, ""'n' should be greater than 0""],
 [33, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [33, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [33, 'n', '>', 0, ""'n' should be greater than 0""],
 [44, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [44, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [44, 'n', '>', 0, ""'n' should be greater than 0""],
 [56, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [56, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [56, 'n', '>', 0, ""'n' should be greater than 0""],
 [68, 'left', '>=', 0, ""Left limit should be non-negative""],
 [68, 'right', '>', 'left', ""Right limit should be greater than left limit""],
 [68, 'n', '>', 0, ""'n' should be greater than 0""],
 [68, 'top', '>', 0, ""'top' should be greater than 0""],
 [80, 'a', '>=', 0, ""Lower limit of integration should be non-negative""],
 [80, 'b', '>', 'a', ""Upper limit 'b' of integration should be greater than lower limit 'a'""],
 [80, 'n', '>', 0, ""'n' should be greater than 0""],
 [80, 'top', '>', 0, ""'top' should be greater than 0""],
 [89, 'double_value1', '>=', 0, ""The first value to compare should be non-negative""],
 [89, 'double_value2', '>=', 0, ""The second value to compare should be non-negative""],
 [89, 'eps', '>', 0, ""The tolerance 'eps' should be greater than 0""]]"
zetaops/ulakbus,"# -*-  coding: utf-8 -*-

# Copyright (C) 2015 ZetaOps Inc.
#
# This file is licensed under the GNU General Public License v3
# (GPLv3).  See LICENSE.txt for details.

from ulakbus.models import User, Personel
from zengine.lib.test_utils import BaseTestCase
from dateutil.relativedelta import relativedelta
from pyoko.db.connection import log_bucket, version_bucket
import datetime

__author__ = 'Mithat Raşit Özçıkrıkcı'


class TestCase(BaseTestCase):
    def test_gorev_suresi_uzatma(self):
        """"""
             Test data'daki mithat kullanıcısı ile test işlemi gerçekleştirilir.
             Seçilen personelin görev süresinin açılan formda görev süresi bitiş
             tarihi girilerek görev süresini uzatma mantığına dayanır.
        """"""
        log_bucket_count = len(log_bucket.get_keys())
        version_bucket_keys = version_bucket.get_keys()

        user = User.objects.get(username=""personel_isleri_1"")
        personel_id = ""V9AJztgnQQc6vbIfNice2ZrHAvF""
        personel = Personel.objects.get(personel_id)
        eski_gorev_suresi_bitis = personel.gorev_suresi_bitis
        yeni_gorev_suresi_bitis = eski_gorev_suresi_bitis + relativedelta(years=1)
        self.prepare_client(""/gorev_suresi_uzatma"", user=user)

        # Görev süresi uzatılacak personel seçilir.
        self.client.post(
            id=personel_id,
            model=""Personel"",
            param=""personel_id"",
            wf=""gorev_suresi_uzatma""
        )

        # Görev süresi uzatma formu doldurulur.
        self.client.post(
            cmd=""kaydet"",
            wf=""gorev_suresi_uzatma"",
            form=dict(gorev_suresi_bitis=yeni_gorev_suresi_bitis.strftime(""%d.%m.%Y""),
                      personel_id=personel.key)
        )

        # save() işlemi meta paremetresi olmadan çalıştırıldığı için aktivite kaydının tutulmaması
        # ve aynı kalması beklenir.
        assert len(log_bucket.get_keys()) == log_bucket_count
        # Yeni versiyon keyleri getirilir.
        versiyon_keyleri = list(set(version_bucket.get_keys()) - set(version_bucket_keys))
        # Personel kaydı ile ilgili versiyon kaydı bulunur.
        key = ''
        for key in versiyon_keyleri:
            if version_bucket.get(key).data['model'] == 'personel':
                break
        yeni_versiyon_key = key

        # Versiyon kaydındaki görev_suresi_bitis field'ınin belirlenen tarihle ayni olmasi kontrol edilir.
        assert version_bucket.get(yeni_versiyon_key).data['data']['gorev_suresi_bitis'] == \
               yeni_gorev_suresi_bitis.strftime(""%Y-%m-%dT%H:%M:%SZ"")
        # Versiyon kaydındaki görev_suresi_baslama field'ınin bugünün tarihiyle ayni olması kontrol edilir.
        assert version_bucket.get(yeni_versiyon_key).data['data']['gorev_suresi_baslama'] == \
               datetime.date.today().strftime(""%Y-%m-%dT%H:%M:%SZ"")

        # Personelin görev süresi bitiş tarihinin belirlediğimiz
        # şekilde değişip değişmediği kontrol ediliyor.
        personel = Personel.objects.get(personel.key)
        assert personel.gorev_suresi_bitis == yeni_gorev_suresi_bitis
","
1# -*-  coding: utf-8 -*-
2
3# Copyright (C) 2015 ZetaOps Inc.
4#
5# This file is licensed under the GNU General Public License v3
6# (GPLv3).  See LICENSE.txt for details.
7
8from ulakbus.models import User, Personel
9from zengine.lib.test_utils import BaseTestCase
10from dateutil.relativedelta import relativedelta
11from pyoko.db.connection import log_bucket, version_bucket
12import datetime
13
14__author__ = 'Mithat Raşit Özçıkrıkcı'
15
16
17class TestCase(BaseTestCase):
18    def test_gorev_suresi_uzatma(self):
19        """"""
20             Test data'daki mithat kullanıcısı ile test işlemi gerçekleştirilir.
21             Seçilen personelin görev süresinin açılan formda görev süresi bitiş
22             tarihi girilerek görev süresini uzatma mantığına dayanır.
23        """"""
24        log_bucket_count = len(log_bucket.get_keys())
25        version_bucket_keys = version_bucket.get_keys()
26
27        user = User.objects.get(username=""personel_isleri_1"")
28        personel_id = ""V9AJztgnQQc6vbIfNice2ZrHAvF""
29        personel = Personel.objects.get(personel_id)
30        eski_gorev_suresi_bitis = personel.gorev_suresi_bitis
31        yeni_gorev_suresi_bitis = eski_gorev_suresi_bitis + relativedelta(years=1)
32        self.prepare_client(""/gorev_suresi_uzatma"", user=user)
33
34        # Görev süresi uzatılacak personel seçilir.
35        self.client.post(
36            id=personel_id,
37            model=""Personel"",
38            param=""personel_id"",
39            wf=""gorev_suresi_uzatma""
40        )
41
42        # Görev süresi uzatma formu doldurulur.
43        self.client.post(
44            cmd=""kaydet"",
45            wf=""gorev_suresi_uzatma"",
46            form=dict(gorev_suresi_bitis=yeni_gorev_suresi_bitis.strftime(""%d.%m.%Y""),
47                      personel_id=personel.key)
48        )
49
50        # save() işlemi meta paremetresi olmadan çalıştırıldığı için aktivite kaydının tutulmaması
51        # ve aynı kalması beklenir.
52        # Yeni versiyon keyleri getirilir.
53        versiyon_keyleri = list(set(version_bucket.get_keys()) - set(version_bucket_keys))
54        # Personel kaydı ile ilgili versiyon kaydı bulunur.
55        key = ''
56        for key in versiyon_keyleri:
57            if version_bucket.get(key).data['model'] == 'personel':
58                break
59        yeni_versiyon_key = key
60
61        # Versiyon kaydındaki görev_suresi_bitis field'ınin belirlenen tarihle ayni olmasi kontrol edilir.
62               yeni_gorev_suresi_bitis.strftime(""%Y-%m-%dT%H:%M:%SZ"")
63        # Versiyon kaydındaki görev_suresi_baslama field'ınin bugünün tarihiyle ayni olması kontrol edilir.
64               datetime.date.today().strftime(""%Y-%m-%dT%H:%M:%SZ"")
65
66        # Personelin görev süresi bitiş tarihinin belirlediğimiz
67        # şekilde değişip değişmediği kontrol ediliyor.
68        personel = Personel.objects.get(personel.key)
69","[['len(log_bucket.get_keys())', '==', 'log_bucket_count'], [""version_bucket.get(yeni_versiyon_key).data['data']['gorev_suresi_bitis']"", '==', '\\'], [""version_bucket.get(yeni_versiyon_key).data['data']['gorev_suresi_baslama']"", '==', '\\'], ['personel.gorev_suresi_bitis', '==', 'yeni_gorev_suresi_bitis']]",4,4,1.0,0.0012928248222365,"['__author__', 'log_bucket_count', 'version_bucket_keys', 'user', 'personel_id', 'personel', 'eski_gorev_suresi_bitis', 'yeni_gorev_suresi_bitis', 'versiyon_keyleri', 'key', 'yeni_versiyon_key']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'log_bucket_count', 'version_bucket_keys', 'user', 'personel_id', 'personel', 'eski_gorev_suresi_bitis', 'yeni_gorev_suresi_bitis', 'versiyon_keyleri', 'key', 'yeni_versiyon_key']
*Code:

1# -*-  coding: utf-8 -*-
2
3# Copyright (C) 2015 ZetaOps Inc.
4#
5# This file is licensed under the GNU General Public License v3
6# (GPLv3).  See LICENSE.txt for details.
7
8from ulakbus.models import User, Personel
9from zengine.lib.test_utils import BaseTestCase
10from dateutil.relativedelta import relativedelta
11from pyoko.db.connection import log_bucket, version_bucket
12import datetime
13
14__author__ = 'Mithat Raşit Özçıkrıkcı'
15
16
17class TestCase(BaseTestCase):
18    def test_gorev_suresi_uzatma(self):
19        """"""
20             Test data'daki mithat kullanıcısı ile test işlemi gerçekleştirilir.
21             Seçilen personelin görev süresinin açılan formda görev süresi bitiş
22             tarihi girilerek görev süresini uzatma mantığına dayanır.
23        """"""
24        log_bucket_count = len(log_bucket.get_keys())
25        version_bucket_keys = version_bucket.get_keys()
26
27        user = User.objects.get(username=""personel_isleri_1"")
28        personel_id = ""V9AJztgnQQc6vbIfNice2ZrHAvF""
29        personel = Personel.objects.get(personel_id)
30        eski_gorev_suresi_bitis = personel.gorev_suresi_bitis
31        yeni_gorev_suresi_bitis = eski_gorev_suresi_bitis + relativedelta(years=1)
32        self.prepare_client(""/gorev_suresi_uzatma"", user=user)
33
34        # Görev süresi uzatılacak personel seçilir.
35        self.client.post(
36            id=personel_id,
37            model=""Personel"",
38            param=""personel_id"",
39            wf=""gorev_suresi_uzatma""
40        )
41
42        # Görev süresi uzatma formu doldurulur.
43        self.client.post(
44            cmd=""kaydet"",
45            wf=""gorev_suresi_uzatma"",
46            form=dict(gorev_suresi_bitis=yeni_gorev_suresi_bitis.strftime(""%d.%m.%Y""),
47                      personel_id=personel.key)
48        )
49
50        # save() işlemi meta paremetresi olmadan çalıştırıldığı için aktivite kaydının tutulmaması
51        # ve aynı kalması beklenir.
52        # Yeni versiyon keyleri getirilir.
53        versiyon_keyleri = list(set(version_bucket.get_keys()) - set(version_bucket_keys))
54        # Personel kaydı ile ilgili versiyon kaydı bulunur.
55        key = ''
56        for key in versiyon_keyleri:
57            if version_bucket.get(key).data['model'] == 'personel':
58                break
59        yeni_versiyon_key = key
60
61        # Versiyon kaydındaki görev_suresi_bitis field'ınin belirlenen tarihle ayni olmasi kontrol edilir.
62               yeni_gorev_suresi_bitis.strftime(""%Y-%m-%dT%H:%M:%SZ"")
63        # Versiyon kaydındaki görev_suresi_baslama field'ınin bugünün tarihiyle ayni olması kontrol edilir.
64               datetime.date.today().strftime(""%Y-%m-%dT%H:%M:%SZ"")
65
66        # Personelin görev süresi bitiş tarihinin belirlediğimiz
67        # şekilde değişip değişmediği kontrol ediliyor.
68        personel = Personel.objects.get(personel.key)
69",4478,"[17, ""__author__"", ""=="", ""Mithat Raşit Özçıkrıkcı"", ""Ensure the author of this code is correct""],
[24, ""log_bucket_count"", "">="", 0, ""log_bucket_count should not be negative""],
[25, ""version_bucket_keys"", "">="", 0, ""version_bucket_keys should not be negative""],
[27, ""user"", ""!="" , None, ""User object cannot be None""],
[29, ""personel_id"", ""!="" , None, ""Personal Id cannot be None""],
[30, ""personel"", ""!="" , None, ""Personel object cannot be None""],
[31, ""eski_gorev_suresi_bitis"", ""<="", ""yeni_gorev_suresi_bitis"", ""Old service end date should be smaller than or equals to the new service end date""],
[59, ""key"", ""!="" , None, ""Key object cannot be None""]]"
Nolski/airmozilla,"from nose.tools import eq_

from airmozilla.base.tests.testbase import DjangoTestCase
from airmozilla.main.models import Event, Channel
from airmozilla.main.utils import get_event_channels


class TestEventsToChannels(DjangoTestCase):
    fixtures = ['airmozilla/manage/tests/main_testdata.json']

    def test_basic_case(self):
        event = Event.objects.get(title='Test event')
        # the fixture event belongs to the Main channel
        assert event.channels.all().count() == 1
        events = Event.objects.all()
        assert events.count() == 1

        channels = get_event_channels(events)
        assert len(channels[event]) == 1
        eq_(channels[event], list(event.channels.all()))

        testing = Channel.objects.create(
            name='Testing',
            slug='testing',
            description='<p>Stuff!</p>'
        )
        event.channels.add(testing)

        channels = get_event_channels(events)
        assert len(channels[event]) == 2
        eq_(channels[event], list(event.channels.all()))
","
1from nose.tools import eq_
2
3from airmozilla.base.tests.testbase import DjangoTestCase
4from airmozilla.main.models import Event, Channel
5from airmozilla.main.utils import get_event_channels
6
7
8class TestEventsToChannels(DjangoTestCase):
9    fixtures = ['airmozilla/manage/tests/main_testdata.json']
10
11    def test_basic_case(self):
12        event = Event.objects.get(title='Test event')
13        # the fixture event belongs to the Main channel
14        events = Event.objects.all()
15
16        channels = get_event_channels(events)
17        eq_(channels[event], list(event.channels.all()))
18
19        testing = Channel.objects.create(
20            name='Testing',
21            slug='testing',
22            description='<p>Stuff!</p>'
23        )
24        event.channels.add(testing)
25
26        channels = get_event_channels(events)
27        eq_(channels[event], list(event.channels.all()))
28","[['event.channels.all().count()', '==', '1'], ['events.count()', '==', '1'], ['len(channels[event])', '==', '1'], ['len(channels[event])', '==', '2']]",4,4,1.0,0.0038647342995169,"['fixtures', 'event', 'events', 'channels', 'testing']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['fixtures', 'event', 'events', 'channels', 'testing']
*Code:

1from nose.tools import eq_
2
3from airmozilla.base.tests.testbase import DjangoTestCase
4from airmozilla.main.models import Event, Channel
5from airmozilla.main.utils import get_event_channels
6
7
8class TestEventsToChannels(DjangoTestCase):
9    fixtures = ['airmozilla/manage/tests/main_testdata.json']
10
11    def test_basic_case(self):
12        event = Event.objects.get(title='Test event')
13        # the fixture event belongs to the Main channel
14        events = Event.objects.all()
15
16        channels = get_event_channels(events)
17        eq_(channels[event], list(event.channels.all()))
18
19        testing = Channel.objects.create(
20            name='Testing',
21            slug='testing',
22            description='<p>Stuff!</p>'
23        )
24        event.channels.add(testing)
25
26        channels = get_event_channels(events)
27        eq_(channels[event], list(event.channels.all()))
28",2351,"[[11, 'event', '!=', None, 'event object must be retrieved successfully from the database'],
[16, 'channels', '==', 'events', ""get_event_channels response size should equal the number of events""],
[19, 'testing', '!=', None, 'Channel object must be created successfully'],
[24, 'event.channels', '>=', 1, ""Event's channels list should not be empty after adding a channel""],
[26, 'channels', '==', 'events', ""get_event_channels response size should equal the number of events""]]"
Ell-i/ELL-i-PyBot-Tests,"
""""""
TEST CASES START
""""""

import re
from Utilities import *

CURRENTPATH = os.getcwd();

def compile_flash_code(setupFlag):
    try:
        if setupFlag == ""High"":
            compile_ = compile(TESTPATH, DigitalReadHigh);
        elif setupFlag == ""Low"":
            compile_ = compile(TESTPATH, DigitalReadLow);
        else:
            print ""Wrong setup flag parameter!""

        if compile_ != True:
            raise RuntimeError, ""Compiling the source code failed!""
    except RuntimeError, arg:
        print arg;
    else:
        print ""Source code compiled! HEX file created!""

def read_high():
    flash_ = flash(TESTPATH, DigitalReadHigh);
    if flash_ != True:
        raise RuntimeError, ""Flashing the device failed!""

    os.chdir(CURRENTPATH);

    sigrok_ = call_sigrok('1');
    if sigrok_ != True:
        raise RuntimeError, ""Call to sigrok to dump output from device failed!""

    try:
        fo = open(""sigrok-output"", ""r"");
        dataLines = fo.readlines();
        testLine = dataLines[2][2:];
        test_output = re.compile('[0-1]');
        str = re.search(test_output, testLine);
        assert (str.group() == '1'), ""Low at pin!""
    except IOError, arg:
        print arg;
        raise RuntimeError, ""Couldn't find/read file!""
    except AssertionError, arg:
        print arg;
        raise RuntimeError, ""Test case failed. The value is not high at pin!""
    except RuntimeError, arg:
        print arg;
    else:
        print ""Test case passed. The value is high at pin!""

def read_low():
    flash_ = flash(TESTPATH, DigitalReadLow);
    if flash_ != True:
        raise RuntimeError, ""Flashing the device failed!""

    os.chdir(CURRENTPATH);

    sigrok_ = call_sigrok('1');
    if sigrok_ != True:
        raise RuntimeError, ""Call to sigrok to dump output from device failed!""

    try:
        fo = open(""sigrok-output"", ""r"");
        dataLines = fo.readlines();
        testLine = dataLines[2][2:];
        test_output = re.compile('[0-1]');
        str = re.search(test_output, testLine);
        assert (str.group() == '0'), ""High at pin!""
    except IOError, arg:
        print arg;
        raise RuntimeError, ""Couldn't find/read file!""
    except AssertionError, arg:
        print arg;
        raise RuntimeError, ""Test case failed. The value is not low at pin!""
    except RuntimeError, arg:
        print arg;
    else:
        print ""Test case passed. The value is low at pin!""

def clean_code(teardownFlag):
    if teardownFlag == ""High"":
        os.chdir(TESTPATH + DigitalReadHigh + ""/"");
    elif teardownFlag == ""Low"":
        os.chdir(TESTPATH + DigitalReadLow + ""/"");
    else:
        print ""Wrong teardown flag!""

    try:
        args = shlex.split(""'make clean'"");
        p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE);
        output, error = p.communicate();
        if p.returncode != 0:
            raise RuntimeError, error;
    except RuntimeError, arg:
        print arg;
        print ""Make clean failed!""
    else:
        print ""Make clean completed!""



""""""
TEST CASES END
""""""
","
1
2""""""
3TEST CASES START
4""""""
5
6import re
7from Utilities import *
8
9CURRENTPATH = os.getcwd();
10
11def compile_flash_code(setupFlag):
12    try:
13        if setupFlag == ""High"":
14            compile_ = compile(TESTPATH, DigitalReadHigh);
15        elif setupFlag == ""Low"":
16            compile_ = compile(TESTPATH, DigitalReadLow);
17        else:
18            print ""Wrong setup flag parameter!""
19
20        if compile_ != True:
21            raise RuntimeError, ""Compiling the source code failed!""
22    except RuntimeError, arg:
23        print arg;
24    else:
25        print ""Source code compiled! HEX file created!""
26
27def read_high():
28    flash_ = flash(TESTPATH, DigitalReadHigh);
29    if flash_ != True:
30        raise RuntimeError, ""Flashing the device failed!""
31
32    os.chdir(CURRENTPATH);
33
34    sigrok_ = call_sigrok('1');
35    if sigrok_ != True:
36        raise RuntimeError, ""Call to sigrok to dump output from device failed!""
37
38    try:
39        fo = open(""sigrok-output"", ""r"");
40        dataLines = fo.readlines();
41        testLine = dataLines[2][2:];
42        test_output = re.compile('[0-1]');
43        str = re.search(test_output, testLine);
44    except IOError, arg:
45        print arg;
46        raise RuntimeError, ""Couldn't find/read file!""
47    except AssertionError, arg:
48        print arg;
49        raise RuntimeError, ""Test case failed. The value is not high at pin!""
50    except RuntimeError, arg:
51        print arg;
52    else:
53        print ""Test case passed. The value is high at pin!""
54
55def read_low():
56    flash_ = flash(TESTPATH, DigitalReadLow);
57    if flash_ != True:
58        raise RuntimeError, ""Flashing the device failed!""
59
60    os.chdir(CURRENTPATH);
61
62    sigrok_ = call_sigrok('1');
63    if sigrok_ != True:
64        raise RuntimeError, ""Call to sigrok to dump output from device failed!""
65
66    try:
67        fo = open(""sigrok-output"", ""r"");
68        dataLines = fo.readlines();
69        testLine = dataLines[2][2:];
70        test_output = re.compile('[0-1]');
71        str = re.search(test_output, testLine);
72    except IOError, arg:
73        print arg;
74        raise RuntimeError, ""Couldn't find/read file!""
75    except AssertionError, arg:
76        print arg;
77        raise RuntimeError, ""Test case failed. The value is not low at pin!""
78    except RuntimeError, arg:
79        print arg;
80    else:
81        print ""Test case passed. The value is low at pin!""
82
83def clean_code(teardownFlag):
84    if teardownFlag == ""High"":
85        os.chdir(TESTPATH + DigitalReadHigh + ""/"");
86    elif teardownFlag == ""Low"":
87        os.chdir(TESTPATH + DigitalReadLow + ""/"");
88    else:
89        print ""Wrong teardown flag!""
90
91    try:
92        args = shlex.split(""'make clean'"");
93        p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE);
94        output, error = p.communicate();
95        if p.returncode != 0:
96            raise RuntimeError, error;
97    except RuntimeError, arg:
98        print arg;
99        print ""Make clean failed!""
100    else:
101        print ""Make clean completed!""
102
103
104
105""""""
106TEST CASES END
107""""""
108","[['(str.group()', '==', ""'1')""], ['(str.group()', '==', ""'0')""]]",2,2,1.0,0.0006455777921239,"['CURRENTPATH', 'setupFlag', 'compile_', 'flash_', 'sigrok_', 'fo', 'dataLines', 'testLine', 'test_output', 'str', 'teardownFlag', 'args', 'p', 'output', 'error']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['CURRENTPATH', 'setupFlag', 'compile_', 'flash_', 'sigrok_', 'fo', 'dataLines', 'testLine', 'test_output', 'str', 'teardownFlag', 'args', 'p', 'output', 'error']
*Code:

1
2""""""
3TEST CASES START
4""""""
5
6import re
7from Utilities import *
8
9CURRENTPATH = os.getcwd();
10
11def compile_flash_code(setupFlag):
12    try:
13        if setupFlag == ""High"":
14            compile_ = compile(TESTPATH, DigitalReadHigh);
15        elif setupFlag == ""Low"":
16            compile_ = compile(TESTPATH, DigitalReadLow);
17        else:
18            print ""Wrong setup flag parameter!""
19
20        if compile_ != True:
21            raise RuntimeError, ""Compiling the source code failed!""
22    except RuntimeError, arg:
23        print arg;
24    else:
25        print ""Source code compiled! HEX file created!""
26
27def read_high():
28    flash_ = flash(TESTPATH, DigitalReadHigh);
29    if flash_ != True:
30        raise RuntimeError, ""Flashing the device failed!""
31
32    os.chdir(CURRENTPATH);
33
34    sigrok_ = call_sigrok('1');
35    if sigrok_ != True:
36        raise RuntimeError, ""Call to sigrok to dump output from device failed!""
37
38    try:
39        fo = open(""sigrok-output"", ""r"");
40        dataLines = fo.readlines();
41        testLine = dataLines[2][2:];
42        test_output = re.compile('[0-1]');
43        str = re.search(test_output, testLine);
44    except IOError, arg:
45        print arg;
46        raise RuntimeError, ""Couldn't find/read file!""
47    except AssertionError, arg:
48        print arg;
49        raise RuntimeError, ""Test case failed. The value is not high at pin!""
50    except RuntimeError, arg:
51        print arg;
52    else:
53        print ""Test case passed. The value is high at pin!""
54
55def read_low():
56    flash_ = flash(TESTPATH, DigitalReadLow);
57    if flash_ != True:
58        raise RuntimeError, ""Flashing the device failed!""
59
60    os.chdir(CURRENTPATH);
61
62    sigrok_ = call_sigrok('1');
63    if sigrok_ != True:
64        raise RuntimeError, ""Call to sigrok to dump output from device failed!""
65
66    try:
67        fo = open(""sigrok-output"", ""r"");
68        dataLines = fo.readlines();
69        testLine = dataLines[2][2:];
70        test_output = re.compile('[0-1]');
71        str = re.search(test_output, testLine);
72    except IOError, arg:
73        print arg;
74        raise RuntimeError, ""Couldn't find/read file!""
75    except AssertionError, arg:
76        print arg;
77        raise RuntimeError, ""Test case failed. The value is not low at pin!""
78    except RuntimeError, arg:
79        print arg;
80    else:
81        print ""Test case passed. The value is low at pin!""
82
83def clean_code(teardownFlag):
84    if teardownFlag == ""High"":
85        os.chdir(TESTPATH + DigitalReadHigh + ""/"");
86    elif teardownFlag == ""Low"":
87        os.chdir(TESTPATH + DigitalReadLow + ""/"");
88    else:
89        print ""Wrong teardown flag!""
90
91    try:
92        args = shlex.split(""'make clean'"");
93        p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE);
94        output, error = p.communicate();
95        if p.returncode != 0:
96            raise RuntimeError, error;
97    except RuntimeError, arg:
98        print arg;
99        print ""Make clean failed!""
100    else:
101        print ""Make clean completed!""
102
103
104
105""""""
106TEST CASES END
107""""""
108",4754,"[[11, 'setupFlag', '==', 'High', 'The setupFlag is expected to be ""High"" for the compile_flash_code function'],
[11, 'setupFlag', '==', 'Low', 'The setupFlag is expected to be ""Low"" for the compile_flash_code function'],
[27, 'flash_', '==', True, 'flash_ is expected to be True when code is successfully flashed for reading high'],
[55, 'flash_', '==', True, 'flash_ is expected to be True when code is successfully flashed for reading low'],
[39, 'fo', '!=', None, 'File object should not be None when trying to read from file in read_high function'],
[39, 'dataLines', '!=', None, 'dataLines should not be empty when trying to read from file in read_high function'],
[67, 'fo', '!=', None, 'File object should not be None when trying to read from file in read_low function'],
[67, 'dataLines', '!=', None, 'dataLines should not be empty when trying to read from file in read_low function'],
[83, 'teardownFlag', '==', 'High', 'The teardownFlag is expected to be ""High"" for the clean_code function'],
[83, 'teardownFlag', '==', 'Low', 'The teardownFlag is expected to be ""Low"" for the clean_code function'],
[91, 'args', '!=', None, 'Command arguments should not be empty when trying to clean code'],
[91, 'p', '!=', None, 'Subprocess object should not be None when cleaning code'],
[91, 'output', '!=', None, 'Output string should not be empty when cleaning code']]"
jbruce12000/monte-carlo-project-estimator,"from scipy import stats
class Ticket(object):
    def __init__(self, name=None, mindays=0, maxdays=0, parallelizable=0):
        self.mindays = mindays
        self.maxdays = maxdays
        self.name = name
        self.mediandays = (float(self.maxdays) + float(self.mindays))/2
        self.parallelizable = 1/float(1+parallelizable)
        self.guesses = []

    def random_guesses(self, size=100000, stddevs=3.29):
        """"""make size random guesses from median out to stddevs
           
        Keyword args:
        size -- number of iterations for this simulation
        stddevs -- distance to include from median in standard deviations
        """"""
        self.guesses = stats.norm.rvs(loc=self.mediandays, scale=stddevs, size=size)
        return self.guesses

    def negatives_to_zero(self,list):
        """"""convert negative numbers to zero for a given list""""""
        # outliers are sometimes negative.  I am torn on whether to remove
        # them.  hubbard says leave them.
        for index, item in enumerate(list):
            if item < 0:
                list[index] = 0
        return list

    def __str__(self):
        return self.name

class TestTicket:
    def test_negatives_to_zero(self):
        alist = [-1,0,1]
        correct = [0,0,1]
        t = Ticket()
        answer = t.negatives_to_zero(alist)
        assert answer == correct
","
1from scipy import stats
2class Ticket(object):
3    def __init__(self, name=None, mindays=0, maxdays=0, parallelizable=0):
4        self.mindays = mindays
5        self.maxdays = maxdays
6        self.name = name
7        self.mediandays = (float(self.maxdays) + float(self.mindays))/2
8        self.parallelizable = 1/float(1+parallelizable)
9        self.guesses = []
10
11    def random_guesses(self, size=100000, stddevs=3.29):
12        """"""make size random guesses from median out to stddevs
13           
14        Keyword args:
15        size -- number of iterations for this simulation
16        stddevs -- distance to include from median in standard deviations
17        """"""
18        self.guesses = stats.norm.rvs(loc=self.mediandays, scale=stddevs, size=size)
19        return self.guesses
20
21    def negatives_to_zero(self,list):
22        """"""convert negative numbers to zero for a given list""""""
23        # outliers are sometimes negative.  I am torn on whether to remove
24        # them.  hubbard says leave them.
25        for index, item in enumerate(list):
26            if item < 0:
27                list[index] = 0
28        return list
29
30    def __str__(self):
31        return self.name
32
33class TestTicket:
34    def test_negatives_to_zero(self):
35        alist = [-1,0,1]
36        correct = [0,0,1]
37        t = Ticket()
38        answer = t.negatives_to_zero(alist)
39","[['answer', '==', 'correct']]",1,1,1.0,0.0007304601899196,"['name', 'mindays', 'maxdays', 'parallelizable', 'self.mindays', 'self.maxdays', 'self.name', 'self.mediandays', 'self.parallelizable', 'self.guesses', 'size', 'stddevs', 'list', 'list[index]', 'alist', 'correct', 't', 'answer']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['name', 'mindays', 'maxdays', 'parallelizable', 'self.mindays', 'self.maxdays', 'self.name', 'self.mediandays', 'self.parallelizable', 'self.guesses', 'size', 'stddevs', 'list', 'list[index]', 'alist', 'correct', 't', 'answer']
*Code:

1from scipy import stats
2class Ticket(object):
3    def __init__(self, name=None, mindays=0, maxdays=0, parallelizable=0):
4        self.mindays = mindays
5        self.maxdays = maxdays
6        self.name = name
7        self.mediandays = (float(self.maxdays) + float(self.mindays))/2
8        self.parallelizable = 1/float(1+parallelizable)
9        self.guesses = []
10
11    def random_guesses(self, size=100000, stddevs=3.29):
12        """"""make size random guesses from median out to stddevs
13           
14        Keyword args:
15        size -- number of iterations for this simulation
16        stddevs -- distance to include from median in standard deviations
17        """"""
18        self.guesses = stats.norm.rvs(loc=self.mediandays, scale=stddevs, size=size)
19        return self.guesses
20
21    def negatives_to_zero(self,list):
22        """"""convert negative numbers to zero for a given list""""""
23        # outliers are sometimes negative.  I am torn on whether to remove
24        # them.  hubbard says leave them.
25        for index, item in enumerate(list):
26            if item < 0:
27                list[index] = 0
28        return list
29
30    def __str__(self):
31        return self.name
32
33class TestTicket:
34    def test_negatives_to_zero(self):
35        alist = [-1,0,1]
36        correct = [0,0,1]
37        t = Ticket()
38        answer = t.negatives_to_zero(alist)
39",3014,"[[3, 'name', '!=', None, ""name should not be None""],
[3, 'mindays', '>=', 0, ""minimum days can't be negative""],
[3, 'maxdays', '>=', 'mindays', ""maximum days should not be less than minimum days""],
[11, 'stddevs', '>=', 0, ""standard deviations should be positive""],
[11, 'size', '>=', 1, ""size should be greater than 0 for iteration""],
[21, 'list', '!=', None, ""input list should not be None""],
[35, 'alist', '!=', None, ""input list should not be None""],
[37, 't', '!=', None, ""Ticket object should not be None""],
[38, 'answer', '!=', None, ""Output should not be None""]]"
SanketDG/coala,"from types import ModuleType

import coalib.bearlib.aspects
from coalib.bearlib.aspects.exceptions import (AspectNotFoundError,
                                               MultipleAspectFoundError)

import pytest
import unittest


class aspectsModuleTest(unittest.TestCase):

    def test_module(self):
        # check that module is correctly wrapped
        assert isinstance(coalib.bearlib.aspects, ModuleType)
        assert type(coalib.bearlib.aspects) is not ModuleType
        assert (type(coalib.bearlib.aspects) is
                coalib.bearlib.aspects.aspectsModule)

    def test__getitem__(self):
        dict_spelling = coalib.bearlib.aspects.Root.Spelling.DictionarySpelling
        # check a leaf aspect
        for aspectname in ['DictionarySpelling',
                           'spelling.DictionarySpelling',
                           'root.SPELLING.DictionarySpelling']:
            assert coalib.bearlib.aspects[aspectname] is dict_spelling
        # check a container aspect
        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
            assert (coalib.bearlib.aspects[aspectname] is
                    coalib.bearlib.aspects.Root.Spelling)
        # check root aspect
        for aspectname in ['Root', 'root', 'ROOT']:
            assert (coalib.bearlib.aspects[aspectname] is
                    coalib.bearlib.aspects.Root)

    def test__getitem__no_match(self):
        for aspectname in ['noaspect', 'NOASPECT',
                           'Root.DictionarySpelling']:
            with pytest.raises(AspectNotFoundError) as exc:
                coalib.bearlib.aspects[aspectname]
            exc.match(r""^No aspect named '%s'$"" % aspectname)

    def test__getitem__multi_match(self):
        for aspectname in ['Length', 'length', 'LENGTH']:
            with pytest.raises(MultipleAspectFoundError) as exc:
                coalib.bearlib.aspects[aspectname]
            exc.match(r""^Multiple aspects named '%s'. "" % aspectname +
                      r'Choose from '
                      r'\[<aspectclass'
                      r"" 'Root.Formatting.Length'>,""
                      r' <aspectclass'
                      r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
                      r' <aspectclass'
                      r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
                      r'\]$')

    def test_get(self):
        # check a leaf aspect
        for aspectname in ['clone', 'redundancy.clone',
                           'root.redundancy.clone']:
            self.assertIs(coalib.bearlib.aspects.get(aspectname),
                          coalib.bearlib.aspects.Root.Redundancy.Clone)
        # check a container aspect
        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
            self.assertIs(coalib.bearlib.aspects.get(aspectname),
                          coalib.bearlib.aspects.Root.Spelling)
        # check root aspect
        for aspectname in ['Root', 'root', 'ROOT']:
            self.assertIs(coalib.bearlib.aspects.get(aspectname),
                          coalib.bearlib.aspects.Root)

    def test_get_no_match(self):
        for aspectname in ['noaspect', 'NOASPECT', 'Root.aspectsYEAH']:
            self.assertIsNone(coalib.bearlib.aspects.get(aspectname))

    def test_get_multi_match(self):
        with self.assertRaisesRegex(
                MultipleAspectFoundError,
                r""^Multiple aspects named 'length'. ""
                r'Choose from '
                r'\[<aspectclass'
                r"" 'Root.Formatting.Length'>,""
                r' <aspectclass'
                r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
                r' <aspectclass'
                r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
                r'\]$'):
            coalib.bearlib.aspects.get('length')
","
1from types import ModuleType
2
3import coalib.bearlib.aspects
4from coalib.bearlib.aspects.exceptions import (AspectNotFoundError,
5                                               MultipleAspectFoundError)
6
7import pytest
8import unittest
9
10
11class aspectsModuleTest(unittest.TestCase):
12
13    def test_module(self):
14        # check that module is correctly wrapped
15                coalib.bearlib.aspects.aspectsModule)
16
17    def test__getitem__(self):
18        dict_spelling = coalib.bearlib.aspects.Root.Spelling.DictionarySpelling
19        # check a leaf aspect
20        for aspectname in ['DictionarySpelling',
21                           'spelling.DictionarySpelling',
22                           'root.SPELLING.DictionarySpelling']:
23        # check a container aspect
24        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
25                    coalib.bearlib.aspects.Root.Spelling)
26        # check root aspect
27        for aspectname in ['Root', 'root', 'ROOT']:
28                    coalib.bearlib.aspects.Root)
29
30    def test__getitem__no_match(self):
31        for aspectname in ['noaspect', 'NOASPECT',
32                           'Root.DictionarySpelling']:
33            with pytest.raises(AspectNotFoundError) as exc:
34                coalib.bearlib.aspects[aspectname]
35            exc.match(r""^No aspect named '%s'$"" % aspectname)
36
37    def test__getitem__multi_match(self):
38        for aspectname in ['Length', 'length', 'LENGTH']:
39            with pytest.raises(MultipleAspectFoundError) as exc:
40                coalib.bearlib.aspects[aspectname]
41            exc.match(r""^Multiple aspects named '%s'. "" % aspectname +
42                      r'Choose from '
43                      r'\[<aspectclass'
44                      r"" 'Root.Formatting.Length'>,""
45                      r' <aspectclass'
46                      r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
47                      r' <aspectclass'
48                      r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
49                      r'\]$')
50
51    def test_get(self):
52        # check a leaf aspect
53        for aspectname in ['clone', 'redundancy.clone',
54                           'root.redundancy.clone']:
55                          coalib.bearlib.aspects.Root.Redundancy.Clone)
56        # check a container aspect
57        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
58                          coalib.bearlib.aspects.Root.Spelling)
59        # check root aspect
60        for aspectname in ['Root', 'root', 'ROOT']:
61                          coalib.bearlib.aspects.Root)
62
63    def test_get_no_match(self):
64        for aspectname in ['noaspect', 'NOASPECT', 'Root.aspectsYEAH']:
65
66    def test_get_multi_match(self):
67                MultipleAspectFoundError,
68                r""^Multiple aspects named 'length'. ""
69                r'Choose from '
70                r'\[<aspectclass'
71                r"" 'Root.Formatting.Length'>,""
72                r' <aspectclass'
73                r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
74                r' <aspectclass'
75                r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
76                r'\]$'):
77            coalib.bearlib.aspects.get('length')
78","[['type(coalib.bearlib.aspects)', '==', 'not ModuleType'], ['(type(coalib.bearlib.aspects)', '==', ''], ['coalib.bearlib.aspects[aspectname]', '==', 'dict_spelling'], ['(coalib.bearlib.aspects[aspectname]', '==', ''], ['(coalib.bearlib.aspects[aspectname]', '==', '']]",11,5,0.4545454545454545,0.0013061650992685,['dict_spelling'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['dict_spelling']
*Code:

1from types import ModuleType
2
3import coalib.bearlib.aspects
4from coalib.bearlib.aspects.exceptions import (AspectNotFoundError,
5                                               MultipleAspectFoundError)
6
7import pytest
8import unittest
9
10
11class aspectsModuleTest(unittest.TestCase):
12
13    def test_module(self):
14        # check that module is correctly wrapped
15                coalib.bearlib.aspects.aspectsModule)
16
17    def test__getitem__(self):
18        dict_spelling = coalib.bearlib.aspects.Root.Spelling.DictionarySpelling
19        # check a leaf aspect
20        for aspectname in ['DictionarySpelling',
21                           'spelling.DictionarySpelling',
22                           'root.SPELLING.DictionarySpelling']:
23        # check a container aspect
24        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
25                    coalib.bearlib.aspects.Root.Spelling)
26        # check root aspect
27        for aspectname in ['Root', 'root', 'ROOT']:
28                    coalib.bearlib.aspects.Root)
29
30    def test__getitem__no_match(self):
31        for aspectname in ['noaspect', 'NOASPECT',
32                           'Root.DictionarySpelling']:
33            with pytest.raises(AspectNotFoundError) as exc:
34                coalib.bearlib.aspects[aspectname]
35            exc.match(r""^No aspect named '%s'$"" % aspectname)
36
37    def test__getitem__multi_match(self):
38        for aspectname in ['Length', 'length', 'LENGTH']:
39            with pytest.raises(MultipleAspectFoundError) as exc:
40                coalib.bearlib.aspects[aspectname]
41            exc.match(r""^Multiple aspects named '%s'. "" % aspectname +
42                      r'Choose from '
43                      r'\[<aspectclass'
44                      r"" 'Root.Formatting.Length'>,""
45                      r' <aspectclass'
46                      r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
47                      r' <aspectclass'
48                      r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
49                      r'\]$')
50
51    def test_get(self):
52        # check a leaf aspect
53        for aspectname in ['clone', 'redundancy.clone',
54                           'root.redundancy.clone']:
55                          coalib.bearlib.aspects.Root.Redundancy.Clone)
56        # check a container aspect
57        for aspectname in ['Spelling', 'SPELLING', 'ROOT.spelling']:
58                          coalib.bearlib.aspects.Root.Spelling)
59        # check root aspect
60        for aspectname in ['Root', 'root', 'ROOT']:
61                          coalib.bearlib.aspects.Root)
62
63    def test_get_no_match(self):
64        for aspectname in ['noaspect', 'NOASPECT', 'Root.aspectsYEAH']:
65
66    def test_get_multi_match(self):
67                MultipleAspectFoundError,
68                r""^Multiple aspects named 'length'. ""
69                r'Choose from '
70                r'\[<aspectclass'
71                r"" 'Root.Formatting.Length'>,""
72                r' <aspectclass'
73                r"" 'Root.Metadata.CommitMessage.Body.Length'>,""
74                r' <aspectclass'
75                r"" 'Root.Metadata.CommitMessage.Shortlog.Length'>""
76                r'\]$'):
77            coalib.bearlib.aspects.get('length')
78",4709,"Based on the provided code, there is only one variable - 'dict_spelling'. However, the nature of the code doesn't require any assertion checks. The python code is basically running different tests in the unittest framework. These tests validate the results. Therefore, the nature of this code doesn't necessarily require assertions to be input.

However, if assertions were to be made, they would be the following:

[18, 'dict_spelling', '!=', None, ""dict_spelling can't be None""]

The assertion checks if 'dict_spelling' is not None after being assigned a value.

Please remember, assertions are generally placed to confirm the code is operating as expected during its development phase. In the given pytest script, assertions are placed implicitly when using statements like 'with pytest.raises'. Hence, often in testing scripts, explicit assertions tend not to be used."
korealerts1/sentry,"from __future__ import absolute_import

from datetime import datetime
from django.core.urlresolvers import reverse

from sentry.models import Release
from sentry.testutils import APITestCase


class ProjectReleaseListTest(APITestCase):
    def test_simple(self):
        self.login_as(user=self.user)

        team = self.create_team()
        project1 = self.create_project(team=team, name='foo')
        project2 = self.create_project(team=team, name='bar')

        release1 = Release.objects.create(
            project=project1,
            version='1',
            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
        )
        release2 = Release.objects.create(
            project=project1,
            version='2',
            date_added=datetime(2013, 8, 14, 3, 8, 24, 880386),
        )
        Release.objects.create(
            project=project2,
            version='1',
        )

        url = reverse('sentry-api-0-project-releases', kwargs={
            'organization_slug': project1.organization.slug,
            'project_slug': project1.slug,
        })
        response = self.client.get(url, format='json')

        assert response.status_code == 200, response.content
        assert len(response.data) == 2
        assert response.data[0]['version'] == release2.version
        assert response.data[1]['version'] == release1.version

    def test_query_filter(self):
        self.login_as(user=self.user)

        team = self.create_team()
        project = self.create_project(team=team, name='foo')

        release = Release.objects.create(
            project=project,
            version='foobar',
            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
        )

        url = reverse('sentry-api-0-project-releases', kwargs={
            'organization_slug': project.organization.slug,
            'project_slug': project.slug,
        })
        response = self.client.get(url + '?query=foo', format='json')

        assert response.status_code == 200, response.content
        assert len(response.data) == 1
        assert response.data[0]['version'] == release.version

        response = self.client.get(url + '?query=bar', format='json')

        assert response.status_code == 200, response.content
        assert len(response.data) == 0


class ProjectReleaseCreateTest(APITestCase):
    def test_minimal(self):
        self.login_as(user=self.user)

        team = self.create_team()
        project = self.create_project(team=team, name='foo')

        url = reverse('sentry-api-0-project-releases', kwargs={
            'organization_slug': project.organization.slug,
            'project_slug': project.slug,
        })
        response = self.client.post(url, data={
            'version': '1.2.1',
        })

        assert response.status_code == 201, response.content
        assert response.data['version']

        release = Release.objects.get(
            project=project,
            version=response.data['version'],
        )
        assert not release.owner

    def test_duplicate(self):
        self.login_as(user=self.user)

        team = self.create_team()
        project = self.create_project(team=team, name='foo')

        Release.objects.create(version='1.2.1', project=project)

        url = reverse('sentry-api-0-project-releases', kwargs={
            'organization_slug': project.organization.slug,
            'project_slug': project.slug,
        })

        response = self.client.post(url, data={
            'version': '1.2.1',
        })

        assert response.status_code == 400, response.content

    def test_features(self):
        self.login_as(user=self.user)

        team = self.create_team()
        project = self.create_project(team=team, name='foo')

        url = reverse('sentry-api-0-project-releases', kwargs={
            'organization_slug': project.organization.slug,
            'project_slug': project.slug,
        })
        response = self.client.post(url, data={
            'version': '1.2.1',
            'owner': self.user.email,
        })

        assert response.status_code == 201, response.content
        assert response.data['version']

        release = Release.objects.get(
            project=project,
            version=response.data['version'],
        )
        assert release.owner == self.user
","
1from __future__ import absolute_import
2
3from datetime import datetime
4from django.core.urlresolvers import reverse
5
6from sentry.models import Release
7from sentry.testutils import APITestCase
8
9
10class ProjectReleaseListTest(APITestCase):
11    def test_simple(self):
12        self.login_as(user=self.user)
13
14        team = self.create_team()
15        project1 = self.create_project(team=team, name='foo')
16        project2 = self.create_project(team=team, name='bar')
17
18        release1 = Release.objects.create(
19            project=project1,
20            version='1',
21            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
22        )
23        release2 = Release.objects.create(
24            project=project1,
25            version='2',
26            date_added=datetime(2013, 8, 14, 3, 8, 24, 880386),
27        )
28        Release.objects.create(
29            project=project2,
30            version='1',
31        )
32
33        url = reverse('sentry-api-0-project-releases', kwargs={
34            'organization_slug': project1.organization.slug,
35            'project_slug': project1.slug,
36        })
37        response = self.client.get(url, format='json')
38
39
40    def test_query_filter(self):
41        self.login_as(user=self.user)
42
43        team = self.create_team()
44        project = self.create_project(team=team, name='foo')
45
46        release = Release.objects.create(
47            project=project,
48            version='foobar',
49            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
50        )
51
52        url = reverse('sentry-api-0-project-releases', kwargs={
53            'organization_slug': project.organization.slug,
54            'project_slug': project.slug,
55        })
56        response = self.client.get(url + '?query=foo', format='json')
57
58
59        response = self.client.get(url + '?query=bar', format='json')
60
61
62
63class ProjectReleaseCreateTest(APITestCase):
64    def test_minimal(self):
65        self.login_as(user=self.user)
66
67        team = self.create_team()
68        project = self.create_project(team=team, name='foo')
69
70        url = reverse('sentry-api-0-project-releases', kwargs={
71            'organization_slug': project.organization.slug,
72            'project_slug': project.slug,
73        })
74        response = self.client.post(url, data={
75            'version': '1.2.1',
76        })
77
78
79        release = Release.objects.get(
80            project=project,
81            version=response.data['version'],
82        )
83
84    def test_duplicate(self):
85        self.login_as(user=self.user)
86
87        team = self.create_team()
88        project = self.create_project(team=team, name='foo')
89
90        Release.objects.create(version='1.2.1', project=project)
91
92        url = reverse('sentry-api-0-project-releases', kwargs={
93            'organization_slug': project.organization.slug,
94            'project_slug': project.slug,
95        })
96
97        response = self.client.post(url, data={
98            'version': '1.2.1',
99        })
100
101
102    def test_features(self):
103        self.login_as(user=self.user)
104
105        team = self.create_team()
106        project = self.create_project(team=team, name='foo')
107
108        url = reverse('sentry-api-0-project-releases', kwargs={
109            'organization_slug': project.organization.slug,
110            'project_slug': project.slug,
111        })
112        response = self.client.post(url, data={
113            'version': '1.2.1',
114            'owner': self.user.email,
115        })
116
117
118        release = Release.objects.get(
119            project=project,
120            version=response.data['version'],
121        )
122","[['response.status_code', '==', '200'], ['len(response.data)', '==', '2'], [""response.data[0]['version']"", '==', 'release2.version'], [""response.data[1]['version']"", '==', 'release1.version'], ['response.status_code', '==', '200'], ['len(response.data)', '==', '1'], [""response.data[0]['version']"", '==', 'release.version'], ['response.status_code', '==', '200'], ['len(response.data)', '==', '0'], ['response.status_code', '==', '201'], [""response.data['version']"", '==', 'True'], ['release.owner', '==', 'False'], ['response.status_code', '==', '400'], ['response.status_code', '==', '201'], [""response.data['version']"", '==', 'True'], ['release.owner', '==', 'self.user']]",16,16,1.0,0.0036934441366574,"['team', 'project1', 'project2', 'release1', 'release2', 'url', 'response', 'project', 'release']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['team', 'project1', 'project2', 'release1', 'release2', 'url', 'response', 'project', 'release']
*Code:

1from __future__ import absolute_import
2
3from datetime import datetime
4from django.core.urlresolvers import reverse
5
6from sentry.models import Release
7from sentry.testutils import APITestCase
8
9
10class ProjectReleaseListTest(APITestCase):
11    def test_simple(self):
12        self.login_as(user=self.user)
13
14        team = self.create_team()
15        project1 = self.create_project(team=team, name='foo')
16        project2 = self.create_project(team=team, name='bar')
17
18        release1 = Release.objects.create(
19            project=project1,
20            version='1',
21            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
22        )
23        release2 = Release.objects.create(
24            project=project1,
25            version='2',
26            date_added=datetime(2013, 8, 14, 3, 8, 24, 880386),
27        )
28        Release.objects.create(
29            project=project2,
30            version='1',
31        )
32
33        url = reverse('sentry-api-0-project-releases', kwargs={
34            'organization_slug': project1.organization.slug,
35            'project_slug': project1.slug,
36        })
37        response = self.client.get(url, format='json')
38
39
40    def test_query_filter(self):
41        self.login_as(user=self.user)
42
43        team = self.create_team()
44        project = self.create_project(team=team, name='foo')
45
46        release = Release.objects.create(
47            project=project,
48            version='foobar',
49            date_added=datetime(2013, 8, 13, 3, 8, 24, 880386),
50        )
51
52        url = reverse('sentry-api-0-project-releases', kwargs={
53            'organization_slug': project.organization.slug,
54            'project_slug': project.slug,
55        })
56        response = self.client.get(url + '?query=foo', format='json')
57
58
59        response = self.client.get(url + '?query=bar', format='json')
60
61
62
63class ProjectReleaseCreateTest(APITestCase):
64    def test_minimal(self):
65        self.login_as(user=self.user)
66
67        team = self.create_team()
68        project = self.create_project(team=team, name='foo')
69
70        url = reverse('sentry-api-0-project-releases', kwargs={
71            'organization_slug': project.organization.slug,
72            'project_slug': project.slug,
73        })
74        response = self.client.post(url, data={
75            'version': '1.2.1',
76        })
77
78
79        release = Release.objects.get(
80            project=project,
81            version=response.data['version'],
82        )
83
84    def test_duplicate(self):
85        self.login_as(user=self.user)
86
87        team = self.create_team()
88        project = self.create_project(team=team, name='foo')
89
90        Release.objects.create(version='1.2.1', project=project)
91
92        url = reverse('sentry-api-0-project-releases', kwargs={
93            'organization_slug': project.organization.slug,
94            'project_slug': project.slug,
95        })
96
97        response = self.client.post(url, data={
98            'version': '1.2.1',
99        })
100
101
102    def test_features(self):
103        self.login_as(user=self.user)
104
105        team = self.create_team()
106        project = self.create_project(team=team, name='foo')
107
108        url = reverse('sentry-api-0-project-releases', kwargs={
109            'organization_slug': project.organization.slug,
110            'project_slug': project.slug,
111        })
112        response = self.client.post(url, data={
113            'version': '1.2.1',
114            'owner': self.user.email,
115        })
116
117
118        release = Release.objects.get(
119            project=project,
120            version=response.data['version'],
121        )
122",5242,"[[14, 'team', '!=', None, 'ensure team is properly created before use'],
[15, 'project1', '!=', None, 'ensure project1 is properly created before use'],
[16, 'project2', '!=', None, 'ensure project2 is properly created before use'],
[22, 'release1', '!=', None, 'ensure release1 is properly created before use'],
[27, 'release2', '!=', None, 'ensure release2 is properly created before use'],
[37, 'response', '!=', None, 'ensure response is received'],
[43, 'team', '!=', None, 'ensure team is properly created before use'],
[44, 'project', '!=', None, 'ensure project is properly created before use'],
[50, 'release', '!=', None, 'ensure release is properly created before use'],
[56, 'response', '!=', None, 'ensure response is received'],
[67, 'team', '!=', None, 'ensure team is properly created before use'],
[68, 'project', '!=', None, 'ensure project is properly created before use'],
[74, 'response', '!=', None, 'ensure response is received'],
[87, 'team', '!=', None, 'ensure team is properly created before use'],
[88, 'project', '!=', None, 'ensure project is properly created before use'],
[97, 'response', '!=', None, 'ensure response is received'],
[105, 'team', '!=', None, 'ensure team is properly created before use'],
[106, 'project', '!=', None, 'ensure project is properly created before use']]
"
matthiascy/panda3d,"
from cPickle import dumps, loads

from direct.directnotify import DirectNotifyGlobal
from direct.distributed.PyDatagram import PyDatagram
from direct.showbase.Messenger import Messenger


# Messages do not need to be in the MESSAGE_TYPES list.
# This is just an optimization.  If the message is found
# in this list, it is reduced to an integer index and
# the message string is not sent.  Otherwise, the message
# string is sent in the datagram.
MESSAGE_TYPES=(
    ""avatarOnline"",
    ""avatarOffline"",
    ""create"",
    ""needUberdogCreates"",
    ""transferDo"",
)

# This is the reverse look up for the recipient of the
# datagram:
MESSAGE_STRINGS={}
for i in zip(MESSAGE_TYPES, range(1, len(MESSAGE_TYPES)+1)):
    MESSAGE_STRINGS[i[0]]=i[1]


class NetMessenger(Messenger):
    """"""
    This works very much like the Messenger class except that messages
    are sent over the network and (possibly) handled (accepted) on a
    remote machine (server).
    """"""
    notify = DirectNotifyGlobal.directNotify.newCategory('NetMessenger')

    def __init__(self, air, channels):
        """"""
        air is the AI Repository.
        channels is a list of channel IDs (uint32 values)
        """"""
        assert self.notify.debugCall()
        Messenger.__init__(self)
        self.air=air
        self.channels=channels
        for i in self.channels:
            self.air.registerForChannel(i)

    def clear(self):
        assert self.notify.debugCall()
        for i in self.channels:
            self.air.unRegisterChannel(i)
        del self.air
        del self.channels
        Messenger.clear(self)

    def send(self, message, sentArgs=[]):
        """"""
        Send message to All AI and Uber Dog servers.
        """"""
        assert self.notify.debugCall()
        datagram = PyDatagram()
        # To:
        datagram.addUint8(1)
        datagram.addChannel(self.channels[0])
        # From:
        datagram.addChannel(self.air.ourChannel)
        #if 1: # We send this just because the air expects it:
        #    # Add an 'A' for AI
        #    datagram.addUint8(ord('A'))

        messageType=MESSAGE_STRINGS.get(message, 0)
        datagram.addUint16(messageType)
        if messageType:
            datagram.addString(str(dumps(sentArgs)))
        else:
            datagram.addString(str(dumps((message, sentArgs))))
        self.air.send(datagram)

    def handle(self, pickleData):
        """"""
        Send pickleData from the net on the local netMessenger.
        The internal data in pickleData should have a tuple of
        (messageString, sendArgsList).
        """"""
        assert self.notify.debugCall()
        messageType=self.air.getMsgType()
        if messageType:
            message=MESSAGE_TYPES[messageType-1]
            sentArgs=loads(pickleData)
        else:
            (message, sentArgs) = loads(pickleData)
        Messenger.send(self, message, sentArgs=sentArgs)


","
1
2from cPickle import dumps, loads
3
4from direct.directnotify import DirectNotifyGlobal
5from direct.distributed.PyDatagram import PyDatagram
6from direct.showbase.Messenger import Messenger
7
8
9# Messages do not need to be in the MESSAGE_TYPES list.
10# This is just an optimization.  If the message is found
11# in this list, it is reduced to an integer index and
12# the message string is not sent.  Otherwise, the message
13# string is sent in the datagram.
14MESSAGE_TYPES=(
15    ""avatarOnline"",
16    ""avatarOffline"",
17    ""create"",
18    ""needUberdogCreates"",
19    ""transferDo"",
20)
21
22# This is the reverse look up for the recipient of the
23# datagram:
24MESSAGE_STRINGS={}
25for i in zip(MESSAGE_TYPES, range(1, len(MESSAGE_TYPES)+1)):
26    MESSAGE_STRINGS[i[0]]=i[1]
27
28
29class NetMessenger(Messenger):
30    """"""
31    This works very much like the Messenger class except that messages
32    are sent over the network and (possibly) handled (accepted) on a
33    remote machine (server).
34    """"""
35    notify = DirectNotifyGlobal.directNotify.newCategory('NetMessenger')
36
37    def __init__(self, air, channels):
38        """"""
39        air is the AI Repository.
40        channels is a list of channel IDs (uint32 values)
41        """"""
42        Messenger.__init__(self)
43        self.air=air
44        self.channels=channels
45        for i in self.channels:
46            self.air.registerForChannel(i)
47
48    def clear(self):
49        for i in self.channels:
50            self.air.unRegisterChannel(i)
51        del self.air
52        del self.channels
53        Messenger.clear(self)
54
55    def send(self, message, sentArgs=[]):
56        """"""
57        Send message to All AI and Uber Dog servers.
58        """"""
59        datagram = PyDatagram()
60        # To:
61        datagram.addUint8(1)
62        datagram.addChannel(self.channels[0])
63        # From:
64        datagram.addChannel(self.air.ourChannel)
65        #if 1: # We send this just because the air expects it:
66        #    # Add an 'A' for AI
67        #    datagram.addUint8(ord('A'))
68
69        messageType=MESSAGE_STRINGS.get(message, 0)
70        datagram.addUint16(messageType)
71        if messageType:
72            datagram.addString(str(dumps(sentArgs)))
73        else:
74            datagram.addString(str(dumps((message, sentArgs))))
75        self.air.send(datagram)
76
77    def handle(self, pickleData):
78        """"""
79        Send pickleData from the net on the local netMessenger.
80        The internal data in pickleData should have a tuple of
81        (messageString, sendArgsList).
82        """"""
83        messageType=self.air.getMsgType()
84        if messageType:
85            message=MESSAGE_TYPES[messageType-1]
86            sentArgs=loads(pickleData)
87        else:
88            (message, sentArgs) = loads(pickleData)
89        Messenger.send(self, message, sentArgs=sentArgs)
90
91
92","[['self.notify.debugCall()', '==', 'True'], ['self.notify.debugCall()', '==', 'True'], ['self.notify.debugCall()', '==', 'True'], ['self.notify.debugCall()', '==', 'True']]",4,4,1.0,0.001375988992088,"['notify', 'air', 'channels', 'message', 'sentArgs', 'datagram', 'pickleData', '(message', 'sentArgs)']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['notify', 'air', 'channels', 'message', 'sentArgs', 'datagram', 'pickleData', '(message', 'sentArgs)']
*Code:

1
2from cPickle import dumps, loads
3
4from direct.directnotify import DirectNotifyGlobal
5from direct.distributed.PyDatagram import PyDatagram
6from direct.showbase.Messenger import Messenger
7
8
9# Messages do not need to be in the MESSAGE_TYPES list.
10# This is just an optimization.  If the message is found
11# in this list, it is reduced to an integer index and
12# the message string is not sent.  Otherwise, the message
13# string is sent in the datagram.
14MESSAGE_TYPES=(
15    ""avatarOnline"",
16    ""avatarOffline"",
17    ""create"",
18    ""needUberdogCreates"",
19    ""transferDo"",
20)
21
22# This is the reverse look up for the recipient of the
23# datagram:
24MESSAGE_STRINGS={}
25for i in zip(MESSAGE_TYPES, range(1, len(MESSAGE_TYPES)+1)):
26    MESSAGE_STRINGS[i[0]]=i[1]
27
28
29class NetMessenger(Messenger):
30    """"""
31    This works very much like the Messenger class except that messages
32    are sent over the network and (possibly) handled (accepted) on a
33    remote machine (server).
34    """"""
35    notify = DirectNotifyGlobal.directNotify.newCategory('NetMessenger')
36
37    def __init__(self, air, channels):
38        """"""
39        air is the AI Repository.
40        channels is a list of channel IDs (uint32 values)
41        """"""
42        Messenger.__init__(self)
43        self.air=air
44        self.channels=channels
45        for i in self.channels:
46            self.air.registerForChannel(i)
47
48    def clear(self):
49        for i in self.channels:
50            self.air.unRegisterChannel(i)
51        del self.air
52        del self.channels
53        Messenger.clear(self)
54
55    def send(self, message, sentArgs=[]):
56        """"""
57        Send message to All AI and Uber Dog servers.
58        """"""
59        datagram = PyDatagram()
60        # To:
61        datagram.addUint8(1)
62        datagram.addChannel(self.channels[0])
63        # From:
64        datagram.addChannel(self.air.ourChannel)
65        #if 1: # We send this just because the air expects it:
66        #    # Add an 'A' for AI
67        #    datagram.addUint8(ord('A'))
68
69        messageType=MESSAGE_STRINGS.get(message, 0)
70        datagram.addUint16(messageType)
71        if messageType:
72            datagram.addString(str(dumps(sentArgs)))
73        else:
74            datagram.addString(str(dumps((message, sentArgs))))
75        self.air.send(datagram)
76
77    def handle(self, pickleData):
78        """"""
79        Send pickleData from the net on the local netMessenger.
80        The internal data in pickleData should have a tuple of
81        (messageString, sendArgsList).
82        """"""
83        messageType=self.air.getMsgType()
84        if messageType:
85            message=MESSAGE_TYPES[messageType-1]
86            sentArgs=loads(pickleData)
87        else:
88            (message, sentArgs) = loads(pickleData)
89        Messenger.send(self, message, sentArgs=sentArgs)
90
91
92",4410,"[[37, 'air', '!=', None, ""air shouldn't be None""],
 [37, 'channels', '!=', None, ""channels shouldn't be None""],
 [37, 'channels', '>=', 1, ""channels should have at least 1 element""],
 [55, 'message', '!=', None, ""message should not be None""],
 [55, 'sentArgs', '!=', None, ""sentArgs should not be None""],
 [77, 'pickleData', '!=', None, ""pickleData should not be None""]]"
stonebig/bokeh,"#-----------------------------------------------------------------------------
# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.
# All rights reserved.
#
# The full license is in the file LICENSE.txt, distributed with this software.
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Boilerplate
#-----------------------------------------------------------------------------
from __future__ import absolute_import, division, print_function, unicode_literals

import pytest ; pytest

#-----------------------------------------------------------------------------
# Imports
#-----------------------------------------------------------------------------

# Standard library imports
from mock import patch

# External imports
from six import string_types

# Bokeh imports

# Module under test
import bokeh.client.session as bcs

#-----------------------------------------------------------------------------
# Setup
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# General API
#-----------------------------------------------------------------------------

def test_DEFAULT_SESSION_ID():
    assert bcs.DEFAULT_SESSION_ID == ""default""

def test_DEFAULT_SERVER_WEBSOCKET_URL():
    assert bcs.DEFAULT_SERVER_WEBSOCKET_URL == ""ws://localhost:5006/ws""

class Test_ClientSession(object):

    def test_creation_defaults(self):
        s = bcs.ClientSession()
        assert s.connected == False
        assert s.document is None
        assert s._connection._arguments is None
        assert isinstance(s.id, string_types)
        assert len(s.id) == 44

    def test_creation_with_session_id(self):
        s = bcs.ClientSession(""sid"")
        assert s.connected == False
        assert s.document is None
        assert s._connection._arguments is None
        assert s.id == ""sid""

    def test_creation_with_ws_url(self):
        s = bcs.ClientSession(websocket_url=""wsurl"")
        assert s.connected == False
        assert s.document is None
        assert s._connection._arguments is None
        assert s._connection.url == ""wsurl""
        assert isinstance(s.id, string_types)
        assert len(s.id) == 44

    def test_creation_with_ioloop(self):
        s = bcs.ClientSession(io_loop=""io_loop"")
        assert s.connected == False
        assert s.document is None
        assert s._connection._arguments is None
        assert s._connection.io_loop == ""io_loop""
        assert isinstance(s.id, string_types)
        assert len(s.id) == 44

    def test_creation_with_arguments(self):
        s = bcs.ClientSession(arguments=""args"")
        assert s.connected == False
        assert s.document is None
        assert s._connection._arguments == ""args""
        assert len(s.id) == 44

    @patch(""bokeh.client.connection.ClientConnection.connect"")
    def test_connect(self, mock_connect):
        s = bcs.ClientSession()
        s.connect()
        assert mock_connect.call_count == 1
        assert mock_connect.call_args[0] == ()
        assert mock_connect.call_args[1] == {}

    @patch(""bokeh.client.connection.ClientConnection.close"")
    def test_close(self, mock_close):
        s = bcs.ClientSession()
        s.close()
        assert mock_close.call_count == 1
        assert mock_close.call_args[0] == (""closed"",)
        assert mock_close.call_args[1] == {}

    @patch(""bokeh.client.connection.ClientConnection.close"")
    def test_context_manager(self, mock_close):
        with bcs.ClientSession() as session:
            assert isinstance(session, bcs.ClientSession)
        assert mock_close.call_count == 1
        assert mock_close.call_args[0] == (""closed"",)
        assert mock_close.call_args[1] == {}

    @patch(""bokeh.client.connection.ClientConnection.close"")
    def test_close_with_why(self, mock_close):
        s = bcs.ClientSession()
        s.close(""foo"")
        assert mock_close.call_count == 1
        assert mock_close.call_args[0] == (""foo"",)
        assert mock_close.call_args[1] == {}

    @patch(""bokeh.client.connection.ClientConnection.force_roundtrip"")
    def test_force_roundtrip(self, mock_force_roundtrip):
        s = bcs.ClientSession()
        s.force_roundtrip()
        assert mock_force_roundtrip.call_count == 1
        assert mock_force_roundtrip.call_args[0] == ()
        assert mock_force_roundtrip.call_args[1] == {}

    @patch(""bokeh.client.connection.ClientConnection.request_server_info"")
    def test_request_server_info(self, mock_request_server_info):
        s = bcs.ClientSession()
        s.request_server_info()
        assert mock_request_server_info.call_count == 1
        assert mock_request_server_info.call_args[0] == ()
        assert mock_request_server_info.call_args[1] == {}

#-----------------------------------------------------------------------------
# Dev API
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Private API
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Code
#-----------------------------------------------------------------------------
","
1#-----------------------------------------------------------------------------
2# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.
3# All rights reserved.
4#
5# The full license is in the file LICENSE.txt, distributed with this software.
6#-----------------------------------------------------------------------------
7
8#-----------------------------------------------------------------------------
9# Boilerplate
10#-----------------------------------------------------------------------------
11from __future__ import absolute_import, division, print_function, unicode_literals
12
13import pytest ; pytest
14
15#-----------------------------------------------------------------------------
16# Imports
17#-----------------------------------------------------------------------------
18
19# Standard library imports
20from mock import patch
21
22# External imports
23from six import string_types
24
25# Bokeh imports
26
27# Module under test
28import bokeh.client.session as bcs
29
30#-----------------------------------------------------------------------------
31# Setup
32#-----------------------------------------------------------------------------
33
34#-----------------------------------------------------------------------------
35# General API
36#-----------------------------------------------------------------------------
37
38def test_DEFAULT_SESSION_ID():
39
40def test_DEFAULT_SERVER_WEBSOCKET_URL():
41
42class Test_ClientSession(object):
43
44    def test_creation_defaults(self):
45        s = bcs.ClientSession()
46
47    def test_creation_with_session_id(self):
48        s = bcs.ClientSession(""sid"")
49
50    def test_creation_with_ws_url(self):
51        s = bcs.ClientSession(websocket_url=""wsurl"")
52
53    def test_creation_with_ioloop(self):
54        s = bcs.ClientSession(io_loop=""io_loop"")
55
56    def test_creation_with_arguments(self):
57        s = bcs.ClientSession(arguments=""args"")
58
59    @patch(""bokeh.client.connection.ClientConnection.connect"")
60    def test_connect(self, mock_connect):
61        s = bcs.ClientSession()
62        s.connect()
63
64    @patch(""bokeh.client.connection.ClientConnection.close"")
65    def test_close(self, mock_close):
66        s = bcs.ClientSession()
67        s.close()
68
69    @patch(""bokeh.client.connection.ClientConnection.close"")
70    def test_context_manager(self, mock_close):
71        with bcs.ClientSession() as session:
72
73    @patch(""bokeh.client.connection.ClientConnection.close"")
74    def test_close_with_why(self, mock_close):
75        s = bcs.ClientSession()
76        s.close(""foo"")
77
78    @patch(""bokeh.client.connection.ClientConnection.force_roundtrip"")
79    def test_force_roundtrip(self, mock_force_roundtrip):
80        s = bcs.ClientSession()
81        s.force_roundtrip()
82
83    @patch(""bokeh.client.connection.ClientConnection.request_server_info"")
84    def test_request_server_info(self, mock_request_server_info):
85        s = bcs.ClientSession()
86        s.request_server_info()
87
88#-----------------------------------------------------------------------------
89# Dev API
90#-----------------------------------------------------------------------------
91
92#-----------------------------------------------------------------------------
93# Private API
94#-----------------------------------------------------------------------------
95
96#-----------------------------------------------------------------------------
97# Code
98#-----------------------------------------------------------------------------
99","[['bcs.DEFAULT_SESSION_ID', '==', '""default""'], ['bcs.DEFAULT_SERVER_WEBSOCKET_URL', '==', '""ws://localhost:5006/ws""'], ['s.connected', '==', 'False'], ['s.document', '==', 'None'], ['s._connection._arguments', '==', 'None'], ['len(s.id)', '==', '44'], ['s.connected', '==', 'False'], ['s.document', '==', 'None'], ['s._connection._arguments', '==', 'None'], ['s.id', '==', '""sid""'], ['s.connected', '==', 'False'], ['s.document', '==', 'None'], ['s._connection._arguments', '==', 'None'], ['s._connection.url', '==', '""wsurl""'], ['len(s.id)', '==', '44'], ['s.connected', '==', 'False'], ['s.document', '==', 'None'], ['s._connection._arguments', '==', 'None'], ['s._connection.io_loop', '==', '""io_loop""'], ['len(s.id)', '==', '44'], ['s.connected', '==', 'False'], ['s.document', '==', 'None'], ['s._connection._arguments', '==', '""args""'], ['len(s.id)', '==', '44'], ['mock_connect.call_count', '==', '1'], ['mock_connect.call_args[0]', '==', '()'], ['mock_connect.call_args[1]', '==', '{}'], ['mock_close.call_count', '==', '1'], ['mock_close.call_args[0]', '==', '(""closed""'], ['mock_close.call_args[1]', '==', '{}'], ['mock_close.call_count', '==', '1'], ['mock_close.call_args[0]', '==', '(""closed""'], ['mock_close.call_args[1]', '==', '{}'], ['mock_close.call_count', '==', '1'], ['mock_close.call_args[0]', '==', '(""foo""'], ['mock_close.call_args[1]', '==', '{}'], ['mock_force_roundtrip.call_count', '==', '1'], ['mock_force_roundtrip.call_args[0]', '==', '()'], ['mock_force_roundtrip.call_args[1]', '==', '{}'], ['mock_request_server_info.call_count', '==', '1'], ['mock_request_server_info.call_args[0]', '==', '()'], ['mock_request_server_info.call_args[1]', '==', '{}']]",46,42,0.9130434782608696,0.0077576653121536,"['s', 'mock_connect', 'mock_close', 'mock_force_roundtrip', 'mock_request_server_info']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['s', 'mock_connect', 'mock_close', 'mock_force_roundtrip', 'mock_request_server_info']
*Code:

1#-----------------------------------------------------------------------------
2# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.
3# All rights reserved.
4#
5# The full license is in the file LICENSE.txt, distributed with this software.
6#-----------------------------------------------------------------------------
7
8#-----------------------------------------------------------------------------
9# Boilerplate
10#-----------------------------------------------------------------------------
11from __future__ import absolute_import, division, print_function, unicode_literals
12
13import pytest ; pytest
14
15#-----------------------------------------------------------------------------
16# Imports
17#-----------------------------------------------------------------------------
18
19# Standard library imports
20from mock import patch
21
22# External imports
23from six import string_types
24
25# Bokeh imports
26
27# Module under test
28import bokeh.client.session as bcs
29
30#-----------------------------------------------------------------------------
31# Setup
32#-----------------------------------------------------------------------------
33
34#-----------------------------------------------------------------------------
35# General API
36#-----------------------------------------------------------------------------
37
38def test_DEFAULT_SESSION_ID():
39
40def test_DEFAULT_SERVER_WEBSOCKET_URL():
41
42class Test_ClientSession(object):
43
44    def test_creation_defaults(self):
45        s = bcs.ClientSession()
46
47    def test_creation_with_session_id(self):
48        s = bcs.ClientSession(""sid"")
49
50    def test_creation_with_ws_url(self):
51        s = bcs.ClientSession(websocket_url=""wsurl"")
52
53    def test_creation_with_ioloop(self):
54        s = bcs.ClientSession(io_loop=""io_loop"")
55
56    def test_creation_with_arguments(self):
57        s = bcs.ClientSession(arguments=""args"")
58
59    @patch(""bokeh.client.connection.ClientConnection.connect"")
60    def test_connect(self, mock_connect):
61        s = bcs.ClientSession()
62        s.connect()
63
64    @patch(""bokeh.client.connection.ClientConnection.close"")
65    def test_close(self, mock_close):
66        s = bcs.ClientSession()
67        s.close()
68
69    @patch(""bokeh.client.connection.ClientConnection.close"")
70    def test_context_manager(self, mock_close):
71        with bcs.ClientSession() as session:
72
73    @patch(""bokeh.client.connection.ClientConnection.close"")
74    def test_close_with_why(self, mock_close):
75        s = bcs.ClientSession()
76        s.close(""foo"")
77
78    @patch(""bokeh.client.connection.ClientConnection.force_roundtrip"")
79    def test_force_roundtrip(self, mock_force_roundtrip):
80        s = bcs.ClientSession()
81        s.force_roundtrip()
82
83    @patch(""bokeh.client.connection.ClientConnection.request_server_info"")
84    def test_request_server_info(self, mock_request_server_info):
85        s = bcs.ClientSession()
86        s.request_server_info()
87
88#-----------------------------------------------------------------------------
89# Dev API
90#-----------------------------------------------------------------------------
91
92#-----------------------------------------------------------------------------
93# Private API
94#-----------------------------------------------------------------------------
95
96#-----------------------------------------------------------------------------
97# Code
98#-----------------------------------------------------------------------------
99",5023,"[[45, 's', '!=', None, ""ClientSession instance must be initialized""],
 [48, 's', '!=', None, ""ClientSession instance must be initialized""],
 [51, 's', '!=', None, ""ClientSession instance must be initialized""],
 [54, 's', '!=', None, ""ClientSession instance must be initialized""],
 [57, 's', '!=', None, ""ClientSession instance must be initialized""],
 [61, 's', '!=', None, ""ClientSession instance must be initialized""],
 [66, 's', '!=', None, ""ClientSession instance must be initialized""],
 [75, 's', '!=', None, ""ClientSession instance must be initialized""],
 [80, 's', '!=', None, ""ClientSession instance must be initialized""],
 [85, 's', '!=', None, ""ClientSession instance must be initialized""]]"
myfavouritekk/TPN,"#!/usr/bin/env python

import argparse
import os
import os.path as osp
import sys
this_dir = osp.dirname(__file__)
sys.path.insert(0, osp.join(this_dir, '../../external'))
sys.path.insert(0, osp.join(this_dir, '../../external/py-faster-rcnn/lib'))
from vdetlib.utils.visual import unique_colors, add_bbox
from vdetlib.utils.common import imread, imwrite
from vdetlib.utils.protocol import proto_load, frame_path_at, boxes_at_frame, annot_boxes_at_frame
from fast_rcnn.bbox_transform import bbox_transform, bbox_transform_inv
from utils.cython_bbox import bbox_overlaps
import cv2
import random
import numpy as np

def _sample_boxes(box_proto, frame_id, num, annot_proto=None):
    boxes = boxes_at_frame(box_proto, frame_id)
    boxes = [box['bbox'] for box in boxes]
    if annot_proto is None:
        boxes = random.sample(boxes, num)
    else:
        gt_boxes = annot_boxes_at_frame(annot_proto, frame_id)
        overlaps = bbox_overlaps(np.asarray(boxes, dtype=np.float),
                                 np.asarray(gt_boxes, dtype=np.float))
        max_overlaps = np.max(overlaps, axis=1)
        idx = np.argsort(max_overlaps)[::-1][:num]
        boxes = [boxes[i] for i in idx]
    return boxes

def _propagate_boxes(boxes, annot_proto, frame_id):
    pred_boxes = []
    annots = []
    for annot in annot_proto['annotations']:
        for idx, box in enumerate(annot['track']):
            if box['frame'] == frame_id and len(annot['track']) > idx + 1:
                gt1 = box['bbox']
                gt2 = annot['track'][idx+1]['bbox']
                delta = bbox_transform(np.asarray([gt1]), np.asarray([gt2]))
                annots.append((gt1, delta))
    gt1 = [annot[0] for annot in annots]
    overlaps = bbox_overlaps(np.require(boxes, dtype=np.float),
                             np.require(gt1, dtype=np.float))
    assert len(overlaps) == len(boxes)
    for gt_overlaps, box in zip(overlaps, boxes):
        max_overlap = np.max(gt_overlaps)
        max_gt = np.argmax(gt_overlaps)
        if max_overlap < 0.5:
            pred_boxes.append(box)
        else:
            delta = annots[max_gt][1]
            pred_boxes.append(bbox_transform_inv(np.asarray([box]), delta)[0].tolist())
    return pred_boxes

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('vid_file')
    parser.add_argument('box_file')
    parser.add_argument('gt_file')
    parser.add_argument('--save_dir', default=None)
    parser.add_argument('--num_tracks', type=int, default=30)
    parser.add_argument('--length', type=int, default=20)
    parser.set_defaults(sample_tracks=False)
    args = parser.parse_args()

    vid_proto = proto_load(args.vid_file)
    box_proto = proto_load(args.box_file)
    annot_proto = proto_load(args.gt_file)

    paried_frames = zip(vid_proto['frames'][:-1], vid_proto['frames'][1:])
    # colors = unique_colors(len(track_proto['tracks']))

    boxes = []
    colors = None
    for frame1, frame2 in paried_frames:
        frame_id = frame1['frame']
        img = imread(frame_path_at(vid_proto, frame1['frame']))
        if frame_id % args.length == 1 or len(boxes) == 0:
            boxes = _sample_boxes(box_proto, frame_id, args.num_tracks, annot_proto)
            colors = unique_colors(len(boxes))
        else:
            boxes = _propagate_boxes(boxes, annot_proto, frame_id-1)
        tracked = add_bbox(img, boxes, None, colors, 2)
        if args.save_dir:
            if not os.path.isdir(args.save_dir):
                try:
                    os.makedirs(args.save_dir)
                except:
                    pass
            imwrite(os.path.join(args.save_dir, ""{:04d}.jpg"".format(frame['frame'])),
                    tracked)
        else:
            cv2.imshow('tracks', tracked)
            if cv2.waitKey(0) == ord('q'):
                cv2.destroyAllWindows()
                sys.exit(0)
    if not args.save_dir:
        cv2.destroyAllWindows()
","
1#!/usr/bin/env python
2
3import argparse
4import os
5import os.path as osp
6import sys
7this_dir = osp.dirname(__file__)
8sys.path.insert(0, osp.join(this_dir, '../../external'))
9sys.path.insert(0, osp.join(this_dir, '../../external/py-faster-rcnn/lib'))
10from vdetlib.utils.visual import unique_colors, add_bbox
11from vdetlib.utils.common import imread, imwrite
12from vdetlib.utils.protocol import proto_load, frame_path_at, boxes_at_frame, annot_boxes_at_frame
13from fast_rcnn.bbox_transform import bbox_transform, bbox_transform_inv
14from utils.cython_bbox import bbox_overlaps
15import cv2
16import random
17import numpy as np
18
19def _sample_boxes(box_proto, frame_id, num, annot_proto=None):
20    boxes = boxes_at_frame(box_proto, frame_id)
21    boxes = [box['bbox'] for box in boxes]
22    if annot_proto is None:
23        boxes = random.sample(boxes, num)
24    else:
25        gt_boxes = annot_boxes_at_frame(annot_proto, frame_id)
26        overlaps = bbox_overlaps(np.asarray(boxes, dtype=np.float),
27                                 np.asarray(gt_boxes, dtype=np.float))
28        max_overlaps = np.max(overlaps, axis=1)
29        idx = np.argsort(max_overlaps)[::-1][:num]
30        boxes = [boxes[i] for i in idx]
31    return boxes
32
33def _propagate_boxes(boxes, annot_proto, frame_id):
34    pred_boxes = []
35    annots = []
36    for annot in annot_proto['annotations']:
37        for idx, box in enumerate(annot['track']):
38            if box['frame'] == frame_id and len(annot['track']) > idx + 1:
39                gt1 = box['bbox']
40                gt2 = annot['track'][idx+1]['bbox']
41                delta = bbox_transform(np.asarray([gt1]), np.asarray([gt2]))
42                annots.append((gt1, delta))
43    gt1 = [annot[0] for annot in annots]
44    overlaps = bbox_overlaps(np.require(boxes, dtype=np.float),
45                             np.require(gt1, dtype=np.float))
46    for gt_overlaps, box in zip(overlaps, boxes):
47        max_overlap = np.max(gt_overlaps)
48        max_gt = np.argmax(gt_overlaps)
49        if max_overlap < 0.5:
50            pred_boxes.append(box)
51        else:
52            delta = annots[max_gt][1]
53            pred_boxes.append(bbox_transform_inv(np.asarray([box]), delta)[0].tolist())
54    return pred_boxes
55
56if __name__ == '__main__':
57    parser = argparse.ArgumentParser()
58    parser.add_argument('vid_file')
59    parser.add_argument('box_file')
60    parser.add_argument('gt_file')
61    parser.add_argument('--save_dir', default=None)
62    parser.add_argument('--num_tracks', type=int, default=30)
63    parser.add_argument('--length', type=int, default=20)
64    parser.set_defaults(sample_tracks=False)
65    args = parser.parse_args()
66
67    vid_proto = proto_load(args.vid_file)
68    box_proto = proto_load(args.box_file)
69    annot_proto = proto_load(args.gt_file)
70
71    paried_frames = zip(vid_proto['frames'][:-1], vid_proto['frames'][1:])
72    # colors = unique_colors(len(track_proto['tracks']))
73
74    boxes = []
75    colors = None
76    for frame1, frame2 in paried_frames:
77        frame_id = frame1['frame']
78        img = imread(frame_path_at(vid_proto, frame1['frame']))
79        if frame_id % args.length == 1 or len(boxes) == 0:
80            boxes = _sample_boxes(box_proto, frame_id, args.num_tracks, annot_proto)
81            colors = unique_colors(len(boxes))
82        else:
83            boxes = _propagate_boxes(boxes, annot_proto, frame_id-1)
84        tracked = add_bbox(img, boxes, None, colors, 2)
85        if args.save_dir:
86            if not os.path.isdir(args.save_dir):
87                try:
88                    os.makedirs(args.save_dir)
89                except:
90                    pass
91            imwrite(os.path.join(args.save_dir, ""{:04d}.jpg"".format(frame['frame'])),
92                    tracked)
93        else:
94            cv2.imshow('tracks', tracked)
95            if cv2.waitKey(0) == ord('q'):
96                cv2.destroyAllWindows()
97                sys.exit(0)
98    if not args.save_dir:
99        cv2.destroyAllWindows()
100","[['len(overlaps)', '==', 'len(boxes)']]",1,1,1.0,0.0002527167045741,"['this_dir', 'box_proto', 'frame_id', 'num', 'annot_proto', 'boxes', 'gt_boxes', 'overlaps', 'max_overlaps', 'idx', 'pred_boxes', 'annots', 'gt1', 'gt2', 'delta', 'max_overlap', 'max_gt', 'parser', 'args', 'vid_proto', 'paried_frames', '# colors', 'colors', 'img', 'tracked']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['this_dir', 'box_proto', 'frame_id', 'num', 'annot_proto', 'boxes', 'gt_boxes', 'overlaps', 'max_overlaps', 'idx', 'pred_boxes', 'annots', 'gt1', 'gt2', 'delta', 'max_overlap', 'max_gt', 'parser', 'args', 'vid_proto', 'paried_frames', '# colors', 'colors', 'img', 'tracked']
*Code:

1#!/usr/bin/env python
2
3import argparse
4import os
5import os.path as osp
6import sys
7this_dir = osp.dirname(__file__)
8sys.path.insert(0, osp.join(this_dir, '../../external'))
9sys.path.insert(0, osp.join(this_dir, '../../external/py-faster-rcnn/lib'))
10from vdetlib.utils.visual import unique_colors, add_bbox
11from vdetlib.utils.common import imread, imwrite
12from vdetlib.utils.protocol import proto_load, frame_path_at, boxes_at_frame, annot_boxes_at_frame
13from fast_rcnn.bbox_transform import bbox_transform, bbox_transform_inv
14from utils.cython_bbox import bbox_overlaps
15import cv2
16import random
17import numpy as np
18
19def _sample_boxes(box_proto, frame_id, num, annot_proto=None):
20    boxes = boxes_at_frame(box_proto, frame_id)
21    boxes = [box['bbox'] for box in boxes]
22    if annot_proto is None:
23        boxes = random.sample(boxes, num)
24    else:
25        gt_boxes = annot_boxes_at_frame(annot_proto, frame_id)
26        overlaps = bbox_overlaps(np.asarray(boxes, dtype=np.float),
27                                 np.asarray(gt_boxes, dtype=np.float))
28        max_overlaps = np.max(overlaps, axis=1)
29        idx = np.argsort(max_overlaps)[::-1][:num]
30        boxes = [boxes[i] for i in idx]
31    return boxes
32
33def _propagate_boxes(boxes, annot_proto, frame_id):
34    pred_boxes = []
35    annots = []
36    for annot in annot_proto['annotations']:
37        for idx, box in enumerate(annot['track']):
38            if box['frame'] == frame_id and len(annot['track']) > idx + 1:
39                gt1 = box['bbox']
40                gt2 = annot['track'][idx+1]['bbox']
41                delta = bbox_transform(np.asarray([gt1]), np.asarray([gt2]))
42                annots.append((gt1, delta))
43    gt1 = [annot[0] for annot in annots]
44    overlaps = bbox_overlaps(np.require(boxes, dtype=np.float),
45                             np.require(gt1, dtype=np.float))
46    for gt_overlaps, box in zip(overlaps, boxes):
47        max_overlap = np.max(gt_overlaps)
48        max_gt = np.argmax(gt_overlaps)
49        if max_overlap < 0.5:
50            pred_boxes.append(box)
51        else:
52            delta = annots[max_gt][1]
53            pred_boxes.append(bbox_transform_inv(np.asarray([box]), delta)[0].tolist())
54    return pred_boxes
55
56if __name__ == '__main__':
57    parser = argparse.ArgumentParser()
58    parser.add_argument('vid_file')
59    parser.add_argument('box_file')
60    parser.add_argument('gt_file')
61    parser.add_argument('--save_dir', default=None)
62    parser.add_argument('--num_tracks', type=int, default=30)
63    parser.add_argument('--length', type=int, default=20)
64    parser.set_defaults(sample_tracks=False)
65    args = parser.parse_args()
66
67    vid_proto = proto_load(args.vid_file)
68    box_proto = proto_load(args.box_file)
69    annot_proto = proto_load(args.gt_file)
70
71    paried_frames = zip(vid_proto['frames'][:-1], vid_proto['frames'][1:])
72    # colors = unique_colors(len(track_proto['tracks']))
73
74    boxes = []
75    colors = None
76    for frame1, frame2 in paried_frames:
77        frame_id = frame1['frame']
78        img = imread(frame_path_at(vid_proto, frame1['frame']))
79        if frame_id % args.length == 1 or len(boxes) == 0:
80            boxes = _sample_boxes(box_proto, frame_id, args.num_tracks, annot_proto)
81            colors = unique_colors(len(boxes))
82        else:
83            boxes = _propagate_boxes(boxes, annot_proto, frame_id-1)
84        tracked = add_bbox(img, boxes, None, colors, 2)
85        if args.save_dir:
86            if not os.path.isdir(args.save_dir):
87                try:
88                    os.makedirs(args.save_dir)
89                except:
90                    pass
91            imwrite(os.path.join(args.save_dir, ""{:04d}.jpg"".format(frame['frame'])),
92                    tracked)
93        else:
94            cv2.imshow('tracks', tracked)
95            if cv2.waitKey(0) == ord('q'):
96                cv2.destroyAllWindows()
97                sys.exit(0)
98    if not args.save_dir:
99        cv2.destroyAllWindows()
100",5766,"[[19, 'box_proto', '!=', None, ""Function '_sample_boxes' requires 'box_proto'""],
[19, 'frame_id', '!=', None, ""Function '_sample_boxes' requires 'frame_id'""],
[19, 'num', '!=', None, ""Function '_sample_boxes' requires 'num'""],
[33, 'boxes', '!=', None, ""Function '_propagate_boxes' requires 'boxes'""],
[33, 'annot_proto', '!=', None, ""Function '_propagate_boxes' requires 'annot_proto'""],
[33, 'frame_id', '!=', None, ""Function '_propagate_boxes' requires 'frame_id'""],
[57, 'args', '!=', None, ""Main function requires 'args' to parse""],
[67, 'vid_proto', '!=', None, ""Main function requires 'vid_proto' to load video protocol""],
[68, 'box_proto', '!=', None, ""Main function requires 'box_proto' to load bounding box protocol""],
[69, 'annot_proto', '!=', None, ""Main function requires 'annot_proto' to load annotation protocol""],
[78, 'img', '!=', None, ""Image required for bounding box addition""],
[79, 'boxes', '!=', None, ""Boxes required for bounding box propagation""]]"
INM-6/python-neo,"import unittest
from pathlib import Path
from numpy.testing import assert_array_equal, assert_

from neo.rawio.tdtrawio import TdtRawIO
from neo.test.rawiotest.common_rawio_test import BaseTestRawIO


class TestTdtRawIO(BaseTestRawIO, unittest.TestCase, ):
    rawioclass = TdtRawIO
    entities_to_download = [
        'tdt'
    ]
    entities_to_test = [
        # test structure directory with multiple blocks
        'tdt/aep_05',
        # test single block
        'tdt/dataset_0_single_block/512ch_reconly_all-181123_B24_rest.Tdx',
        'tdt/dataset_1_single_block/ECTest-220207-135355_ECTest_B1.Tdx',
        'tdt/aep_05/Block-1/aep_05_Block-1.Tdx'
    ]

    def test_invalid_dirname(self):
        invalid_name = 'random_non_existant_tdt_filename'
        assert not Path(invalid_name).exists()

        with self.assertRaises(ValueError):
            TdtRawIO(invalid_name)

    def test_compare_load_multi_single_block(self):
        dirname = self.get_local_path('tdt/aep_05')
        filename = self.get_local_path('tdt/aep_05/Block-1/aep_05_Block-1.Tdx')

        io_single = TdtRawIO(filename)
        io_multi = TdtRawIO(dirname)

        io_single.parse_header()
        io_multi.parse_header()

        self.assertEqual(io_single.tdt_block_mode, 'single')
        self.assertEqual(io_multi.tdt_block_mode, 'multi')

        self.assertEqual(io_single.block_count(), 1)
        self.assertEqual(io_multi.block_count(), 1)

        self.assertEqual(io_single.segment_count(0), 1)
        self.assertEqual(io_multi.segment_count(0), 2)

        # compare header infos
        assert_array_equal(io_single.header['signal_streams'], io_multi.header['signal_streams'])
        assert_array_equal(io_single.header['signal_channels'], io_multi.header['signal_channels'])
        assert_array_equal(io_single.header['event_channels'], io_multi.header['event_channels'])

        # not all spiking channels are present in first tdt block (segment)
        for spike_channel in io_single.header['spike_channels']:
            self.assertIn(spike_channel, io_multi.header['spike_channels'])

        # check that extracted signal chunks are identical
        assert_array_equal(io_single.get_analogsignal_chunk(0, 0, 0, 100, 0),
                           io_multi.get_analogsignal_chunk(0, 0, 0, 100, 0))


if __name__ == ""__main__"":
    unittest.main()
","
1import unittest
2from pathlib import Path
3
4from neo.rawio.tdtrawio import TdtRawIO
5from neo.test.rawiotest.common_rawio_test import BaseTestRawIO
6
7
8class TestTdtRawIO(BaseTestRawIO, unittest.TestCase, ):
9    rawioclass = TdtRawIO
10    entities_to_download = [
11        'tdt'
12    ]
13    entities_to_test = [
14        # test structure directory with multiple blocks
15        'tdt/aep_05',
16        # test single block
17        'tdt/dataset_0_single_block/512ch_reconly_all-181123_B24_rest.Tdx',
18        'tdt/dataset_1_single_block/ECTest-220207-135355_ECTest_B1.Tdx',
19        'tdt/aep_05/Block-1/aep_05_Block-1.Tdx'
20    ]
21
22    def test_invalid_dirname(self):
23        invalid_name = 'random_non_existant_tdt_filename'
24
25            TdtRawIO(invalid_name)
26
27    def test_compare_load_multi_single_block(self):
28        dirname = self.get_local_path('tdt/aep_05')
29        filename = self.get_local_path('tdt/aep_05/Block-1/aep_05_Block-1.Tdx')
30
31        io_single = TdtRawIO(filename)
32        io_multi = TdtRawIO(dirname)
33
34        io_single.parse_header()
35        io_multi.parse_header()
36
37
38
39
40        # compare header infos
41
42        # not all spiking channels are present in first tdt block (segment)
43        for spike_channel in io_single.header['spike_channels']:
44
45        # check that extracted signal chunks are identical
46                           io_multi.get_analogsignal_chunk(0, 0, 0, 100, 0))
47
48
49if __name__ == ""__main__"":
50    unittest.main()
51","[['Path(invalid_name).exists()', '==', 'False']]",14,1,0.0714285714285714,0.0004228329809725,"['rawioclass', 'entities_to_download', 'entities_to_test', 'invalid_name', 'dirname', 'filename', 'io_single', 'io_multi']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['rawioclass', 'entities_to_download', 'entities_to_test', 'invalid_name', 'dirname', 'filename', 'io_single', 'io_multi']
*Code:

1import unittest
2from pathlib import Path
3
4from neo.rawio.tdtrawio import TdtRawIO
5from neo.test.rawiotest.common_rawio_test import BaseTestRawIO
6
7
8class TestTdtRawIO(BaseTestRawIO, unittest.TestCase, ):
9    rawioclass = TdtRawIO
10    entities_to_download = [
11        'tdt'
12    ]
13    entities_to_test = [
14        # test structure directory with multiple blocks
15        'tdt/aep_05',
16        # test single block
17        'tdt/dataset_0_single_block/512ch_reconly_all-181123_B24_rest.Tdx',
18        'tdt/dataset_1_single_block/ECTest-220207-135355_ECTest_B1.Tdx',
19        'tdt/aep_05/Block-1/aep_05_Block-1.Tdx'
20    ]
21
22    def test_invalid_dirname(self):
23        invalid_name = 'random_non_existant_tdt_filename'
24
25            TdtRawIO(invalid_name)
26
27    def test_compare_load_multi_single_block(self):
28        dirname = self.get_local_path('tdt/aep_05')
29        filename = self.get_local_path('tdt/aep_05/Block-1/aep_05_Block-1.Tdx')
30
31        io_single = TdtRawIO(filename)
32        io_multi = TdtRawIO(dirname)
33
34        io_single.parse_header()
35        io_multi.parse_header()
36
37
38
39
40        # compare header infos
41
42        # not all spiking channels are present in first tdt block (segment)
43        for spike_channel in io_single.header['spike_channels']:
44
45        # check that extracted signal chunks are identical
46                           io_multi.get_analogsignal_chunk(0, 0, 0, 100, 0))
47
48
49if __name__ == ""__main__"":
50    unittest.main()
51",3030,"[[22, 'invalid_name', '!=', '', 'invalid_name should contain a value'],
 [27, 'dirname', '!=', '', 'dirname should contain a value'],
 [29, 'filename', '!=', '', 'filename should contain a value'],
 [31, 'io_single', '!=', '', 'io_single should be initialized'],
 [32, 'io_multi', '!=', '', 'io_multi should be initialized']]"
keerts/home-assistant,"""""""The tests for the command line notification platform.""""""
import os
import tempfile
import unittest
from unittest.mock import patch

from homeassistant.bootstrap import setup_component
import homeassistant.components.notify as notify
from tests.common import assert_setup_component, get_test_home_assistant


class TestCommandLine(unittest.TestCase):
    """"""Test the command line notifications.""""""

    def setUp(self):  # pylint: disable=invalid-name
        """"""Setup things to be run when tests are started.""""""
        self.hass = get_test_home_assistant()

    def tearDown(self):  # pylint: disable=invalid-name
        """"""Stop down everything that was started.""""""
        self.hass.stop()

    def test_setup(self):
        """"""Test setup.""""""
        with assert_setup_component(1) as handle_config:
            assert setup_component(self.hass, 'notify', {
                'notify': {
                    'name': 'test',
                    'platform': 'command_line',
                    'command': 'echo $(cat); exit 1', }
            })
        assert handle_config[notify.DOMAIN]

    def test_bad_config(self):
        """"""Test set up the platform with bad/missing configuration.""""""
        config = {
            notify.DOMAIN: {
                'name': 'test',
                'platform': 'command_line',
            }
        }
        with assert_setup_component(0) as handle_config:
            assert setup_component(self.hass, notify.DOMAIN, config)
        assert not handle_config[notify.DOMAIN]

    def test_command_line_output(self):
        """"""Test the command line output.""""""
        with tempfile.TemporaryDirectory() as tempdirname:
            filename = os.path.join(tempdirname, 'message.txt')
            message = 'one, two, testing, testing'
            with assert_setup_component(1) as handle_config:
                self.assertTrue(setup_component(self.hass, notify.DOMAIN, {
                    'notify': {
                        'name': 'test',
                        'platform': 'command_line',
                        'command': 'echo $(cat) > {}'.format(filename)
                    }
                }))
            assert handle_config[notify.DOMAIN]

            self.assertTrue(
                self.hass.services.call('notify', 'test', {'message': message},
                                        blocking=True)
            )

            result = open(filename).read()
            # the echo command adds a line break
            self.assertEqual(result, ""{}\n"".format(message))

    @patch('homeassistant.components.notify.command_line._LOGGER.error')
    def test_error_for_none_zero_exit_code(self, mock_error):
        """"""Test if an error is logged for non zero exit codes.""""""
        with assert_setup_component(1) as handle_config:
            self.assertTrue(setup_component(self.hass, notify.DOMAIN, {
                'notify': {
                    'name': 'test',
                    'platform': 'command_line',
                    'command': 'echo $(cat); exit 1'
                }
            }))
        assert handle_config[notify.DOMAIN]

        self.assertTrue(
            self.hass.services.call('notify', 'test', {'message': 'error'},
                                    blocking=True)
        )
        self.assertEqual(1, mock_error.call_count)
","
1""""""The tests for the command line notification platform.""""""
2import os
3import tempfile
4import unittest
5from unittest.mock import patch
6
7from homeassistant.bootstrap import setup_component
8import homeassistant.components.notify as notify
9
10
11class TestCommandLine(unittest.TestCase):
12    """"""Test the command line notifications.""""""
13
14    def setUp(self):  # pylint: disable=invalid-name
15        """"""Setup things to be run when tests are started.""""""
16        self.hass = get_test_home_assistant()
17
18    def tearDown(self):  # pylint: disable=invalid-name
19        """"""Stop down everything that was started.""""""
20        self.hass.stop()
21
22    def test_setup(self):
23        """"""Test setup.""""""
24                'notify': {
25                    'name': 'test',
26                    'platform': 'command_line',
27                    'command': 'echo $(cat); exit 1', }
28            })
29
30    def test_bad_config(self):
31        """"""Test set up the platform with bad/missing configuration.""""""
32        config = {
33            notify.DOMAIN: {
34                'name': 'test',
35                'platform': 'command_line',
36            }
37        }
38
39    def test_command_line_output(self):
40        """"""Test the command line output.""""""
41        with tempfile.TemporaryDirectory() as tempdirname:
42            filename = os.path.join(tempdirname, 'message.txt')
43            message = 'one, two, testing, testing'
44                    'notify': {
45                        'name': 'test',
46                        'platform': 'command_line',
47                        'command': 'echo $(cat) > {}'.format(filename)
48                    }
49                }))
50
51                self.hass.services.call('notify', 'test', {'message': message},
52                                        blocking=True)
53            )
54
55            result = open(filename).read()
56            # the echo command adds a line break
57
58    @patch('homeassistant.components.notify.command_line._LOGGER.error')
59    def test_error_for_none_zero_exit_code(self, mock_error):
60        """"""Test if an error is logged for non zero exit codes.""""""
61                'notify': {
62                    'name': 'test',
63                    'platform': 'command_line',
64                    'command': 'echo $(cat); exit 1'
65                }
66            }))
67
68            self.hass.services.call('notify', 'test', {'message': 'error'},
69                                    blocking=True)
70        )
71","[['le_config:', '==', 'True'], ['setup_component(self.hass', '==', 'True'], ['h', '==', 'True'], ['le_config[notify.DOMAIN]', '==', 'True'], ['le_config:', '==', 'True'], ['setup_component(self.hass', '==', 'True'], ['h', '==', 'False'], ['le_config[notify.DOMAIN]', '==', 'True'], ['le_config:', '==', 'True'], ['h', '==', 'True'], ['le_config[notify.DOMAIN]', '==', 'True'], ['le_config:', '==', 'True'], ['h', '==', 'True'], ['le_config[notify.DOMAIN]', '==', 'True']]",17,14,0.8235294117647058,0.0042194092827004,"['self.hass', 'config', 'filename', 'message', 'result', 'mock_error']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.hass', 'config', 'filename', 'message', 'result', 'mock_error']
*Code:

1""""""The tests for the command line notification platform.""""""
2import os
3import tempfile
4import unittest
5from unittest.mock import patch
6
7from homeassistant.bootstrap import setup_component
8import homeassistant.components.notify as notify
9
10
11class TestCommandLine(unittest.TestCase):
12    """"""Test the command line notifications.""""""
13
14    def setUp(self):  # pylint: disable=invalid-name
15        """"""Setup things to be run when tests are started.""""""
16        self.hass = get_test_home_assistant()
17
18    def tearDown(self):  # pylint: disable=invalid-name
19        """"""Stop down everything that was started.""""""
20        self.hass.stop()
21
22    def test_setup(self):
23        """"""Test setup.""""""
24                'notify': {
25                    'name': 'test',
26                    'platform': 'command_line',
27                    'command': 'echo $(cat); exit 1', }
28            })
29
30    def test_bad_config(self):
31        """"""Test set up the platform with bad/missing configuration.""""""
32        config = {
33            notify.DOMAIN: {
34                'name': 'test',
35                'platform': 'command_line',
36            }
37        }
38
39    def test_command_line_output(self):
40        """"""Test the command line output.""""""
41        with tempfile.TemporaryDirectory() as tempdirname:
42            filename = os.path.join(tempdirname, 'message.txt')
43            message = 'one, two, testing, testing'
44                    'notify': {
45                        'name': 'test',
46                        'platform': 'command_line',
47                        'command': 'echo $(cat) > {}'.format(filename)
48                    }
49                }))
50
51                self.hass.services.call('notify', 'test', {'message': message},
52                                        blocking=True)
53            )
54
55            result = open(filename).read()
56            # the echo command adds a line break
57
58    @patch('homeassistant.components.notify.command_line._LOGGER.error')
59    def test_error_for_none_zero_exit_code(self, mock_error):
60        """"""Test if an error is logged for non zero exit codes.""""""
61                'notify': {
62                    'name': 'test',
63                    'platform': 'command_line',
64                    'command': 'echo $(cat); exit 1'
65                }
66            }))
67
68            self.hass.services.call('notify', 'test', {'message': 'error'},
69                                    blocking=True)
70        )
71",3972,"[[14, 'self.hass', '!=', None, ""self.hass is initialized and should not be None""],
[31, 'config', '!=', None, ""config is used in the test and should not be None""],
[42, 'filename', '!=', None, ""filename should not be None as it is used to store the message""],
[43, 'message', '!=', None, ""message is used in the test and should not be None""],
[55, 'result', '!=', None, ""result is used to store the output and should not be None""],
[59, 'mock_error', '!=', None, ""mock_error is used in the test and should not be None""]]"
geokrety/geokrety-api,"from __future__ import absolute_import
import responses

VALUES = [
    ('43.69448', '6.85575', 'FR', '720'),
    ('52.06453', '9.32880', 'DE', '79'),
    ('52.06255', '9.34737', 'DE', '73'),
    ('52.06313', '9.32412', 'DE', '79'),
    ('52.07567', '9.35367', 'DE', '126'),
    ('52.08638', '9.50065', 'DE', '130'),
    ('52.07258', '9.35628', 'DE', '154'),
    ('43.69363', '6.86093', 'FR', '759'),
    ('43.67920', '6.85293', 'FR', '699'),
    ('43.70423', '6.86983', 'FR', '1105'),
    ('43.70177', '6.84085', 'FR', '705'),
    ('0.00000', '0.00000', '', 'None'),
    ('43.78000', '7.06000', 'FR', '996'),
    ('43.79000', '7.06000', 'FR', '997'),
    ('0.00000', '1.00000', '', 'None'),
    ('1.00000', '0.00000', '', 'None'),
]


class ResponsesMixin(object):
    def setUp(self):
        assert responses, 'responses package required to use ResponsesMixin'
        responses.start()
        for lat, lon, country, elevation in VALUES:
            responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat={}&lon={}'.format(lat, lon),
                          status=200, body=country, match_querystring=True)
            responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat={}&lon={}'.format(lat, lon),
                          status=200, body=elevation, match_querystring=True)

        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=42.00000&lon=42.00000',
                      status=400, match_querystring=True)
        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=42.00000&lon=42.00000',
                      status=500, match_querystring=True)

        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=None',
                      status=500, match_querystring=True)
        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=None',
                      status=500, match_querystring=True)

        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=0.00000&lon=None',
                      status=500, match_querystring=True)
        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=0.00000&lon=None',
                      status=500, match_querystring=True)
        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=0.00000',
                      status=500, match_querystring=True)
        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=0.00000',
                      status=500, match_querystring=True)

        super(ResponsesMixin, self).setUp()

    def tearDown(self):
        super(ResponsesMixin, self).tearDown()
        responses.stop()
        responses.reset()
","
1from __future__ import absolute_import
2import responses
3
4VALUES = [
5    ('43.69448', '6.85575', 'FR', '720'),
6    ('52.06453', '9.32880', 'DE', '79'),
7    ('52.06255', '9.34737', 'DE', '73'),
8    ('52.06313', '9.32412', 'DE', '79'),
9    ('52.07567', '9.35367', 'DE', '126'),
10    ('52.08638', '9.50065', 'DE', '130'),
11    ('52.07258', '9.35628', 'DE', '154'),
12    ('43.69363', '6.86093', 'FR', '759'),
13    ('43.67920', '6.85293', 'FR', '699'),
14    ('43.70423', '6.86983', 'FR', '1105'),
15    ('43.70177', '6.84085', 'FR', '705'),
16    ('0.00000', '0.00000', '', 'None'),
17    ('43.78000', '7.06000', 'FR', '996'),
18    ('43.79000', '7.06000', 'FR', '997'),
19    ('0.00000', '1.00000', '', 'None'),
20    ('1.00000', '0.00000', '', 'None'),
21]
22
23
24class ResponsesMixin(object):
25    def setUp(self):
26        responses.start()
27        for lat, lon, country, elevation in VALUES:
28            responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat={}&lon={}'.format(lat, lon),
29                          status=200, body=country, match_querystring=True)
30            responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat={}&lon={}'.format(lat, lon),
31                          status=200, body=elevation, match_querystring=True)
32
33        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=42.00000&lon=42.00000',
34                      status=400, match_querystring=True)
35        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=42.00000&lon=42.00000',
36                      status=500, match_querystring=True)
37
38        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=None',
39                      status=500, match_querystring=True)
40        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=None',
41                      status=500, match_querystring=True)
42
43        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=0.00000&lon=None',
44                      status=500, match_querystring=True)
45        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=0.00000&lon=None',
46                      status=500, match_querystring=True)
47        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=0.00000',
48                      status=500, match_querystring=True)
49        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=0.00000',
50                      status=500, match_querystring=True)
51
52        super(ResponsesMixin, self).setUp()
53
54    def tearDown(self):
55        super(ResponsesMixin, self).tearDown()
56        responses.stop()
57        responses.reset()
58","[['responses', '==', 'True']]",1,1,1.0,0.0003645643456069,['VALUES'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['VALUES']
*Code:

1from __future__ import absolute_import
2import responses
3
4VALUES = [
5    ('43.69448', '6.85575', 'FR', '720'),
6    ('52.06453', '9.32880', 'DE', '79'),
7    ('52.06255', '9.34737', 'DE', '73'),
8    ('52.06313', '9.32412', 'DE', '79'),
9    ('52.07567', '9.35367', 'DE', '126'),
10    ('52.08638', '9.50065', 'DE', '130'),
11    ('52.07258', '9.35628', 'DE', '154'),
12    ('43.69363', '6.86093', 'FR', '759'),
13    ('43.67920', '6.85293', 'FR', '699'),
14    ('43.70423', '6.86983', 'FR', '1105'),
15    ('43.70177', '6.84085', 'FR', '705'),
16    ('0.00000', '0.00000', '', 'None'),
17    ('43.78000', '7.06000', 'FR', '996'),
18    ('43.79000', '7.06000', 'FR', '997'),
19    ('0.00000', '1.00000', '', 'None'),
20    ('1.00000', '0.00000', '', 'None'),
21]
22
23
24class ResponsesMixin(object):
25    def setUp(self):
26        responses.start()
27        for lat, lon, country, elevation in VALUES:
28            responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat={}&lon={}'.format(lat, lon),
29                          status=200, body=country, match_querystring=True)
30            responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat={}&lon={}'.format(lat, lon),
31                          status=200, body=elevation, match_querystring=True)
32
33        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=42.00000&lon=42.00000',
34                      status=400, match_querystring=True)
35        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=42.00000&lon=42.00000',
36                      status=500, match_querystring=True)
37
38        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=None',
39                      status=500, match_querystring=True)
40        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=None',
41                      status=500, match_querystring=True)
42
43        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=0.00000&lon=None',
44                      status=500, match_querystring=True)
45        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=0.00000&lon=None',
46                      status=500, match_querystring=True)
47        responses.add(responses.GET, 'https://geo.kumy.org/api/getCountry?lat=None&lon=0.00000',
48                      status=500, match_querystring=True)
49        responses.add(responses.GET, 'https://geo.kumy.org/api/getElevation?lat=None&lon=0.00000',
50                      status=500, match_querystring=True)
51
52        super(ResponsesMixin, self).setUp()
53
54    def tearDown(self):
55        super(ResponsesMixin, self).tearDown()
56        responses.stop()
57        responses.reset()
58",4164,"[[4, 'VALUES', '!=', [], 'VALUES variable is used in the creation of responses so it should not be empty'],
[27, 'lat', '!=', 'None', 'latitude value is used in the URL and cannot be None'],
[27, 'lon', '!=', 'None', 'longitude value is used in the URL and cannot be None'],
[27, 'country', '!=', 'None', 'country value is used in the response body and cannot be None'],
[27, 'elevation', '!=', 'None', 'elevation value is used in the response body and cannot be None']]"
SANDAG/pandana,"import os
import tempfile

import pandas as pd
import pytest

import pandas.util.testing as pdt
from pandana import Network
from pandana.testing import skipiftravis

from pandana.loaders import pandash5 as ph5


@pytest.fixture(scope='module')
def nodes():
    return pd.DataFrame(
        {'x': [1, 2, 3, 4] * 3,
         'y': [1] * 4 + [2] * 4 + [3] * 4})


@pytest.fixture(scope='module')
def edges():
    return pd.DataFrame(
        {'from': [0, 4, 5, 6, 2, 2, 6, 10, 9, 7],
         'to': [4, 5, 6, 2, 1, 3, 10, 9, 8, 11]})


@pytest.fixture(scope='module')
def impedance_names():
    return ['distance', 'time']


@pytest.fixture(scope='module')
def edge_weights(edges, impedance_names):
    return pd.DataFrame(
        {impedance_names[0]: [1] * len(edges),
         impedance_names[1]: range(1, len(edges) + 1)})


@pytest.fixture(scope='module')
def two_way():
    return True


@pytest.fixture(scope='module')
def network(nodes, edges, edge_weights, two_way):
    return Network(
        nodes['x'], nodes['y'], edges['from'], edges['to'], edge_weights,
        two_way)


@pytest.fixture(scope='module')
def edges_df(edges, edge_weights):
    return edges.join(edge_weights)


@pytest.fixture(scope='module')
def rm_nodes():
    return [0, 7, 6]


@pytest.fixture
def tmpfile(request):
    fname = tempfile.NamedTemporaryFile().name

    def cleanup():
        if os.path.exists(fname):
            os.remove(fname)
    request.addfinalizer(cleanup)

    return fname


@skipiftravis
def test_remove_nodes(network, rm_nodes):
    # node 0 is connected to node 4, which is in turn connected to node 5
    # node 7 is connected to node 11, which has no other connections
    # node 6 is connected to nodes 2, 5, and 10,
    #     which all have other connections
    nodes, edges = ph5.remove_nodes(network, rm_nodes)

    exp_nodes = pd.DataFrame(
        {'x': [2, 3, 4, 1, 2, 1, 2, 3, 4],
         'y': [1, 1, 1, 2, 2, 3, 3, 3, 3]},
        index=[1, 2, 3, 4, 5, 8, 9, 10, 11])

    exp_edges = pd.DataFrame(
        {'from': [4, 2, 2, 10, 9],
         'to': [5, 1, 3, 9, 8],
         'distance': [1, 1, 1, 1, 1],
         'time': [2, 5, 6, 8, 9]},
        index=[1, 4, 5, 7, 8])
    exp_edges = exp_edges[['from', 'to', 'distance', 'time']]  # order columns

    pdt.assert_frame_equal(nodes, exp_nodes)
    pdt.assert_frame_equal(edges, exp_edges)


@skipiftravis
def test_network_to_pandas_hdf5(
        tmpfile, network, nodes, edges_df, impedance_names, two_way):
    ph5.network_to_pandas_hdf5(network, tmpfile)

    store = pd.HDFStore(tmpfile)

    pdt.assert_frame_equal(store['nodes'], nodes)
    pdt.assert_frame_equal(store['edges'], edges_df)
    pdt.assert_series_equal(store['two_way'], pd.Series([two_way]))
    pdt.assert_series_equal(
        store['impedance_names'], pd.Series(impedance_names))


@skipiftravis
def test_network_to_pandas_hdf5_removal(
        tmpfile, network, impedance_names, two_way, rm_nodes):
    nodes, edges = ph5.remove_nodes(network, rm_nodes)
    ph5.network_to_pandas_hdf5(network, tmpfile, rm_nodes)

    store = pd.HDFStore(tmpfile)

    pdt.assert_frame_equal(store['nodes'], nodes)
    pdt.assert_frame_equal(store['edges'], edges)
    pdt.assert_series_equal(store['two_way'], pd.Series([two_way]))
    pdt.assert_series_equal(
        store['impedance_names'], pd.Series(impedance_names))


@skipiftravis
def test_network_from_pandas_hdf5(
        tmpfile, network, nodes, edges_df, impedance_names, two_way):
    ph5.network_to_pandas_hdf5(network, tmpfile)
    new_net = ph5.network_from_pandas_hdf5(Network, tmpfile)

    pdt.assert_frame_equal(new_net.nodes_df, nodes)
    pdt.assert_frame_equal(new_net.edges_df, edges_df)
    assert new_net._twoway == two_way
    assert new_net.impedance_names == impedance_names


@skipiftravis
def test_network_save_load_hdf5(
        tmpfile, network, impedance_names, two_way, rm_nodes):
    network.save_hdf5(tmpfile, rm_nodes)
    new_net = Network.from_hdf5(tmpfile)

    nodes, edges = ph5.remove_nodes(network, rm_nodes)

    pdt.assert_frame_equal(new_net.nodes_df, nodes)
    pdt.assert_frame_equal(new_net.edges_df, edges)
    assert new_net._twoway == two_way
    assert new_net.impedance_names == impedance_names


# this is an odd place for this test because it's not related to HDF5,
# but my test Network is perfect.
@skipiftravis
def test_network_low_connectivity_nodes(network, impedance_names):
    nodes = network.low_connectivity_nodes(10, 3, imp_name=impedance_names[0])
    assert list(nodes) == [7, 11]
","
1import os
2import tempfile
3
4import pandas as pd
5import pytest
6
7import pandas.util.testing as pdt
8from pandana import Network
9from pandana.testing import skipiftravis
10
11from pandana.loaders import pandash5 as ph5
12
13
14@pytest.fixture(scope='module')
15def nodes():
16    return pd.DataFrame(
17        {'x': [1, 2, 3, 4] * 3,
18         'y': [1] * 4 + [2] * 4 + [3] * 4})
19
20
21@pytest.fixture(scope='module')
22def edges():
23    return pd.DataFrame(
24        {'from': [0, 4, 5, 6, 2, 2, 6, 10, 9, 7],
25         'to': [4, 5, 6, 2, 1, 3, 10, 9, 8, 11]})
26
27
28@pytest.fixture(scope='module')
29def impedance_names():
30    return ['distance', 'time']
31
32
33@pytest.fixture(scope='module')
34def edge_weights(edges, impedance_names):
35    return pd.DataFrame(
36        {impedance_names[0]: [1] * len(edges),
37         impedance_names[1]: range(1, len(edges) + 1)})
38
39
40@pytest.fixture(scope='module')
41def two_way():
42    return True
43
44
45@pytest.fixture(scope='module')
46def network(nodes, edges, edge_weights, two_way):
47    return Network(
48        nodes['x'], nodes['y'], edges['from'], edges['to'], edge_weights,
49        two_way)
50
51
52@pytest.fixture(scope='module')
53def edges_df(edges, edge_weights):
54    return edges.join(edge_weights)
55
56
57@pytest.fixture(scope='module')
58def rm_nodes():
59    return [0, 7, 6]
60
61
62@pytest.fixture
63def tmpfile(request):
64    fname = tempfile.NamedTemporaryFile().name
65
66    def cleanup():
67        if os.path.exists(fname):
68            os.remove(fname)
69    request.addfinalizer(cleanup)
70
71    return fname
72
73
74@skipiftravis
75def test_remove_nodes(network, rm_nodes):
76    # node 0 is connected to node 4, which is in turn connected to node 5
77    # node 7 is connected to node 11, which has no other connections
78    # node 6 is connected to nodes 2, 5, and 10,
79    #     which all have other connections
80    nodes, edges = ph5.remove_nodes(network, rm_nodes)
81
82    exp_nodes = pd.DataFrame(
83        {'x': [2, 3, 4, 1, 2, 1, 2, 3, 4],
84         'y': [1, 1, 1, 2, 2, 3, 3, 3, 3]},
85        index=[1, 2, 3, 4, 5, 8, 9, 10, 11])
86
87    exp_edges = pd.DataFrame(
88        {'from': [4, 2, 2, 10, 9],
89         'to': [5, 1, 3, 9, 8],
90         'distance': [1, 1, 1, 1, 1],
91         'time': [2, 5, 6, 8, 9]},
92        index=[1, 4, 5, 7, 8])
93    exp_edges = exp_edges[['from', 'to', 'distance', 'time']]  # order columns
94
95
96
97@skipiftravis
98def test_network_to_pandas_hdf5(
99        tmpfile, network, nodes, edges_df, impedance_names, two_way):
100    ph5.network_to_pandas_hdf5(network, tmpfile)
101
102    store = pd.HDFStore(tmpfile)
103
104        store['impedance_names'], pd.Series(impedance_names))
105
106
107@skipiftravis
108def test_network_to_pandas_hdf5_removal(
109        tmpfile, network, impedance_names, two_way, rm_nodes):
110    nodes, edges = ph5.remove_nodes(network, rm_nodes)
111    ph5.network_to_pandas_hdf5(network, tmpfile, rm_nodes)
112
113    store = pd.HDFStore(tmpfile)
114
115        store['impedance_names'], pd.Series(impedance_names))
116
117
118@skipiftravis
119def test_network_from_pandas_hdf5(
120        tmpfile, network, nodes, edges_df, impedance_names, two_way):
121    ph5.network_to_pandas_hdf5(network, tmpfile)
122    new_net = ph5.network_from_pandas_hdf5(Network, tmpfile)
123
124
125
126@skipiftravis
127def test_network_save_load_hdf5(
128        tmpfile, network, impedance_names, two_way, rm_nodes):
129    network.save_hdf5(tmpfile, rm_nodes)
130    new_net = Network.from_hdf5(tmpfile)
131
132    nodes, edges = ph5.remove_nodes(network, rm_nodes)
133
134
135
136# this is an odd place for this test because it's not related to HDF5,
137# but my test Network is perfect.
138@skipiftravis
139def test_network_low_connectivity_nodes(network, impedance_names):
140    nodes = network.low_connectivity_nodes(10, 3, imp_name=impedance_names[0])
141","[['new_net._twoway', '==', 'two_way'], ['new_net.impedance_names', '==', 'impedance_names'], ['new_net._twoway', '==', 'two_way'], ['new_net.impedance_names', '==', 'impedance_names'], ['list(nodes)', '==', '[7']]",19,5,0.2631578947368421,0.0011022927689594,"['edges', 'impedance_names', 'nodes', 'edge_weights', 'two_way', 'request', 'fname', 'network', 'rm_nodes', 'exp_nodes', 'exp_edges', 'store', 'new_net']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['edges', 'impedance_names', 'nodes', 'edge_weights', 'two_way', 'request', 'fname', 'network', 'rm_nodes', 'exp_nodes', 'exp_edges', 'store', 'new_net']
*Code:

1import os
2import tempfile
3
4import pandas as pd
5import pytest
6
7import pandas.util.testing as pdt
8from pandana import Network
9from pandana.testing import skipiftravis
10
11from pandana.loaders import pandash5 as ph5
12
13
14@pytest.fixture(scope='module')
15def nodes():
16    return pd.DataFrame(
17        {'x': [1, 2, 3, 4] * 3,
18         'y': [1] * 4 + [2] * 4 + [3] * 4})
19
20
21@pytest.fixture(scope='module')
22def edges():
23    return pd.DataFrame(
24        {'from': [0, 4, 5, 6, 2, 2, 6, 10, 9, 7],
25         'to': [4, 5, 6, 2, 1, 3, 10, 9, 8, 11]})
26
27
28@pytest.fixture(scope='module')
29def impedance_names():
30    return ['distance', 'time']
31
32
33@pytest.fixture(scope='module')
34def edge_weights(edges, impedance_names):
35    return pd.DataFrame(
36        {impedance_names[0]: [1] * len(edges),
37         impedance_names[1]: range(1, len(edges) + 1)})
38
39
40@pytest.fixture(scope='module')
41def two_way():
42    return True
43
44
45@pytest.fixture(scope='module')
46def network(nodes, edges, edge_weights, two_way):
47    return Network(
48        nodes['x'], nodes['y'], edges['from'], edges['to'], edge_weights,
49        two_way)
50
51
52@pytest.fixture(scope='module')
53def edges_df(edges, edge_weights):
54    return edges.join(edge_weights)
55
56
57@pytest.fixture(scope='module')
58def rm_nodes():
59    return [0, 7, 6]
60
61
62@pytest.fixture
63def tmpfile(request):
64    fname = tempfile.NamedTemporaryFile().name
65
66    def cleanup():
67        if os.path.exists(fname):
68            os.remove(fname)
69    request.addfinalizer(cleanup)
70
71    return fname
72
73
74@skipiftravis
75def test_remove_nodes(network, rm_nodes):
76    # node 0 is connected to node 4, which is in turn connected to node 5
77    # node 7 is connected to node 11, which has no other connections
78    # node 6 is connected to nodes 2, 5, and 10,
79    #     which all have other connections
80    nodes, edges = ph5.remove_nodes(network, rm_nodes)
81
82    exp_nodes = pd.DataFrame(
83        {'x': [2, 3, 4, 1, 2, 1, 2, 3, 4],
84         'y': [1, 1, 1, 2, 2, 3, 3, 3, 3]},
85        index=[1, 2, 3, 4, 5, 8, 9, 10, 11])
86
87    exp_edges = pd.DataFrame(
88        {'from': [4, 2, 2, 10, 9],
89         'to': [5, 1, 3, 9, 8],
90         'distance': [1, 1, 1, 1, 1],
91         'time': [2, 5, 6, 8, 9]},
92        index=[1, 4, 5, 7, 8])
93    exp_edges = exp_edges[['from', 'to', 'distance', 'time']]  # order columns
94
95
96
97@skipiftravis
98def test_network_to_pandas_hdf5(
99        tmpfile, network, nodes, edges_df, impedance_names, two_way):
100    ph5.network_to_pandas_hdf5(network, tmpfile)
101
102    store = pd.HDFStore(tmpfile)
103
104        store['impedance_names'], pd.Series(impedance_names))
105
106
107@skipiftravis
108def test_network_to_pandas_hdf5_removal(
109        tmpfile, network, impedance_names, two_way, rm_nodes):
110    nodes, edges = ph5.remove_nodes(network, rm_nodes)
111    ph5.network_to_pandas_hdf5(network, tmpfile, rm_nodes)
112
113    store = pd.HDFStore(tmpfile)
114
115        store['impedance_names'], pd.Series(impedance_names))
116
117
118@skipiftravis
119def test_network_from_pandas_hdf5(
120        tmpfile, network, nodes, edges_df, impedance_names, two_way):
121    ph5.network_to_pandas_hdf5(network, tmpfile)
122    new_net = ph5.network_from_pandas_hdf5(Network, tmpfile)
123
124
125
126@skipiftravis
127def test_network_save_load_hdf5(
128        tmpfile, network, impedance_names, two_way, rm_nodes):
129    network.save_hdf5(tmpfile, rm_nodes)
130    new_net = Network.from_hdf5(tmpfile)
131
132    nodes, edges = ph5.remove_nodes(network, rm_nodes)
133
134
135
136# this is an odd place for this test because it's not related to HDF5,
137# but my test Network is perfect.
138@skipiftravis
139def test_network_low_connectivity_nodes(network, impedance_names):
140    nodes = network.low_connectivity_nodes(10, 3, imp_name=impedance_names[0])
141",5469,"[[15, 'nodes', '==', 12, 'There should be 12 nodes'],
 [22, 'edges', '==', 10, 'There should be 10 edges'],
 [29, 'impedance_names', '==', 2, 'There should be 2 impedance names'],
 [34, 'edge_weights', '==', 10, 'Edge weights should match number of edges'],
 [41, 'two_way', '==', 1, 'two_way should be boolean, True or False represented as 1 or 0'],
 [46, 'network', '!=', 'None', 'Network should be not be None after creation'],
 [58, 'rm_nodes', '==', 3, 'There should be 3 nodes to be removed'],
 [75, 'rm_nodes', '!=', 'None', 'rm_nodes should be provided for node removal test'],
 [98, 'fname', '!=', 'None', 'Filename should not be None for hdf5 conversion'],
 [119, 'new_net', '!=', 'None', 'new_net should not be None after loading from hdf5'], 
 [127, 'new_net', '!=', 'None', 'new_net should not be None after loading from hdf5'],
 [139, 'impedance_names', '!=', 'None', 'Impedance name should be provided for low connectivity nodes test']]"
jairhenrique/django-elephant,"# -*- coding: utf-8 -*-
import pytest

from elephant import memorize
from elephant.exceptions import CacheKeyFunctionNotDefined
from django.core.cache import cache as default_cache


@memorize()
def fake_function():
    return 'dumbo'


class TestElephant(object):

    def test_should_raise_exception_when_cache_key_functions_is_not_callable(self):  # noqa

        @memorize(cache_key=None)
        def dumbo():
            return 'dumbo'

        with pytest.raises(CacheKeyFunctionNotDefined):
            assert dumbo() == 'dumbo'

    def test_should_save_result_on_cache(self):

        @memorize(
            timeout=10,
            cache_key=lambda function: 'fake_key'
        )
        def dumbo():
            return 'dumbo'

        assert dumbo() == 'dumbo'

        data = default_cache.get('fake_key')

        assert data == 'dumbo'

    def test_should_use_generic_cache_key(self):
        assert fake_function() == 'dumbo'

        data = default_cache.get('tests.test_elephant.fake_function')
        assert data == 'dumbo'
","
1# -*- coding: utf-8 -*-
2import pytest
3
4from elephant import memorize
5from elephant.exceptions import CacheKeyFunctionNotDefined
6from django.core.cache import cache as default_cache
7
8
9@memorize()
10def fake_function():
11    return 'dumbo'
12
13
14class TestElephant(object):
15
16    def test_should_raise_exception_when_cache_key_functions_is_not_callable(self):  # noqa
17
18        @memorize(cache_key=None)
19        def dumbo():
20            return 'dumbo'
21
22        with pytest.raises(CacheKeyFunctionNotDefined):
23
24    def test_should_save_result_on_cache(self):
25
26        @memorize(
27            timeout=10,
28            cache_key=lambda function: 'fake_key'
29        )
30        def dumbo():
31            return 'dumbo'
32
33
34        data = default_cache.get('fake_key')
35
36
37    def test_should_use_generic_cache_key(self):
38
39        data = default_cache.get('tests.test_elephant.fake_function')
40","[['dumbo()', '==', ""'dumbo'""], ['dumbo()', '==', ""'dumbo'""], ['data', '==', ""'dumbo'""], ['fake_function()', '==', ""'dumbo'""], ['data', '==', ""'dumbo'""]]",5,5,1.0,0.0047892720306513,['data'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['data']
*Code:

1# -*- coding: utf-8 -*-
2import pytest
3
4from elephant import memorize
5from elephant.exceptions import CacheKeyFunctionNotDefined
6from django.core.cache import cache as default_cache
7
8
9@memorize()
10def fake_function():
11    return 'dumbo'
12
13
14class TestElephant(object):
15
16    def test_should_raise_exception_when_cache_key_functions_is_not_callable(self):  # noqa
17
18        @memorize(cache_key=None)
19        def dumbo():
20            return 'dumbo'
21
22        with pytest.raises(CacheKeyFunctionNotDefined):
23
24    def test_should_save_result_on_cache(self):
25
26        @memorize(
27            timeout=10,
28            cache_key=lambda function: 'fake_key'
29        )
30        def dumbo():
31            return 'dumbo'
32
33
34        data = default_cache.get('fake_key')
35
36
37    def test_should_use_generic_cache_key(self):
38
39        data = default_cache.get('tests.test_elephant.fake_function')
40",2328,"[[34, 'data', '!=', None, ""to ensure that the data is retrieved from default_cache by 'fake_key'""], 
[39, 'data', '!=', None, ""to ensure that the data is retrieved from default_cache by 'tests.test_elephant.fake_function'""]]"
jr0d/mercury,"# Copyright 2017 Rackspace
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License"");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.
import mock
import pytest

from mercury.rpc.controller import RPCController


@pytest.fixture()
def frontend_controller(async_mongodb):
    jobs_collection = async_mongodb.rpc_jobs
    tasks_collection = async_mongodb.rpc_tasks
    inventory_client = mock.Mock()
    controller = RPCController(inventory_client,
                               jobs_collection,
                               tasks_collection)
    return controller


class TestFrontendController(object):

    @pytest.mark.asyncio
    async def test_get_job(self, frontend_controller):
        job = await frontend_controller.get_job('job-1')
        assert job.get('job_id') == 'job-1'

    @pytest.mark.asyncio
    async def test_get_job_none(self, frontend_controller):
        job = await frontend_controller.get_job('job-x')
        assert job == None
","
1# Copyright 2017 Rackspace
2# All Rights Reserved.
3#
4#    Licensed under the Apache License, Version 2.0 (the ""License"");
5#    you may not use this file except in compliance with the License.
6#    You may obtain a copy of the License at
7#
8#      http://www.apache.org/licenses/LICENSE-2.0
9#
10#    Unless required by applicable law or agreed to in writing, software
11#    distributed under the License is distributed on an ""AS IS"" BASIS,
12#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13#    See the License for the specific language governing permissions and
14#    limitations under the License.
15import mock
16import pytest
17
18from mercury.rpc.controller import RPCController
19
20
21@pytest.fixture()
22def frontend_controller(async_mongodb):
23    jobs_collection = async_mongodb.rpc_jobs
24    tasks_collection = async_mongodb.rpc_tasks
25    inventory_client = mock.Mock()
26    controller = RPCController(inventory_client,
27                               jobs_collection,
28                               tasks_collection)
29    return controller
30
31
32class TestFrontendController(object):
33
34    @pytest.mark.asyncio
35    async def test_get_job(self, frontend_controller):
36        job = await frontend_controller.get_job('job-1')
37
38    @pytest.mark.asyncio
39    async def test_get_job_none(self, frontend_controller):
40        job = await frontend_controller.get_job('job-x')
41","[[""job.get('job_id')"", '==', ""'job-1'""], ['job', '==', 'None']]",2,2,1.0,0.0013850415512465,"['async_mongodb', 'jobs_collection', 'tasks_collection', 'inventory_client', 'controller', 'frontend_controller', 'job']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['async_mongodb', 'jobs_collection', 'tasks_collection', 'inventory_client', 'controller', 'frontend_controller', 'job']
*Code:

1# Copyright 2017 Rackspace
2# All Rights Reserved.
3#
4#    Licensed under the Apache License, Version 2.0 (the ""License"");
5#    you may not use this file except in compliance with the License.
6#    You may obtain a copy of the License at
7#
8#      http://www.apache.org/licenses/LICENSE-2.0
9#
10#    Unless required by applicable law or agreed to in writing, software
11#    distributed under the License is distributed on an ""AS IS"" BASIS,
12#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13#    See the License for the specific language governing permissions and
14#    limitations under the License.
15import mock
16import pytest
17
18from mercury.rpc.controller import RPCController
19
20
21@pytest.fixture()
22def frontend_controller(async_mongodb):
23    jobs_collection = async_mongodb.rpc_jobs
24    tasks_collection = async_mongodb.rpc_tasks
25    inventory_client = mock.Mock()
26    controller = RPCController(inventory_client,
27                               jobs_collection,
28                               tasks_collection)
29    return controller
30
31
32class TestFrontendController(object):
33
34    @pytest.mark.asyncio
35    async def test_get_job(self, frontend_controller):
36        job = await frontend_controller.get_job('job-1')
37
38    @pytest.mark.asyncio
39    async def test_get_job_none(self, frontend_controller):
40        job = await frontend_controller.get_job('job-x')
41",2947,"[[22, 'async_mongodb', '!=', None, ""the frontend_controller can't be initialized with a null async_mongodb""],
[26, 'jobs_collection', '!=', None, ""RPCController can't be initialized with a null jobs_collection""],
[26, 'tasks_collection', '!=', None, ""RPCController can't be initialized with a null tasks_collection""],
[26, 'inventory_client', '!=', None, ""RPCController can't be initialized with a null inventory_client""],
[36, 'frontend_controller', '!=', None, ""the function test_get_job can't operate without a frontend_controller""],
[40, 'frontend_controller', '!=', None, ""the function test_get_job_none can't operate without a frontend_controller""]]"
V155/qutebrowser,"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2016-2021 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <https://www.gnu.org/licenses/>.

import pytest
from PyQt5.QtCore import Qt

from qutebrowser.mainwindow import messageview
from qutebrowser.utils import usertypes


@pytest.fixture
def view(qtbot, config_stub):
    config_stub.val.messages.timeout = 100
    mv = messageview.MessageView()
    qtbot.add_widget(mv)
    return mv


@pytest.mark.parametrize('level', [usertypes.MessageLevel.info,
                                   usertypes.MessageLevel.warning,
                                   usertypes.MessageLevel.error])
@pytest.mark.flaky  # on macOS
def test_single_message(qtbot, view, level):
    with qtbot.waitExposed(view, timeout=5000):
        view.show_message(level, 'test')
    assert view._messages[0].isVisible()


def test_message_hiding(qtbot, view):
    """"""Messages should be hidden after the timer times out.""""""
    with qtbot.waitSignal(view._clear_timer.timeout):
        view.show_message(usertypes.MessageLevel.info, 'test')
    assert not view._messages


def test_size_hint(view):
    """"""The message height should increase with more messages.""""""
    view.show_message(usertypes.MessageLevel.info, 'test1')
    height1 = view.sizeHint().height()
    assert height1 > 0
    view.show_message(usertypes.MessageLevel.info, 'test2')
    height2 = view.sizeHint().height()
    assert height2 == height1 * 2


def test_word_wrap(view, qtbot):
    """"""A long message should be wrapped.""""""
    with qtbot.waitSignal(view._clear_timer.timeout):
        view.show_message(usertypes.MessageLevel.info, 'short')
        height1 = view.sizeHint().height()
        assert height1 > 0

    text = (""Athene, the bright-eyed goddess, answered him at once: Father of ""
            ""us all, Son of Cronos, Highest King, clearly that man deserved to be ""
            ""destroyed: so let all be destroyed who act as he did. But my heart aches ""
            ""for Odysseus, wise but ill fated, who suffers far from his friends on an ""
            ""island deep in the sea."")

    view.show_message(usertypes.MessageLevel.info, text)
    height2 = view.sizeHint().height()

    assert height2 > height1
    assert view._messages[0].wordWrap()


def test_show_message_twice(view):
    """"""Show the same message twice -> only one should be shown.""""""
    view.show_message(usertypes.MessageLevel.info, 'test')
    view.show_message(usertypes.MessageLevel.info, 'test')
    assert len(view._messages) == 1


def test_show_message_twice_after_first_disappears(qtbot, view):
    """"""Show the same message twice after the first is gone.""""""
    with qtbot.waitSignal(view._clear_timer.timeout):
        view.show_message(usertypes.MessageLevel.info, 'test')
    # Just a sanity check
    assert not view._messages

    view.show_message(usertypes.MessageLevel.info, 'test')
    assert len(view._messages) == 1


def test_changing_timer_with_messages_shown(qtbot, view, config_stub):
    """"""When we change messages.timeout, the timer should be restarted.""""""
    config_stub.val.messages.timeout = 900000  # 15s
    view.show_message(usertypes.MessageLevel.info, 'test')
    with qtbot.waitSignal(view._clear_timer.timeout):
        config_stub.val.messages.timeout = 100


@pytest.mark.parametrize('count, expected', [(1, 100), (3, 300),
                                             (5, 500), (7, 500)])
def test_show_multiple_messages_longer(view, count, expected):
    """"""When there are multiple messages, messages should be shown longer.

    There is an upper maximum to avoid messages never disappearing.
    """"""
    for message_number in range(1, count+1):
        view.show_message(usertypes.MessageLevel.info,
                          'test ' + str(message_number))
    assert view._clear_timer.interval() == expected


@pytest.mark.parametrize('replace1, replace2, length', [
    (False, False, 2),    # Two stacked messages
    (True, True, 1),  # Two replaceable messages
    (False, True, 2),  # Stacked and replaceable
    (True, False, 2),  # Replaceable and stacked
])
def test_replaced_messages(view, replace1, replace2, length):
    """"""Show two stack=False messages which should replace each other.""""""
    view.show_message(usertypes.MessageLevel.info, 'test', replace=replace1)
    view.show_message(usertypes.MessageLevel.info, 'test 2', replace=replace2)
    assert len(view._messages) == length


@pytest.mark.parametrize('button, count', [
    (Qt.LeftButton, 0),
    (Qt.MiddleButton, 0),
    (Qt.RightButton, 0),
    (Qt.BackButton, 2),
])
def test_click_messages(qtbot, view, button, count):
    """"""Messages should disappear when we click on them.""""""
    view.show_message(usertypes.MessageLevel.info, 'test mouse click')
    view.show_message(usertypes.MessageLevel.info, 'test mouse click 2')
    qtbot.mousePress(view, button)
    assert len(view._messages) == count
","
1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2016-2021 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <https://www.gnu.org/licenses/>.
19
20import pytest
21from PyQt5.QtCore import Qt
22
23from qutebrowser.mainwindow import messageview
24from qutebrowser.utils import usertypes
25
26
27@pytest.fixture
28def view(qtbot, config_stub):
29    config_stub.val.messages.timeout = 100
30    mv = messageview.MessageView()
31    qtbot.add_widget(mv)
32    return mv
33
34
35@pytest.mark.parametrize('level', [usertypes.MessageLevel.info,
36                                   usertypes.MessageLevel.warning,
37                                   usertypes.MessageLevel.error])
38@pytest.mark.flaky  # on macOS
39def test_single_message(qtbot, view, level):
40    with qtbot.waitExposed(view, timeout=5000):
41        view.show_message(level, 'test')
42
43
44def test_message_hiding(qtbot, view):
45    """"""Messages should be hidden after the timer times out.""""""
46    with qtbot.waitSignal(view._clear_timer.timeout):
47        view.show_message(usertypes.MessageLevel.info, 'test')
48
49
50def test_size_hint(view):
51    """"""The message height should increase with more messages.""""""
52    view.show_message(usertypes.MessageLevel.info, 'test1')
53    height1 = view.sizeHint().height()
54    view.show_message(usertypes.MessageLevel.info, 'test2')
55    height2 = view.sizeHint().height()
56
57
58def test_word_wrap(view, qtbot):
59    """"""A long message should be wrapped.""""""
60    with qtbot.waitSignal(view._clear_timer.timeout):
61        view.show_message(usertypes.MessageLevel.info, 'short')
62        height1 = view.sizeHint().height()
63
64    text = (""Athene, the bright-eyed goddess, answered him at once: Father of ""
65            ""us all, Son of Cronos, Highest King, clearly that man deserved to be ""
66            ""destroyed: so let all be destroyed who act as he did. But my heart aches ""
67            ""for Odysseus, wise but ill fated, who suffers far from his friends on an ""
68            ""island deep in the sea."")
69
70    view.show_message(usertypes.MessageLevel.info, text)
71    height2 = view.sizeHint().height()
72
73
74
75def test_show_message_twice(view):
76    """"""Show the same message twice -> only one should be shown.""""""
77    view.show_message(usertypes.MessageLevel.info, 'test')
78    view.show_message(usertypes.MessageLevel.info, 'test')
79
80
81def test_show_message_twice_after_first_disappears(qtbot, view):
82    """"""Show the same message twice after the first is gone.""""""
83    with qtbot.waitSignal(view._clear_timer.timeout):
84        view.show_message(usertypes.MessageLevel.info, 'test')
85    # Just a sanity check
86
87    view.show_message(usertypes.MessageLevel.info, 'test')
88
89
90def test_changing_timer_with_messages_shown(qtbot, view, config_stub):
91    """"""When we change messages.timeout, the timer should be restarted.""""""
92    config_stub.val.messages.timeout = 900000  # 15s
93    view.show_message(usertypes.MessageLevel.info, 'test')
94    with qtbot.waitSignal(view._clear_timer.timeout):
95        config_stub.val.messages.timeout = 100
96
97
98@pytest.mark.parametrize('count, expected', [(1, 100), (3, 300),
99                                             (5, 500), (7, 500)])
100def test_show_multiple_messages_longer(view, count, expected):
101    """"""When there are multiple messages, messages should be shown longer.
102
103    There is an upper maximum to avoid messages never disappearing.
104    """"""
105    for message_number in range(1, count+1):
106        view.show_message(usertypes.MessageLevel.info,
107                          'test ' + str(message_number))
108
109
110@pytest.mark.parametrize('replace1, replace2, length', [
111    (False, False, 2),    # Two stacked messages
112    (True, True, 1),  # Two replaceable messages
113    (False, True, 2),  # Stacked and replaceable
114    (True, False, 2),  # Replaceable and stacked
115])
116def test_replaced_messages(view, replace1, replace2, length):
117    """"""Show two stack=False messages which should replace each other.""""""
118    view.show_message(usertypes.MessageLevel.info, 'test', replace=replace1)
119    view.show_message(usertypes.MessageLevel.info, 'test 2', replace=replace2)
120
121
122@pytest.mark.parametrize('button, count', [
123    (Qt.LeftButton, 0),
124    (Qt.MiddleButton, 0),
125    (Qt.RightButton, 0),
126    (Qt.BackButton, 2),
127])
128def test_click_messages(qtbot, view, button, count):
129    """"""Messages should disappear when we click on them.""""""
130    view.show_message(usertypes.MessageLevel.info, 'test mouse click')
131    view.show_message(usertypes.MessageLevel.info, 'test mouse click 2')
132    qtbot.mousePress(view, button)
133","[['view._messages[0].isVisible()', '==', 'True'], ['view._messages', '==', 'False'], ['height1', '>', '0'], ['height2', '==', 'height1 * 2'], ['height1', '>', '0'], ['height2', '>', 'height1'], ['view._messages[0].wordWrap()', '==', 'True'], ['len(view._messages)', '==', '1'], ['view._messages', '==', 'False'], ['len(view._messages)', '==', '1'], ['view._clear_timer.interval()', '==', 'expected'], ['len(view._messages)', '==', 'length'], ['len(view._messages)', '==', 'count']]",13,13,1.0,0.0023406553835073,"['qtbot', 'config_stub', 'config_stub.val.messages.timeout', 'mv', 'view', 'level', 'height1', 'height2', 'text', 'count', 'expected', 'replace1', 'replace2', 'length', 'button']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['qtbot', 'config_stub', 'config_stub.val.messages.timeout', 'mv', 'view', 'level', 'height1', 'height2', 'text', 'count', 'expected', 'replace1', 'replace2', 'length', 'button']
*Code:

1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2016-2021 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <https://www.gnu.org/licenses/>.
19
20import pytest
21from PyQt5.QtCore import Qt
22
23from qutebrowser.mainwindow import messageview
24from qutebrowser.utils import usertypes
25
26
27@pytest.fixture
28def view(qtbot, config_stub):
29    config_stub.val.messages.timeout = 100
30    mv = messageview.MessageView()
31    qtbot.add_widget(mv)
32    return mv
33
34
35@pytest.mark.parametrize('level', [usertypes.MessageLevel.info,
36                                   usertypes.MessageLevel.warning,
37                                   usertypes.MessageLevel.error])
38@pytest.mark.flaky  # on macOS
39def test_single_message(qtbot, view, level):
40    with qtbot.waitExposed(view, timeout=5000):
41        view.show_message(level, 'test')
42
43
44def test_message_hiding(qtbot, view):
45    """"""Messages should be hidden after the timer times out.""""""
46    with qtbot.waitSignal(view._clear_timer.timeout):
47        view.show_message(usertypes.MessageLevel.info, 'test')
48
49
50def test_size_hint(view):
51    """"""The message height should increase with more messages.""""""
52    view.show_message(usertypes.MessageLevel.info, 'test1')
53    height1 = view.sizeHint().height()
54    view.show_message(usertypes.MessageLevel.info, 'test2')
55    height2 = view.sizeHint().height()
56
57
58def test_word_wrap(view, qtbot):
59    """"""A long message should be wrapped.""""""
60    with qtbot.waitSignal(view._clear_timer.timeout):
61        view.show_message(usertypes.MessageLevel.info, 'short')
62        height1 = view.sizeHint().height()
63
64    text = (""Athene, the bright-eyed goddess, answered him at once: Father of ""
65            ""us all, Son of Cronos, Highest King, clearly that man deserved to be ""
66            ""destroyed: so let all be destroyed who act as he did. But my heart aches ""
67            ""for Odysseus, wise but ill fated, who suffers far from his friends on an ""
68            ""island deep in the sea."")
69
70    view.show_message(usertypes.MessageLevel.info, text)
71    height2 = view.sizeHint().height()
72
73
74
75def test_show_message_twice(view):
76    """"""Show the same message twice -> only one should be shown.""""""
77    view.show_message(usertypes.MessageLevel.info, 'test')
78    view.show_message(usertypes.MessageLevel.info, 'test')
79
80
81def test_show_message_twice_after_first_disappears(qtbot, view):
82    """"""Show the same message twice after the first is gone.""""""
83    with qtbot.waitSignal(view._clear_timer.timeout):
84        view.show_message(usertypes.MessageLevel.info, 'test')
85    # Just a sanity check
86
87    view.show_message(usertypes.MessageLevel.info, 'test')
88
89
90def test_changing_timer_with_messages_shown(qtbot, view, config_stub):
91    """"""When we change messages.timeout, the timer should be restarted.""""""
92    config_stub.val.messages.timeout = 900000  # 15s
93    view.show_message(usertypes.MessageLevel.info, 'test')
94    with qtbot.waitSignal(view._clear_timer.timeout):
95        config_stub.val.messages.timeout = 100
96
97
98@pytest.mark.parametrize('count, expected', [(1, 100), (3, 300),
99                                             (5, 500), (7, 500)])
100def test_show_multiple_messages_longer(view, count, expected):
101    """"""When there are multiple messages, messages should be shown longer.
102
103    There is an upper maximum to avoid messages never disappearing.
104    """"""
105    for message_number in range(1, count+1):
106        view.show_message(usertypes.MessageLevel.info,
107                          'test ' + str(message_number))
108
109
110@pytest.mark.parametrize('replace1, replace2, length', [
111    (False, False, 2),    # Two stacked messages
112    (True, True, 1),  # Two replaceable messages
113    (False, True, 2),  # Stacked and replaceable
114    (True, False, 2),  # Replaceable and stacked
115])
116def test_replaced_messages(view, replace1, replace2, length):
117    """"""Show two stack=False messages which should replace each other.""""""
118    view.show_message(usertypes.MessageLevel.info, 'test', replace=replace1)
119    view.show_message(usertypes.MessageLevel.info, 'test 2', replace=replace2)
120
121
122@pytest.mark.parametrize('button, count', [
123    (Qt.LeftButton, 0),
124    (Qt.MiddleButton, 0),
125    (Qt.RightButton, 0),
126    (Qt.BackButton, 2),
127])
128def test_click_messages(qtbot, view, button, count):
129    """"""Messages should disappear when we click on them.""""""
130    view.show_message(usertypes.MessageLevel.info, 'test mouse click')
131    view.show_message(usertypes.MessageLevel.info, 'test mouse click 2')
132    qtbot.mousePress(view, button)
133",6945,"[[28, 'config_stub.val.messages.timeout', >=, 0, ""The timeout value must be a positive integer to delay the next action""],
 [40, 'level', !=, None, ""The message level should be defined""],
 [64, 'text', !=, None, ""The text message should not be empty""],
 [105, 'count', >=, 0, ""The count of messages should be a positive integer""],
 [116, 'length', >=, 0, ""The length of the message should be a positive integer""],
 [128, 'count', >=, 0, ""The count of messages should be a positive integer to show the number of messages""]]"
AdaHeads/Coverage_Tests,"__author__ = 'krc'

####
#
#  Tests protocol interface documented at:
#  https://github.com/AdaHeads/DatabaseServers/wiki/Server-Reception
#

import config
import logging
import time


# Exceptions
from database_reception import Server_404, Database_Reception

try:
    import unittest2 as unittest
except ImportError:
    import unittest

class Reception_List(unittest.TestCase):

    log = logging.getLogger(__name__)
    server = Database_Reception(uri=config.reception_server_uri,authtoken=config.global_token)

    def test_CORS_headers_present(self):
        headers, body = self.server.Request (""/nonexistingpath"", exceptions=False)
        assert 'access-control-allow-origin' in headers or 'Access-Control-Allow-Origin' in headers

        reception_id = 1

        self.log.info (""Looking up reception "" + str(reception_id) +""."")
        headers, body = self.server.Request(""/reception/""+str(reception_id))
        assert 'access-control-allow-origin' in headers or 'Access-Control-Allow-Origin' in headers

    def test_nonexisting_uri(self):
        try:
            self.server.Request (""/nonexistingpath"")
        except Server_404:
            return

        self.fail(""Expected 404 here."")

    def test_found(self):
        reception_id = 1

        self.log.info (""Looking up reception "" + str(reception_id))
        reception = self.server.get (reception_id=reception_id)

    def test_found_single(self):
        reception_id = 1

        self.log.info (""Looking up reception "" + str(reception_id) +""."")
        self.server.get (reception_id=reception_id)

    def test_not_found_single(self):
        reception_id = -1

        self.log.info (""Looking up reception "" + str(reception_id) +""."")
        try:
            self.server.get (reception_id=reception_id)
        except Server_404:
            return

        self.fail(""Expected 404 here."")

    def test_calendar_single_lookup_single(self):
        reception_id = 1
        event_id     = 4

        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
        event = self.server.calendar_event (reception_id = reception_id,
                                            event_id     = event_id)

    def test_calendar_create(self):
        start        = time.time() #NOW

        reception_id = 1

        event        = {'event' : {'start'  : int(start),
                                   'stop'   : int(start)+3600,
                                   'content': 'Merely a reception event test.'}}

        self.log.info (""Looking up reception "" + str(reception_id) +""."")
        response = self.server.calendar_event_create (reception_id = reception_id,
                                                      event        = event)

    def test_calendar_update(self):
        start        = time.time() #NOW

        reception_id = 1

        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']

        last_event      = events[-1]

        event        = self.server.calendar_event (reception_id = reception_id,
                                                   event_id     = last_event['id'])
        # bump start time
        event['event']['start'] = int(start)
        event['event']['stop']  = int(start)+3600

        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
        response = self.server.calendar_event_update (reception_id = reception_id,
                                                      event_id     = last_event['id'],
                                                      event        = event)


        remote_event = self.server.calendar_event (reception_id = reception_id,
                                                   event_id     = last_event['id'])

        assert (event['event']['start']   == remote_event['event']['start'])
        assert (event['event']['stop']    == remote_event['event']['stop'])
        assert (event['event']['content'] == remote_event['event']['content'])


    def test_calendar_list(self):
        reception_id = 1

        events = self.server.calendar_events (reception_id = reception_id)

    def test_calendar_delete(self):
        reception_id = 1

        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']

        previous_length = len(events)
        last_event      = events[-1]

        response = self.server.calendar_event_delete (reception_id = reception_id,
                                                      event_id     = last_event['id'])
        #Refetch the event list
        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']

        assert (len(events) != previous_length)

        self.log.info (""Looking up calendar of reception "" + str(reception_id) +""."")
        try:
           self.server.calendar_event (reception_id = reception_id,
                                       event_id     = last_event['id'])
        except Server_404:
            return

        self.fail(""Expected 404 here."")
","
1__author__ = 'krc'
2
3####
4#
5#  Tests protocol interface documented at:
6#  https://github.com/AdaHeads/DatabaseServers/wiki/Server-Reception
7#
8
9import config
10import logging
11import time
12
13
14# Exceptions
15from database_reception import Server_404, Database_Reception
16
17try:
18    import unittest2 as unittest
19except ImportError:
20    import unittest
21
22class Reception_List(unittest.TestCase):
23
24    log = logging.getLogger(__name__)
25    server = Database_Reception(uri=config.reception_server_uri,authtoken=config.global_token)
26
27    def test_CORS_headers_present(self):
28        headers, body = self.server.Request (""/nonexistingpath"", exceptions=False)
29
30        reception_id = 1
31
32        self.log.info (""Looking up reception "" + str(reception_id) +""."")
33        headers, body = self.server.Request(""/reception/""+str(reception_id))
34
35    def test_nonexisting_uri(self):
36        try:
37            self.server.Request (""/nonexistingpath"")
38        except Server_404:
39            return
40
41        self.fail(""Expected 404 here."")
42
43    def test_found(self):
44        reception_id = 1
45
46        self.log.info (""Looking up reception "" + str(reception_id))
47        reception = self.server.get (reception_id=reception_id)
48
49    def test_found_single(self):
50        reception_id = 1
51
52        self.log.info (""Looking up reception "" + str(reception_id) +""."")
53        self.server.get (reception_id=reception_id)
54
55    def test_not_found_single(self):
56        reception_id = -1
57
58        self.log.info (""Looking up reception "" + str(reception_id) +""."")
59        try:
60            self.server.get (reception_id=reception_id)
61        except Server_404:
62            return
63
64        self.fail(""Expected 404 here."")
65
66    def test_calendar_single_lookup_single(self):
67        reception_id = 1
68        event_id     = 4
69
70        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
71        event = self.server.calendar_event (reception_id = reception_id,
72                                            event_id     = event_id)
73
74    def test_calendar_create(self):
75        start        = time.time() #NOW
76
77        reception_id = 1
78
79        event        = {'event' : {'start'  : int(start),
80                                   'stop'   : int(start)+3600,
81                                   'content': 'Merely a reception event test.'}}
82
83        self.log.info (""Looking up reception "" + str(reception_id) +""."")
84        response = self.server.calendar_event_create (reception_id = reception_id,
85                                                      event        = event)
86
87    def test_calendar_update(self):
88        start        = time.time() #NOW
89
90        reception_id = 1
91
92        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
93
94        last_event      = events[-1]
95
96        event        = self.server.calendar_event (reception_id = reception_id,
97                                                   event_id     = last_event['id'])
98        # bump start time
99        event['event']['start'] = int(start)
100        event['event']['stop']  = int(start)+3600
101
102        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
103        response = self.server.calendar_event_update (reception_id = reception_id,
104                                                      event_id     = last_event['id'],
105                                                      event        = event)
106
107
108        remote_event = self.server.calendar_event (reception_id = reception_id,
109                                                   event_id     = last_event['id'])
110
111
112
113    def test_calendar_list(self):
114        reception_id = 1
115
116        events = self.server.calendar_events (reception_id = reception_id)
117
118    def test_calendar_delete(self):
119        reception_id = 1
120
121        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
122
123        previous_length = len(events)
124        last_event      = events[-1]
125
126        response = self.server.calendar_event_delete (reception_id = reception_id,
127                                                      event_id     = last_event['id'])
128        #Refetch the event list
129        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
130
131
132        self.log.info (""Looking up calendar of reception "" + str(reception_id) +""."")
133        try:
134           self.server.calendar_event (reception_id = reception_id,
135                                       event_id     = last_event['id'])
136        except Server_404:
137            return
138
139        self.fail(""Expected 404 here."")
140","[[""(event['event']['start']"", '==', ""remote_event['event']['start'])""], [""(event['event']['stop']"", '==', ""remote_event['event']['stop'])""], [""(event['event']['content']"", '==', ""remote_event['event']['content'])""], ['(len(events)', '!=', 'previous_length)']]",6,4,0.6666666666666666,0.0007963368504877,"['__author__', 'log', 'server', 'headers', 'body', 'reception_id', 'reception', 'event_id', 'event', 'start', 'response', 'events', 'last_event', ""event['event']['start']"", ""event['event']['stop']"", 'remote_event', 'previous_length', 'self.server.calendar_event (reception_id']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'log', 'server', 'headers', 'body', 'reception_id', 'reception', 'event_id', 'event', 'start', 'response', 'events', 'last_event', ""event['event']['start']"", ""event['event']['stop']"", 'remote_event', 'previous_length', 'self.server.calendar_event (reception_id']
*Code:

1__author__ = 'krc'
2
3####
4#
5#  Tests protocol interface documented at:
6#  https://github.com/AdaHeads/DatabaseServers/wiki/Server-Reception
7#
8
9import config
10import logging
11import time
12
13
14# Exceptions
15from database_reception import Server_404, Database_Reception
16
17try:
18    import unittest2 as unittest
19except ImportError:
20    import unittest
21
22class Reception_List(unittest.TestCase):
23
24    log = logging.getLogger(__name__)
25    server = Database_Reception(uri=config.reception_server_uri,authtoken=config.global_token)
26
27    def test_CORS_headers_present(self):
28        headers, body = self.server.Request (""/nonexistingpath"", exceptions=False)
29
30        reception_id = 1
31
32        self.log.info (""Looking up reception "" + str(reception_id) +""."")
33        headers, body = self.server.Request(""/reception/""+str(reception_id))
34
35    def test_nonexisting_uri(self):
36        try:
37            self.server.Request (""/nonexistingpath"")
38        except Server_404:
39            return
40
41        self.fail(""Expected 404 here."")
42
43    def test_found(self):
44        reception_id = 1
45
46        self.log.info (""Looking up reception "" + str(reception_id))
47        reception = self.server.get (reception_id=reception_id)
48
49    def test_found_single(self):
50        reception_id = 1
51
52        self.log.info (""Looking up reception "" + str(reception_id) +""."")
53        self.server.get (reception_id=reception_id)
54
55    def test_not_found_single(self):
56        reception_id = -1
57
58        self.log.info (""Looking up reception "" + str(reception_id) +""."")
59        try:
60            self.server.get (reception_id=reception_id)
61        except Server_404:
62            return
63
64        self.fail(""Expected 404 here."")
65
66    def test_calendar_single_lookup_single(self):
67        reception_id = 1
68        event_id     = 4
69
70        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
71        event = self.server.calendar_event (reception_id = reception_id,
72                                            event_id     = event_id)
73
74    def test_calendar_create(self):
75        start        = time.time() #NOW
76
77        reception_id = 1
78
79        event        = {'event' : {'start'  : int(start),
80                                   'stop'   : int(start)+3600,
81                                   'content': 'Merely a reception event test.'}}
82
83        self.log.info (""Looking up reception "" + str(reception_id) +""."")
84        response = self.server.calendar_event_create (reception_id = reception_id,
85                                                      event        = event)
86
87    def test_calendar_update(self):
88        start        = time.time() #NOW
89
90        reception_id = 1
91
92        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
93
94        last_event      = events[-1]
95
96        event        = self.server.calendar_event (reception_id = reception_id,
97                                                   event_id     = last_event['id'])
98        # bump start time
99        event['event']['start'] = int(start)
100        event['event']['stop']  = int(start)+3600
101
102        self.log.info (""Looking up contact reception "" + str(reception_id) +""."")
103        response = self.server.calendar_event_update (reception_id = reception_id,
104                                                      event_id     = last_event['id'],
105                                                      event        = event)
106
107
108        remote_event = self.server.calendar_event (reception_id = reception_id,
109                                                   event_id     = last_event['id'])
110
111
112
113    def test_calendar_list(self):
114        reception_id = 1
115
116        events = self.server.calendar_events (reception_id = reception_id)
117
118    def test_calendar_delete(self):
119        reception_id = 1
120
121        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
122
123        previous_length = len(events)
124        last_event      = events[-1]
125
126        response = self.server.calendar_event_delete (reception_id = reception_id,
127                                                      event_id     = last_event['id'])
128        #Refetch the event list
129        events = self.server.calendar_events (reception_id = reception_id)['CalendarEvents']
130
131
132        self.log.info (""Looking up calendar of reception "" + str(reception_id) +""."")
133        try:
134           self.server.calendar_event (reception_id = reception_id,
135                                       event_id     = last_event['id'])
136        except Server_404:
137            return
138
139        self.fail(""Expected 404 here."")
140",6513,"[[30, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'],
[44, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[50, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[56, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[67, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'],
[68, 'event_id', '>=', 1, 'event_id should be a positive integer, since negative or zero values are invalid for id\'s'],
[75, 'start', '>', 0, 'start time should be a positive number, since time cannot be negative or zero'], 
[78, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[88, 'start', '>', 0, 'start time should be a positive number, since time cannot be negative or zero'], 
[90, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'],
[98, ""event['event']['start']"", '>', 0, 'event start time should be a positive number, since time cannot be negative or zero'], 
[99, ""event['event']['stop']"", '>', ""event['event']['start']"", 'event stop time should be greater than the start time'], 
[114, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[119, 'reception_id', '>=', 1, 'reception_id should be a positive integer, since negative or zero values are invalid for id\'s'], 
[129, 'events', '!=', 'previous_length', 'the length of the events list should decrease after delete operation']]"
gauthierm/bedrock,"# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.

from selenium.webdriver.common.by import By
from selenium.webdriver.support.select import Select

from pages.firefox.base import FirefoxBasePage, FirefoxBasePageRegion
from pages.regions.modal import Modal


class DevicesPage(FirefoxBasePage):

    _url = '{base_url}/{locale}/firefox/os/devices'

    _location_select_locator = (By.ID, 'location')
    _get_phone_button_locator = (By.CSS_SELECTOR, '.location-select-wrapper button')
    _phone_thumbnail_locator = (By.CSS_SELECTOR, '#smartphones li:first-child > .device-thumbnail')
    _phone_detail_locator = (By.CSS_SELECTOR, '.smartphone-detail-list .device-detail:first-child')
    _tv_thumbnail_locator = (By.CSS_SELECTOR, '#tvs li:first-child > .device-thumbnail')
    _tv_detail_locator = (By.CSS_SELECTOR, '.tvs-detail-list .device-detail:first-child')

    def select_location(self, value):
        el = self.find_element(self._location_select_locator)
        Select(el).select_by_visible_text(value)
        self.wait.until(lambda s: self.is_get_a_phone_enabled)

    @property
    def is_get_a_phone_enabled(self):
        return self.find_element(self._get_phone_button_locator).is_enabled()

    def get_a_phone(self):
        modal = Modal(self)
        self.find_element(self._get_phone_button_locator).click()
        self.wait.until(lambda s: modal.is_displayed)
        return modal

    def open_phone_detail(self):
        self.scroll_element_into_view(self._phone_thumbnail_locator).click()
        el = self.find_element(self._phone_detail_locator)
        detail = DeviceDetail(self, root=el)
        # wait until close button is displayed for detail pane to initialize
        self.wait.until(lambda s: detail.is_close_displayed)
        return detail

    def open_tv_detail(self):
        self.scroll_element_into_view(self._tv_thumbnail_locator).click()
        el = self.find_element(self._tv_detail_locator)
        detail = DeviceDetail(self, root=el)
        self.find_element(self._tv_thumbnail_locator).click()
        # wait until close button is displayed for detail pane to initialize
        self.wait.until(lambda s: detail.is_close_displayed)
        return detail


class DeviceDetail(FirefoxBasePageRegion):

    _detail_locator = (By.CSS_SELECTOR, '.container')
    _features_locator = (By.CSS_SELECTOR, '.features')
    _specifications_locator = (By.CSS_SELECTOR, '.specifications')
    _close_button_locator = (By.CSS_SELECTOR, '.device-detail-close')
    _features_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:first-child > a')
    _specifications_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:last-child > a')

    @property
    def is_displayed(self):
        return self.is_element_displayed(self._detail_locator)

    @property
    def is_features_displayed(self):
        return self.is_element_displayed(self._features_locator)

    @property
    def is_specifications_displayed(self):
        return self.is_element_displayed(self._specifications_locator)

    @property
    def is_close_displayed(self):
        return self.is_element_displayed(self._close_button_locator)

    def show_specifications(self):
        assert not self.is_specifications_displayed, 'Specifications tab is already displayed'
        self.scroll_element_into_view(self._specifications_link_locator).click()
        self.wait.until(lambda s: self.is_specifications_displayed)

    def show_features(self):
        assert not self.is_features_displayed, 'Features tab is already displayed'
        self.scroll_element_into_view(self._features_link_locator).click()
        self.wait.until(lambda s: self.is_features_displayed)

    def close(self):
        self.scroll_element_into_view(self._close_button_locator).click()
        self.wait.until(lambda s: not self.is_displayed)
","
1# This Source Code Form is subject to the terms of the Mozilla Public
2# License, v. 2.0. If a copy of the MPL was not distributed with this
3# file, You can obtain one at http://mozilla.org/MPL/2.0/.
4
5from selenium.webdriver.common.by import By
6from selenium.webdriver.support.select import Select
7
8from pages.firefox.base import FirefoxBasePage, FirefoxBasePageRegion
9from pages.regions.modal import Modal
10
11
12class DevicesPage(FirefoxBasePage):
13
14    _url = '{base_url}/{locale}/firefox/os/devices'
15
16    _location_select_locator = (By.ID, 'location')
17    _get_phone_button_locator = (By.CSS_SELECTOR, '.location-select-wrapper button')
18    _phone_thumbnail_locator = (By.CSS_SELECTOR, '#smartphones li:first-child > .device-thumbnail')
19    _phone_detail_locator = (By.CSS_SELECTOR, '.smartphone-detail-list .device-detail:first-child')
20    _tv_thumbnail_locator = (By.CSS_SELECTOR, '#tvs li:first-child > .device-thumbnail')
21    _tv_detail_locator = (By.CSS_SELECTOR, '.tvs-detail-list .device-detail:first-child')
22
23    def select_location(self, value):
24        el = self.find_element(self._location_select_locator)
25        Select(el).select_by_visible_text(value)
26        self.wait.until(lambda s: self.is_get_a_phone_enabled)
27
28    @property
29    def is_get_a_phone_enabled(self):
30        return self.find_element(self._get_phone_button_locator).is_enabled()
31
32    def get_a_phone(self):
33        modal = Modal(self)
34        self.find_element(self._get_phone_button_locator).click()
35        self.wait.until(lambda s: modal.is_displayed)
36        return modal
37
38    def open_phone_detail(self):
39        self.scroll_element_into_view(self._phone_thumbnail_locator).click()
40        el = self.find_element(self._phone_detail_locator)
41        detail = DeviceDetail(self, root=el)
42        # wait until close button is displayed for detail pane to initialize
43        self.wait.until(lambda s: detail.is_close_displayed)
44        return detail
45
46    def open_tv_detail(self):
47        self.scroll_element_into_view(self._tv_thumbnail_locator).click()
48        el = self.find_element(self._tv_detail_locator)
49        detail = DeviceDetail(self, root=el)
50        self.find_element(self._tv_thumbnail_locator).click()
51        # wait until close button is displayed for detail pane to initialize
52        self.wait.until(lambda s: detail.is_close_displayed)
53        return detail
54
55
56class DeviceDetail(FirefoxBasePageRegion):
57
58    _detail_locator = (By.CSS_SELECTOR, '.container')
59    _features_locator = (By.CSS_SELECTOR, '.features')
60    _specifications_locator = (By.CSS_SELECTOR, '.specifications')
61    _close_button_locator = (By.CSS_SELECTOR, '.device-detail-close')
62    _features_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:first-child > a')
63    _specifications_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:last-child > a')
64
65    @property
66    def is_displayed(self):
67        return self.is_element_displayed(self._detail_locator)
68
69    @property
70    def is_features_displayed(self):
71        return self.is_element_displayed(self._features_locator)
72
73    @property
74    def is_specifications_displayed(self):
75        return self.is_element_displayed(self._specifications_locator)
76
77    @property
78    def is_close_displayed(self):
79        return self.is_element_displayed(self._close_button_locator)
80
81    def show_specifications(self):
82        self.scroll_element_into_view(self._specifications_link_locator).click()
83        self.wait.until(lambda s: self.is_specifications_displayed)
84
85    def show_features(self):
86        self.scroll_element_into_view(self._features_link_locator).click()
87        self.wait.until(lambda s: self.is_features_displayed)
88
89    def close(self):
90        self.scroll_element_into_view(self._close_button_locator).click()
91        self.wait.until(lambda s: not self.is_displayed)
92","[['self.is_specifications_displayed', '==', 'False'], ['self.is_features_displayed', '==', 'False']]",2,2,1.0,0.00050390526581,"['_url', '_location_select_locator', '_get_phone_button_locator', '_phone_thumbnail_locator', '_phone_detail_locator', '_tv_thumbnail_locator', '_tv_detail_locator', 'value', 'el', 'modal', 'detail', '_detail_locator', '_features_locator', '_specifications_locator', '_close_button_locator', '_features_link_locator', '_specifications_link_locator']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_url', '_location_select_locator', '_get_phone_button_locator', '_phone_thumbnail_locator', '_phone_detail_locator', '_tv_thumbnail_locator', '_tv_detail_locator', 'value', 'el', 'modal', 'detail', '_detail_locator', '_features_locator', '_specifications_locator', '_close_button_locator', '_features_link_locator', '_specifications_link_locator']
*Code:

1# This Source Code Form is subject to the terms of the Mozilla Public
2# License, v. 2.0. If a copy of the MPL was not distributed with this
3# file, You can obtain one at http://mozilla.org/MPL/2.0/.
4
5from selenium.webdriver.common.by import By
6from selenium.webdriver.support.select import Select
7
8from pages.firefox.base import FirefoxBasePage, FirefoxBasePageRegion
9from pages.regions.modal import Modal
10
11
12class DevicesPage(FirefoxBasePage):
13
14    _url = '{base_url}/{locale}/firefox/os/devices'
15
16    _location_select_locator = (By.ID, 'location')
17    _get_phone_button_locator = (By.CSS_SELECTOR, '.location-select-wrapper button')
18    _phone_thumbnail_locator = (By.CSS_SELECTOR, '#smartphones li:first-child > .device-thumbnail')
19    _phone_detail_locator = (By.CSS_SELECTOR, '.smartphone-detail-list .device-detail:first-child')
20    _tv_thumbnail_locator = (By.CSS_SELECTOR, '#tvs li:first-child > .device-thumbnail')
21    _tv_detail_locator = (By.CSS_SELECTOR, '.tvs-detail-list .device-detail:first-child')
22
23    def select_location(self, value):
24        el = self.find_element(self._location_select_locator)
25        Select(el).select_by_visible_text(value)
26        self.wait.until(lambda s: self.is_get_a_phone_enabled)
27
28    @property
29    def is_get_a_phone_enabled(self):
30        return self.find_element(self._get_phone_button_locator).is_enabled()
31
32    def get_a_phone(self):
33        modal = Modal(self)
34        self.find_element(self._get_phone_button_locator).click()
35        self.wait.until(lambda s: modal.is_displayed)
36        return modal
37
38    def open_phone_detail(self):
39        self.scroll_element_into_view(self._phone_thumbnail_locator).click()
40        el = self.find_element(self._phone_detail_locator)
41        detail = DeviceDetail(self, root=el)
42        # wait until close button is displayed for detail pane to initialize
43        self.wait.until(lambda s: detail.is_close_displayed)
44        return detail
45
46    def open_tv_detail(self):
47        self.scroll_element_into_view(self._tv_thumbnail_locator).click()
48        el = self.find_element(self._tv_detail_locator)
49        detail = DeviceDetail(self, root=el)
50        self.find_element(self._tv_thumbnail_locator).click()
51        # wait until close button is displayed for detail pane to initialize
52        self.wait.until(lambda s: detail.is_close_displayed)
53        return detail
54
55
56class DeviceDetail(FirefoxBasePageRegion):
57
58    _detail_locator = (By.CSS_SELECTOR, '.container')
59    _features_locator = (By.CSS_SELECTOR, '.features')
60    _specifications_locator = (By.CSS_SELECTOR, '.specifications')
61    _close_button_locator = (By.CSS_SELECTOR, '.device-detail-close')
62    _features_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:first-child > a')
63    _specifications_link_locator = (By.CSS_SELECTOR, '.pager-tabs li:last-child > a')
64
65    @property
66    def is_displayed(self):
67        return self.is_element_displayed(self._detail_locator)
68
69    @property
70    def is_features_displayed(self):
71        return self.is_element_displayed(self._features_locator)
72
73    @property
74    def is_specifications_displayed(self):
75        return self.is_element_displayed(self._specifications_locator)
76
77    @property
78    def is_close_displayed(self):
79        return self.is_element_displayed(self._close_button_locator)
80
81    def show_specifications(self):
82        self.scroll_element_into_view(self._specifications_link_locator).click()
83        self.wait.until(lambda s: self.is_specifications_displayed)
84
85    def show_features(self):
86        self.scroll_element_into_view(self._features_link_locator).click()
87        self.wait.until(lambda s: self.is_features_displayed)
88
89    def close(self):
90        self.scroll_element_into_view(self._close_button_locator).click()
91        self.wait.until(lambda s: not self.is_displayed)
92",5696,"[[23, 'value', '!=', None, ""function select_location requires a non-null input""], 
 [32, 'modal', '!=', None, ""function get_a_phone requires a non-null modal""], 
 [39, 'el', '!=', None, ""function open_phone_detail requires a non-null element""], 
 [47, 'el', '!=', None, ""function open_tv_detail requires a non-null element""],
 [81, '_specifications_link_locator', '!=', None, ""function show_specifications requires a non-null link locator""],
 [85, '_features_link_locator', '!=', None, ""function show_features requires a non-null link locator""],
 [89, '_close_button_locator', '!=', None, ""function close requires a non-null button locator""]]"
robbiet480/home-assistant,"""""""Test cors for the HTTP component.""""""
from pathlib import Path

from aiohttp import web
from aiohttp.hdrs import (
    ACCESS_CONTROL_ALLOW_HEADERS,
    ACCESS_CONTROL_ALLOW_ORIGIN,
    ACCESS_CONTROL_REQUEST_HEADERS,
    ACCESS_CONTROL_REQUEST_METHOD,
    AUTHORIZATION,
    ORIGIN,
)
import pytest

from homeassistant.components.http.cors import setup_cors
from homeassistant.components.http.view import HomeAssistantView
from homeassistant.setup import async_setup_component

from . import HTTP_HEADER_HA_AUTH

from tests.async_mock import patch

TRUSTED_ORIGIN = ""https://home-assistant.io""


async def test_cors_middleware_loaded_by_default(hass):
    """"""Test accessing to server from banned IP when feature is off.""""""
    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
        await async_setup_component(hass, ""http"", {""http"": {}})

    assert len(mock_setup.mock_calls) == 1


async def test_cors_middleware_loaded_from_config(hass):
    """"""Test accessing to server from banned IP when feature is off.""""""
    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
        await async_setup_component(
            hass,
            ""http"",
            {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
        )

    assert len(mock_setup.mock_calls) == 1


async def mock_handler(request):
    """"""Return if request was authenticated.""""""
    return web.Response(status=200)


@pytest.fixture
def client(loop, aiohttp_client):
    """"""Fixture to set up a web.Application.""""""
    app = web.Application()
    app.router.add_get(""/"", mock_handler)
    setup_cors(app, [TRUSTED_ORIGIN])
    return loop.run_until_complete(aiohttp_client(app))


async def test_cors_requests(client):
    """"""Test cross origin requests.""""""
    req = await client.get(""/"", headers={ORIGIN: TRUSTED_ORIGIN})
    assert req.status == 200
    assert req.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == TRUSTED_ORIGIN

    # With password in URL
    req = await client.get(
        ""/"", params={""api_password"": ""some-pass""}, headers={ORIGIN: TRUSTED_ORIGIN}
    )
    assert req.status == 200
    assert req.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == TRUSTED_ORIGIN

    # With password in headers
    req = await client.get(
        ""/"", headers={HTTP_HEADER_HA_AUTH: ""some-pass"", ORIGIN: TRUSTED_ORIGIN}
    )
    assert req.status == 200
    assert req.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == TRUSTED_ORIGIN

    # With auth token in headers
    req = await client.get(
        ""/"", headers={AUTHORIZATION: ""Bearer some-token"", ORIGIN: TRUSTED_ORIGIN}
    )
    assert req.status == 200
    assert req.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == TRUSTED_ORIGIN


async def test_cors_preflight_allowed(client):
    """"""Test cross origin resource sharing preflight (OPTIONS) request.""""""
    req = await client.options(
        ""/"",
        headers={
            ORIGIN: TRUSTED_ORIGIN,
            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
            ACCESS_CONTROL_REQUEST_HEADERS: ""x-requested-with"",
        },
    )

    assert req.status == 200
    assert req.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == TRUSTED_ORIGIN
    assert req.headers[ACCESS_CONTROL_ALLOW_HEADERS] == ""X-REQUESTED-WITH""


async def test_cors_middleware_with_cors_allowed_view(hass):
    """"""Test that we can configure cors and have a cors_allowed view.""""""

    class MyView(HomeAssistantView):
        """"""Test view that allows CORS.""""""

        requires_auth = False
        cors_allowed = True

        def __init__(self, url, name):
            """"""Initialize test view.""""""
            self.url = url
            self.name = name

        async def get(self, request):
            """"""Test response.""""""
            return ""test""

    assert await async_setup_component(
        hass, ""http"", {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}}
    )

    hass.http.register_view(MyView(""/api/test"", ""api:test""))
    hass.http.register_view(MyView(""/api/test"", ""api:test2""))
    hass.http.register_view(MyView(""/api/test2"", ""api:test""))

    hass.http.app._on_startup.freeze()
    await hass.http.app.startup()


async def test_cors_works_with_frontend(hass, hass_client):
    """"""Test CORS works with the frontend.""""""
    assert await async_setup_component(
        hass,
        ""frontend"",
        {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
    )
    client = await hass_client()
    resp = await client.get(""/"")
    assert resp.status == 200


async def test_cors_on_static_files(hass, hass_client):
    """"""Test that we enable CORS for static files.""""""
    assert await async_setup_component(
        hass, ""frontend"", {""http"": {""cors_allowed_origins"": [""http://www.example.com""]}}
    )
    hass.http.register_static_path(""/something"", str(Path(__file__).parent))

    client = await hass_client()
    resp = await client.options(
        ""/something/__init__.py"",
        headers={
            ""origin"": ""http://www.example.com"",
            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
        },
    )
    assert resp.status == 200
    assert resp.headers[ACCESS_CONTROL_ALLOW_ORIGIN] == ""http://www.example.com""
","
1""""""Test cors for the HTTP component.""""""
2from pathlib import Path
3
4from aiohttp import web
5from aiohttp.hdrs import (
6    ACCESS_CONTROL_ALLOW_HEADERS,
7    ACCESS_CONTROL_ALLOW_ORIGIN,
8    ACCESS_CONTROL_REQUEST_HEADERS,
9    ACCESS_CONTROL_REQUEST_METHOD,
10    AUTHORIZATION,
11    ORIGIN,
12)
13import pytest
14
15from homeassistant.components.http.cors import setup_cors
16from homeassistant.components.http.view import HomeAssistantView
17from homeassistant.setup import async_setup_component
18
19from . import HTTP_HEADER_HA_AUTH
20
21from tests.async_mock import patch
22
23TRUSTED_ORIGIN = ""https://home-assistant.io""
24
25
26async def test_cors_middleware_loaded_by_default(hass):
27    """"""Test accessing to server from banned IP when feature is off.""""""
28    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
29        await async_setup_component(hass, ""http"", {""http"": {}})
30
31
32
33async def test_cors_middleware_loaded_from_config(hass):
34    """"""Test accessing to server from banned IP when feature is off.""""""
35    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
36        await async_setup_component(
37            hass,
38            ""http"",
39            {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
40        )
41
42
43
44async def mock_handler(request):
45    """"""Return if request was authenticated.""""""
46    return web.Response(status=200)
47
48
49@pytest.fixture
50def client(loop, aiohttp_client):
51    """"""Fixture to set up a web.Application.""""""
52    app = web.Application()
53    app.router.add_get(""/"", mock_handler)
54    setup_cors(app, [TRUSTED_ORIGIN])
55    return loop.run_until_complete(aiohttp_client(app))
56
57
58async def test_cors_requests(client):
59    """"""Test cross origin requests.""""""
60    req = await client.get(""/"", headers={ORIGIN: TRUSTED_ORIGIN})
61
62    # With password in URL
63    req = await client.get(
64        ""/"", params={""api_password"": ""some-pass""}, headers={ORIGIN: TRUSTED_ORIGIN}
65    )
66
67    # With password in headers
68    req = await client.get(
69        ""/"", headers={HTTP_HEADER_HA_AUTH: ""some-pass"", ORIGIN: TRUSTED_ORIGIN}
70    )
71
72    # With auth token in headers
73    req = await client.get(
74        ""/"", headers={AUTHORIZATION: ""Bearer some-token"", ORIGIN: TRUSTED_ORIGIN}
75    )
76
77
78async def test_cors_preflight_allowed(client):
79    """"""Test cross origin resource sharing preflight (OPTIONS) request.""""""
80    req = await client.options(
81        ""/"",
82        headers={
83            ORIGIN: TRUSTED_ORIGIN,
84            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
85            ACCESS_CONTROL_REQUEST_HEADERS: ""x-requested-with"",
86        },
87    )
88
89
90
91async def test_cors_middleware_with_cors_allowed_view(hass):
92    """"""Test that we can configure cors and have a cors_allowed view.""""""
93
94    class MyView(HomeAssistantView):
95        """"""Test view that allows CORS.""""""
96
97        requires_auth = False
98        cors_allowed = True
99
100        def __init__(self, url, name):
101            """"""Initialize test view.""""""
102            self.url = url
103            self.name = name
104
105        async def get(self, request):
106            """"""Test response.""""""
107            return ""test""
108
109        hass, ""http"", {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}}
110    )
111
112    hass.http.register_view(MyView(""/api/test"", ""api:test""))
113    hass.http.register_view(MyView(""/api/test"", ""api:test2""))
114    hass.http.register_view(MyView(""/api/test2"", ""api:test""))
115
116    hass.http.app._on_startup.freeze()
117    await hass.http.app.startup()
118
119
120async def test_cors_works_with_frontend(hass, hass_client):
121    """"""Test CORS works with the frontend.""""""
122        hass,
123        ""frontend"",
124        {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
125    )
126    client = await hass_client()
127    resp = await client.get(""/"")
128
129
130async def test_cors_on_static_files(hass, hass_client):
131    """"""Test that we enable CORS for static files.""""""
132        hass, ""frontend"", {""http"": {""cors_allowed_origins"": [""http://www.example.com""]}}
133    )
134    hass.http.register_static_path(""/something"", str(Path(__file__).parent))
135
136    client = await hass_client()
137    resp = await client.options(
138        ""/something/__init__.py"",
139        headers={
140            ""origin"": ""http://www.example.com"",
141            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
142        },
143    )
144","[['len(mock_setup.mock_calls)', '==', '1'], ['len(mock_setup.mock_calls)', '==', '1'], ['req.status', '==', '200'], ['req.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', 'TRUSTED_ORIGIN'], ['req.status', '==', '200'], ['req.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', 'TRUSTED_ORIGIN'], ['req.status', '==', '200'], ['req.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', 'TRUSTED_ORIGIN'], ['req.status', '==', '200'], ['req.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', 'TRUSTED_ORIGIN'], ['req.status', '==', '200'], ['req.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', 'TRUSTED_ORIGIN'], ['req.headers[ACCESS_CONTROL_ALLOW_HEADERS]', '==', '""X-REQUESTED-WITH""'], ['await', 'async_setup_component('], ['await', 'async_setup_component('], ['resp.status', '==', '200'], ['await', 'async_setup_component('], ['resp.status', '==', '200'], ['resp.headers[ACCESS_CONTROL_ALLOW_ORIGIN]', '==', '""http://www.example.com""']]",19,19,1.0,0.0036986568035818,"['TRUSTED_ORIGIN', 'hass', 'request', 'loop', 'aiohttp_client', 'app', 'client', 'req', 'requires_auth', 'cors_allowed', 'url', 'name', 'self.url', 'self.name', 'hass_client', 'resp']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['TRUSTED_ORIGIN', 'hass', 'request', 'loop', 'aiohttp_client', 'app', 'client', 'req', 'requires_auth', 'cors_allowed', 'url', 'name', 'self.url', 'self.name', 'hass_client', 'resp']
*Code:

1""""""Test cors for the HTTP component.""""""
2from pathlib import Path
3
4from aiohttp import web
5from aiohttp.hdrs import (
6    ACCESS_CONTROL_ALLOW_HEADERS,
7    ACCESS_CONTROL_ALLOW_ORIGIN,
8    ACCESS_CONTROL_REQUEST_HEADERS,
9    ACCESS_CONTROL_REQUEST_METHOD,
10    AUTHORIZATION,
11    ORIGIN,
12)
13import pytest
14
15from homeassistant.components.http.cors import setup_cors
16from homeassistant.components.http.view import HomeAssistantView
17from homeassistant.setup import async_setup_component
18
19from . import HTTP_HEADER_HA_AUTH
20
21from tests.async_mock import patch
22
23TRUSTED_ORIGIN = ""https://home-assistant.io""
24
25
26async def test_cors_middleware_loaded_by_default(hass):
27    """"""Test accessing to server from banned IP when feature is off.""""""
28    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
29        await async_setup_component(hass, ""http"", {""http"": {}})
30
31
32
33async def test_cors_middleware_loaded_from_config(hass):
34    """"""Test accessing to server from banned IP when feature is off.""""""
35    with patch(""homeassistant.components.http.setup_cors"") as mock_setup:
36        await async_setup_component(
37            hass,
38            ""http"",
39            {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
40        )
41
42
43
44async def mock_handler(request):
45    """"""Return if request was authenticated.""""""
46    return web.Response(status=200)
47
48
49@pytest.fixture
50def client(loop, aiohttp_client):
51    """"""Fixture to set up a web.Application.""""""
52    app = web.Application()
53    app.router.add_get(""/"", mock_handler)
54    setup_cors(app, [TRUSTED_ORIGIN])
55    return loop.run_until_complete(aiohttp_client(app))
56
57
58async def test_cors_requests(client):
59    """"""Test cross origin requests.""""""
60    req = await client.get(""/"", headers={ORIGIN: TRUSTED_ORIGIN})
61
62    # With password in URL
63    req = await client.get(
64        ""/"", params={""api_password"": ""some-pass""}, headers={ORIGIN: TRUSTED_ORIGIN}
65    )
66
67    # With password in headers
68    req = await client.get(
69        ""/"", headers={HTTP_HEADER_HA_AUTH: ""some-pass"", ORIGIN: TRUSTED_ORIGIN}
70    )
71
72    # With auth token in headers
73    req = await client.get(
74        ""/"", headers={AUTHORIZATION: ""Bearer some-token"", ORIGIN: TRUSTED_ORIGIN}
75    )
76
77
78async def test_cors_preflight_allowed(client):
79    """"""Test cross origin resource sharing preflight (OPTIONS) request.""""""
80    req = await client.options(
81        ""/"",
82        headers={
83            ORIGIN: TRUSTED_ORIGIN,
84            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
85            ACCESS_CONTROL_REQUEST_HEADERS: ""x-requested-with"",
86        },
87    )
88
89
90
91async def test_cors_middleware_with_cors_allowed_view(hass):
92    """"""Test that we can configure cors and have a cors_allowed view.""""""
93
94    class MyView(HomeAssistantView):
95        """"""Test view that allows CORS.""""""
96
97        requires_auth = False
98        cors_allowed = True
99
100        def __init__(self, url, name):
101            """"""Initialize test view.""""""
102            self.url = url
103            self.name = name
104
105        async def get(self, request):
106            """"""Test response.""""""
107            return ""test""
108
109        hass, ""http"", {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}}
110    )
111
112    hass.http.register_view(MyView(""/api/test"", ""api:test""))
113    hass.http.register_view(MyView(""/api/test"", ""api:test2""))
114    hass.http.register_view(MyView(""/api/test2"", ""api:test""))
115
116    hass.http.app._on_startup.freeze()
117    await hass.http.app.startup()
118
119
120async def test_cors_works_with_frontend(hass, hass_client):
121    """"""Test CORS works with the frontend.""""""
122        hass,
123        ""frontend"",
124        {""http"": {""cors_allowed_origins"": [""http://home-assistant.io""]}},
125    )
126    client = await hass_client()
127    resp = await client.get(""/"")
128
129
130async def test_cors_on_static_files(hass, hass_client):
131    """"""Test that we enable CORS for static files.""""""
132        hass, ""frontend"", {""http"": {""cors_allowed_origins"": [""http://www.example.com""]}}
133    )
134    hass.http.register_static_path(""/something"", str(Path(__file__).parent))
135
136    client = await hass_client()
137    resp = await client.options(
138        ""/something/__init__.py"",
139        headers={
140            ""origin"": ""http://www.example.com"",
141            ACCESS_CONTROL_REQUEST_METHOD: ""GET"",
142        },
143    )
144",6108,"[[26, 'hass', '!=', None, ""Initializer function can't accept None type""],
 [33, 'hass', '!=', None, ""Initializer function can't accept None type""],
 [58, 'client', '!=', None, ""Client can't be None""],
 [78, 'client', '!=', None, ""Client can't be None""],
 [91, 'hass', '!=', None, ""Initializer can't accept None type""],
 [108, 'request', '!=', None, ""Request handling function can't accept None""],
 [120, 'hass', '!=', None, ""Initializer can't accept None""],
 [120, 'hass_client', '!=', None, ""Client initializer function can't accept None type""],
 [130, 'hass', '!=', None, ""Initializer can't accept None""],
 [130, 'hass_client', '!=', None, ""Client initializer function can't accept None type""]]"
aaalgo/cls,"#!/usr/bin/env python3

import numpy as np

CLASSES = ['aeroplane',
           'bicycle',
           'bird',
           'boat',
           'bottle',
           'bus',
           'car',
           'cat',
           'chair',
           'cow',
           'diningtable',
           'dog',
           'horse',
           'motorbike',
           'person',
           'pottedplant',
           'sheep',
           'sofa',
           'train',
           'tvmonitor']

assert len(CLASSES) == 20

def load_list (Class, Set, difficult = True):
    # Class is the class name
    # Set can be 'train', 'val', or 'trainval'
    # set difficult to False to remove difficult examples

    # return X, Y
    # where X: list of image paths
    #       Y: labels of 0, 1

    path = 'data/VOC2012/ImageSets/Main/%s_%s.txt' % (Class, Set)
    X = []
    Y = []
    with open(path, 'r') as f:
        for line in f:
            fs = line.strip().split(' ')
            name = fs[0]
            label = fs[-1]
            label = int(label)
            if label == 0:
                if not difficult:
                    continue
                label = 1
            elif label == -1:
                label = 0
            elif label == 1:
                pass
            else:
                assert False    # unknown label
                pass
            image_path = 'data/VOC2012/JPEGImages/%s.jpg' % name
            X.append(image_path)
            Y.append(label)
            pass
        pass
    return X, np.array(Y, dtype=np.int32)

","
1#!/usr/bin/env python3
2
3import numpy as np
4
5CLASSES = ['aeroplane',
6           'bicycle',
7           'bird',
8           'boat',
9           'bottle',
10           'bus',
11           'car',
12           'cat',
13           'chair',
14           'cow',
15           'diningtable',
16           'dog',
17           'horse',
18           'motorbike',
19           'person',
20           'pottedplant',
21           'sheep',
22           'sofa',
23           'train',
24           'tvmonitor']
25
26
27def load_list (Class, Set, difficult = True):
28    # Class is the class name
29    # Set can be 'train', 'val', or 'trainval'
30    # set difficult to False to remove difficult examples
31
32    # return X, Y
33    # where X: list of image paths
34    #       Y: labels of 0, 1
35
36    path = 'data/VOC2012/ImageSets/Main/%s_%s.txt' % (Class, Set)
37    X = []
38    Y = []
39    with open(path, 'r') as f:
40        for line in f:
41            fs = line.strip().split(' ')
42            name = fs[0]
43            label = fs[-1]
44            label = int(label)
45            if label == 0:
46                if not difficult:
47                    continue
48                label = 1
49            elif label == -1:
50                label = 0
51            elif label == 1:
52                pass
53            else:
54                pass
55            image_path = 'data/VOC2012/JPEGImages/%s.jpg' % name
56            X.append(image_path)
57            Y.append(label)
58            pass
59        pass
60    return X, np.array(Y, dtype=np.int32)
61
62","[['len(CLASSES)', '==', '20'], ['False', '==', 'True']]",2,2,1.0,0.0013097576948264,"['CLASSES', 'Class', 'Set', 'difficult', 'path', 'X', 'Y', 'fs', 'name', 'label', 'image_path']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['CLASSES', 'Class', 'Set', 'difficult', 'path', 'X', 'Y', 'fs', 'name', 'label', 'image_path']
*Code:

1#!/usr/bin/env python3
2
3import numpy as np
4
5CLASSES = ['aeroplane',
6           'bicycle',
7           'bird',
8           'boat',
9           'bottle',
10           'bus',
11           'car',
12           'cat',
13           'chair',
14           'cow',
15           'diningtable',
16           'dog',
17           'horse',
18           'motorbike',
19           'person',
20           'pottedplant',
21           'sheep',
22           'sofa',
23           'train',
24           'tvmonitor']
25
26
27def load_list (Class, Set, difficult = True):
28    # Class is the class name
29    # Set can be 'train', 'val', or 'trainval'
30    # set difficult to False to remove difficult examples
31
32    # return X, Y
33    # where X: list of image paths
34    #       Y: labels of 0, 1
35
36    path = 'data/VOC2012/ImageSets/Main/%s_%s.txt' % (Class, Set)
37    X = []
38    Y = []
39    with open(path, 'r') as f:
40        for line in f:
41            fs = line.strip().split(' ')
42            name = fs[0]
43            label = fs[-1]
44            label = int(label)
45            if label == 0:
46                if not difficult:
47                    continue
48                label = 1
49            elif label == -1:
50                label = 0
51            elif label == 1:
52                pass
53            else:
54                pass
55            image_path = 'data/VOC2012/JPEGImages/%s.jpg' % name
56            X.append(image_path)
57            Y.append(label)
58            pass
59        pass
60    return X, np.array(Y, dtype=np.int32)
61
62",3044,"[[27, 'Class', '!=', '', 'Class should not be an empty string'],
 [27, 'Class', 'in', 'CLASSES', 'Provided Class should be in the predefined classes'],
 [27, 'Set', '!=', '', 'Set should not be an empty string'],
 [27, 'Set', 'in', ['train', 'val', 'trainval'], 'Set can only be either train, val, or trainval'],
 [38, 'X', 'is', 'list', 'X should be a list'],
 [39, 'Y', 'is', 'list', 'Y should be a list'],
 [60, 'Y', '>=', 0, 'Y should be an array of integers with values of either 0 or 1']]"
initcron/ansible,"# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.


import os

from types import NoneType

from ansible.errors import AnsibleParserError
from ansible.parsing.yaml.objects import AnsibleBaseYAMLObject


def load_list_of_blocks(ds, parent_block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
    '''
    Given a list of mixed task/block data (parsed from YAML),
    return a list of Block() objects, where implicit blocks
    are created for each bare Task.
    '''
 
    # we import here to prevent a circular dependency with imports
    from ansible.playbook.block import Block

    assert type(ds) in (list, NoneType)

    block_list = []
    if ds:
        for block in ds:
            b = Block.load(
                block,
                parent_block=parent_block,
                role=role,
                task_include=task_include,
                use_handlers=use_handlers,
                variable_manager=variable_manager,
                loader=loader
            )
            block_list.append(b)

    return block_list


def load_list_of_tasks(ds, block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
    '''
    Given a list of task datastructures (parsed from YAML),
    return a list of Task() or TaskInclude() objects.
    '''

    # we import here to prevent a circular dependency with imports
    from ansible.playbook.handler import Handler
    from ansible.playbook.task import Task
    #from ansible.playbook.task_include import TaskInclude

    assert type(ds) == list

    task_list = []
    for task in ds:
        if not isinstance(task, dict):
            raise AnsibleParserError(""task/handler entries must be dictionaries (got a %s)"" % type(task), obj=ds)

        #if 'include' in task:
        #    cur_basedir = None
        #    if isinstance(task, AnsibleBaseYAMLObject) and loader:
        #        pos_info = task.get_position_info()
        #        new_basedir = os.path.dirname(pos_info[0])
        #        cur_basedir = loader.get_basedir()
        #        loader.set_basedir(new_basedir)

        #    t = TaskInclude.load(
        #        task,
        #        block=block,
        #        role=role,
        #        task_include=task_include,
        #        use_handlers=use_handlers,
        #        loader=loader
        #    )

        #    if cur_basedir and loader:
        #        loader.set_basedir(cur_basedir)
        #else:
        if True:
            if use_handlers:
                t = Handler.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)
            else:
                t = Task.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)

        task_list.append(t)

    return task_list


def load_list_of_roles(ds, current_role_path=None, variable_manager=None, loader=None):
    '''
    Loads and returns a list of RoleInclude objects from the datastructure
    list of role definitions
    '''

    # we import here to prevent a circular dependency with imports
    from ansible.playbook.role.include import RoleInclude

    assert isinstance(ds, list)

    roles = []
    for role_def in ds:
        i = RoleInclude.load(role_def, current_role_path=current_role_path, variable_manager=variable_manager, loader=loader)
        roles.append(i)

    return roles

def compile_block_list(block_list):
    '''
    Given a list of blocks, compile them into a flat list of tasks
    '''

    task_list = []

    for block in block_list:
        task_list.extend(block.compile())

    return task_list

","
1# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
2#
3# This file is part of Ansible
4#
5# Ansible is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# Ansible is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
17
18
19import os
20
21from types import NoneType
22
23from ansible.errors import AnsibleParserError
24from ansible.parsing.yaml.objects import AnsibleBaseYAMLObject
25
26
27def load_list_of_blocks(ds, parent_block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
28    '''
29    Given a list of mixed task/block data (parsed from YAML),
30    return a list of Block() objects, where implicit blocks
31    are created for each bare Task.
32    '''
33 
34    # we import here to prevent a circular dependency with imports
35    from ansible.playbook.block import Block
36
37
38    block_list = []
39    if ds:
40        for block in ds:
41            b = Block.load(
42                block,
43                parent_block=parent_block,
44                role=role,
45                task_include=task_include,
46                use_handlers=use_handlers,
47                variable_manager=variable_manager,
48                loader=loader
49            )
50            block_list.append(b)
51
52    return block_list
53
54
55def load_list_of_tasks(ds, block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
56    '''
57    Given a list of task datastructures (parsed from YAML),
58    return a list of Task() or TaskInclude() objects.
59    '''
60
61    # we import here to prevent a circular dependency with imports
62    from ansible.playbook.handler import Handler
63    from ansible.playbook.task import Task
64    #from ansible.playbook.task_include import TaskInclude
65
66
67    task_list = []
68    for task in ds:
69        if not isinstance(task, dict):
70            raise AnsibleParserError(""task/handler entries must be dictionaries (got a %s)"" % type(task), obj=ds)
71
72        #if 'include' in task:
73        #    cur_basedir = None
74        #    if isinstance(task, AnsibleBaseYAMLObject) and loader:
75        #        pos_info = task.get_position_info()
76        #        new_basedir = os.path.dirname(pos_info[0])
77        #        cur_basedir = loader.get_basedir()
78        #        loader.set_basedir(new_basedir)
79
80        #    t = TaskInclude.load(
81        #        task,
82        #        block=block,
83        #        role=role,
84        #        task_include=task_include,
85        #        use_handlers=use_handlers,
86        #        loader=loader
87        #    )
88
89        #    if cur_basedir and loader:
90        #        loader.set_basedir(cur_basedir)
91        #else:
92        if True:
93            if use_handlers:
94                t = Handler.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)
95            else:
96                t = Task.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)
97
98        task_list.append(t)
99
100    return task_list
101
102
103def load_list_of_roles(ds, current_role_path=None, variable_manager=None, loader=None):
104    '''
105    Loads and returns a list of RoleInclude objects from the datastructure
106    list of role definitions
107    '''
108
109    # we import here to prevent a circular dependency with imports
110    from ansible.playbook.role.include import RoleInclude
111
112
113    roles = []
114    for role_def in ds:
115        i = RoleInclude.load(role_def, current_role_path=current_role_path, variable_manager=variable_manager, loader=loader)
116        roles.append(i)
117
118    return roles
119
120def compile_block_list(block_list):
121    '''
122    Given a list of blocks, compile them into a flat list of tasks
123    '''
124
125    task_list = []
126
127    for block in block_list:
128        task_list.extend(block.compile())
129
130    return task_list
131
132","[['type(ds)', '==', 'list']]",3,1,0.3333333333333333,0.0002299908003679,"['ds', 'parent_block', 'role', 'task_include', 'use_handlers', 'variable_manager', 'loader', 'block_list', 'b', 'block', 'task_list', '#    cur_basedir', '#        pos_info', '#        new_basedir', '#        cur_basedir', '#    t', 't', 'current_role_path', 'roles', 'for role_def in ds', 'i']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ds', 'parent_block', 'role', 'task_include', 'use_handlers', 'variable_manager', 'loader', 'block_list', 'b', 'block', 'task_list', '#    cur_basedir', '#        pos_info', '#        new_basedir', '#        cur_basedir', '#    t', 't', 'current_role_path', 'roles', 'for role_def in ds', 'i']
*Code:

1# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
2#
3# This file is part of Ansible
4#
5# Ansible is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# Ansible is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
17
18
19import os
20
21from types import NoneType
22
23from ansible.errors import AnsibleParserError
24from ansible.parsing.yaml.objects import AnsibleBaseYAMLObject
25
26
27def load_list_of_blocks(ds, parent_block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
28    '''
29    Given a list of mixed task/block data (parsed from YAML),
30    return a list of Block() objects, where implicit blocks
31    are created for each bare Task.
32    '''
33 
34    # we import here to prevent a circular dependency with imports
35    from ansible.playbook.block import Block
36
37
38    block_list = []
39    if ds:
40        for block in ds:
41            b = Block.load(
42                block,
43                parent_block=parent_block,
44                role=role,
45                task_include=task_include,
46                use_handlers=use_handlers,
47                variable_manager=variable_manager,
48                loader=loader
49            )
50            block_list.append(b)
51
52    return block_list
53
54
55def load_list_of_tasks(ds, block=None, role=None, task_include=None, use_handlers=False, variable_manager=None, loader=None):
56    '''
57    Given a list of task datastructures (parsed from YAML),
58    return a list of Task() or TaskInclude() objects.
59    '''
60
61    # we import here to prevent a circular dependency with imports
62    from ansible.playbook.handler import Handler
63    from ansible.playbook.task import Task
64    #from ansible.playbook.task_include import TaskInclude
65
66
67    task_list = []
68    for task in ds:
69        if not isinstance(task, dict):
70            raise AnsibleParserError(""task/handler entries must be dictionaries (got a %s)"" % type(task), obj=ds)
71
72        #if 'include' in task:
73        #    cur_basedir = None
74        #    if isinstance(task, AnsibleBaseYAMLObject) and loader:
75        #        pos_info = task.get_position_info()
76        #        new_basedir = os.path.dirname(pos_info[0])
77        #        cur_basedir = loader.get_basedir()
78        #        loader.set_basedir(new_basedir)
79
80        #    t = TaskInclude.load(
81        #        task,
82        #        block=block,
83        #        role=role,
84        #        task_include=task_include,
85        #        use_handlers=use_handlers,
86        #        loader=loader
87        #    )
88
89        #    if cur_basedir and loader:
90        #        loader.set_basedir(cur_basedir)
91        #else:
92        if True:
93            if use_handlers:
94                t = Handler.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)
95            else:
96                t = Task.load(task, block=block, role=role, task_include=task_include, variable_manager=variable_manager, loader=loader)
97
98        task_list.append(t)
99
100    return task_list
101
102
103def load_list_of_roles(ds, current_role_path=None, variable_manager=None, loader=None):
104    '''
105    Loads and returns a list of RoleInclude objects from the datastructure
106    list of role definitions
107    '''
108
109    # we import here to prevent a circular dependency with imports
110    from ansible.playbook.role.include import RoleInclude
111
112
113    roles = []
114    for role_def in ds:
115        i = RoleInclude.load(role_def, current_role_path=current_role_path, variable_manager=variable_manager, loader=loader)
116        roles.append(i)
117
118    return roles
119
120def compile_block_list(block_list):
121    '''
122    Given a list of blocks, compile them into a flat list of tasks
123    '''
124
125    task_list = []
126
127    for block in block_list:
128        task_list.extend(block.compile())
129
130    return task_list
131
132",6211,"[[27, 'ds', '!=', None, 'ds should not be None to proceed with loading a list of blocks'],
[27, 'block_list', '==', [], 'block_list should be an empty list initially'],
[39, 'ds', '!=', None, 'ds must not be None for the loading process to proceed'],
[55, 'ds', '!=', None, 'ds should not be None to proceed with loading a list of tasks'],
[55, 'task_list', '==', [], 'task_list should be an empty list initially'],
[68, 'ds', '!=', None, 'ds must not be None for the task loading process to proceed'],
[103, 'ds', '!=', None, 'ds should not be None to proceed with loading a list of roles'],
[103, 'roles', '==', [], 'roles should be an empty list initially'],
[114, 'ds', '!=', None, 'ds must not be None for the role loading process to proceed'],
[120, 'block_list', '!=', None, 'block_list should not be None to compile them into a flat list of tasks'],
[120, 'task_list', '==', [], 'task_list should be an empty list initially'],
[127, 'block_list', '!=', None, 'block_list must not be None for the task compiling process to proceed']]"
spacy-io/spaCy,"import pytest
from spacy.lang.fr.lex_attrs import like_num


def test_tokenizer_handles_long_text(fr_tokenizer):
    text = """"""L'histoire du TAL commence dans les années 1950, bien que l'on puisse \
trouver des travaux antérieurs. En 1950, Alan Turing éditait un article \
célèbre sous le titre « Computing machinery and intelligence » qui propose ce \
qu'on appelle à présent le test de Turing comme critère d'intelligence. \
Ce critère dépend de la capacité d'un programme informatique de personnifier \
un humain dans une conversation écrite en temps réel, de façon suffisamment \
convaincante que l'interlocuteur humain ne peut distinguer sûrement — sur la \
base du seul contenu de la conversation — s'il interagit avec un programme \
ou avec un autre vrai humain.""""""
    tokens = fr_tokenizer(text)
    assert len(tokens) == 113


@pytest.mark.parametrize(""word"", [""onze"", ""onzième""])
def test_fr_lex_attrs_capitals(word):
    assert like_num(word)
    assert like_num(word.upper())
","
1import pytest
2from spacy.lang.fr.lex_attrs import like_num
3
4
5def test_tokenizer_handles_long_text(fr_tokenizer):
6    text = """"""L'histoire du TAL commence dans les années 1950, bien que l'on puisse \
7trouver des travaux antérieurs. En 1950, Alan Turing éditait un article \
8célèbre sous le titre « Computing machinery and intelligence » qui propose ce \
9qu'on appelle à présent le test de Turing comme critère d'intelligence. \
10Ce critère dépend de la capacité d'un programme informatique de personnifier \
11un humain dans une conversation écrite en temps réel, de façon suffisamment \
12convaincante que l'interlocuteur humain ne peut distinguer sûrement — sur la \
13base du seul contenu de la conversation — s'il interagit avec un programme \
14ou avec un autre vrai humain.""""""
15    tokens = fr_tokenizer(text)
16
17
18@pytest.mark.parametrize(""word"", [""onze"", ""onzième""])
19def test_fr_lex_attrs_capitals(word):
20","[['len(tokens)', '==', '113'], ['like_num(word)', '==', 'True'], ['like_num(word.upper())', '==', 'True']]",3,3,1.0,0.0030333670374115,"['fr_tokenizer', 'text', 'tokens', 'word']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['fr_tokenizer', 'text', 'tokens', 'word']
*Code:

1import pytest
2from spacy.lang.fr.lex_attrs import like_num
3
4
5def test_tokenizer_handles_long_text(fr_tokenizer):
6    text = """"""L'histoire du TAL commence dans les années 1950, bien que l'on puisse \
7trouver des travaux antérieurs. En 1950, Alan Turing éditait un article \
8célèbre sous le titre « Computing machinery and intelligence » qui propose ce \
9qu'on appelle à présent le test de Turing comme critère d'intelligence. \
10Ce critère dépend de la capacité d'un programme informatique de personnifier \
11un humain dans une conversation écrite en temps réel, de façon suffisamment \
12convaincante que l'interlocuteur humain ne peut distinguer sûrement — sur la \
13base du seul contenu de la conversation — s'il interagit avec un programme \
14ou avec un autre vrai humain.""""""
15    tokens = fr_tokenizer(text)
16
17
18@pytest.mark.parametrize(""word"", [""onze"", ""onzième""])
19def test_fr_lex_attrs_capitals(word):
20",2353,"[[5, 'fr_tokenizer', '!=', None, ""the tokenizer function can't be none""],
 [5, 'text', '!=', '', 'text should not be empty'],
 [15, 'tokens', '!=', None, 'the output of tokenizer function should not be none'],
 [19, 'word', '!=', '', 'word to be tested should not be empty']]"
befelix/Safe-RL-Benchmark,"""""""Policy tests.""""""
from __future__ import division, print_function, absolute_import

from SafeRLBench.spaces import BoundedSpace
from SafeRLBench.envs.quadrocopter import Reference
from SafeRLBench.envs._quadrocopter import StateVector
from SafeRLBench.policy import (NeuralNetwork,
                                LinearPolicy,
                                DiscreteLinearPolicy,
                                NonLinearQuadrocopterController)

import numpy as np
from numpy import isclose

import tensorflow as tf

from unittest2 import TestCase
from mock import Mock

import logging

logger = logging.getLogger(__name__)


class TestNeuralNetwork(TestCase):
    """"""Test the Neural Netork Policy.""""""

    fields = ['args', 'kwargs', 'action_space', 'state_space', 'dtype',
              'layers', 'scope', 'init_weights', 'activation', 'X', 'a',
              'W_action', 'W_var', 'a_pred', 'var', 'h', 'is_set_up']

    def test_initialization(self):
        """"""Test: NEURALNETWORK: initialization.""""""
        # test bad layer size:
        args = [[2]]
        with self.assertRaises(ValueError):
            NeuralNetwork(*args)

        # test field existence
        args = [[2, 6, 1]]

        nn = NeuralNetwork(*args)

        for field in self.fields:
            assert hasattr(nn, field)

        # test network setup
        kwargs = {
            'do_setup': True
        }

        nn = NeuralNetwork(*args, **kwargs)

        # check field contents.
        assert(all([a == b for a, b in zip(args, nn.args)]))
        self.assertEqual(nn.layers, args[0])
        self.assertEqual(nn.dtype, 'float')

        self.assertEqual(len(nn.W_action), 2)
        self.assertEqual(len(nn.W_var), 1)

        # well... because is does not work for whatever fucking reason.
        self.assertEqual(str(type(nn.a_pred)), str(tf.Tensor))
        self.assertIn(str(type(nn.var)), (str(tf.Tensor), str(tf.constant)))

        self.assertEqual(len(nn.h), 2)

    def test_mapping(self):
        """"""Test: NEURALNETWORK: mapping.""""""
        args = [[2, 1]]

        kwargs = {
            'weights': [tf.constant([2., 1.], shape=(2, 1))],
            'do_setup': True,
        }

        nn = NeuralNetwork(*args, **kwargs)

        sess = tf.Session()

        with sess.as_default():
            self.assertEqual(nn(np.array([2., 1.])), [5.])

    def test_variable_assignment(self):
        """"""Test: NEURALNETWORK: parameter assignment.""""""
        args = [[2, 1]]
        kwargs = {'do_setup': True}

        nn = NeuralNetwork(*args, **kwargs)

        with tf.Session().as_default():
            nn.parameters = nn.W_action[0].assign([[2.], [1.]])
            assert((np.array([[2.], [1.]]) == nn.parameters).all())
            self.assertEqual(nn(np.array([2., 1.])), [5.])

    def test_copy(self):
        """"""Test: NEURALNETWORK: copy.""""""
        nn = NeuralNetwork([2, 6, 1])
        nn_copy = nn.copy(scope='copy', do_setup=False)

        exclude = ('scope', 'kwargs')

        for field in self.fields:
            if field not in exclude and field in nn.kwargs.keys():
                print(field)
                self.assertEquals(getattr(nn, field, None),
                                  getattr(nn_copy, field, None))


class TestLinearPolicy(TestCase):
    """"""Test the Linear Policy.""""""

    def test_initialization(self):
        """"""Test: LINEARPOLICY: initialization.""""""
        lp = LinearPolicy(2, 1)

        self.assertEqual(lp.d_state, 2)
        self.assertEqual(lp.d_action, 1)

        self.assertEqual(lp.par_dim, 2)
        self.assertIs(lp._par_space, None)

        self.assertFalse(lp.initialized)

        self.assertIs(lp._parameters, None)
        self.assertTrue(lp.biased)
        self.assertEqual(lp._bias, 0)
        self.assertIs(lp._par, None)

        par_mock = Mock()
        par_space_mock = Mock()

        with self.assertRaises(ValueError):
            lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)

        par_mock = [2, 1]

        lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)

        self.assertTrue(lp_mocked.initialized)
        assert(all(par_mock == lp_mocked.parameters))

        self.assertEqual(par_space_mock, lp_mocked.parameter_space)

    def test_discrete_map(self):
        """"""Test: DISCRETELINEARPOLICY: map.""""""
        dp = DiscreteLinearPolicy(2, 1, biased=False)
        dp.parameters = np.array([1, 1])
        self.assertEqual(dp([1, 1]), 1)
        self.assertEqual(dp([-1, -1]), 0)

        dp2 = DiscreteLinearPolicy(2, 2, biased=False)
        dp2.parameters = np.array([1, 1, -1, -1])
        assert(all(dp2([1, 1]) == [1, 0]))
        assert(all(dp2([-1, -1]) == [0, 1]))


class TestController(TestCase):
    """"""Test NonLinearQuadrocopterController.""""""

    def test_controller_init(self):
        """"""Test: CONTROLLER: initialization.""""""
        ctrl = NonLinearQuadrocopterController()

        self.assertEquals(ctrl._zeta_z, .7)
        assert(all(isclose(ctrl._params, [.7, .7, .7, .5, .707])))
        self.assertIsNone(ctrl.reference)
        self.assertTrue(ctrl.initialized)
        self.assertIsInstance(ctrl._par_space, BoundedSpace)

    def test_controller_map(self):
        """"""Test: CONTROLLER: mapping.""""""
        ref = Reference('circle', 1 / 70.)
        ref.reset(StateVector())
        ctrl = NonLinearQuadrocopterController(reference=ref)

        action = ctrl(StateVector())

        print(action)
        assert all(isclose(action, [0.20510876, -0.30667618, 0., -6.28318548]))

    def test_controller_properties(self):
        """"""Test: CONTROLLER: properties.""""""
        ctrl = NonLinearQuadrocopterController()

        ctrl.parameters = [0., 1., 0., 1., 0.]
        assert(all(np.isclose(ctrl.parameters, [0., 1., 0., 1., 0.])))

        self.assertEquals(ctrl.parameter_space, ctrl._par_space)
","
1""""""Policy tests.""""""
2from __future__ import division, print_function, absolute_import
3
4from SafeRLBench.spaces import BoundedSpace
5from SafeRLBench.envs.quadrocopter import Reference
6from SafeRLBench.envs._quadrocopter import StateVector
7from SafeRLBench.policy import (NeuralNetwork,
8                                LinearPolicy,
9                                DiscreteLinearPolicy,
10                                NonLinearQuadrocopterController)
11
12import numpy as np
13from numpy import isclose
14
15import tensorflow as tf
16
17from unittest2 import TestCase
18from mock import Mock
19
20import logging
21
22logger = logging.getLogger(__name__)
23
24
25class TestNeuralNetwork(TestCase):
26    """"""Test the Neural Netork Policy.""""""
27
28    fields = ['args', 'kwargs', 'action_space', 'state_space', 'dtype',
29              'layers', 'scope', 'init_weights', 'activation', 'X', 'a',
30              'W_action', 'W_var', 'a_pred', 'var', 'h', 'is_set_up']
31
32    def test_initialization(self):
33        """"""Test: NEURALNETWORK: initialization.""""""
34        # test bad layer size:
35        args = [[2]]
36            NeuralNetwork(*args)
37
38        # test field existence
39        args = [[2, 6, 1]]
40
41        nn = NeuralNetwork(*args)
42
43        for field in self.fields:
44
45        # test network setup
46        kwargs = {
47            'do_setup': True
48        }
49
50        nn = NeuralNetwork(*args, **kwargs)
51
52        # check field contents.
53
54
55        # well... because is does not work for whatever fucking reason.
56
57
58    def test_mapping(self):
59        """"""Test: NEURALNETWORK: mapping.""""""
60        args = [[2, 1]]
61
62        kwargs = {
63            'weights': [tf.constant([2., 1.], shape=(2, 1))],
64            'do_setup': True,
65        }
66
67        nn = NeuralNetwork(*args, **kwargs)
68
69        sess = tf.Session()
70
71        with sess.as_default():
72
73    def test_variable_assignment(self):
74        """"""Test: NEURALNETWORK: parameter assignment.""""""
75        args = [[2, 1]]
76        kwargs = {'do_setup': True}
77
78        nn = NeuralNetwork(*args, **kwargs)
79
80        with tf.Session().as_default():
81            nn.parameters = nn.W_action[0].assign([[2.], [1.]])
82
83    def test_copy(self):
84        """"""Test: NEURALNETWORK: copy.""""""
85        nn = NeuralNetwork([2, 6, 1])
86        nn_copy = nn.copy(scope='copy', do_setup=False)
87
88        exclude = ('scope', 'kwargs')
89
90        for field in self.fields:
91            if field not in exclude and field in nn.kwargs.keys():
92                print(field)
93                                  getattr(nn_copy, field, None))
94
95
96class TestLinearPolicy(TestCase):
97    """"""Test the Linear Policy.""""""
98
99    def test_initialization(self):
100        """"""Test: LINEARPOLICY: initialization.""""""
101        lp = LinearPolicy(2, 1)
102
103
104
105
106
107        par_mock = Mock()
108        par_space_mock = Mock()
109
110            lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)
111
112        par_mock = [2, 1]
113
114        lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)
115
116
117
118    def test_discrete_map(self):
119        """"""Test: DISCRETELINEARPOLICY: map.""""""
120        dp = DiscreteLinearPolicy(2, 1, biased=False)
121        dp.parameters = np.array([1, 1])
122
123        dp2 = DiscreteLinearPolicy(2, 2, biased=False)
124        dp2.parameters = np.array([1, 1, -1, -1])
125
126
127class TestController(TestCase):
128    """"""Test NonLinearQuadrocopterController.""""""
129
130    def test_controller_init(self):
131        """"""Test: CONTROLLER: initialization.""""""
132        ctrl = NonLinearQuadrocopterController()
133
134
135    def test_controller_map(self):
136        """"""Test: CONTROLLER: mapping.""""""
137        ref = Reference('circle', 1 / 70.)
138        ref.reset(StateVector())
139        ctrl = NonLinearQuadrocopterController(reference=ref)
140
141        action = ctrl(StateVector())
142
143        print(action)
144
145    def test_controller_properties(self):
146        """"""Test: CONTROLLER: properties.""""""
147        ctrl = NonLinearQuadrocopterController()
148
149        ctrl.parameters = [0., 1., 0., 1., 0.]
150
151","[['hasattr(nn', '==', 'True'], ['all(isclose(action', '==', 'True']]",39,2,0.0512820512820512,0.0003430531732418,"['logger', 'fields', 'args', 'nn', 'kwargs', 'sess', 'nn.parameters', 'nn_copy', 'exclude', 'lp', 'par_mock', 'par_space_mock', 'lp_mocked', 'dp', 'dp.parameters', 'dp2', 'dp2.parameters', 'ctrl', 'ref', 'action', 'ctrl.parameters']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logger', 'fields', 'args', 'nn', 'kwargs', 'sess', 'nn.parameters', 'nn_copy', 'exclude', 'lp', 'par_mock', 'par_space_mock', 'lp_mocked', 'dp', 'dp.parameters', 'dp2', 'dp2.parameters', 'ctrl', 'ref', 'action', 'ctrl.parameters']
*Code:

1""""""Policy tests.""""""
2from __future__ import division, print_function, absolute_import
3
4from SafeRLBench.spaces import BoundedSpace
5from SafeRLBench.envs.quadrocopter import Reference
6from SafeRLBench.envs._quadrocopter import StateVector
7from SafeRLBench.policy import (NeuralNetwork,
8                                LinearPolicy,
9                                DiscreteLinearPolicy,
10                                NonLinearQuadrocopterController)
11
12import numpy as np
13from numpy import isclose
14
15import tensorflow as tf
16
17from unittest2 import TestCase
18from mock import Mock
19
20import logging
21
22logger = logging.getLogger(__name__)
23
24
25class TestNeuralNetwork(TestCase):
26    """"""Test the Neural Netork Policy.""""""
27
28    fields = ['args', 'kwargs', 'action_space', 'state_space', 'dtype',
29              'layers', 'scope', 'init_weights', 'activation', 'X', 'a',
30              'W_action', 'W_var', 'a_pred', 'var', 'h', 'is_set_up']
31
32    def test_initialization(self):
33        """"""Test: NEURALNETWORK: initialization.""""""
34        # test bad layer size:
35        args = [[2]]
36            NeuralNetwork(*args)
37
38        # test field existence
39        args = [[2, 6, 1]]
40
41        nn = NeuralNetwork(*args)
42
43        for field in self.fields:
44
45        # test network setup
46        kwargs = {
47            'do_setup': True
48        }
49
50        nn = NeuralNetwork(*args, **kwargs)
51
52        # check field contents.
53
54
55        # well... because is does not work for whatever fucking reason.
56
57
58    def test_mapping(self):
59        """"""Test: NEURALNETWORK: mapping.""""""
60        args = [[2, 1]]
61
62        kwargs = {
63            'weights': [tf.constant([2., 1.], shape=(2, 1))],
64            'do_setup': True,
65        }
66
67        nn = NeuralNetwork(*args, **kwargs)
68
69        sess = tf.Session()
70
71        with sess.as_default():
72
73    def test_variable_assignment(self):
74        """"""Test: NEURALNETWORK: parameter assignment.""""""
75        args = [[2, 1]]
76        kwargs = {'do_setup': True}
77
78        nn = NeuralNetwork(*args, **kwargs)
79
80        with tf.Session().as_default():
81            nn.parameters = nn.W_action[0].assign([[2.], [1.]])
82
83    def test_copy(self):
84        """"""Test: NEURALNETWORK: copy.""""""
85        nn = NeuralNetwork([2, 6, 1])
86        nn_copy = nn.copy(scope='copy', do_setup=False)
87
88        exclude = ('scope', 'kwargs')
89
90        for field in self.fields:
91            if field not in exclude and field in nn.kwargs.keys():
92                print(field)
93                                  getattr(nn_copy, field, None))
94
95
96class TestLinearPolicy(TestCase):
97    """"""Test the Linear Policy.""""""
98
99    def test_initialization(self):
100        """"""Test: LINEARPOLICY: initialization.""""""
101        lp = LinearPolicy(2, 1)
102
103
104
105
106
107        par_mock = Mock()
108        par_space_mock = Mock()
109
110            lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)
111
112        par_mock = [2, 1]
113
114        lp_mocked = LinearPolicy(2, 1, par_mock, par_space_mock)
115
116
117
118    def test_discrete_map(self):
119        """"""Test: DISCRETELINEARPOLICY: map.""""""
120        dp = DiscreteLinearPolicy(2, 1, biased=False)
121        dp.parameters = np.array([1, 1])
122
123        dp2 = DiscreteLinearPolicy(2, 2, biased=False)
124        dp2.parameters = np.array([1, 1, -1, -1])
125
126
127class TestController(TestCase):
128    """"""Test NonLinearQuadrocopterController.""""""
129
130    def test_controller_init(self):
131        """"""Test: CONTROLLER: initialization.""""""
132        ctrl = NonLinearQuadrocopterController()
133
134
135    def test_controller_map(self):
136        """"""Test: CONTROLLER: mapping.""""""
137        ref = Reference('circle', 1 / 70.)
138        ref.reset(StateVector())
139        ctrl = NonLinearQuadrocopterController(reference=ref)
140
141        action = ctrl(StateVector())
142
143        print(action)
144
145    def test_controller_properties(self):
146        """"""Test: CONTROLLER: properties.""""""
147        ctrl = NonLinearQuadrocopterController()
148
149        ctrl.parameters = [0., 1., 0., 1., 0.]
150
151",5828,"[[35, 'args', '==', 1, ""NeuralNetwork initialization requires 1 argument""],
 [39, 'args', '==', 1, ""NeuralNetwork initialization requires 1 argument""],
 [45, 'fields', '!=', None, ""Fields must be defined to check the network setup""],
 [46, 'kwargs', '==', 1, ""NeuralNetwork initialization with setup options requires kwargs""],
 [50, 'nn', '!=', None, ""The neural network object must have been successfully created""],
 [59, 'args', '==', 1, ""NeuralNetwork mapping test requires 1 argument""],
 [62, 'kwargs', '!=', None, ""Weigths and setup options are needed for mapping test""],
 [67, 'nn', '!=', None, ""The neural network object must be successfully created for mapping test""],
 [69, 'sess', '!=', None, ""Session must have been created before testing mapping""],
 [74, 'args', '==', 1, ""NeuralNetwork parameter assignment test requires 1 argument""],
 [76, 'kwargs', '==', 1, ""NeuralNetwork parameter assignment requires kwargs""],
 [78, 'nn', '!=', None, ""The neural network object must be successfully created for parameter assignment test""],
 [85, 'nn', '!=', None, ""The neural network object must have been successfully created for copy test""],
 [86, 'nn_copy', '!=', None, ""The copy of the neural network object must have been created successfully""],
 [88, 'exclude', '!=', None, ""Exclude fields must be defined for copy test""],
 [97, 'lp', '!=', None, ""LinearPolicy must be created for initialization test""],
 [107, 'par_mock', '!=', None, ""Parameter mockup must be successfully created for initialization test""],
 [108, 'par_space_mock', '!=', None, ""Parameter space mockup must be created for the policy initialization test""],
 [110, 'lp_mocked', '!=', None, ""Mocked LinearPolicy must be created for initialization test""],
 [120, 'dp', '!=', None, ""DiscreteLinearPolicy must be successfully created for map test""],
 [121, 'dp.parameters', '!=', None, ""Parameters of the DiscreteLinearPolicy must exist for map test""],
 [123, 'dp2', '!=', None, ""The secondary DiscreteLinearPolicy must be created for map test""],
 [124, 'dp2.parameters', '!=', None, ""The secondary parameters of the DiscreteLinearPolicy must exist for map test""],
 [132, 'ctrl', '!=', None, ""NonLinearQuadrocopterController must be created for initialization test""],
 [136, 'ref', '!=', None, ""Reference must be defined for mapping test""],
 [139, 'ctrl', '!=', None, ""NonLinearQuadrocopterController must be created for mapping test""],
 [145, 'ctrl', '!=', None, ""NonLinearQuadrocopterController must be created to test properties""],
 [149, 'ctrl.parameters', '==', 5, ""The controller should have 5 parameters""]]"
jonnylamb/debexpo,"import os.path
import pylons
from paste.deploy import appconfig


def easy_app_init(ini_path):
    ini_path = os.path.abspath(ini_path)
    assert os.path.exists(ini_path)

    # Initialize Pylons app
    conf = appconfig('config:' + ini_path)
    import debexpo.config.environment
    pylons.config = debexpo.config.environment.load_environment(conf.global_conf, conf.local_conf)

","
1import os.path
2import pylons
3from paste.deploy import appconfig
4
5
6def easy_app_init(ini_path):
7    ini_path = os.path.abspath(ini_path)
8
9    # Initialize Pylons app
10    conf = appconfig('config:' + ini_path)
11    import debexpo.config.environment
12    pylons.config = debexpo.config.environment.load_environment(conf.global_conf, conf.local_conf)
13
14","[['os.path.exists(ini_path)', '==', 'True']]",1,1,1.0,0.0026178010471204,"['ini_path', 'conf', 'pylons.config']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ini_path', 'conf', 'pylons.config']
*Code:

1import os.path
2import pylons
3from paste.deploy import appconfig
4
5
6def easy_app_init(ini_path):
7    ini_path = os.path.abspath(ini_path)
8
9    # Initialize Pylons app
10    conf = appconfig('config:' + ini_path)
11    import debexpo.config.environment
12    pylons.config = debexpo.config.environment.load_environment(conf.global_conf, conf.local_conf)
13
14",1783,"[[6, 'ini_path', '!=', '', 'the ini_path should not be an empty string'], 
 [10, 'conf', '!=', '', 'Configuration should not be empty'],
 [12, 'pylons.config', '!=', '', 'Pylons configuration should not be empty']]"
kevinlondon/sentry,"from __future__ import absolute_import

from django.core import mail

from sentry.models import Activity, Release
from sentry.testutils import TestCase


class SendNotificationTest(TestCase):
    def test_note(self):
        user_foo = self.create_user('foo@example.com')

        activity = Activity.objects.create(
            project=self.project,
            group=self.group,
            type=Activity.NOTE,
            user=user_foo,
            event=self.create_event('a' * 32, group=self.group),
            data={
                'text': 'sup guise',
            },
        )

        self.project.team.organization.member_set.create(user=user_foo)

        with self.tasks():
            activity.send_notification()

        assert len(mail.outbox) == 1

        msg = mail.outbox[0]

        assert msg.subject == 'Re: [Sentry] [foo Bar] ERROR: Foo bar'
        assert msg.to == [self.user.email]

    def test_release(self):
        user_foo = self.create_user('foo@example.com')

        release = Release.objects.create(
            project=self.project,
            version='a' * 40,
        )

        activity = Activity.objects.create(
            project=self.project,
            type=Activity.RELEASE,
            user=user_foo,
            event=self.create_event('a' * 32, group=self.group),
            data={
                'version': release.version,
            },
        )

        self.project.team.organization.member_set.create(user=user_foo)

        with self.tasks():
            activity.send_notification()

        assert len(mail.outbox) == 1

        msg = mail.outbox[0]

        assert msg.subject == '[Sentry] Release %s' % (release.version,)
        assert msg.to == [self.user.email]
","
1from __future__ import absolute_import
2
3from django.core import mail
4
5from sentry.models import Activity, Release
6from sentry.testutils import TestCase
7
8
9class SendNotificationTest(TestCase):
10    def test_note(self):
11        user_foo = self.create_user('foo@example.com')
12
13        activity = Activity.objects.create(
14            project=self.project,
15            group=self.group,
16            type=Activity.NOTE,
17            user=user_foo,
18            event=self.create_event('a' * 32, group=self.group),
19            data={
20                'text': 'sup guise',
21            },
22        )
23
24        self.project.team.organization.member_set.create(user=user_foo)
25
26        with self.tasks():
27            activity.send_notification()
28
29
30        msg = mail.outbox[0]
31
32
33    def test_release(self):
34        user_foo = self.create_user('foo@example.com')
35
36        release = Release.objects.create(
37            project=self.project,
38            version='a' * 40,
39        )
40
41        activity = Activity.objects.create(
42            project=self.project,
43            type=Activity.RELEASE,
44            user=user_foo,
45            event=self.create_event('a' * 32, group=self.group),
46            data={
47                'version': release.version,
48            },
49        )
50
51        self.project.team.organization.member_set.create(user=user_foo)
52
53        with self.tasks():
54            activity.send_notification()
55
56
57        msg = mail.outbox[0]
58
59","[['len(mail.outbox)', '==', '1'], ['msg.subject', '==', ""'Re: [Sentry] [foo Bar] ERROR: Foo bar'""], ['msg.to', '==', '[self.user.email]'], ['len(mail.outbox)', '==', '1'], ['msg.subject', '==', ""'[Sentry] Release %s' % (release.version""], ['msg.to', '==', '[self.user.email]']]",6,6,1.0,0.0034642032332563,"['user_foo', 'activity', 'msg', 'release']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['user_foo', 'activity', 'msg', 'release']
*Code:

1from __future__ import absolute_import
2
3from django.core import mail
4
5from sentry.models import Activity, Release
6from sentry.testutils import TestCase
7
8
9class SendNotificationTest(TestCase):
10    def test_note(self):
11        user_foo = self.create_user('foo@example.com')
12
13        activity = Activity.objects.create(
14            project=self.project,
15            group=self.group,
16            type=Activity.NOTE,
17            user=user_foo,
18            event=self.create_event('a' * 32, group=self.group),
19            data={
20                'text': 'sup guise',
21            },
22        )
23
24        self.project.team.organization.member_set.create(user=user_foo)
25
26        with self.tasks():
27            activity.send_notification()
28
29
30        msg = mail.outbox[0]
31
32
33    def test_release(self):
34        user_foo = self.create_user('foo@example.com')
35
36        release = Release.objects.create(
37            project=self.project,
38            version='a' * 40,
39        )
40
41        activity = Activity.objects.create(
42            project=self.project,
43            type=Activity.RELEASE,
44            user=user_foo,
45            event=self.create_event('a' * 32, group=self.group),
46            data={
47                'version': release.version,
48            },
49        )
50
51        self.project.team.organization.member_set.create(user=user_foo)
52
53        with self.tasks():
54            activity.send_notification()
55
56
57        msg = mail.outbox[0]
58
59",2961,"[[11, 'user_foo', '!=', None, 'user_foo should be initialized and not None'],
[22, 'activity', '!=', None, 'activity should be initialized and not None'],
[30, 'msg', '!=', None, 'msg should be initialized and not None'],
[56, 'msg', '!=', None, 'msg should be initialized and not None'],
[36, 'release', '!=', None, 'release should be initialized and not None']]"
Acehaidrey/incubator-airflow,"# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# ""License""); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import unittest
from unittest import mock

from airflow import configuration
from airflow.providers.amazon.aws.hooks.glue import GlueJobHook
from airflow.providers.amazon.aws.sensors.glue import GlueJobSensor


class TestGlueJobSensor(unittest.TestCase):
    def setUp(self):
        configuration.load_test_config()

    @mock.patch.object(GlueJobHook, 'get_conn')
    @mock.patch.object(GlueJobHook, 'get_job_state')
    def test_poke(self, mock_get_job_state, mock_conn):
        mock_conn.return_value.get_job_run()
        mock_get_job_state.return_value = 'SUCCEEDED'
        op = GlueJobSensor(
            task_id='test_glue_job_sensor',
            job_name='aws_test_glue_job',
            run_id='5152fgsfsjhsh61661',
            poke_interval=1,
            timeout=5,
            aws_conn_id='aws_default',
        )
        assert op.poke({})

    @mock.patch.object(GlueJobHook, 'get_conn')
    @mock.patch.object(GlueJobHook, 'get_job_state')
    def test_poke_false(self, mock_get_job_state, mock_conn):
        mock_conn.return_value.get_job_run()
        mock_get_job_state.return_value = 'RUNNING'
        op = GlueJobSensor(
            task_id='test_glue_job_sensor',
            job_name='aws_test_glue_job',
            run_id='5152fgsfsjhsh61661',
            poke_interval=1,
            timeout=5,
            aws_conn_id='aws_default',
        )
        assert not op.poke({})


if __name__ == '__main__':
    unittest.main()
","
1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18import unittest
19from unittest import mock
20
21from airflow import configuration
22from airflow.providers.amazon.aws.hooks.glue import GlueJobHook
23from airflow.providers.amazon.aws.sensors.glue import GlueJobSensor
24
25
26class TestGlueJobSensor(unittest.TestCase):
27    def setUp(self):
28        configuration.load_test_config()
29
30    @mock.patch.object(GlueJobHook, 'get_conn')
31    @mock.patch.object(GlueJobHook, 'get_job_state')
32    def test_poke(self, mock_get_job_state, mock_conn):
33        mock_conn.return_value.get_job_run()
34        mock_get_job_state.return_value = 'SUCCEEDED'
35        op = GlueJobSensor(
36            task_id='test_glue_job_sensor',
37            job_name='aws_test_glue_job',
38            run_id='5152fgsfsjhsh61661',
39            poke_interval=1,
40            timeout=5,
41            aws_conn_id='aws_default',
42        )
43
44    @mock.patch.object(GlueJobHook, 'get_conn')
45    @mock.patch.object(GlueJobHook, 'get_job_state')
46    def test_poke_false(self, mock_get_job_state, mock_conn):
47        mock_conn.return_value.get_job_run()
48        mock_get_job_state.return_value = 'RUNNING'
49        op = GlueJobSensor(
50            task_id='test_glue_job_sensor',
51            job_name='aws_test_glue_job',
52            run_id='5152fgsfsjhsh61661',
53            poke_interval=1,
54            timeout=5,
55            aws_conn_id='aws_default',
56        )
57
58
59if __name__ == '__main__':
60    unittest.main()
61","[['op.poke({})', '==', 'True'], ['op.poke({})', '==', 'False']]",2,2,1.0,0.0008928571428571,"['mock_get_job_state', 'mock_conn', 'mock_get_job_state.return_value', 'op']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mock_get_job_state', 'mock_conn', 'mock_get_job_state.return_value', 'op']
*Code:

1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18import unittest
19from unittest import mock
20
21from airflow import configuration
22from airflow.providers.amazon.aws.hooks.glue import GlueJobHook
23from airflow.providers.amazon.aws.sensors.glue import GlueJobSensor
24
25
26class TestGlueJobSensor(unittest.TestCase):
27    def setUp(self):
28        configuration.load_test_config()
29
30    @mock.patch.object(GlueJobHook, 'get_conn')
31    @mock.patch.object(GlueJobHook, 'get_job_state')
32    def test_poke(self, mock_get_job_state, mock_conn):
33        mock_conn.return_value.get_job_run()
34        mock_get_job_state.return_value = 'SUCCEEDED'
35        op = GlueJobSensor(
36            task_id='test_glue_job_sensor',
37            job_name='aws_test_glue_job',
38            run_id='5152fgsfsjhsh61661',
39            poke_interval=1,
40            timeout=5,
41            aws_conn_id='aws_default',
42        )
43
44    @mock.patch.object(GlueJobHook, 'get_conn')
45    @mock.patch.object(GlueJobHook, 'get_job_state')
46    def test_poke_false(self, mock_get_job_state, mock_conn):
47        mock_conn.return_value.get_job_run()
48        mock_get_job_state.return_value = 'RUNNING'
49        op = GlueJobSensor(
50            task_id='test_glue_job_sensor',
51            job_name='aws_test_glue_job',
52            run_id='5152fgsfsjhsh61661',
53            poke_interval=1,
54            timeout=5,
55            aws_conn_id='aws_default',
56        )
57
58
59if __name__ == '__main__':
60    unittest.main()
61",3752,"[[32, 'mock_get_job_state', '!=', None, ""Function 'get_job_state' from 'GlueJobHook' must be able to be called""],
[32, 'mock_conn', '!=', None, ""Function 'get_conn' from 'GlueJobHook' must be able to be called""],
[34, 'mock_get_job_state.return_value', '==', 'SUCCEEDED', ""The returned job state should be 'SUCCEEDED'""],
[48, 'mock_get_job_state.return_value', '==', 'RUNNING', ""The returned job state should be 'RUNNING'""],
[42, 'op', '!=', None, ""GlueJobSensor object 'op' is supposed to be instantiated""],
[56, 'op', '!=', None, ""GlueJobSensor object 'op' is supposed to be instantiated""]]"
si618/pi-time,"# pylint:disable=W0105, W0511, misplaced-comparison-constant
""""""Stray backslash escapes may be missing a raw-string prefix.""""""

__revision__ = '$Id$'

# Bad escape sequences, which probably don't do what you expect.
A = ""\[\]\\""
assert '\/' == '\\/'
ESCAPE_BACKSLASH = '\`'

# Valid escape sequences.
NEWLINE = ""\n""
OLD_ESCAPES = '\a\b\f\n\t\r\v'
HEX = '\xad\x0a\x0d'
FALSE_OCTAL = '\o123\o000'  # Not octal in Python
OCTAL = '\123\000'
NOT_OCTAL = '\888\999'
NUL = '\0'
UNICODE = u'\u1234'
HIGH_UNICODE = u'\U0000abcd'
QUOTES = '\'\""'
LITERAL_NEWLINE = '\
'
ESCAPE_UNICODE = ""\\\\n""

# Bad docstring
""""""Even in a docstring

You shouldn't have ambiguous text like: C:\Program Files\alpha
""""""
","
1# pylint:disable=W0105, W0511, misplaced-comparison-constant
2""""""Stray backslash escapes may be missing a raw-string prefix.""""""
3
4__revision__ = '$Id$'
5
6# Bad escape sequences, which probably don't do what you expect.
7A = ""\[\]\\""
8ESCAPE_BACKSLASH = '\`'
9
10# Valid escape sequences.
11NEWLINE = ""\n""
12OLD_ESCAPES = '\a\b\f\n\t\r\v'
13HEX = '\xad\x0a\x0d'
14FALSE_OCTAL = '\o123\o000'  # Not octal in Python
15OCTAL = '\123\000'
16NOT_OCTAL = '\888\999'
17NUL = '\0'
18UNICODE = u'\u1234'
19HIGH_UNICODE = u'\U0000abcd'
20QUOTES = '\'\""'
21LITERAL_NEWLINE = '\
22'
23ESCAPE_UNICODE = ""\\\\n""
24
25# Bad docstring
26""""""Even in a docstring
27
28You shouldn't have ambiguous text like: C:\Program Files\alpha
29""""""
30","[[""'\\/'"", '==', ""'\\\\/'""]]",1,1,1.0,0.0014450867052023,"['__revision__', 'A', 'ESCAPE_BACKSLASH', 'NEWLINE', 'OLD_ESCAPES', 'HEX', 'FALSE_OCTAL', 'OCTAL', 'NOT_OCTAL', 'NUL', 'UNICODE', 'HIGH_UNICODE', 'QUOTES', 'LITERAL_NEWLINE', 'ESCAPE_UNICODE']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__revision__', 'A', 'ESCAPE_BACKSLASH', 'NEWLINE', 'OLD_ESCAPES', 'HEX', 'FALSE_OCTAL', 'OCTAL', 'NOT_OCTAL', 'NUL', 'UNICODE', 'HIGH_UNICODE', 'QUOTES', 'LITERAL_NEWLINE', 'ESCAPE_UNICODE']
*Code:

1# pylint:disable=W0105, W0511, misplaced-comparison-constant
2""""""Stray backslash escapes may be missing a raw-string prefix.""""""
3
4__revision__ = '$Id$'
5
6# Bad escape sequences, which probably don't do what you expect.
7A = ""\[\]\\""
8ESCAPE_BACKSLASH = '\`'
9
10# Valid escape sequences.
11NEWLINE = ""\n""
12OLD_ESCAPES = '\a\b\f\n\t\r\v'
13HEX = '\xad\x0a\x0d'
14FALSE_OCTAL = '\o123\o000'  # Not octal in Python
15OCTAL = '\123\000'
16NOT_OCTAL = '\888\999'
17NUL = '\0'
18UNICODE = u'\u1234'
19HIGH_UNICODE = u'\U0000abcd'
20QUOTES = '\'\""'
21LITERAL_NEWLINE = '\
22'
23ESCAPE_UNICODE = ""\\\\n""
24
25# Bad docstring
26""""""Even in a docstring
27
28You shouldn't have ambiguous text like: C:\Program Files\alpha
29""""""
30",2295,"[[6, 'A', '==', 6, ""A has length 6 characters""],
 [8, 'ESCAPE_BACKSLASH', '==', 2, ""ESCAPE_BACKSLASH has length 2 characters""],
 [11, 'NEWLINE', '==', 1, ""NEWLINE has length 1 character""],
 [12, 'OLD_ESCAPES', '==', 7, ""OLD_ESCAPES has length 7 characters""],
 [13, 'HEX', '==', 5, ""HEX has length 5 characters""],
 [14, 'FALSE_OCTAL', '==', 8, ""FALSE_OCTAL has length 8 characters""],
 [15, 'OCTAL', '==', 6, ""OCTAL has length 6 characters""],
 [16, 'NOT_OCTAL', '==', 6, ""NOT_OCTAL has length 6 characters""],
 [17, 'NUL', '==', 1, ""NUL has length 1 character""],
 [18, 'UNICODE', '==', 1, ""UNICODE has length 1 character""],
 [19, 'HIGH_UNICODE', '==', 1, ""HIGH_UNICODE has length 1 character""],
 [20, 'QUOTES', '==', 2, ""QUOTES has length 2 characters""],
 [22, 'LITERAL_NEWLINE', '==', 1, ""LITERAL_NEWLINE has length 1 character""],
 [23, 'ESCAPE_UNICODE', '==', 3, ""ESCAPE_UNICODE has length 3 characters""]]"
ee08b397/LeetCode-4,"""""""
Design a data structure that supports the following two operations:

void addWord(word)
bool search(word)
search(word) can search a literal word or a regular expression string containing only letters a-z or .. A . means it can
represent any one letter.

For example:

addWord(""bad"")
addWord(""dad"")
addWord(""mad"")
search(""pad"") -> false
search(""bad"") -> true
search("".ad"") -> true
search(""b.."") -> true
Note:
You may assume that all words are consist of lowercase letters a-z.
""""""
__author__ = 'Daniel'


class TrieNode:
    def __init__(self):
        """"""
        Initialize your data structure here.
        """"""
        # node value depends on the parent's hash mapping
        self.ended = False
        self.children = {}


class WordDictionary:
    def __init__(self):
        """"""
        initialize your data structure here.
        """"""
        self.root = TrieNode()

    def addWord(self, word):
        """"""
        Adds a word into the data structure.
        :type word: str
        :rtype: None
        """"""
        cur = self.root
        for w in word:
            if w not in cur.children:
                cur.children[w] = TrieNode()
            cur = cur.children[w]

        cur.ended = True

    def search(self, word):
        """"""
        Returns if the word is in the data structure. A word could contain the dot character '.' to represent any one
        letter.
        :type word: str
        :rtype: bool
        """"""
        return self.__search(word, self.root)

    def __search(self, word, cur):
        if not word:
            return cur.ended

        w = word[0]
        if w != ""."":
            if w in cur.children:
                return self.__search(word[1:], cur.children[w])
            else:
                return False
        else:
            for child in cur.children.values():
                if self.__search(word[1:], child):
                    return True

        return False

if __name__ == ""__main__"":
    dic = WordDictionary()
    dic.addWord(""a"")
    assert dic.search(""."") == True","
1""""""
2Design a data structure that supports the following two operations:
3
4void addWord(word)
5bool search(word)
6search(word) can search a literal word or a regular expression string containing only letters a-z or .. A . means it can
7represent any one letter.
8
9For example:
10
11addWord(""bad"")
12addWord(""dad"")
13addWord(""mad"")
14search(""pad"") -> false
15search(""bad"") -> true
16search("".ad"") -> true
17search(""b.."") -> true
18Note:
19You may assume that all words are consist of lowercase letters a-z.
20""""""
21__author__ = 'Daniel'
22
23
24class TrieNode:
25    def __init__(self):
26        """"""
27        Initialize your data structure here.
28        """"""
29        # node value depends on the parent's hash mapping
30        self.ended = False
31        self.children = {}
32
33
34class WordDictionary:
35    def __init__(self):
36        """"""
37        initialize your data structure here.
38        """"""
39        self.root = TrieNode()
40
41    def addWord(self, word):
42        """"""
43        Adds a word into the data structure.
44        :type word: str
45        :rtype: None
46        """"""
47        cur = self.root
48        for w in word:
49            if w not in cur.children:
50                cur.children[w] = TrieNode()
51            cur = cur.children[w]
52
53        cur.ended = True
54
55    def search(self, word):
56        """"""
57        Returns if the word is in the data structure. A word could contain the dot character '.' to represent any one
58        letter.
59        :type word: str
60        :rtype: bool
61        """"""
62        return self.__search(word, self.root)
63
64    def __search(self, word, cur):
65        if not word:
66            return cur.ended
67
68        w = word[0]
69        if w != ""."":
70            if w in cur.children:
71                return self.__search(word[1:], cur.children[w])
72            else:
73                return False
74        else:
75            for child in cur.children.values():
76                if self.__search(word[1:], child):
77                    return True
78
79        return False
80
81if __name__ == ""__main__"":
82    dic = WordDictionary()
83    dic.addWord(""a"")","[['dic.search(""."")', '==', 'True']]",1,1,1.0,0.0004904364884747,"['__author__', 'self.ended', 'self.children', 'self.root', 'word', 'cur', 'cur.children[w]', 'cur.ended', 'w', 'dic']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'self.ended', 'self.children', 'self.root', 'word', 'cur', 'cur.children[w]', 'cur.ended', 'w', 'dic']
*Code:

1""""""
2Design a data structure that supports the following two operations:
3
4void addWord(word)
5bool search(word)
6search(word) can search a literal word or a regular expression string containing only letters a-z or .. A . means it can
7represent any one letter.
8
9For example:
10
11addWord(""bad"")
12addWord(""dad"")
13addWord(""mad"")
14search(""pad"") -> false
15search(""bad"") -> true
16search("".ad"") -> true
17search(""b.."") -> true
18Note:
19You may assume that all words are consist of lowercase letters a-z.
20""""""
21__author__ = 'Daniel'
22
23
24class TrieNode:
25    def __init__(self):
26        """"""
27        Initialize your data structure here.
28        """"""
29        # node value depends on the parent's hash mapping
30        self.ended = False
31        self.children = {}
32
33
34class WordDictionary:
35    def __init__(self):
36        """"""
37        initialize your data structure here.
38        """"""
39        self.root = TrieNode()
40
41    def addWord(self, word):
42        """"""
43        Adds a word into the data structure.
44        :type word: str
45        :rtype: None
46        """"""
47        cur = self.root
48        for w in word:
49            if w not in cur.children:
50                cur.children[w] = TrieNode()
51            cur = cur.children[w]
52
53        cur.ended = True
54
55    def search(self, word):
56        """"""
57        Returns if the word is in the data structure. A word could contain the dot character '.' to represent any one
58        letter.
59        :type word: str
60        :rtype: bool
61        """"""
62        return self.__search(word, self.root)
63
64    def __search(self, word, cur):
65        if not word:
66            return cur.ended
67
68        w = word[0]
69        if w != ""."":
70            if w in cur.children:
71                return self.__search(word[1:], cur.children[w])
72            else:
73                return False
74        else:
75            for child in cur.children.values():
76                if self.__search(word[1:], child):
77                    return True
78
79        return False
80
81if __name__ == ""__main__"":
82    dic = WordDictionary()
83    dic.addWord(""a"")",3659,"[[25, 'self.ended', '==', False, ""in the TrieNode initialization, ended should be False""],
[26, 'self.children', '==', {}, ""in the TrieNode initialization, children should be an empty dictionary""],
[35, 'self.root', '!=', None, ""root should not be none after WordDictionary initialization""],
[41, 'word', '!=', None, ""word should not be none""],
[46, 'cur', '!=', None, ""cur should not be none in the loop""],
[63, 'word', '!=', None, ""word should not be none when searching""],
[64, 'cur', '!=', None, ""cur should not be none when searching""],
[68, 'w', '!=', None, ""w, the first character of word, should not be none""],
[70, 'cur.children[w]', '!=', None, ""the corresponding TrieNode should not be none when w is a child of cur""],
[81, 'dic', '!=', None, ""dic initialization should be successful""]]"
mhvk/numpy,"import io
import re
from contextlib import redirect_stdout

import pytest

from numpy.distutils import log


def setup_module():
    f = io.StringIO()  # changing verbosity also logs here, capture that
    with redirect_stdout(f):
        log.set_verbosity(2, force=True)  # i.e. DEBUG


def teardown_module():
    log.set_verbosity(0, force=True)  # the default


r_ansi = re.compile(r""\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])"")


@pytest.mark.parametrize(""func_name"", [""error"", ""warn"", ""info"", ""debug""])
def test_log_prefix(func_name):
    func = getattr(log, func_name)
    msg = f""{func_name} message""
    f = io.StringIO()
    with redirect_stdout(f):
        func(msg)
    out = f.getvalue()
    assert out  # sanity check
    clean_out = r_ansi.sub("""", out)
    line = next(line for line in clean_out.splitlines())
    assert line == f""{func_name.upper()}: {msg}""
","
1import io
2import re
3from contextlib import redirect_stdout
4
5import pytest
6
7from numpy.distutils import log
8
9
10def setup_module():
11    f = io.StringIO()  # changing verbosity also logs here, capture that
12    with redirect_stdout(f):
13        log.set_verbosity(2, force=True)  # i.e. DEBUG
14
15
16def teardown_module():
17    log.set_verbosity(0, force=True)  # the default
18
19
20r_ansi = re.compile(r""\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])"")
21
22
23@pytest.mark.parametrize(""func_name"", [""error"", ""warn"", ""info"", ""debug""])
24def test_log_prefix(func_name):
25    func = getattr(log, func_name)
26    msg = f""{func_name} message""
27    f = io.StringIO()
28    with redirect_stdout(f):
29        func(msg)
30    out = f.getvalue()
31    clean_out = r_ansi.sub("""", out)
32    line = next(line for line in clean_out.splitlines())
33","[['out', '==', 'True'], ['line', '==', 'f""{func_name.upper()}: {msg}""']]",2,2,1.0,0.0023041474654377,"['f', 'r_ansi', 'func_name', 'func', 'msg', 'out', 'clean_out', 'line']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['f', 'r_ansi', 'func_name', 'func', 'msg', 'out', 'clean_out', 'line']
*Code:

1import io
2import re
3from contextlib import redirect_stdout
4
5import pytest
6
7from numpy.distutils import log
8
9
10def setup_module():
11    f = io.StringIO()  # changing verbosity also logs here, capture that
12    with redirect_stdout(f):
13        log.set_verbosity(2, force=True)  # i.e. DEBUG
14
15
16def teardown_module():
17    log.set_verbosity(0, force=True)  # the default
18
19
20r_ansi = re.compile(r""\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])"")
21
22
23@pytest.mark.parametrize(""func_name"", [""error"", ""warn"", ""info"", ""debug""])
24def test_log_prefix(func_name):
25    func = getattr(log, func_name)
26    msg = f""{func_name} message""
27    f = io.StringIO()
28    with redirect_stdout(f):
29        func(msg)
30    out = f.getvalue()
31    clean_out = r_ansi.sub("""", out)
32    line = next(line for line in clean_out.splitlines())
33",2297,"[[10, 'f', '==', None, ""assert 'f' is initialized and not used before initialization""], 
 [20, 'r_ansi', '!=', None, ""assert that 'r_ansi' has been compiled successfully""],
 [24, 'func_name', '!=', None, ""assert 'func_name' is available for the function 'test_log_prefix' to prevent name error""],
 [29, 'msg', '!=', None, ""assert 'msg' exists to make sure the log message is presented""],
 [30, 'out', '!=', None,  ""assert 'out' captures the log message""],
 [31, 'clean_out', '!=', None,  ""assert function 'r_ansi.sub' works correctly and 'clean_out' is not None""],
 [32, 'line', '!=', None, ""assert 'line' is generated and not None after splitting 'clean_out'""]]"
mind1master/aiohttp,"import asyncio

import pytest

from aiohttp import web


@pytest.mark.run_loop
def test_middleware_modifies_response(create_app_and_client):

    @asyncio.coroutine
    def handler(request):
        return web.Response(body=b'OK')

    @asyncio.coroutine
    def middleware_factory(app, handler):

        @asyncio.coroutine
        def middleware(request):
            resp = yield from handler(request)
            assert 200 == resp.status
            resp.set_status(201)
            resp.text = resp.text + '[MIDDLEWARE]'
            return resp
        return middleware

    app, client = yield from create_app_and_client()
    app.middlewares.append(middleware_factory)
    app.router.add_route('GET', '/', handler)
    resp = yield from client.get('/')
    assert 201 == resp.status
    txt = yield from resp.text()
    assert 'OK[MIDDLEWARE]' == txt


@pytest.mark.run_loop
def test_middleware_handles_exception(create_app_and_client):

    @asyncio.coroutine
    def handler(request):
        raise RuntimeError('Error text')

    @asyncio.coroutine
    def middleware_factory(app, handler):

        @asyncio.coroutine
        def middleware(request):
            with pytest.raises(RuntimeError) as ctx:
                yield from handler(request)
            return web.Response(status=501,
                                text=str(ctx.value) + '[MIDDLEWARE]')

        return middleware

    app, client = yield from create_app_and_client()
    app.middlewares.append(middleware_factory)
    app.router.add_route('GET', '/', handler)
    resp = yield from client.get('/')
    assert 501 == resp.status
    txt = yield from resp.text()
    assert 'Error text[MIDDLEWARE]' == txt


@pytest.mark.run_loop
def test_middleware_chain(create_app_and_client):

    @asyncio.coroutine
    def handler(request):
        return web.Response(text='OK')

    def make_factory(num):

        @asyncio.coroutine
        def factory(app, handler):

            def middleware(request):
                resp = yield from handler(request)
                resp.text = resp.text + '[{}]'.format(num)
                return resp

            return middleware
        return factory

    app, client = yield from create_app_and_client()
    app.middlewares.append(make_factory(1))
    app.middlewares.append(make_factory(2))
    app.router.add_route('GET', '/', handler)
    resp = yield from client.get('/')
    assert 200 == resp.status
    txt = yield from resp.text()
    assert 'OK[2][1]' == txt
","
1import asyncio
2
3import pytest
4
5from aiohttp import web
6
7
8@pytest.mark.run_loop
9def test_middleware_modifies_response(create_app_and_client):
10
11    @asyncio.coroutine
12    def handler(request):
13        return web.Response(body=b'OK')
14
15    @asyncio.coroutine
16    def middleware_factory(app, handler):
17
18        @asyncio.coroutine
19        def middleware(request):
20            resp = yield from handler(request)
21            resp.set_status(201)
22            resp.text = resp.text + '[MIDDLEWARE]'
23            return resp
24        return middleware
25
26    app, client = yield from create_app_and_client()
27    app.middlewares.append(middleware_factory)
28    app.router.add_route('GET', '/', handler)
29    resp = yield from client.get('/')
30    txt = yield from resp.text()
31
32
33@pytest.mark.run_loop
34def test_middleware_handles_exception(create_app_and_client):
35
36    @asyncio.coroutine
37    def handler(request):
38        raise RuntimeError('Error text')
39
40    @asyncio.coroutine
41    def middleware_factory(app, handler):
42
43        @asyncio.coroutine
44        def middleware(request):
45            with pytest.raises(RuntimeError) as ctx:
46                yield from handler(request)
47            return web.Response(status=501,
48                                text=str(ctx.value) + '[MIDDLEWARE]')
49
50        return middleware
51
52    app, client = yield from create_app_and_client()
53    app.middlewares.append(middleware_factory)
54    app.router.add_route('GET', '/', handler)
55    resp = yield from client.get('/')
56    txt = yield from resp.text()
57
58
59@pytest.mark.run_loop
60def test_middleware_chain(create_app_and_client):
61
62    @asyncio.coroutine
63    def handler(request):
64        return web.Response(text='OK')
65
66    def make_factory(num):
67
68        @asyncio.coroutine
69        def factory(app, handler):
70
71            def middleware(request):
72                resp = yield from handler(request)
73                resp.text = resp.text + '[{}]'.format(num)
74                return resp
75
76            return middleware
77        return factory
78
79    app, client = yield from create_app_and_client()
80    app.middlewares.append(make_factory(1))
81    app.middlewares.append(make_factory(2))
82    app.router.add_route('GET', '/', handler)
83    resp = yield from client.get('/')
84    txt = yield from resp.text()
85","[['200', '==', 'resp.status'], ['201', '==', 'resp.status'], [""'OK[MIDDLEWARE]'"", '==', 'txt'], ['501', '==', 'resp.status'], [""'Error text[MIDDLEWARE]'"", '==', 'txt'], ['200', '==', 'resp.status'], [""'OK[2][1]'"", '==', 'txt']]",7,7,1.0,0.0028056112224448,"['create_app_and_client', 'request', 'app', 'handler', 'resp', 'resp.text', 'client', 'txt', 'num']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['create_app_and_client', 'request', 'app', 'handler', 'resp', 'resp.text', 'client', 'txt', 'num']
*Code:

1import asyncio
2
3import pytest
4
5from aiohttp import web
6
7
8@pytest.mark.run_loop
9def test_middleware_modifies_response(create_app_and_client):
10
11    @asyncio.coroutine
12    def handler(request):
13        return web.Response(body=b'OK')
14
15    @asyncio.coroutine
16    def middleware_factory(app, handler):
17
18        @asyncio.coroutine
19        def middleware(request):
20            resp = yield from handler(request)
21            resp.set_status(201)
22            resp.text = resp.text + '[MIDDLEWARE]'
23            return resp
24        return middleware
25
26    app, client = yield from create_app_and_client()
27    app.middlewares.append(middleware_factory)
28    app.router.add_route('GET', '/', handler)
29    resp = yield from client.get('/')
30    txt = yield from resp.text()
31
32
33@pytest.mark.run_loop
34def test_middleware_handles_exception(create_app_and_client):
35
36    @asyncio.coroutine
37    def handler(request):
38        raise RuntimeError('Error text')
39
40    @asyncio.coroutine
41    def middleware_factory(app, handler):
42
43        @asyncio.coroutine
44        def middleware(request):
45            with pytest.raises(RuntimeError) as ctx:
46                yield from handler(request)
47            return web.Response(status=501,
48                                text=str(ctx.value) + '[MIDDLEWARE]')
49
50        return middleware
51
52    app, client = yield from create_app_and_client()
53    app.middlewares.append(middleware_factory)
54    app.router.add_route('GET', '/', handler)
55    resp = yield from client.get('/')
56    txt = yield from resp.text()
57
58
59@pytest.mark.run_loop
60def test_middleware_chain(create_app_and_client):
61
62    @asyncio.coroutine
63    def handler(request):
64        return web.Response(text='OK')
65
66    def make_factory(num):
67
68        @asyncio.coroutine
69        def factory(app, handler):
70
71            def middleware(request):
72                resp = yield from handler(request)
73                resp.text = resp.text + '[{}]'.format(num)
74                return resp
75
76            return middleware
77        return factory
78
79    app, client = yield from create_app_and_client()
80    app.middlewares.append(make_factory(1))
81    app.middlewares.append(make_factory(2))
82    app.router.add_route('GET', '/', handler)
83    resp = yield from client.get('/')
84    txt = yield from resp.text()
85",3901,"[[9, 'create_app_and_client', '!=', None, ""Function create_app_and_client needs to be defined for the test""],
[11, 'handler', '!=', None, ""Handler function must not be None""],
[16, 'app', '!=', None, ""Application object 'app' must not be None""],
[16, 'handler', '!=', None, ""handler must not be initialized, not None""],
[19, 'middleware', '!=', None, ""The middleware function must not be None""],
[19, 'request', '!=', None, ""The request object cannot be None""],
[20, 'resp', '!=', None, ""The resp object must not be None""],
[26, 'app', '!=', None, ""Application object 'app' must not be None""],
[26, 'client', '!=', None, ""Client object 'client' must not be None""],
[30, 'txt', '!=', None, ""txt object should not be None""],
[34, 'create_app_and_client', '!=', None, ""Function create_app_and_client needs to be defined for the test""],
[37, 'handler', '!=', None, ""Handler function must not be None""],
[52, 'app', '!=', None, ""Application object 'app' must not be None""],
[52, 'client', '!=', None, ""Client object 'client' must not be None""],
[56, 'txt', '!=', None, ""txt object should not be None""],
[60, 'create_app_and_client', '!=', None, ""Function create_app_and_client needs to be defined for the test""],
[79, 'app', '!=', None, ""Application object 'app' must not be None""],
[79, 'client', '!=', None, ""Client object 'client' must not be None""],
[84, 'txt', '!=', None, ""txt object should not be None""]]"
rosenbrockc/acorn,"""""""Tests the decoration and logging of the pandas package by running some common
code lines and checking that the logged entries make sense.
""""""
import pytest
import six
@pytest.fixture(scope=""module"", autouse=True)
def acorndb(request, dbdir):
    """"""Creates a sub-directory in the temporary folder for the `pandas` package's
    database logging. Also sets the package and task to `acorn` and `pandas`
    respectively.

    Returns:
        (py.path.local): representing the sub-directory for the packages JSON
          files.
    """"""
    from db import db_init
    return db_init(""pandas"", dbdir)

def test_decorate():
    """"""Tests the decoration of the full numpy module. Since the module can
    change, the exact number of methods and objects decorated will be constantly
    changing. Instead, we just make sure that some were decorated, skipped and
    N/A in the module statistics.
    """"""
    import acorn.pandas as pd
    from db import decorate_check
    decorate_check(""pandas"")

def test_readcsv():
    """"""Tests reading from a CSV file, since it is one of the most common methods
    that gets called on the pandas library.
    """"""
    import acorn.pandas as pd
    from os import path
    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))

    from db import db_entries
    sentries, uuids = db_entries(""pandas"")

    uid, entry = sentries[-1]
    assert entry[""m""] == ""pandas.io.parsers.read_csv""
    assert uid in uuids
    assert entry[""a""][""_""] == [""tests/darwin.csv""]

    assert uuids[uid][""fqdn""] == ""pandas.core.frame.DataFrame""
    assert ""columns"" in uuids[uid]
    assert uuids[uid][""shape""] == (15, 2)
    assert len(uuids[uid][""columns""]) == 2
    
    #So far, we have been checking the logging directly on the object. We need
    #to make sure that the data was actually writen to file.
    from acorn.logging.database import dbs
    tdb = dbs[(""acorn"", ""pandas"")]
    assert len(tdb.entities) > 0
    assert len(tdb.uuids) > 0

def test_frametypes():
    """"""Tests construction of :class:`pandas.Series` and
    :class:`pandas.Index`. :class:`~pandas.Series` and :class:`~pandas.Index` are
    tricky because they alse have `staticmethod` constructors that get called by
    the :class:`pandas.DataFrame` constructor. So we need to test direct
    construction as well.
    """"""
    #Since we have already tested the writing to disk, we will now disable the
    #writing and just examine the in-memory collections.
    import acorn.pandas as pd
    ind = pd.Index([1./i for i in range(1, 11)], dtype=float)
    ser = pd.Series(range(2, 12), index=ind)

    from db import db_entries
    sentries, uuids = db_entries(""pandas"")

    u0, e0 = sentries[-2]
    u1, e1 = sentries[-1]

    assert e0[""m""] == ""pandas.indexes.base.Index.__new__""
    assert e0[""a""][""dtype""] == ""float""
    assert ""len=10"" in e0[""a""][""_""][0]
    assert ""max=1.0"" in e0[""a""][""_""][0]

    assert e1[""m""] == ""pandas.core.series.Series.__new__""
    assert e1[""a""][""index""] == u0
    if six.PY2:
        assert e1[""a""][""_""] == [""<type 'list'> len=10 min=2 max=11""]
    else:
        assert e1[""a""][""_""] == [""<class 'range'> len=10 min=2 max=11""]
    
def test_instance():
    """"""Tests the instance methods :meth:`pandas.DataFrame.apply` using a lambda
    function and :func:`numpy.sqrt`; also tests
    :meth:`pandas.DataFrame.describe` because it has a tricky decorator using
    `staticmethod` (it gets bound as an instance method by the __init__ call on
    the newly constructed :class:`pandas.DataFrame`.
    """"""
    from numpy import sqrt
    lambfun = lambda x: x**2

    import acorn.pandas as pd
    import acorn.numpy as np
    if six.PY2:
        pdf = pd.DataFrame(range(15,25))
    else:
        pdf = pd.DataFrame(data=list(range(15,25)))
    pdf.apply(lambfun)
    pdf.apply(np.sqrt)
    pdf.describe()

    from db import db_entries
    sentries, uuids = db_entries(""pandas"")

    u0, e0 = sentries[-4] #Constructor
    u1, e1 = sentries[-3] #lambda apply
    u2, e2 = sentries[-2] #sqrt apply
    u3, e3 = sentries[-1] #describe

    #pandas in python 3 requires us to name the data keyword argument; it
    #doesn't automatically splice it into the first position.
    assert e0[""m""] == ""pandas.core.frame.DataFrame.__new__""
    if six.PY2:
        assert e0[""a""][""_""] == [""<type 'list'> len=10 min=15 max=24""]
    else:
        assert e0[""a""][""data""] == ""<class 'list'> len=10 min=15 max=24""
    
    assert e1[""m""] == ""pandas.core.frame.apply""
    assert e1[""a""][""_""][0] == u0
    assert e1[""a""][""_""][1] == ""lambda (x)""
    #For instance methods, the uuid keys in the entries dict are those of the
    #instance that the method was called on.
    assert u1 == u0

    assert e2[""m""] == ""pandas.core.frame.apply""
    assert e2[""a""][""_""][0] == u0
    #Unfortunately, the order in which members of a package is returned is not
    #always deterministic, so numpy.sqrt may be first picked up by
    #numpy.matlib.sqrt.
    assert (e2[""a""][""_""][1] == ""numpy.sqrt"" or
            e2[""a""][""_""][1] == ""numpy.matlib.sqrt"")
    assert u2 == u0

    assert e3[""m""] == ""pandas.core.generic.describe""
    assert e3[""a""][""_""][0] == u0
    assert u3 == u0

def test_gets():
    """"""Tests the pandas.get and pandas.__getitem__ logging.
    """"""
    import acorn.pandas as pd
    from os import path
    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))
    csdf.get([""y""])
    csdf[[""Unnamed: 0"", ""y""]]
    
    from db import db_entries
    sentries, uuids = db_entries(""pandas"")

    u0, e0 = sentries[-3] #Constructor
    u1, e1 = sentries[-2] #static get
    u2, e2 = sentries[-1] #getitem

    assert e0[""m""] == ""pandas.io.parsers.read_csv""
    assert e0[""a""][""_""] == [""tests/darwin.csv""]
    
    assert e1[""m""] == ""pandas.core.generic.get""
    if six.PY2:
        assert e1[""a""][""_""] == [u0, ""<type 'list'> len=1 min=y max=y""]
    else:
        assert e1[""a""][""_""] == [u0, ""<class 'list'> len=1 min=y max=y""]

    assert e2[""m""] == ""pandas.core.frame.__getitem__""
    if six.PY2:
        assert e2[""a""][""_""] == [u0, ""<type 'list'> len=2 min=Unnamed: 0 max=y""]
    else:
        assert e2[""a""][""_""] == [u0, ""<class 'list'> len=2 min=Unnamed: 0 max=y""]
","
1""""""Tests the decoration and logging of the pandas package by running some common
2code lines and checking that the logged entries make sense.
3""""""
4import pytest
5import six
6@pytest.fixture(scope=""module"", autouse=True)
7def acorndb(request, dbdir):
8    """"""Creates a sub-directory in the temporary folder for the `pandas` package's
9    database logging. Also sets the package and task to `acorn` and `pandas`
10    respectively.
11
12    Returns:
13        (py.path.local): representing the sub-directory for the packages JSON
14          files.
15    """"""
16    from db import db_init
17    return db_init(""pandas"", dbdir)
18
19def test_decorate():
20    """"""Tests the decoration of the full numpy module. Since the module can
21    change, the exact number of methods and objects decorated will be constantly
22    changing. Instead, we just make sure that some were decorated, skipped and
23    N/A in the module statistics.
24    """"""
25    import acorn.pandas as pd
26    from db import decorate_check
27    decorate_check(""pandas"")
28
29def test_readcsv():
30    """"""Tests reading from a CSV file, since it is one of the most common methods
31    that gets called on the pandas library.
32    """"""
33    import acorn.pandas as pd
34    from os import path
35    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))
36
37    from db import db_entries
38    sentries, uuids = db_entries(""pandas"")
39
40    uid, entry = sentries[-1]
41
42    
43    #So far, we have been checking the logging directly on the object. We need
44    #to make sure that the data was actually writen to file.
45    from acorn.logging.database import dbs
46    tdb = dbs[(""acorn"", ""pandas"")]
47
48def test_frametypes():
49    """"""Tests construction of :class:`pandas.Series` and
50    :class:`pandas.Index`. :class:`~pandas.Series` and :class:`~pandas.Index` are
51    tricky because they alse have `staticmethod` constructors that get called by
52    the :class:`pandas.DataFrame` constructor. So we need to test direct
53    construction as well.
54    """"""
55    #Since we have already tested the writing to disk, we will now disable the
56    #writing and just examine the in-memory collections.
57    import acorn.pandas as pd
58    ind = pd.Index([1./i for i in range(1, 11)], dtype=float)
59    ser = pd.Series(range(2, 12), index=ind)
60
61    from db import db_entries
62    sentries, uuids = db_entries(""pandas"")
63
64    u0, e0 = sentries[-2]
65    u1, e1 = sentries[-1]
66
67
68    if six.PY2:
69    else:
70    
71def test_instance():
72    """"""Tests the instance methods :meth:`pandas.DataFrame.apply` using a lambda
73    function and :func:`numpy.sqrt`; also tests
74    :meth:`pandas.DataFrame.describe` because it has a tricky decorator using
75    `staticmethod` (it gets bound as an instance method by the __init__ call on
76    the newly constructed :class:`pandas.DataFrame`.
77    """"""
78    from numpy import sqrt
79    lambfun = lambda x: x**2
80
81    import acorn.pandas as pd
82    import acorn.numpy as np
83    if six.PY2:
84        pdf = pd.DataFrame(range(15,25))
85    else:
86        pdf = pd.DataFrame(data=list(range(15,25)))
87    pdf.apply(lambfun)
88    pdf.apply(np.sqrt)
89    pdf.describe()
90
91    from db import db_entries
92    sentries, uuids = db_entries(""pandas"")
93
94    u0, e0 = sentries[-4] #Constructor
95    u1, e1 = sentries[-3] #lambda apply
96    u2, e2 = sentries[-2] #sqrt apply
97    u3, e3 = sentries[-1] #describe
98
99    #pandas in python 3 requires us to name the data keyword argument; it
100    #doesn't automatically splice it into the first position.
101    if six.PY2:
102    else:
103    
104    #For instance methods, the uuid keys in the entries dict are those of the
105    #instance that the method was called on.
106
107    #Unfortunately, the order in which members of a package is returned is not
108    #always deterministic, so numpy.sqrt may be first picked up by
109    #numpy.matlib.sqrt.
110            e2[""a""][""_""][1] == ""numpy.matlib.sqrt"")
111
112
113def test_gets():
114    """"""Tests the pandas.get and pandas.__getitem__ logging.
115    """"""
116    import acorn.pandas as pd
117    from os import path
118    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))
119    csdf.get([""y""])
120    csdf[[""Unnamed: 0"", ""y""]]
121    
122    from db import db_entries
123    sentries, uuids = db_entries(""pandas"")
124
125    u0, e0 = sentries[-3] #Constructor
126    u1, e1 = sentries[-2] #static get
127    u2, e2 = sentries[-1] #getitem
128
129    
130    if six.PY2:
131    else:
132
133    if six.PY2:
134    else:
135","[['entry[""m""]', '==', '""p'], ['as.io.parsers.read_csv""', '==', 'True'], ['entry[""a""][""_""]', '==', '[""tests/darwin.csv""]'], ['uuids[uid][""fqdn""]', '==', '""p'], ['as.core.frame.DataFrame""', '==', 'True'], ['uuids[uid][""shape""]', '==', '(15'], ['len(uuids[uid][""columns""])', '==', '2'], ['len(tdb.entities)', '>', '0'], ['len(tdb.uuids)', '>', '0'], ['e0[""m""]', '==', '""p'], ['as.indexes.base.Index.__new__""', '==', 'True'], ['e0[""a""][""dtype""]', '==', '""float""'], ['e1[""m""]', '==', '""p'], ['as.core.series.Series.__new__""', '==', 'True'], ['e1[""a""][""index""]', '==', 'u0'], ['e1[""a""][""_""]', '==', '[""<type \'list\'> len=10 min=2 max=11""]'], ['e1[""a""][""_""]', '==', '[""<class \'range\'> len=10 min=2 max=11""]'], ['e0[""m""]', '==', '""p'], ['as.core.frame.DataFrame.__new__""', '==', 'True'], ['e0[""a""][""_""]', '==', '[""<type \'list\'> len=10 min=15 max=24""]'], ['e0[""a""][""data""]', '==', '""<class \'list\'> len=10 min=15 max=24""'], ['e1[""m""]', '==', '""p'], ['as.core.frame.apply""', '==', 'True'], ['e1[""a""][""_""][0]', '==', 'u0'], ['e1[""a""][""_""][1]', '==', '""lambda (x)""'], ['u1', '==', 'u0'], ['e2[""m""]', '==', '""p'], ['as.core.frame.apply""', '==', 'True'], ['e2[""a""][""_""][0]', '==', 'u0'], ['(e2[""a""][""_""][1]', '==', '""numpy.sqrt"" or'], ['u2', '==', 'u0'], ['e3[""m""]', '==', '""p'], ['as.core.generic.describe""', '==', 'True'], ['e3[""a""][""_""][0]', '==', 'u0'], ['u3', '==', 'u0'], ['e0[""m""]', '==', '""p'], ['as.io.parsers.read_csv""', '==', 'True'], ['e0[""a""][""_""]', '==', '[""tests/darwin.csv""]'], ['e1[""m""]', '==', '""p'], ['as.core.generic.get""', '==', 'True'], ['e1[""a""][""_""]', '==', '[u0'], ['e1[""a""][""_""]', '==', '[u0'], ['e2[""m""]', '==', '""p'], ['as.core.frame.__getitem__""', '==', 'True'], ['e2[""a""][""_""]', '==', '[u0'], ['e2[""a""][""_""]', '==', '[u0']]",39,46,1.1794871794871795,0.0074638974525393,"['request', 'dbdir', 'sentries', 'uuids', 'uid', 'entry', 'tdb', 'ind', 'ser', 'u0', 'e0', 'u1', 'e1', 'lambfun', 'pdf', 'u2', 'e2', 'u3', 'e3']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['request', 'dbdir', 'sentries', 'uuids', 'uid', 'entry', 'tdb', 'ind', 'ser', 'u0', 'e0', 'u1', 'e1', 'lambfun', 'pdf', 'u2', 'e2', 'u3', 'e3']
*Code:

1""""""Tests the decoration and logging of the pandas package by running some common
2code lines and checking that the logged entries make sense.
3""""""
4import pytest
5import six
6@pytest.fixture(scope=""module"", autouse=True)
7def acorndb(request, dbdir):
8    """"""Creates a sub-directory in the temporary folder for the `pandas` package's
9    database logging. Also sets the package and task to `acorn` and `pandas`
10    respectively.
11
12    Returns:
13        (py.path.local): representing the sub-directory for the packages JSON
14          files.
15    """"""
16    from db import db_init
17    return db_init(""pandas"", dbdir)
18
19def test_decorate():
20    """"""Tests the decoration of the full numpy module. Since the module can
21    change, the exact number of methods and objects decorated will be constantly
22    changing. Instead, we just make sure that some were decorated, skipped and
23    N/A in the module statistics.
24    """"""
25    import acorn.pandas as pd
26    from db import decorate_check
27    decorate_check(""pandas"")
28
29def test_readcsv():
30    """"""Tests reading from a CSV file, since it is one of the most common methods
31    that gets called on the pandas library.
32    """"""
33    import acorn.pandas as pd
34    from os import path
35    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))
36
37    from db import db_entries
38    sentries, uuids = db_entries(""pandas"")
39
40    uid, entry = sentries[-1]
41
42    
43    #So far, we have been checking the logging directly on the object. We need
44    #to make sure that the data was actually writen to file.
45    from acorn.logging.database import dbs
46    tdb = dbs[(""acorn"", ""pandas"")]
47
48def test_frametypes():
49    """"""Tests construction of :class:`pandas.Series` and
50    :class:`pandas.Index`. :class:`~pandas.Series` and :class:`~pandas.Index` are
51    tricky because they alse have `staticmethod` constructors that get called by
52    the :class:`pandas.DataFrame` constructor. So we need to test direct
53    construction as well.
54    """"""
55    #Since we have already tested the writing to disk, we will now disable the
56    #writing and just examine the in-memory collections.
57    import acorn.pandas as pd
58    ind = pd.Index([1./i for i in range(1, 11)], dtype=float)
59    ser = pd.Series(range(2, 12), index=ind)
60
61    from db import db_entries
62    sentries, uuids = db_entries(""pandas"")
63
64    u0, e0 = sentries[-2]
65    u1, e1 = sentries[-1]
66
67
68    if six.PY2:
69    else:
70    
71def test_instance():
72    """"""Tests the instance methods :meth:`pandas.DataFrame.apply` using a lambda
73    function and :func:`numpy.sqrt`; also tests
74    :meth:`pandas.DataFrame.describe` because it has a tricky decorator using
75    `staticmethod` (it gets bound as an instance method by the __init__ call on
76    the newly constructed :class:`pandas.DataFrame`.
77    """"""
78    from numpy import sqrt
79    lambfun = lambda x: x**2
80
81    import acorn.pandas as pd
82    import acorn.numpy as np
83    if six.PY2:
84        pdf = pd.DataFrame(range(15,25))
85    else:
86        pdf = pd.DataFrame(data=list(range(15,25)))
87    pdf.apply(lambfun)
88    pdf.apply(np.sqrt)
89    pdf.describe()
90
91    from db import db_entries
92    sentries, uuids = db_entries(""pandas"")
93
94    u0, e0 = sentries[-4] #Constructor
95    u1, e1 = sentries[-3] #lambda apply
96    u2, e2 = sentries[-2] #sqrt apply
97    u3, e3 = sentries[-1] #describe
98
99    #pandas in python 3 requires us to name the data keyword argument; it
100    #doesn't automatically splice it into the first position.
101    if six.PY2:
102    else:
103    
104    #For instance methods, the uuid keys in the entries dict are those of the
105    #instance that the method was called on.
106
107    #Unfortunately, the order in which members of a package is returned is not
108    #always deterministic, so numpy.sqrt may be first picked up by
109    #numpy.matlib.sqrt.
110            e2[""a""][""_""][1] == ""numpy.matlib.sqrt"")
111
112
113def test_gets():
114    """"""Tests the pandas.get and pandas.__getitem__ logging.
115    """"""
116    import acorn.pandas as pd
117    from os import path
118    csdf=pd.read_csv(path.join(""tests"", ""darwin.csv""))
119    csdf.get([""y""])
120    csdf[[""Unnamed: 0"", ""y""]]
121    
122    from db import db_entries
123    sentries, uuids = db_entries(""pandas"")
124
125    u0, e0 = sentries[-3] #Constructor
126    u1, e1 = sentries[-2] #static get
127    u2, e2 = sentries[-1] #getitem
128
129    
130    if six.PY2:
131    else:
132
133    if six.PY2:
134    else:
135",6097,"[[7, 'request', '!=', None, ""the function needs the request""],
[7, 'dbdir', '!=', None, ""the function needs the dbdir""],
[37, 'sentries', '!=', None, ""the function checks for the presence of sentries""],
[37, 'uuids', '!=', None, ""the function checks for the presence of uuids""],
[40, 'uid', '!=', None, ""the function uses the uid""],
[40, 'entry', '!=', None, ""the function uses the entry""],
[46, 'tdb', '!=', None, ""the function uses the tdb""],
[62, 'sentries', '!=', None, ""the function checks for the presence of sentries""],
[62, 'uuids', '!=', None, ""the function checks for the presence of uuids""],
[64, 'u0', '!=', None, ""the function uses u0""],
[64, 'e0', '!=', None, ""the function uses e0""],
[65, 'u1', '!=', None, ""the function uses u1""],
[65, 'e1', '!=', None, ""the function uses e1""],
[78, 'lambfun', '!=', None, ""the function uses the lambfun""],
[92, 'sentries', '!=', None, ""the function checks for the presence of sentries""],
[92, 'uuids', '!=', None, ""the function checks for the presence of uuids""],
[94, 'u0', '!=', None, ""the function uses u0""],
[94, 'e0', '!=', None, ""the function uses e0""],
[95, 'u1', '!=', None, ""the function uses u1""],
[95, 'e1', '!=', None, ""the function uses e1""],
[96, 'u2', '!=', None, ""the function uses u2""],
[96, 'e2', '!=', None, ""the function uses e2""],
[97, 'u3', '!=', None, ""the function uses u3""],
[97, 'e3', '!=', None, ""the function uses e3""],
[123, 'sentries', '!=', None, ""the function checks for the presence of sentries""],
[123, 'uuids', '!=', None, ""the function checks for the presence of uuids""],
[125, 'u0', '!=', None, ""the function uses u0""],
[125, 'e0', '!=', None, ""the function uses e0""],
[126, 'u1', '!=', None, ""the function uses u1""],
[126, 'e1', '!=', None, ""the function uses e1""],
[127, 'u2', '!=', None, ""the function uses u2""],
[127, 'e2', '!=', None, ""the function uses e2""]]"
hickerson/bbn,"
from __future__ import division
import warnings
import time
import stat
import re
import os
import sys

# XXX CCTBX itself requires at least Python 2.5 (and some packages such as
# Phenix require 2.7+), but this script is intended to bootstrap an
# installation on older systems as well
def check_python_version () :
  if (not sys.version_info >= (2,3)) :
    raise Exception(""Python version 2.3 or greater required to run this ""+
      ""script."")
  elif (sys.version_info < (2,4)) : # subprocess module not available
    warnings.warn(""You are running an obsolete version of Python; this script ""+
      ""should still run, but not all functionality is available."",
      DeprecationWarning)
    time.sleep(2)

def call (args, log) :
  rc = None
  if (sys.version_info[1] >= 7) :
    import subprocess
  else :
    # XXX HACK
    libtbx_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
    if (not libtbx_path in sys.path) :
      sys.path.append(libtbx_path)
    import subprocess_with_fixes as subprocess
  if isinstance(args, list) :
    args = "" "".join(args)
  p = subprocess.Popen(
    args=args,
    shell=True,
    bufsize=-1,
    stdin=None,
    stdout=log, #subprocess.PIPE,
    stderr=subprocess.STDOUT,
    universal_newlines=True,
    close_fds=False)
  #o, e = p.communicate()
  #log.write(o)
  log.flush()
  p.wait()
  log.flush()
  rc = p.returncode
  if (rc != 0) :
    raise RuntimeError(""Call to '%s' failed with exit code %d"" % (args, rc))

def untar (pkg_name, log=sys.stdout, verbose=False, change_ownership=False,
    check_output_path=True) :
  assert os.path.isfile(pkg_name), pkg_name
  verbose_flag = owner_flag = """"
  if (verbose) :
    verbose_flag = ""v""
  if (change_ownership) :
    owner_flag = ""o""
  cmd = [ ""tar"", ""x%s%sf"" % (owner_flag, verbose_flag) ]
  if (pkg_name.endswith(""gz"")) :
    cmd = [""tar"", ""zx%s%sf"" % (owner_flag, verbose_flag) ]
  elif (pkg_name.endswith(""bz2"")) :
    cmd = [""tar"", ""jx%s%sf"" % (owner_flag, verbose_flag) ]
  args = cmd + [pkg_name]
  call("" "".join(args), log)
  dir_name = re.sub("".tgz"", """",
               re.sub("".tar.gz"", """",
                 re.sub("".tar.bz2"", """",
                   os.path.basename(pkg_name))))
  if (check_output_path) :
    if (not os.path.isdir(dir_name)) :
      time.sleep(1)
      if (not os.path.isdir(dir_name)) :
        raise RuntimeError(""Expected directory '%s' not found!"" % dir_name)
    return os.path.abspath(dir_name)
  return None

def detect_osx_version () :
  uname = os.uname()
  version = uname[2]
  major, minor, rev = version.split(""."")
  return int(major)

def copy_file (src_path, dest_path, executable=None) :
  assert os.path.isfile(src_path)
  open(dest_path, ""wb"").write(open(src_path, ""rb"").read())
  if os.access(src_path, os.X_OK) or executable :
    mode = os.stat(dest_path).st_mode
    os.chmod(dest_path, mode | stat.S_IXUSR)

# shutil.copytree replacement - circumvents this bug:
# http://bugs.python.org/issue14662
# this is not a general solution, but it is good enough for the installer
# process (at least on Unix)
def copy_tree (src_path, dest_path, verbose=False, log=sys.stdout) :
  assert os.path.isdir(src_path) and not os.path.exists(dest_path)
  if (verbose) :
    print >> log, ""creating %s"" % dest_path
  os.makedirs(dest_path)
  for path_name in os.listdir(src_path) :
    node_src_path = os.path.join(src_path, path_name)
    node_dest_path = os.path.join(dest_path, path_name)
    if os.path.isfile(node_src_path) :
      if (verbose) :
        print >> log, ""  copy %s -> %s"" % (node_src_path, node_dest_path)
      copy_file(node_src_path, node_dest_path)
    elif os.path.isdir(node_src_path) :
      copy_tree(node_src_path, node_dest_path)
    else :
      if (verbose) :
        print >> log, ""  skipping %s"" % node_src_path
","
1
2from __future__ import division
3import warnings
4import time
5import stat
6import re
7import os
8import sys
9
10# XXX CCTBX itself requires at least Python 2.5 (and some packages such as
11# Phenix require 2.7+), but this script is intended to bootstrap an
12# installation on older systems as well
13def check_python_version () :
14  if (not sys.version_info >= (2,3)) :
15    raise Exception(""Python version 2.3 or greater required to run this ""+
16      ""script."")
17  elif (sys.version_info < (2,4)) : # subprocess module not available
18    warnings.warn(""You are running an obsolete version of Python; this script ""+
19      ""should still run, but not all functionality is available."",
20      DeprecationWarning)
21    time.sleep(2)
22
23def call (args, log) :
24  rc = None
25  if (sys.version_info[1] >= 7) :
26    import subprocess
27  else :
28    # XXX HACK
29    libtbx_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
30    if (not libtbx_path in sys.path) :
31      sys.path.append(libtbx_path)
32    import subprocess_with_fixes as subprocess
33  if isinstance(args, list) :
34    args = "" "".join(args)
35  p = subprocess.Popen(
36    args=args,
37    shell=True,
38    bufsize=-1,
39    stdin=None,
40    stdout=log, #subprocess.PIPE,
41    stderr=subprocess.STDOUT,
42    universal_newlines=True,
43    close_fds=False)
44  #o, e = p.communicate()
45  #log.write(o)
46  log.flush()
47  p.wait()
48  log.flush()
49  rc = p.returncode
50  if (rc != 0) :
51    raise RuntimeError(""Call to '%s' failed with exit code %d"" % (args, rc))
52
53def untar (pkg_name, log=sys.stdout, verbose=False, change_ownership=False,
54    check_output_path=True) :
55  verbose_flag = owner_flag = """"
56  if (verbose) :
57    verbose_flag = ""v""
58  if (change_ownership) :
59    owner_flag = ""o""
60  cmd = [ ""tar"", ""x%s%sf"" % (owner_flag, verbose_flag) ]
61  if (pkg_name.endswith(""gz"")) :
62    cmd = [""tar"", ""zx%s%sf"" % (owner_flag, verbose_flag) ]
63  elif (pkg_name.endswith(""bz2"")) :
64    cmd = [""tar"", ""jx%s%sf"" % (owner_flag, verbose_flag) ]
65  args = cmd + [pkg_name]
66  call("" "".join(args), log)
67  dir_name = re.sub("".tgz"", """",
68               re.sub("".tar.gz"", """",
69                 re.sub("".tar.bz2"", """",
70                   os.path.basename(pkg_name))))
71  if (check_output_path) :
72    if (not os.path.isdir(dir_name)) :
73      time.sleep(1)
74      if (not os.path.isdir(dir_name)) :
75        raise RuntimeError(""Expected directory '%s' not found!"" % dir_name)
76    return os.path.abspath(dir_name)
77  return None
78
79def detect_osx_version () :
80  uname = os.uname()
81  version = uname[2]
82  major, minor, rev = version.split(""."")
83  return int(major)
84
85def copy_file (src_path, dest_path, executable=None) :
86  open(dest_path, ""wb"").write(open(src_path, ""rb"").read())
87  if os.access(src_path, os.X_OK) or executable :
88    mode = os.stat(dest_path).st_mode
89    os.chmod(dest_path, mode | stat.S_IXUSR)
90
91# shutil.copytree replacement - circumvents this bug:
92# http://bugs.python.org/issue14662
93# this is not a general solution, but it is good enough for the installer
94# process (at least on Unix)
95def copy_tree (src_path, dest_path, verbose=False, log=sys.stdout) :
96  if (verbose) :
97    print >> log, ""creating %s"" % dest_path
98  os.makedirs(dest_path)
99  for path_name in os.listdir(src_path) :
100    node_src_path = os.path.join(src_path, path_name)
101    node_dest_path = os.path.join(dest_path, path_name)
102    if os.path.isfile(node_src_path) :
103      if (verbose) :
104        print >> log, ""  copy %s -> %s"" % (node_src_path, node_dest_path)
105      copy_file(node_src_path, node_dest_path)
106    elif os.path.isdir(node_src_path) :
107      copy_tree(node_src_path, node_dest_path)
108    else :
109      if (verbose) :
110        print >> log, ""  skipping %s"" % node_src_path
111","[['os.path.isfile(pkg_name)', '==', 'True'], ['os.path.isfile(src_path)', '==', 'True'], ['os.path.isdir(src_path)', '==', 'True'], ['os.path.exists(dest_path)', '==', 'False']]",3,4,1.3333333333333333,0.0010540184453227,"['args', 'log', 'rc', 'libtbx_path', 'p', '#o', 'e', 'pkg_name', 'verbose', 'change_ownership', 'verbose_flag', 'owner_flag', 'cmd', 'dir_name', 'uname', 'version', 'major', 'minor', 'rev', 'src_path', 'dest_path', 'executable', 'mode', 'node_src_path', 'node_dest_path']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['args', 'log', 'rc', 'libtbx_path', 'p', '#o', 'e', 'pkg_name', 'verbose', 'change_ownership', 'verbose_flag', 'owner_flag', 'cmd', 'dir_name', 'uname', 'version', 'major', 'minor', 'rev', 'src_path', 'dest_path', 'executable', 'mode', 'node_src_path', 'node_dest_path']
*Code:

1
2from __future__ import division
3import warnings
4import time
5import stat
6import re
7import os
8import sys
9
10# XXX CCTBX itself requires at least Python 2.5 (and some packages such as
11# Phenix require 2.7+), but this script is intended to bootstrap an
12# installation on older systems as well
13def check_python_version () :
14  if (not sys.version_info >= (2,3)) :
15    raise Exception(""Python version 2.3 or greater required to run this ""+
16      ""script."")
17  elif (sys.version_info < (2,4)) : # subprocess module not available
18    warnings.warn(""You are running an obsolete version of Python; this script ""+
19      ""should still run, but not all functionality is available."",
20      DeprecationWarning)
21    time.sleep(2)
22
23def call (args, log) :
24  rc = None
25  if (sys.version_info[1] >= 7) :
26    import subprocess
27  else :
28    # XXX HACK
29    libtbx_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
30    if (not libtbx_path in sys.path) :
31      sys.path.append(libtbx_path)
32    import subprocess_with_fixes as subprocess
33  if isinstance(args, list) :
34    args = "" "".join(args)
35  p = subprocess.Popen(
36    args=args,
37    shell=True,
38    bufsize=-1,
39    stdin=None,
40    stdout=log, #subprocess.PIPE,
41    stderr=subprocess.STDOUT,
42    universal_newlines=True,
43    close_fds=False)
44  #o, e = p.communicate()
45  #log.write(o)
46  log.flush()
47  p.wait()
48  log.flush()
49  rc = p.returncode
50  if (rc != 0) :
51    raise RuntimeError(""Call to '%s' failed with exit code %d"" % (args, rc))
52
53def untar (pkg_name, log=sys.stdout, verbose=False, change_ownership=False,
54    check_output_path=True) :
55  verbose_flag = owner_flag = """"
56  if (verbose) :
57    verbose_flag = ""v""
58  if (change_ownership) :
59    owner_flag = ""o""
60  cmd = [ ""tar"", ""x%s%sf"" % (owner_flag, verbose_flag) ]
61  if (pkg_name.endswith(""gz"")) :
62    cmd = [""tar"", ""zx%s%sf"" % (owner_flag, verbose_flag) ]
63  elif (pkg_name.endswith(""bz2"")) :
64    cmd = [""tar"", ""jx%s%sf"" % (owner_flag, verbose_flag) ]
65  args = cmd + [pkg_name]
66  call("" "".join(args), log)
67  dir_name = re.sub("".tgz"", """",
68               re.sub("".tar.gz"", """",
69                 re.sub("".tar.bz2"", """",
70                   os.path.basename(pkg_name))))
71  if (check_output_path) :
72    if (not os.path.isdir(dir_name)) :
73      time.sleep(1)
74      if (not os.path.isdir(dir_name)) :
75        raise RuntimeError(""Expected directory '%s' not found!"" % dir_name)
76    return os.path.abspath(dir_name)
77  return None
78
79def detect_osx_version () :
80  uname = os.uname()
81  version = uname[2]
82  major, minor, rev = version.split(""."")
83  return int(major)
84
85def copy_file (src_path, dest_path, executable=None) :
86  open(dest_path, ""wb"").write(open(src_path, ""rb"").read())
87  if os.access(src_path, os.X_OK) or executable :
88    mode = os.stat(dest_path).st_mode
89    os.chmod(dest_path, mode | stat.S_IXUSR)
90
91# shutil.copytree replacement - circumvents this bug:
92# http://bugs.python.org/issue14662
93# this is not a general solution, but it is good enough for the installer
94# process (at least on Unix)
95def copy_tree (src_path, dest_path, verbose=False, log=sys.stdout) :
96  if (verbose) :
97    print >> log, ""creating %s"" % dest_path
98  os.makedirs(dest_path)
99  for path_name in os.listdir(src_path) :
100    node_src_path = os.path.join(src_path, path_name)
101    node_dest_path = os.path.join(dest_path, path_name)
102    if os.path.isfile(node_src_path) :
103      if (verbose) :
104        print >> log, ""  copy %s -> %s"" % (node_src_path, node_dest_path)
105      copy_file(node_src_path, node_dest_path)
106    elif os.path.isdir(node_src_path) :
107      copy_tree(node_src_path, node_dest_path)
108    else :
109      if (verbose) :
110        print >> log, ""  skipping %s"" % node_src_path
111",5527,"[[13, 'sys.version_info', '>=', (2,3), 'Python version 2.3 or greater is required to run this script'],
 [23, 'args', '!=', None, 'args must be provided to call the function'],
 [23, 'log', '!=', None, 'log must be provided to write'],
 [24, 'rc', '==', None, 'rc variable is None initially'],
 [33, 'args', '!=', None, 'args should be a list that can be joined'],
 [49, 'rc', '!=', None, 'rc contains the returned code'],
 [53, 'pkg_name', '!=', None, 'name of the package needs to be provided'],
 [53, 'log', '!=', None, 'log system output stream needs to be defined'],
 [54, 'check_output_path', '==', True, 'a correct and existing output path should be provided'],
 [79, 'uname', '!=', '', 'in order to detect OS version, uname should have some value'],
 [85, 'src_path', '!=', None, 'source path of the file to be copied needs to be provided'],
 [85, 'dest_path', '!=', None, 'destination path where file needs to be copied should be provided'],
 [95, 'src_path', '!=', None, 'source path of the tree to be copied needs to be provided'],
 [95, 'dest_path', '!=', None, 'destination path where tree needs to be copied should be provided']]"
krzysztof/zenodo,"# -*- coding: utf-8 -*-
#
# This file is part of Zenodo.
# Copyright (C) 2016 CERN.
#
# Zenodo is free software; you can redistribute it
# and/or modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation; either version 2 of the
# License, or (at your option) any later version.
#
# Zenodo is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Zenodo; if not, write to the
# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
# MA 02111-1307, USA.
#
# In applying this license, CERN does not
# waive the privileges and immunities granted to it by virtue of its status
# as an Intergovernmental Organization or submit itself to any jurisdiction.

""""""Test Zenodo deposit utils.""""""

from __future__ import absolute_import, print_function

from zenodo.modules.deposit.utils import suggest_language


def test_suggest_language():
    """"""Test language suggestions.""""""
    s = suggest_language('pl')
    assert len(s) == 1
    assert s[0].alpha_3 == 'pol'
    # 'Northern Sami' doesn't contain 'sme' substring but should be first
    # in suggestions, since 'sme' is its ISO 639-2 code.
    s = suggest_language('sme')
    assert len(s) > 1  # More than one result
    assert s[0].alpha_3 == 'sme'
    assert 'sme' not in s[0].name.lower()
    assert 'sme' in s[1].name.lower()  # Second result matched by name

    s = suggest_language('POLISH')
    assert s[0].alpha_3 == 'pol'

    # lower-case
    s = suggest_language('polish')
    assert s[0].alpha_3 == 'pol'
","
1# -*- coding: utf-8 -*-
2#
3# This file is part of Zenodo.
4# Copyright (C) 2016 CERN.
5#
6# Zenodo is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Zenodo is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Zenodo; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25""""""Test Zenodo deposit utils.""""""
26
27from __future__ import absolute_import, print_function
28
29from zenodo.modules.deposit.utils import suggest_language
30
31
32def test_suggest_language():
33    """"""Test language suggestions.""""""
34    s = suggest_language('pl')
35    # 'Northern Sami' doesn't contain 'sme' substring but should be first
36    # in suggestions, since 'sme' is its ISO 639-2 code.
37    s = suggest_language('sme')
38
39    s = suggest_language('POLISH')
40
41    # lower-case
42    s = suggest_language('polish')
43","[['len(s)', '==', '1'], ['s[0].alpha_3', '==', ""'pol'""], ['len(s)', '>', '1'], ['s[0].alpha_3', '==', ""'sme'""], ['s[0].alpha_3', '==', ""'pol'""], ['s[0].alpha_3', '==', ""'pol'""]]",8,6,0.75,0.0033688938798427,['s'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['s']
*Code:

1# -*- coding: utf-8 -*-
2#
3# This file is part of Zenodo.
4# Copyright (C) 2016 CERN.
5#
6# Zenodo is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Zenodo is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Zenodo; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25""""""Test Zenodo deposit utils.""""""
26
27from __future__ import absolute_import, print_function
28
29from zenodo.modules.deposit.utils import suggest_language
30
31
32def test_suggest_language():
33    """"""Test language suggestions.""""""
34    s = suggest_language('pl')
35    # 'Northern Sami' doesn't contain 'sme' substring but should be first
36    # in suggestions, since 'sme' is its ISO 639-2 code.
37    s = suggest_language('sme')
38
39    s = suggest_language('POLISH')
40
41    # lower-case
42    s = suggest_language('polish')
43",2930,"[[32, 's', '!=', '', ""the input for suggest_language function can't be an empty string""]]"
OpenDataNode/ckanext-odn-pipeline,"'''
Created on 11.11.2014

@author: mvi
'''


from sqlalchemy.sql.expression import or_
from sqlalchemy import types, Column, Table, ForeignKey
import vdm.sqlalchemy

import types as _types
from ckan.model import domain_object
from ckan.model.meta import metadata, Session, mapper
from sqlalchemy.orm import relationship, backref
from ckan.model.package import Package


pipelines_table = Table('pipelines', metadata,
            Column('package_id', ForeignKey('package.id'), primary_key=True, nullable=False, unique=False, autoincrement=False),
            Column('pipeline_id', types.BIGINT, primary_key=True, nullable=False, unique=True, autoincrement=False),
            Column('name', types.UnicodeText, nullable=True, unique=False)
            )


class Pipelines(domain_object.DomainObject):
    
    def __init__(self, package_id, pipeline_id, name=None):
        assert package_id
        assert pipeline_id
        self.package_id = package_id
        self.pipeline_id = pipeline_id
        self.name = name
    
    @classmethod
    def get_all(cls):
        return Session.query(cls).all()
    
    @classmethod
    def by_dataset_id(cls, dataset_id):
        assert dataset_id
        return Session.query(cls)\
            .filter_by(package_id = dataset_id).all()
            
    @classmethod
    def by_pipeline_id(cls, pipeline_id):
        assert pipeline_id
        return Session.query(cls)\
            .filter_by(pipeline_id = pipeline_id).first()
            
    def get(self):
        return Session.query(Pipelines)\
            .filter_by(package_id = self.package_id, pipeline_id = self.pipeline_id).first()
            

mapper(Pipelines, pipelines_table, properties={
    ""pipelines"": relationship(Package, single_parent=True, backref=backref('pipelines', cascade=""all, delete, delete-orphan""))
})","
1'''
2Created on 11.11.2014
3
4@author: mvi
5'''
6
7
8from sqlalchemy.sql.expression import or_
9from sqlalchemy import types, Column, Table, ForeignKey
10import vdm.sqlalchemy
11
12import types as _types
13from ckan.model import domain_object
14from ckan.model.meta import metadata, Session, mapper
15from sqlalchemy.orm import relationship, backref
16from ckan.model.package import Package
17
18
19pipelines_table = Table('pipelines', metadata,
20            Column('package_id', ForeignKey('package.id'), primary_key=True, nullable=False, unique=False, autoincrement=False),
21            Column('pipeline_id', types.BIGINT, primary_key=True, nullable=False, unique=True, autoincrement=False),
22            Column('name', types.UnicodeText, nullable=True, unique=False)
23            )
24
25
26class Pipelines(domain_object.DomainObject):
27    
28    def __init__(self, package_id, pipeline_id, name=None):
29        self.package_id = package_id
30        self.pipeline_id = pipeline_id
31        self.name = name
32    
33    @classmethod
34    def get_all(cls):
35        return Session.query(cls).all()
36    
37    @classmethod
38    def by_dataset_id(cls, dataset_id):
39        return Session.query(cls)\
40            .filter_by(package_id = dataset_id).all()
41            
42    @classmethod
43    def by_pipeline_id(cls, pipeline_id):
44        return Session.query(cls)\
45            .filter_by(pipeline_id = pipeline_id).first()
46            
47    def get(self):
48        return Session.query(Pipelines)\
49            .filter_by(package_id = self.package_id, pipeline_id = self.pipeline_id).first()
50            
51
52mapper(Pipelines, pipelines_table, properties={
53    ""pipelines"": relationship(Package, single_parent=True, backref=backref('pipelines', cascade=""all, delete, delete-orphan""))
54})","[['package_id', '==', 'True'], ['pipeline_id', '==', 'True'], ['dataset_id', '==', 'True'], ['pipeline_id', '==', 'True']]",4,4,1.0,0.0021869874248223,"['pipelines_table', 'package_id', 'pipeline_id', 'name', 'self.package_id', 'self.pipeline_id', 'self.name', 'cls', 'dataset_id', '.filter_by(package_id', '.filter_by(pipeline_id']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pipelines_table', 'package_id', 'pipeline_id', 'name', 'self.package_id', 'self.pipeline_id', 'self.name', 'cls', 'dataset_id', '.filter_by(package_id', '.filter_by(pipeline_id']
*Code:

1'''
2Created on 11.11.2014
3
4@author: mvi
5'''
6
7
8from sqlalchemy.sql.expression import or_
9from sqlalchemy import types, Column, Table, ForeignKey
10import vdm.sqlalchemy
11
12import types as _types
13from ckan.model import domain_object
14from ckan.model.meta import metadata, Session, mapper
15from sqlalchemy.orm import relationship, backref
16from ckan.model.package import Package
17
18
19pipelines_table = Table('pipelines', metadata,
20            Column('package_id', ForeignKey('package.id'), primary_key=True, nullable=False, unique=False, autoincrement=False),
21            Column('pipeline_id', types.BIGINT, primary_key=True, nullable=False, unique=True, autoincrement=False),
22            Column('name', types.UnicodeText, nullable=True, unique=False)
23            )
24
25
26class Pipelines(domain_object.DomainObject):
27    
28    def __init__(self, package_id, pipeline_id, name=None):
29        self.package_id = package_id
30        self.pipeline_id = pipeline_id
31        self.name = name
32    
33    @classmethod
34    def get_all(cls):
35        return Session.query(cls).all()
36    
37    @classmethod
38    def by_dataset_id(cls, dataset_id):
39        return Session.query(cls)\
40            .filter_by(package_id = dataset_id).all()
41            
42    @classmethod
43    def by_pipeline_id(cls, pipeline_id):
44        return Session.query(cls)\
45            .filter_by(pipeline_id = pipeline_id).first()
46            
47    def get(self):
48        return Session.query(Pipelines)\
49            .filter_by(package_id = self.package_id, pipeline_id = self.pipeline_id).first()
50            
51
52mapper(Pipelines, pipelines_table, properties={
53    ""pipelines"": relationship(Package, single_parent=True, backref=backref('pipelines', cascade=""all, delete, delete-orphan""))
54})",3383,"[28, 'package_id', '!=', None, 'package_id cannot be None'],
[28, 'pipeline_id', '!=', None, 'pipeline_id cannot be None'],
[38, 'dataset_id', '!=', None, 'dataset_id cannot be None'],
[43, 'pipeline_id', '!=', None, 'pipeline_id cannot be None'],
[48, 'self.package_id', '!=', None, 'package_id cannot be None'],
[48, 'self.pipeline_id', '!=', None, 'pipeline_id cannot be None']"
mitsuhiko/pip,"""""""
tests specific to uninstalling --user installs
""""""

import sys
import os
import textwrap
from os.path import abspath, join, curdir, isdir, isfile

import pytest
from pip.locations import bin_user
from tests.lib import pyversion, assert_all_changes
from tests.functional.test_install_user import _patch_dist_in_site_packages


# --user option is broken in pypy
@pytest.mark.skipif(""hasattr(sys, 'pypy_version_info')"")
class Tests_UninstallUserSite:

    def test_uninstall_from_usersite(self, script, virtualenv):
        """"""
        Test uninstall from usersite
        """"""
        virtualenv.system_site_packages = True
        result1 = script.pip('install', '--user', 'INITools==0.3')
        result2 = script.pip('uninstall', '-y', 'INITools')
        assert_all_changes(result1, result2, [script.venv/'build', 'cache'])


    def test_uninstall_from_usersite_with_dist_in_global_site(self, script, virtualenv):
        """"""
        Test uninstall from usersite (with same dist in global site)
        """"""
        # the test framework only supports testing using virtualenvs.
        # the sys.path ordering for virtualenvs with --system-site-packages is this: virtualenv-site, user-site, global-site.
        # this test will use 2 modifications to simulate the user-site/global-site relationship
        # 1) a monkey patch which will make it appear piptestpackage is not in the virtualenv site
        #    if we don't patch this, pip will return an installation error:  ""Will not install to the usersite because it will lack sys.path precedence...""
        # 2) adding usersite to PYTHONPATH, so usersite has sys.path precedence over the virtualenv site

        virtualenv.system_site_packages = True
        script.environ[""PYTHONPATH""] = script.base_path / script.user_site
        _patch_dist_in_site_packages(script)

        result1 = script.pip_install_local('pip-test-package==0.1')
        result2 = script.pip_install_local('--user', 'pip-test-package==0.1.1')
        result3 = script.pip('uninstall', '-vy', 'pip-test-package')

        # uninstall console is mentioning user scripts, but not global scripts
        assert script.user_bin_path in result3.stdout
        assert script.bin_path not in result3.stdout

        # uninstall worked
        assert_all_changes(result2, result3, [script.venv/'build', 'cache'])

        # site still has 0.2 (can't look in result1; have to check)
        egg_info_folder = script.base_path / script.site_packages / 'pip_test_package-0.1-py%s.egg-info' % pyversion
        assert isdir(egg_info_folder)


    def test_uninstall_editable_from_usersite(self, script, virtualenv, data):
        """"""
        Test uninstall editable local user install
        """"""
        virtualenv.system_site_packages = True
        script.user_site_path.makedirs()

        #install
        to_install = data.packages.join(""FSPkg"")
        result1 = script.pip('install', '--user', '-e', to_install, expect_error=False)
        egg_link = script.user_site/'FSPkg.egg-link'
        assert egg_link in result1.files_created, str(result1.stdout)

        #uninstall
        result2 = script.pip('uninstall', '-y', 'FSPkg')
        assert not isfile(script.base_path / egg_link)

        assert_all_changes(result1, result2,
                           [script.venv/'build', 'cache', script.user_site/'easy-install.pth'])

","
1""""""
2tests specific to uninstalling --user installs
3""""""
4
5import sys
6import os
7import textwrap
8from os.path import abspath, join, curdir, isdir, isfile
9
10import pytest
11from pip.locations import bin_user
12from tests.functional.test_install_user import _patch_dist_in_site_packages
13
14
15# --user option is broken in pypy
16@pytest.mark.skipif(""hasattr(sys, 'pypy_version_info')"")
17class Tests_UninstallUserSite:
18
19    def test_uninstall_from_usersite(self, script, virtualenv):
20        """"""
21        Test uninstall from usersite
22        """"""
23        virtualenv.system_site_packages = True
24        result1 = script.pip('install', '--user', 'INITools==0.3')
25        result2 = script.pip('uninstall', '-y', 'INITools')
26
27
28    def test_uninstall_from_usersite_with_dist_in_global_site(self, script, virtualenv):
29        """"""
30        Test uninstall from usersite (with same dist in global site)
31        """"""
32        # the test framework only supports testing using virtualenvs.
33        # the sys.path ordering for virtualenvs with --system-site-packages is this: virtualenv-site, user-site, global-site.
34        # this test will use 2 modifications to simulate the user-site/global-site relationship
35        # 1) a monkey patch which will make it appear piptestpackage is not in the virtualenv site
36        #    if we don't patch this, pip will return an installation error:  ""Will not install to the usersite because it will lack sys.path precedence...""
37        # 2) adding usersite to PYTHONPATH, so usersite has sys.path precedence over the virtualenv site
38
39        virtualenv.system_site_packages = True
40        script.environ[""PYTHONPATH""] = script.base_path / script.user_site
41        _patch_dist_in_site_packages(script)
42
43        result1 = script.pip_install_local('pip-test-package==0.1')
44        result2 = script.pip_install_local('--user', 'pip-test-package==0.1.1')
45        result3 = script.pip('uninstall', '-vy', 'pip-test-package')
46
47        # uninstall console is mentioning user scripts, but not global scripts
48
49        # uninstall worked
50
51        # site still has 0.2 (can't look in result1; have to check)
52        egg_info_folder = script.base_path / script.site_packages / 'pip_test_package-0.1-py%s.egg-info' % pyversion
53
54
55    def test_uninstall_editable_from_usersite(self, script, virtualenv, data):
56        """"""
57        Test uninstall editable local user install
58        """"""
59        virtualenv.system_site_packages = True
60        script.user_site_path.makedirs()
61
62        #install
63        to_install = data.packages.join(""FSPkg"")
64        result1 = script.pip('install', '--user', '-e', to_install, expect_error=False)
65        egg_link = script.user_site/'FSPkg.egg-link'
66
67        #uninstall
68        result2 = script.pip('uninstall', '-y', 'FSPkg')
69
70                           [script.venv/'build', 'cache', script.user_site/'easy-install.pth'])
71
72","[['isdir(egg_info_folder)', '==', 'True'], ['isfile(script.base_path', '/', 'egg_link)']]",9,2,0.2222222222222222,0.0005945303210463,"['script', 'virtualenv', 'virtualenv.system_site_packages', 'result1', 'result2', 'script.environ[""PYTHONPATH""]', 'result3', 'egg_info_folder', 'data', 'to_install', 'egg_link']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['script', 'virtualenv', 'virtualenv.system_site_packages', 'result1', 'result2', 'script.environ[""PYTHONPATH""]', 'result3', 'egg_info_folder', 'data', 'to_install', 'egg_link']
*Code:

1""""""
2tests specific to uninstalling --user installs
3""""""
4
5import sys
6import os
7import textwrap
8from os.path import abspath, join, curdir, isdir, isfile
9
10import pytest
11from pip.locations import bin_user
12from tests.functional.test_install_user import _patch_dist_in_site_packages
13
14
15# --user option is broken in pypy
16@pytest.mark.skipif(""hasattr(sys, 'pypy_version_info')"")
17class Tests_UninstallUserSite:
18
19    def test_uninstall_from_usersite(self, script, virtualenv):
20        """"""
21        Test uninstall from usersite
22        """"""
23        virtualenv.system_site_packages = True
24        result1 = script.pip('install', '--user', 'INITools==0.3')
25        result2 = script.pip('uninstall', '-y', 'INITools')
26
27
28    def test_uninstall_from_usersite_with_dist_in_global_site(self, script, virtualenv):
29        """"""
30        Test uninstall from usersite (with same dist in global site)
31        """"""
32        # the test framework only supports testing using virtualenvs.
33        # the sys.path ordering for virtualenvs with --system-site-packages is this: virtualenv-site, user-site, global-site.
34        # this test will use 2 modifications to simulate the user-site/global-site relationship
35        # 1) a monkey patch which will make it appear piptestpackage is not in the virtualenv site
36        #    if we don't patch this, pip will return an installation error:  ""Will not install to the usersite because it will lack sys.path precedence...""
37        # 2) adding usersite to PYTHONPATH, so usersite has sys.path precedence over the virtualenv site
38
39        virtualenv.system_site_packages = True
40        script.environ[""PYTHONPATH""] = script.base_path / script.user_site
41        _patch_dist_in_site_packages(script)
42
43        result1 = script.pip_install_local('pip-test-package==0.1')
44        result2 = script.pip_install_local('--user', 'pip-test-package==0.1.1')
45        result3 = script.pip('uninstall', '-vy', 'pip-test-package')
46
47        # uninstall console is mentioning user scripts, but not global scripts
48
49        # uninstall worked
50
51        # site still has 0.2 (can't look in result1; have to check)
52        egg_info_folder = script.base_path / script.site_packages / 'pip_test_package-0.1-py%s.egg-info' % pyversion
53
54
55    def test_uninstall_editable_from_usersite(self, script, virtualenv, data):
56        """"""
57        Test uninstall editable local user install
58        """"""
59        virtualenv.system_site_packages = True
60        script.user_site_path.makedirs()
61
62        #install
63        to_install = data.packages.join(""FSPkg"")
64        result1 = script.pip('install', '--user', '-e', to_install, expect_error=False)
65        egg_link = script.user_site/'FSPkg.egg-link'
66
67        #uninstall
68        result2 = script.pip('uninstall', '-y', 'FSPkg')
69
70                           [script.venv/'build', 'cache', script.user_site/'easy-install.pth'])
71
72",4536,"[[19, 'script', '!=', None, ""the 'script' fixture needs to be initialized for the tests""],
 [19, 'virtualenv', '!=', None, ""the 'virtualenv' fixture needs to be initialized for the tests""],
 [24, 'result1', '==', None, ""'result1' should be None before assignment""],
 [25, 'result2', '==', None, ""'result2' should be None before assignment""],
 [28, 'script.environ[""PYTHONPATH""]', '==', None, ""'PYTHONPATH' should be None before assignment""],
 [43, 'result1', '==', None, ""'result1' should be None before assignment""], 
 [44, 'result2', '==', None, ""'result2' should be None before assignment""],
 [45, 'result3', '==', None, ""'result3' should be None before assignment""],
 [52, 'egg_info_folder', '==', None, ""'egg_info_folder' should be None before assignment""],
 [55, 'data', '!=', None, ""the 'data' fixture needs to be initialized for the tests""],
 [63, 'to_install', '==', None, ""'to_install' should be None before assignment""],
 [64, 'result1', '==', None, ""'result1' should be None before assignment""],
 [65, 'egg_link', '==', None, ""'egg_link' should be None before assignment""],
 [68, 'result2', '==', None, ""'result2' should be None before assignment""]
]"
menpo/menpo,"import numpy as np

from menpo.shape import PointCloud, TriMesh

from menpo.transform import TransformChain, Translation, Scale
from menpo.transform.thinplatesplines import ThinPlateSplines
from menpo.transform.piecewiseaffine import PiecewiseAffine


def test_chain_tps_before_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps_one = ThinPlateSplines(a, b)
    tps_two = ThinPlateSplines(b, a)
    chain = tps_one.compose_before(tps_two)
    assert isinstance(chain, TransformChain)
    points = PointCloud(np.random.random([10, 2]))
    chain_res = chain.apply(points)
    manual_res = tps_two.apply(tps_one.apply(points))
    assert np.all(chain_res.points == manual_res.points)


def test_chain_tps_after_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps_one = ThinPlateSplines(a, b)
    tps_two = ThinPlateSplines(b, a)
    chain = tps_one.compose_after(tps_two)
    assert isinstance(chain, TransformChain)
    points = PointCloud(np.random.random([10, 2]))
    chain_res = chain.apply(points)
    manual_res = tps_one.apply(tps_two.apply(points))
    assert np.all(chain_res.points == manual_res.points)


def test_chain_pwa_before_tps():
    a_tm = TriMesh(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    pwa = PiecewiseAffine(a_tm, b)
    tps = ThinPlateSplines(b, a_tm)
    chain = pwa.compose_before(tps)
    assert isinstance(chain, TransformChain)


def test_chain_pwa_after_tps():
    a_tm = TriMesh(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    pwa = PiecewiseAffine(a_tm, b)
    tps = ThinPlateSplines(b, a_tm)
    chain = pwa.compose_after(tps)
    assert isinstance(chain, TransformChain)


def test_chain_tps_before_pwa():
    a_tm = TriMesh(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    pwa = PiecewiseAffine(a_tm, b)
    tps = ThinPlateSplines(b, a_tm)
    chain = tps.compose_before(pwa)
    assert isinstance(chain, TransformChain)


def test_chain_tps_after_pwa():
    a_tm = TriMesh(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    pwa = PiecewiseAffine(a_tm, b)
    tps = ThinPlateSplines(b, a_tm)
    chain = tps.compose_after(pwa)
    assert isinstance(chain, TransformChain)


def test_compose_tps_after_translation():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    t = Translation([3, 4])
    tps = ThinPlateSplines(a, b)
    chain = tps.compose_after(t)
    assert isinstance(chain, TransformChain)


def test_manual_no_op_chain():
    points = PointCloud(np.random.random([10, 2]))
    t = Translation([3, 4])
    chain = TransformChain([t, t.pseudoinverse()])
    points_applied = chain.apply(points)
    assert np.allclose(points_applied.points, points.points)


def test_chain_compose_before_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps = ThinPlateSplines(a, b)

    t = Translation([3, 4])
    s = Scale([4, 2])
    chain = TransformChain([t, s])
    chain_mod = chain.compose_before(tps)

    points = PointCloud(np.random.random([10, 2]))

    manual_res = tps.apply(s.apply(t.apply(points)))
    chain_res = chain_mod.apply(points)
    assert np.all(manual_res.points == chain_res.points)


def test_chain_compose_after_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps = ThinPlateSplines(a, b)

    t = Translation([3, 4])
    s = Scale([4, 2])
    chain = TransformChain([t, s])
    chain_mod = chain.compose_after(tps)

    points = PointCloud(np.random.random([10, 2]))

    manual_res = s.apply(t.apply(tps.apply(points)))
    chain_res = chain_mod.apply(points)
    assert np.all(manual_res.points == chain_res.points)


def test_chain_compose_before_inplace_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps = ThinPlateSplines(a, b)

    t = Translation([3, 4])
    s = Scale([4, 2])
    chain = TransformChain([t, s])
    chain.compose_before_inplace(tps)

    points = PointCloud(np.random.random([10, 2]))

    manual_res = tps.apply(s.apply(t.apply(points)))
    chain_res = chain.apply(points)
    assert np.all(manual_res.points == chain_res.points)


def test_chain_compose_after_inplace_tps():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))
    tps = ThinPlateSplines(a, b)

    t = Translation([3, 4])
    s = Scale([4, 2])
    chain = TransformChain([t, s])
    chain.compose_after_inplace(tps)

    points = PointCloud(np.random.random([10, 2]))

    manual_res = s.apply(t.apply(tps.apply(points)))
    chain_res = chain.apply(points)
    assert np.all(manual_res.points == chain_res.points)


def test_chain_compose_after_inplace_chain():
    a = PointCloud(np.random.random([10, 2]))
    b = PointCloud(np.random.random([10, 2]))

    t = Translation([3, 4])
    s = Scale([4, 2])
    chain_1 = TransformChain([t, s])
    chain_2 = TransformChain([s.pseudoinverse(), t.pseudoinverse()])
    chain_1.compose_before_inplace(chain_2)

    points = PointCloud(np.random.random([10, 2]))
    chain_res = chain_1.apply(points)
    assert np.allclose(points.points, chain_res.points)
","
1import numpy as np
2
3from menpo.shape import PointCloud, TriMesh
4
5from menpo.transform import TransformChain, Translation, Scale
6from menpo.transform.thinplatesplines import ThinPlateSplines
7from menpo.transform.piecewiseaffine import PiecewiseAffine
8
9
10def test_chain_tps_before_tps():
11    a = PointCloud(np.random.random([10, 2]))
12    b = PointCloud(np.random.random([10, 2]))
13    tps_one = ThinPlateSplines(a, b)
14    tps_two = ThinPlateSplines(b, a)
15    chain = tps_one.compose_before(tps_two)
16    points = PointCloud(np.random.random([10, 2]))
17    chain_res = chain.apply(points)
18    manual_res = tps_two.apply(tps_one.apply(points))
19
20
21def test_chain_tps_after_tps():
22    a = PointCloud(np.random.random([10, 2]))
23    b = PointCloud(np.random.random([10, 2]))
24    tps_one = ThinPlateSplines(a, b)
25    tps_two = ThinPlateSplines(b, a)
26    chain = tps_one.compose_after(tps_two)
27    points = PointCloud(np.random.random([10, 2]))
28    chain_res = chain.apply(points)
29    manual_res = tps_one.apply(tps_two.apply(points))
30
31
32def test_chain_pwa_before_tps():
33    a_tm = TriMesh(np.random.random([10, 2]))
34    b = PointCloud(np.random.random([10, 2]))
35    pwa = PiecewiseAffine(a_tm, b)
36    tps = ThinPlateSplines(b, a_tm)
37    chain = pwa.compose_before(tps)
38
39
40def test_chain_pwa_after_tps():
41    a_tm = TriMesh(np.random.random([10, 2]))
42    b = PointCloud(np.random.random([10, 2]))
43    pwa = PiecewiseAffine(a_tm, b)
44    tps = ThinPlateSplines(b, a_tm)
45    chain = pwa.compose_after(tps)
46
47
48def test_chain_tps_before_pwa():
49    a_tm = TriMesh(np.random.random([10, 2]))
50    b = PointCloud(np.random.random([10, 2]))
51    pwa = PiecewiseAffine(a_tm, b)
52    tps = ThinPlateSplines(b, a_tm)
53    chain = tps.compose_before(pwa)
54
55
56def test_chain_tps_after_pwa():
57    a_tm = TriMesh(np.random.random([10, 2]))
58    b = PointCloud(np.random.random([10, 2]))
59    pwa = PiecewiseAffine(a_tm, b)
60    tps = ThinPlateSplines(b, a_tm)
61    chain = tps.compose_after(pwa)
62
63
64def test_compose_tps_after_translation():
65    a = PointCloud(np.random.random([10, 2]))
66    b = PointCloud(np.random.random([10, 2]))
67    t = Translation([3, 4])
68    tps = ThinPlateSplines(a, b)
69    chain = tps.compose_after(t)
70
71
72def test_manual_no_op_chain():
73    points = PointCloud(np.random.random([10, 2]))
74    t = Translation([3, 4])
75    chain = TransformChain([t, t.pseudoinverse()])
76    points_applied = chain.apply(points)
77
78
79def test_chain_compose_before_tps():
80    a = PointCloud(np.random.random([10, 2]))
81    b = PointCloud(np.random.random([10, 2]))
82    tps = ThinPlateSplines(a, b)
83
84    t = Translation([3, 4])
85    s = Scale([4, 2])
86    chain = TransformChain([t, s])
87    chain_mod = chain.compose_before(tps)
88
89    points = PointCloud(np.random.random([10, 2]))
90
91    manual_res = tps.apply(s.apply(t.apply(points)))
92    chain_res = chain_mod.apply(points)
93
94
95def test_chain_compose_after_tps():
96    a = PointCloud(np.random.random([10, 2]))
97    b = PointCloud(np.random.random([10, 2]))
98    tps = ThinPlateSplines(a, b)
99
100    t = Translation([3, 4])
101    s = Scale([4, 2])
102    chain = TransformChain([t, s])
103    chain_mod = chain.compose_after(tps)
104
105    points = PointCloud(np.random.random([10, 2]))
106
107    manual_res = s.apply(t.apply(tps.apply(points)))
108    chain_res = chain_mod.apply(points)
109
110
111def test_chain_compose_before_inplace_tps():
112    a = PointCloud(np.random.random([10, 2]))
113    b = PointCloud(np.random.random([10, 2]))
114    tps = ThinPlateSplines(a, b)
115
116    t = Translation([3, 4])
117    s = Scale([4, 2])
118    chain = TransformChain([t, s])
119    chain.compose_before_inplace(tps)
120
121    points = PointCloud(np.random.random([10, 2]))
122
123    manual_res = tps.apply(s.apply(t.apply(points)))
124    chain_res = chain.apply(points)
125
126
127def test_chain_compose_after_inplace_tps():
128    a = PointCloud(np.random.random([10, 2]))
129    b = PointCloud(np.random.random([10, 2]))
130    tps = ThinPlateSplines(a, b)
131
132    t = Translation([3, 4])
133    s = Scale([4, 2])
134    chain = TransformChain([t, s])
135    chain.compose_after_inplace(tps)
136
137    points = PointCloud(np.random.random([10, 2]))
138
139    manual_res = s.apply(t.apply(tps.apply(points)))
140    chain_res = chain.apply(points)
141
142
143def test_chain_compose_after_inplace_chain():
144    a = PointCloud(np.random.random([10, 2]))
145    b = PointCloud(np.random.random([10, 2]))
146
147    t = Translation([3, 4])
148    s = Scale([4, 2])
149    chain_1 = TransformChain([t, s])
150    chain_2 = TransformChain([s.pseudoinverse(), t.pseudoinverse()])
151    chain_1.compose_before_inplace(chain_2)
152
153    points = PointCloud(np.random.random([10, 2]))
154    chain_res = chain_1.apply(points)
155","[['np.all(chain_res.points', '==', 'manual_res.points)'], ['np.all(chain_res.points', '==', 'manual_res.points)'], ['np.allclose(points_applied.points', '==', 'True'], ['np.all(manual_res.points', '==', 'chain_res.points)'], ['np.all(manual_res.points', '==', 'chain_res.points)'], ['np.all(manual_res.points', '==', 'chain_res.points)'], ['np.all(manual_res.points', '==', 'chain_res.points)'], ['np.allclose(points.points', '==', 'True']]",15,8,0.5333333333333333,0.001498407941562,"['a', 'b', 'tps_one', 'tps_two', 'chain', 'points', 'chain_res', 'manual_res', 'a_tm', 'pwa', 'tps', 't', 'points_applied', 's', 'chain_mod', 'chain_1', 'chain_2']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['a', 'b', 'tps_one', 'tps_two', 'chain', 'points', 'chain_res', 'manual_res', 'a_tm', 'pwa', 'tps', 't', 'points_applied', 's', 'chain_mod', 'chain_1', 'chain_2']
*Code:

1import numpy as np
2
3from menpo.shape import PointCloud, TriMesh
4
5from menpo.transform import TransformChain, Translation, Scale
6from menpo.transform.thinplatesplines import ThinPlateSplines
7from menpo.transform.piecewiseaffine import PiecewiseAffine
8
9
10def test_chain_tps_before_tps():
11    a = PointCloud(np.random.random([10, 2]))
12    b = PointCloud(np.random.random([10, 2]))
13    tps_one = ThinPlateSplines(a, b)
14    tps_two = ThinPlateSplines(b, a)
15    chain = tps_one.compose_before(tps_two)
16    points = PointCloud(np.random.random([10, 2]))
17    chain_res = chain.apply(points)
18    manual_res = tps_two.apply(tps_one.apply(points))
19
20
21def test_chain_tps_after_tps():
22    a = PointCloud(np.random.random([10, 2]))
23    b = PointCloud(np.random.random([10, 2]))
24    tps_one = ThinPlateSplines(a, b)
25    tps_two = ThinPlateSplines(b, a)
26    chain = tps_one.compose_after(tps_two)
27    points = PointCloud(np.random.random([10, 2]))
28    chain_res = chain.apply(points)
29    manual_res = tps_one.apply(tps_two.apply(points))
30
31
32def test_chain_pwa_before_tps():
33    a_tm = TriMesh(np.random.random([10, 2]))
34    b = PointCloud(np.random.random([10, 2]))
35    pwa = PiecewiseAffine(a_tm, b)
36    tps = ThinPlateSplines(b, a_tm)
37    chain = pwa.compose_before(tps)
38
39
40def test_chain_pwa_after_tps():
41    a_tm = TriMesh(np.random.random([10, 2]))
42    b = PointCloud(np.random.random([10, 2]))
43    pwa = PiecewiseAffine(a_tm, b)
44    tps = ThinPlateSplines(b, a_tm)
45    chain = pwa.compose_after(tps)
46
47
48def test_chain_tps_before_pwa():
49    a_tm = TriMesh(np.random.random([10, 2]))
50    b = PointCloud(np.random.random([10, 2]))
51    pwa = PiecewiseAffine(a_tm, b)
52    tps = ThinPlateSplines(b, a_tm)
53    chain = tps.compose_before(pwa)
54
55
56def test_chain_tps_after_pwa():
57    a_tm = TriMesh(np.random.random([10, 2]))
58    b = PointCloud(np.random.random([10, 2]))
59    pwa = PiecewiseAffine(a_tm, b)
60    tps = ThinPlateSplines(b, a_tm)
61    chain = tps.compose_after(pwa)
62
63
64def test_compose_tps_after_translation():
65    a = PointCloud(np.random.random([10, 2]))
66    b = PointCloud(np.random.random([10, 2]))
67    t = Translation([3, 4])
68    tps = ThinPlateSplines(a, b)
69    chain = tps.compose_after(t)
70
71
72def test_manual_no_op_chain():
73    points = PointCloud(np.random.random([10, 2]))
74    t = Translation([3, 4])
75    chain = TransformChain([t, t.pseudoinverse()])
76    points_applied = chain.apply(points)
77
78
79def test_chain_compose_before_tps():
80    a = PointCloud(np.random.random([10, 2]))
81    b = PointCloud(np.random.random([10, 2]))
82    tps = ThinPlateSplines(a, b)
83
84    t = Translation([3, 4])
85    s = Scale([4, 2])
86    chain = TransformChain([t, s])
87    chain_mod = chain.compose_before(tps)
88
89    points = PointCloud(np.random.random([10, 2]))
90
91    manual_res = tps.apply(s.apply(t.apply(points)))
92    chain_res = chain_mod.apply(points)
93
94
95def test_chain_compose_after_tps():
96    a = PointCloud(np.random.random([10, 2]))
97    b = PointCloud(np.random.random([10, 2]))
98    tps = ThinPlateSplines(a, b)
99
100    t = Translation([3, 4])
101    s = Scale([4, 2])
102    chain = TransformChain([t, s])
103    chain_mod = chain.compose_after(tps)
104
105    points = PointCloud(np.random.random([10, 2]))
106
107    manual_res = s.apply(t.apply(tps.apply(points)))
108    chain_res = chain_mod.apply(points)
109
110
111def test_chain_compose_before_inplace_tps():
112    a = PointCloud(np.random.random([10, 2]))
113    b = PointCloud(np.random.random([10, 2]))
114    tps = ThinPlateSplines(a, b)
115
116    t = Translation([3, 4])
117    s = Scale([4, 2])
118    chain = TransformChain([t, s])
119    chain.compose_before_inplace(tps)
120
121    points = PointCloud(np.random.random([10, 2]))
122
123    manual_res = tps.apply(s.apply(t.apply(points)))
124    chain_res = chain.apply(points)
125
126
127def test_chain_compose_after_inplace_tps():
128    a = PointCloud(np.random.random([10, 2]))
129    b = PointCloud(np.random.random([10, 2]))
130    tps = ThinPlateSplines(a, b)
131
132    t = Translation([3, 4])
133    s = Scale([4, 2])
134    chain = TransformChain([t, s])
135    chain.compose_after_inplace(tps)
136
137    points = PointCloud(np.random.random([10, 2]))
138
139    manual_res = s.apply(t.apply(tps.apply(points)))
140    chain_res = chain.apply(points)
141
142
143def test_chain_compose_after_inplace_chain():
144    a = PointCloud(np.random.random([10, 2]))
145    b = PointCloud(np.random.random([10, 2]))
146
147    t = Translation([3, 4])
148    s = Scale([4, 2])
149    chain_1 = TransformChain([t, s])
150    chain_2 = TransformChain([s.pseudoinverse(), t.pseudoinverse()])
151    chain_1.compose_before_inplace(chain_2)
152
153    points = PointCloud(np.random.random([10, 2]))
154    chain_res = chain_1.apply(points)
155",6466,"[[11, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [12, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [16, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [22, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [23, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [27, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [33, 'a_tm', '==', 10, ""The TriMesh should have an exact size of 10""],
 [34, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [41, 'a_tm', '==', 10, ""The TriMesh should have an exact size of 10""],
 [42, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [49, 'a_tm', '==', 10, ""The TriMesh should have an exact size of 10""],
 [50, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [57, 'a_tm', '==', 10, ""The TriMesh should have an exact size 10""],
 [58, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [65, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [66, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [73, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [80, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [81, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [89, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [96, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [97, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [105, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [112, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [113, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [121, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [128, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [129, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [137, 'points', '==', 10, ""The PointCloud should have an exact size of 10""],
 [144, 'a', '==', 10, ""The PointCloud should have an exact size of 10""],
 [145, 'b', '==', 10, ""The PointCloud should have an exact size of 10""],
 [153, 'points', '==', 10, ""The PointCloud should have an exact size of 10""]]"
lsqtongxin/ryu,"# Copyright (C) 2014 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""
 Utilities related to bgp data types and models.
""""""
import logging
import socket

from ryu.lib.packet.bgp import BGPUpdate
from ryu.lib.packet.bgp import RF_IPv4_UC
from ryu.lib.packet.bgp import RF_IPv6_UC
from ryu.lib.packet.bgp import RF_IPv4_VPN
from ryu.lib.packet.bgp import RF_IPv6_VPN
from ryu.lib.packet.bgp import RF_RTC_UC
from ryu.lib.packet.bgp import RouteTargetMembershipNLRI
from ryu.lib.packet.bgp import BGP_ATTR_TYPE_MULTI_EXIT_DISC
from ryu.lib.packet.bgp import BGPPathAttributeMultiExitDisc
from ryu.lib.packet.bgp import BGPPathAttributeMpUnreachNLRI
from ryu.lib.packet.bgp import BGPPathAttributeUnknown
from ryu.services.protocols.bgp.info_base.rtc import RtcPath
from ryu.services.protocols.bgp.info_base.ipv4 import Ipv4Path
from ryu.services.protocols.bgp.info_base.ipv6 import Ipv6Path
from ryu.services.protocols.bgp.info_base.vpnv4 import Vpnv4Path
from ryu.services.protocols.bgp.info_base.vpnv6 import Vpnv6Path


LOG = logging.getLogger('utils.bgp')

# RouteFmaily to path sub-class mapping.
_ROUTE_FAMILY_TO_PATH_MAP = {RF_IPv4_UC: Ipv4Path,
                             RF_IPv6_UC: Ipv6Path,
                             RF_IPv4_VPN: Vpnv4Path,
                             RF_IPv6_VPN: Vpnv6Path,
                             RF_RTC_UC: RtcPath}


def create_path(src_peer, nlri, **kwargs):
    route_family = nlri.ROUTE_FAMILY
    assert route_family in _ROUTE_FAMILY_TO_PATH_MAP.keys()
    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
    return path_cls(src_peer, nlri, src_peer.version_num, **kwargs)


def clone_path_and_update_med_for_target_neighbor(path, med):
    assert path and med
    route_family = path.route_family
    if route_family not in _ROUTE_FAMILY_TO_PATH_MAP.keys():
        raise ValueError('Clone is not supported for address-family %s' %
                         route_family)
    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
    pattrs = path.pathattr_map
    pattrs[BGP_ATTR_TYPE_MULTI_EXIT_DISC] = BGPPathAttributeMultiExitDisc(med)
    return path_cls(
        path.source, path.nlri, path.source_version_num,
        pattrs=pattrs, nexthop=path.nexthop,
        is_withdraw=path.is_withdraw,
        med_set_by_target_neighbor=True
    )


def clone_rtcpath_update_rt_as(path, new_rt_as):
    """"""Clones given RT NLRI `path`, and updates it with new RT_NLRI AS.

        Parameters:
            - `path`: (Path) RT_NLRI path
            - `new_rt_as`: AS value of cloned paths' RT_NLRI
    """"""
    assert path and new_rt_as
    if not path or path.route_family != RF_RTC_UC:
        raise ValueError('Expected RT_NLRI path')
    old_nlri = path.nlri
    new_rt_nlri = RouteTargetMembershipNLRI(new_rt_as, old_nlri.route_target)
    return RtcPath(path.source, new_rt_nlri, path.source_version_num,
                   pattrs=path.pathattr_map, nexthop=path.nexthop,
                   is_withdraw=path.is_withdraw)


def from_inet_ptoi(bgp_id):
    """"""Convert an IPv4 address string format to a four byte long.
    """"""
    four_byte_id = None
    try:
        packed_byte = socket.inet_pton(socket.AF_INET, bgp_id)
        four_byte_id = long(packed_byte.encode('hex'), 16)
    except ValueError:
        LOG.debug('Invalid bgp id given for conversion to integer value %s',
                  bgp_id)

    return four_byte_id


def get_unknow_opttrans_attr(path):
    """"""Utility method that gives a `dict` of unknown optional transitive
    path attributes of `path`.

    Returns dict: <key> - attribute type code, <value> - unknown path-attr.
    """"""
    path_attrs = path.pathattr_map
    unknown_opt_tran_attrs = {}
    for _, attr in path_attrs.items():
        if (isinstance(attr, BGPPathAttributeUnknown) and
                attr.is_optional_transitive()):
            unknown_opt_tran_attrs[attr.type_code] = attr
    return unknown_opt_tran_attrs


def create_end_of_rib_update():
    """"""Construct end-of-rib (EOR) Update instance.""""""
    mpunreach_attr = BGPPathAttributeMpUnreachNLRI(RF_IPv4_VPN.afi,
                                                   RF_IPv4_VPN.safi,
                                                   [])
    eor = BGPUpdate(path_attributes=[mpunreach_attr])
    return eor


# Bgp update message instance that can used as End of RIB marker.
UPDATE_EOR = create_end_of_rib_update()
","
1# Copyright (C) 2014 Nippon Telegraph and Telephone Corporation.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
12# implied.
13# See the License for the specific language governing permissions and
14# limitations under the License.
15
16""""""
17 Utilities related to bgp data types and models.
18""""""
19import logging
20import socket
21
22from ryu.lib.packet.bgp import BGPUpdate
23from ryu.lib.packet.bgp import RF_IPv4_UC
24from ryu.lib.packet.bgp import RF_IPv6_UC
25from ryu.lib.packet.bgp import RF_IPv4_VPN
26from ryu.lib.packet.bgp import RF_IPv6_VPN
27from ryu.lib.packet.bgp import RF_RTC_UC
28from ryu.lib.packet.bgp import RouteTargetMembershipNLRI
29from ryu.lib.packet.bgp import BGP_ATTR_TYPE_MULTI_EXIT_DISC
30from ryu.lib.packet.bgp import BGPPathAttributeMultiExitDisc
31from ryu.lib.packet.bgp import BGPPathAttributeMpUnreachNLRI
32from ryu.lib.packet.bgp import BGPPathAttributeUnknown
33from ryu.services.protocols.bgp.info_base.rtc import RtcPath
34from ryu.services.protocols.bgp.info_base.ipv4 import Ipv4Path
35from ryu.services.protocols.bgp.info_base.ipv6 import Ipv6Path
36from ryu.services.protocols.bgp.info_base.vpnv4 import Vpnv4Path
37from ryu.services.protocols.bgp.info_base.vpnv6 import Vpnv6Path
38
39
40LOG = logging.getLogger('utils.bgp')
41
42# RouteFmaily to path sub-class mapping.
43_ROUTE_FAMILY_TO_PATH_MAP = {RF_IPv4_UC: Ipv4Path,
44                             RF_IPv6_UC: Ipv6Path,
45                             RF_IPv4_VPN: Vpnv4Path,
46                             RF_IPv6_VPN: Vpnv6Path,
47                             RF_RTC_UC: RtcPath}
48
49
50def create_path(src_peer, nlri, **kwargs):
51    route_family = nlri.ROUTE_FAMILY
52    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
53    return path_cls(src_peer, nlri, src_peer.version_num, **kwargs)
54
55
56def clone_path_and_update_med_for_target_neighbor(path, med):
57    route_family = path.route_family
58    if route_family not in _ROUTE_FAMILY_TO_PATH_MAP.keys():
59        raise ValueError('Clone is not supported for address-family %s' %
60                         route_family)
61    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
62    pattrs = path.pathattr_map
63    pattrs[BGP_ATTR_TYPE_MULTI_EXIT_DISC] = BGPPathAttributeMultiExitDisc(med)
64    return path_cls(
65        path.source, path.nlri, path.source_version_num,
66        pattrs=pattrs, nexthop=path.nexthop,
67        is_withdraw=path.is_withdraw,
68        med_set_by_target_neighbor=True
69    )
70
71
72def clone_rtcpath_update_rt_as(path, new_rt_as):
73    """"""Clones given RT NLRI `path`, and updates it with new RT_NLRI AS.
74
75        Parameters:
76            - `path`: (Path) RT_NLRI path
77            - `new_rt_as`: AS value of cloned paths' RT_NLRI
78    """"""
79    if not path or path.route_family != RF_RTC_UC:
80        raise ValueError('Expected RT_NLRI path')
81    old_nlri = path.nlri
82    new_rt_nlri = RouteTargetMembershipNLRI(new_rt_as, old_nlri.route_target)
83    return RtcPath(path.source, new_rt_nlri, path.source_version_num,
84                   pattrs=path.pathattr_map, nexthop=path.nexthop,
85                   is_withdraw=path.is_withdraw)
86
87
88def from_inet_ptoi(bgp_id):
89    """"""Convert an IPv4 address string format to a four byte long.
90    """"""
91    four_byte_id = None
92    try:
93        packed_byte = socket.inet_pton(socket.AF_INET, bgp_id)
94        four_byte_id = long(packed_byte.encode('hex'), 16)
95    except ValueError:
96        LOG.debug('Invalid bgp id given for conversion to integer value %s',
97                  bgp_id)
98
99    return four_byte_id
100
101
102def get_unknow_opttrans_attr(path):
103    """"""Utility method that gives a `dict` of unknown optional transitive
104    path attributes of `path`.
105
106    Returns dict: <key> - attribute type code, <value> - unknown path-attr.
107    """"""
108    path_attrs = path.pathattr_map
109    unknown_opt_tran_attrs = {}
110    for _, attr in path_attrs.items():
111        if (isinstance(attr, BGPPathAttributeUnknown) and
112                attr.is_optional_transitive()):
113            unknown_opt_tran_attrs[attr.type_code] = attr
114    return unknown_opt_tran_attrs
115
116
117def create_end_of_rib_update():
118    """"""Construct end-of-rib (EOR) Update instance.""""""
119    mpunreach_attr = BGPPathAttributeMpUnreachNLRI(RF_IPv4_VPN.afi,
120                                                   RF_IPv4_VPN.safi,
121                                                   [])
122    eor = BGPUpdate(path_attributes=[mpunreach_attr])
123    return eor
124
125
126# Bgp update message instance that can used as End of RIB marker.
127UPDATE_EOR = create_end_of_rib_update()
128","[['path', '==', 'True'], ['med', '==', 'True'], ['path', '==', 'True'], ['new_rt_as', '==', 'True']]",3,4,1.3333333333333333,0.0008131734092295,"['LOG', '_ROUTE_FAMILY_TO_PATH_MAP', 'src_peer', 'nlri', '**kwargs', 'route_family', 'path_cls', 'path', 'med', 'pattrs', 'pattrs[BGP_ATTR_TYPE_MULTI_EXIT_DISC]', 'new_rt_as', 'old_nlri', 'new_rt_nlri', 'bgp_id', 'four_byte_id', 'packed_byte', 'path_attrs', 'unknown_opt_tran_attrs', 'unknown_opt_tran_attrs[attr.type_code]', 'mpunreach_attr', 'eor', 'UPDATE_EOR']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['LOG', '_ROUTE_FAMILY_TO_PATH_MAP', 'src_peer', 'nlri', '**kwargs', 'route_family', 'path_cls', 'path', 'med', 'pattrs', 'pattrs[BGP_ATTR_TYPE_MULTI_EXIT_DISC]', 'new_rt_as', 'old_nlri', 'new_rt_nlri', 'bgp_id', 'four_byte_id', 'packed_byte', 'path_attrs', 'unknown_opt_tran_attrs', 'unknown_opt_tran_attrs[attr.type_code]', 'mpunreach_attr', 'eor', 'UPDATE_EOR']
*Code:

1# Copyright (C) 2014 Nippon Telegraph and Telephone Corporation.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
12# implied.
13# See the License for the specific language governing permissions and
14# limitations under the License.
15
16""""""
17 Utilities related to bgp data types and models.
18""""""
19import logging
20import socket
21
22from ryu.lib.packet.bgp import BGPUpdate
23from ryu.lib.packet.bgp import RF_IPv4_UC
24from ryu.lib.packet.bgp import RF_IPv6_UC
25from ryu.lib.packet.bgp import RF_IPv4_VPN
26from ryu.lib.packet.bgp import RF_IPv6_VPN
27from ryu.lib.packet.bgp import RF_RTC_UC
28from ryu.lib.packet.bgp import RouteTargetMembershipNLRI
29from ryu.lib.packet.bgp import BGP_ATTR_TYPE_MULTI_EXIT_DISC
30from ryu.lib.packet.bgp import BGPPathAttributeMultiExitDisc
31from ryu.lib.packet.bgp import BGPPathAttributeMpUnreachNLRI
32from ryu.lib.packet.bgp import BGPPathAttributeUnknown
33from ryu.services.protocols.bgp.info_base.rtc import RtcPath
34from ryu.services.protocols.bgp.info_base.ipv4 import Ipv4Path
35from ryu.services.protocols.bgp.info_base.ipv6 import Ipv6Path
36from ryu.services.protocols.bgp.info_base.vpnv4 import Vpnv4Path
37from ryu.services.protocols.bgp.info_base.vpnv6 import Vpnv6Path
38
39
40LOG = logging.getLogger('utils.bgp')
41
42# RouteFmaily to path sub-class mapping.
43_ROUTE_FAMILY_TO_PATH_MAP = {RF_IPv4_UC: Ipv4Path,
44                             RF_IPv6_UC: Ipv6Path,
45                             RF_IPv4_VPN: Vpnv4Path,
46                             RF_IPv6_VPN: Vpnv6Path,
47                             RF_RTC_UC: RtcPath}
48
49
50def create_path(src_peer, nlri, **kwargs):
51    route_family = nlri.ROUTE_FAMILY
52    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
53    return path_cls(src_peer, nlri, src_peer.version_num, **kwargs)
54
55
56def clone_path_and_update_med_for_target_neighbor(path, med):
57    route_family = path.route_family
58    if route_family not in _ROUTE_FAMILY_TO_PATH_MAP.keys():
59        raise ValueError('Clone is not supported for address-family %s' %
60                         route_family)
61    path_cls = _ROUTE_FAMILY_TO_PATH_MAP.get(route_family)
62    pattrs = path.pathattr_map
63    pattrs[BGP_ATTR_TYPE_MULTI_EXIT_DISC] = BGPPathAttributeMultiExitDisc(med)
64    return path_cls(
65        path.source, path.nlri, path.source_version_num,
66        pattrs=pattrs, nexthop=path.nexthop,
67        is_withdraw=path.is_withdraw,
68        med_set_by_target_neighbor=True
69    )
70
71
72def clone_rtcpath_update_rt_as(path, new_rt_as):
73    """"""Clones given RT NLRI `path`, and updates it with new RT_NLRI AS.
74
75        Parameters:
76            - `path`: (Path) RT_NLRI path
77            - `new_rt_as`: AS value of cloned paths' RT_NLRI
78    """"""
79    if not path or path.route_family != RF_RTC_UC:
80        raise ValueError('Expected RT_NLRI path')
81    old_nlri = path.nlri
82    new_rt_nlri = RouteTargetMembershipNLRI(new_rt_as, old_nlri.route_target)
83    return RtcPath(path.source, new_rt_nlri, path.source_version_num,
84                   pattrs=path.pathattr_map, nexthop=path.nexthop,
85                   is_withdraw=path.is_withdraw)
86
87
88def from_inet_ptoi(bgp_id):
89    """"""Convert an IPv4 address string format to a four byte long.
90    """"""
91    four_byte_id = None
92    try:
93        packed_byte = socket.inet_pton(socket.AF_INET, bgp_id)
94        four_byte_id = long(packed_byte.encode('hex'), 16)
95    except ValueError:
96        LOG.debug('Invalid bgp id given for conversion to integer value %s',
97                  bgp_id)
98
99    return four_byte_id
100
101
102def get_unknow_opttrans_attr(path):
103    """"""Utility method that gives a `dict` of unknown optional transitive
104    path attributes of `path`.
105
106    Returns dict: <key> - attribute type code, <value> - unknown path-attr.
107    """"""
108    path_attrs = path.pathattr_map
109    unknown_opt_tran_attrs = {}
110    for _, attr in path_attrs.items():
111        if (isinstance(attr, BGPPathAttributeUnknown) and
112                attr.is_optional_transitive()):
113            unknown_opt_tran_attrs[attr.type_code] = attr
114    return unknown_opt_tran_attrs
115
116
117def create_end_of_rib_update():
118    """"""Construct end-of-rib (EOR) Update instance.""""""
119    mpunreach_attr = BGPPathAttributeMpUnreachNLRI(RF_IPv4_VPN.afi,
120                                                   RF_IPv4_VPN.safi,
121                                                   [])
122    eor = BGPUpdate(path_attributes=[mpunreach_attr])
123    return eor
124
125
126# Bgp update message instance that can used as End of RIB marker.
127UPDATE_EOR = create_end_of_rib_update()
128",6826,"[[50, 'src_peer', '!=', None, ""function 'create_path' requires 'src_peer' as input""],
[50, 'nlri', '!=', None, ""function 'create_path' requires 'nlri' as input""],
[56, 'path', '!=', None, ""function 'clone_path_and_update_med_for_target_neighbor' requires 'path' as input""],
[56, 'med', '!=', None, ""function 'clone_path_and_update_med_for_target_neighbor' requires 'med' as input""],
[72, 'path', '!=', None, ""function 'clone_rtcpath_update_rt_as' requires 'path' as input""],
[72, 'new_rt_as', '!=', None, ""function 'clone_rtcpath_update_rt_as' require 'new_rt_as' as input""],
[88, 'bgp_id', '!=', None, ""function 'from_inet_ptoi' require 'bgp_id' as input""],
[102, 'path', '!=', None, ""function 'get_unknow_opttrans_attr' requires 'path' as input""]]"
mzbyszynski/pyleus,"import logging.config
import os.path

from pyleus.storm import StormTuple
from pyleus.storm.component import DEFAULT_LOGGING_CONFIG_PATH
from pyleus.storm.serializers.serializer import Serializer
from pyleus.testing import ComponentTestCase, mock, builtins


class TestComponent(ComponentTestCase):

    def test__msg_is_command(self):
        command_msg = dict(this_is_a_command=True)
        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]

        assert self.instance._msg_is_command(command_msg)
        assert not self.instance._msg_is_command(taskid_msg)

    def test__msg_is_taskid(self):
        command_msg = dict(this_is_a_command=True)
        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]

        assert not self.instance._msg_is_taskid(command_msg)
        assert self.instance._msg_is_taskid(taskid_msg)

    def test_read_command(self):
        command_msg = dict(this_is_a_command=True)
        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]

        messages = [
            taskid_msg,
            taskid_msg,
            taskid_msg,
            command_msg,
        ]

        with mock.patch.object(
                self.instance, '_serializer', autospec=Serializer):
            self.instance._serializer.read_msg.side_effect = messages
            command = self.instance.read_command()

        assert command == command_msg
        assert len(self.instance._pending_taskids) == 3

    def test_read_command_queued(self):
        next_command = dict(next_command=3)
        another_command = dict(another_command=7)

        self.instance._pending_commands.extend([
            next_command,
            another_command,
            another_command,
        ])

        assert self.instance.read_command() == next_command
        assert len(self.instance._pending_commands) == 2

    def test_read_taskid(self):
        command_msg = dict(this_is_a_command=True)
        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]

        messages = [
            command_msg,
            command_msg,
            command_msg,
            taskid_msg,
        ]

        with mock.patch.object(
                self.instance, '_serializer', autospec=Serializer):
            self.instance._serializer.read_msg.side_effect = messages
            taskid = self.instance.read_taskid()

        assert taskid == taskid_msg
        assert len(self.instance._pending_commands) == 3

    def test_read_taskid_queued(self):
        next_taskid = dict(next_taskid=3)
        another_taskid = dict(another_taskid=7)

        self.instance._pending_taskids.extend([
            next_taskid,
            another_taskid,
            another_taskid,
        ])

        assert self.instance.read_taskid() == next_taskid
        assert len(self.instance._pending_taskids) == 2

    def test_read_tuple(self):
        command_dict = {
            'id': ""id"",
            'comp': ""comp"",
            'stream': ""stream"",
            'task': ""task"",
            'tuple': ""tuple"",
        }

        expected_storm_tuple = StormTuple(
            ""id"", ""comp"", ""stream"", ""task"", ""tuple"")

        with mock.patch.object(
                self.instance, 'read_command', return_value=command_dict):
            storm_tuple = self.instance.read_tuple()

        assert isinstance(storm_tuple, StormTuple)
        assert storm_tuple == expected_storm_tuple

    def test__create_pidfile(self):
        with mock.patch.object(builtins, 'open', autospec=True) as mock_open:
            self.instance._create_pidfile(""pid_dir"", ""pid"")

        mock_open.assert_called_once_with(""pid_dir/pid"", 'a')

    def test__init_component(self):
        handshake_msg = {
            'conf': {""foo"": ""bar""},
            'context': ""context"",
            'pidDir': ""pidDir"",
        }

        patch_serializer = mock.patch.object(
            self.instance, '_serializer', autospec=Serializer)
        patch_os_getpid = mock.patch('os.getpid', return_value=1234)
        patch__create_pidfile = mock.patch.object(
            self.instance, '_create_pidfile')

        with patch_serializer as mock_serializer:
            with patch_os_getpid as mock_os_getpid:
                with patch__create_pidfile as mock__create_pidfile:
                    mock_serializer.read_msg.return_value = handshake_msg
                    conf, context = self.instance._init_component()

        mock_os_getpid.assert_called_once_with()
        mock_serializer.send_msg.assert_called_once_with({'pid': 1234})
        mock__create_pidfile.assert_called_once_with(""pidDir"", 1234)

        assert conf == {""foo"": ""bar""}
        assert context == ""context""

    def test_send_command_with_opts(self):
        with mock.patch.object(
                self.instance, '_serializer', autospec=Serializer):
            self.instance.send_command('test', {'option': ""foo""})

            self.instance._serializer.send_msg.assert_called_once_with({
                'command': ""test"",
                'option': ""foo"",
            })

    def test_send_command_with_no_opts(self):
        with mock.patch.object(
                self.instance, '_serializer', autospec=Serializer):
            self.instance.send_command('test')

            self.instance._serializer.send_msg.assert_called_once_with({
                'command': ""test"",
            })

    def test_send_command_clobber_command(self):
        with mock.patch.object(
                self.instance, '_serializer', autospec=Serializer):
            self.instance.send_command('test', {'command': ""joe""})

            self.instance._serializer.send_msg.assert_called_once_with({
                'command': ""test"",
            })

    @mock.patch.object(logging.config, 'fileConfig')
    def test_initialize_logging(self, fileConfig):
        pyleus_config = {
            'logging_config_path': mock.sentinel.logging_config_path}
        with mock.patch.object(self.instance, 'pyleus_config', pyleus_config):
            self.instance.initialize_logging()

        fileConfig.assert_called_once_with(mock.sentinel.logging_config_path)

    @mock.patch.object(logging.config, 'fileConfig')
    def test_initialize_logging_default_exists(self, fileConfig):
        with mock.patch.object(self.instance, 'pyleus_config', {}):
            with mock.patch.object(os.path, 'isfile', return_value=True):
                self.instance.initialize_logging()

        fileConfig.assert_called_once_with(DEFAULT_LOGGING_CONFIG_PATH)

    @mock.patch.object(logging.config, 'fileConfig')
    def test_initialize_logging_default_no_exists(self, fileConfig):
        with mock.patch.object(self.instance, 'pyleus_config', {}):
            with mock.patch.object(os.path, 'isfile', return_value=False):
                self.instance.initialize_logging()

        assert not fileConfig.called
","
1import logging.config
2import os.path
3
4from pyleus.storm import StormTuple
5from pyleus.storm.component import DEFAULT_LOGGING_CONFIG_PATH
6from pyleus.storm.serializers.serializer import Serializer
7from pyleus.testing import ComponentTestCase, mock, builtins
8
9
10class TestComponent(ComponentTestCase):
11
12    def test__msg_is_command(self):
13        command_msg = dict(this_is_a_command=True)
14        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
15
16
17    def test__msg_is_taskid(self):
18        command_msg = dict(this_is_a_command=True)
19        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
20
21
22    def test_read_command(self):
23        command_msg = dict(this_is_a_command=True)
24        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
25
26        messages = [
27            taskid_msg,
28            taskid_msg,
29            taskid_msg,
30            command_msg,
31        ]
32
33        with mock.patch.object(
34                self.instance, '_serializer', autospec=Serializer):
35            self.instance._serializer.read_msg.side_effect = messages
36            command = self.instance.read_command()
37
38
39    def test_read_command_queued(self):
40        next_command = dict(next_command=3)
41        another_command = dict(another_command=7)
42
43        self.instance._pending_commands.extend([
44            next_command,
45            another_command,
46            another_command,
47        ])
48
49
50    def test_read_taskid(self):
51        command_msg = dict(this_is_a_command=True)
52        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
53
54        messages = [
55            command_msg,
56            command_msg,
57            command_msg,
58            taskid_msg,
59        ]
60
61        with mock.patch.object(
62                self.instance, '_serializer', autospec=Serializer):
63            self.instance._serializer.read_msg.side_effect = messages
64            taskid = self.instance.read_taskid()
65
66
67    def test_read_taskid_queued(self):
68        next_taskid = dict(next_taskid=3)
69        another_taskid = dict(another_taskid=7)
70
71        self.instance._pending_taskids.extend([
72            next_taskid,
73            another_taskid,
74            another_taskid,
75        ])
76
77
78    def test_read_tuple(self):
79        command_dict = {
80            'id': ""id"",
81            'comp': ""comp"",
82            'stream': ""stream"",
83            'task': ""task"",
84            'tuple': ""tuple"",
85        }
86
87        expected_storm_tuple = StormTuple(
88            ""id"", ""comp"", ""stream"", ""task"", ""tuple"")
89
90        with mock.patch.object(
91                self.instance, 'read_command', return_value=command_dict):
92            storm_tuple = self.instance.read_tuple()
93
94
95    def test__create_pidfile(self):
96        with mock.patch.object(builtins, 'open', autospec=True) as mock_open:
97            self.instance._create_pidfile(""pid_dir"", ""pid"")
98
99
100    def test__init_component(self):
101        handshake_msg = {
102            'conf': {""foo"": ""bar""},
103            'context': ""context"",
104            'pidDir': ""pidDir"",
105        }
106
107        patch_serializer = mock.patch.object(
108            self.instance, '_serializer', autospec=Serializer)
109        patch_os_getpid = mock.patch('os.getpid', return_value=1234)
110        patch__create_pidfile = mock.patch.object(
111            self.instance, '_create_pidfile')
112
113        with patch_serializer as mock_serializer:
114            with patch_os_getpid as mock_os_getpid:
115                with patch__create_pidfile as mock__create_pidfile:
116                    mock_serializer.read_msg.return_value = handshake_msg
117                    conf, context = self.instance._init_component()
118
119
120
121    def test_send_command_with_opts(self):
122        with mock.patch.object(
123                self.instance, '_serializer', autospec=Serializer):
124            self.instance.send_command('test', {'option': ""foo""})
125
126                'command': ""test"",
127                'option': ""foo"",
128            })
129
130    def test_send_command_with_no_opts(self):
131        with mock.patch.object(
132                self.instance, '_serializer', autospec=Serializer):
133            self.instance.send_command('test')
134
135                'command': ""test"",
136            })
137
138    def test_send_command_clobber_command(self):
139        with mock.patch.object(
140                self.instance, '_serializer', autospec=Serializer):
141            self.instance.send_command('test', {'command': ""joe""})
142
143                'command': ""test"",
144            })
145
146    @mock.patch.object(logging.config, 'fileConfig')
147    def test_initialize_logging(self, fileConfig):
148        pyleus_config = {
149            'logging_config_path': mock.sentinel.logging_config_path}
150        with mock.patch.object(self.instance, 'pyleus_config', pyleus_config):
151            self.instance.initialize_logging()
152
153
154    @mock.patch.object(logging.config, 'fileConfig')
155    def test_initialize_logging_default_exists(self, fileConfig):
156        with mock.patch.object(self.instance, 'pyleus_config', {}):
157            with mock.patch.object(os.path, 'isfile', return_value=True):
158                self.instance.initialize_logging()
159
160
161    @mock.patch.object(logging.config, 'fileConfig')
162    def test_initialize_logging_default_no_exists(self, fileConfig):
163        with mock.patch.object(self.instance, 'pyleus_config', {}):
164            with mock.patch.object(os.path, 'isfile', return_value=False):
165                self.instance.initialize_logging()
166
167","[['self.instance._msg_is_comm', '==', 'True'], ['(comm', '==', 'True'], ['_msg)', '==', 'True'], ['self.instance._msg_is_comm', '==', 'False'], ['(taskid_msg)', '==', 'True'], ['self.instance._msg_is_taskid(comm', '==', 'False'], ['_msg)', '==', 'True'], ['self.instance._msg_is_taskid(taskid_msg)', '==', 'True'], ['comm', '==', 'True'], ['', '==', 'comm'], ['_msg', '==', 'True'], ['len(self.instance._pending_taskids)', '==', '3'], ['self.instance.read_comm', '==', 'True'], ['()', '==', 'next_comm'], ['len(self.instance._pending_comm', '==', 'True'], ['s)', '==', '2'], ['taskid', '==', 'taskid_msg'], ['len(self.instance._pending_comm', '==', 'True'], ['s)', '==', '3'], ['self.instance.read_taskid()', '==', 'next_taskid'], ['len(self.instance._pending_taskids)', '==', '2'], ['storm_tuple', '==', 'expected_storm_tuple'], ['conf', '==', '{""foo"": ""bar""}'], ['context', '==', '""context""'], ['fileConfig.called', '==', 'False']]",26,25,0.9615384615384616,0.0036748493311774,"['command_msg', 'taskid_msg', 'messages', 'self.instance._serializer.read_msg.side_effect', 'command', 'next_command', 'another_command', 'taskid', 'next_taskid', 'another_taskid', 'command_dict', 'expected_storm_tuple', 'storm_tuple', 'handshake_msg', 'patch_serializer', 'patch_os_getpid', 'patch__create_pidfile', 'mock_serializer.read_msg.return_value', 'conf', 'context', 'fileConfig', 'pyleus_config']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['command_msg', 'taskid_msg', 'messages', 'self.instance._serializer.read_msg.side_effect', 'command', 'next_command', 'another_command', 'taskid', 'next_taskid', 'another_taskid', 'command_dict', 'expected_storm_tuple', 'storm_tuple', 'handshake_msg', 'patch_serializer', 'patch_os_getpid', 'patch__create_pidfile', 'mock_serializer.read_msg.return_value', 'conf', 'context', 'fileConfig', 'pyleus_config']
*Code:

1import logging.config
2import os.path
3
4from pyleus.storm import StormTuple
5from pyleus.storm.component import DEFAULT_LOGGING_CONFIG_PATH
6from pyleus.storm.serializers.serializer import Serializer
7from pyleus.testing import ComponentTestCase, mock, builtins
8
9
10class TestComponent(ComponentTestCase):
11
12    def test__msg_is_command(self):
13        command_msg = dict(this_is_a_command=True)
14        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
15
16
17    def test__msg_is_taskid(self):
18        command_msg = dict(this_is_a_command=True)
19        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
20
21
22    def test_read_command(self):
23        command_msg = dict(this_is_a_command=True)
24        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
25
26        messages = [
27            taskid_msg,
28            taskid_msg,
29            taskid_msg,
30            command_msg,
31        ]
32
33        with mock.patch.object(
34                self.instance, '_serializer', autospec=Serializer):
35            self.instance._serializer.read_msg.side_effect = messages
36            command = self.instance.read_command()
37
38
39    def test_read_command_queued(self):
40        next_command = dict(next_command=3)
41        another_command = dict(another_command=7)
42
43        self.instance._pending_commands.extend([
44            next_command,
45            another_command,
46            another_command,
47        ])
48
49
50    def test_read_taskid(self):
51        command_msg = dict(this_is_a_command=True)
52        taskid_msg = [""this"", ""is"", ""a"", ""taskid"", ""list""]
53
54        messages = [
55            command_msg,
56            command_msg,
57            command_msg,
58            taskid_msg,
59        ]
60
61        with mock.patch.object(
62                self.instance, '_serializer', autospec=Serializer):
63            self.instance._serializer.read_msg.side_effect = messages
64            taskid = self.instance.read_taskid()
65
66
67    def test_read_taskid_queued(self):
68        next_taskid = dict(next_taskid=3)
69        another_taskid = dict(another_taskid=7)
70
71        self.instance._pending_taskids.extend([
72            next_taskid,
73            another_taskid,
74            another_taskid,
75        ])
76
77
78    def test_read_tuple(self):
79        command_dict = {
80            'id': ""id"",
81            'comp': ""comp"",
82            'stream': ""stream"",
83            'task': ""task"",
84            'tuple': ""tuple"",
85        }
86
87        expected_storm_tuple = StormTuple(
88            ""id"", ""comp"", ""stream"", ""task"", ""tuple"")
89
90        with mock.patch.object(
91                self.instance, 'read_command', return_value=command_dict):
92            storm_tuple = self.instance.read_tuple()
93
94
95    def test__create_pidfile(self):
96        with mock.patch.object(builtins, 'open', autospec=True) as mock_open:
97            self.instance._create_pidfile(""pid_dir"", ""pid"")
98
99
100    def test__init_component(self):
101        handshake_msg = {
102            'conf': {""foo"": ""bar""},
103            'context': ""context"",
104            'pidDir': ""pidDir"",
105        }
106
107        patch_serializer = mock.patch.object(
108            self.instance, '_serializer', autospec=Serializer)
109        patch_os_getpid = mock.patch('os.getpid', return_value=1234)
110        patch__create_pidfile = mock.patch.object(
111            self.instance, '_create_pidfile')
112
113        with patch_serializer as mock_serializer:
114            with patch_os_getpid as mock_os_getpid:
115                with patch__create_pidfile as mock__create_pidfile:
116                    mock_serializer.read_msg.return_value = handshake_msg
117                    conf, context = self.instance._init_component()
118
119
120
121    def test_send_command_with_opts(self):
122        with mock.patch.object(
123                self.instance, '_serializer', autospec=Serializer):
124            self.instance.send_command('test', {'option': ""foo""})
125
126                'command': ""test"",
127                'option': ""foo"",
128            })
129
130    def test_send_command_with_no_opts(self):
131        with mock.patch.object(
132                self.instance, '_serializer', autospec=Serializer):
133            self.instance.send_command('test')
134
135                'command': ""test"",
136            })
137
138    def test_send_command_clobber_command(self):
139        with mock.patch.object(
140                self.instance, '_serializer', autospec=Serializer):
141            self.instance.send_command('test', {'command': ""joe""})
142
143                'command': ""test"",
144            })
145
146    @mock.patch.object(logging.config, 'fileConfig')
147    def test_initialize_logging(self, fileConfig):
148        pyleus_config = {
149            'logging_config_path': mock.sentinel.logging_config_path}
150        with mock.patch.object(self.instance, 'pyleus_config', pyleus_config):
151            self.instance.initialize_logging()
152
153
154    @mock.patch.object(logging.config, 'fileConfig')
155    def test_initialize_logging_default_exists(self, fileConfig):
156        with mock.patch.object(self.instance, 'pyleus_config', {}):
157            with mock.patch.object(os.path, 'isfile', return_value=True):
158                self.instance.initialize_logging()
159
160
161    @mock.patch.object(logging.config, 'fileConfig')
162    def test_initialize_logging_default_no_exists(self, fileConfig):
163        with mock.patch.object(self.instance, 'pyleus_config', {}):
164            with mock.patch.object(os.path, 'isfile', return_value=False):
165                self.instance.initialize_logging()
166
167",7496,"[[13, 'command_msg', '==', {'this_is_a_command': True}, 'command_msg should be a dictionary indicating a command'],
[14, 'taskid_msg', '==', ['this', 'is', 'a', 'taskid', 'list'], 'taskid_msg should be a list indicating a taskid'],
[18, 'command_msg', '==', {'this_is_a_command': True}, 'command_msg should be a dictionary indicating a command'],
[19, 'taskid_msg', '==', ['this', 'is', 'a', 'taskid', 'list'], 'taskid_msg should be a list indicating a taskid'],
[23, 'command_msg', '==', {'this_is_a_command': True}, 'command_msg should be a dictionary indicating a command'],
[24, 'taskid_msg', '==', ['this', 'is', 'a', 'taskid', 'list'], 'taskid_msg should be a list indicating a taskid'],
[39, 'next_command', '==', {'next_command': 3}, 'next_command should be able to indicate the next command'],
[40, 'another_command', '==', {'another_command': 7}, 'another_command should indicate a different command'],
[50, 'command_msg', '==', {'this_is_a_command': True}, 'command_msg should be a dictionary indicating a command'],
[51, 'taskid_msg', '==', ['this', 'is', 'a', 'taskid', 'list'], 'taskid_msg should be a list indicating a taskid'],
[67, 'next_taskid', '==', {'next_taskid': 3}, 'next_taskid should be indicating the next taskid'],
[68, 'another_taskid', '==', {'another_taskid': 7}, 'another_taskid should indicate a different taskid'],
[78, 'command_dict', '==', {'id': ""id"", 'comp': ""comp"", 'stream': ""stream"", 'task': ""task"", 'tuple': ""tuple""}, 'command_dict should be a dictionary containing different parameters'],
[96, 'mock_open', '==', {'open': True}, 'mock_open should be open when creating pidfile'],
[101, 'handshake_msg', '==', {'conf': {""foo"": ""bar""}, 'context': ""context"", 'pidDir' : 'pidDir'}, 'handshake message should contain configuration, context and pid directory']]"
jakirkham/billiard,"#
# Support for the API of the multiprocessing package using threads
#
# multiprocessing/dummy/__init__.py
#
# Copyright (c) 2006-2008, R Oudkerk
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of author nor the names of any contributors may be
#    used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ""AS IS"" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.
#
from __future__ import absolute_import

#
# Imports
#

import threading
import sys
import weakref
import array

from threading import Lock, RLock, Semaphore, BoundedSemaphore
from threading import Event

from billiard.five import Queue

from billiard.connection import Pipe

__all__ = [
    'Process', 'current_process', 'active_children', 'freeze_support',
    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',
    'Event', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'
]


class DummyProcess(threading.Thread):

    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):
        threading.Thread.__init__(self, group, target, name, args, kwargs)
        self._pid = None
        self._children = weakref.WeakKeyDictionary()
        self._start_called = False
        self._parent = current_process()

    def start(self):
        assert self._parent is current_process()
        self._start_called = True
        self._parent._children[self] = None
        threading.Thread.start(self)

    @property
    def exitcode(self):
        if self._start_called and not self.is_alive():
            return 0
        else:
            return None


try:
    _Condition = threading._Condition
except AttributeError:  # Py3
    _Condition = threading.Condition  # noqa


class Condition(_Condition):
    if sys.version_info[0] == 3:
        notify_all = _Condition.notifyAll
    else:
        notify_all = _Condition.notifyAll.__func__


Process = DummyProcess
current_process = threading.current_thread
current_process()._children = weakref.WeakKeyDictionary()


def active_children():
    children = current_process()._children
    for p in list(children):
        if not p.is_alive():
            children.pop(p, None)
    return list(children)


def freeze_support():
    pass


class Namespace(object):

    def __init__(self, **kwds):
        self.__dict__.update(kwds)

    def __repr__(self):
        items = list(self.__dict__.items())
        temp = []
        for name, value in items:
            if not name.startswith('_'):
                temp.append('%s=%r' % (name, value))
        temp.sort()
        return '%s(%s)' % (self.__class__.__name__, str.join(', ', temp))


dict = dict
list = list


def Array(typecode, sequence, lock=True):
    return array.array(typecode, sequence)


class Value(object):

    def __init__(self, typecode, value, lock=True):
        self._typecode = typecode
        self._value = value

    def _get(self):
        return self._value

    def _set(self, value):
        self._value = value
    value = property(_get, _set)

    def __repr__(self):
        return '<%r(%r, %r)>' % (type(self).__name__,
                                 self._typecode, self._value)


def Manager():
    return sys.modules[__name__]


def shutdown():
    pass


def Pool(processes=None, initializer=None, initargs=()):
    from billiard.pool import ThreadPool
    return ThreadPool(processes, initializer, initargs)

JoinableQueue = Queue
","
1#
2# Support for the API of the multiprocessing package using threads
3#
4# multiprocessing/dummy/__init__.py
5#
6# Copyright (c) 2006-2008, R Oudkerk
7# All rights reserved.
8#
9# Redistribution and use in source and binary forms, with or without
10# modification, are permitted provided that the following conditions
11# are met:
12#
13# 1. Redistributions of source code must retain the above copyright
14#    notice, this list of conditions and the following disclaimer.
15# 2. Redistributions in binary form must reproduce the above copyright
16#    notice, this list of conditions and the following disclaimer in the
17#    documentation and/or other materials provided with the distribution.
18# 3. Neither the name of author nor the names of any contributors may be
19#    used to endorse or promote products derived from this software
20#    without specific prior written permission.
21#
22# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ""AS IS"" AND
23# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
24# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
25# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
26# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
27# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
28# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
29# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
30# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
31# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
32# SUCH DAMAGE.
33#
34from __future__ import absolute_import
35
36#
37# Imports
38#
39
40import threading
41import sys
42import weakref
43import array
44
45from threading import Lock, RLock, Semaphore, BoundedSemaphore
46from threading import Event
47
48from billiard.five import Queue
49
50from billiard.connection import Pipe
51
52__all__ = [
53    'Process', 'current_process', 'active_children', 'freeze_support',
54    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',
55    'Event', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'
56]
57
58
59class DummyProcess(threading.Thread):
60
61    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):
62        threading.Thread.__init__(self, group, target, name, args, kwargs)
63        self._pid = None
64        self._children = weakref.WeakKeyDictionary()
65        self._start_called = False
66        self._parent = current_process()
67
68    def start(self):
69        self._start_called = True
70        self._parent._children[self] = None
71        threading.Thread.start(self)
72
73    @property
74    def exitcode(self):
75        if self._start_called and not self.is_alive():
76            return 0
77        else:
78            return None
79
80
81try:
82    _Condition = threading._Condition
83except AttributeError:  # Py3
84    _Condition = threading.Condition  # noqa
85
86
87class Condition(_Condition):
88    if sys.version_info[0] == 3:
89        notify_all = _Condition.notifyAll
90    else:
91        notify_all = _Condition.notifyAll.__func__
92
93
94Process = DummyProcess
95current_process = threading.current_thread
96current_process()._children = weakref.WeakKeyDictionary()
97
98
99def active_children():
100    children = current_process()._children
101    for p in list(children):
102        if not p.is_alive():
103            children.pop(p, None)
104    return list(children)
105
106
107def freeze_support():
108    pass
109
110
111class Namespace(object):
112
113    def __init__(self, **kwds):
114        self.__dict__.update(kwds)
115
116    def __repr__(self):
117        items = list(self.__dict__.items())
118        temp = []
119        for name, value in items:
120            if not name.startswith('_'):
121                temp.append('%s=%r' % (name, value))
122        temp.sort()
123        return '%s(%s)' % (self.__class__.__name__, str.join(', ', temp))
124
125
126dict = dict
127list = list
128
129
130def Array(typecode, sequence, lock=True):
131    return array.array(typecode, sequence)
132
133
134class Value(object):
135
136    def __init__(self, typecode, value, lock=True):
137        self._typecode = typecode
138        self._value = value
139
140    def _get(self):
141        return self._value
142
143    def _set(self, value):
144        self._value = value
145    value = property(_get, _set)
146
147    def __repr__(self):
148        return '<%r(%r, %r)>' % (type(self).__name__,
149                                 self._typecode, self._value)
150
151
152def Manager():
153    return sys.modules[__name__]
154
155
156def shutdown():
157    pass
158
159
160def Pool(processes=None, initializer=None, initargs=()):
161    from billiard.pool import ThreadPool
162    return ThreadPool(processes, initializer, initargs)
163
164JoinableQueue = Queue
165","[['self._parent', '==', 'current_process()']]",1,1,1.0,0.0002160760587726,"['__all__', 'group', 'target', 'name', 'args', 'self._pid', 'self._children', 'self._start_called', 'self._parent', 'self._parent._children[self]', '_Condition', 'notify_all', 'Process', 'current_process', 'current_process()._children', 'children', '**kwds', 'items', 'temp', 'dict', 'list', 'typecode', 'sequence', 'lock', 'value', 'self._typecode', 'self._value', 'processes', 'initializer', 'initargs', 'JoinableQueue']",31,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'group', 'target', 'name', 'args', 'self._pid', 'self._children', 'self._start_called', 'self._parent', 'self._parent._children[self]', '_Condition', 'notify_all', 'Process', 'current_process', 'current_process()._children', 'children', '**kwds', 'items', 'temp', 'dict', 'list', 'typecode', 'sequence', 'lock', 'value', 'self._typecode', 'self._value', 'processes', 'initializer', 'initargs', 'JoinableQueue']
*Code:

1#
2# Support for the API of the multiprocessing package using threads
3#
4# multiprocessing/dummy/__init__.py
5#
6# Copyright (c) 2006-2008, R Oudkerk
7# All rights reserved.
8#
9# Redistribution and use in source and binary forms, with or without
10# modification, are permitted provided that the following conditions
11# are met:
12#
13# 1. Redistributions of source code must retain the above copyright
14#    notice, this list of conditions and the following disclaimer.
15# 2. Redistributions in binary form must reproduce the above copyright
16#    notice, this list of conditions and the following disclaimer in the
17#    documentation and/or other materials provided with the distribution.
18# 3. Neither the name of author nor the names of any contributors may be
19#    used to endorse or promote products derived from this software
20#    without specific prior written permission.
21#
22# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ""AS IS"" AND
23# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
24# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
25# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
26# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
27# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
28# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
29# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
30# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
31# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
32# SUCH DAMAGE.
33#
34from __future__ import absolute_import
35
36#
37# Imports
38#
39
40import threading
41import sys
42import weakref
43import array
44
45from threading import Lock, RLock, Semaphore, BoundedSemaphore
46from threading import Event
47
48from billiard.five import Queue
49
50from billiard.connection import Pipe
51
52__all__ = [
53    'Process', 'current_process', 'active_children', 'freeze_support',
54    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',
55    'Event', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'
56]
57
58
59class DummyProcess(threading.Thread):
60
61    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):
62        threading.Thread.__init__(self, group, target, name, args, kwargs)
63        self._pid = None
64        self._children = weakref.WeakKeyDictionary()
65        self._start_called = False
66        self._parent = current_process()
67
68    def start(self):
69        self._start_called = True
70        self._parent._children[self] = None
71        threading.Thread.start(self)
72
73    @property
74    def exitcode(self):
75        if self._start_called and not self.is_alive():
76            return 0
77        else:
78            return None
79
80
81try:
82    _Condition = threading._Condition
83except AttributeError:  # Py3
84    _Condition = threading.Condition  # noqa
85
86
87class Condition(_Condition):
88    if sys.version_info[0] == 3:
89        notify_all = _Condition.notifyAll
90    else:
91        notify_all = _Condition.notifyAll.__func__
92
93
94Process = DummyProcess
95current_process = threading.current_thread
96current_process()._children = weakref.WeakKeyDictionary()
97
98
99def active_children():
100    children = current_process()._children
101    for p in list(children):
102        if not p.is_alive():
103            children.pop(p, None)
104    return list(children)
105
106
107def freeze_support():
108    pass
109
110
111class Namespace(object):
112
113    def __init__(self, **kwds):
114        self.__dict__.update(kwds)
115
116    def __repr__(self):
117        items = list(self.__dict__.items())
118        temp = []
119        for name, value in items:
120            if not name.startswith('_'):
121                temp.append('%s=%r' % (name, value))
122        temp.sort()
123        return '%s(%s)' % (self.__class__.__name__, str.join(', ', temp))
124
125
126dict = dict
127list = list
128
129
130def Array(typecode, sequence, lock=True):
131    return array.array(typecode, sequence)
132
133
134class Value(object):
135
136    def __init__(self, typecode, value, lock=True):
137        self._typecode = typecode
138        self._value = value
139
140    def _get(self):
141        return self._value
142
143    def _set(self, value):
144        self._value = value
145    value = property(_get, _set)
146
147    def __repr__(self):
148        return '<%r(%r, %r)>' % (type(self).__name__,
149                                 self._typecode, self._value)
150
151
152def Manager():
153    return sys.modules[__name__]
154
155
156def shutdown():
157    pass
158
159
160def Pool(processes=None, initializer=None, initargs=()):
161    from billiard.pool import ThreadPool
162    return ThreadPool(processes, initializer, initargs)
163
164JoinableQueue = Queue
165",6769,"[[61, 'args', '==', 'tuple', ""args should be a tuple for threading.Thread constructor""], 
 [61, 'kwargs', '==', 'dict', ""kwargs should be a dictionary for threading.Thread constructor""], 
 [136, 'typecode', '==', 'str', ""typecode should be a string for array constructor""], 
 [136, 'value', '!=', None, ""value should not be None""], 
 [160, 'initargs', '==', 'tuple', ""initargs should be a tuple for ThreadPool constructor""]]"
SimonSapin/servo,"import pytest

from webdriver.error import NoSuchWindowException

from tests.actions.support.mouse import get_inview_center, get_viewport_rect
from tests.actions.support.refine import get_events, filter_dict
from tests.support.asserts import assert_move_to_coordinates
from tests.support.inline import inline
from tests.support.wait import wait


def link_doc(dest):
    content = ""<a href=\""{}\"" id=\""link\"">destination</a>"".format(dest)
    return inline(content)


def test_null_response_value(session, mouse_chain):
    value = mouse_chain.click().perform()
    assert value is None

    value = session.actions.release()
    assert value is None


def test_no_browsing_context(session, closed_window, mouse_chain):
    with pytest.raises(NoSuchWindowException):
        mouse_chain.click().perform()


def test_click_at_coordinates(session, test_actions_page, mouse_chain):
    div_point = {
        ""x"": 82,
        ""y"": 187,
    }
    mouse_chain \
        .pointer_move(div_point[""x""], div_point[""y""], duration=1000) \
        .click() \
        .perform()
    events = get_events(session)
    assert len(events) == 4
    assert_move_to_coordinates(div_point, ""outer"", events)
    for e in events:
        if e[""type""] != ""mousedown"":
            assert e[""buttons""] == 0
        assert e[""button""] == 0
    expected = [
        {""type"": ""mousedown"", ""buttons"": 1},
        {""type"": ""mouseup"", ""buttons"": 0},
        {""type"": ""click"", ""buttons"": 0},
    ]
    filtered_events = [filter_dict(e, expected[0]) for e in events]
    assert expected == filtered_events[1:]


def test_context_menu_at_coordinates(session, test_actions_page, mouse_chain):
    div_point = {
        ""x"": 82,
        ""y"": 187,
    }
    mouse_chain \
        .pointer_move(div_point[""x""], div_point[""y""]) \
        .pointer_down(button=2) \
        .pointer_up(button=2) \
        .perform()
    events = get_events(session)
    expected = [
        {""type"": ""mousedown"", ""button"": 2},
        {""type"": ""contextmenu"", ""button"": 2},
    ]
    assert len(events) == 4
    filtered_events = [filter_dict(e, expected[0]) for e in events]
    mousedown_contextmenu_events = [
        x for x in filtered_events
        if x[""type""] in [""mousedown"", ""contextmenu""]
    ]
    assert expected == mousedown_contextmenu_events


def test_click_element_center(session, test_actions_page, mouse_chain):
    outer = session.find.css(""#outer"", all=False)
    center = get_inview_center(outer.rect, get_viewport_rect(session))
    mouse_chain.click(element=outer).perform()
    events = get_events(session)
    assert len(events) == 4
    event_types = [e[""type""] for e in events]
    assert [""mousemove"", ""mousedown"", ""mouseup"", ""click""] == event_types
    for e in events:
        if e[""type""] != ""mousemove"":
            assert pytest.approx(e[""pageX""], center[""x""])
            assert pytest.approx(e[""pageY""], center[""y""])
            assert e[""target""] == ""outer""


def test_click_navigation(session, url, release_actions):
    destination = url(""/webdriver/tests/actions/support/test_actions_wdspec.html"")
    start = link_doc(destination)

    def click(link):
        mouse_chain = session.actions.sequence(
            ""pointer"", ""pointer_id"", {""pointerType"": ""mouse""})
        mouse_chain.click(element=link).perform()

    session.url = start
    error_message = ""Did not navigate to %s"" % destination

    click(session.find.css(""#link"", all=False))
    wait(session, lambda s: s.url == destination, error_message)
    # repeat steps to check behaviour after document unload
    session.url = start
    click(session.find.css(""#link"", all=False))
    wait(session, lambda s: s.url == destination, error_message)


@pytest.mark.parametrize(""drag_duration"", [0, 300, 800])
@pytest.mark.parametrize(""dx, dy"", [
    (20, 0), (0, 15), (10, 15), (-20, 0), (10, -15), (-10, -15)
])
def test_drag_and_drop(session,
                       test_actions_page,
                       mouse_chain,
                       dx,
                       dy,
                       drag_duration):
    drag_target = session.find.css(""#dragTarget"", all=False)
    initial_rect = drag_target.rect
    initial_center = get_inview_center(initial_rect, get_viewport_rect(session))
    # Conclude chain with extra move to allow time for last queued
    # coordinate-update of drag_target and to test that drag_target is ""dropped"".
    mouse_chain \
        .pointer_move(0, 0, origin=drag_target) \
        .pointer_down() \
        .pointer_move(dx, dy, duration=drag_duration, origin=""pointer"") \
        .pointer_up() \
        .pointer_move(80, 50, duration=100, origin=""pointer"") \
        .perform()
    # mouseup that ends the drag is at the expected destination
    e = get_events(session)[1]
    assert e[""type""] == ""mouseup""
    assert pytest.approx(e[""pageX""], initial_center[""x""] + dx)
    assert pytest.approx(e[""pageY""], initial_center[""y""] + dy)
    # check resulting location of the dragged element
    final_rect = drag_target.rect
    assert initial_rect[""x""] + dx == final_rect[""x""]
    assert initial_rect[""y""] + dy == final_rect[""y""]
","
1import pytest
2
3from webdriver.error import NoSuchWindowException
4
5from tests.actions.support.mouse import get_inview_center, get_viewport_rect
6from tests.actions.support.refine import get_events, filter_dict
7from tests.support.inline import inline
8from tests.support.wait import wait
9
10
11def link_doc(dest):
12    content = ""<a href=\""{}\"" id=\""link\"">destination</a>"".format(dest)
13    return inline(content)
14
15
16def test_null_response_value(session, mouse_chain):
17    value = mouse_chain.click().perform()
18
19    value = session.actions.release()
20
21
22def test_no_browsing_context(session, closed_window, mouse_chain):
23    with pytest.raises(NoSuchWindowException):
24        mouse_chain.click().perform()
25
26
27def test_click_at_coordinates(session, test_actions_page, mouse_chain):
28    div_point = {
29        ""x"": 82,
30        ""y"": 187,
31    }
32    mouse_chain \
33        .pointer_move(div_point[""x""], div_point[""y""], duration=1000) \
34        .click() \
35        .perform()
36    events = get_events(session)
37    for e in events:
38        if e[""type""] != ""mousedown"":
39    expected = [
40        {""type"": ""mousedown"", ""buttons"": 1},
41        {""type"": ""mouseup"", ""buttons"": 0},
42        {""type"": ""click"", ""buttons"": 0},
43    ]
44    filtered_events = [filter_dict(e, expected[0]) for e in events]
45
46
47def test_context_menu_at_coordinates(session, test_actions_page, mouse_chain):
48    div_point = {
49        ""x"": 82,
50        ""y"": 187,
51    }
52    mouse_chain \
53        .pointer_move(div_point[""x""], div_point[""y""]) \
54        .pointer_down(button=2) \
55        .pointer_up(button=2) \
56        .perform()
57    events = get_events(session)
58    expected = [
59        {""type"": ""mousedown"", ""button"": 2},
60        {""type"": ""contextmenu"", ""button"": 2},
61    ]
62    filtered_events = [filter_dict(e, expected[0]) for e in events]
63    mousedown_contextmenu_events = [
64        x for x in filtered_events
65        if x[""type""] in [""mousedown"", ""contextmenu""]
66    ]
67
68
69def test_click_element_center(session, test_actions_page, mouse_chain):
70    outer = session.find.css(""#outer"", all=False)
71    center = get_inview_center(outer.rect, get_viewport_rect(session))
72    mouse_chain.click(element=outer).perform()
73    events = get_events(session)
74    event_types = [e[""type""] for e in events]
75    for e in events:
76        if e[""type""] != ""mousemove"":
77
78
79def test_click_navigation(session, url, release_actions):
80    destination = url(""/webdriver/tests/actions/support/test_actions_wdspec.html"")
81    start = link_doc(destination)
82
83    def click(link):
84        mouse_chain = session.actions.sequence(
85            ""pointer"", ""pointer_id"", {""pointerType"": ""mouse""})
86        mouse_chain.click(element=link).perform()
87
88    session.url = start
89    error_message = ""Did not navigate to %s"" % destination
90
91    click(session.find.css(""#link"", all=False))
92    wait(session, lambda s: s.url == destination, error_message)
93    # repeat steps to check behaviour after document unload
94    session.url = start
95    click(session.find.css(""#link"", all=False))
96    wait(session, lambda s: s.url == destination, error_message)
97
98
99@pytest.mark.parametrize(""drag_duration"", [0, 300, 800])
100@pytest.mark.parametrize(""dx, dy"", [
101    (20, 0), (0, 15), (10, 15), (-20, 0), (10, -15), (-10, -15)
102])
103def test_drag_and_drop(session,
104                       test_actions_page,
105                       mouse_chain,
106                       dx,
107                       dy,
108                       drag_duration):
109    drag_target = session.find.css(""#dragTarget"", all=False)
110    initial_rect = drag_target.rect
111    initial_center = get_inview_center(initial_rect, get_viewport_rect(session))
112    # Conclude chain with extra move to allow time for last queued
113    # coordinate-update of drag_target and to test that drag_target is ""dropped"".
114    mouse_chain \
115        .pointer_move(0, 0, origin=drag_target) \
116        .pointer_down() \
117        .pointer_move(dx, dy, duration=drag_duration, origin=""pointer"") \
118        .pointer_up() \
119        .pointer_move(80, 50, duration=100, origin=""pointer"") \
120        .perform()
121    # mouseup that ends the drag is at the expected destination
122    e = get_events(session)[1]
123    # check resulting location of the dragged element
124    final_rect = drag_target.rect
125","[['value', '==', 'None'], ['value', '==', 'None'], ['len(events)', '==', '4'], ['e[""buttons""]', '==', '0'], ['e[""button""]', '==', '0'], ['expected', '==', 'filtered_events[1:]'], ['len(events)', '==', '4'], ['expected', '==', 'mousedown_contextmenu_events'], ['len(events)', '==', '4'], ['[""mousemove""', '==', 'True'], ['pytest.approx(e[""pageX""]', '==', 'True'], ['pytest.approx(e[""pageY""]', '==', 'True'], ['e[""target""]', '==', '""outer""'], ['e[""type""]', '==', '""mouseup""'], ['pytest.approx(e[""pageX""]', '==', 'True'], ['pytest.approx(e[""pageY""]', '==', 'True'], ['initial_rect[""x""] + dx', '==', 'final_rect[""x""]'], ['initial_rect[""y""] + dy', '==', 'final_rect[""y""]']]",20,18,0.9,0.003523194362889,"['dest', 'content', 'session', 'mouse_chain', 'value', 'closed_window', 'test_actions_page', 'div_point', 'events', 'expected', 'filtered_events', 'mousedown_contextmenu_events', 'outer', 'center', 'event_types', 'url', 'release_actions', 'destination', 'start', 'link', 'session.url', 'error_message', 'drag_target', 'initial_rect', 'initial_center', 'e', 'final_rect']",27,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['dest', 'content', 'session', 'mouse_chain', 'value', 'closed_window', 'test_actions_page', 'div_point', 'events', 'expected', 'filtered_events', 'mousedown_contextmenu_events', 'outer', 'center', 'event_types', 'url', 'release_actions', 'destination', 'start', 'link', 'session.url', 'error_message', 'drag_target', 'initial_rect', 'initial_center', 'e', 'final_rect']
*Code:

1import pytest
2
3from webdriver.error import NoSuchWindowException
4
5from tests.actions.support.mouse import get_inview_center, get_viewport_rect
6from tests.actions.support.refine import get_events, filter_dict
7from tests.support.inline import inline
8from tests.support.wait import wait
9
10
11def link_doc(dest):
12    content = ""<a href=\""{}\"" id=\""link\"">destination</a>"".format(dest)
13    return inline(content)
14
15
16def test_null_response_value(session, mouse_chain):
17    value = mouse_chain.click().perform()
18
19    value = session.actions.release()
20
21
22def test_no_browsing_context(session, closed_window, mouse_chain):
23    with pytest.raises(NoSuchWindowException):
24        mouse_chain.click().perform()
25
26
27def test_click_at_coordinates(session, test_actions_page, mouse_chain):
28    div_point = {
29        ""x"": 82,
30        ""y"": 187,
31    }
32    mouse_chain \
33        .pointer_move(div_point[""x""], div_point[""y""], duration=1000) \
34        .click() \
35        .perform()
36    events = get_events(session)
37    for e in events:
38        if e[""type""] != ""mousedown"":
39    expected = [
40        {""type"": ""mousedown"", ""buttons"": 1},
41        {""type"": ""mouseup"", ""buttons"": 0},
42        {""type"": ""click"", ""buttons"": 0},
43    ]
44    filtered_events = [filter_dict(e, expected[0]) for e in events]
45
46
47def test_context_menu_at_coordinates(session, test_actions_page, mouse_chain):
48    div_point = {
49        ""x"": 82,
50        ""y"": 187,
51    }
52    mouse_chain \
53        .pointer_move(div_point[""x""], div_point[""y""]) \
54        .pointer_down(button=2) \
55        .pointer_up(button=2) \
56        .perform()
57    events = get_events(session)
58    expected = [
59        {""type"": ""mousedown"", ""button"": 2},
60        {""type"": ""contextmenu"", ""button"": 2},
61    ]
62    filtered_events = [filter_dict(e, expected[0]) for e in events]
63    mousedown_contextmenu_events = [
64        x for x in filtered_events
65        if x[""type""] in [""mousedown"", ""contextmenu""]
66    ]
67
68
69def test_click_element_center(session, test_actions_page, mouse_chain):
70    outer = session.find.css(""#outer"", all=False)
71    center = get_inview_center(outer.rect, get_viewport_rect(session))
72    mouse_chain.click(element=outer).perform()
73    events = get_events(session)
74    event_types = [e[""type""] for e in events]
75    for e in events:
76        if e[""type""] != ""mousemove"":
77
78
79def test_click_navigation(session, url, release_actions):
80    destination = url(""/webdriver/tests/actions/support/test_actions_wdspec.html"")
81    start = link_doc(destination)
82
83    def click(link):
84        mouse_chain = session.actions.sequence(
85            ""pointer"", ""pointer_id"", {""pointerType"": ""mouse""})
86        mouse_chain.click(element=link).perform()
87
88    session.url = start
89    error_message = ""Did not navigate to %s"" % destination
90
91    click(session.find.css(""#link"", all=False))
92    wait(session, lambda s: s.url == destination, error_message)
93    # repeat steps to check behaviour after document unload
94    session.url = start
95    click(session.find.css(""#link"", all=False))
96    wait(session, lambda s: s.url == destination, error_message)
97
98
99@pytest.mark.parametrize(""drag_duration"", [0, 300, 800])
100@pytest.mark.parametrize(""dx, dy"", [
101    (20, 0), (0, 15), (10, 15), (-20, 0), (10, -15), (-10, -15)
102])
103def test_drag_and_drop(session,
104                       test_actions_page,
105                       mouse_chain,
106                       dx,
107                       dy,
108                       drag_duration):
109    drag_target = session.find.css(""#dragTarget"", all=False)
110    initial_rect = drag_target.rect
111    initial_center = get_inview_center(initial_rect, get_viewport_rect(session))
112    # Conclude chain with extra move to allow time for last queued
113    # coordinate-update of drag_target and to test that drag_target is ""dropped"".
114    mouse_chain \
115        .pointer_move(0, 0, origin=drag_target) \
116        .pointer_down() \
117        .pointer_move(dx, dy, duration=drag_duration, origin=""pointer"") \
118        .pointer_up() \
119        .pointer_move(80, 50, duration=100, origin=""pointer"") \
120        .perform()
121    # mouseup that ends the drag is at the expected destination
122    e = get_events(session)[1]
123    # check resulting location of the dragged element
124    final_rect = drag_target.rect
125",6212,"[[11, 'dest', '!=', None, ""Link destination must not be None""],
[16, 'session', '!=', None, ""Session object must not be None""],
[16, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[22, 'session', '!=', None, ""Session object must not be None""],
[22, 'closed_window', '!=', None, ""Closed window object must not be None""],
[22, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[27, 'session', '!=', None, ""Session object must not be None""],
[27, 'test_actions_page', '!=', None, ""Test actions page must not be None""],
[27, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[47, 'session', '!=', None, ""Session object must not be None""],
[47, 'test_actions_page', '!=', None, ""Test actions page must not be None""],
[47, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[69, 'session', '!=', None, ""Session object must not be None""],
[69, 'test_actions_page', '!=', None, ""Test actions page must not be None""],
[69, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[79, 'session', '!=', None, ""Session object must not be None""],
[79, 'url', '!=', None, ""URL must not be None""],
[79, 'release_actions', '!=', None, ""Release actions must not be None""],
[103, 'session', '!=', None, ""Session object must not be None""],
[103, 'test_actions_page', '!=', None, ""Test actions page must not be None""],
[103, 'mouse_chain', '!=', None, ""Mouse chain must not be None""],
[103, 'dx', '!=', None, ""Distance in x axis must not be None""],
[103, 'dy', '!=', None, ""Distance in y axis must not be None""],
[103, 'drag_duration', '>=', 0, ""Drag duration must not be negative""],
[122, 'e', '!=', None, 'Event object must not be None'],
[124, 'drag_target', '!=', None, ""Drag target must not be None""]]"
meles5/qutebrowser,"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2016 Ryan Roden-Corrent (rcorre) <ryan@rcorre.net>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

import pytest_bdd as bdd
bdd.scenarios('marks.feature')


@bdd.then(bdd.parsers.parse(""the page should be scrolled to {x} {y}""))
def check_y(quteproc, x, y):
    data = quteproc.get_session()
    pos = data['windows'][0]['tabs'][0]['history'][-1]['scroll-pos']
    assert int(x) == pos['x']
    assert int(y) == pos['y']
","
1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2016 Ryan Roden-Corrent (rcorre) <ryan@rcorre.net>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
19
20import pytest_bdd as bdd
21bdd.scenarios('marks.feature')
22
23
24@bdd.then(bdd.parsers.parse(""the page should be scrolled to {x} {y}""))
25def check_y(quteproc, x, y):
26    data = quteproc.get_session()
27    pos = data['windows'][0]['tabs'][0]['history'][-1]['scroll-pos']
28","[['int(x)', '==', ""pos['x']""], ['int(y)', '==', ""pos['y']""]]",2,2,1.0,0.0018050541516245,"['quteproc', 'x', 'y', 'data', 'pos']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['quteproc', 'x', 'y', 'data', 'pos']
*Code:

1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2016 Ryan Roden-Corrent (rcorre) <ryan@rcorre.net>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
19
20import pytest_bdd as bdd
21bdd.scenarios('marks.feature')
22
23
24@bdd.then(bdd.parsers.parse(""the page should be scrolled to {x} {y}""))
25def check_y(quteproc, x, y):
26    data = quteproc.get_session()
27    pos = data['windows'][0]['tabs'][0]['history'][-1]['scroll-pos']
28",2513,"[[26, 'quteproc', '!=', None, ""quteproc shouldn't be None""], [26, 'x', '!=', None, ""x shouldn't be None""], [26, 'y', '!=', None, ""y shouldn't be None""], [28, 'data', '!=', None, ""data shouldn't be None after getting the session""], [28, 'data', '==', 'dict', ""data should be a dictionary""], [28, 'data[\'windows\'][0][\'tabs\'][0][\'history\'][-1]['scroll-pos']', '>=', 0, ""scrolling positions should always be non-negative as it starts from 0""]]"
edx/edx-platform,"""""""
Test the user api's partition extensions.
""""""


from collections import defaultdict
from unittest.mock import patch

import pytest
from django.test import TestCase

from openedx.core.djangoapps.user_api.partition_schemes import RandomUserPartitionScheme, UserPartitionError
from common.djangoapps.student.tests.factories import UserFactory
from xmodule.partitions.partitions import Group, UserPartition  # lint-amnesty, pylint: disable=wrong-import-order
from xmodule.partitions.tests.test_partitions import PartitionTestCase  # lint-amnesty, pylint: disable=wrong-import-order


class MemoryCourseTagAPI:
    """"""
    An implementation of a user service that uses an in-memory dictionary for storage
    """"""
    def __init__(self):
        self._tags = defaultdict(dict)

    def get_course_tag(self, __, course_id, key):
        """"""Sets the value of ``key`` to ``value``""""""
        return self._tags[course_id].get(key)

    def set_course_tag(self, __, course_id, key, value):
        """"""Gets the value of ``key``""""""
        self._tags[course_id][key] = value

    class BulkCourseTags:
        @classmethod
        def is_prefetched(self, course_id):  # lint-amnesty, pylint: disable=bad-classmethod-argument, unused-argument
            return False


@pytest.mark.django_db
class TestRandomUserPartitionScheme(PartitionTestCase):
    """"""
    Test getting a user's group out of a partition
    """"""

    MOCK_COURSE_ID = ""mock-course-id""

    def setUp(self):
        super().setUp()
        # Patch in a memory-based user service instead of using the persistent version
        course_tag_api = MemoryCourseTagAPI()
        self.user_service_patcher = patch(
            'openedx.core.djangoapps.user_api.partition_schemes.course_tag_api', course_tag_api
        )
        self.user_service_patcher.start()
        self.addCleanup(self.user_service_patcher.stop)

        # Create a test user
        self.user = UserFactory.create()

    def test_get_group_for_user(self):
        # get a group assigned to the user
        group1_id = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)

        # make sure we get the same group back out every time
        for __ in range(10):
            group2_id = RandomUserPartitionScheme.get_group_for_user(
                self.MOCK_COURSE_ID,
                self.user,
                self.user_partition
            )
            assert group1_id == group2_id

    def test_get_group_for_user_with_assign(self):
        """"""
        Make sure get_group_for_user returns None if no group is already
        assigned to a user instead of assigning/creating a group automatically
        """"""
        # We should not get any group because assign is False which will
        # protect us from automatically creating a group for user
        group = RandomUserPartitionScheme.get_group_for_user(
            self.MOCK_COURSE_ID, self.user, self.user_partition, assign=False
        )

        assert group is None

        # We should get a group automatically assigned to user
        group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)

        assert group is not None

    def test_empty_partition(self):
        empty_partition = UserPartition(
            self.TEST_ID,
            'Test Partition',
            'for testing purposes',
            [],
            scheme=RandomUserPartitionScheme
        )
        # get a group assigned to the user
        with self.assertRaisesRegex(UserPartitionError, ""Cannot assign user to an empty user partition""):
            RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, empty_partition)

    def test_user_in_deleted_group(self):
        # get a group assigned to the user - should be group 0 or 1
        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
        assert old_group.id in [0, 1]

        # Change the group definitions! No more group 0 or 1
        groups = [Group(3, 'Group 3'), Group(4, 'Group 4')]
        user_partition = UserPartition(self.TEST_ID, 'Test Partition', 'for testing purposes', groups)

        # Now, get a new group using the same call - should be 3 or 4
        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
        assert new_group.id in [3, 4]

        # We should get the same group over multiple calls
        new_group_2 = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
        assert new_group == new_group_2

    def test_change_group_name(self):
        # Changing the name of the group shouldn't affect anything
        # get a group assigned to the user - should be group 0 or 1
        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
        assert old_group.id in [0, 1]

        # Change the group names
        groups = [Group(0, 'Group 0'), Group(1, 'Group 1')]
        user_partition = UserPartition(
            self.TEST_ID,
            'Test Partition',
            'for testing purposes',
            groups,
            scheme=RandomUserPartitionScheme
        )

        # Now, get a new group using the same call
        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
        assert old_group.id == new_group.id


class TestExtension(TestCase):
    """"""
    Ensure that the scheme extension is correctly plugged in (via entry point
    in setup.py)
    """"""

    def test_get_scheme(self):
        assert UserPartition.get_scheme('random') == RandomUserPartitionScheme
        with self.assertRaisesRegex(UserPartitionError, 'Unrecognized scheme'):
            UserPartition.get_scheme('other')
","
1""""""
2Test the user api's partition extensions.
3""""""
4
5
6from collections import defaultdict
7from unittest.mock import patch
8
9import pytest
10from django.test import TestCase
11
12from openedx.core.djangoapps.user_api.partition_schemes import RandomUserPartitionScheme, UserPartitionError
13from common.djangoapps.student.tests.factories import UserFactory
14from xmodule.partitions.partitions import Group, UserPartition  # lint-amnesty, pylint: disable=wrong-import-order
15from xmodule.partitions.tests.test_partitions import PartitionTestCase  # lint-amnesty, pylint: disable=wrong-import-order
16
17
18class MemoryCourseTagAPI:
19    """"""
20    An implementation of a user service that uses an in-memory dictionary for storage
21    """"""
22    def __init__(self):
23        self._tags = defaultdict(dict)
24
25    def get_course_tag(self, __, course_id, key):
26        """"""Sets the value of ``key`` to ``value``""""""
27        return self._tags[course_id].get(key)
28
29    def set_course_tag(self, __, course_id, key, value):
30        """"""Gets the value of ``key``""""""
31        self._tags[course_id][key] = value
32
33    class BulkCourseTags:
34        @classmethod
35        def is_prefetched(self, course_id):  # lint-amnesty, pylint: disable=bad-classmethod-argument, unused-argument
36            return False
37
38
39@pytest.mark.django_db
40class TestRandomUserPartitionScheme(PartitionTestCase):
41    """"""
42    Test getting a user's group out of a partition
43    """"""
44
45    MOCK_COURSE_ID = ""mock-course-id""
46
47    def setUp(self):
48        super().setUp()
49        # Patch in a memory-based user service instead of using the persistent version
50        course_tag_api = MemoryCourseTagAPI()
51        self.user_service_patcher = patch(
52            'openedx.core.djangoapps.user_api.partition_schemes.course_tag_api', course_tag_api
53        )
54        self.user_service_patcher.start()
55        self.addCleanup(self.user_service_patcher.stop)
56
57        # Create a test user
58        self.user = UserFactory.create()
59
60    def test_get_group_for_user(self):
61        # get a group assigned to the user
62        group1_id = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
63
64        # make sure we get the same group back out every time
65        for __ in range(10):
66            group2_id = RandomUserPartitionScheme.get_group_for_user(
67                self.MOCK_COURSE_ID,
68                self.user,
69                self.user_partition
70            )
71
72    def test_get_group_for_user_with_assign(self):
73        """"""
74        Make sure get_group_for_user returns None if no group is already
75        assigned to a user instead of assigning/creating a group automatically
76        """"""
77        # We should not get any group because assign is False which will
78        # protect us from automatically creating a group for user
79        group = RandomUserPartitionScheme.get_group_for_user(
80            self.MOCK_COURSE_ID, self.user, self.user_partition, assign=False
81        )
82
83
84        # We should get a group automatically assigned to user
85        group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
86
87
88    def test_empty_partition(self):
89        empty_partition = UserPartition(
90            self.TEST_ID,
91            'Test Partition',
92            'for testing purposes',
93            [],
94            scheme=RandomUserPartitionScheme
95        )
96        # get a group assigned to the user
97            RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, empty_partition)
98
99    def test_user_in_deleted_group(self):
100        # get a group assigned to the user - should be group 0 or 1
101        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
102
103        # Change the group definitions! No more group 0 or 1
104        groups = [Group(3, 'Group 3'), Group(4, 'Group 4')]
105        user_partition = UserPartition(self.TEST_ID, 'Test Partition', 'for testing purposes', groups)
106
107        # Now, get a new group using the same call - should be 3 or 4
108        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
109
110        # We should get the same group over multiple calls
111        new_group_2 = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
112
113    def test_change_group_name(self):
114        # Changing the name of the group shouldn't affect anything
115        # get a group assigned to the user - should be group 0 or 1
116        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
117
118        # Change the group names
119        groups = [Group(0, 'Group 0'), Group(1, 'Group 1')]
120        user_partition = UserPartition(
121            self.TEST_ID,
122            'Test Partition',
123            'for testing purposes',
124            groups,
125            scheme=RandomUserPartitionScheme
126        )
127
128        # Now, get a new group using the same call
129        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
130
131
132class TestExtension(TestCase):
133    """"""
134    Ensure that the scheme extension is correctly plugged in (via entry point
135    in setup.py)
136    """"""
137
138    def test_get_scheme(self):
139            UserPartition.get_scheme('other')
140","[['group1_id', '==', 'group2_id'], ['group', '==', 'None'], ['group', '==', 'not None'], ['new_group', '==', 'new_group_2'], ['old_group.id', '==', 'new_group.id'], [""UserPartition.get_scheme('r"", '==', 'True'], [""om')"", '==', 'R'], ['omUserPartitionScheme', '==', 'True']]",11,8,0.7272727272727273,0.0013637913399249,"['self._tags', '__', 'course_id', 'key', 'value', 'self._tags[course_id][key]', 'MOCK_COURSE_ID', 'course_tag_api', 'self.user_service_patcher', 'self.user', 'group1_id', 'group2_id', 'group', 'empty_partition', 'old_group', 'groups', 'user_partition', 'new_group', 'new_group_2']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self._tags', '__', 'course_id', 'key', 'value', 'self._tags[course_id][key]', 'MOCK_COURSE_ID', 'course_tag_api', 'self.user_service_patcher', 'self.user', 'group1_id', 'group2_id', 'group', 'empty_partition', 'old_group', 'groups', 'user_partition', 'new_group', 'new_group_2']
*Code:

1""""""
2Test the user api's partition extensions.
3""""""
4
5
6from collections import defaultdict
7from unittest.mock import patch
8
9import pytest
10from django.test import TestCase
11
12from openedx.core.djangoapps.user_api.partition_schemes import RandomUserPartitionScheme, UserPartitionError
13from common.djangoapps.student.tests.factories import UserFactory
14from xmodule.partitions.partitions import Group, UserPartition  # lint-amnesty, pylint: disable=wrong-import-order
15from xmodule.partitions.tests.test_partitions import PartitionTestCase  # lint-amnesty, pylint: disable=wrong-import-order
16
17
18class MemoryCourseTagAPI:
19    """"""
20    An implementation of a user service that uses an in-memory dictionary for storage
21    """"""
22    def __init__(self):
23        self._tags = defaultdict(dict)
24
25    def get_course_tag(self, __, course_id, key):
26        """"""Sets the value of ``key`` to ``value``""""""
27        return self._tags[course_id].get(key)
28
29    def set_course_tag(self, __, course_id, key, value):
30        """"""Gets the value of ``key``""""""
31        self._tags[course_id][key] = value
32
33    class BulkCourseTags:
34        @classmethod
35        def is_prefetched(self, course_id):  # lint-amnesty, pylint: disable=bad-classmethod-argument, unused-argument
36            return False
37
38
39@pytest.mark.django_db
40class TestRandomUserPartitionScheme(PartitionTestCase):
41    """"""
42    Test getting a user's group out of a partition
43    """"""
44
45    MOCK_COURSE_ID = ""mock-course-id""
46
47    def setUp(self):
48        super().setUp()
49        # Patch in a memory-based user service instead of using the persistent version
50        course_tag_api = MemoryCourseTagAPI()
51        self.user_service_patcher = patch(
52            'openedx.core.djangoapps.user_api.partition_schemes.course_tag_api', course_tag_api
53        )
54        self.user_service_patcher.start()
55        self.addCleanup(self.user_service_patcher.stop)
56
57        # Create a test user
58        self.user = UserFactory.create()
59
60    def test_get_group_for_user(self):
61        # get a group assigned to the user
62        group1_id = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
63
64        # make sure we get the same group back out every time
65        for __ in range(10):
66            group2_id = RandomUserPartitionScheme.get_group_for_user(
67                self.MOCK_COURSE_ID,
68                self.user,
69                self.user_partition
70            )
71
72    def test_get_group_for_user_with_assign(self):
73        """"""
74        Make sure get_group_for_user returns None if no group is already
75        assigned to a user instead of assigning/creating a group automatically
76        """"""
77        # We should not get any group because assign is False which will
78        # protect us from automatically creating a group for user
79        group = RandomUserPartitionScheme.get_group_for_user(
80            self.MOCK_COURSE_ID, self.user, self.user_partition, assign=False
81        )
82
83
84        # We should get a group automatically assigned to user
85        group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
86
87
88    def test_empty_partition(self):
89        empty_partition = UserPartition(
90            self.TEST_ID,
91            'Test Partition',
92            'for testing purposes',
93            [],
94            scheme=RandomUserPartitionScheme
95        )
96        # get a group assigned to the user
97            RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, empty_partition)
98
99    def test_user_in_deleted_group(self):
100        # get a group assigned to the user - should be group 0 or 1
101        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
102
103        # Change the group definitions! No more group 0 or 1
104        groups = [Group(3, 'Group 3'), Group(4, 'Group 4')]
105        user_partition = UserPartition(self.TEST_ID, 'Test Partition', 'for testing purposes', groups)
106
107        # Now, get a new group using the same call - should be 3 or 4
108        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
109
110        # We should get the same group over multiple calls
111        new_group_2 = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
112
113    def test_change_group_name(self):
114        # Changing the name of the group shouldn't affect anything
115        # get a group assigned to the user - should be group 0 or 1
116        old_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, self.user_partition)
117
118        # Change the group names
119        groups = [Group(0, 'Group 0'), Group(1, 'Group 1')]
120        user_partition = UserPartition(
121            self.TEST_ID,
122            'Test Partition',
123            'for testing purposes',
124            groups,
125            scheme=RandomUserPartitionScheme
126        )
127
128        # Now, get a new group using the same call
129        new_group = RandomUserPartitionScheme.get_group_for_user(self.MOCK_COURSE_ID, self.user, user_partition)
130
131
132class TestExtension(TestCase):
133    """"""
134    Ensure that the scheme extension is correctly plugged in (via entry point
135    in setup.py)
136    """"""
137
138    def test_get_scheme(self):
139            UserPartition.get_scheme('other')
140",7272,"[[22, 'self._tags', '==', {}, 'MemoryCourseTagAPI is initialized with an empty dictionary'], 
[75, 'group', '==', None, 'Check whether group is None when assign is set as False in get_group_for_user'],
[102, 'old_group', '!=', None, 'Assigned group should not be None'],
[108, 'new_group', '>=', 3, 'New group should be either 3 or 4 as groups 0 and 1 are removed'],
[111, 'new_group_2', '==', 'new_group', 'Multiple calls should result in the same group'],
[116, 'old_group', '!=', None, 'Assigned group should not be None'],
[129, 'new_group', '==', 'old_group', 'Group should not change if only name has changed']]"
fitnr/convertdate,"# -*- coding: utf-8 -*-
'''
    Convert between Gregorian/Julian Day and Comte's Positivist calendar.
    The Positivist calendar has 13 months and one or two festival days.
    Festival days are given as the fourteenth month.
    The Gregorian date 1789-01-01 is Positivist 0001-01-01.
'''
# This file is part of convertdate.
# http://github.com/fitnr/convertdate
# Licensed under the MIT license:
# http://opensource.org/licenses/MIT
# Copyright (c) 2016, fitnr <fitnr@fakeisthenewreal>
from calendar import isleap
from math import floor

from . import gregorian
from .data import positivist as data

# Positivist calendar has 13 28-day months and one festival day

EPOCH = 2374479.5

YEAR_EPOCH = 1789

DAYS_IN_YEAR = 365

MONTHS = (
    'Moses',
    'Homer',
    'Aristotle',
    'Archimedes',
    'Caesar',
    'Saint Paul',
    'Charlemagne',
    'Dante',
    'Gutenberg',
    'Shakespeare',
    'Descartes',
    'Frederic',
    'Bichat',
    '',
)


def legal_date(year, month, day):
    '''Checks if a given date is a legal positivist date'''
    try:
        assert year >= 1
        assert 0 < month <= 14
        assert 0 < day <= 28
        if month == 14:
            if isleap(year + YEAR_EPOCH - 1):
                assert day <= 2
            else:
                assert day == 1

    except AssertionError as err:
        raise ValueError(""Invalid Positivist date: ({}, {}, {})"".format(year, month, day)) from err

    return True


def to_jd(year, month, day):
    '''Convert a Positivist date to Julian day count.'''
    legal_date(year, month, day)
    gyear = year + YEAR_EPOCH - 1

    return (
        gregorian.EPOCH
        - 1
        + (365 * (gyear - 1))
        + floor((gyear - 1) / 4)
        + (-floor((gyear - 1) / 100))
        + floor((gyear - 1) / 400)
        + (month - 1) * 28
        + day
    )


def from_jd(jd):
    '''Convert a Julian day count to Positivist date.'''
    try:
        assert jd >= EPOCH
    except AssertionError as err:
        raise ValueError('Invalid Julian day') from err

    depoch = floor(jd - 0.5) + 0.5 - gregorian.EPOCH

    quadricent = floor(depoch / gregorian.INTERCALATION_CYCLE_DAYS)
    dqc = depoch % gregorian.INTERCALATION_CYCLE_DAYS

    cent = floor(dqc / gregorian.LEAP_SUPPRESSION_DAYS)
    dcent = dqc % gregorian.LEAP_SUPPRESSION_DAYS

    quad = floor(dcent / gregorian.LEAP_CYCLE_DAYS)
    dquad = dcent % gregorian.LEAP_CYCLE_DAYS

    yindex = floor(dquad / gregorian.YEAR_DAYS)
    year = (
        quadricent * gregorian.INTERCALATION_CYCLE_YEARS
        + cent * gregorian.LEAP_SUPPRESSION_YEARS
        + quad * gregorian.LEAP_CYCLE_YEARS
        + yindex
    )

    if yindex == 4:
        yearday = 365
        year = year - 1

    else:
        yearday = (
            depoch
            - quadricent * gregorian.INTERCALATION_CYCLE_DAYS
            - cent * gregorian.LEAP_SUPPRESSION_DAYS
            - quad * gregorian.LEAP_CYCLE_DAYS
            - yindex * gregorian.YEAR_DAYS
        )

    month = floor(yearday / 28)

    return (year - YEAR_EPOCH + 2, month + 1, int(yearday - (month * 28)) + 1)


def from_gregorian(year, month, day):
    return from_jd(gregorian.to_jd(year, month, day))


def to_gregorian(year, month, day):
    return gregorian.from_jd(to_jd(year, month, day))


def dayname(year, month, day):
    """"""
    Give the name of the month and day for a given date.

    Returns:
        tuple month_name, day_name
    """"""
    legal_date(year, month, day)

    yearday = (month - 1) * 28 + day

    if isleap(year + YEAR_EPOCH - 1):
        dname = data.DAY_NAMES_LEAP[yearday - 1]
    else:
        dname = data.DAY_NAMES[yearday - 1]

    return MONTHS[month - 1], dname


def weekday(day):
    """"""
    Gives the weekday (0=Monday) of a positivist month and day.
    Note that the festival month does not have a day.
    """"""
    return (day % 7) - 1


def festival(month, day):
    """"""
    Gives the festival day for a month and day.
    Returns None if inapplicable.
    """"""
    return data.FESTIVALS.get((month, day))
","
1# -*- coding: utf-8 -*-
2'''
3    Convert between Gregorian/Julian Day and Comte's Positivist calendar.
4    The Positivist calendar has 13 months and one or two festival days.
5    Festival days are given as the fourteenth month.
6    The Gregorian date 1789-01-01 is Positivist 0001-01-01.
7'''
8# This file is part of convertdate.
9# http://github.com/fitnr/convertdate
10# Licensed under the MIT license:
11# http://opensource.org/licenses/MIT
12# Copyright (c) 2016, fitnr <fitnr@fakeisthenewreal>
13from calendar import isleap
14from math import floor
15
16from . import gregorian
17from .data import positivist as data
18
19# Positivist calendar has 13 28-day months and one festival day
20
21EPOCH = 2374479.5
22
23YEAR_EPOCH = 1789
24
25DAYS_IN_YEAR = 365
26
27MONTHS = (
28    'Moses',
29    'Homer',
30    'Aristotle',
31    'Archimedes',
32    'Caesar',
33    'Saint Paul',
34    'Charlemagne',
35    'Dante',
36    'Gutenberg',
37    'Shakespeare',
38    'Descartes',
39    'Frederic',
40    'Bichat',
41    '',
42)
43
44
45def legal_date(year, month, day):
46    '''Checks if a given date is a legal positivist date'''
47    try:
48        if month == 14:
49            if isleap(year + YEAR_EPOCH - 1):
50            else:
51
52    except AssertionError as err:
53        raise ValueError(""Invalid Positivist date: ({}, {}, {})"".format(year, month, day)) from err
54
55    return True
56
57
58def to_jd(year, month, day):
59    '''Convert a Positivist date to Julian day count.'''
60    legal_date(year, month, day)
61    gyear = year + YEAR_EPOCH - 1
62
63    return (
64        gregorian.EPOCH
65        - 1
66        + (365 * (gyear - 1))
67        + floor((gyear - 1) / 4)
68        + (-floor((gyear - 1) / 100))
69        + floor((gyear - 1) / 400)
70        + (month - 1) * 28
71        + day
72    )
73
74
75def from_jd(jd):
76    '''Convert a Julian day count to Positivist date.'''
77    try:
78    except AssertionError as err:
79        raise ValueError('Invalid Julian day') from err
80
81    depoch = floor(jd - 0.5) + 0.5 - gregorian.EPOCH
82
83    quadricent = floor(depoch / gregorian.INTERCALATION_CYCLE_DAYS)
84    dqc = depoch % gregorian.INTERCALATION_CYCLE_DAYS
85
86    cent = floor(dqc / gregorian.LEAP_SUPPRESSION_DAYS)
87    dcent = dqc % gregorian.LEAP_SUPPRESSION_DAYS
88
89    quad = floor(dcent / gregorian.LEAP_CYCLE_DAYS)
90    dquad = dcent % gregorian.LEAP_CYCLE_DAYS
91
92    yindex = floor(dquad / gregorian.YEAR_DAYS)
93    year = (
94        quadricent * gregorian.INTERCALATION_CYCLE_YEARS
95        + cent * gregorian.LEAP_SUPPRESSION_YEARS
96        + quad * gregorian.LEAP_CYCLE_YEARS
97        + yindex
98    )
99
100    if yindex == 4:
101        yearday = 365
102        year = year - 1
103
104    else:
105        yearday = (
106            depoch
107            - quadricent * gregorian.INTERCALATION_CYCLE_DAYS
108            - cent * gregorian.LEAP_SUPPRESSION_DAYS
109            - quad * gregorian.LEAP_CYCLE_DAYS
110            - yindex * gregorian.YEAR_DAYS
111        )
112
113    month = floor(yearday / 28)
114
115    return (year - YEAR_EPOCH + 2, month + 1, int(yearday - (month * 28)) + 1)
116
117
118def from_gregorian(year, month, day):
119    return from_jd(gregorian.to_jd(year, month, day))
120
121
122def to_gregorian(year, month, day):
123    return gregorian.from_jd(to_jd(year, month, day))
124
125
126def dayname(year, month, day):
127    """"""
128    Give the name of the month and day for a given date.
129
130    Returns:
131        tuple month_name, day_name
132    """"""
133    legal_date(year, month, day)
134
135    yearday = (month - 1) * 28 + day
136
137    if isleap(year + YEAR_EPOCH - 1):
138        dname = data.DAY_NAMES_LEAP[yearday - 1]
139    else:
140        dname = data.DAY_NAMES[yearday - 1]
141
142    return MONTHS[month - 1], dname
143
144
145def weekday(day):
146    """"""
147    Gives the weekday (0=Monday) of a positivist month and day.
148    Note that the festival month does not have a day.
149    """"""
150    return (day % 7) - 1
151
152
153def festival(month, day):
154    """"""
155    Gives the festival day for a month and day.
156    Returns None if inapplicable.
157    """"""
158    return data.FESTIVALS.get((month, day))
159","[['year', '>=', '1'], ['0', '<', 'month <= 14'], ['0', '<', 'day <= 28'], ['day', '<=', '2'], ['day', '==', '1'], ['jd', '>=', 'EPOCH']]",6,6,1.0,0.0014840465001236,"['EPOCH', 'YEAR_EPOCH', 'DAYS_IN_YEAR', 'MONTHS', 'year', 'month', 'day', 'gyear', 'jd', 'depoch', 'quadricent', 'dqc', 'cent', 'dcent', 'quad', 'dquad', 'yindex', 'yearday', 'dname']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['EPOCH', 'YEAR_EPOCH', 'DAYS_IN_YEAR', 'MONTHS', 'year', 'month', 'day', 'gyear', 'jd', 'depoch', 'quadricent', 'dqc', 'cent', 'dcent', 'quad', 'dquad', 'yindex', 'yearday', 'dname']
*Code:

1# -*- coding: utf-8 -*-
2'''
3    Convert between Gregorian/Julian Day and Comte's Positivist calendar.
4    The Positivist calendar has 13 months and one or two festival days.
5    Festival days are given as the fourteenth month.
6    The Gregorian date 1789-01-01 is Positivist 0001-01-01.
7'''
8# This file is part of convertdate.
9# http://github.com/fitnr/convertdate
10# Licensed under the MIT license:
11# http://opensource.org/licenses/MIT
12# Copyright (c) 2016, fitnr <fitnr@fakeisthenewreal>
13from calendar import isleap
14from math import floor
15
16from . import gregorian
17from .data import positivist as data
18
19# Positivist calendar has 13 28-day months and one festival day
20
21EPOCH = 2374479.5
22
23YEAR_EPOCH = 1789
24
25DAYS_IN_YEAR = 365
26
27MONTHS = (
28    'Moses',
29    'Homer',
30    'Aristotle',
31    'Archimedes',
32    'Caesar',
33    'Saint Paul',
34    'Charlemagne',
35    'Dante',
36    'Gutenberg',
37    'Shakespeare',
38    'Descartes',
39    'Frederic',
40    'Bichat',
41    '',
42)
43
44
45def legal_date(year, month, day):
46    '''Checks if a given date is a legal positivist date'''
47    try:
48        if month == 14:
49            if isleap(year + YEAR_EPOCH - 1):
50            else:
51
52    except AssertionError as err:
53        raise ValueError(""Invalid Positivist date: ({}, {}, {})"".format(year, month, day)) from err
54
55    return True
56
57
58def to_jd(year, month, day):
59    '''Convert a Positivist date to Julian day count.'''
60    legal_date(year, month, day)
61    gyear = year + YEAR_EPOCH - 1
62
63    return (
64        gregorian.EPOCH
65        - 1
66        + (365 * (gyear - 1))
67        + floor((gyear - 1) / 4)
68        + (-floor((gyear - 1) / 100))
69        + floor((gyear - 1) / 400)
70        + (month - 1) * 28
71        + day
72    )
73
74
75def from_jd(jd):
76    '''Convert a Julian day count to Positivist date.'''
77    try:
78    except AssertionError as err:
79        raise ValueError('Invalid Julian day') from err
80
81    depoch = floor(jd - 0.5) + 0.5 - gregorian.EPOCH
82
83    quadricent = floor(depoch / gregorian.INTERCALATION_CYCLE_DAYS)
84    dqc = depoch % gregorian.INTERCALATION_CYCLE_DAYS
85
86    cent = floor(dqc / gregorian.LEAP_SUPPRESSION_DAYS)
87    dcent = dqc % gregorian.LEAP_SUPPRESSION_DAYS
88
89    quad = floor(dcent / gregorian.LEAP_CYCLE_DAYS)
90    dquad = dcent % gregorian.LEAP_CYCLE_DAYS
91
92    yindex = floor(dquad / gregorian.YEAR_DAYS)
93    year = (
94        quadricent * gregorian.INTERCALATION_CYCLE_YEARS
95        + cent * gregorian.LEAP_SUPPRESSION_YEARS
96        + quad * gregorian.LEAP_CYCLE_YEARS
97        + yindex
98    )
99
100    if yindex == 4:
101        yearday = 365
102        year = year - 1
103
104    else:
105        yearday = (
106            depoch
107            - quadricent * gregorian.INTERCALATION_CYCLE_DAYS
108            - cent * gregorian.LEAP_SUPPRESSION_DAYS
109            - quad * gregorian.LEAP_CYCLE_DAYS
110            - yindex * gregorian.YEAR_DAYS
111        )
112
113    month = floor(yearday / 28)
114
115    return (year - YEAR_EPOCH + 2, month + 1, int(yearday - (month * 28)) + 1)
116
117
118def from_gregorian(year, month, day):
119    return from_jd(gregorian.to_jd(year, month, day))
120
121
122def to_gregorian(year, month, day):
123    return gregorian.from_jd(to_jd(year, month, day))
124
125
126def dayname(year, month, day):
127    """"""
128    Give the name of the month and day for a given date.
129
130    Returns:
131        tuple month_name, day_name
132    """"""
133    legal_date(year, month, day)
134
135    yearday = (month - 1) * 28 + day
136
137    if isleap(year + YEAR_EPOCH - 1):
138        dname = data.DAY_NAMES_LEAP[yearday - 1]
139    else:
140        dname = data.DAY_NAMES[yearday - 1]
141
142    return MONTHS[month - 1], dname
143
144
145def weekday(day):
146    """"""
147    Gives the weekday (0=Monday) of a positivist month and day.
148    Note that the festival month does not have a day.
149    """"""
150    return (day % 7) - 1
151
152
153def festival(month, day):
154    """"""
155    Gives the festival day for a month and day.
156    Returns None if inapplicable.
157    """"""
158    return data.FESTIVALS.get((month, day))
159",5800,"[[45, 'year', '>=', 1, ""Year should be at least 1 as the year cannot be negative or zero""],
[45, 'month', '>=', 1, ""Month number should be at least 1""],
[45, 'month', '<=', 14, ""Month number should not exceed 14 as there are only 14 months in a positivist calendar""],
[45, 'day', '>=', 1, ""Day number should be at least 1""],
[45, 'day', '<=', 28, ""Day number should not exceed 28 as there are only 28 days in a month""],
[58, 'year', '>=', 1, ""Year should be at least 1 as the year cannot be negative or zero""],
[58, 'month', '>=', 1, ""Month number should be at least 1""],
[58, 'month', '<=', 14, ""Month number should not exceed 14 as there are only 14 months in a positivist calendar""],
[58, 'day', '>=', 1, ""Day number should be at least 1""],
[58, 'day', '<=', 28, ""Day number should not exceed 28 as there are only 28 days in a month""],
[75, 'jd', '>=', 1, ""Julian day should be at least 1""],
[118, 'year', '>=', 1789, ""Year should be at least 1789 (Gregorian Calendar)""],
[118, 'month', '>=', 1, ""Month number should be at least 1""],
[118, 'month', '<=', 12, ""Month number should not exceed 12 as there are only 12 months in a Gregorian calendar""],
[118, 'day', '>=', 1, ""Day number should be at least 1""],
[122, 'year', '>=', 1, ""Year should be at least 1 as the year cannot be negative or zero""],
[122, 'month', '>=', 1, ""Month number should be at least 1""],
[122, 'month', '<=', 14, ""Month number should not exceed 14 as there are only 14 months in a positivist calendar""],
[122, 'day', '>=', 1, ""Day number should be at least 1""],
[122, 'day', '<=', 28, ""Day number should not exceed 28 as there are only 28 days in a month""],
[126, 'year', '>=', 1, ""Year should be at least 1 as the year cannot be negative or zero""],
[126, 'month', '>=', 1, ""Month number should be at least 1""],
[126, 'month', '<=', 14, ""Month number should not exceed 14 as there are only 14 months in a positivist calendar""],
[126, 'day', '>=', 1, ""Day number should be at least 1""],
[126, 'day', '<=', 28, ""Day number should not exceed 28 as there are only 28 days in a month""],
[145, 'day', '>=', 1, ""Day number should be at least 1""],
[145, 'day', '<=', 28, ""Day number should not exceed 7 as there are only 7 weekdays""],
[153, 'month', '>=', 1, ""Month number should be at least 1""],
[153, 'month', '<=', 14, ""Month number should not exceed 14 as there are only 14 months in a positivist calendar""],
[153, 'day', '>=', 1, ""Day number should be at least 1""],
[153, 'day', '<=', 28, ""Day number should not exceed 28 as there are only 28 days in a month""]]"
concurrence/concurrence,"# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence.timer import Timeout
from concurrence.database.mysql import ProxyProtocol, PacketReader, PACKET_READ_RESULT, CLIENT_STATES, SERVER_STATES

class Proxy(object):

    #errors
    EOF_READ = -1
    EOF_WRITE = -2
    
    #direction
    CLIENT_TO_SERVER = 1
    SERVER_TO_CLIENT = 2
    
    def __init__(self, clientStream, serverStream, buffer, initState):
        self.clientStream = clientStream
        self.serverStream = serverStream
        self.readStream = self.clientStream
        self.writeStream = self.serverStream
        self.direction = self.CLIENT_TO_SERVER        
        self.protocol = ProxyProtocol(initState)
        self.reader = PacketReader()
        self.buffer = buffer
        self.remaining = 0
        
    def close(self):
        self.clientStream = None
        self.serverStream = None
        self.readStream = None
        self.writeStream = None
        self.protocol = None
        self.reader = None
        self.buffer = None
        
    def reset(self, state):
        self.protocol.reset(state)
        
    def readFromStream(self):
        #read some data from stream into buffer
        if self.remaining:
            #some leftover partially read packet from previous read, put it in front of buffer
            self.buffer.limit = self.buffer.position + self.remaining
            self.buffer.compact()
        else:
            #normal clear, position = 0, limit = capacity
            self.buffer.clear()
        #read data from socket
        return self.readStream.read(self.buffer, Timeout.current())
    
    def writeToStream(self):
        #forward data to receiving socket
        self.buffer.flip()
        while self.buffer.remaining:
            if not self.writeStream.write(self.buffer, Timeout.current()):
                return False
        return True                   
        
    def next(self, readResult, newState, prevState):
        return 0
    
    def cycle(self, readProtocol):
        
        if not self.readFromStream():
            return self.EOF_READ

        #inspect data read according to protocol
        n = 0
        self.buffer.flip()
        while True:                
            readResult, newState, prevState = readProtocol(self.reader, self.buffer)
            #make note of any remaining data (half read packets),
            # we use buffer.compact to put remainder in front next time around
            self.remaining = self.buffer.remaining
            #take action depending on state transition
            n = self.next(readResult, newState, prevState)
            if n != 0:
                break
            if not (readResult & PACKET_READ_RESULT.MORE):
                break

        if n == 0:
            #write data trough to write stream
            if not self.writeToStream():
                return self.EOF_WRITE
        
        return n
    
    def run(self):
        while True:
            state = self.protocol.state
            if state in SERVER_STATES:
                self.direction = self.SERVER_TO_CLIENT
                self.readStream = self.serverStream
                self.writeStream = self.clientStream
                n = self.cycle(self.protocol.readServer)
            elif state in CLIENT_STATES:
                self.direction = self.CLIENT_TO_SERVER
                self.readStream = self.clientStream
                self.writeStream = self.serverStream
                n = self.cycle(self.protocol.readClient)
            else:
                assert False, ""Unknown state %s"" % state
            if n < 0:
                return n 
","
1# Copyright (C) 2009, Hyves (Startphone Ltd.)
2#
3# This module is part of the Concurrence Framework and is released under
4# the New BSD License: http://www.opensource.org/licenses/bsd-license.php
5
6from concurrence.timer import Timeout
7from concurrence.database.mysql import ProxyProtocol, PacketReader, PACKET_READ_RESULT, CLIENT_STATES, SERVER_STATES
8
9class Proxy(object):
10
11    #errors
12    EOF_READ = -1
13    EOF_WRITE = -2
14    
15    #direction
16    CLIENT_TO_SERVER = 1
17    SERVER_TO_CLIENT = 2
18    
19    def __init__(self, clientStream, serverStream, buffer, initState):
20        self.clientStream = clientStream
21        self.serverStream = serverStream
22        self.readStream = self.clientStream
23        self.writeStream = self.serverStream
24        self.direction = self.CLIENT_TO_SERVER        
25        self.protocol = ProxyProtocol(initState)
26        self.reader = PacketReader()
27        self.buffer = buffer
28        self.remaining = 0
29        
30    def close(self):
31        self.clientStream = None
32        self.serverStream = None
33        self.readStream = None
34        self.writeStream = None
35        self.protocol = None
36        self.reader = None
37        self.buffer = None
38        
39    def reset(self, state):
40        self.protocol.reset(state)
41        
42    def readFromStream(self):
43        #read some data from stream into buffer
44        if self.remaining:
45            #some leftover partially read packet from previous read, put it in front of buffer
46            self.buffer.limit = self.buffer.position + self.remaining
47            self.buffer.compact()
48        else:
49            #normal clear, position = 0, limit = capacity
50            self.buffer.clear()
51        #read data from socket
52        return self.readStream.read(self.buffer, Timeout.current())
53    
54    def writeToStream(self):
55        #forward data to receiving socket
56        self.buffer.flip()
57        while self.buffer.remaining:
58            if not self.writeStream.write(self.buffer, Timeout.current()):
59                return False
60        return True                   
61        
62    def next(self, readResult, newState, prevState):
63        return 0
64    
65    def cycle(self, readProtocol):
66        
67        if not self.readFromStream():
68            return self.EOF_READ
69
70        #inspect data read according to protocol
71        n = 0
72        self.buffer.flip()
73        while True:                
74            readResult, newState, prevState = readProtocol(self.reader, self.buffer)
75            #make note of any remaining data (half read packets),
76            # we use buffer.compact to put remainder in front next time around
77            self.remaining = self.buffer.remaining
78            #take action depending on state transition
79            n = self.next(readResult, newState, prevState)
80            if n != 0:
81                break
82            if not (readResult & PACKET_READ_RESULT.MORE):
83                break
84
85        if n == 0:
86            #write data trough to write stream
87            if not self.writeToStream():
88                return self.EOF_WRITE
89        
90        return n
91    
92    def run(self):
93        while True:
94            state = self.protocol.state
95            if state in SERVER_STATES:
96                self.direction = self.SERVER_TO_CLIENT
97                self.readStream = self.serverStream
98                self.writeStream = self.clientStream
99                n = self.cycle(self.protocol.readServer)
100            elif state in CLIENT_STATES:
101                self.direction = self.CLIENT_TO_SERVER
102                self.readStream = self.clientStream
103                self.writeStream = self.serverStream
104                n = self.cycle(self.protocol.readClient)
105            else:
106            if n < 0:
107                return n 
108","[['False', '==', 'True']]",1,1,1.0,0.000263852242744,"['EOF_READ', 'EOF_WRITE', 'CLIENT_TO_SERVER', 'SERVER_TO_CLIENT', 'clientStream', 'serverStream', 'buffer', 'initState', 'self.clientStream', 'self.serverStream', 'self.readStream', 'self.writeStream', 'self.direction', 'self.protocol', 'self.reader', 'self.buffer', 'self.remaining', 'state', 'self.buffer.limit', '#normal clear', 'position', 'readResult', 'newState', 'prevState', 'readProtocol', 'n']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['EOF_READ', 'EOF_WRITE', 'CLIENT_TO_SERVER', 'SERVER_TO_CLIENT', 'clientStream', 'serverStream', 'buffer', 'initState', 'self.clientStream', 'self.serverStream', 'self.readStream', 'self.writeStream', 'self.direction', 'self.protocol', 'self.reader', 'self.buffer', 'self.remaining', 'state', 'self.buffer.limit', '#normal clear', 'position', 'readResult', 'newState', 'prevState', 'readProtocol', 'n']
*Code:

1# Copyright (C) 2009, Hyves (Startphone Ltd.)
2#
3# This module is part of the Concurrence Framework and is released under
4# the New BSD License: http://www.opensource.org/licenses/bsd-license.php
5
6from concurrence.timer import Timeout
7from concurrence.database.mysql import ProxyProtocol, PacketReader, PACKET_READ_RESULT, CLIENT_STATES, SERVER_STATES
8
9class Proxy(object):
10
11    #errors
12    EOF_READ = -1
13    EOF_WRITE = -2
14    
15    #direction
16    CLIENT_TO_SERVER = 1
17    SERVER_TO_CLIENT = 2
18    
19    def __init__(self, clientStream, serverStream, buffer, initState):
20        self.clientStream = clientStream
21        self.serverStream = serverStream
22        self.readStream = self.clientStream
23        self.writeStream = self.serverStream
24        self.direction = self.CLIENT_TO_SERVER        
25        self.protocol = ProxyProtocol(initState)
26        self.reader = PacketReader()
27        self.buffer = buffer
28        self.remaining = 0
29        
30    def close(self):
31        self.clientStream = None
32        self.serverStream = None
33        self.readStream = None
34        self.writeStream = None
35        self.protocol = None
36        self.reader = None
37        self.buffer = None
38        
39    def reset(self, state):
40        self.protocol.reset(state)
41        
42    def readFromStream(self):
43        #read some data from stream into buffer
44        if self.remaining:
45            #some leftover partially read packet from previous read, put it in front of buffer
46            self.buffer.limit = self.buffer.position + self.remaining
47            self.buffer.compact()
48        else:
49            #normal clear, position = 0, limit = capacity
50            self.buffer.clear()
51        #read data from socket
52        return self.readStream.read(self.buffer, Timeout.current())
53    
54    def writeToStream(self):
55        #forward data to receiving socket
56        self.buffer.flip()
57        while self.buffer.remaining:
58            if not self.writeStream.write(self.buffer, Timeout.current()):
59                return False
60        return True                   
61        
62    def next(self, readResult, newState, prevState):
63        return 0
64    
65    def cycle(self, readProtocol):
66        
67        if not self.readFromStream():
68            return self.EOF_READ
69
70        #inspect data read according to protocol
71        n = 0
72        self.buffer.flip()
73        while True:                
74            readResult, newState, prevState = readProtocol(self.reader, self.buffer)
75            #make note of any remaining data (half read packets),
76            # we use buffer.compact to put remainder in front next time around
77            self.remaining = self.buffer.remaining
78            #take action depending on state transition
79            n = self.next(readResult, newState, prevState)
80            if n != 0:
81                break
82            if not (readResult & PACKET_READ_RESULT.MORE):
83                break
84
85        if n == 0:
86            #write data trough to write stream
87            if not self.writeToStream():
88                return self.EOF_WRITE
89        
90        return n
91    
92    def run(self):
93        while True:
94            state = self.protocol.state
95            if state in SERVER_STATES:
96                self.direction = self.SERVER_TO_CLIENT
97                self.readStream = self.serverStream
98                self.writeStream = self.clientStream
99                n = self.cycle(self.protocol.readServer)
100            elif state in CLIENT_STATES:
101                self.direction = self.CLIENT_TO_SERVER
102                self.readStream = self.clientStream
103                self.writeStream = self.serverStream
104                n = self.cycle(self.protocol.readClient)
105            else:
106            if n < 0:
107                return n 
108",5733,"[[19, 'clientStream', '!=', 'None', 'Proxy object requires clientStream for initialization'],
[19, 'serverStream', '!=', 'None', 'Proxy object requires serverStream for initialization'],
[19, 'buffer', '!=', 'None', 'Proxy object requires buffer for initialization'],
[30, 'self.clientStream', '!=', 'None', 'Before closing, check if clientStream is not already None'],
[30, 'self.serverStream', '!=', 'None', 'Before closing, check if serverStream is not already None'],
[65, 'self.readFromStream', '!=', 'None', 'Before calling readFromStream function, make sure it is not None'],
[87, 'self.writeToStream', '!=', 'None', 'Check if writeToStream function is not None before calling'],
[94, 'state', '!=', 'None', 'state should not be None to determine the direction'],
[99, 'n', '>=', 0, 'n must be equal or higher than 0 after cycle'],
[104, 'n', '>=', 0, 'n must be equal or higher than 0 after cycle']]"
Metaswitch/horizon,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import re

from six.moves import html_parser as _HTMLParser


def parse_starttag_patched(self, i):
    """"""This method is a patched version of the parse_starttag method from
    django.utils.html_parser.HTMLParser class, used to patch bug 1273943.
    The code is taken from file django/utils/html_parser.py, commit 6bc1b22299.
    """"""
    self.__starttag_text = None
    endpos = self.check_for_whole_start_tag(i)
    if endpos < 0:
        return endpos
    rawdata = self.rawdata
    self.__starttag_text = rawdata[i:endpos]

    # Now parse the data between i+1 and j into a tag and attrs
    attrs = []
    tagfind = re.compile('([a-zA-Z][-.a-zA-Z0-9:_]*)(?:\s|/(?!>))*')
    match = tagfind.match(rawdata, i + 1)
    assert match, 'unexpected call to parse_starttag()'
    k = match.end()
    self.lasttag = tag = match.group(1).lower()

    while k < endpos:
        m = _HTMLParser.attrfind.match(rawdata, k)
        if not m:
            break
        attrname, rest, attrvalue = m.group(1, 2, 3)
        if not rest:
            attrvalue = None
        elif (attrvalue[:1] == '\'' == attrvalue[-1:] or
              attrvalue[:1] == '""' == attrvalue[-1:]):
            attrvalue = attrvalue[1:-1]
        if attrvalue:
            attrvalue = self.unescape(attrvalue)
        attrs.append((attrname.lower(), attrvalue))
        k = m.end()

    end = rawdata[k:endpos].strip()
    if end not in ("">"", ""/>""):
        lineno, offset = self.getpos()
        if ""\n"" in self.__starttag_text:
            lineno = lineno + self.__starttag_text.count(""\n"")
            offset = (len(self.__starttag_text)
                      - self.__starttag_text.rfind(""\n""))
        else:
            offset = offset + len(self.__starttag_text)
        self.error(""junk characters in start tag: %r""
                   % (rawdata[k:endpos][:20],))
    if end.endswith('/>'):
        # XHTML-style empty tag: <span attr=""value"" />
        self.handle_startendtag(tag, attrs)
    else:
        self.handle_starttag(tag, attrs)
        if tag in self.CDATA_CONTENT_ELEMENTS:
            self.set_cdata_mode(tag)    # <--------------------------- Changed
    return endpos
","
1# Licensed under the Apache License, Version 2.0 (the ""License""); you may
2# not use this file except in compliance with the License. You may obtain
3# a copy of the License at
4#
5#      http://www.apache.org/licenses/LICENSE-2.0
6#
7# Unless required by applicable law or agreed to in writing, software
8# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
9# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
10# License for the specific language governing permissions and limitations
11# under the License.
12
13import re
14
15from six.moves import html_parser as _HTMLParser
16
17
18def parse_starttag_patched(self, i):
19    """"""This method is a patched version of the parse_starttag method from
20    django.utils.html_parser.HTMLParser class, used to patch bug 1273943.
21    The code is taken from file django/utils/html_parser.py, commit 6bc1b22299.
22    """"""
23    self.__starttag_text = None
24    endpos = self.check_for_whole_start_tag(i)
25    if endpos < 0:
26        return endpos
27    rawdata = self.rawdata
28    self.__starttag_text = rawdata[i:endpos]
29
30    # Now parse the data between i+1 and j into a tag and attrs
31    attrs = []
32    tagfind = re.compile('([a-zA-Z][-.a-zA-Z0-9:_]*)(?:\s|/(?!>))*')
33    match = tagfind.match(rawdata, i + 1)
34    k = match.end()
35    self.lasttag = tag = match.group(1).lower()
36
37    while k < endpos:
38        m = _HTMLParser.attrfind.match(rawdata, k)
39        if not m:
40            break
41        attrname, rest, attrvalue = m.group(1, 2, 3)
42        if not rest:
43            attrvalue = None
44        elif (attrvalue[:1] == '\'' == attrvalue[-1:] or
45              attrvalue[:1] == '""' == attrvalue[-1:]):
46            attrvalue = attrvalue[1:-1]
47        if attrvalue:
48            attrvalue = self.unescape(attrvalue)
49        attrs.append((attrname.lower(), attrvalue))
50        k = m.end()
51
52    end = rawdata[k:endpos].strip()
53    if end not in ("">"", ""/>""):
54        lineno, offset = self.getpos()
55        if ""\n"" in self.__starttag_text:
56            lineno = lineno + self.__starttag_text.count(""\n"")
57            offset = (len(self.__starttag_text)
58                      - self.__starttag_text.rfind(""\n""))
59        else:
60            offset = offset + len(self.__starttag_text)
61        self.error(""junk characters in start tag: %r""
62                   % (rawdata[k:endpos][:20],))
63    if end.endswith('/>'):
64        # XHTML-style empty tag: <span attr=""value"" />
65        self.handle_startendtag(tag, attrs)
66    else:
67        self.handle_starttag(tag, attrs)
68        if tag in self.CDATA_CONTENT_ELEMENTS:
69            self.set_cdata_mode(tag)    # <--------------------------- Changed
70    return endpos
71","[['match', '==', 'True']]",1,1,1.0,0.0003695491500369,"['i', 'self.__starttag_text', 'endpos', 'rawdata', 'attrs', 'tagfind', 'match', 'k', 'self.lasttag', 'm', 'attrname', 'rest', 'attrvalue', 'end', 'lineno', 'offset']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['i', 'self.__starttag_text', 'endpos', 'rawdata', 'attrs', 'tagfind', 'match', 'k', 'self.lasttag', 'm', 'attrname', 'rest', 'attrvalue', 'end', 'lineno', 'offset']
*Code:

1# Licensed under the Apache License, Version 2.0 (the ""License""); you may
2# not use this file except in compliance with the License. You may obtain
3# a copy of the License at
4#
5#      http://www.apache.org/licenses/LICENSE-2.0
6#
7# Unless required by applicable law or agreed to in writing, software
8# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
9# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
10# License for the specific language governing permissions and limitations
11# under the License.
12
13import re
14
15from six.moves import html_parser as _HTMLParser
16
17
18def parse_starttag_patched(self, i):
19    """"""This method is a patched version of the parse_starttag method from
20    django.utils.html_parser.HTMLParser class, used to patch bug 1273943.
21    The code is taken from file django/utils/html_parser.py, commit 6bc1b22299.
22    """"""
23    self.__starttag_text = None
24    endpos = self.check_for_whole_start_tag(i)
25    if endpos < 0:
26        return endpos
27    rawdata = self.rawdata
28    self.__starttag_text = rawdata[i:endpos]
29
30    # Now parse the data between i+1 and j into a tag and attrs
31    attrs = []
32    tagfind = re.compile('([a-zA-Z][-.a-zA-Z0-9:_]*)(?:\s|/(?!>))*')
33    match = tagfind.match(rawdata, i + 1)
34    k = match.end()
35    self.lasttag = tag = match.group(1).lower()
36
37    while k < endpos:
38        m = _HTMLParser.attrfind.match(rawdata, k)
39        if not m:
40            break
41        attrname, rest, attrvalue = m.group(1, 2, 3)
42        if not rest:
43            attrvalue = None
44        elif (attrvalue[:1] == '\'' == attrvalue[-1:] or
45              attrvalue[:1] == '""' == attrvalue[-1:]):
46            attrvalue = attrvalue[1:-1]
47        if attrvalue:
48            attrvalue = self.unescape(attrvalue)
49        attrs.append((attrname.lower(), attrvalue))
50        k = m.end()
51
52    end = rawdata[k:endpos].strip()
53    if end not in ("">"", ""/>""):
54        lineno, offset = self.getpos()
55        if ""\n"" in self.__starttag_text:
56            lineno = lineno + self.__starttag_text.count(""\n"")
57            offset = (len(self.__starttag_text)
58                      - self.__starttag_text.rfind(""\n""))
59        else:
60            offset = offset + len(self.__starttag_text)
61        self.error(""junk characters in start tag: %r""
62                   % (rawdata[k:endpos][:20],))
63    if end.endswith('/>'):
64        # XHTML-style empty tag: <span attr=""value"" />
65        self.handle_startendtag(tag, attrs)
66    else:
67        self.handle_starttag(tag, attrs)
68        if tag in self.CDATA_CONTENT_ELEMENTS:
69            self.set_cdata_mode(tag)    # <--------------------------- Changed
70    return endpos
71",4329,"[[18, 'i', '>=', 0, 'i must be a non-negative index'],
 [24, 'endpos', '>=', -1, 'endpos must be a valid position in the string or -1'],
 [27, 'rawdata', '!=', '', 'rawdata must not be an empty string'],
 [33, 'match', '!=', None, 'match cannot be None after regex match operation'],
 [37, 'k', '<=', 'endpos', 'k should not exceed endpos'],
 [52, 'end', '!=', '', 'end must not be an empty string'],
 [64, 'tag', '!=', '', 'tag should not be a empty string'],
 [70, 'endpos', '>', 'i', 'endpos should be greater than start position i']]"
rolando/scrapy,"import warnings
import weakref
from twisted.trial import unittest
from scrapy.http import TextResponse, HtmlResponse, XmlResponse
from scrapy.selector import Selector
from scrapy.selector.lxmlsel import XmlXPathSelector, HtmlXPathSelector, XPathSelector
from lxml import etree


class SelectorTestCase(unittest.TestCase):

    def test_simple_selection(self):
        """"""Simple selector tests""""""
        body = b""<p><input name='a'value='1'/><input name='b'value='2'/></p>""
        response = TextResponse(url=""http://example.com"", body=body, encoding='utf-8')
        sel = Selector(response)

        xl = sel.xpath('//input')
        self.assertEqual(2, len(xl))
        for x in xl:
            assert isinstance(x, Selector)

        self.assertEqual(sel.xpath('//input').extract(),
                         [x.extract() for x in sel.xpath('//input')])

        self.assertEqual([x.extract() for x in sel.xpath(""//input[@name='a']/@name"")],
                         [u'a'])
        self.assertEqual([x.extract() for x in sel.xpath(""number(concat(//input[@name='a']/@value, //input[@name='b']/@value))"")],
                         [u'12.0'])

        self.assertEqual(sel.xpath(""concat('xpath', 'rules')"").extract(),
                         [u'xpathrules'])
        self.assertEqual([x.extract() for x in sel.xpath(""concat(//input[@name='a']/@value, //input[@name='b']/@value)"")],
                         [u'12'])

    def test_root_base_url(self):
        body = b'<html><form action=""/path""><input name=""a"" /></form></html>'
        url = ""http://example.com""
        response = TextResponse(url=url, body=body, encoding='utf-8')
        sel = Selector(response)
        self.assertEqual(url, sel.root.base)

    def test_deprecated_root_argument(self):
        with warnings.catch_warnings(record=True) as w:
            root = etree.fromstring(u'<html/>')
            sel = Selector(_root=root)
            self.assertIs(root, sel.root)
            self.assertEqual(str(w[-1].message),
                             'Argument `_root` is deprecated, use `root` instead')

    def test_deprecated_root_argument_ambiguous(self):
        with warnings.catch_warnings(record=True) as w:
            _root = etree.fromstring(u'<xml/>')
            root = etree.fromstring(u'<html/>')
            sel = Selector(_root=_root, root=root)
            self.assertIs(root, sel.root)
            self.assertIn('Ignoring deprecated `_root` argument', str(w[-1].message))

    def test_flavor_detection(self):
        text = b'<div><img src=""a.jpg""><p>Hello</div>'
        sel = Selector(XmlResponse('http://example.com', body=text, encoding='utf-8'))
        self.assertEqual(sel.type, 'xml')
        self.assertEqual(sel.xpath(""//div"").extract(),
                         [u'<div><img src=""a.jpg""><p>Hello</p></img></div>'])

        sel = Selector(HtmlResponse('http://example.com', body=text, encoding='utf-8'))
        self.assertEqual(sel.type, 'html')
        self.assertEqual(sel.xpath(""//div"").extract(),
                         [u'<div><img src=""a.jpg""><p>Hello</p></div>'])

    def test_http_header_encoding_precedence(self):
        # u'\xa3'     = pound symbol in unicode
        # u'\xc2\xa3' = pound symbol in utf-8
        # u'\xa3'     = pound symbol in latin-1 (iso-8859-1)

        meta = u'<meta http-equiv=""Content-Type"" content=""text/html; charset=iso-8859-1"">'
        head = u'<head>' + meta + u'</head>'
        body_content = u'<span id=""blank"">\xa3</span>'
        body = u'<body>' + body_content + u'</body>'
        html = u'<html>' + head + body + u'</html>'
        encoding = 'utf-8'
        html_utf8 = html.encode(encoding)

        headers = {'Content-Type': ['text/html; charset=utf-8']}
        response = HtmlResponse(url=""http://example.com"", headers=headers, body=html_utf8)
        x = Selector(response)
        self.assertEquals(x.xpath(""//span[@id='blank']/text()"").extract(),
                          [u'\xa3'])

    def test_badly_encoded_body(self):
        # \xe9 alone isn't valid utf8 sequence
        r1 = TextResponse('http://www.example.com', \
                          body=b'<html><p>an Jos\xe9 de</p><html>', \
                          encoding='utf-8')
        Selector(r1).xpath('//text()').extract()

    def test_weakref_slots(self):
        """"""Check that classes are using slots and are weak-referenceable""""""
        x = Selector(text='')
        weakref.ref(x)
        assert not hasattr(x, '__dict__'), ""%s does not use __slots__"" % \
            x.__class__.__name__

    def test_deprecated_selector_methods(self):
        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))

        with warnings.catch_warnings(record=True) as w:
            sel.select('//p')
            self.assertSubstring('Use .xpath() instead', str(w[-1].message))

        with warnings.catch_warnings(record=True) as w:
            sel.extract_unquoted()
            self.assertSubstring('Use .extract() instead', str(w[-1].message))

    def test_deprecated_selectorlist_methods(self):
        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))

        with warnings.catch_warnings(record=True) as w:
            sel.xpath('//p').select('.')
            self.assertSubstring('Use .xpath() instead', str(w[-1].message))

        with warnings.catch_warnings(record=True) as w:
            sel.xpath('//p').extract_unquoted()
            self.assertSubstring('Use .extract() instead', str(w[-1].message))

    def test_selector_bad_args(self):
        with self.assertRaisesRegexp(ValueError, 'received both response and text'):
            Selector(TextResponse(url='http://example.com', body=b''), text=u'')


class DeprecatedXpathSelectorTest(unittest.TestCase):

    text = '<div><img src=""a.jpg""><p>Hello</div>'

    def test_warnings_xpathselector(self):
        cls = XPathSelector
        with warnings.catch_warnings(record=True) as w:
            class UserClass(cls):
                pass

            # subclassing must issue a warning
            self.assertEqual(len(w), 1, str(cls))
            self.assertIn('scrapy.Selector', str(w[0].message))

            # subclass instance doesn't issue a warning
            usel = UserClass(text=self.text)
            self.assertEqual(len(w), 1)

            # class instance must issue a warning
            sel = cls(text=self.text)
            self.assertEqual(len(w), 2, str((cls, [x.message for x in w])))
            self.assertIn('scrapy.Selector', str(w[1].message))

            # subclass and instance checks
            self.assertTrue(issubclass(cls, Selector))
            self.assertTrue(isinstance(sel, Selector))
            self.assertTrue(isinstance(usel, Selector))

    def test_warnings_xmlxpathselector(self):
        cls = XmlXPathSelector
        with warnings.catch_warnings(record=True) as w:
            class UserClass(cls):
                pass

            # subclassing must issue a warning
            self.assertEqual(len(w), 1, str(cls))
            self.assertIn('scrapy.Selector', str(w[0].message))

            # subclass instance doesn't issue a warning
            usel = UserClass(text=self.text)
            self.assertEqual(len(w), 1)

            # class instance must issue a warning
            sel = cls(text=self.text)
            self.assertEqual(len(w), 2, str((cls, [x.message for x in w])))
            self.assertIn('scrapy.Selector', str(w[1].message))

            # subclass and instance checks
            self.assertTrue(issubclass(cls, Selector))
            self.assertTrue(issubclass(cls, XPathSelector))
            self.assertTrue(isinstance(sel, Selector))
            self.assertTrue(isinstance(usel, Selector))
            self.assertTrue(isinstance(sel, XPathSelector))
            self.assertTrue(isinstance(usel, XPathSelector))

    def test_warnings_htmlxpathselector(self):
        cls = HtmlXPathSelector
        with warnings.catch_warnings(record=True) as w:
            class UserClass(cls):
                pass

            # subclassing must issue a warning
            self.assertEqual(len(w), 1, str(cls))
            self.assertIn('scrapy.Selector', str(w[0].message))

            # subclass instance doesn't issue a warning
            usel = UserClass(text=self.text)
            self.assertEqual(len(w), 1)

            # class instance must issue a warning
            sel = cls(text=self.text)
            self.assertEqual(len(w), 2, str((cls, [x.message for x in w])))
            self.assertIn('scrapy.Selector', str(w[1].message))

            # subclass and instance checks
            self.assertTrue(issubclass(cls, Selector))
            self.assertTrue(issubclass(cls, XPathSelector))
            self.assertTrue(isinstance(sel, Selector))
            self.assertTrue(isinstance(usel, Selector))
            self.assertTrue(isinstance(sel, XPathSelector))
            self.assertTrue(isinstance(usel, XPathSelector))
","
1import warnings
2import weakref
3from twisted.trial import unittest
4from scrapy.http import TextResponse, HtmlResponse, XmlResponse
5from scrapy.selector import Selector
6from scrapy.selector.lxmlsel import XmlXPathSelector, HtmlXPathSelector, XPathSelector
7from lxml import etree
8
9
10class SelectorTestCase(unittest.TestCase):
11
12    def test_simple_selection(self):
13        """"""Simple selector tests""""""
14        body = b""<p><input name='a'value='1'/><input name='b'value='2'/></p>""
15        response = TextResponse(url=""http://example.com"", body=body, encoding='utf-8')
16        sel = Selector(response)
17
18        xl = sel.xpath('//input')
19        for x in xl:
20
21                         [x.extract() for x in sel.xpath('//input')])
22
23                         [u'a'])
24                         [u'12.0'])
25
26                         [u'xpathrules'])
27                         [u'12'])
28
29    def test_root_base_url(self):
30        body = b'<html><form action=""/path""><input name=""a"" /></form></html>'
31        url = ""http://example.com""
32        response = TextResponse(url=url, body=body, encoding='utf-8')
33        sel = Selector(response)
34
35    def test_deprecated_root_argument(self):
36        with warnings.catch_warnings(record=True) as w:
37            root = etree.fromstring(u'<html/>')
38            sel = Selector(_root=root)
39                             'Argument `_root` is deprecated, use `root` instead')
40
41    def test_deprecated_root_argument_ambiguous(self):
42        with warnings.catch_warnings(record=True) as w:
43            _root = etree.fromstring(u'<xml/>')
44            root = etree.fromstring(u'<html/>')
45            sel = Selector(_root=_root, root=root)
46
47    def test_flavor_detection(self):
48        text = b'<div><img src=""a.jpg""><p>Hello</div>'
49        sel = Selector(XmlResponse('http://example.com', body=text, encoding='utf-8'))
50                         [u'<div><img src=""a.jpg""><p>Hello</p></img></div>'])
51
52        sel = Selector(HtmlResponse('http://example.com', body=text, encoding='utf-8'))
53                         [u'<div><img src=""a.jpg""><p>Hello</p></div>'])
54
55    def test_http_header_encoding_precedence(self):
56        # u'\xa3'     = pound symbol in unicode
57        # u'\xc2\xa3' = pound symbol in utf-8
58        # u'\xa3'     = pound symbol in latin-1 (iso-8859-1)
59
60        meta = u'<meta http-equiv=""Content-Type"" content=""text/html; charset=iso-8859-1"">'
61        head = u'<head>' + meta + u'</head>'
62        body_content = u'<span id=""blank"">\xa3</span>'
63        body = u'<body>' + body_content + u'</body>'
64        html = u'<html>' + head + body + u'</html>'
65        encoding = 'utf-8'
66        html_utf8 = html.encode(encoding)
67
68        headers = {'Content-Type': ['text/html; charset=utf-8']}
69        response = HtmlResponse(url=""http://example.com"", headers=headers, body=html_utf8)
70        x = Selector(response)
71                          [u'\xa3'])
72
73    def test_badly_encoded_body(self):
74        # \xe9 alone isn't valid utf8 sequence
75        r1 = TextResponse('http://www.example.com', \
76                          body=b'<html><p>an Jos\xe9 de</p><html>', \
77                          encoding='utf-8')
78        Selector(r1).xpath('//text()').extract()
79
80    def test_weakref_slots(self):
81        """"""Check that classes are using slots and are weak-referenceable""""""
82        x = Selector(text='')
83        weakref.ref(x)
84            x.__class__.__name__
85
86    def test_deprecated_selector_methods(self):
87        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))
88
89        with warnings.catch_warnings(record=True) as w:
90            sel.select('//p')
91
92        with warnings.catch_warnings(record=True) as w:
93            sel.extract_unquoted()
94
95    def test_deprecated_selectorlist_methods(self):
96        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))
97
98        with warnings.catch_warnings(record=True) as w:
99            sel.xpath('//p').select('.')
100
101        with warnings.catch_warnings(record=True) as w:
102            sel.xpath('//p').extract_unquoted()
103
104    def test_selector_bad_args(self):
105            Selector(TextResponse(url='http://example.com', body=b''), text=u'')
106
107
108class DeprecatedXpathSelectorTest(unittest.TestCase):
109
110    text = '<div><img src=""a.jpg""><p>Hello</div>'
111
112    def test_warnings_xpathselector(self):
113        cls = XPathSelector
114        with warnings.catch_warnings(record=True) as w:
115            class UserClass(cls):
116                pass
117
118            # subclassing must issue a warning
119
120            # subclass instance doesn't issue a warning
121            usel = UserClass(text=self.text)
122
123            # class instance must issue a warning
124            sel = cls(text=self.text)
125
126            # subclass and instance checks
127
128    def test_warnings_xmlxpathselector(self):
129        cls = XmlXPathSelector
130        with warnings.catch_warnings(record=True) as w:
131            class UserClass(cls):
132                pass
133
134            # subclassing must issue a warning
135
136            # subclass instance doesn't issue a warning
137            usel = UserClass(text=self.text)
138
139            # class instance must issue a warning
140            sel = cls(text=self.text)
141
142            # subclass and instance checks
143
144    def test_warnings_htmlxpathselector(self):
145        cls = HtmlXPathSelector
146        with warnings.catch_warnings(record=True) as w:
147            class UserClass(cls):
148                pass
149
150            # subclassing must issue a warning
151
152            # subclass instance doesn't issue a warning
153            usel = UserClass(text=self.text)
154
155            # class instance must issue a warning
156            sel = cls(text=self.text)
157
158            # subclass and instance checks
159","[['hasattr(x', '==', 'False'], [""text'):"", '==', 'True']]",53,2,0.0377358490566037,0.0002229654403567,"['body', 'response', 'sel', 'xl', 'url', 'root', '_root', 'text', ""# u'\\xa3'"", ""# u'\\xc2\\xa3'"", 'meta', 'head', 'body_content', 'html', 'encoding', 'html_utf8', 'headers', 'x', 'r1', 'cls', 'usel']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['body', 'response', 'sel', 'xl', 'url', 'root', '_root', 'text', ""# u'\\xa3'"", ""# u'\\xc2\\xa3'"", 'meta', 'head', 'body_content', 'html', 'encoding', 'html_utf8', 'headers', 'x', 'r1', 'cls', 'usel']
*Code:

1import warnings
2import weakref
3from twisted.trial import unittest
4from scrapy.http import TextResponse, HtmlResponse, XmlResponse
5from scrapy.selector import Selector
6from scrapy.selector.lxmlsel import XmlXPathSelector, HtmlXPathSelector, XPathSelector
7from lxml import etree
8
9
10class SelectorTestCase(unittest.TestCase):
11
12    def test_simple_selection(self):
13        """"""Simple selector tests""""""
14        body = b""<p><input name='a'value='1'/><input name='b'value='2'/></p>""
15        response = TextResponse(url=""http://example.com"", body=body, encoding='utf-8')
16        sel = Selector(response)
17
18        xl = sel.xpath('//input')
19        for x in xl:
20
21                         [x.extract() for x in sel.xpath('//input')])
22
23                         [u'a'])
24                         [u'12.0'])
25
26                         [u'xpathrules'])
27                         [u'12'])
28
29    def test_root_base_url(self):
30        body = b'<html><form action=""/path""><input name=""a"" /></form></html>'
31        url = ""http://example.com""
32        response = TextResponse(url=url, body=body, encoding='utf-8')
33        sel = Selector(response)
34
35    def test_deprecated_root_argument(self):
36        with warnings.catch_warnings(record=True) as w:
37            root = etree.fromstring(u'<html/>')
38            sel = Selector(_root=root)
39                             'Argument `_root` is deprecated, use `root` instead')
40
41    def test_deprecated_root_argument_ambiguous(self):
42        with warnings.catch_warnings(record=True) as w:
43            _root = etree.fromstring(u'<xml/>')
44            root = etree.fromstring(u'<html/>')
45            sel = Selector(_root=_root, root=root)
46
47    def test_flavor_detection(self):
48        text = b'<div><img src=""a.jpg""><p>Hello</div>'
49        sel = Selector(XmlResponse('http://example.com', body=text, encoding='utf-8'))
50                         [u'<div><img src=""a.jpg""><p>Hello</p></img></div>'])
51
52        sel = Selector(HtmlResponse('http://example.com', body=text, encoding='utf-8'))
53                         [u'<div><img src=""a.jpg""><p>Hello</p></div>'])
54
55    def test_http_header_encoding_precedence(self):
56        # u'\xa3'     = pound symbol in unicode
57        # u'\xc2\xa3' = pound symbol in utf-8
58        # u'\xa3'     = pound symbol in latin-1 (iso-8859-1)
59
60        meta = u'<meta http-equiv=""Content-Type"" content=""text/html; charset=iso-8859-1"">'
61        head = u'<head>' + meta + u'</head>'
62        body_content = u'<span id=""blank"">\xa3</span>'
63        body = u'<body>' + body_content + u'</body>'
64        html = u'<html>' + head + body + u'</html>'
65        encoding = 'utf-8'
66        html_utf8 = html.encode(encoding)
67
68        headers = {'Content-Type': ['text/html; charset=utf-8']}
69        response = HtmlResponse(url=""http://example.com"", headers=headers, body=html_utf8)
70        x = Selector(response)
71                          [u'\xa3'])
72
73    def test_badly_encoded_body(self):
74        # \xe9 alone isn't valid utf8 sequence
75        r1 = TextResponse('http://www.example.com', \
76                          body=b'<html><p>an Jos\xe9 de</p><html>', \
77                          encoding='utf-8')
78        Selector(r1).xpath('//text()').extract()
79
80    def test_weakref_slots(self):
81        """"""Check that classes are using slots and are weak-referenceable""""""
82        x = Selector(text='')
83        weakref.ref(x)
84            x.__class__.__name__
85
86    def test_deprecated_selector_methods(self):
87        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))
88
89        with warnings.catch_warnings(record=True) as w:
90            sel.select('//p')
91
92        with warnings.catch_warnings(record=True) as w:
93            sel.extract_unquoted()
94
95    def test_deprecated_selectorlist_methods(self):
96        sel = Selector(TextResponse(url=""http://example.com"", body=b'<p>some text</p>'))
97
98        with warnings.catch_warnings(record=True) as w:
99            sel.xpath('//p').select('.')
100
101        with warnings.catch_warnings(record=True) as w:
102            sel.xpath('//p').extract_unquoted()
103
104    def test_selector_bad_args(self):
105            Selector(TextResponse(url='http://example.com', body=b''), text=u'')
106
107
108class DeprecatedXpathSelectorTest(unittest.TestCase):
109
110    text = '<div><img src=""a.jpg""><p>Hello</div>'
111
112    def test_warnings_xpathselector(self):
113        cls = XPathSelector
114        with warnings.catch_warnings(record=True) as w:
115            class UserClass(cls):
116                pass
117
118            # subclassing must issue a warning
119
120            # subclass instance doesn't issue a warning
121            usel = UserClass(text=self.text)
122
123            # class instance must issue a warning
124            sel = cls(text=self.text)
125
126            # subclass and instance checks
127
128    def test_warnings_xmlxpathselector(self):
129        cls = XmlXPathSelector
130        with warnings.catch_warnings(record=True) as w:
131            class UserClass(cls):
132                pass
133
134            # subclassing must issue a warning
135
136            # subclass instance doesn't issue a warning
137            usel = UserClass(text=self.text)
138
139            # class instance must issue a warning
140            sel = cls(text=self.text)
141
142            # subclass and instance checks
143
144    def test_warnings_htmlxpathselector(self):
145        cls = HtmlXPathSelector
146        with warnings.catch_warnings(record=True) as w:
147            class UserClass(cls):
148                pass
149
150            # subclassing must issue a warning
151
152            # subclass instance doesn't issue a warning
153            usel = UserClass(text=self.text)
154
155            # class instance must issue a warning
156            sel = cls(text=self.text)
157
158            # subclass and instance checks
159",7620,"[[5, 'Selector', '!=', None, ""Selector should have a value""],
[14, 'body', '!=', None, ""Body should have a value""],
[15, 'response', '!=', None, ""Response should have a value""],
[16, 'sel', '!=', None, ""Selector instance should have a value""],
[18, 'xl', '!=', None, ""XML path should have a value""],
[30, 'body', '!=', None, ""Body should have a value""],
[32, 'response', '!=', None, ""Response should have a value""],
[33, 'sel', '!=', None, ""Selector instance should have a value""],
[37, 'root', '!=', None, ""Root should have a value""],
[38, 'sel', '!=', None, ""Selector instance should have a value""],
[43, '_root', '!=', None, ""_Root should have a value""],
[44, 'root', '!=', None, ""Root should have a value""],
[45, 'sel', '!=', None, ""Selector instance should have a value""],
[48, 'text', '!=', None, ""Text should have a value""],
[49, 'sel', '!=', None, ""Selector instance should have a value""],
[52, 'sel', '!=', None, ""Selector instance should have a value""],
[61, 'meta', '!=', None, ""Meta should have a value""],
[62, 'head', '!=', None, ""Head should have a value""],
[63, 'body_content', '!=', None, ""Body_content should have a value""],
[64, 'html', '!=', None, ""Html should have a value""],
[65, 'encoding', '!=', None, ""Encoding should have a value""],
[66, 'html_utf8', '!=', None, ""Html_utf8 should have a value""],
[68, 'headers', '!=', None, ""Headers should have a value""],
[69, 'response', '!=', None, ""Response should have a value""],
[70, 'x', '!=', None, ""X(Selector instance) should have a value""],
[75, 'r1', '!=', None, ""R1 (Response instance) should have a value""],
[78, 'response', '!=', None, ""Response object doesn't return null""],
[82, 'x', '!=', None, ""X (Selector instance) should have a value""],
[105, 'response', '!=', None, ""Response object doesn't return null""],
[115, 'cls', '==', 'XPathSelector', ""Cls should be XPathSelector for proper function""],
[121, 'usel', '!=', None, ""UserSelector instance should have a value""],
[124, 'sel', '!=', None, ""Selector instance should have a value""],
[129, 'cls', '==', 'XmlXPathSelector', ""Cls should be XmlXPathSelector for proper function""],
[131, 'usel', '!=', None, ""UserSelector instance should have a value""],
[140, 'sel', '!=', None, ""Selector instance should have a value""],
[145, 'cls', '==', 'HtmlXPathSelector', ""Cls should be HtmlXPathSelector for proper function""],
[153, 'usel', '!=', None, ""UserSelector instance should have a value""],
[156, 'sel', '!=', None, ""Selector instance should have a value""]]"
catapult-project/catapult,"# Copyright (c) 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import os
import uuid


class AbspathInvalidError(Exception):
  """"""Raised if an abspath cannot be sanitized based on an app's source paths.""""""


class UserFriendlyStringInvalidError(Exception):
  """"""Raised if a user friendly string cannot be parsed.""""""


class ModuleToLoad(object):

  def __init__(self, href=None, filename=None):
    if bool(href) == bool(filename):
      raise Exception('ModuleToLoad must specify exactly one of href and '
                      'filename.')
    self.href = href
    self.filename = filename

  def __repr__(self):
    if self.href:
      return 'ModuleToLoad(href=""%s"")' % self.href
    return 'ModuleToLoad(filename=""%s"")' % self.filename

  def AsDict(self):
    if self.href:
      return {'href': self.href}
    return {'filename': self.filename}

  @staticmethod
  def FromDict(module_dict):
    return ModuleToLoad(module_dict.get('href'), module_dict.get('filename'))


class FunctionHandle(object):

  def __init__(self, modules_to_load=None, function_name=None,
               options=None, guid=uuid.uuid4()):
    self.modules_to_load = modules_to_load
    self.function_name = function_name
    self.options = options
    self._guid = guid

  def __repr__(self):
    return 'FunctionHandle(modules_to_load=[%s], function_name=""%s"")' % (
        ', '.join([str(module) for module in self.modules_to_load]),
        self.function_name)

  @property
  def guid(self):
    return self._guid

  @property
  def has_hrefs(self):
    return any(module.href for module in self.modules_to_load)

  def AsDict(self):
    handle_dict = {
        'function_name': self.function_name
    }

    if self.modules_to_load is not None:
      handle_dict['modules_to_load'] = [module.AsDict() for module in
                                        self.modules_to_load]
    if self.options is not None:
      handle_dict['options'] = self.options

    return handle_dict

  def ConvertHrefsToAbsFilenames(self, app):
    """"""Converts hrefs to absolute filenames in the context of |app|.

    In an app-serving context, functions must only reside in files which the app
    is serving, in order to prevent directory traversal attacks. In addition, we
    rely on paths being absolute when actually executing functions.

    Args:
      app: A dev server instance requesting abspath conversion.

    Returns:
      A new FunctionHandle instance with no hrefs.

    Raises:
      AbspathInvalidError: If there is no source path with which a given abspath
          shares a common prefix.
    """"""
    new_modules_to_load = []
    for module in self.modules_to_load:
      if module.href:
        abspath = app.GetAbsFilenameForHref(module.href)
      else:
        assert os.path.abspath(module.filename) == module.filename
        abspath = module.filename

      if not abspath:
        raise AbspathInvalidError('Filename %s invalid' % abspath)

      new_modules_to_load.append(ModuleToLoad(filename=abspath))

    return FunctionHandle(modules_to_load=new_modules_to_load,
                          function_name=self.function_name)

  @staticmethod
  def FromDict(handle_dict):
    if handle_dict.get('modules_to_load') is not None:
      modules_to_load = [ModuleToLoad.FromDict(module_dict) for module_dict in
                         handle_dict['modules_to_load']]
    else:
      modules_to_load = []
    options = handle_dict.get('options')
    return FunctionHandle(modules_to_load=modules_to_load,
                          function_name=handle_dict['function_name'],
                          options=options)

  def AsUserFriendlyString(self, app):
    parts = [module.filename for module in
             self.ConvertHrefsToAbsFilenames(app).modules_to_load]
    parts.append(self.function_name)

    return ':'.join(parts)

  @staticmethod
  def FromUserFriendlyString(user_str):
    parts = user_str.split(':')
    if len(parts) < 2:
      raise UserFriendlyStringInvalidError(
          'Tried to deserialize string with less than two parts: ' + user_str)

    modules_to_load = [ModuleToLoad(filename=name) for name in parts[:-1]]

    return FunctionHandle(modules_to_load=modules_to_load,
                          function_name=parts[-1])
","
1# Copyright (c) 2015 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5import os
6import uuid
7
8
9class AbspathInvalidError(Exception):
10  """"""Raised if an abspath cannot be sanitized based on an app's source paths.""""""
11
12
13class UserFriendlyStringInvalidError(Exception):
14  """"""Raised if a user friendly string cannot be parsed.""""""
15
16
17class ModuleToLoad(object):
18
19  def __init__(self, href=None, filename=None):
20    if bool(href) == bool(filename):
21      raise Exception('ModuleToLoad must specify exactly one of href and '
22                      'filename.')
23    self.href = href
24    self.filename = filename
25
26  def __repr__(self):
27    if self.href:
28      return 'ModuleToLoad(href=""%s"")' % self.href
29    return 'ModuleToLoad(filename=""%s"")' % self.filename
30
31  def AsDict(self):
32    if self.href:
33      return {'href': self.href}
34    return {'filename': self.filename}
35
36  @staticmethod
37  def FromDict(module_dict):
38    return ModuleToLoad(module_dict.get('href'), module_dict.get('filename'))
39
40
41class FunctionHandle(object):
42
43  def __init__(self, modules_to_load=None, function_name=None,
44               options=None, guid=uuid.uuid4()):
45    self.modules_to_load = modules_to_load
46    self.function_name = function_name
47    self.options = options
48    self._guid = guid
49
50  def __repr__(self):
51    return 'FunctionHandle(modules_to_load=[%s], function_name=""%s"")' % (
52        ', '.join([str(module) for module in self.modules_to_load]),
53        self.function_name)
54
55  @property
56  def guid(self):
57    return self._guid
58
59  @property
60  def has_hrefs(self):
61    return any(module.href for module in self.modules_to_load)
62
63  def AsDict(self):
64    handle_dict = {
65        'function_name': self.function_name
66    }
67
68    if self.modules_to_load is not None:
69      handle_dict['modules_to_load'] = [module.AsDict() for module in
70                                        self.modules_to_load]
71    if self.options is not None:
72      handle_dict['options'] = self.options
73
74    return handle_dict
75
76  def ConvertHrefsToAbsFilenames(self, app):
77    """"""Converts hrefs to absolute filenames in the context of |app|.
78
79    In an app-serving context, functions must only reside in files which the app
80    is serving, in order to prevent directory traversal attacks. In addition, we
81    rely on paths being absolute when actually executing functions.
82
83    Args:
84      app: A dev server instance requesting abspath conversion.
85
86    Returns:
87      A new FunctionHandle instance with no hrefs.
88
89    Raises:
90      AbspathInvalidError: If there is no source path with which a given abspath
91          shares a common prefix.
92    """"""
93    new_modules_to_load = []
94    for module in self.modules_to_load:
95      if module.href:
96        abspath = app.GetAbsFilenameForHref(module.href)
97      else:
98        abspath = module.filename
99
100      if not abspath:
101        raise AbspathInvalidError('Filename %s invalid' % abspath)
102
103      new_modules_to_load.append(ModuleToLoad(filename=abspath))
104
105    return FunctionHandle(modules_to_load=new_modules_to_load,
106                          function_name=self.function_name)
107
108  @staticmethod
109  def FromDict(handle_dict):
110    if handle_dict.get('modules_to_load') is not None:
111      modules_to_load = [ModuleToLoad.FromDict(module_dict) for module_dict in
112                         handle_dict['modules_to_load']]
113    else:
114      modules_to_load = []
115    options = handle_dict.get('options')
116    return FunctionHandle(modules_to_load=modules_to_load,
117                          function_name=handle_dict['function_name'],
118                          options=options)
119
120  def AsUserFriendlyString(self, app):
121    parts = [module.filename for module in
122             self.ConvertHrefsToAbsFilenames(app).modules_to_load]
123    parts.append(self.function_name)
124
125    return ':'.join(parts)
126
127  @staticmethod
128  def FromUserFriendlyString(user_str):
129    parts = user_str.split(':')
130    if len(parts) < 2:
131      raise UserFriendlyStringInvalidError(
132          'Tried to deserialize string with less than two parts: ' + user_str)
133
134    modules_to_load = [ModuleToLoad(filename=name) for name in parts[:-1]]
135
136    return FunctionHandle(modules_to_load=modules_to_load,
137                          function_name=parts[-1])
138","[['os.path.abspath(module.filename)', '==', 'module.filename']]",1,1,1.0,0.0002296211251435,"['href', 'filename', 'self.href', 'self.filename', 'module_dict', 'modules_to_load', 'function_name', 'self.modules_to_load', 'self.function_name', 'self.options', 'self._guid', 'handle_dict', ""handle_dict['modules_to_load']"", ""handle_dict['options']"", 'app', 'new_modules_to_load', 'abspath', 'options', 'parts', 'user_str']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['href', 'filename', 'self.href', 'self.filename', 'module_dict', 'modules_to_load', 'function_name', 'self.modules_to_load', 'self.function_name', 'self.options', 'self._guid', 'handle_dict', ""handle_dict['modules_to_load']"", ""handle_dict['options']"", 'app', 'new_modules_to_load', 'abspath', 'options', 'parts', 'user_str']
*Code:

1# Copyright (c) 2015 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5import os
6import uuid
7
8
9class AbspathInvalidError(Exception):
10  """"""Raised if an abspath cannot be sanitized based on an app's source paths.""""""
11
12
13class UserFriendlyStringInvalidError(Exception):
14  """"""Raised if a user friendly string cannot be parsed.""""""
15
16
17class ModuleToLoad(object):
18
19  def __init__(self, href=None, filename=None):
20    if bool(href) == bool(filename):
21      raise Exception('ModuleToLoad must specify exactly one of href and '
22                      'filename.')
23    self.href = href
24    self.filename = filename
25
26  def __repr__(self):
27    if self.href:
28      return 'ModuleToLoad(href=""%s"")' % self.href
29    return 'ModuleToLoad(filename=""%s"")' % self.filename
30
31  def AsDict(self):
32    if self.href:
33      return {'href': self.href}
34    return {'filename': self.filename}
35
36  @staticmethod
37  def FromDict(module_dict):
38    return ModuleToLoad(module_dict.get('href'), module_dict.get('filename'))
39
40
41class FunctionHandle(object):
42
43  def __init__(self, modules_to_load=None, function_name=None,
44               options=None, guid=uuid.uuid4()):
45    self.modules_to_load = modules_to_load
46    self.function_name = function_name
47    self.options = options
48    self._guid = guid
49
50  def __repr__(self):
51    return 'FunctionHandle(modules_to_load=[%s], function_name=""%s"")' % (
52        ', '.join([str(module) for module in self.modules_to_load]),
53        self.function_name)
54
55  @property
56  def guid(self):
57    return self._guid
58
59  @property
60  def has_hrefs(self):
61    return any(module.href for module in self.modules_to_load)
62
63  def AsDict(self):
64    handle_dict = {
65        'function_name': self.function_name
66    }
67
68    if self.modules_to_load is not None:
69      handle_dict['modules_to_load'] = [module.AsDict() for module in
70                                        self.modules_to_load]
71    if self.options is not None:
72      handle_dict['options'] = self.options
73
74    return handle_dict
75
76  def ConvertHrefsToAbsFilenames(self, app):
77    """"""Converts hrefs to absolute filenames in the context of |app|.
78
79    In an app-serving context, functions must only reside in files which the app
80    is serving, in order to prevent directory traversal attacks. In addition, we
81    rely on paths being absolute when actually executing functions.
82
83    Args:
84      app: A dev server instance requesting abspath conversion.
85
86    Returns:
87      A new FunctionHandle instance with no hrefs.
88
89    Raises:
90      AbspathInvalidError: If there is no source path with which a given abspath
91          shares a common prefix.
92    """"""
93    new_modules_to_load = []
94    for module in self.modules_to_load:
95      if module.href:
96        abspath = app.GetAbsFilenameForHref(module.href)
97      else:
98        abspath = module.filename
99
100      if not abspath:
101        raise AbspathInvalidError('Filename %s invalid' % abspath)
102
103      new_modules_to_load.append(ModuleToLoad(filename=abspath))
104
105    return FunctionHandle(modules_to_load=new_modules_to_load,
106                          function_name=self.function_name)
107
108  @staticmethod
109  def FromDict(handle_dict):
110    if handle_dict.get('modules_to_load') is not None:
111      modules_to_load = [ModuleToLoad.FromDict(module_dict) for module_dict in
112                         handle_dict['modules_to_load']]
113    else:
114      modules_to_load = []
115    options = handle_dict.get('options')
116    return FunctionHandle(modules_to_load=modules_to_load,
117                          function_name=handle_dict['function_name'],
118                          options=options)
119
120  def AsUserFriendlyString(self, app):
121    parts = [module.filename for module in
122             self.ConvertHrefsToAbsFilenames(app).modules_to_load]
123    parts.append(self.function_name)
124
125    return ':'.join(parts)
126
127  @staticmethod
128  def FromUserFriendlyString(user_str):
129    parts = user_str.split(':')
130    if len(parts) < 2:
131      raise UserFriendlyStringInvalidError(
132          'Tried to deserialize string with less than two parts: ' + user_str)
133
134    modules_to_load = [ModuleToLoad(filename=name) for name in parts[:-1]]
135
136    return FunctionHandle(modules_to_load=modules_to_load,
137                          function_name=parts[-1])
138",6300,"[[19, 'href', '!=', 'filename', ""ModuleToLoad must specify exactly one of href and filename""], [43, 'modules_to_load', '!=', None, ""FunctionHandle requires modules_to_load for initialization""], [43, 'function_name', '!=', None, ""FunctionHandle requires function_name for initialization""], [96, 'abspath', '!=', None, ""absolute filepath should exist""], [109, ""handle_dict['modules_to_load']"", '!=', None, ""modules_to_load is required for initialization of FunctionHandle from dictionary""], [109, ""handle_dict['function_name']"", '!=', None, ""function_name is required for initialization of FunctionHandle from dictionary""], [128, 'user_str', '!=', None, ""User string should not be None""], [130, 'parts', '>=', 2, ""Deserialized string should have at least two parts""]]"
martinohanlon/pyjokes,"from pyjokes.jokes_en import jokes_en
from pyjokes.jokes_de import jokes_de
from pyjokes.jokes_es import jokes_es


def _test_joke_length(joke):
    assert len(joke) <= 140


def _test_joke_group(jokes):
    for joke in jokes:
        _test_joke_length(joke)


def test_jokes_lengths():
    jokes_sets = [jokes_en, jokes_es, jokes_de]
    for jokes in jokes_sets:
        _test_joke_group(jokes['all'])
","
1from pyjokes.jokes_en import jokes_en
2from pyjokes.jokes_de import jokes_de
3from pyjokes.jokes_es import jokes_es
4
5
6def _test_joke_length(joke):
7
8
9def _test_joke_group(jokes):
10    for joke in jokes:
11        _test_joke_length(joke)
12
13
14def test_jokes_lengths():
15    jokes_sets = [jokes_en, jokes_es, jokes_de]
16    for jokes in jokes_sets:
17        _test_joke_group(jokes['all'])
18","[['len(joke)', '<=', '140']]",1,1,1.0,0.0024813895781637,"['joke', 'jokes', 'jokes_sets']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['joke', 'jokes', 'jokes_sets']
*Code:

1from pyjokes.jokes_en import jokes_en
2from pyjokes.jokes_de import jokes_de
3from pyjokes.jokes_es import jokes_es
4
5
6def _test_joke_length(joke):
7
8
9def _test_joke_group(jokes):
10    for joke in jokes:
11        _test_joke_length(joke)
12
13
14def test_jokes_lengths():
15    jokes_sets = [jokes_en, jokes_es, jokes_de]
16    for jokes in jokes_sets:
17        _test_joke_group(jokes['all'])
18",1814,"[[6, 'joke', '!=', None, ""make sure a joke is set and won't result in a null-value error""],
 [14, 'jokes_sets', '!=', None, ""make sure jokes_sets are not null before running tests""],
 [16, 'jokes', '!=', None, ""make sure there are jokes in the joke set before testing""]]"
avikivity/scylla,"# Copyright 2020 ScyllaDB
#
# This file is part of Scylla.
#
# Scylla is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Scylla is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with Scylla.  If not, see <http://www.gnu.org/licenses/>.

# This file contains tests which check Scylla-specific features that do
# not exist on AWS. So all these tests are skipped when running with ""--aws"".

import pytest
import requests
import json

# Test that the ""/localnodes"" request works, returning at least the one node.
# TODO: A more through test would need to start a cluster with multiple nodes
# in multiple data centers, and check that we can get a list of nodes in each
# data center. But this test framework cannot yet test that.
def test_localnodes(scylla_only, dynamodb):
    url = dynamodb.meta.client._endpoint.host
    response = requests.get(url + '/localnodes', verify=False)
    assert response.ok
    j = json.loads(response.content.decode('utf-8'))
    assert isinstance(j, list)
    assert len(j) >= 1
","
1# Copyright 2020 ScyllaDB
2#
3# This file is part of Scylla.
4#
5# Scylla is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# Scylla is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with Scylla.  If not, see <http://www.gnu.org/licenses/>.
17
18# This file contains tests which check Scylla-specific features that do
19# not exist on AWS. So all these tests are skipped when running with ""--aws"".
20
21import pytest
22import requests
23import json
24
25# Test that the ""/localnodes"" request works, returning at least the one node.
26# TODO: A more through test would need to start a cluster with multiple nodes
27# in multiple data centers, and check that we can get a list of nodes in each
28# data center. But this test framework cannot yet test that.
29def test_localnodes(scylla_only, dynamodb):
30    url = dynamodb.meta.client._endpoint.host
31    response = requests.get(url + '/localnodes', verify=False)
32    j = json.loads(response.content.decode('utf-8'))
33","[['response.ok', '==', 'True'], ['len(j)', '>=', '1']]",3,2,0.6666666666666666,0.0013661202185792,"['scylla_only', 'dynamodb', 'url', 'response', 'j']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['scylla_only', 'dynamodb', 'url', 'response', 'j']
*Code:

1# Copyright 2020 ScyllaDB
2#
3# This file is part of Scylla.
4#
5# Scylla is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# Scylla is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with Scylla.  If not, see <http://www.gnu.org/licenses/>.
17
18# This file contains tests which check Scylla-specific features that do
19# not exist on AWS. So all these tests are skipped when running with ""--aws"".
20
21import pytest
22import requests
23import json
24
25# Test that the ""/localnodes"" request works, returning at least the one node.
26# TODO: A more through test would need to start a cluster with multiple nodes
27# in multiple data centers, and check that we can get a list of nodes in each
28# data center. But this test framework cannot yet test that.
29def test_localnodes(scylla_only, dynamodb):
30    url = dynamodb.meta.client._endpoint.host
31    response = requests.get(url + '/localnodes', verify=False)
32    j = json.loads(response.content.decode('utf-8'))
33",2876,"[[29, 'scylla_only', '!=', None, ""scylla_only input is necessary""], 
[29, 'dynamodb', '!=', None, ""dynamodb input is necessary""], 
[30, 'url', '!=', None, ""url needs to be initialized""], 
[31, 'response', '!=', None, ""response needs to be initialized""], 
[32, 'j', '!=', None, ""json loads should not return None""]]"
shurihell/testasia,"# pylint: disable=missing-docstring

from lettuce import world, step
from django.conf import settings
from common import upload_file
from nose.tools import assert_equal

TEST_ROOT = settings.COMMON_TEST_DATA_ROOT


@step(u'I go to the textbooks page')
def go_to_uploads(_step):
    world.wait_for_js_to_load()
    world.click_course_content()
    menu_css = 'li.nav-course-courseware-textbooks a'
    world.css_click(menu_css)


@step(u'I should see a message telling me to create a new textbook')
def assert_create_new_textbook_msg(_step):
    css = "".wrapper-content .no-textbook-content""
    assert world.is_css_present(css)
    no_tb = world.css_find(css)
    assert ""You haven't added any textbooks"" in no_tb.text


@step(u'I upload the textbook ""([^""]*)""$')
def upload_textbook(_step, file_name):
    upload_file(file_name, sub_path=""uploads/"")


@step(u'I click (on )?the New Textbook button')
def click_new_textbook(_step, on):
    button_css = "".nav-actions .new-button""
    button = world.css_find(button_css)
    button.click()


@step(u'I name my textbook ""([^""]*)""')
def name_textbook(_step, name):
    input_css = "".textbook input[name=textbook-name]""
    world.css_fill(input_css, name)
    if world.is_firefox():
        world.trigger_event(input_css)


@step(u'I name the (first|second|third) chapter ""([^""]*)""')
def name_chapter(_step, ordinal, name):
    index = [""first"", ""second"", ""third""].index(ordinal)
    input_css = "".textbook .chapter{i} input.chapter-name"".format(i=index + 1)
    world.css_fill(input_css, name)
    if world.is_firefox():
        world.trigger_event(input_css)


@step(u'I type in ""([^""]*)"" for the (first|second|third) chapter asset')
def asset_chapter(_step, name, ordinal):
    index = [""first"", ""second"", ""third""].index(ordinal)
    input_css = "".textbook .chapter{i} input.chapter-asset-path"".format(i=index + 1)
    world.css_fill(input_css, name)
    if world.is_firefox():
        world.trigger_event(input_css)


@step(u'I click the Upload Asset link for the (first|second|third) chapter')
def click_upload_asset(_step, ordinal):
    index = [""first"", ""second"", ""third""].index(ordinal)
    button_css = "".textbook .chapter{i} .action-upload"".format(i=index + 1)
    world.css_click(button_css)


@step(u'I click Add a Chapter')
def click_add_chapter(_step):
    button_css = "".textbook .action-add-chapter""
    world.css_click(button_css)


@step(u'I save the textbook')
def save_textbook(_step):
    submit_css = ""form.edit-textbook button[type=submit]""
    world.css_click(submit_css)


@step(u'I should see a textbook named ""([^""]*)"" with a chapter path containing ""([^""]*)""')
def check_textbook(_step, textbook_name, chapter_name):
    title = world.css_text("".textbook h3.textbook-title"", index=0)
    chapter = world.css_text("".textbook .wrap-textbook p"", index=0)
    assert_equal(title, textbook_name)
    assert_equal(chapter, chapter_name)


@step(u'I should see a textbook named ""([^""]*)"" with (\d+) chapters')
def check_textbook_chapters(_step, textbook_name, num_chapters_str):
    num_chapters = int(num_chapters_str)
    title = world.css_text("".textbook .view-textbook h3.textbook-title"", index=0)
    toggle_text = world.css_text("".textbook .view-textbook .chapter-toggle"", index=0)
    assert_equal(title, textbook_name)
    assert_equal(
        toggle_text,
        ""{num} PDF Chapters"".format(num=num_chapters),
        ""Expected {num} chapters, found {real}"".format(num=num_chapters, real=toggle_text)
    )


@step(u'I click the textbook chapters')
def click_chapters(_step):
    world.css_click("".textbook a.chapter-toggle"")


@step(u'the (first|second|third) chapter should be named ""([^""]*)""')
def check_chapter_name(_step, ordinal, name):
    index = [""first"", ""second"", ""third""].index(ordinal)
    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
    element = chapter.find_by_css("".chapter-name"")
    assert element.text == name, ""Expected chapter named {expected}, found chapter named {actual}"".format(
        expected=name, actual=element.text)


@step(u'the (first|second|third) chapter should have an asset called ""([^""]*)""')
def check_chapter_asset(_step, ordinal, name):
    index = [""first"", ""second"", ""third""].index(ordinal)
    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
    element = chapter.find_by_css("".chapter-asset-path"")
    assert element.text == name, ""Expected chapter with asset {expected}, found chapter with asset {actual}"".format(
        expected=name, actual=element.text)
","
1# pylint: disable=missing-docstring
2
3from lettuce import world, step
4from django.conf import settings
5from common import upload_file
6
7TEST_ROOT = settings.COMMON_TEST_DATA_ROOT
8
9
10@step(u'I go to the textbooks page')
11def go_to_uploads(_step):
12    world.wait_for_js_to_load()
13    world.click_course_content()
14    menu_css = 'li.nav-course-courseware-textbooks a'
15    world.css_click(menu_css)
16
17
18@step(u'I should see a message telling me to create a new textbook')
19    css = "".wrapper-content .no-textbook-content""
20    no_tb = world.css_find(css)
21
22
23@step(u'I upload the textbook ""([^""]*)""$')
24def upload_textbook(_step, file_name):
25    upload_file(file_name, sub_path=""uploads/"")
26
27
28@step(u'I click (on )?the New Textbook button')
29def click_new_textbook(_step, on):
30    button_css = "".nav-actions .new-button""
31    button = world.css_find(button_css)
32    button.click()
33
34
35@step(u'I name my textbook ""([^""]*)""')
36def name_textbook(_step, name):
37    input_css = "".textbook input[name=textbook-name]""
38    world.css_fill(input_css, name)
39    if world.is_firefox():
40        world.trigger_event(input_css)
41
42
43@step(u'I name the (first|second|third) chapter ""([^""]*)""')
44def name_chapter(_step, ordinal, name):
45    index = [""first"", ""second"", ""third""].index(ordinal)
46    input_css = "".textbook .chapter{i} input.chapter-name"".format(i=index + 1)
47    world.css_fill(input_css, name)
48    if world.is_firefox():
49        world.trigger_event(input_css)
50
51
52@step(u'I type in ""([^""]*)"" for the (first|second|third) chapter asset')
53def asset_chapter(_step, name, ordinal):
54    index = [""first"", ""second"", ""third""].index(ordinal)
55    input_css = "".textbook .chapter{i} input.chapter-asset-path"".format(i=index + 1)
56    world.css_fill(input_css, name)
57    if world.is_firefox():
58        world.trigger_event(input_css)
59
60
61@step(u'I click the Upload Asset link for the (first|second|third) chapter')
62def click_upload_asset(_step, ordinal):
63    index = [""first"", ""second"", ""third""].index(ordinal)
64    button_css = "".textbook .chapter{i} .action-upload"".format(i=index + 1)
65    world.css_click(button_css)
66
67
68@step(u'I click Add a Chapter')
69def click_add_chapter(_step):
70    button_css = "".textbook .action-add-chapter""
71    world.css_click(button_css)
72
73
74@step(u'I save the textbook')
75def save_textbook(_step):
76    submit_css = ""form.edit-textbook button[type=submit]""
77    world.css_click(submit_css)
78
79
80@step(u'I should see a textbook named ""([^""]*)"" with a chapter path containing ""([^""]*)""')
81def check_textbook(_step, textbook_name, chapter_name):
82    title = world.css_text("".textbook h3.textbook-title"", index=0)
83    chapter = world.css_text("".textbook .wrap-textbook p"", index=0)
84
85
86@step(u'I should see a textbook named ""([^""]*)"" with (\d+) chapters')
87def check_textbook_chapters(_step, textbook_name, num_chapters_str):
88    num_chapters = int(num_chapters_str)
89    title = world.css_text("".textbook .view-textbook h3.textbook-title"", index=0)
90    toggle_text = world.css_text("".textbook .view-textbook .chapter-toggle"", index=0)
91        toggle_text,
92        ""{num} PDF Chapters"".format(num=num_chapters),
93        ""Expected {num} chapters, found {real}"".format(num=num_chapters, real=toggle_text)
94    )
95
96
97@step(u'I click the textbook chapters')
98def click_chapters(_step):
99    world.css_click("".textbook a.chapter-toggle"")
100
101
102@step(u'the (first|second|third) chapter should be named ""([^""]*)""')
103def check_chapter_name(_step, ordinal, name):
104    index = [""first"", ""second"", ""third""].index(ordinal)
105    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
106    element = chapter.find_by_css("".chapter-name"")
107        expected=name, actual=element.text)
108
109
110@step(u'the (first|second|third) chapter should have an asset called ""([^""]*)""')
111def check_chapter_asset(_step, ordinal, name):
112    index = [""first"", ""second"", ""third""].index(ordinal)
113    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
114    element = chapter.find_by_css("".chapter-asset-path"")
115        expected=name, actual=element.text)
116","[['world.is_css_present(css)', '==', 'True'], ['element.text', '==', 'name'], ['element.text', '==', 'name']]",10,3,0.3,0.0006606474344857,"['TEST_ROOT', '_step', 'menu_css', 'css', 'no_tb', 'file_name', 'on', 'button_css', 'button', 'name', 'input_css', 'ordinal', 'index', 'submit_css', 'textbook_name', 'chapter_name', 'title', 'chapter', 'num_chapters_str', 'num_chapters', 'toggle_text', 'element']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['TEST_ROOT', '_step', 'menu_css', 'css', 'no_tb', 'file_name', 'on', 'button_css', 'button', 'name', 'input_css', 'ordinal', 'index', 'submit_css', 'textbook_name', 'chapter_name', 'title', 'chapter', 'num_chapters_str', 'num_chapters', 'toggle_text', 'element']
*Code:

1# pylint: disable=missing-docstring
2
3from lettuce import world, step
4from django.conf import settings
5from common import upload_file
6
7TEST_ROOT = settings.COMMON_TEST_DATA_ROOT
8
9
10@step(u'I go to the textbooks page')
11def go_to_uploads(_step):
12    world.wait_for_js_to_load()
13    world.click_course_content()
14    menu_css = 'li.nav-course-courseware-textbooks a'
15    world.css_click(menu_css)
16
17
18@step(u'I should see a message telling me to create a new textbook')
19    css = "".wrapper-content .no-textbook-content""
20    no_tb = world.css_find(css)
21
22
23@step(u'I upload the textbook ""([^""]*)""$')
24def upload_textbook(_step, file_name):
25    upload_file(file_name, sub_path=""uploads/"")
26
27
28@step(u'I click (on )?the New Textbook button')
29def click_new_textbook(_step, on):
30    button_css = "".nav-actions .new-button""
31    button = world.css_find(button_css)
32    button.click()
33
34
35@step(u'I name my textbook ""([^""]*)""')
36def name_textbook(_step, name):
37    input_css = "".textbook input[name=textbook-name]""
38    world.css_fill(input_css, name)
39    if world.is_firefox():
40        world.trigger_event(input_css)
41
42
43@step(u'I name the (first|second|third) chapter ""([^""]*)""')
44def name_chapter(_step, ordinal, name):
45    index = [""first"", ""second"", ""third""].index(ordinal)
46    input_css = "".textbook .chapter{i} input.chapter-name"".format(i=index + 1)
47    world.css_fill(input_css, name)
48    if world.is_firefox():
49        world.trigger_event(input_css)
50
51
52@step(u'I type in ""([^""]*)"" for the (first|second|third) chapter asset')
53def asset_chapter(_step, name, ordinal):
54    index = [""first"", ""second"", ""third""].index(ordinal)
55    input_css = "".textbook .chapter{i} input.chapter-asset-path"".format(i=index + 1)
56    world.css_fill(input_css, name)
57    if world.is_firefox():
58        world.trigger_event(input_css)
59
60
61@step(u'I click the Upload Asset link for the (first|second|third) chapter')
62def click_upload_asset(_step, ordinal):
63    index = [""first"", ""second"", ""third""].index(ordinal)
64    button_css = "".textbook .chapter{i} .action-upload"".format(i=index + 1)
65    world.css_click(button_css)
66
67
68@step(u'I click Add a Chapter')
69def click_add_chapter(_step):
70    button_css = "".textbook .action-add-chapter""
71    world.css_click(button_css)
72
73
74@step(u'I save the textbook')
75def save_textbook(_step):
76    submit_css = ""form.edit-textbook button[type=submit]""
77    world.css_click(submit_css)
78
79
80@step(u'I should see a textbook named ""([^""]*)"" with a chapter path containing ""([^""]*)""')
81def check_textbook(_step, textbook_name, chapter_name):
82    title = world.css_text("".textbook h3.textbook-title"", index=0)
83    chapter = world.css_text("".textbook .wrap-textbook p"", index=0)
84
85
86@step(u'I should see a textbook named ""([^""]*)"" with (\d+) chapters')
87def check_textbook_chapters(_step, textbook_name, num_chapters_str):
88    num_chapters = int(num_chapters_str)
89    title = world.css_text("".textbook .view-textbook h3.textbook-title"", index=0)
90    toggle_text = world.css_text("".textbook .view-textbook .chapter-toggle"", index=0)
91        toggle_text,
92        ""{num} PDF Chapters"".format(num=num_chapters),
93        ""Expected {num} chapters, found {real}"".format(num=num_chapters, real=toggle_text)
94    )
95
96
97@step(u'I click the textbook chapters')
98def click_chapters(_step):
99    world.css_click("".textbook a.chapter-toggle"")
100
101
102@step(u'the (first|second|third) chapter should be named ""([^""]*)""')
103def check_chapter_name(_step, ordinal, name):
104    index = [""first"", ""second"", ""third""].index(ordinal)
105    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
106    element = chapter.find_by_css("".chapter-name"")
107        expected=name, actual=element.text)
108
109
110@step(u'the (first|second|third) chapter should have an asset called ""([^""]*)""')
111def check_chapter_asset(_step, ordinal, name):
112    index = [""first"", ""second"", ""third""].index(ordinal)
113    chapter = world.css_find("".textbook .view-textbook ol.chapters li"")[index]
114    element = chapter.find_by_css("".chapter-asset-path"")
115        expected=name, actual=element.text)
116",5890,"[[11, '_step', '!=', None, ""functions should have an input""],
 [24, '_step', '!=', None, ""functions should have an input""],
 [24, 'file_name', '!=', None, ""functions should have an input""],
 [29, '_step', '!=', None, ""functions should have an input""],
 [29, 'on', '!=', None, ""functions should have an input""],
 [36, '_step', '!=', None, ""functions should have an input""],
 [36, 'name', '!=', None, ""functions should have an input""],
 [44, '_step', '!=', None, ""functions should have an input""],
 [44, 'ordinal', '!=', None, ""functions should have an input""],
 [44, 'name', '!=', None, ""functions should have an input""],
 [53, '_step', '!=', None, ""functions should have an input""],
 [53, 'name', '!=', None, ""functions should have an input""],
 [53, 'ordinal', '!=', None, ""functions should have an input""],
 [62, '_step', '!=', None, ""functions should have an input""],
 [62, 'ordinal', '!=', None, ""functions should have an input""],
 [69, '_step', '!=', None, ""functions should have an input""],
 [75, '_step', '!=', None, ""functions should have an input""],
 [81, '_step', '!=', None, ""functions should have an input""],
 [81, 'textbook_name', '!=', None, ""functions should have an input""],
 [81, 'chapter_name', '!=', None, ""functions should have an input""],
 [87, '_step', '!=', None, ""functions should have an input""],
 [87, 'textbook_name', '!=', None, ""functions should have an input""],
 [87, 'num_chapters_str', '!=', None, ""functions should have an input""],
 [98, '_step', '!=', None, ""functions should have an input""],
 [103, '_step', '!=', None, ""functions should have an input""],
 [103, 'ordinal', '!=', None, ""functions should have an input""],
 [103, 'name', '!=', None, ""functions should have an input""],
 [111, '_step', '!=', None, ""functions should have an input""],
 [111, 'ordinal', '!=', None, ""functions should have an input""],
 [111, 'name', '!=', None, ""functions should have an input""]]"
soldag/home-assistant,"""""""Test Automation config panel.""""""
import json

from homeassistant.bootstrap import async_setup_component
from homeassistant.components import config
from homeassistant.util.yaml import dump

from tests.async_mock import patch


async def test_update_scene(hass, hass_client):
    """"""Test updating a scene.""""""
    with patch.object(config, ""SECTIONS"", [""scene""]):
        await async_setup_component(hass, ""config"", {})

    client = await hass_client()

    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]

    def mock_read(path):
        """"""Mock reading data.""""""
        return orig_data

    written = []

    def mock_write(path, data):
        """"""Mock writing data.""""""
        data = dump(data)
        written.append(data)

    with patch(""homeassistant.components.config._read"", mock_read), patch(
        ""homeassistant.components.config._write"", mock_write
    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
        resp = await client.post(
            ""/api/config/scene/config/light_off"",
            data=json.dumps(
                {
                    ""id"": ""light_off"",
                    ""name"": ""Lights off"",
                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
                }
            ),
        )

    assert resp.status == 200
    result = await resp.json()
    assert result == {""result"": ""ok""}

    assert len(written) == 1
    written_yaml = written[0]
    assert (
        written_yaml
        == """"""- id: light_on
- id: light_off
  name: Lights off
  entities:
    light.bedroom:
      state: 'off'
""""""
    )


async def test_bad_formatted_scene(hass, hass_client):
    """"""Test that we handle scene without ID.""""""
    with patch.object(config, ""SECTIONS"", [""scene""]):
        await async_setup_component(hass, ""config"", {})

    client = await hass_client()

    orig_data = [
        {
            # No ID
            ""entities"": {""light.bedroom"": ""on""}
        },
        {""id"": ""light_off""},
    ]

    def mock_read(path):
        """"""Mock reading data.""""""
        return orig_data

    written = []

    def mock_write(path, data):
        """"""Mock writing data.""""""
        written.append(data)

    with patch(""homeassistant.components.config._read"", mock_read), patch(
        ""homeassistant.components.config._write"", mock_write
    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
        resp = await client.post(
            ""/api/config/scene/config/light_off"",
            data=json.dumps(
                {
                    ""id"": ""light_off"",
                    ""name"": ""Lights off"",
                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
                }
            ),
        )

    assert resp.status == 200
    result = await resp.json()
    assert result == {""result"": ""ok""}

    # Verify ID added to orig_data
    assert ""id"" in orig_data[0]

    assert orig_data[1] == {
        ""id"": ""light_off"",
        ""name"": ""Lights off"",
        ""entities"": {""light.bedroom"": {""state"": ""off""}},
    }


async def test_delete_scene(hass, hass_client):
    """"""Test deleting a scene.""""""
    ent_reg = await hass.helpers.entity_registry.async_get_registry()

    assert await async_setup_component(
        hass,
        ""scene"",
        {
            ""scene"": [
                {""id"": ""light_on"", ""name"": ""Light on"", ""entities"": {}},
                {""id"": ""light_off"", ""name"": ""Light off"", ""entities"": {}},
            ]
        },
    )

    assert len(ent_reg.entities) == 2

    with patch.object(config, ""SECTIONS"", [""scene""]):
        assert await async_setup_component(hass, ""config"", {})

    client = await hass_client()

    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]

    def mock_read(path):
        """"""Mock reading data.""""""
        return orig_data

    written = []

    def mock_write(path, data):
        """"""Mock writing data.""""""
        written.append(data)

    with patch(""homeassistant.components.config._read"", mock_read), patch(
        ""homeassistant.components.config._write"", mock_write
    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
        resp = await client.delete(""/api/config/scene/config/light_on"")
        await hass.async_block_till_done()

    assert resp.status == 200
    result = await resp.json()
    assert result == {""result"": ""ok""}

    assert len(written) == 1
    assert written[0][0][""id""] == ""light_off""

    assert len(ent_reg.entities) == 1
","
1""""""Test Automation config panel.""""""
2import json
3
4from homeassistant.bootstrap import async_setup_component
5from homeassistant.components import config
6from homeassistant.util.yaml import dump
7
8from tests.async_mock import patch
9
10
11async def test_update_scene(hass, hass_client):
12    """"""Test updating a scene.""""""
13    with patch.object(config, ""SECTIONS"", [""scene""]):
14        await async_setup_component(hass, ""config"", {})
15
16    client = await hass_client()
17
18    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]
19
20    def mock_read(path):
21        """"""Mock reading data.""""""
22        return orig_data
23
24    written = []
25
26    def mock_write(path, data):
27        """"""Mock writing data.""""""
28        data = dump(data)
29        written.append(data)
30
31    with patch(""homeassistant.components.config._read"", mock_read), patch(
32        ""homeassistant.components.config._write"", mock_write
33    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
34        resp = await client.post(
35            ""/api/config/scene/config/light_off"",
36            data=json.dumps(
37                {
38                    ""id"": ""light_off"",
39                    ""name"": ""Lights off"",
40                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
41                }
42            ),
43        )
44
45    result = await resp.json()
46
47    written_yaml = written[0]
48        written_yaml
49        == """"""- id: light_on
50- id: light_off
51  name: Lights off
52  entities:
53    light.bedroom:
54      state: 'off'
55""""""
56    )
57
58
59async def test_bad_formatted_scene(hass, hass_client):
60    """"""Test that we handle scene without ID.""""""
61    with patch.object(config, ""SECTIONS"", [""scene""]):
62        await async_setup_component(hass, ""config"", {})
63
64    client = await hass_client()
65
66    orig_data = [
67        {
68            # No ID
69            ""entities"": {""light.bedroom"": ""on""}
70        },
71        {""id"": ""light_off""},
72    ]
73
74    def mock_read(path):
75        """"""Mock reading data.""""""
76        return orig_data
77
78    written = []
79
80    def mock_write(path, data):
81        """"""Mock writing data.""""""
82        written.append(data)
83
84    with patch(""homeassistant.components.config._read"", mock_read), patch(
85        ""homeassistant.components.config._write"", mock_write
86    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
87        resp = await client.post(
88            ""/api/config/scene/config/light_off"",
89            data=json.dumps(
90                {
91                    ""id"": ""light_off"",
92                    ""name"": ""Lights off"",
93                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
94                }
95            ),
96        )
97
98    result = await resp.json()
99
100    # Verify ID added to orig_data
101
102        ""id"": ""light_off"",
103        ""name"": ""Lights off"",
104        ""entities"": {""light.bedroom"": {""state"": ""off""}},
105    }
106
107
108async def test_delete_scene(hass, hass_client):
109    """"""Test deleting a scene.""""""
110    ent_reg = await hass.helpers.entity_registry.async_get_registry()
111
112        hass,
113        ""scene"",
114        {
115            ""scene"": [
116                {""id"": ""light_on"", ""name"": ""Light on"", ""entities"": {}},
117                {""id"": ""light_off"", ""name"": ""Light off"", ""entities"": {}},
118            ]
119        },
120    )
121
122
123    with patch.object(config, ""SECTIONS"", [""scene""]):
124
125    client = await hass_client()
126
127    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]
128
129    def mock_read(path):
130        """"""Mock reading data.""""""
131        return orig_data
132
133    written = []
134
135    def mock_write(path, data):
136        """"""Mock writing data.""""""
137        written.append(data)
138
139    with patch(""homeassistant.components.config._read"", mock_read), patch(
140        ""homeassistant.components.config._write"", mock_write
141    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
142        resp = await client.delete(""/api/config/scene/config/light_on"")
143        await hass.async_block_till_done()
144
145    result = await resp.json()
146
147
148","[['resp.status', '==', '200'], ['result', '==', '{""result"": ""ok""}'], ['len(written)', '==', '1'], ['(', '==', 'True'], ['resp.status', '==', '200'], ['result', '==', '{""result"": ""ok""}'], ['orig_data[1]', '==', '{'], ['await', 'async_setup_component('], ['len(ent_reg.entities)', '==', '2'], ['await', 'async_setup_component(hass'], ['resp.status', '==', '200'], ['result', '==', '{""result"": ""ok""}'], ['len(written)', '==', '1'], ['written[0][0][""id""]', '==', '""light_off""'], ['len(ent_reg.entities)', '==', '1']]",16,15,0.9375,0.0033579583613163,"['hass', 'hass_client', 'client', 'orig_data', 'path', 'written', 'data', 'resp', 'result', 'written_yaml', 'ent_reg']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'hass_client', 'client', 'orig_data', 'path', 'written', 'data', 'resp', 'result', 'written_yaml', 'ent_reg']
*Code:

1""""""Test Automation config panel.""""""
2import json
3
4from homeassistant.bootstrap import async_setup_component
5from homeassistant.components import config
6from homeassistant.util.yaml import dump
7
8from tests.async_mock import patch
9
10
11async def test_update_scene(hass, hass_client):
12    """"""Test updating a scene.""""""
13    with patch.object(config, ""SECTIONS"", [""scene""]):
14        await async_setup_component(hass, ""config"", {})
15
16    client = await hass_client()
17
18    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]
19
20    def mock_read(path):
21        """"""Mock reading data.""""""
22        return orig_data
23
24    written = []
25
26    def mock_write(path, data):
27        """"""Mock writing data.""""""
28        data = dump(data)
29        written.append(data)
30
31    with patch(""homeassistant.components.config._read"", mock_read), patch(
32        ""homeassistant.components.config._write"", mock_write
33    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
34        resp = await client.post(
35            ""/api/config/scene/config/light_off"",
36            data=json.dumps(
37                {
38                    ""id"": ""light_off"",
39                    ""name"": ""Lights off"",
40                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
41                }
42            ),
43        )
44
45    result = await resp.json()
46
47    written_yaml = written[0]
48        written_yaml
49        == """"""- id: light_on
50- id: light_off
51  name: Lights off
52  entities:
53    light.bedroom:
54      state: 'off'
55""""""
56    )
57
58
59async def test_bad_formatted_scene(hass, hass_client):
60    """"""Test that we handle scene without ID.""""""
61    with patch.object(config, ""SECTIONS"", [""scene""]):
62        await async_setup_component(hass, ""config"", {})
63
64    client = await hass_client()
65
66    orig_data = [
67        {
68            # No ID
69            ""entities"": {""light.bedroom"": ""on""}
70        },
71        {""id"": ""light_off""},
72    ]
73
74    def mock_read(path):
75        """"""Mock reading data.""""""
76        return orig_data
77
78    written = []
79
80    def mock_write(path, data):
81        """"""Mock writing data.""""""
82        written.append(data)
83
84    with patch(""homeassistant.components.config._read"", mock_read), patch(
85        ""homeassistant.components.config._write"", mock_write
86    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
87        resp = await client.post(
88            ""/api/config/scene/config/light_off"",
89            data=json.dumps(
90                {
91                    ""id"": ""light_off"",
92                    ""name"": ""Lights off"",
93                    ""entities"": {""light.bedroom"": {""state"": ""off""}},
94                }
95            ),
96        )
97
98    result = await resp.json()
99
100    # Verify ID added to orig_data
101
102        ""id"": ""light_off"",
103        ""name"": ""Lights off"",
104        ""entities"": {""light.bedroom"": {""state"": ""off""}},
105    }
106
107
108async def test_delete_scene(hass, hass_client):
109    """"""Test deleting a scene.""""""
110    ent_reg = await hass.helpers.entity_registry.async_get_registry()
111
112        hass,
113        ""scene"",
114        {
115            ""scene"": [
116                {""id"": ""light_on"", ""name"": ""Light on"", ""entities"": {}},
117                {""id"": ""light_off"", ""name"": ""Light off"", ""entities"": {}},
118            ]
119        },
120    )
121
122
123    with patch.object(config, ""SECTIONS"", [""scene""]):
124
125    client = await hass_client()
126
127    orig_data = [{""id"": ""light_on""}, {""id"": ""light_off""}]
128
129    def mock_read(path):
130        """"""Mock reading data.""""""
131        return orig_data
132
133    written = []
134
135    def mock_write(path, data):
136        """"""Mock writing data.""""""
137        written.append(data)
138
139    with patch(""homeassistant.components.config._read"", mock_read), patch(
140        ""homeassistant.components.config._write"", mock_write
141    ), patch(""homeassistant.config.async_hass_config_yaml"", return_value={}):
142        resp = await client.delete(""/api/config/scene/config/light_on"")
143        await hass.async_block_till_done()
144
145    result = await resp.json()
146
147
148",5741,"[[16, 'hass_client', '!=', None, 'hass_client should not be None before assignment to client'],
[18, 'orig_data', '==', 2, 'orig_data should be a list of length 2 before mocked reading data'],
[24, 'written', '==', 0, 'written should be an empty list before mocked writing data'],
[34, 'client', '!=', None, 'client should not be None before making a post request'],
[45, 'resp', '!=', None, 'resp should not be None before getting the result'],
[64, 'hass_client', '!=', None, 'hass_client should not be None before assignment to client'],
[66, 'orig_data', '!=', None, 'orig_data should not be None before mocked reading data'],
[78, 'written', '==', 0, 'written should be an empty list before mocked writing data'],
[87, 'client', '!=', None, 'client should not be None before making a post request'],
[98, 'resp', '!=', None, 'resp should not be None before getting the result'],
[110, 'hass', '!=', None, 'hass should not be None before accessing entity_registry'],
[125, 'hass_client', '!=', None, 'hass_client should not be None before assignment to client'],
[127, 'orig_data', '==', 2, 'orig_data should be a list of length 2 before mocked reading data'],
[133, 'written', '==', 0, 'written should be an empty list before mocked writing data'],
[142, 'client', '!=', None, 'client should not be None before making a delete request'],
[145, 'resp', '!=', None, 'resp should not be None before getting the result']]"
gbirke/scrapy,"import functools
import operator
import unittest
from itertools import count

from scrapy.utils.python import str_to_unicode, unicode_to_str, \
    memoizemethod_noargs, isbinarytext, equal_attributes, \
    WeakKeyCache, stringify_dict, get_func_args

__doctests__ = ['scrapy.utils.python']

class UtilsPythonTestCase(unittest.TestCase):
    def test_str_to_unicode(self):
        # converting an utf-8 encoded string to unicode
        self.assertEqual(str_to_unicode('lel\xc3\xb1e'), u'lel\xf1e')

        # converting a latin-1 encoded string to unicode
        self.assertEqual(str_to_unicode('lel\xf1e', 'latin-1'), u'lel\xf1e')

        # converting a unicode to unicode should return the same object
        self.assertEqual(str_to_unicode(u'\xf1e\xf1e\xf1e'), u'\xf1e\xf1e\xf1e')

        # converting a strange object should raise TypeError
        self.assertRaises(TypeError, str_to_unicode, 423)

        # check errors argument works
        assert u'\ufffd' in str_to_unicode('a\xedb', 'utf-8', errors='replace')

    def test_unicode_to_str(self):
        # converting a unicode object to an utf-8 encoded string
        self.assertEqual(unicode_to_str(u'\xa3 49'), '\xc2\xa3 49')

        # converting a unicode object to a latin-1 encoded string
        self.assertEqual(unicode_to_str(u'\xa3 49', 'latin-1'), '\xa3 49')

        # converting a regular string to string should return the same object
        self.assertEqual(unicode_to_str('lel\xf1e'), 'lel\xf1e')

        # converting a strange object should raise TypeError
        self.assertRaises(TypeError, unicode_to_str, unittest)

        # check errors argument works
        assert '?' in unicode_to_str(u'a\ufffdb', 'latin-1', errors='replace')

    def test_memoizemethod_noargs(self):
        class A(object):

            @memoizemethod_noargs
            def cached(self):
                return object()

            def noncached(self):
                return object()

        a = A()
        one = a.cached()
        two = a.cached()
        three = a.noncached()
        assert one is two
        assert one is not three

    def test_isbinarytext(self):

        # basic tests
        assert not isbinarytext(""hello"")

        # utf-16 strings contain null bytes
        assert not isbinarytext(u""hello"".encode('utf-16'))

        # one with encoding
        assert not isbinarytext(""<div>Price \xa3</div>"")

        # finally some real binary bytes
        assert isbinarytext(""\x02\xa3"")

    def test_equal_attributes(self):
        class Obj:
            pass

        a = Obj()
        b = Obj()
        # no attributes given return False
        self.failIf(equal_attributes(a, b, []))
        # not existent attributes
        self.failIf(equal_attributes(a, b, ['x', 'y']))

        a.x = 1
        b.x = 1
        # equal attribute
        self.assertTrue(equal_attributes(a, b, ['x']))

        b.y = 2
        # obj1 has no attribute y
        self.failIf(equal_attributes(a, b, ['x', 'y']))

        a.y = 2
        # equal attributes
        self.assertTrue(equal_attributes(a, b, ['x', 'y']))

        a.y = 1
        # differente attributes
        self.failIf(equal_attributes(a, b, ['x', 'y']))

        # test callable
        a.meta = {}
        b.meta = {}
        self.assertTrue(equal_attributes(a, b, ['meta']))

        # compare ['meta']['a']
        a.meta['z'] = 1
        b.meta['z'] = 1

        get_z = operator.itemgetter('z')
        get_meta = operator.attrgetter('meta')
        compare_z = lambda obj: get_z(get_meta(obj))

        self.assertTrue(equal_attributes(a, b, [compare_z, 'x']))
        # fail z equality
        a.meta['z'] = 2
        self.failIf(equal_attributes(a, b, [compare_z, 'x']))

    def test_weakkeycache(self):
        class _Weakme(object): pass
        _values = count()
        wk = WeakKeyCache(lambda k: next(_values))
        k = _Weakme()
        v = wk[k]
        self.assertEqual(v, wk[k])
        self.assertNotEqual(v, wk[_Weakme()])
        self.assertEqual(v, wk[k])
        del k
        self.assertFalse(len(wk._weakdict))

    def test_stringify_dict(self):
        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
        d2 = stringify_dict(d, keys_only=False)
        self.assertEqual(d, d2)
        self.failIf(d is d2) # shouldn't modify in place
        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))
        self.failIf(any(isinstance(x, unicode) for x in d2.values()))

    def test_stringify_dict_tuples(self):
        tuples = [('a', 123), (u'b', 'c'), (u'd', u'e'), (object(), u'e')]
        d = dict(tuples)
        d2 = stringify_dict(tuples, keys_only=False)
        self.assertEqual(d, d2)
        self.failIf(d is d2) # shouldn't modify in place
        self.failIf(any(isinstance(x, unicode) for x in d2.keys()), d2.keys())
        self.failIf(any(isinstance(x, unicode) for x in d2.values()))

    def test_stringify_dict_keys_only(self):
        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
        d2 = stringify_dict(d)
        self.assertEqual(d, d2)
        self.failIf(d is d2) # shouldn't modify in place
        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))

    def test_get_func_args(self):
        def f1(a, b, c):
            pass

        def f2(a, b=None, c=None):
            pass

        class A(object):
            def __init__(self, a, b, c):
                pass

            def method(self, a, b, c):
                pass

        class Callable(object):

            def __call__(self, a, b, c):
                pass

        a = A(1, 2, 3)
        cal = Callable()
        partial_f1 = functools.partial(f1, None)
        partial_f2 = functools.partial(f1, b=None)
        partial_f3 = functools.partial(partial_f2, None)

        self.assertEqual(get_func_args(f1), ['a', 'b', 'c'])
        self.assertEqual(get_func_args(f2), ['a', 'b', 'c'])
        self.assertEqual(get_func_args(A), ['a', 'b', 'c'])
        self.assertEqual(get_func_args(a.method), ['a', 'b', 'c'])
        self.assertEqual(get_func_args(partial_f1), ['b', 'c'])
        self.assertEqual(get_func_args(partial_f2), ['a', 'c'])
        self.assertEqual(get_func_args(partial_f3), ['c'])
        self.assertEqual(get_func_args(cal), ['a', 'b', 'c'])
        self.assertEqual(get_func_args(object), [])

        # TODO: how do we fix this to return the actual argument names?
        self.assertEqual(get_func_args(unicode.split), [])
        self.assertEqual(get_func_args("" "".join), [])
        self.assertEqual(get_func_args(operator.itemgetter(2)), [])

if __name__ == ""__main__"":
    unittest.main()
","
1import functools
2import operator
3import unittest
4from itertools import count
5
6from scrapy.utils.python import str_to_unicode, unicode_to_str, \
7    memoizemethod_noargs, isbinarytext, equal_attributes, \
8    WeakKeyCache, stringify_dict, get_func_args
9
10__doctests__ = ['scrapy.utils.python']
11
12class UtilsPythonTestCase(unittest.TestCase):
13    def test_str_to_unicode(self):
14        # converting an utf-8 encoded string to unicode
15
16        # converting a latin-1 encoded string to unicode
17
18        # converting a unicode to unicode should return the same object
19
20        # converting a strange object should raise TypeError
21
22        # check errors argument works
23
24    def test_unicode_to_str(self):
25        # converting a unicode object to an utf-8 encoded string
26
27        # converting a unicode object to a latin-1 encoded string
28
29        # converting a regular string to string should return the same object
30
31        # converting a strange object should raise TypeError
32
33        # check errors argument works
34
35    def test_memoizemethod_noargs(self):
36        class A(object):
37
38            @memoizemethod_noargs
39            def cached(self):
40                return object()
41
42            def noncached(self):
43                return object()
44
45        a = A()
46        one = a.cached()
47        two = a.cached()
48        three = a.noncached()
49
50    def test_isbinarytext(self):
51
52        # basic tests
53
54        # utf-16 strings contain null bytes
55
56        # one with encoding
57
58        # finally some real binary bytes
59
60    def test_equal_attributes(self):
61        class Obj:
62            pass
63
64        a = Obj()
65        b = Obj()
66        # no attributes given return False
67        self.failIf(equal_attributes(a, b, []))
68        # not existent attributes
69        self.failIf(equal_attributes(a, b, ['x', 'y']))
70
71        a.x = 1
72        b.x = 1
73        # equal attribute
74
75        b.y = 2
76        # obj1 has no attribute y
77        self.failIf(equal_attributes(a, b, ['x', 'y']))
78
79        a.y = 2
80        # equal attributes
81
82        a.y = 1
83        # differente attributes
84        self.failIf(equal_attributes(a, b, ['x', 'y']))
85
86        # test callable
87        a.meta = {}
88        b.meta = {}
89
90        # compare ['meta']['a']
91        a.meta['z'] = 1
92        b.meta['z'] = 1
93
94        get_z = operator.itemgetter('z')
95        get_meta = operator.attrgetter('meta')
96        compare_z = lambda obj: get_z(get_meta(obj))
97
98        # fail z equality
99        a.meta['z'] = 2
100        self.failIf(equal_attributes(a, b, [compare_z, 'x']))
101
102    def test_weakkeycache(self):
103        class _Weakme(object): pass
104        _values = count()
105        wk = WeakKeyCache(lambda k: next(_values))
106        k = _Weakme()
107        v = wk[k]
108        del k
109
110    def test_stringify_dict(self):
111        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
112        d2 = stringify_dict(d, keys_only=False)
113        self.failIf(d is d2) # shouldn't modify in place
114        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))
115        self.failIf(any(isinstance(x, unicode) for x in d2.values()))
116
117    def test_stringify_dict_tuples(self):
118        tuples = [('a', 123), (u'b', 'c'), (u'd', u'e'), (object(), u'e')]
119        d = dict(tuples)
120        d2 = stringify_dict(tuples, keys_only=False)
121        self.failIf(d is d2) # shouldn't modify in place
122        self.failIf(any(isinstance(x, unicode) for x in d2.keys()), d2.keys())
123        self.failIf(any(isinstance(x, unicode) for x in d2.values()))
124
125    def test_stringify_dict_keys_only(self):
126        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
127        d2 = stringify_dict(d)
128        self.failIf(d is d2) # shouldn't modify in place
129        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))
130
131    def test_get_func_args(self):
132        def f1(a, b, c):
133            pass
134
135        def f2(a, b=None, c=None):
136            pass
137
138        class A(object):
139            def __init__(self, a, b, c):
140                pass
141
142            def method(self, a, b, c):
143                pass
144
145        class Callable(object):
146
147            def __call__(self, a, b, c):
148                pass
149
150        a = A(1, 2, 3)
151        cal = Callable()
152        partial_f1 = functools.partial(f1, None)
153        partial_f2 = functools.partial(f1, b=None)
154        partial_f3 = functools.partial(partial_f2, None)
155
156
157        # TODO: how do we fix this to return the actual argument names?
158
159if __name__ == ""__main__"":
160    unittest.main()
161","[['one', '==', 'two'], ['one', '==', 'not three'], ['isbinarytext(""hello"")', '==', 'False'], ['isbinarytext(u""hello"".encode(\'utf-16\'))', '==', 'False'], ['isbinarytext(""<div>Price', '\\xa3</div>"")'], ['isbinarytext(""\\x02\\xa3"")', '==', 'True']]",39,6,0.1538461538461538,0.0009055236945366,"['__doctests__', 'a', 'one', 'two', 'three', 'b', 'a.x', 'b.x', 'b.y', 'a.y', 'a.meta', 'b.meta', ""a.meta['z']"", ""b.meta['z']"", 'get_z', 'get_meta', 'compare_z', '_values', 'wk', 'k', 'v', 'd', 'd2', 'tuples', 'c', 'cal', 'partial_f1', 'partial_f2', 'partial_f3']",29,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__doctests__', 'a', 'one', 'two', 'three', 'b', 'a.x', 'b.x', 'b.y', 'a.y', 'a.meta', 'b.meta', ""a.meta['z']"", ""b.meta['z']"", 'get_z', 'get_meta', 'compare_z', '_values', 'wk', 'k', 'v', 'd', 'd2', 'tuples', 'c', 'cal', 'partial_f1', 'partial_f2', 'partial_f3']
*Code:

1import functools
2import operator
3import unittest
4from itertools import count
5
6from scrapy.utils.python import str_to_unicode, unicode_to_str, \
7    memoizemethod_noargs, isbinarytext, equal_attributes, \
8    WeakKeyCache, stringify_dict, get_func_args
9
10__doctests__ = ['scrapy.utils.python']
11
12class UtilsPythonTestCase(unittest.TestCase):
13    def test_str_to_unicode(self):
14        # converting an utf-8 encoded string to unicode
15
16        # converting a latin-1 encoded string to unicode
17
18        # converting a unicode to unicode should return the same object
19
20        # converting a strange object should raise TypeError
21
22        # check errors argument works
23
24    def test_unicode_to_str(self):
25        # converting a unicode object to an utf-8 encoded string
26
27        # converting a unicode object to a latin-1 encoded string
28
29        # converting a regular string to string should return the same object
30
31        # converting a strange object should raise TypeError
32
33        # check errors argument works
34
35    def test_memoizemethod_noargs(self):
36        class A(object):
37
38            @memoizemethod_noargs
39            def cached(self):
40                return object()
41
42            def noncached(self):
43                return object()
44
45        a = A()
46        one = a.cached()
47        two = a.cached()
48        three = a.noncached()
49
50    def test_isbinarytext(self):
51
52        # basic tests
53
54        # utf-16 strings contain null bytes
55
56        # one with encoding
57
58        # finally some real binary bytes
59
60    def test_equal_attributes(self):
61        class Obj:
62            pass
63
64        a = Obj()
65        b = Obj()
66        # no attributes given return False
67        self.failIf(equal_attributes(a, b, []))
68        # not existent attributes
69        self.failIf(equal_attributes(a, b, ['x', 'y']))
70
71        a.x = 1
72        b.x = 1
73        # equal attribute
74
75        b.y = 2
76        # obj1 has no attribute y
77        self.failIf(equal_attributes(a, b, ['x', 'y']))
78
79        a.y = 2
80        # equal attributes
81
82        a.y = 1
83        # differente attributes
84        self.failIf(equal_attributes(a, b, ['x', 'y']))
85
86        # test callable
87        a.meta = {}
88        b.meta = {}
89
90        # compare ['meta']['a']
91        a.meta['z'] = 1
92        b.meta['z'] = 1
93
94        get_z = operator.itemgetter('z')
95        get_meta = operator.attrgetter('meta')
96        compare_z = lambda obj: get_z(get_meta(obj))
97
98        # fail z equality
99        a.meta['z'] = 2
100        self.failIf(equal_attributes(a, b, [compare_z, 'x']))
101
102    def test_weakkeycache(self):
103        class _Weakme(object): pass
104        _values = count()
105        wk = WeakKeyCache(lambda k: next(_values))
106        k = _Weakme()
107        v = wk[k]
108        del k
109
110    def test_stringify_dict(self):
111        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
112        d2 = stringify_dict(d, keys_only=False)
113        self.failIf(d is d2) # shouldn't modify in place
114        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))
115        self.failIf(any(isinstance(x, unicode) for x in d2.values()))
116
117    def test_stringify_dict_tuples(self):
118        tuples = [('a', 123), (u'b', 'c'), (u'd', u'e'), (object(), u'e')]
119        d = dict(tuples)
120        d2 = stringify_dict(tuples, keys_only=False)
121        self.failIf(d is d2) # shouldn't modify in place
122        self.failIf(any(isinstance(x, unicode) for x in d2.keys()), d2.keys())
123        self.failIf(any(isinstance(x, unicode) for x in d2.values()))
124
125    def test_stringify_dict_keys_only(self):
126        d = {'a': 123, u'b': 'c', u'd': u'e', object(): u'e'}
127        d2 = stringify_dict(d)
128        self.failIf(d is d2) # shouldn't modify in place
129        self.failIf(any(isinstance(x, unicode) for x in d2.keys()))
130
131    def test_get_func_args(self):
132        def f1(a, b, c):
133            pass
134
135        def f2(a, b=None, c=None):
136            pass
137
138        class A(object):
139            def __init__(self, a, b, c):
140                pass
141
142            def method(self, a, b, c):
143                pass
144
145        class Callable(object):
146
147            def __call__(self, a, b, c):
148                pass
149
150        a = A(1, 2, 3)
151        cal = Callable()
152        partial_f1 = functools.partial(f1, None)
153        partial_f2 = functools.partial(f1, b=None)
154        partial_f3 = functools.partial(partial_f2, None)
155
156
157        # TODO: how do we fix this to return the actual argument names?
158
159if __name__ == ""__main__"":
160    unittest.main()
161",6448,"[[45, 'a', '!=', None, 'a should be an instance of A to call methods on it'],
[46, 'one', '!=', None, 'one must not be None after calling method'],
[47, 'two', '!=', None, 'two must not be None after calling method'],
[48, 'three', '!=', None, 'three must not be None after calling method'],
[65, 'a', '!=', None, 'a should be an instance of Obj to set attributes on it'],
[66, 'b', '!=', None, 'b should be an instance of Obj to set attributes on it'],
[106, 'wk', '!=', None, 'wk must be an instance of WeakKeyCache'],
[107, 'k', '!=', None, 'k should be an instance of _Weakme to be used as a key in WeakKeyCache'],
[108, 'v', '!=', None, 'v must not be None after retrieving value from WeakKeyCache'],
[111, 'd', '!=', None, 'd should be a dictionary to test stringify_dict functions'],
[113, 'd2', '!=', None, 'stringify_dict should return a new dictionary'],
[117, 'tuples', '!=', None, 'tuples should be a list to be used in test_stringify_dict_tuples'],
[119, 'd', '!=', None, 'd should be a dictionary to test stringify_dict_tuples'],
[120, 'd2', '!=', None, 'stringify_dict should return a new dictionary when tuples passed'],
[126, 'd', '!=', None, 'd should be a dictionary to test stringify_dict_keys_only'],
[127, 'd2', '!=', None, 'stringify_dict should return a new dictionary when keys_only=True'],
[150, 'a', '!=', None, 'a should be an instance of A to be used in test_get_func_args'],
[151, 'cal', '!=', None, 'cal should be an instance of Callable to be used in test_get_func_args'],
[152, 'partial_f1', '!=', None, 'partial_f1 must not be None after partial application of f1'],
[153, 'partial_f2', '!=', None, 'partial_f2 must not be None after partial application of f1'],
[154, 'partial_f3', '!=', None, 'partial_f3 must not be None after nested partial application']]"
bartvm/gensim,"#!/usr/bin/env python
#
# Copyright (C) 2010 Radim Rehurek <radimrehurek@seznam.cz>
# Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html

""""""
USAGE: %(program)s LANGUAGE METHOD
    Generate similar.xml files, using a previously built model for METHOD.

Example: ./gensim_xml.py eng lsi
""""""


import logging
import sys
import os.path
import re


from gensim.corpora import sources, dmlcorpus, MmCorpus
from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity

import gensim_build


# set to True to do everything EXCEPT actually writing out similar.xml files to disk.
# similar.xml files are NOT written if DRY_RUN is true.
DRY_RUN = False

# how many 'most similar' documents to store in each similar.xml?
MIN_SCORE = 0.0 # prune based on similarity score (all below MIN_SCORE are ignored)
MAX_SIMILAR = 10 # prune based on rank (at most MAX_SIMILAR are stored). set to 0 to store all of them (no limit).

# if there are no similar articles (after the pruning), do we still want to generate similar.xml?
SAVE_EMPTY = True

# xml template for similar articles
ARTICLE = """"""
    <article weight=""%(score)f"">
        <authors>
            <author>%(author)s</author>
        </authors>
        <title>%(title)s</title>
        <suffix>%(suffix)s</suffix>
        <links>
            <link source=""%(source)s"" id=""%(intId)s"" path=""%(pathId)s""/>
        </links>
    </article>""""""

# template for the whole similar.xml file (will be filled with multiple ARTICLE instances)
SIMILAR = """"""\
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes"" ?>
<related>%s
</related>
""""""



def generateSimilar(corpus, index, method):
    for docNo, topSims in enumerate(index): # for each document
        # store similarities to the following file
        outfile = os.path.join(corpus.articleDir(docNo), 'similar_%s.xml' % method)

        articles = [] # collect similars in this list
        for docNo2, score in topSims: # for each most similar article
            if score > MIN_SCORE and docNo != docNo2: # if similarity is above MIN_SCORE and not identity (=always maximum similarity, boring)
                source, (intId, pathId) = corpus.documents[docNo2]
                meta = corpus.getMeta(docNo2)
                suffix, author, title = '', meta.get('author', ''), meta.get('title', '')
                articles.append(ARTICLE % locals()) # add the similar article to output
                if len(articles) >= MAX_SIMILAR:
                    break

        # now `articles` holds multiple strings in similar_*.xml format
        if SAVE_EMPTY or articles:
            output = ''.join(articles) # concat all similars to one string
            if not DRY_RUN: # only open output files for writing if DRY_RUN is false
                logging.info(""generating %s (%i similars)"" % (outfile, len(articles)))
                outfile = open(outfile, 'w')
                outfile.write(SIMILAR % output) # add xml headers and print to file
                outfile.close()
            else:
                logging.info(""would be generating %s (%i similars):%s\n"" % (outfile, len(articles), output))
        else:
            logging.debug(""skipping %s (no similar found)"" % outfile)



if __name__ == '__main__':
    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')
    logging.root.setLevel(level=logging.INFO)
    logging.info(""running %s"" % ' '.join(sys.argv))

    program = os.path.basename(sys.argv[0])

    # check and process input arguments
    if len(sys.argv) < 3:
        print(globals()['__doc__'] % locals())
        sys.exit(1)
    language = sys.argv[1]
    method = sys.argv[2].strip().lower()

    logging.info(""loading corpus mappings"")
    config = dmlcorpus.DmlConfig('%s_%s' % (gensim_build.PREFIX, language),
                                 resultDir=gensim_build.RESULT_DIR, acceptLangs=[language])

    logging.info(""loading word id mapping from %s"" % config.resultFile('wordids.txt'))
    id2word = dmlcorpus.DmlCorpus.loadDictionary(config.resultFile('wordids.txt'))
    logging.info(""loaded %i word ids"" % len(id2word))

    corpus = dmlcorpus.DmlCorpus.load(config.resultFile('.pkl'))
    input = MmCorpus(config.resultFile('_%s.mm' % method))
    assert len(input) == len(corpus), ""corpus size mismatch (%i vs %i): run ./gensim_genmodel.py again"" % (len(input), len(corpus))

     # initialize structure for similarity queries
    if method == 'lsi' or method == 'rp': # for these methods, use dense vectors
        index = MatrixSimilarity(input, numBest=MAX_SIMILAR + 1, numFeatures=input.numTerms)
    else:
        index = SparseMatrixSimilarity(input, numBest=MAX_SIMILAR + 1)

    index.normalize = False # do not normalize query vectors during similarity queries (the index is already built normalized, so it would be a no-op)
    generateSimilar(corpus, index, method) # for each document, print MAX_SIMILAR nearest documents to a xml file, in dml-cz specific format

    logging.info(""finished running %s"" % program)

","
1#!/usr/bin/env python
2#
3# Copyright (C) 2010 Radim Rehurek <radimrehurek@seznam.cz>
4# Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html
5
6""""""
7USAGE: %(program)s LANGUAGE METHOD
8    Generate similar.xml files, using a previously built model for METHOD.
9
10Example: ./gensim_xml.py eng lsi
11""""""
12
13
14import logging
15import sys
16import os.path
17import re
18
19
20from gensim.corpora import sources, dmlcorpus, MmCorpus
21from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity
22
23import gensim_build
24
25
26# set to True to do everything EXCEPT actually writing out similar.xml files to disk.
27# similar.xml files are NOT written if DRY_RUN is true.
28DRY_RUN = False
29
30# how many 'most similar' documents to store in each similar.xml?
31MIN_SCORE = 0.0 # prune based on similarity score (all below MIN_SCORE are ignored)
32MAX_SIMILAR = 10 # prune based on rank (at most MAX_SIMILAR are stored). set to 0 to store all of them (no limit).
33
34# if there are no similar articles (after the pruning), do we still want to generate similar.xml?
35SAVE_EMPTY = True
36
37# xml template for similar articles
38ARTICLE = """"""
39    <article weight=""%(score)f"">
40        <authors>
41            <author>%(author)s</author>
42        </authors>
43        <title>%(title)s</title>
44        <suffix>%(suffix)s</suffix>
45        <links>
46            <link source=""%(source)s"" id=""%(intId)s"" path=""%(pathId)s""/>
47        </links>
48    </article>""""""
49
50# template for the whole similar.xml file (will be filled with multiple ARTICLE instances)
51SIMILAR = """"""\
52<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes"" ?>
53<related>%s
54</related>
55""""""
56
57
58
59def generateSimilar(corpus, index, method):
60    for docNo, topSims in enumerate(index): # for each document
61        # store similarities to the following file
62        outfile = os.path.join(corpus.articleDir(docNo), 'similar_%s.xml' % method)
63
64        articles = [] # collect similars in this list
65        for docNo2, score in topSims: # for each most similar article
66            if score > MIN_SCORE and docNo != docNo2: # if similarity is above MIN_SCORE and not identity (=always maximum similarity, boring)
67                source, (intId, pathId) = corpus.documents[docNo2]
68                meta = corpus.getMeta(docNo2)
69                suffix, author, title = '', meta.get('author', ''), meta.get('title', '')
70                articles.append(ARTICLE % locals()) # add the similar article to output
71                if len(articles) >= MAX_SIMILAR:
72                    break
73
74        # now `articles` holds multiple strings in similar_*.xml format
75        if SAVE_EMPTY or articles:
76            output = ''.join(articles) # concat all similars to one string
77            if not DRY_RUN: # only open output files for writing if DRY_RUN is false
78                logging.info(""generating %s (%i similars)"" % (outfile, len(articles)))
79                outfile = open(outfile, 'w')
80                outfile.write(SIMILAR % output) # add xml headers and print to file
81                outfile.close()
82            else:
83                logging.info(""would be generating %s (%i similars):%s\n"" % (outfile, len(articles), output))
84        else:
85            logging.debug(""skipping %s (no similar found)"" % outfile)
86
87
88
89if __name__ == '__main__':
90    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')
91    logging.root.setLevel(level=logging.INFO)
92    logging.info(""running %s"" % ' '.join(sys.argv))
93
94    program = os.path.basename(sys.argv[0])
95
96    # check and process input arguments
97    if len(sys.argv) < 3:
98        print(globals()['__doc__'] % locals())
99        sys.exit(1)
100    language = sys.argv[1]
101    method = sys.argv[2].strip().lower()
102
103    logging.info(""loading corpus mappings"")
104    config = dmlcorpus.DmlConfig('%s_%s' % (gensim_build.PREFIX, language),
105                                 resultDir=gensim_build.RESULT_DIR, acceptLangs=[language])
106
107    logging.info(""loading word id mapping from %s"" % config.resultFile('wordids.txt'))
108    id2word = dmlcorpus.DmlCorpus.loadDictionary(config.resultFile('wordids.txt'))
109    logging.info(""loaded %i word ids"" % len(id2word))
110
111    corpus = dmlcorpus.DmlCorpus.load(config.resultFile('.pkl'))
112    input = MmCorpus(config.resultFile('_%s.mm' % method))
113
114     # initialize structure for similarity queries
115    if method == 'lsi' or method == 'rp': # for these methods, use dense vectors
116        index = MatrixSimilarity(input, numBest=MAX_SIMILAR + 1, numFeatures=input.numTerms)
117    else:
118        index = SparseMatrixSimilarity(input, numBest=MAX_SIMILAR + 1)
119
120    index.normalize = False # do not normalize query vectors during similarity queries (the index is already built normalized, so it would be a no-op)
121    generateSimilar(corpus, index, method) # for each document, print MAX_SIMILAR nearest documents to a xml file, in dml-cz specific format
122
123    logging.info(""finished running %s"" % program)
124
125","[['len(input)', '==', 'len(corpus)']]",1,1,1.0,0.0001996007984031,"['DRY_RUN', 'MIN_SCORE', 'MAX_SIMILAR', 'SAVE_EMPTY', 'ARTICLE', 'SIMILAR', 'corpus', 'index', 'method', 'outfile', 'articles', 'source', '(intId', 'pathId)', 'meta', 'suffix', 'author', 'title', 'output', 'program', 'language', 'config', 'id2word', 'input', 'index.normalize']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['DRY_RUN', 'MIN_SCORE', 'MAX_SIMILAR', 'SAVE_EMPTY', 'ARTICLE', 'SIMILAR', 'corpus', 'index', 'method', 'outfile', 'articles', 'source', '(intId', 'pathId)', 'meta', 'suffix', 'author', 'title', 'output', 'program', 'language', 'config', 'id2word', 'input', 'index.normalize']
*Code:

1#!/usr/bin/env python
2#
3# Copyright (C) 2010 Radim Rehurek <radimrehurek@seznam.cz>
4# Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html
5
6""""""
7USAGE: %(program)s LANGUAGE METHOD
8    Generate similar.xml files, using a previously built model for METHOD.
9
10Example: ./gensim_xml.py eng lsi
11""""""
12
13
14import logging
15import sys
16import os.path
17import re
18
19
20from gensim.corpora import sources, dmlcorpus, MmCorpus
21from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity
22
23import gensim_build
24
25
26# set to True to do everything EXCEPT actually writing out similar.xml files to disk.
27# similar.xml files are NOT written if DRY_RUN is true.
28DRY_RUN = False
29
30# how many 'most similar' documents to store in each similar.xml?
31MIN_SCORE = 0.0 # prune based on similarity score (all below MIN_SCORE are ignored)
32MAX_SIMILAR = 10 # prune based on rank (at most MAX_SIMILAR are stored). set to 0 to store all of them (no limit).
33
34# if there are no similar articles (after the pruning), do we still want to generate similar.xml?
35SAVE_EMPTY = True
36
37# xml template for similar articles
38ARTICLE = """"""
39    <article weight=""%(score)f"">
40        <authors>
41            <author>%(author)s</author>
42        </authors>
43        <title>%(title)s</title>
44        <suffix>%(suffix)s</suffix>
45        <links>
46            <link source=""%(source)s"" id=""%(intId)s"" path=""%(pathId)s""/>
47        </links>
48    </article>""""""
49
50# template for the whole similar.xml file (will be filled with multiple ARTICLE instances)
51SIMILAR = """"""\
52<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes"" ?>
53<related>%s
54</related>
55""""""
56
57
58
59def generateSimilar(corpus, index, method):
60    for docNo, topSims in enumerate(index): # for each document
61        # store similarities to the following file
62        outfile = os.path.join(corpus.articleDir(docNo), 'similar_%s.xml' % method)
63
64        articles = [] # collect similars in this list
65        for docNo2, score in topSims: # for each most similar article
66            if score > MIN_SCORE and docNo != docNo2: # if similarity is above MIN_SCORE and not identity (=always maximum similarity, boring)
67                source, (intId, pathId) = corpus.documents[docNo2]
68                meta = corpus.getMeta(docNo2)
69                suffix, author, title = '', meta.get('author', ''), meta.get('title', '')
70                articles.append(ARTICLE % locals()) # add the similar article to output
71                if len(articles) >= MAX_SIMILAR:
72                    break
73
74        # now `articles` holds multiple strings in similar_*.xml format
75        if SAVE_EMPTY or articles:
76            output = ''.join(articles) # concat all similars to one string
77            if not DRY_RUN: # only open output files for writing if DRY_RUN is false
78                logging.info(""generating %s (%i similars)"" % (outfile, len(articles)))
79                outfile = open(outfile, 'w')
80                outfile.write(SIMILAR % output) # add xml headers and print to file
81                outfile.close()
82            else:
83                logging.info(""would be generating %s (%i similars):%s\n"" % (outfile, len(articles), output))
84        else:
85            logging.debug(""skipping %s (no similar found)"" % outfile)
86
87
88
89if __name__ == '__main__':
90    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')
91    logging.root.setLevel(level=logging.INFO)
92    logging.info(""running %s"" % ' '.join(sys.argv))
93
94    program = os.path.basename(sys.argv[0])
95
96    # check and process input arguments
97    if len(sys.argv) < 3:
98        print(globals()['__doc__'] % locals())
99        sys.exit(1)
100    language = sys.argv[1]
101    method = sys.argv[2].strip().lower()
102
103    logging.info(""loading corpus mappings"")
104    config = dmlcorpus.DmlConfig('%s_%s' % (gensim_build.PREFIX, language),
105                                 resultDir=gensim_build.RESULT_DIR, acceptLangs=[language])
106
107    logging.info(""loading word id mapping from %s"" % config.resultFile('wordids.txt'))
108    id2word = dmlcorpus.DmlCorpus.loadDictionary(config.resultFile('wordids.txt'))
109    logging.info(""loaded %i word ids"" % len(id2word))
110
111    corpus = dmlcorpus.DmlCorpus.load(config.resultFile('.pkl'))
112    input = MmCorpus(config.resultFile('_%s.mm' % method))
113
114     # initialize structure for similarity queries
115    if method == 'lsi' or method == 'rp': # for these methods, use dense vectors
116        index = MatrixSimilarity(input, numBest=MAX_SIMILAR + 1, numFeatures=input.numTerms)
117    else:
118        index = SparseMatrixSimilarity(input, numBest=MAX_SIMILAR + 1)
119
120    index.normalize = False # do not normalize query vectors during similarity queries (the index is already built normalized, so it would be a no-op)
121    generateSimilar(corpus, index, method) # for each document, print MAX_SIMILAR nearest documents to a xml file, in dml-cz specific format
122
123    logging.info(""finished running %s"" % program)
124
125",6803,"[[28, 'DRY_RUN', '==', False, ""similar.xml files are not written if DRY_RUN is true""],
 [31, 'MIN_SCORE', '>=', 0.0, ""all similarities below MIN_SCORE are ignored""],
 [32, 'MAX_SIMILAR', '>=', 0, ""at most MAX_SIMILAR many similarities are stored. It can be 0 to store all of them, i.e., no limit""],
 [35, 'SAVE_EMPTY', '==', True, ""even if there are no similar articles (after the pruning), similar.xml files are generated when SAVE_EMPTY is true""],
 [59, 'corpus', '!=', None, ""corpus should not be None to generate the similar.xml files""],
 [59, 'index', '!=', None, ""index should not be None to generate the similar.xml files""],
 [59, 'method', '!=', None, ""method should not be None to generate the similar.xml files""],
 [70, 'articles', '>=', 0, ""the number of articles stored should be greater than or equal to 0""],
 [77, 'articles', '>=', 0, ""the number of articles stored should be greater than or equal to 0 even after concatenating all similars to one string""],
 [97, 'len(sys.argv)', '>=', 3, ""at least 3 arguments needed to run the script""],
 [106, 'language', '!=', None, ""language is needed to load corpus mappings""],
 [101, 'method', '!=', None, ""method is needed to load corpus mappings""],
 [116, 'index', '!=', None, ""for methods 'lsi' or 'rp', index needed and should not be None""],
 [118, 'index', '!=', None, ""for methods other than 'lsi' or 'rp', index needed and should not be None""],
 [120, 'index.normalize', '==', False, ""query vectors during similarity queries are not normalized""],
 [121, 'corpus', '!=', None, ""corpus needed to print nearest documents to xml file""],
 [121, 'index', '!=', None, ""index needed to print nearest documents to xml file""],
 [121, 'method', '!=', None, ""method needed to print nearest documents to xml file""]]"
beeftornado/sentry,"from __future__ import absolute_import

import itertools
import six

from django.db import IntegrityError, router, transaction
from django.db.models import Model, Q
from django.db.models.expressions import CombinedExpression
from django.db.models.signals import post_save
from six.moves import reduce

from .utils import resolve_combined_expression

__all__ = (""update"", ""create_or_update"")


def update(self, using=None, **kwargs):
    """"""
    Updates specified attributes on the current instance.
    """"""
    assert self.pk, ""Cannot update an instance that has not yet been created.""

    using = using or router.db_for_write(self.__class__, instance=self)

    for field in self._meta.fields:
        if getattr(field, ""auto_now"", False) and field.name not in kwargs:
            kwargs[field.name] = field.pre_save(self, False)

    affected = self.__class__._base_manager.using(using).filter(pk=self.pk).update(**kwargs)
    for k, v in six.iteritems(kwargs):
        if isinstance(v, CombinedExpression):
            v = resolve_combined_expression(self, v)
        setattr(self, k, v)
    if affected == 1:
        post_save.send(sender=self.__class__, instance=self, created=False)
        return affected
    elif affected == 0:
        return affected
    elif affected < 0:
        raise ValueError(
            ""Somehow we have updated a negative number of rows. You seem to have a problem with your db backend.""
        )
    else:
        raise ValueError(""Somehow we have updated multiple rows, and you are now royally fucked."")


update.alters_data = True


def create_or_update(model, using=None, **kwargs):
    """"""
    Similar to get_or_create, either updates a row or creates it.

    In order to determine if the row exists, this searches on all of the kwargs
    besides `values` and `default`.

    If the row exists, it is updated with the data in `values`. If it
    doesn't, it is created with the data in `values`, `defaults`, and the remaining
    kwargs.

    The result will be (rows affected, False) if the row was not created,
    or (instance, True) if the object is new.

    >>> create_or_update(MyModel, key='value', values={
    >>>     'col_name': F('col_name') + 1,
    >>> }, defaults={'created_at': timezone.now()})
    """"""
    values = kwargs.pop(""values"", {})
    defaults = kwargs.pop(""defaults"", {})

    if not using:
        using = router.db_for_write(model)

    objects = model.objects.using(using)

    affected = objects.filter(**kwargs).update(**values)
    if affected:
        return affected, False

    create_kwargs = kwargs.copy()
    inst = objects.model()
    for k, v in itertools.chain(six.iteritems(values), six.iteritems(defaults)):
        # XXX(dcramer): we want to support column shortcut on create so
        # we can do create_or_update(..., {'project': 1})
        if not isinstance(v, Model):
            k = model._meta.get_field(k).attname
        if isinstance(v, CombinedExpression):
            create_kwargs[k] = resolve_combined_expression(inst, v)
        else:
            create_kwargs[k] = v

    try:
        with transaction.atomic(using=using):
            return objects.create(**create_kwargs), True
    except IntegrityError:
        affected = objects.filter(**kwargs).update(**values)

    return affected, False


def in_iexact(column, values):
    """"""Operator to test if any of the given values are (case-insensitive)
       matching to values in the given column.""""""
    from operator import or_

    query = u""{}__iexact"".format(column)

    return reduce(or_, [Q(**{query: v}) for v in values])


def in_icontains(column, values):
    """"""Operator to test if any of the given values are (case-insensitively)
       contained within values in the given column.""""""
    from operator import or_

    query = u""{}__icontains"".format(column)

    return reduce(or_, [Q(**{query: v}) for v in values])
","
1from __future__ import absolute_import
2
3import itertools
4import six
5
6from django.db import IntegrityError, router, transaction
7from django.db.models import Model, Q
8from django.db.models.expressions import CombinedExpression
9from django.db.models.signals import post_save
10from six.moves import reduce
11
12from .utils import resolve_combined_expression
13
14__all__ = (""update"", ""create_or_update"")
15
16
17def update(self, using=None, **kwargs):
18    """"""
19    Updates specified attributes on the current instance.
20    """"""
21
22    using = using or router.db_for_write(self.__class__, instance=self)
23
24    for field in self._meta.fields:
25        if getattr(field, ""auto_now"", False) and field.name not in kwargs:
26            kwargs[field.name] = field.pre_save(self, False)
27
28    affected = self.__class__._base_manager.using(using).filter(pk=self.pk).update(**kwargs)
29    for k, v in six.iteritems(kwargs):
30        if isinstance(v, CombinedExpression):
31            v = resolve_combined_expression(self, v)
32        setattr(self, k, v)
33    if affected == 1:
34        post_save.send(sender=self.__class__, instance=self, created=False)
35        return affected
36    elif affected == 0:
37        return affected
38    elif affected < 0:
39        raise ValueError(
40            ""Somehow we have updated a negative number of rows. You seem to have a problem with your db backend.""
41        )
42    else:
43        raise ValueError(""Somehow we have updated multiple rows, and you are now royally fucked."")
44
45
46update.alters_data = True
47
48
49def create_or_update(model, using=None, **kwargs):
50    """"""
51    Similar to get_or_create, either updates a row or creates it.
52
53    In order to determine if the row exists, this searches on all of the kwargs
54    besides `values` and `default`.
55
56    If the row exists, it is updated with the data in `values`. If it
57    doesn't, it is created with the data in `values`, `defaults`, and the remaining
58    kwargs.
59
60    The result will be (rows affected, False) if the row was not created,
61    or (instance, True) if the object is new.
62
63    >>> create_or_update(MyModel, key='value', values={
64    >>>     'col_name': F('col_name') + 1,
65    >>> }, defaults={'created_at': timezone.now()})
66    """"""
67    values = kwargs.pop(""values"", {})
68    defaults = kwargs.pop(""defaults"", {})
69
70    if not using:
71        using = router.db_for_write(model)
72
73    objects = model.objects.using(using)
74
75    affected = objects.filter(**kwargs).update(**values)
76    if affected:
77        return affected, False
78
79    create_kwargs = kwargs.copy()
80    inst = objects.model()
81    for k, v in itertools.chain(six.iteritems(values), six.iteritems(defaults)):
82        # XXX(dcramer): we want to support column shortcut on create so
83        # we can do create_or_update(..., {'project': 1})
84        if not isinstance(v, Model):
85            k = model._meta.get_field(k).attname
86        if isinstance(v, CombinedExpression):
87            create_kwargs[k] = resolve_combined_expression(inst, v)
88        else:
89            create_kwargs[k] = v
90
91    try:
92        with transaction.atomic(using=using):
93            return objects.create(**create_kwargs), True
94    except IntegrityError:
95        affected = objects.filter(**kwargs).update(**values)
96
97    return affected, False
98
99
100def in_iexact(column, values):
101    """"""Operator to test if any of the given values are (case-insensitive)
102       matching to values in the given column.""""""
103    from operator import or_
104
105    query = u""{}__iexact"".format(column)
106
107    return reduce(or_, [Q(**{query: v}) for v in values])
108
109
110def in_icontains(column, values):
111    """"""Operator to test if any of the given values are (case-insensitively)
112       contained within values in the given column.""""""
113    from operator import or_
114
115    query = u""{}__icontains"".format(column)
116
117    return reduce(or_, [Q(**{query: v}) for v in values])
118","[['self.pk', '==', 'True']]",1,1,1.0,0.0002570694087403,"['__all__', 'using', '**kwargs', 'kwargs[field.name]', 'affected', 'v', 'update.alters_data', 'model', 'values', 'defaults', 'objects', 'create_kwargs', 'inst', 'k', 'create_kwargs[k]', 'column', 'query']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'using', '**kwargs', 'kwargs[field.name]', 'affected', 'v', 'update.alters_data', 'model', 'values', 'defaults', 'objects', 'create_kwargs', 'inst', 'k', 'create_kwargs[k]', 'column', 'query']
*Code:

1from __future__ import absolute_import
2
3import itertools
4import six
5
6from django.db import IntegrityError, router, transaction
7from django.db.models import Model, Q
8from django.db.models.expressions import CombinedExpression
9from django.db.models.signals import post_save
10from six.moves import reduce
11
12from .utils import resolve_combined_expression
13
14__all__ = (""update"", ""create_or_update"")
15
16
17def update(self, using=None, **kwargs):
18    """"""
19    Updates specified attributes on the current instance.
20    """"""
21
22    using = using or router.db_for_write(self.__class__, instance=self)
23
24    for field in self._meta.fields:
25        if getattr(field, ""auto_now"", False) and field.name not in kwargs:
26            kwargs[field.name] = field.pre_save(self, False)
27
28    affected = self.__class__._base_manager.using(using).filter(pk=self.pk).update(**kwargs)
29    for k, v in six.iteritems(kwargs):
30        if isinstance(v, CombinedExpression):
31            v = resolve_combined_expression(self, v)
32        setattr(self, k, v)
33    if affected == 1:
34        post_save.send(sender=self.__class__, instance=self, created=False)
35        return affected
36    elif affected == 0:
37        return affected
38    elif affected < 0:
39        raise ValueError(
40            ""Somehow we have updated a negative number of rows. You seem to have a problem with your db backend.""
41        )
42    else:
43        raise ValueError(""Somehow we have updated multiple rows, and you are now royally fucked."")
44
45
46update.alters_data = True
47
48
49def create_or_update(model, using=None, **kwargs):
50    """"""
51    Similar to get_or_create, either updates a row or creates it.
52
53    In order to determine if the row exists, this searches on all of the kwargs
54    besides `values` and `default`.
55
56    If the row exists, it is updated with the data in `values`. If it
57    doesn't, it is created with the data in `values`, `defaults`, and the remaining
58    kwargs.
59
60    The result will be (rows affected, False) if the row was not created,
61    or (instance, True) if the object is new.
62
63    >>> create_or_update(MyModel, key='value', values={
64    >>>     'col_name': F('col_name') + 1,
65    >>> }, defaults={'created_at': timezone.now()})
66    """"""
67    values = kwargs.pop(""values"", {})
68    defaults = kwargs.pop(""defaults"", {})
69
70    if not using:
71        using = router.db_for_write(model)
72
73    objects = model.objects.using(using)
74
75    affected = objects.filter(**kwargs).update(**values)
76    if affected:
77        return affected, False
78
79    create_kwargs = kwargs.copy()
80    inst = objects.model()
81    for k, v in itertools.chain(six.iteritems(values), six.iteritems(defaults)):
82        # XXX(dcramer): we want to support column shortcut on create so
83        # we can do create_or_update(..., {'project': 1})
84        if not isinstance(v, Model):
85            k = model._meta.get_field(k).attname
86        if isinstance(v, CombinedExpression):
87            create_kwargs[k] = resolve_combined_expression(inst, v)
88        else:
89            create_kwargs[k] = v
90
91    try:
92        with transaction.atomic(using=using):
93            return objects.create(**create_kwargs), True
94    except IntegrityError:
95        affected = objects.filter(**kwargs).update(**values)
96
97    return affected, False
98
99
100def in_iexact(column, values):
101    """"""Operator to test if any of the given values are (case-insensitive)
102       matching to values in the given column.""""""
103    from operator import or_
104
105    query = u""{}__iexact"".format(column)
106
107    return reduce(or_, [Q(**{query: v}) for v in values])
108
109
110def in_icontains(column, values):
111    """"""Operator to test if any of the given values are (case-insensitively)
112       contained within values in the given column.""""""
113    from operator import or_
114
115    query = u""{}__icontains"".format(column)
116
117    return reduce(or_, [Q(**{query: v}) for v in values])
118",5642,"[[17, '__all__', '!=', None, 'Must define __all__ variable before update function to serve as imported functions when importing module'],
 [17, 'using', '!=', None, 'The using variable should be defined before function execution'],
 [17, '**kwargs', '!=', None, 'Keyword arguments should not be None'],
 [28, 'affected', '!=', None, 'Affected variable needs to be not None after database update operation'],
 [29, 'v', '!=', None, 'The variable v should be defined as not None in key-value iteration'],
 [78, 'create_kwargs', '!=', None, 'The create_kwargs dictionary must be initiated as not None'],
 [80, 'inst', '!=', None, 'Instanced model must be not None'],
 [95, 'affected', '>=', 0, 'Affected rows on exception handling must be zero or more. Result could not be negative'],
 [100, 'column', '!=', None, 'Column name for in_iexact function must not be None'],
 [100, 'values', '!=', None, 'Values for in_iexact function must not be None'],
 [110, 'column', '!=', None, 'Column name for in_icontains function must not be None'],
 [110, 'values', '!=', None, 'Values for in_icontains function must not be None']]"
mkraemer67/pylearn2,"""""""
This script creates a preprocessed dataset of image pairs
related by the defined transformation. The content of the
images is generated with a uniform distribution, this to
to show that the gating models do not depend on the
content but only on the relations.
""""""

import itertools
import numpy
from pylearn2.datasets import preprocessing
from pylearn2.utils import serial
from pylearn2.datasets import dense_design_matrix
from pylearn2.utils.rng import make_np_rng
from pylearn2.datasets.vector_spaces_dataset import VectorSpacesDataset
from pylearn2.space import VectorSpace, CompositeSpace, Conv2DSpace


def generate(opc):
    """"""
    Summary (Generates a dataset with the chosen transformation).

    Parameters
    ----------
    opc: string
        Only two options, shifts or rotations.
    """"""
    dim = 19  # outer square
    # A bigger image is used to avoid empty pixels in the
    # borders.
    reg = 13  # inner square
    total = 20000  # Number of training examples

    im1 = numpy.zeros((total, reg, reg, 1), dtype='float32')
    im2 = numpy.zeros((total, reg, reg, 1), dtype='float32')
    Y = numpy.zeros((total, 1), dtype='uint8')
    rng = make_np_rng(9001, [1, 2, 3], which_method=""uniform"")
    transformation = opc

    if transformation == 'shifts':
        # Shifts
        # only shifts between [-3, +3] pixels
        shifts = list(itertools.product(range(-3, 4), range(-3, 4)))
        t = 0
        while t < total:
            x = rng.uniform(0, 1, (dim, dim))
            x = numpy.ceil(x * 255)
            im_x = x[3:16, 3:16][:, :, None]
            ind = rng.randint(0, len(shifts))
            Y[t] = ind
            txy = shifts[ind]
            tx, ty = txy
            im_y = x[(3 + tx):(16 + tx), (3 + ty):(16 + ty)][:, :, None]
            im1[t, :] = im_x
            im2[t, :] = im_y
            t += 1
    else:
        assert transformation == 'rotations'
        # Rotations
        import Image
        # import cv2
        angs = numpy.linspace(0, 359, 90)
        t = 0
        while t < total:
            x = rng.uniform(0, 1, (dim, dim))
            x = numpy.ceil(x * 255)
            im_x = x[3:16, 3:16][:, :, None]
            ind = rng.randint(0, len(angs))
            Y[t] = ind
            ang = angs[ind]
            y = numpy.asarray(Image.fromarray(x).rotate(ang))
            # scale = 1
            # M1 = cv2.getRotationMatrix2D((dim/2, dim/2), ang, scale)
            # y = cv2.warpAffine(x, M1, (dim, dim))
            im_y = y[3:16, 3:16][:, :, None]
            im1[t, :] = im_x
            im2[t, :] = im_y
            t += 1

    view_converter = dense_design_matrix.DefaultViewConverter((reg, reg, 1))

    design_X = view_converter.topo_view_to_design_mat(im1)
    design_Y = view_converter.topo_view_to_design_mat(im2)

    # Normalize data:
    pipeline = preprocessing.Pipeline()
    gcn = preprocessing.GlobalContrastNormalization(
        sqrt_bias=10., use_std=True)
    pipeline.items.append(gcn)
    XY = numpy.concatenate((design_X, design_Y), 0)
    XY_ImP = dense_design_matrix.DenseDesignMatrix(X=XY)
    XY_ImP.apply_preprocessor(preprocessor=pipeline, can_fit=True)

    X1 = XY_ImP.X[0:design_X.shape[0], :]
    X2 = XY_ImP.X[design_X.shape[0]:, :]

    # As a Conv2DSpace
    topo_X1 = view_converter.design_mat_to_topo_view(X1)
    topo_X2 = view_converter.design_mat_to_topo_view(X2)
    axes = ('b', 0, 1, 'c')
    data_specs = (CompositeSpace(
        [Conv2DSpace((reg, reg), num_channels=1, axes=axes),
         Conv2DSpace((reg, reg), num_channels=1, axes=axes),
         VectorSpace(1)]),
        ('featuresX', 'featuresY', 'targets'))
    train = VectorSpacesDataset((topo_X1, topo_X2, Y), data_specs=data_specs)

    # As a VectorSpace
    # data_specs = (CompositeSpace(
    # [VectorSpace(reg * reg),
    # VectorSpace(reg * reg),
    #      VectorSpace(1)]),
    #               ('featuresX', 'featuresY', 'targets'))
    # train = VectorSpacesDataset(data=(X1, X2, Y), data_specs=data_specs)

    import os

    save_path = os.path.dirname(os.path.realpath(__file__))
    serial.save(os.path.join(save_path, 'train_preprocessed.pkl'), train)

if __name__ == '__main__':
    # Define the desired transformation between views
    generate('shifts')  # shifts or rotations
","
1""""""
2This script creates a preprocessed dataset of image pairs
3related by the defined transformation. The content of the
4images is generated with a uniform distribution, this to
5to show that the gating models do not depend on the
6content but only on the relations.
7""""""
8
9import itertools
10import numpy
11from pylearn2.datasets import preprocessing
12from pylearn2.utils import serial
13from pylearn2.datasets import dense_design_matrix
14from pylearn2.utils.rng import make_np_rng
15from pylearn2.datasets.vector_spaces_dataset import VectorSpacesDataset
16from pylearn2.space import VectorSpace, CompositeSpace, Conv2DSpace
17
18
19def generate(opc):
20    """"""
21    Summary (Generates a dataset with the chosen transformation).
22
23    Parameters
24    ----------
25    opc: string
26        Only two options, shifts or rotations.
27    """"""
28    dim = 19  # outer square
29    # A bigger image is used to avoid empty pixels in the
30    # borders.
31    reg = 13  # inner square
32    total = 20000  # Number of training examples
33
34    im1 = numpy.zeros((total, reg, reg, 1), dtype='float32')
35    im2 = numpy.zeros((total, reg, reg, 1), dtype='float32')
36    Y = numpy.zeros((total, 1), dtype='uint8')
37    rng = make_np_rng(9001, [1, 2, 3], which_method=""uniform"")
38    transformation = opc
39
40    if transformation == 'shifts':
41        # Shifts
42        # only shifts between [-3, +3] pixels
43        shifts = list(itertools.product(range(-3, 4), range(-3, 4)))
44        t = 0
45        while t < total:
46            x = rng.uniform(0, 1, (dim, dim))
47            x = numpy.ceil(x * 255)
48            im_x = x[3:16, 3:16][:, :, None]
49            ind = rng.randint(0, len(shifts))
50            Y[t] = ind
51            txy = shifts[ind]
52            tx, ty = txy
53            im_y = x[(3 + tx):(16 + tx), (3 + ty):(16 + ty)][:, :, None]
54            im1[t, :] = im_x
55            im2[t, :] = im_y
56            t += 1
57    else:
58        # Rotations
59        import Image
60        # import cv2
61        angs = numpy.linspace(0, 359, 90)
62        t = 0
63        while t < total:
64            x = rng.uniform(0, 1, (dim, dim))
65            x = numpy.ceil(x * 255)
66            im_x = x[3:16, 3:16][:, :, None]
67            ind = rng.randint(0, len(angs))
68            Y[t] = ind
69            ang = angs[ind]
70            y = numpy.asarray(Image.fromarray(x).rotate(ang))
71            # scale = 1
72            # M1 = cv2.getRotationMatrix2D((dim/2, dim/2), ang, scale)
73            # y = cv2.warpAffine(x, M1, (dim, dim))
74            im_y = y[3:16, 3:16][:, :, None]
75            im1[t, :] = im_x
76            im2[t, :] = im_y
77            t += 1
78
79    view_converter = dense_design_matrix.DefaultViewConverter((reg, reg, 1))
80
81    design_X = view_converter.topo_view_to_design_mat(im1)
82    design_Y = view_converter.topo_view_to_design_mat(im2)
83
84    # Normalize data:
85    pipeline = preprocessing.Pipeline()
86    gcn = preprocessing.GlobalContrastNormalization(
87        sqrt_bias=10., use_std=True)
88    pipeline.items.append(gcn)
89    XY = numpy.concatenate((design_X, design_Y), 0)
90    XY_ImP = dense_design_matrix.DenseDesignMatrix(X=XY)
91    XY_ImP.apply_preprocessor(preprocessor=pipeline, can_fit=True)
92
93    X1 = XY_ImP.X[0:design_X.shape[0], :]
94    X2 = XY_ImP.X[design_X.shape[0]:, :]
95
96    # As a Conv2DSpace
97    topo_X1 = view_converter.design_mat_to_topo_view(X1)
98    topo_X2 = view_converter.design_mat_to_topo_view(X2)
99    axes = ('b', 0, 1, 'c')
100    data_specs = (CompositeSpace(
101        [Conv2DSpace((reg, reg), num_channels=1, axes=axes),
102         Conv2DSpace((reg, reg), num_channels=1, axes=axes),
103         VectorSpace(1)]),
104        ('featuresX', 'featuresY', 'targets'))
105    train = VectorSpacesDataset((topo_X1, topo_X2, Y), data_specs=data_specs)
106
107    # As a VectorSpace
108    # data_specs = (CompositeSpace(
109    # [VectorSpace(reg * reg),
110    # VectorSpace(reg * reg),
111    #      VectorSpace(1)]),
112    #               ('featuresX', 'featuresY', 'targets'))
113    # train = VectorSpacesDataset(data=(X1, X2, Y), data_specs=data_specs)
114
115    import os
116
117    save_path = os.path.dirname(os.path.realpath(__file__))
118    serial.save(os.path.join(save_path, 'train_preprocessed.pkl'), train)
119
120if __name__ == '__main__':
121    # Define the desired transformation between views
122    generate('shifts')  # shifts or rotations
123","[['transformation', '==', ""'rotations'""]]",1,1,1.0,0.0002335902826442,"['opc', 'dim', 'reg', 'total', 'im1', 'im2', 'Y', 'rng', 'transformation', 'shifts', 't', 'x', 'im_x', 'ind', 'Y[t]', 'txy', 'tx', 'ty', 'im_y', 'im1[t', ':]', 'im2[t', 'angs', 'ang', 'y', '# scale', '# M1', '# y', 'view_converter', 'design_X', 'design_Y', 'pipeline', 'gcn', 'XY', 'XY_ImP', 'X1', 'X2', 'topo_X1', 'topo_X2', 'axes', 'data_specs', 'train', '# data_specs', '# train', 'save_path']",45,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['opc', 'dim', 'reg', 'total', 'im1', 'im2', 'Y', 'rng', 'transformation', 'shifts', 't', 'x', 'im_x', 'ind', 'Y[t]', 'txy', 'tx', 'ty', 'im_y', 'im1[t', ':]', 'im2[t', 'angs', 'ang', 'y', '# scale', '# M1', '# y', 'view_converter', 'design_X', 'design_Y', 'pipeline', 'gcn', 'XY', 'XY_ImP', 'X1', 'X2', 'topo_X1', 'topo_X2', 'axes', 'data_specs', 'train', '# data_specs', '# train', 'save_path']
*Code:

1""""""
2This script creates a preprocessed dataset of image pairs
3related by the defined transformation. The content of the
4images is generated with a uniform distribution, this to
5to show that the gating models do not depend on the
6content but only on the relations.
7""""""
8
9import itertools
10import numpy
11from pylearn2.datasets import preprocessing
12from pylearn2.utils import serial
13from pylearn2.datasets import dense_design_matrix
14from pylearn2.utils.rng import make_np_rng
15from pylearn2.datasets.vector_spaces_dataset import VectorSpacesDataset
16from pylearn2.space import VectorSpace, CompositeSpace, Conv2DSpace
17
18
19def generate(opc):
20    """"""
21    Summary (Generates a dataset with the chosen transformation).
22
23    Parameters
24    ----------
25    opc: string
26        Only two options, shifts or rotations.
27    """"""
28    dim = 19  # outer square
29    # A bigger image is used to avoid empty pixels in the
30    # borders.
31    reg = 13  # inner square
32    total = 20000  # Number of training examples
33
34    im1 = numpy.zeros((total, reg, reg, 1), dtype='float32')
35    im2 = numpy.zeros((total, reg, reg, 1), dtype='float32')
36    Y = numpy.zeros((total, 1), dtype='uint8')
37    rng = make_np_rng(9001, [1, 2, 3], which_method=""uniform"")
38    transformation = opc
39
40    if transformation == 'shifts':
41        # Shifts
42        # only shifts between [-3, +3] pixels
43        shifts = list(itertools.product(range(-3, 4), range(-3, 4)))
44        t = 0
45        while t < total:
46            x = rng.uniform(0, 1, (dim, dim))
47            x = numpy.ceil(x * 255)
48            im_x = x[3:16, 3:16][:, :, None]
49            ind = rng.randint(0, len(shifts))
50            Y[t] = ind
51            txy = shifts[ind]
52            tx, ty = txy
53            im_y = x[(3 + tx):(16 + tx), (3 + ty):(16 + ty)][:, :, None]
54            im1[t, :] = im_x
55            im2[t, :] = im_y
56            t += 1
57    else:
58        # Rotations
59        import Image
60        # import cv2
61        angs = numpy.linspace(0, 359, 90)
62        t = 0
63        while t < total:
64            x = rng.uniform(0, 1, (dim, dim))
65            x = numpy.ceil(x * 255)
66            im_x = x[3:16, 3:16][:, :, None]
67            ind = rng.randint(0, len(angs))
68            Y[t] = ind
69            ang = angs[ind]
70            y = numpy.asarray(Image.fromarray(x).rotate(ang))
71            # scale = 1
72            # M1 = cv2.getRotationMatrix2D((dim/2, dim/2), ang, scale)
73            # y = cv2.warpAffine(x, M1, (dim, dim))
74            im_y = y[3:16, 3:16][:, :, None]
75            im1[t, :] = im_x
76            im2[t, :] = im_y
77            t += 1
78
79    view_converter = dense_design_matrix.DefaultViewConverter((reg, reg, 1))
80
81    design_X = view_converter.topo_view_to_design_mat(im1)
82    design_Y = view_converter.topo_view_to_design_mat(im2)
83
84    # Normalize data:
85    pipeline = preprocessing.Pipeline()
86    gcn = preprocessing.GlobalContrastNormalization(
87        sqrt_bias=10., use_std=True)
88    pipeline.items.append(gcn)
89    XY = numpy.concatenate((design_X, design_Y), 0)
90    XY_ImP = dense_design_matrix.DenseDesignMatrix(X=XY)
91    XY_ImP.apply_preprocessor(preprocessor=pipeline, can_fit=True)
92
93    X1 = XY_ImP.X[0:design_X.shape[0], :]
94    X2 = XY_ImP.X[design_X.shape[0]:, :]
95
96    # As a Conv2DSpace
97    topo_X1 = view_converter.design_mat_to_topo_view(X1)
98    topo_X2 = view_converter.design_mat_to_topo_view(X2)
99    axes = ('b', 0, 1, 'c')
100    data_specs = (CompositeSpace(
101        [Conv2DSpace((reg, reg), num_channels=1, axes=axes),
102         Conv2DSpace((reg, reg), num_channels=1, axes=axes),
103         VectorSpace(1)]),
104        ('featuresX', 'featuresY', 'targets'))
105    train = VectorSpacesDataset((topo_X1, topo_X2, Y), data_specs=data_specs)
106
107    # As a VectorSpace
108    # data_specs = (CompositeSpace(
109    # [VectorSpace(reg * reg),
110    # VectorSpace(reg * reg),
111    #      VectorSpace(1)]),
112    #               ('featuresX', 'featuresY', 'targets'))
113    # train = VectorSpacesDataset(data=(X1, X2, Y), data_specs=data_specs)
114
115    import os
116
117    save_path = os.path.dirname(os.path.realpath(__file__))
118    serial.save(os.path.join(save_path, 'train_preprocessed.pkl'), train)
119
120if __name__ == '__main__':
121    # Define the desired transformation between views
122    generate('shifts')  # shifts or rotations
123",6274,"[[33, 'total', '==', 20000, 'Total is fixed to 20000 for number of training examples'], [34, 'im1', '==', [20000, 13, 13, 1], 'arrangement of array should be of the specified size'], [35, 'im2', '==', [20000, 13, 13, 1], 'arrangement of array should be of the specified size'], [36, 'Y', '==', [20000, 1], 'arrangement of array should be of the specified size'], [45, 't', '<=', 'total', 't should never exceed the total'], [49, 'ind', '<', 'len(shifts)', 'Index should not be greater than total length of shifts'], [63, 't', '<=', 'total', 't should not exceed the total'], [67, 'ind', '<', 'len(angs)', 'Index should not be greater than total elements in angs'], [94, 'X1', '==', 'design_X.shape[0]', 'Matrix X1 should have shape equals to design_X'], [95, 'X2', '==', 'design_Y.shape[0]', 'Matrix X2 should have shape equals to design_Y']]"
algorhythms/LintCode,"""""""
Given a list of non negative integers, arrange them such that they form the largest number.

Example
Given [1, 20, 23, 4, 8], the largest formed number is 8423201.
""""""
__author__ = 'Daniel'


class Solution:
    def largestNumber(self, nums):
        """"""
        Start off by enumerate simple examples

        Compare digit by digit
        The comparator is the core.

        :type nums: list[int]
        :rtype: str
        """"""
        nums = map(str, nums)
        nums.sort(cmp=self.cmp, reverse=True)
        nums = """".join(nums)
        nums = nums.lstrip(""0"")
        if not nums:
            nums = ""0""
        return nums

    def cmp(self, a, b):
        """"""
        :type a: str
        :type b: str
        :rtype: int
        """"""
        order = 1
        if len(a) > len(b):
            order = -1
            a, b = b, a

        for i in xrange(len(a)):
            if int(a[i]) != int(b[i]):
                return order*(int(a[i])-int(b[i]))

        if len(a) == len(b):
            return 0

        return order*self.cmp(a, b[len(a):])


if __name__ == ""__main__"":
    assert Solution().largestNumber([0, 0]) == ""0""
    assert Solution().largestNumber([1, 20, 23, 4, 8]) == ""8423201""","
1""""""
2Given a list of non negative integers, arrange them such that they form the largest number.
3
4Example
5Given [1, 20, 23, 4, 8], the largest formed number is 8423201.
6""""""
7__author__ = 'Daniel'
8
9
10class Solution:
11    def largestNumber(self, nums):
12        """"""
13        Start off by enumerate simple examples
14
15        Compare digit by digit
16        The comparator is the core.
17
18        :type nums: list[int]
19        :rtype: str
20        """"""
21        nums = map(str, nums)
22        nums.sort(cmp=self.cmp, reverse=True)
23        nums = """".join(nums)
24        nums = nums.lstrip(""0"")
25        if not nums:
26            nums = ""0""
27        return nums
28
29    def cmp(self, a, b):
30        """"""
31        :type a: str
32        :type b: str
33        :rtype: int
34        """"""
35        order = 1
36        if len(a) > len(b):
37            order = -1
38            a, b = b, a
39
40        for i in xrange(len(a)):
41            if int(a[i]) != int(b[i]):
42                return order*(int(a[i])-int(b[i]))
43
44        if len(a) == len(b):
45            return 0
46
47        return order*self.cmp(a, b[len(a):])
48
49
50if __name__ == ""__main__"":","[['Solution().largestNumber([0', '==', 'True'], ['Solution().largestNumber([1', '==', 'True']]",2,2,1.0,0.0016515276630883,"['__author__', 'nums', 'a', 'b', 'order']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'nums', 'a', 'b', 'order']
*Code:

1""""""
2Given a list of non negative integers, arrange them such that they form the largest number.
3
4Example
5Given [1, 20, 23, 4, 8], the largest formed number is 8423201.
6""""""
7__author__ = 'Daniel'
8
9
10class Solution:
11    def largestNumber(self, nums):
12        """"""
13        Start off by enumerate simple examples
14
15        Compare digit by digit
16        The comparator is the core.
17
18        :type nums: list[int]
19        :rtype: str
20        """"""
21        nums = map(str, nums)
22        nums.sort(cmp=self.cmp, reverse=True)
23        nums = """".join(nums)
24        nums = nums.lstrip(""0"")
25        if not nums:
26            nums = ""0""
27        return nums
28
29    def cmp(self, a, b):
30        """"""
31        :type a: str
32        :type b: str
33        :rtype: int
34        """"""
35        order = 1
36        if len(a) > len(b):
37            order = -1
38            a, b = b, a
39
40        for i in xrange(len(a)):
41            if int(a[i]) != int(b[i]):
42                return order*(int(a[i])-int(b[i]))
43
44        if len(a) == len(b):
45            return 0
46
47        return order*self.cmp(a, b[len(a):])
48
49
50if __name__ == ""__main__"":",2605,"[[11, 'nums', '!=', None, ""Ensure the function receives necessary input""],
 [25, 'nums', '!=', '', ""Assertion to ensure the resulting number is not an empty string""],
 [35, 'order', '==', 1, ""Ensure order is correctly initialized""],
 [36, 'a', '>=', 'b', ""Ensure a and b are ordered correctly""]]"
fabioticconi/scikit-learn,"# Author: Brian M. Clapper, G Varoquaux
# License: BSD

import numpy as np

# XXX we should be testing the public API here
from sklearn.utils.linear_assignment_ import _hungarian


def test_hungarian():
    matrices = [
        # Square
        ([[400, 150, 400],
          [400, 450, 600],
          [300, 225, 300]],
         850  # expected cost
         ),

        # Rectangular variant
        ([[400, 150, 400, 1],
          [400, 450, 600, 2],
          [300, 225, 300, 3]],
         452  # expected cost
         ),

        # Square
        ([[10, 10,  8],
          [9,  8,  1],
          [9,  7,  4]],
         18
         ),

        # Rectangular variant
        ([[10, 10,  8, 11],
          [9, 8, 1, 1],
          [9, 7, 4, 10]],
         15
         ),

        # n == 2, m == 0 matrix
        ([[], []],
         0
         ),
    ]

    for cost_matrix, expected_total in matrices:
        cost_matrix = np.array(cost_matrix)
        indexes = _hungarian(cost_matrix)
        total_cost = 0
        for r, c in indexes:
            x = cost_matrix[r, c]
            total_cost += x
        assert expected_total == total_cost

        indexes = _hungarian(cost_matrix.T)
        total_cost = 0
        for c, r in indexes:
            x = cost_matrix[r, c]
            total_cost += x
        assert expected_total == total_cost
","
1# Author: Brian M. Clapper, G Varoquaux
2# License: BSD
3
4import numpy as np
5
6# XXX we should be testing the public API here
7from sklearn.utils.linear_assignment_ import _hungarian
8
9
10def test_hungarian():
11    matrices = [
12        # Square
13        ([[400, 150, 400],
14          [400, 450, 600],
15          [300, 225, 300]],
16         850  # expected cost
17         ),
18
19        # Rectangular variant
20        ([[400, 150, 400, 1],
21          [400, 450, 600, 2],
22          [300, 225, 300, 3]],
23         452  # expected cost
24         ),
25
26        # Square
27        ([[10, 10,  8],
28          [9,  8,  1],
29          [9,  7,  4]],
30         18
31         ),
32
33        # Rectangular variant
34        ([[10, 10,  8, 11],
35          [9, 8, 1, 1],
36          [9, 7, 4, 10]],
37         15
38         ),
39
40        # n == 2, m == 0 matrix
41        ([[], []],
42         0
43         ),
44    ]
45
46    for cost_matrix, expected_total in matrices:
47        cost_matrix = np.array(cost_matrix)
48        indexes = _hungarian(cost_matrix)
49        total_cost = 0
50        for r, c in indexes:
51            x = cost_matrix[r, c]
52            total_cost += x
53
54        indexes = _hungarian(cost_matrix.T)
55        total_cost = 0
56        for c, r in indexes:
57            x = cost_matrix[r, c]
58            total_cost += x
59","[['expected_total', '==', 'total_cost'], ['expected_total', '==', 'total_cost']]",2,2,1.0,0.0014825796886582,"['matrices', 'cost_matrix', 'indexes', 'total_cost', 'x']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['matrices', 'cost_matrix', 'indexes', 'total_cost', 'x']
*Code:

1# Author: Brian M. Clapper, G Varoquaux
2# License: BSD
3
4import numpy as np
5
6# XXX we should be testing the public API here
7from sklearn.utils.linear_assignment_ import _hungarian
8
9
10def test_hungarian():
11    matrices = [
12        # Square
13        ([[400, 150, 400],
14          [400, 450, 600],
15          [300, 225, 300]],
16         850  # expected cost
17         ),
18
19        # Rectangular variant
20        ([[400, 150, 400, 1],
21          [400, 450, 600, 2],
22          [300, 225, 300, 3]],
23         452  # expected cost
24         ),
25
26        # Square
27        ([[10, 10,  8],
28          [9,  8,  1],
29          [9,  7,  4]],
30         18
31         ),
32
33        # Rectangular variant
34        ([[10, 10,  8, 11],
35          [9, 8, 1, 1],
36          [9, 7, 4, 10]],
37         15
38         ),
39
40        # n == 2, m == 0 matrix
41        ([[], []],
42         0
43         ),
44    ]
45
46    for cost_matrix, expected_total in matrices:
47        cost_matrix = np.array(cost_matrix)
48        indexes = _hungarian(cost_matrix)
49        total_cost = 0
50        for r, c in indexes:
51            x = cost_matrix[r, c]
52            total_cost += x
53
54        indexes = _hungarian(cost_matrix.T)
55        total_cost = 0
56        for c, r in indexes:
57            x = cost_matrix[r, c]
58            total_cost += x
59",2808,"[[10, 'matrices', '!=', [], ""matrices should not be empty as this is the main input of the function""],
[46, 'cost_matrix', '!=', [], ""cost_matrix should not be empty because it's derived from matrices and used in the function""],
[52, 'total_cost', '>=', 0, ""total cost should always be zero or more""],
[54, 'indexes', '!=', [], ""indexes should not be empty because it's used in the function""]]"
jamesblunt/sympy,"from sympy.matrices.sparsetools import _doktocsr, _csrtodok
from sympy import SparseMatrix


def test_doktocsr():
    a = SparseMatrix([[1, 2, 0, 0], [0, 3, 9, 0], [0, 1, 4, 0]])
    b = SparseMatrix(4, 6, [10, 20, 0, 0, 0, 0, 0, 30, 0, 40, 0, 0, 0, 0, 50,
        60, 70, 0, 0, 0, 0, 0, 0, 80])
    c = SparseMatrix(4, 4, [0, 0, 0, 0, 0, 12, 0, 2, 15, 0, 12, 0, 0, 0, 0, 4])
    d = SparseMatrix(10, 10, {(1, 1): 12, (3, 5): 7, (7, 8): 12})
    e = SparseMatrix([[0, 0, 0], [1, 0, 2], [3, 0, 0]])
    f = SparseMatrix(7, 8, {(2, 3): 5, (4, 5):12})
    assert _doktocsr(a) == [[1, 2, 3, 9, 1, 4], [0, 1, 1, 2, 1, 2],
        [0, 2, 4, 6], [3, 4]]
    assert _doktocsr(b) == [[10, 20, 30, 40, 50, 60, 70, 80],
        [0, 1, 1, 3, 2, 3, 4, 5], [0, 2, 4, 7, 8], [4, 6]]
    assert _doktocsr(c) == [[12, 2, 15, 12, 4], [1, 3, 0, 2, 3],
        [0, 0, 2, 4, 5], [4, 4]]
    assert _doktocsr(d) == [[12, 7, 12], [1, 5, 8],
        [0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3], [10, 10]]
    assert _doktocsr(e) == [[1, 2, 3], [0, 2, 0], [0, 0, 2, 3], [3, 3]]
    assert _doktocsr(f) == [[5, 12], [3, 5], [0, 0, 0, 1, 1, 2, 2, 2], [7, 8]]


def test_csrtodok():
    h = [[5, 7, 5], [2, 1, 3], [0, 1, 1, 3], [3, 4]]
    g = [[12, 5, 4], [2, 4, 2], [0, 1, 2, 3], [3, 7]]
    i = [[1, 3, 12], [0, 2, 4], [0, 2, 3], [2, 5]]
    j = [[11, 15, 12, 15], [2, 4, 1, 2], [0, 1, 1, 2, 3, 4], [5, 8]]
    k = [[1, 3], [2, 1], [0, 1, 1, 2], [3, 3]]
    assert _csrtodok(h) == SparseMatrix(3, 4,
        {(0, 2): 5, (2, 1): 7, (2, 3): 5})
    assert _csrtodok(g) == SparseMatrix(3, 7,
        {(0, 2): 12, (1, 4): 5, (2, 2): 4})
    assert _csrtodok(i) == SparseMatrix([[1, 0, 3, 0, 0], [0, 0, 0, 0, 12]])
    assert _csrtodok(j) == SparseMatrix(5, 8,
        {(0, 2): 11, (2, 4): 15, (3, 1): 12, (4, 2): 15})
    assert _csrtodok(k) == SparseMatrix(3, 3, {(0, 2): 1, (2, 1): 3})
","
1from sympy.matrices.sparsetools import _doktocsr, _csrtodok
2from sympy import SparseMatrix
3
4
5def test_doktocsr():
6    a = SparseMatrix([[1, 2, 0, 0], [0, 3, 9, 0], [0, 1, 4, 0]])
7    b = SparseMatrix(4, 6, [10, 20, 0, 0, 0, 0, 0, 30, 0, 40, 0, 0, 0, 0, 50,
8        60, 70, 0, 0, 0, 0, 0, 0, 80])
9    c = SparseMatrix(4, 4, [0, 0, 0, 0, 0, 12, 0, 2, 15, 0, 12, 0, 0, 0, 0, 4])
10    d = SparseMatrix(10, 10, {(1, 1): 12, (3, 5): 7, (7, 8): 12})
11    e = SparseMatrix([[0, 0, 0], [1, 0, 2], [3, 0, 0]])
12    f = SparseMatrix(7, 8, {(2, 3): 5, (4, 5):12})
13        [0, 2, 4, 6], [3, 4]]
14        [0, 1, 1, 3, 2, 3, 4, 5], [0, 2, 4, 7, 8], [4, 6]]
15        [0, 0, 2, 4, 5], [4, 4]]
16        [0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3], [10, 10]]
17
18
19def test_csrtodok():
20    h = [[5, 7, 5], [2, 1, 3], [0, 1, 1, 3], [3, 4]]
21    g = [[12, 5, 4], [2, 4, 2], [0, 1, 2, 3], [3, 7]]
22    i = [[1, 3, 12], [0, 2, 4], [0, 2, 3], [2, 5]]
23    j = [[11, 15, 12, 15], [2, 4, 1, 2], [0, 1, 1, 2, 3, 4], [5, 8]]
24    k = [[1, 3], [2, 1], [0, 1, 1, 2], [3, 3]]
25        {(0, 2): 5, (2, 1): 7, (2, 3): 5})
26        {(0, 2): 12, (1, 4): 5, (2, 2): 4})
27        {(0, 2): 11, (2, 4): 15, (3, 1): 12, (4, 2): 15})
28","[['_doktocsr(a)', '==', '[[1'], ['_doktocsr(b)', '==', '[[10'], ['_doktocsr(c)', '==', '[[12'], ['_doktocsr(d)', '==', '[[12'], ['_doktocsr(e)', '==', '[[1'], ['_doktocsr(f)', '==', '[[5'], ['_csrtodok(h)', '==', 'SparseMatrix(3'], ['_csrtodok(g)', '==', 'SparseMatrix(3'], ['_csrtodok(i)', '==', 'SparseMatrix([[1'], ['_csrtodok(j)', '==', 'SparseMatrix(5'], ['_csrtodok(k)', '==', 'SparseMatrix(3']]",11,11,1.0,0.0059491617090319,"['a', 'b', 'c', 'd', 'e', 'f', 'h', 'g', 'i', 'j', 'k']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['a', 'b', 'c', 'd', 'e', 'f', 'h', 'g', 'i', 'j', 'k']
*Code:

1from sympy.matrices.sparsetools import _doktocsr, _csrtodok
2from sympy import SparseMatrix
3
4
5def test_doktocsr():
6    a = SparseMatrix([[1, 2, 0, 0], [0, 3, 9, 0], [0, 1, 4, 0]])
7    b = SparseMatrix(4, 6, [10, 20, 0, 0, 0, 0, 0, 30, 0, 40, 0, 0, 0, 0, 50,
8        60, 70, 0, 0, 0, 0, 0, 0, 80])
9    c = SparseMatrix(4, 4, [0, 0, 0, 0, 0, 12, 0, 2, 15, 0, 12, 0, 0, 0, 0, 4])
10    d = SparseMatrix(10, 10, {(1, 1): 12, (3, 5): 7, (7, 8): 12})
11    e = SparseMatrix([[0, 0, 0], [1, 0, 2], [3, 0, 0]])
12    f = SparseMatrix(7, 8, {(2, 3): 5, (4, 5):12})
13        [0, 2, 4, 6], [3, 4]]
14        [0, 1, 1, 3, 2, 3, 4, 5], [0, 2, 4, 7, 8], [4, 6]]
15        [0, 0, 2, 4, 5], [4, 4]]
16        [0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3], [10, 10]]
17
18
19def test_csrtodok():
20    h = [[5, 7, 5], [2, 1, 3], [0, 1, 1, 3], [3, 4]]
21    g = [[12, 5, 4], [2, 4, 2], [0, 1, 2, 3], [3, 7]]
22    i = [[1, 3, 12], [0, 2, 4], [0, 2, 3], [2, 5]]
23    j = [[11, 15, 12, 15], [2, 4, 1, 2], [0, 1, 1, 2, 3, 4], [5, 8]]
24    k = [[1, 3], [2, 1], [0, 1, 1, 2], [3, 3]]
25        {(0, 2): 5, (2, 1): 7, (2, 3): 5})
26        {(0, 2): 12, (1, 4): 5, (2, 2): 4})
27        {(0, 2): 11, (2, 4): 15, (3, 1): 12, (4, 2): 15})
28",2649,"[[6, 'a', '==', 4, ""The variable 'a' should be of size 4""],
[8, 'b', '==', 4, ""The variable 'b' should be of size 4""],
[9, 'c', '==', 4, ""The variable 'c' should be of size 4""],
[10, 'd', '==', 10, ""The variable 'd' should be of size 10""],
[11, 'e', '==', 3, ""The variable 'e' should be of size 3""],
[12, 'f', '==', 7, ""The variable 'f' should be of size 7""],
[20, 'h', '==', 4, ""The variable 'h' should be of size 4""],
[21, 'g', '==', 4, ""The variable 'g' should be of size 4""],
[22, 'i', '==', 4, ""The variable 'i' should be of size 4""],
[23, 'j', '==', 4, ""The variable 'j' should be of size 4""],
[24, 'k', '==', 4, ""The variable 'k' should be of size 4""]]"
project-rig/rig,"""""""Test the discover command.""""""

import pytest

from rig.scripts import rig_discover

from mock import Mock


@pytest.mark.parametrize(""should_work"", [True, False])
@pytest.mark.parametrize(""args,timeout"", [("""", 6.0), (""-t 100.5"", 100.5)])
def test_rig_discover(args, should_work, timeout, monkeypatch, capsys):
    if should_work:
        mock_listen = Mock(return_value=""127.0.0.1"")
    else:
        mock_listen = Mock(return_value=None)
    monkeypatch.setattr(rig_discover, ""listen"", mock_listen)

    assert rig_discover.main(args.split()) == int(not should_work)

    out, err = capsys.readouterr()
    if should_work:
        assert out == ""127.0.0.1\n""
    else:
        assert out == """"

    assert mock_listen.called_once_with(timeout)
","
1""""""Test the discover command.""""""
2
3import pytest
4
5from rig.scripts import rig_discover
6
7from mock import Mock
8
9
10@pytest.mark.parametrize(""should_work"", [True, False])
11@pytest.mark.parametrize(""args,timeout"", [("""", 6.0), (""-t 100.5"", 100.5)])
12def test_rig_discover(args, should_work, timeout, monkeypatch, capsys):
13    if should_work:
14        mock_listen = Mock(return_value=""127.0.0.1"")
15    else:
16        mock_listen = Mock(return_value=None)
17    monkeypatch.setattr(rig_discover, ""listen"", mock_listen)
18
19
20    out, err = capsys.readouterr()
21    if should_work:
22    else:
23
24","[['rig_discover.main(args.split())', '==', 'int(not should_work)'], ['out', '==', '""127.0.0.1\\n""'], ['out', '==', '""""'], ['mock_listen.called_once_with(timeout)', '==', 'True']]",4,4,1.0,0.0053475935828877,"['args', 'should_work', 'timeout', 'monkeypatch', 'capsys', 'mock_listen', 'out', 'err']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['args', 'should_work', 'timeout', 'monkeypatch', 'capsys', 'mock_listen', 'out', 'err']
*Code:

1""""""Test the discover command.""""""
2
3import pytest
4
5from rig.scripts import rig_discover
6
7from mock import Mock
8
9
10@pytest.mark.parametrize(""should_work"", [True, False])
11@pytest.mark.parametrize(""args,timeout"", [("""", 6.0), (""-t 100.5"", 100.5)])
12def test_rig_discover(args, should_work, timeout, monkeypatch, capsys):
13    if should_work:
14        mock_listen = Mock(return_value=""127.0.0.1"")
15    else:
16        mock_listen = Mock(return_value=None)
17    monkeypatch.setattr(rig_discover, ""listen"", mock_listen)
18
19
20    out, err = capsys.readouterr()
21    if should_work:
22    else:
23
24",2079,"[[11, 'args', '!=', '', ""args should not be empty""],
 [11, 'timeout', '>=', 6.0, ""timeout should be at least 6.0""],
 [13, 'should_work', '==', True, ""should_work should be a boolean""],
 [14, 'mock_listen', '!=', None, ""mock_listen return value should not be None when should_work is True""],
 [16, 'mock_listen', '==', None, ""mock_listen return value should be None when should_work is False""],
 [20, 'out', '==', '', ""initial output should be empty""],
 [20, 'err', '==', '', ""initial error should be empty""]]"
hachreak/zenodo,"# -*- coding: utf-8 -*-
#
# This file is part of Invenio.
# Copyright (C) 2016 CERN.
#
# Invenio is free software; you can redistribute it
# and/or modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation; either version 2 of the
# License, or (at your option) any later version.
#
# Invenio is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Invenio; if not, write to the
# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
# MA 02111-1307, USA.
#
# In applying this license, CERN does not
# waive the privileges and immunities granted to it by virtue of its status
# as an Intergovernmental Organization or submit itself to any jurisdiction.


""""""Test CLI for GitHub.""""""

from __future__ import absolute_import, print_function

import pytest
from invenio_github.api import GitHubAPI


def test_hook_sync(mocker, app, cli_run, g_tester_id):
    """"""Test 'sync' CLI.""""""
    # Test with user's email
    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
    ret = cli_run('sync info@inveniosoftware.org -E')
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(hooks=False, async_hooks=False)

    # Test call with user ID
    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
    ret = cli_run('sync {0} -E'.format(g_tester_id))
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(hooks=False, async_hooks=False)

    # Test call with flags
    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
    ret = cli_run('sync info@inveniosoftware.org --hooks True'
                  ' --async-hooks=True -E')
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(hooks=True, async_hooks=True)


def test_hook_create(mocker, app, cli_run, g_users, g_repositories):
    """"""Test 'createhook' CLI.""""""
    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
    ret = cli_run('createhook u1@foo.bar foo/bar --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output.startswith('Hook is already installed for')
    assert not mock_obj.called

    repo = g_repositories[1]  # baz/spam repository
    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
    ret = cli_run('createhook u1@foo.bar baz/spam --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(repo['github_id'], repo['name'])

    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
    ret = cli_run('createhook u1@foo.bar {0} --yes-i-know -E'.format(
        repo['github_id']))
    assert ret.output == ''
    assert ret.exit_code == 0
    mock_obj.assert_called_once_with(repo['github_id'], repo['name'])


def test_hook_remove(mocker, app, cli_run, g_users, g_repositories):
    """"""Test 'removehook' CLI.""""""
    repo0 = g_repositories[0]  # foo/bar repository, owned by u1
    repo1 = g_repositories[1]  # baz/spam repository, orphaned

    # Remove hook from an 'enabled' repo without a user
    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
    ret = cli_run('removehook foo/bar --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(repo0['github_id'], repo0['name'])

    # Remove hook from an 'enabled' repo with owner specified
    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
    ret = cli_run('removehook foo/bar -u u1@foo.bar --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == ''
    mock_obj.assert_called_once_with(repo0['github_id'], repo0['name'])

    # Remove hook from an 'enabled' repo with non-owner specified
    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
    ret = cli_run('removehook foo/bar -u u2@foo.bar --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == \
        'Warning: Specified user is not the owner of this repository.\n'
    mock_obj.assert_called_once_with(repo0['github_id'], repo0['name'])

    # Remove hook from an orphaned repo without specifying a user
    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
    ret = cli_run('removehook baz/spam --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == \
        ""Repository doesn't have an owner, please specify a user.\n""
    assert not mock_obj.called

    # Remove hook from an orphaned repo with user specified
    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
    ret = cli_run('removehook baz/spam -u u1@foo.bar --yes-i-know -E')
    assert ret.exit_code == 0
    assert ret.output == 'Warning: Repository is not owned by any user.\n'
    mock_obj.assert_called_once_with(repo1['github_id'], repo1['name'])


def test_repo_list(app, cli_run, g_users, g_repositories, g_remoteaccounts):
    """"""Test 'list' CLI.""""""
    # List repos 'owned' by the user
    ret = cli_run('list u1@foo.bar -E')
    assert ret.exit_code == 0
    assert ret.output.startswith('User has 2 enabled repositories.')
    assert 'foo/bar:8000' in ret.output
    assert 'bacon/eggs:8002' in ret.output
    assert 'other/repo:8003' not in ret.output


def test_repo_assign(mocker, app, cli_run, g_users, g_repositories):
    """"""Test 'assign' CLI.""""""
    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
    ret = cli_run('assign u2@foo.bar 8000 --yes-i-know -E')
    assert ret.exit_code == 0
    rh_mock.assert_called_once_with(8000, 'foo/bar')
    ch_mock.assert_called_once_with(8000, 'foo/bar')


@pytest.mark.parametrize('u2', ['u2@foo.bar', '2'])
@pytest.mark.parametrize('r1', ['foo/bar', '8000'])
@pytest.mark.parametrize('r2', ['bacon/eggs', '8002'])
def test_repo_assign_many(mocker, r2, r1, u2, app, cli_run,
                          g_users, g_repositories):
    """"""Test 'assign' CLI.""""""
    # Make sure the 'u2' parameter is correct
    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
    assert g_users[1]['email'] == 'u2@foo.bar'
    assert g_users[1]['id'] == 2
    cmd = 'assign {0} {1} {2} --yes-i-know -E'.format(u2, r1, r2)
    ret = cli_run(cmd)
    assert ret.exit_code == 0
    rh_mock.call_count == 2
    ch_mock.call_count == 2
    rh_mock.assert_any_call(8000, 'foo/bar')
    rh_mock.assert_any_call(8002, 'bacon/eggs')
    ch_mock.assert_any_call(8000, 'foo/bar')
    ch_mock.assert_any_call(8002, 'bacon/eggs')
","
1# -*- coding: utf-8 -*-
2#
3# This file is part of Invenio.
4# Copyright (C) 2016 CERN.
5#
6# Invenio is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Invenio is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Invenio; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25
26""""""Test CLI for GitHub.""""""
27
28from __future__ import absolute_import, print_function
29
30import pytest
31from invenio_github.api import GitHubAPI
32
33
34def test_hook_sync(mocker, app, cli_run, g_tester_id):
35    """"""Test 'sync' CLI.""""""
36    # Test with user's email
37    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
38    ret = cli_run('sync info@inveniosoftware.org -E')
39
40    # Test call with user ID
41    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
42    ret = cli_run('sync {0} -E'.format(g_tester_id))
43
44    # Test call with flags
45    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
46    ret = cli_run('sync info@inveniosoftware.org --hooks True'
47                  ' --async-hooks=True -E')
48
49
50def test_hook_create(mocker, app, cli_run, g_users, g_repositories):
51    """"""Test 'createhook' CLI.""""""
52    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
53    ret = cli_run('createhook u1@foo.bar foo/bar --yes-i-know -E')
54
55    repo = g_repositories[1]  # baz/spam repository
56    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
57    ret = cli_run('createhook u1@foo.bar baz/spam --yes-i-know -E')
58
59    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
60    ret = cli_run('createhook u1@foo.bar {0} --yes-i-know -E'.format(
61        repo['github_id']))
62
63
64def test_hook_remove(mocker, app, cli_run, g_users, g_repositories):
65    """"""Test 'removehook' CLI.""""""
66    repo0 = g_repositories[0]  # foo/bar repository, owned by u1
67    repo1 = g_repositories[1]  # baz/spam repository, orphaned
68
69    # Remove hook from an 'enabled' repo without a user
70    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
71    ret = cli_run('removehook foo/bar --yes-i-know -E')
72
73    # Remove hook from an 'enabled' repo with owner specified
74    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
75    ret = cli_run('removehook foo/bar -u u1@foo.bar --yes-i-know -E')
76
77    # Remove hook from an 'enabled' repo with non-owner specified
78    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
79    ret = cli_run('removehook foo/bar -u u2@foo.bar --yes-i-know -E')
80        'Warning: Specified user is not the owner of this repository.\n'
81
82    # Remove hook from an orphaned repo without specifying a user
83    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
84    ret = cli_run('removehook baz/spam --yes-i-know -E')
85        ""Repository doesn't have an owner, please specify a user.\n""
86
87    # Remove hook from an orphaned repo with user specified
88    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
89    ret = cli_run('removehook baz/spam -u u1@foo.bar --yes-i-know -E')
90
91
92def test_repo_list(app, cli_run, g_users, g_repositories, g_remoteaccounts):
93    """"""Test 'list' CLI.""""""
94    # List repos 'owned' by the user
95    ret = cli_run('list u1@foo.bar -E')
96
97
98def test_repo_assign(mocker, app, cli_run, g_users, g_repositories):
99    """"""Test 'assign' CLI.""""""
100    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
101    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
102    ret = cli_run('assign u2@foo.bar 8000 --yes-i-know -E')
103
104
105@pytest.mark.parametrize('u2', ['u2@foo.bar', '2'])
106@pytest.mark.parametrize('r1', ['foo/bar', '8000'])
107@pytest.mark.parametrize('r2', ['bacon/eggs', '8002'])
108def test_repo_assign_many(mocker, r2, r1, u2, app, cli_run,
109                          g_users, g_repositories):
110    """"""Test 'assign' CLI.""""""
111    # Make sure the 'u2' parameter is correct
112    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
113    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
114    cmd = 'assign {0} {1} {2} --yes-i-know -E'.format(u2, r1, r2)
115    ret = cli_run(cmd)
116    rh_mock.call_count == 2
117    ch_mock.call_count == 2
118","[['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], [""ret.output.startswith('Hook"", '==', ""already installed for')""], ['mock_obj.called', '==', 'False'], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""''""], ['ret.exit_code', '==', '0'], ['ret.output', '==', '\\'], ['ret.exit_code', '==', '0'], ['ret.output', '==', '\\'], ['mock_obj.called', '==', 'False'], ['ret.exit_code', '==', '0'], ['ret.output', '==', ""'Warning: Repository is not owned by any user.\\n'""], ['ret.exit_code', '==', '0'], [""ret.output.startswith('User"", 'has', '2', 'enabled', ""repositories.')""], ['ret.exit_code', '==', '0'], [""g_users[1]['email']"", '==', ""'u2@foo.bar'""], [""g_users[1]['id']"", '==', '2'], ['ret.exit_code', '==', '0']]",48,30,0.625,0.0044749403341288,"['mocker', 'app', 'cli_run', 'g_tester_id', 'mock_obj', 'ret', 'g_users', 'g_repositories', 'repo', 'repo0', 'repo1', 'g_remoteaccounts', 'rh_mock', 'ch_mock', 'r2', 'r1', 'u2', 'cmd']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mocker', 'app', 'cli_run', 'g_tester_id', 'mock_obj', 'ret', 'g_users', 'g_repositories', 'repo', 'repo0', 'repo1', 'g_remoteaccounts', 'rh_mock', 'ch_mock', 'r2', 'r1', 'u2', 'cmd']
*Code:

1# -*- coding: utf-8 -*-
2#
3# This file is part of Invenio.
4# Copyright (C) 2016 CERN.
5#
6# Invenio is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Invenio is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Invenio; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25
26""""""Test CLI for GitHub.""""""
27
28from __future__ import absolute_import, print_function
29
30import pytest
31from invenio_github.api import GitHubAPI
32
33
34def test_hook_sync(mocker, app, cli_run, g_tester_id):
35    """"""Test 'sync' CLI.""""""
36    # Test with user's email
37    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
38    ret = cli_run('sync info@inveniosoftware.org -E')
39
40    # Test call with user ID
41    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
42    ret = cli_run('sync {0} -E'.format(g_tester_id))
43
44    # Test call with flags
45    mock_obj = mocker.patch.object(GitHubAPI, 'sync')
46    ret = cli_run('sync info@inveniosoftware.org --hooks True'
47                  ' --async-hooks=True -E')
48
49
50def test_hook_create(mocker, app, cli_run, g_users, g_repositories):
51    """"""Test 'createhook' CLI.""""""
52    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
53    ret = cli_run('createhook u1@foo.bar foo/bar --yes-i-know -E')
54
55    repo = g_repositories[1]  # baz/spam repository
56    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
57    ret = cli_run('createhook u1@foo.bar baz/spam --yes-i-know -E')
58
59    mock_obj = mocker.patch.object(GitHubAPI, 'create_hook')
60    ret = cli_run('createhook u1@foo.bar {0} --yes-i-know -E'.format(
61        repo['github_id']))
62
63
64def test_hook_remove(mocker, app, cli_run, g_users, g_repositories):
65    """"""Test 'removehook' CLI.""""""
66    repo0 = g_repositories[0]  # foo/bar repository, owned by u1
67    repo1 = g_repositories[1]  # baz/spam repository, orphaned
68
69    # Remove hook from an 'enabled' repo without a user
70    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
71    ret = cli_run('removehook foo/bar --yes-i-know -E')
72
73    # Remove hook from an 'enabled' repo with owner specified
74    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
75    ret = cli_run('removehook foo/bar -u u1@foo.bar --yes-i-know -E')
76
77    # Remove hook from an 'enabled' repo with non-owner specified
78    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
79    ret = cli_run('removehook foo/bar -u u2@foo.bar --yes-i-know -E')
80        'Warning: Specified user is not the owner of this repository.\n'
81
82    # Remove hook from an orphaned repo without specifying a user
83    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
84    ret = cli_run('removehook baz/spam --yes-i-know -E')
85        ""Repository doesn't have an owner, please specify a user.\n""
86
87    # Remove hook from an orphaned repo with user specified
88    mock_obj = mocker.patch.object(GitHubAPI, 'remove_hook')
89    ret = cli_run('removehook baz/spam -u u1@foo.bar --yes-i-know -E')
90
91
92def test_repo_list(app, cli_run, g_users, g_repositories, g_remoteaccounts):
93    """"""Test 'list' CLI.""""""
94    # List repos 'owned' by the user
95    ret = cli_run('list u1@foo.bar -E')
96
97
98def test_repo_assign(mocker, app, cli_run, g_users, g_repositories):
99    """"""Test 'assign' CLI.""""""
100    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
101    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
102    ret = cli_run('assign u2@foo.bar 8000 --yes-i-know -E')
103
104
105@pytest.mark.parametrize('u2', ['u2@foo.bar', '2'])
106@pytest.mark.parametrize('r1', ['foo/bar', '8000'])
107@pytest.mark.parametrize('r2', ['bacon/eggs', '8002'])
108def test_repo_assign_many(mocker, r2, r1, u2, app, cli_run,
109                          g_users, g_repositories):
110    """"""Test 'assign' CLI.""""""
111    # Make sure the 'u2' parameter is correct
112    rh_mock = mocker.patch.object(GitHubAPI, 'remove_hook')
113    ch_mock = mocker.patch.object(GitHubAPI, 'create_hook')
114    cmd = 'assign {0} {1} {2} --yes-i-know -E'.format(u2, r1, r2)
115    ret = cli_run(cmd)
116    rh_mock.call_count == 2
117    ch_mock.call_count == 2
118",6438,"[[34, 'mocker', '!=', None, ""the function 'test_hook_sync' requires a mocker object""],
[34, 'app', '!=', None, ""the function 'test_hook_sync' requires an app object""],
[34, 'cli_run', '!=', None, ""the function 'test_hook_sync' requires a cli_run function""],
[34, 'g_tester_id', '!=', None, ""the function 'test_hook_sync' requires a variable 'g_tester_id'""],

[50, 'mocker', '!=', None, ""the function 'test_hook_create' requires a mocker object""],
[50, 'app', '!=', None, ""the function 'test_hook_create' requires an app object""],
[50, 'cli_run', '!=', None, ""the function 'test_hook_create' requires a cli_run function""],
[50, 'g_users', '!=', None, ""the function 'test_hook_create' requires variable 'g_users'""],
[50, 'g_repositories', '!=', None, ""the function 'test_hook_create' requires variable 'g_repositories'""],

[64, 'mocker', '!=', None, ""the function 'test_hook_remove' requires a mocker object""],
[64, 'app', '!=', None, ""the function 'test_hook_remove' requires an app object""],
[64, 'cli_run', '!=', None, ""the function 'test_hook_remove' requires a cli_run function""],
[64, 'g_users', '!=', None, ""the function 'test_hook_remove' requires variable 'g_users'""],
[64, 'g_repositories', '!=', None, ""the function 'test_hook_remove' requires variable 'g_repositories'""],

[92, 'app', '!=', None, ""the function 'test_repo_list' requires an app object""],
[92, 'cli_run', '!=', None, ""the function 'test_repo_list' requires a cli_run function""],
[92, 'g_users', '!=', None, ""the function 'test_repo_list' requires variable 'g_users'""],

[98, 'mocker', '!=', None, ""the function 'test_repo_assign' requires a mocker object""],
[98, 'app', '!=', None, ""the function 'test_repo_assign' requires an app object""],
[98, 'cli_run', '!=', None, ""the function 'test_repo_assign' requires a cli_run function""],
[98, 'g_users', '!=', None, ""the function 'test_repo_assign' requires variable 'g_users'""],
[98, 'g_repositories', '!=', None, ""the function 'test_repo_assign' requires variable 'g_repositories'""]
]"
valohai/valohai-cli,"import glob
import os
import random
import re
import string
import unicodedata
import webbrowser
from typing import Any, Dict, Iterable, Iterator, Tuple, Union

import click

ansi_escape_re = re.compile(r'\x1B\[[0-?]*[ -/]*[@-~]')  # https://stackoverflow.com/a/14693789/51685
control_character_re = re.compile(r'[\x00-\x1F\x7F\x80-\x9F]')
control_characters_re = re.compile(f'{control_character_re.pattern}+')


def walk_directory_parents(dir: str) -> Iterator[str]:
    """"""
    Yield the passed directory and its parents' names, all the way up until filesystem root.

    :param dir: A directory path.
    :return: directories!
    """"""
    assert os.path.isdir(dir)
    dir = os.path.realpath(dir)
    while True:
        yield dir
        new_dir = os.path.dirname(dir)
        if dir == new_dir:  # We've reached the root!
            break
        dir = new_dir


def get_project_directory() -> str:
    dir = os.environ.get('VALOHAI_PROJECT_DIR') or os.getcwd()
    return os.path.realpath(dir)


def get_random_string(length: int = 12, keyspace: str = (string.ascii_letters + string.digits)) -> str:
    return ''.join(random.choice(keyspace) for x in range(length))


def force_text(v: Union[str, bytes], encoding: str = 'UTF-8', errors: str = 'strict') -> str:
    if isinstance(v, str):
        return v
    elif isinstance(v, bytes):
        return v.decode(encoding, errors)
    return str(v)


def force_bytes(v: Union[str, int], encoding: str = 'UTF-8', errors: str = 'strict') -> bytes:
    if isinstance(v, bytes):
        return v
    return str(v).encode(encoding, errors)


def humanize_identifier(identifier: str) -> str:
    return re.sub('[-_]+', ' ', force_text(identifier)).strip()


extension_to_interpreter: Dict[str, str] = {
    '.lua': 'lua',
    '.py': 'python',
    '.rb': 'ruby',
    '.sh': 'bash',
}


def find_scripts(directory: str) -> Iterator[Tuple[str, str]]:
    """"""
    Yield pairs of (interpreter, filename) for scripts found in `directory`.

    :param directory: Directory to look in
    :return: Pairs of interpreter and filename
    """"""
    for filename in glob.glob(os.path.join(directory, '*.*')):
        interpreter = extension_to_interpreter.get(os.path.splitext(filename.lower())[1])
        if interpreter:
            yield (interpreter, os.path.basename(filename))


def open_browser(object: Dict[str, Any], url_name: str = 'display') -> bool:
    if 'urls' not in object:
        return False
    url = object['urls'][url_name]
    click.echo(f'Opening {click.style(url, bold=True)} ...')
    webbrowser.open(url)
    return True


def subset_keys(dict: Dict[Any, Any], keys: Iterable[Any]) -> Dict[Any, Any]:
    return {key: dict[key] for key in dict if key in keys}


def clean_log_line(line: str) -> str:
    line = force_text(line)
    line = ansi_escape_re.sub('', line)
    line = control_characters_re.sub(' ', line)
    return line.strip()


def ensure_makedirs(path: str, mode: int = 0o744) -> None:
    # http://stackoverflow.com/questions/5231901/permission-problems-when-creating-a-dir-with-os-makedirs-python
    original_umask = os.umask(0)
    try:
        # only newly create directories get the defined mode
        if not os.path.exists(path):
            os.makedirs(path, mode)
        # ensure that the last directory has the right mode if it exists
        os.chmod(path, mode)
    finally:
        os.umask(original_umask)


def sanitize_filename(name: str, replacement: str = '-') -> str:
    # Via https://github.com/parshap/node-sanitize-filename/blob/0d21bf13be419fcde5bc3f241672bd29f7e72c63/index.js
    return re.sub(r'[\x00-\x1f\x80-\x9f/?<>\\:*|""]', replacement, name)


def sanitize_option_name(name: str) -> str:
    # In order to comply with `click.core.Option#_parse_decls`, this should
    # actually ensure `name` is a valid Python identifier (`s.isidentifier()`)
    # after dashes are replaced with underscores.
    #
    # However, what with Unicode letter characters being allowed for identifiers,
    # the rules for `.isidentifier` are, ah, arcane to say the least.
    #
    # Instead, we'll just fold everything down to ASCII with the good old
    # normalize-and-encode-and-decode dance, and then replace everything
    # non-alphanumeric into dashes to be safe.
    name = unicodedata.normalize('NFKD', str(name)).encode('ascii', errors='ignore').decode()
    return re.sub(r'[^-a-z0-9]+', '-', name, flags=re.IGNORECASE).strip('-')


def parse_environment_variable_strings(envvar_strings: Iterable[str]) -> Dict[str, str]:
    """"""
    Parse a list of environment variable strings into a dict.
    """"""
    environment_variables = {}
    for envstr in envvar_strings:
        key, _, value = envstr.partition('=')
        key = key.strip()
        if not key:
            continue
        environment_variables[key] = value.strip()
    return environment_variables


def compact_dict(dct: dict) -> dict:
    return {key: value for (key, value) in dct.items() if key and value}
","
1import glob
2import os
3import random
4import re
5import string
6import unicodedata
7import webbrowser
8from typing import Any, Dict, Iterable, Iterator, Tuple, Union
9
10import click
11
12ansi_escape_re = re.compile(r'\x1B\[[0-?]*[ -/]*[@-~]')  # https://stackoverflow.com/a/14693789/51685
13control_character_re = re.compile(r'[\x00-\x1F\x7F\x80-\x9F]')
14control_characters_re = re.compile(f'{control_character_re.pattern}+')
15
16
17def walk_directory_parents(dir: str) -> Iterator[str]:
18    """"""
19    Yield the passed directory and its parents' names, all the way up until filesystem root.
20
21    :param dir: A directory path.
22    :return: directories!
23    """"""
24    dir = os.path.realpath(dir)
25    while True:
26        yield dir
27        new_dir = os.path.dirname(dir)
28        if dir == new_dir:  # We've reached the root!
29            break
30        dir = new_dir
31
32
33def get_project_directory() -> str:
34    dir = os.environ.get('VALOHAI_PROJECT_DIR') or os.getcwd()
35    return os.path.realpath(dir)
36
37
38def get_random_string(length: int = 12, keyspace: str = (string.ascii_letters + string.digits)) -> str:
39    return ''.join(random.choice(keyspace) for x in range(length))
40
41
42def force_text(v: Union[str, bytes], encoding: str = 'UTF-8', errors: str = 'strict') -> str:
43    if isinstance(v, str):
44        return v
45    elif isinstance(v, bytes):
46        return v.decode(encoding, errors)
47    return str(v)
48
49
50def force_bytes(v: Union[str, int], encoding: str = 'UTF-8', errors: str = 'strict') -> bytes:
51    if isinstance(v, bytes):
52        return v
53    return str(v).encode(encoding, errors)
54
55
56def humanize_identifier(identifier: str) -> str:
57    return re.sub('[-_]+', ' ', force_text(identifier)).strip()
58
59
60extension_to_interpreter: Dict[str, str] = {
61    '.lua': 'lua',
62    '.py': 'python',
63    '.rb': 'ruby',
64    '.sh': 'bash',
65}
66
67
68def find_scripts(directory: str) -> Iterator[Tuple[str, str]]:
69    """"""
70    Yield pairs of (interpreter, filename) for scripts found in `directory`.
71
72    :param directory: Directory to look in
73    :return: Pairs of interpreter and filename
74    """"""
75    for filename in glob.glob(os.path.join(directory, '*.*')):
76        interpreter = extension_to_interpreter.get(os.path.splitext(filename.lower())[1])
77        if interpreter:
78            yield (interpreter, os.path.basename(filename))
79
80
81def open_browser(object: Dict[str, Any], url_name: str = 'display') -> bool:
82    if 'urls' not in object:
83        return False
84    url = object['urls'][url_name]
85    click.echo(f'Opening {click.style(url, bold=True)} ...')
86    webbrowser.open(url)
87    return True
88
89
90def subset_keys(dict: Dict[Any, Any], keys: Iterable[Any]) -> Dict[Any, Any]:
91    return {key: dict[key] for key in dict if key in keys}
92
93
94def clean_log_line(line: str) -> str:
95    line = force_text(line)
96    line = ansi_escape_re.sub('', line)
97    line = control_characters_re.sub(' ', line)
98    return line.strip()
99
100
101def ensure_makedirs(path: str, mode: int = 0o744) -> None:
102    # http://stackoverflow.com/questions/5231901/permission-problems-when-creating-a-dir-with-os-makedirs-python
103    original_umask = os.umask(0)
104    try:
105        # only newly create directories get the defined mode
106        if not os.path.exists(path):
107            os.makedirs(path, mode)
108        # ensure that the last directory has the right mode if it exists
109        os.chmod(path, mode)
110    finally:
111        os.umask(original_umask)
112
113
114def sanitize_filename(name: str, replacement: str = '-') -> str:
115    # Via https://github.com/parshap/node-sanitize-filename/blob/0d21bf13be419fcde5bc3f241672bd29f7e72c63/index.js
116    return re.sub(r'[\x00-\x1f\x80-\x9f/?<>\\:*|""]', replacement, name)
117
118
119def sanitize_option_name(name: str) -> str:
120    # In order to comply with `click.core.Option#_parse_decls`, this should
121    # actually ensure `name` is a valid Python identifier (`s.isidentifier()`)
122    # after dashes are replaced with underscores.
123    #
124    # However, what with Unicode letter characters being allowed for identifiers,
125    # the rules for `.isidentifier` are, ah, arcane to say the least.
126    #
127    # Instead, we'll just fold everything down to ASCII with the good old
128    # normalize-and-encode-and-decode dance, and then replace everything
129    # non-alphanumeric into dashes to be safe.
130    name = unicodedata.normalize('NFKD', str(name)).encode('ascii', errors='ignore').decode()
131    return re.sub(r'[^-a-z0-9]+', '-', name, flags=re.IGNORECASE).strip('-')
132
133
134def parse_environment_variable_strings(envvar_strings: Iterable[str]) -> Dict[str, str]:
135    """"""
136    Parse a list of environment variable strings into a dict.
137    """"""
138    environment_variables = {}
139    for envstr in envvar_strings:
140        key, _, value = envstr.partition('=')
141        key = key.strip()
142        if not key:
143            continue
144        environment_variables[key] = value.strip()
145    return environment_variables
146
147
148def compact_dict(dct: dict) -> dict:
149    return {key: value for (key, value) in dct.items() if key and value}
150","[['os.path.isdir(dir)', '==', 'True']]",1,1,1.0,0.00020084354288,"['ansi_escape_re', 'control_character_re', 'control_characters_re', 'dir: str', 'dir', 'new_dir', 'length: int', 'keyspace: str', 'v: Union[str', 'bytes]', 'encoding: str', 'errors: str', 'int]', 'identifier: str', 'extension_to_interpreter: Dict[str', 'str]', 'directory: str', 'interpreter', 'object: Dict[str', 'Any]', 'url_name: str', 'url', 'dict: Dict[Any', 'keys: Iterable[Any]', 'line: str', 'line', 'path: str', 'mode: int', 'original_umask', 'name: str', 'replacement: str', 'name', 'envvar_strings: Iterable[str]', 'environment_variables', 'key', '_', 'value', 'environment_variables[key]', 'dct: dict']",39,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ansi_escape_re', 'control_character_re', 'control_characters_re', 'dir: str', 'dir', 'new_dir', 'length: int', 'keyspace: str', 'v: Union[str', 'bytes]', 'encoding: str', 'errors: str', 'int]', 'identifier: str', 'extension_to_interpreter: Dict[str', 'str]', 'directory: str', 'interpreter', 'object: Dict[str', 'Any]', 'url_name: str', 'url', 'dict: Dict[Any', 'keys: Iterable[Any]', 'line: str', 'line', 'path: str', 'mode: int', 'original_umask', 'name: str', 'replacement: str', 'name', 'envvar_strings: Iterable[str]', 'environment_variables', 'key', '_', 'value', 'environment_variables[key]', 'dct: dict']
*Code:

1import glob
2import os
3import random
4import re
5import string
6import unicodedata
7import webbrowser
8from typing import Any, Dict, Iterable, Iterator, Tuple, Union
9
10import click
11
12ansi_escape_re = re.compile(r'\x1B\[[0-?]*[ -/]*[@-~]')  # https://stackoverflow.com/a/14693789/51685
13control_character_re = re.compile(r'[\x00-\x1F\x7F\x80-\x9F]')
14control_characters_re = re.compile(f'{control_character_re.pattern}+')
15
16
17def walk_directory_parents(dir: str) -> Iterator[str]:
18    """"""
19    Yield the passed directory and its parents' names, all the way up until filesystem root.
20
21    :param dir: A directory path.
22    :return: directories!
23    """"""
24    dir = os.path.realpath(dir)
25    while True:
26        yield dir
27        new_dir = os.path.dirname(dir)
28        if dir == new_dir:  # We've reached the root!
29            break
30        dir = new_dir
31
32
33def get_project_directory() -> str:
34    dir = os.environ.get('VALOHAI_PROJECT_DIR') or os.getcwd()
35    return os.path.realpath(dir)
36
37
38def get_random_string(length: int = 12, keyspace: str = (string.ascii_letters + string.digits)) -> str:
39    return ''.join(random.choice(keyspace) for x in range(length))
40
41
42def force_text(v: Union[str, bytes], encoding: str = 'UTF-8', errors: str = 'strict') -> str:
43    if isinstance(v, str):
44        return v
45    elif isinstance(v, bytes):
46        return v.decode(encoding, errors)
47    return str(v)
48
49
50def force_bytes(v: Union[str, int], encoding: str = 'UTF-8', errors: str = 'strict') -> bytes:
51    if isinstance(v, bytes):
52        return v
53    return str(v).encode(encoding, errors)
54
55
56def humanize_identifier(identifier: str) -> str:
57    return re.sub('[-_]+', ' ', force_text(identifier)).strip()
58
59
60extension_to_interpreter: Dict[str, str] = {
61    '.lua': 'lua',
62    '.py': 'python',
63    '.rb': 'ruby',
64    '.sh': 'bash',
65}
66
67
68def find_scripts(directory: str) -> Iterator[Tuple[str, str]]:
69    """"""
70    Yield pairs of (interpreter, filename) for scripts found in `directory`.
71
72    :param directory: Directory to look in
73    :return: Pairs of interpreter and filename
74    """"""
75    for filename in glob.glob(os.path.join(directory, '*.*')):
76        interpreter = extension_to_interpreter.get(os.path.splitext(filename.lower())[1])
77        if interpreter:
78            yield (interpreter, os.path.basename(filename))
79
80
81def open_browser(object: Dict[str, Any], url_name: str = 'display') -> bool:
82    if 'urls' not in object:
83        return False
84    url = object['urls'][url_name]
85    click.echo(f'Opening {click.style(url, bold=True)} ...')
86    webbrowser.open(url)
87    return True
88
89
90def subset_keys(dict: Dict[Any, Any], keys: Iterable[Any]) -> Dict[Any, Any]:
91    return {key: dict[key] for key in dict if key in keys}
92
93
94def clean_log_line(line: str) -> str:
95    line = force_text(line)
96    line = ansi_escape_re.sub('', line)
97    line = control_characters_re.sub(' ', line)
98    return line.strip()
99
100
101def ensure_makedirs(path: str, mode: int = 0o744) -> None:
102    # http://stackoverflow.com/questions/5231901/permission-problems-when-creating-a-dir-with-os-makedirs-python
103    original_umask = os.umask(0)
104    try:
105        # only newly create directories get the defined mode
106        if not os.path.exists(path):
107            os.makedirs(path, mode)
108        # ensure that the last directory has the right mode if it exists
109        os.chmod(path, mode)
110    finally:
111        os.umask(original_umask)
112
113
114def sanitize_filename(name: str, replacement: str = '-') -> str:
115    # Via https://github.com/parshap/node-sanitize-filename/blob/0d21bf13be419fcde5bc3f241672bd29f7e72c63/index.js
116    return re.sub(r'[\x00-\x1f\x80-\x9f/?<>\\:*|""]', replacement, name)
117
118
119def sanitize_option_name(name: str) -> str:
120    # In order to comply with `click.core.Option#_parse_decls`, this should
121    # actually ensure `name` is a valid Python identifier (`s.isidentifier()`)
122    # after dashes are replaced with underscores.
123    #
124    # However, what with Unicode letter characters being allowed for identifiers,
125    # the rules for `.isidentifier` are, ah, arcane to say the least.
126    #
127    # Instead, we'll just fold everything down to ASCII with the good old
128    # normalize-and-encode-and-decode dance, and then replace everything
129    # non-alphanumeric into dashes to be safe.
130    name = unicodedata.normalize('NFKD', str(name)).encode('ascii', errors='ignore').decode()
131    return re.sub(r'[^-a-z0-9]+', '-', name, flags=re.IGNORECASE).strip('-')
132
133
134def parse_environment_variable_strings(envvar_strings: Iterable[str]) -> Dict[str, str]:
135    """"""
136    Parse a list of environment variable strings into a dict.
137    """"""
138    environment_variables = {}
139    for envstr in envvar_strings:
140        key, _, value = envstr.partition('=')
141        key = key.strip()
142        if not key:
143            continue
144        environment_variables[key] = value.strip()
145    return environment_variables
146
147
148def compact_dict(dct: dict) -> dict:
149    return {key: value for (key, value) in dct.items() if key and value}
150",7286,"[17, 'dir', '!=', '', ""function 'walk_directory_parents' can't work with an empty string as input""],
[33, 'VALOHAI_PROJECT_DIR', '!=', '', ""'os.environ.get('VALOHAI_PROJECT_DIR')' can't return an empty string""],
[38, 'length', '>=', 0, 'Length for a random string should be zero or greater'],
[38, 'keyspace', '!=', '', 'Empty keyspace would result in an empty string'],
[42, 'v', '!=', '', 'Function force_text is not designed for empty input values'],
[50, 'v', '!=', '', 'Function force_bytes is not designed for empty input values'],
[68, 'directory', '!=', '', 'Function find_scripts cannot operate with an empty directory path'],
[81, 'object', '!=', '', 'Function open_browser needs a non-empty Dictionary object as input'],
[81, 'url_name', '!=', '', 'url_name cannot be an empty string for function open_browser'],
[90, 'dict', '!=', {}, 'Function subset_keys cannot operate on an empty dictionary'],
[90, 'keys', '!=', [], 'keys for function subset_keys should be non-empty'],
[94, 'line', '!=', '', 'Function clean_log_line needs a non-empty string argument'],
[101, 'path', '!=', '', 'Function ensure_makedirs needs a non-empty path as argument'],
[114, 'name', '!=', '', 'Function sanitize_filename needs a non-empty string as input argument'],
[119, 'name', '!=', '', 'Function sanitize_option_name needs a non-empty string as input argument'],
[134, 'envvar_strings', '!=', [], 'Function parse_environment_variable_strings requires non-empty list as input'],
[148, 'dct', '!=', {}, 'Function compact_dict cannot operate on an empty dictionary']"
arokem/scipy,"from __future__ import division, print_function, absolute_import

import numpy as np
from numpy.testing import assert_array_almost_equal, assert_
from scipy.sparse import csr_matrix, csc_matrix

import pytest


def test_csc_getrow():
    N = 10
    np.random.seed(0)
    X = np.random.random((N, N))
    X[X > 0.7] = 0
    Xcsc = csc_matrix(X)

    for i in range(N):
        arr_row = X[i:i + 1, :]
        csc_row = Xcsc.getrow(i)

        assert_array_almost_equal(arr_row, csc_row.toarray())
        assert_(type(csc_row) is csr_matrix)


def test_csc_getcol():
    N = 10
    np.random.seed(0)
    X = np.random.random((N, N))
    X[X > 0.7] = 0
    Xcsc = csc_matrix(X)

    for i in range(N):
        arr_col = X[:, i:i + 1]
        csc_col = Xcsc.getcol(i)

        assert_array_almost_equal(arr_col, csc_col.toarray())
        assert_(type(csc_col) is csc_matrix)

@pytest.mark.parametrize(""matrix_input, axis, expected_shape"",
    [(csc_matrix([[1, 0],
                [0, 0],
                [0, 2]]),
      0, (0, 2)),
     (csc_matrix([[1, 0],
                [0, 0],
                [0, 2]]),
      1, (3, 0)),
     (csc_matrix([[1, 0],
                [0, 0],
                [0, 2]]),
      'both', (0, 0)),
     (csc_matrix([[0, 1, 0, 0, 0, 0],
                [0, 0, 0, 0, 0, 0],
                [0, 0, 2, 3, 0, 1]]),
      0, (0, 6))])
def test_csc_empty_slices(matrix_input, axis, expected_shape):
    # see gh-11127 for related discussion
    slice_1 = matrix_input.A.shape[0] - 1
    slice_2 = slice_1
    slice_3 = slice_2 - 1

    if axis == 0:
        actual_shape_1 = matrix_input[slice_1:slice_2, :].A.shape
        actual_shape_2 = matrix_input[slice_1:slice_3, :].A.shape
    elif axis == 1:
        actual_shape_1 = matrix_input[:, slice_1:slice_2].A.shape
        actual_shape_2 = matrix_input[:, slice_1:slice_3].A.shape
    elif axis == 'both':
        actual_shape_1 = matrix_input[slice_1:slice_2, slice_1:slice_2].A.shape
        actual_shape_2 = matrix_input[slice_1:slice_3, slice_1:slice_3].A.shape

    assert actual_shape_1 == expected_shape
    assert actual_shape_1 == actual_shape_2
","
1from __future__ import division, print_function, absolute_import
2
3import numpy as np
4from scipy.sparse import csr_matrix, csc_matrix
5
6import pytest
7
8
9def test_csc_getrow():
10    N = 10
11    np.random.seed(0)
12    X = np.random.random((N, N))
13    X[X > 0.7] = 0
14    Xcsc = csc_matrix(X)
15
16    for i in range(N):
17        arr_row = X[i:i + 1, :]
18        csc_row = Xcsc.getrow(i)
19
20
21
22def test_csc_getcol():
23    N = 10
24    np.random.seed(0)
25    X = np.random.random((N, N))
26    X[X > 0.7] = 0
27    Xcsc = csc_matrix(X)
28
29    for i in range(N):
30        arr_col = X[:, i:i + 1]
31        csc_col = Xcsc.getcol(i)
32
33
34@pytest.mark.parametrize(""matrix_input, axis, expected_shape"",
35    [(csc_matrix([[1, 0],
36                [0, 0],
37                [0, 2]]),
38      0, (0, 2)),
39     (csc_matrix([[1, 0],
40                [0, 0],
41                [0, 2]]),
42      1, (3, 0)),
43     (csc_matrix([[1, 0],
44                [0, 0],
45                [0, 2]]),
46      'both', (0, 0)),
47     (csc_matrix([[0, 1, 0, 0, 0, 0],
48                [0, 0, 0, 0, 0, 0],
49                [0, 0, 2, 3, 0, 1]]),
50      0, (0, 6))])
51def test_csc_empty_slices(matrix_input, axis, expected_shape):
52    # see gh-11127 for related discussion
53    slice_1 = matrix_input.A.shape[0] - 1
54    slice_2 = slice_1
55    slice_3 = slice_2 - 1
56
57    if axis == 0:
58        actual_shape_1 = matrix_input[slice_1:slice_2, :].A.shape
59        actual_shape_2 = matrix_input[slice_1:slice_3, :].A.shape
60    elif axis == 1:
61        actual_shape_1 = matrix_input[:, slice_1:slice_2].A.shape
62        actual_shape_2 = matrix_input[:, slice_1:slice_3].A.shape
63    elif axis == 'both':
64        actual_shape_1 = matrix_input[slice_1:slice_2, slice_1:slice_2].A.shape
65        actual_shape_2 = matrix_input[slice_1:slice_3, slice_1:slice_3].A.shape
66
67","[['actual_shape_1', '==', 'expected_shape'], ['actual_shape_1', '==', 'actual_shape_2']]",7,2,0.2857142857142857,0.000940291490362,"['N', 'X', 'X[X > 0.7]', 'Xcsc', 'arr_row', 'csc_row', 'arr_col', 'csc_col', 'matrix_input', 'axis', 'expected_shape', 'slice_1', 'slice_2', 'slice_3', 'actual_shape_1', 'actual_shape_2']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['N', 'X', 'X[X > 0.7]', 'Xcsc', 'arr_row', 'csc_row', 'arr_col', 'csc_col', 'matrix_input', 'axis', 'expected_shape', 'slice_1', 'slice_2', 'slice_3', 'actual_shape_1', 'actual_shape_2']
*Code:

1from __future__ import division, print_function, absolute_import
2
3import numpy as np
4from scipy.sparse import csr_matrix, csc_matrix
5
6import pytest
7
8
9def test_csc_getrow():
10    N = 10
11    np.random.seed(0)
12    X = np.random.random((N, N))
13    X[X > 0.7] = 0
14    Xcsc = csc_matrix(X)
15
16    for i in range(N):
17        arr_row = X[i:i + 1, :]
18        csc_row = Xcsc.getrow(i)
19
20
21
22def test_csc_getcol():
23    N = 10
24    np.random.seed(0)
25    X = np.random.random((N, N))
26    X[X > 0.7] = 0
27    Xcsc = csc_matrix(X)
28
29    for i in range(N):
30        arr_col = X[:, i:i + 1]
31        csc_col = Xcsc.getcol(i)
32
33
34@pytest.mark.parametrize(""matrix_input, axis, expected_shape"",
35    [(csc_matrix([[1, 0],
36                [0, 0],
37                [0, 2]]),
38      0, (0, 2)),
39     (csc_matrix([[1, 0],
40                [0, 0],
41                [0, 2]]),
42      1, (3, 0)),
43     (csc_matrix([[1, 0],
44                [0, 0],
45                [0, 2]]),
46      'both', (0, 0)),
47     (csc_matrix([[0, 1, 0, 0, 0, 0],
48                [0, 0, 0, 0, 0, 0],
49                [0, 0, 2, 3, 0, 1]]),
50      0, (0, 6))])
51def test_csc_empty_slices(matrix_input, axis, expected_shape):
52    # see gh-11127 for related discussion
53    slice_1 = matrix_input.A.shape[0] - 1
54    slice_2 = slice_1
55    slice_3 = slice_2 - 1
56
57    if axis == 0:
58        actual_shape_1 = matrix_input[slice_1:slice_2, :].A.shape
59        actual_shape_2 = matrix_input[slice_1:slice_3, :].A.shape
60    elif axis == 1:
61        actual_shape_1 = matrix_input[:, slice_1:slice_2].A.shape
62        actual_shape_2 = matrix_input[:, slice_1:slice_3].A.shape
63    elif axis == 'both':
64        actual_shape_1 = matrix_input[slice_1:slice_2, slice_1:slice_2].A.shape
65        actual_shape_2 = matrix_input[slice_1:slice_3, slice_1:slice_3].A.shape
66
67",3457,"[[10, 'N', >=, 1, ""N should be at least 1 as it denotes the dimensions of the matrix""], 
 [17, 'arr_row', ==, 'csc_row', ""Both row implementations in arr_row and csc_row should be the same""],
 [23, 'N', >=, 1, ""N should be at least 1 as it denotes the dimensions of the matrix""],  
 [30, 'arr_col', ==, 'csc_col', ""Both column implementations in arr_col and csc_col should be the same""], 
 [52, 'expected_shape', ==, 'actual_shape_1', ""The actual shape of the 1st slice should match the expected shape""], 
 [56, 'expected_shape', ==, 'actual_shape_2', ""The actual shape of the 2nd slice should match the expected shape""]]"
motmot/flytrax,"from __future__ import division, with_statement
import pkg_resources
import numpy as np
import motmot.FlyMovieFormat.FlyMovieFormat as fmf_mod
import motmot.flytrax.traxio as traxio
import os, sys, collections
from optparse import OptionParser

def trx2fmf(trx_filename,output_filename):
    base,ext = os.path.splitext(trx_filename)
    assert ext=='.trx','must give .trx filename'
    fmf_filename = base + '.fmf'
    fmf = fmf_mod.FlyMovie(fmf_filename)
    assert fmf.get_format()=='MONO8'
    w,h=fmf.get_width(),fmf.get_height()
    bg_image, orig_data = traxio.readtrax(trx_filename,
                                          return_structured_array=True)
    progress=True
    if progress:
        import progressbar
        widgets=['saving frames: ', progressbar.Percentage(), ' ',
                 progressbar.Bar(), ' ', progressbar.ETA()]
        pbar=progressbar.ProgressBar(widgets=widgets,maxval=len(orig_data)).start()

    cur_image = np.array(bg_image,copy=True)

    fmf_saver = fmf_mod.FlyMovieSaver(output_filename)
    for i,trx_row in enumerate(orig_data):
        if progress:
            pbar.update(i)
        orig_fmf_image,fmf_timestamp = fmf.get_next_frame()
        assert trx_row['timestamp']==fmf_timestamp
        windowx=trx_row['windowx'][0]
        windowy=trx_row['windowy'][0]
        cur_image[windowy:windowy+h,windowx:windowx+w] = orig_fmf_image
        fmf_saver.add_frame(cur_image,fmf_timestamp)
    fmf_saver.close()
    fmf.close()
    if progress:
        pbar.finish()

def main():
    usage = '%prog INPUT.trx OUTPUT.fmf [options]'
    parser = OptionParser(usage)
    (options, args) = parser.parse_args()

    if len(args)>2:
        print >> sys.stderr,  ""too many arguments given""
        parser.print_help()
        sys.exit(1)

    if len(args)<2:
        print >> sys.stderr,  ""too few arguments given""
        parser.print_help()
        sys.exit(1)

    trx_filename=args[0]
    output_filename=args[1]
    trx2fmf(trx_filename,output_filename)

if __name__=='__main__':
    main()
","
1from __future__ import division, with_statement
2import pkg_resources
3import numpy as np
4import motmot.FlyMovieFormat.FlyMovieFormat as fmf_mod
5import motmot.flytrax.traxio as traxio
6import os, sys, collections
7from optparse import OptionParser
8
9def trx2fmf(trx_filename,output_filename):
10    base,ext = os.path.splitext(trx_filename)
11    fmf_filename = base + '.fmf'
12    fmf = fmf_mod.FlyMovie(fmf_filename)
13    w,h=fmf.get_width(),fmf.get_height()
14    bg_image, orig_data = traxio.readtrax(trx_filename,
15                                          return_structured_array=True)
16    progress=True
17    if progress:
18        import progressbar
19        widgets=['saving frames: ', progressbar.Percentage(), ' ',
20                 progressbar.Bar(), ' ', progressbar.ETA()]
21        pbar=progressbar.ProgressBar(widgets=widgets,maxval=len(orig_data)).start()
22
23    cur_image = np.array(bg_image,copy=True)
24
25    fmf_saver = fmf_mod.FlyMovieSaver(output_filename)
26    for i,trx_row in enumerate(orig_data):
27        if progress:
28            pbar.update(i)
29        orig_fmf_image,fmf_timestamp = fmf.get_next_frame()
30        windowx=trx_row['windowx'][0]
31        windowy=trx_row['windowy'][0]
32        cur_image[windowy:windowy+h,windowx:windowx+w] = orig_fmf_image
33        fmf_saver.add_frame(cur_image,fmf_timestamp)
34    fmf_saver.close()
35    fmf.close()
36    if progress:
37        pbar.finish()
38
39def main():
40    usage = '%prog INPUT.trx OUTPUT.fmf [options]'
41    parser = OptionParser(usage)
42    (options, args) = parser.parse_args()
43
44    if len(args)>2:
45        print >> sys.stderr,  ""too many arguments given""
46        parser.print_help()
47        sys.exit(1)
48
49    if len(args)<2:
50        print >> sys.stderr,  ""too few arguments given""
51        parser.print_help()
52        sys.exit(1)
53
54    trx_filename=args[0]
55    output_filename=args[1]
56    trx2fmf(trx_filename,output_filename)
57
58if __name__=='__main__':
59    main()
60","[[""ext=='.trx'"", '==', 'True'], [""fmf.get_format()=='MONO8'"", '==', 'True'], [""trx_row['timestamp']==fmf_timestamp"", '==', 'True']]",3,3,1.0,0.0014698677119059,"['trx_filename', 'output_filename', 'base', 'ext', 'fmf_filename', 'fmf', 'bg_image', 'orig_data', 'cur_image', 'fmf_saver', 'orig_fmf_image', 'fmf_timestamp', 'cur_image[windowy:windowy+h', 'windowx:windowx+w]', 'usage', 'parser', '(options', 'args)']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['trx_filename', 'output_filename', 'base', 'ext', 'fmf_filename', 'fmf', 'bg_image', 'orig_data', 'cur_image', 'fmf_saver', 'orig_fmf_image', 'fmf_timestamp', 'cur_image[windowy:windowy+h', 'windowx:windowx+w]', 'usage', 'parser', '(options', 'args)']
*Code:

1from __future__ import division, with_statement
2import pkg_resources
3import numpy as np
4import motmot.FlyMovieFormat.FlyMovieFormat as fmf_mod
5import motmot.flytrax.traxio as traxio
6import os, sys, collections
7from optparse import OptionParser
8
9def trx2fmf(trx_filename,output_filename):
10    base,ext = os.path.splitext(trx_filename)
11    fmf_filename = base + '.fmf'
12    fmf = fmf_mod.FlyMovie(fmf_filename)
13    w,h=fmf.get_width(),fmf.get_height()
14    bg_image, orig_data = traxio.readtrax(trx_filename,
15                                          return_structured_array=True)
16    progress=True
17    if progress:
18        import progressbar
19        widgets=['saving frames: ', progressbar.Percentage(), ' ',
20                 progressbar.Bar(), ' ', progressbar.ETA()]
21        pbar=progressbar.ProgressBar(widgets=widgets,maxval=len(orig_data)).start()
22
23    cur_image = np.array(bg_image,copy=True)
24
25    fmf_saver = fmf_mod.FlyMovieSaver(output_filename)
26    for i,trx_row in enumerate(orig_data):
27        if progress:
28            pbar.update(i)
29        orig_fmf_image,fmf_timestamp = fmf.get_next_frame()
30        windowx=trx_row['windowx'][0]
31        windowy=trx_row['windowy'][0]
32        cur_image[windowy:windowy+h,windowx:windowx+w] = orig_fmf_image
33        fmf_saver.add_frame(cur_image,fmf_timestamp)
34    fmf_saver.close()
35    fmf.close()
36    if progress:
37        pbar.finish()
38
39def main():
40    usage = '%prog INPUT.trx OUTPUT.fmf [options]'
41    parser = OptionParser(usage)
42    (options, args) = parser.parse_args()
43
44    if len(args)>2:
45        print >> sys.stderr,  ""too many arguments given""
46        parser.print_help()
47        sys.exit(1)
48
49    if len(args)<2:
50        print >> sys.stderr,  ""too few arguments given""
51        parser.print_help()
52        sys.exit(1)
53
54    trx_filename=args[0]
55    output_filename=args[1]
56    trx2fmf(trx_filename,output_filename)
57
58if __name__=='__main__':
59    main()
60",3648,"[[9, 'trx_filename', '!=', '', 'the filename should not be an empty string'],
 [9, 'output_filename', '!=', '', 'the output filename should not be an empty string'],
 [14, 'bg_image', '!=', None, 'Background image should not be None'],
 [14, 'orig_data', '!=', None, 'Original data should not be None'],
 [23, 'cur_image', '!=', None, 'The current image should not be None'],
 [25, 'fmf_saver', '!=', None, 'The FlyMovieSaver object should not be None'],
 [29, 'orig_fmf_image', '!=', None, 'The original FlyMovieFormat image should not be None'],
 [29, 'fmf_timestamp', '!=', None, 'The timestamp of the FlyMovieFormat should not be None'],
 [44, 'args', '>=', 2, 'At least 2 arguments should be provided'],
 [49, 'args', '<=', 2, 'No more than 2 arguments should be provided']]"
bgris/ODL_bgris,"r""""""
Tests for QtAwesome.
""""""
# Standard library imports
import subprocess

# Test Library imports
import pytest

def test_segfault_import():
    output_number = subprocess.call('python -c ""import qtawesome '
                                    '; qtawesome.icon()""', shell=True)
    assert output_number == 0
    
if __name__ == ""__main__"":
    pytest.main()
","
1r""""""
2Tests for QtAwesome.
3""""""
4# Standard library imports
5import subprocess
6
7# Test Library imports
8import pytest
9
10def test_segfault_import():
11    output_number = subprocess.call('python -c ""import qtawesome '
12                                    '; qtawesome.icon()""', shell=True)
13    
14if __name__ == ""__main__"":
15    pytest.main()
16","[['output_number', '==', '0']]",1,1,1.0,0.0027777777777777,['output_number'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['output_number']
*Code:

1r""""""
2Tests for QtAwesome.
3""""""
4# Standard library imports
5import subprocess
6
7# Test Library imports
8import pytest
9
10def test_segfault_import():
11    output_number = subprocess.call('python -c ""import qtawesome '
12                                    '; qtawesome.icon()""', shell=True)
13    
14if __name__ == ""__main__"":
15    pytest.main()
16",1751,"[[11, 'output_number', '>=', 0, ""output_number should not be negative as it represents a process exit status""]]"
influence-usa/pupa,"import pytest
from opencivicdata.models import Organization
from pupa.scrape import Organization as ScrapeOrganization
from pupa.importers import OrganizationImporter
from pupa.exceptions import UnresolvedIdError


@pytest.mark.django_db
def test_full_organization():
    org = ScrapeOrganization('United Nations', classification='international')
    org.add_identifier('un')
    org.add_name('UN', start_date='1945')
    org.add_contact_detail(type='phone', value='555-555-1234', note='this is fake')
    org.add_link('http://example.com/link')
    org.add_source('http://example.com/source')

    # import org
    od = org.as_dict()
    OrganizationImporter('jurisdiction-id').import_data([od])

    # get person from db and assert it imported correctly
    o = Organization.objects.get()
    assert 'ocd-organization' in o.id
    assert o.name == org.name

    assert o.identifiers.all()[0].identifier == 'un'
    assert o.identifiers.all()[0].scheme == ''

    assert o.other_names.all()[0].name == 'UN'
    assert o.other_names.all()[0].start_date == '1945'

    assert o.contact_details.all()[0].type == 'phone'
    assert o.contact_details.all()[0].value == '555-555-1234'
    assert o.contact_details.all()[0].note == 'this is fake'

    assert o.links.all()[0].url == 'http://example.com/link'
    assert o.sources.all()[0].url == 'http://example.com/source'


@pytest.mark.django_db
def test_deduplication_similar_but_different():
    o1 = ScrapeOrganization('United Nations', classification='international')
    # different classification
    o2 = ScrapeOrganization('United Nations', classification='global')
    # different name
    o3 = ScrapeOrganization('United Nations of Earth', classification='international')
    # has a parent
    o4 = ScrapeOrganization('United Nations', classification='international', parent_id=o1._id)

    # similar, but no duplicates
    orgs = [o1.as_dict(), o2.as_dict(), o3.as_dict(), o4.as_dict()]
    OrganizationImporter('jurisdiction-id').import_data(orgs)
    assert Organization.objects.count() == 4

    # should get a new one  when jurisdiction_id changes
    o5 = ScrapeOrganization('United Nations', classification='international')
    OrganizationImporter('new-jurisdiction-id').import_data([o5.as_dict()])
    assert Organization.objects.count() == 5


@pytest.mark.django_db
def test_deduplication_parties():
    party = ScrapeOrganization('Wild', classification='party')
    OrganizationImporter('jurisdiction-id').import_data([party.as_dict()])
    assert Organization.objects.count() == 1

    # parties shouldn't get jurisdiction id attached, so don't differ on import
    party = ScrapeOrganization('Wild', classification='party')
    OrganizationImporter('new-jurisdiction-id').import_data([party.as_dict()])
    assert Organization.objects.count() == 1


@pytest.mark.django_db
def test_deduplication_prevents_identical():
    org1 = ScrapeOrganization('United Nations', classification='international')
    org2 = ScrapeOrganization('United Nations', classification='international',
                              founding_date='1945')
    OrganizationImporter('jurisdiction-id').import_data([org1.as_dict()])
    assert Organization.objects.count() == 1

    OrganizationImporter('jurisdiction-id').import_data([org2.as_dict()])
    assert Organization.objects.count() == 1


@pytest.mark.django_db
def test_pseudo_ids():
    wild = Organization.objects.create(id='1', name='Wild', classification='party')
    senate = Organization.objects.create(id='2', name='Senate', classification='upper',
                                         jurisdiction_id='jid1')
    house = Organization.objects.create(id='3', name='House', classification='lower',
                                        jurisdiction_id='jid1')
    un = Organization.objects.create(id='4', name='United Nations', classification='international',
                                     jurisdiction_id='jid2')

    oi1 = OrganizationImporter('jid1')
    assert oi1.resolve_json_id('~{""classification"":""upper""}') == senate.id
    assert oi1.resolve_json_id('~{""classification"":""lower""}') == house.id
    assert oi1.resolve_json_id('~{""classification"":""party"", ""name"":""Wild""}') == wild.id

    with pytest.raises(UnresolvedIdError):
        oi1.resolve_json_id('~{""classification"":""international"", ""name"":""United Nations""}')

    oi2 = OrganizationImporter('jid2')
    assert (oi2.resolve_json_id('~{""classification"":""international"", ""name"":""United Nations""}') ==
            un.id)


@pytest.mark.django_db
def test_parent_id_resolution():
    parent = ScrapeOrganization('UN', classification='international')
    child = ScrapeOrganization('UNESCO', classification='unknown', parent_id=parent._id)
    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
    assert Organization.objects.count() == 2
    assert Organization.objects.get(name='UN').children.count() == 1
    assert Organization.objects.get(name='UNESCO').parent.name == 'UN'


@pytest.mark.django_db
def test_pseudo_parent_id_resolution():
    parent = ScrapeOrganization('UN', classification='international')
    child = ScrapeOrganization('UNESCO', classification='unknown',
                               parent_id='~{""classification"": ""international""}')
    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
    assert Organization.objects.count() == 2
    assert Organization.objects.get(name='UN').children.count() == 1
    assert Organization.objects.get(name='UNESCO').parent.name == 'UN'


@pytest.mark.django_db
def test_extras_organization():
    org = ScrapeOrganization('United Nations', classification='international')
    org.extras = {""hello"": ""world"",
                  ""foo"": {""bar"": ""baz""}}
    od = org.as_dict()
    OrganizationImporter('jurisdiction-id').import_data([od])
    o = Organization.objects.get()
    assert o.extras['foo']['bar'] == 'baz'
","
1import pytest
2from opencivicdata.models import Organization
3from pupa.scrape import Organization as ScrapeOrganization
4from pupa.importers import OrganizationImporter
5from pupa.exceptions import UnresolvedIdError
6
7
8@pytest.mark.django_db
9def test_full_organization():
10    org = ScrapeOrganization('United Nations', classification='international')
11    org.add_identifier('un')
12    org.add_name('UN', start_date='1945')
13    org.add_contact_detail(type='phone', value='555-555-1234', note='this is fake')
14    org.add_link('http://example.com/link')
15    org.add_source('http://example.com/source')
16
17    # import org
18    od = org.as_dict()
19    OrganizationImporter('jurisdiction-id').import_data([od])
20
21    o = Organization.objects.get()
22
23
24
25
26
27
28@pytest.mark.django_db
29def test_deduplication_similar_but_different():
30    o1 = ScrapeOrganization('United Nations', classification='international')
31    # different classification
32    o2 = ScrapeOrganization('United Nations', classification='global')
33    # different name
34    o3 = ScrapeOrganization('United Nations of Earth', classification='international')
35    # has a parent
36    o4 = ScrapeOrganization('United Nations', classification='international', parent_id=o1._id)
37
38    # similar, but no duplicates
39    orgs = [o1.as_dict(), o2.as_dict(), o3.as_dict(), o4.as_dict()]
40    OrganizationImporter('jurisdiction-id').import_data(orgs)
41
42    # should get a new one  when jurisdiction_id changes
43    o5 = ScrapeOrganization('United Nations', classification='international')
44    OrganizationImporter('new-jurisdiction-id').import_data([o5.as_dict()])
45
46
47@pytest.mark.django_db
48def test_deduplication_parties():
49    party = ScrapeOrganization('Wild', classification='party')
50    OrganizationImporter('jurisdiction-id').import_data([party.as_dict()])
51
52    # parties shouldn't get jurisdiction id attached, so don't differ on import
53    party = ScrapeOrganization('Wild', classification='party')
54    OrganizationImporter('new-jurisdiction-id').import_data([party.as_dict()])
55
56
57@pytest.mark.django_db
58def test_deduplication_prevents_identical():
59    org1 = ScrapeOrganization('United Nations', classification='international')
60    org2 = ScrapeOrganization('United Nations', classification='international',
61                              founding_date='1945')
62    OrganizationImporter('jurisdiction-id').import_data([org1.as_dict()])
63
64    OrganizationImporter('jurisdiction-id').import_data([org2.as_dict()])
65
66
67@pytest.mark.django_db
68def test_pseudo_ids():
69    wild = Organization.objects.create(id='1', name='Wild', classification='party')
70    senate = Organization.objects.create(id='2', name='Senate', classification='upper',
71                                         jurisdiction_id='jid1')
72    house = Organization.objects.create(id='3', name='House', classification='lower',
73                                        jurisdiction_id='jid1')
74    un = Organization.objects.create(id='4', name='United Nations', classification='international',
75                                     jurisdiction_id='jid2')
76
77    oi1 = OrganizationImporter('jid1')
78
79    with pytest.raises(UnresolvedIdError):
80        oi1.resolve_json_id('~{""classification"":""international"", ""name"":""United Nations""}')
81
82    oi2 = OrganizationImporter('jid2')
83            un.id)
84
85
86@pytest.mark.django_db
87def test_parent_id_resolution():
88    parent = ScrapeOrganization('UN', classification='international')
89    child = ScrapeOrganization('UNESCO', classification='unknown', parent_id=parent._id)
90    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
91
92
93@pytest.mark.django_db
94def test_pseudo_parent_id_resolution():
95    parent = ScrapeOrganization('UN', classification='international')
96    child = ScrapeOrganization('UNESCO', classification='unknown',
97                               parent_id='~{""classification"": ""international""}')
98    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
99
100
101@pytest.mark.django_db
102def test_extras_organization():
103    org = ScrapeOrganization('United Nations', classification='international')
104    org.extras = {""hello"": ""world"",
105                  ""foo"": {""bar"": ""baz""}}
106    od = org.as_dict()
107    OrganizationImporter('jurisdiction-id').import_data([od])
108    o = Organization.objects.get()
109","[['assert', 'it', 'imported', 'correctly'], ['o.name', '==', 'org.name'], ['o.identifiers.all()[0].identifier', '==', ""'un'""], ['o.identifiers.all()[0].scheme', '==', ""''""], ['o.other_names.all()[0].name', '==', ""'UN'""], ['o.other_names.all()[0].start_date', '==', ""'1945'""], ['o.contact_details.all()[0].type', '==', ""'phone'""], ['o.contact_details.all()[0].value', '==', ""'555-555-1234'""], ['o.contact_details.all()[0].note', '==', ""'this is fake'""], ['o.links.all()[0].url', '==', ""'http://example.com/link'""], ['o.sources.all()[0].url', '==', ""'http://example.com/source'""], ['Organization.objects.count()', '==', '4'], ['Organization.objects.count()', '==', '5'], ['Organization.objects.count()', '==', '1'], ['Organization.objects.count()', '==', '1'], ['Organization.objects.count()', '==', '1'], ['Organization.objects.count()', '==', '1'], ['oi1.resolve_json_id(\'~{""classification"":""upper""}\')', '==', 'senate.id'], ['oi1.resolve_json_id(\'~{""classification"":""lower""}\')', '==', 'house.id'], ['oi1.resolve_json_id(\'~{""classification"":""party""', '==', 'True'], ['(oi2.resolve_json_id(\'~{""classification"":""international""', '==', 'True'], ['Organization.objects.count()', '==', '2'], [""Organization.objects.get(name='UN').children.count()"", '==', '1'], [""Organization.objects.get(name='UNESCO').parent.name"", '==', ""'UN'""], ['Organization.objects.count()', '==', '2'], [""Organization.objects.get(name='UN').children.count()"", '==', '1'], [""Organization.objects.get(name='UNESCO').parent.name"", '==', ""'UN'""], [""o.extras['foo']['bar']"", '==', ""'baz'""]]",29,28,0.9655172413793104,0.0047138047138047,"['org', 'od', 'o', 'o1', 'o2', 'o3', 'o4', 'orgs', 'o5', 'party', 'org1', 'org2', 'wild', 'senate', 'house', 'un', 'oi1', 'oi2', 'parent', 'child', 'org.extras']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['org', 'od', 'o', 'o1', 'o2', 'o3', 'o4', 'orgs', 'o5', 'party', 'org1', 'org2', 'wild', 'senate', 'house', 'un', 'oi1', 'oi2', 'parent', 'child', 'org.extras']
*Code:

1import pytest
2from opencivicdata.models import Organization
3from pupa.scrape import Organization as ScrapeOrganization
4from pupa.importers import OrganizationImporter
5from pupa.exceptions import UnresolvedIdError
6
7
8@pytest.mark.django_db
9def test_full_organization():
10    org = ScrapeOrganization('United Nations', classification='international')
11    org.add_identifier('un')
12    org.add_name('UN', start_date='1945')
13    org.add_contact_detail(type='phone', value='555-555-1234', note='this is fake')
14    org.add_link('http://example.com/link')
15    org.add_source('http://example.com/source')
16
17    # import org
18    od = org.as_dict()
19    OrganizationImporter('jurisdiction-id').import_data([od])
20
21    o = Organization.objects.get()
22
23
24
25
26
27
28@pytest.mark.django_db
29def test_deduplication_similar_but_different():
30    o1 = ScrapeOrganization('United Nations', classification='international')
31    # different classification
32    o2 = ScrapeOrganization('United Nations', classification='global')
33    # different name
34    o3 = ScrapeOrganization('United Nations of Earth', classification='international')
35    # has a parent
36    o4 = ScrapeOrganization('United Nations', classification='international', parent_id=o1._id)
37
38    # similar, but no duplicates
39    orgs = [o1.as_dict(), o2.as_dict(), o3.as_dict(), o4.as_dict()]
40    OrganizationImporter('jurisdiction-id').import_data(orgs)
41
42    # should get a new one  when jurisdiction_id changes
43    o5 = ScrapeOrganization('United Nations', classification='international')
44    OrganizationImporter('new-jurisdiction-id').import_data([o5.as_dict()])
45
46
47@pytest.mark.django_db
48def test_deduplication_parties():
49    party = ScrapeOrganization('Wild', classification='party')
50    OrganizationImporter('jurisdiction-id').import_data([party.as_dict()])
51
52    # parties shouldn't get jurisdiction id attached, so don't differ on import
53    party = ScrapeOrganization('Wild', classification='party')
54    OrganizationImporter('new-jurisdiction-id').import_data([party.as_dict()])
55
56
57@pytest.mark.django_db
58def test_deduplication_prevents_identical():
59    org1 = ScrapeOrganization('United Nations', classification='international')
60    org2 = ScrapeOrganization('United Nations', classification='international',
61                              founding_date='1945')
62    OrganizationImporter('jurisdiction-id').import_data([org1.as_dict()])
63
64    OrganizationImporter('jurisdiction-id').import_data([org2.as_dict()])
65
66
67@pytest.mark.django_db
68def test_pseudo_ids():
69    wild = Organization.objects.create(id='1', name='Wild', classification='party')
70    senate = Organization.objects.create(id='2', name='Senate', classification='upper',
71                                         jurisdiction_id='jid1')
72    house = Organization.objects.create(id='3', name='House', classification='lower',
73                                        jurisdiction_id='jid1')
74    un = Organization.objects.create(id='4', name='United Nations', classification='international',
75                                     jurisdiction_id='jid2')
76
77    oi1 = OrganizationImporter('jid1')
78
79    with pytest.raises(UnresolvedIdError):
80        oi1.resolve_json_id('~{""classification"":""international"", ""name"":""United Nations""}')
81
82    oi2 = OrganizationImporter('jid2')
83            un.id)
84
85
86@pytest.mark.django_db
87def test_parent_id_resolution():
88    parent = ScrapeOrganization('UN', classification='international')
89    child = ScrapeOrganization('UNESCO', classification='unknown', parent_id=parent._id)
90    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
91
92
93@pytest.mark.django_db
94def test_pseudo_parent_id_resolution():
95    parent = ScrapeOrganization('UN', classification='international')
96    child = ScrapeOrganization('UNESCO', classification='unknown',
97                               parent_id='~{""classification"": ""international""}')
98    OrganizationImporter('jurisdiction-id').import_data([parent.as_dict(), child.as_dict()])
99
100
101@pytest.mark.django_db
102def test_extras_organization():
103    org = ScrapeOrganization('United Nations', classification='international')
104    org.extras = {""hello"": ""world"",
105                  ""foo"": {""bar"": ""baz""}}
106    od = org.as_dict()
107    OrganizationImporter('jurisdiction-id').import_data([od])
108    o = Organization.objects.get()
109",6051,"[[9, 'ScrapeOrganization', '!=', None, 'ScrapeOrganization must be imported properly for the function to work'],
[10, 'org', '!=', None, 'org must be properly initialized and not None'],
[18, 'od', '!=', None, 'od must be properly initialized and not None'],
[19, 'OrganizationImporter', '!=', None, 'OrganizationImporter must be imported properly for the function to work'],
[21, 'o', '!=', None, 'o must be properly initialized and not None'], 
[29, 'o1', '!=', None, 'o1 must be properly initialized and not None'],
[32, 'o2', '!=', None, 'o2 must be properly initialized and not None'],
[34, 'o3', '!=', None, 'o3 must be properly initialized and not None'],
[36, 'o4', '!=', None, 'o4 must be properly initialized and not None'],
[40, 'orgs', '!=', None, 'orgs must be properly initialized and not None'],
[43, 'o5', '!=', None, 'o5 must be properly initialized and not None'],
[49, 'party', '!=', None, 'party must be properly initialized and not None'],
[59, 'org1', '!=', None, 'org1 must be properly initialized and not None'],
[60, 'org2', '!=', None, 'org2 must be properly initialized and not None'],
[69, 'wild', '!=', None, 'wild must be properly initialized and not None'],
[70, 'senate', '!=', None, 'senate must be properly initialized and not None'],
[72, 'house', '!=', None, 'house must be properly initialized and not None'],
[74, 'un', '!=', None, 'un must be properly initialized and not None'],
[77, 'oi1', '!=', None, 'oi1 must be properly initialized and not None'],
[82, 'oi2', '!=', None, 'oi2 must be properly initialized and not None'],
[88, 'parent', '!=', None, 'parent must be properly initialized and not None'],
[89, 'child', '!=', None, 'child must be properly initialized and not None'],
[95, 'parent', '!=', None, 'parent must be properly initialized and not None'],
[96, 'child', '!=', None, 'child must be properly initialized and not None'],
[103, 'org', '!=', None, 'org must be properly initialized and not None'],
[104, 'org.extras', '!=', None, 'org.extras must be properly initialized and not None'],
[106, 'od', '!=', None, 'od must be properly initialized and not None'],
[108, 'o', '!=', None, 'o must be properly initialized and not None']]"
tcoenraad/rolit,"from rolit.board import *
from rolit.ball import Ball

import pytest

class TestBoard():

    def setup_method(self, method):
        self.board = Board()

    def test_it_setups(self):
        assert self.board.field(3, 3) == Ball(Ball.RED)
        assert self.board.field(3, 4) == Ball(Ball.BLUE)
        assert self.board.field(4, 3) == Ball(Ball.YELLOW)
        assert self.board.field(4, 4) == Ball(Ball.GREEN)

    def test_it_places_fields_vertically(self):
        assert self.board.field(3, 2) == Ball(Ball.EMPTY)
        with pytest.raises(ForcedMoveError):
            self.board.place(3, 2, Ball.RED)

        self.board.place(3, 2, Ball.BLUE)
        assert self.board.field(3, 2) == Ball(Ball.BLUE)
        assert self.board.field(3, 3) == Ball(Ball.BLUE)

    def test_it_places_fields_horizontally(self):
        assert self.board.field(5, 4) == Ball(Ball.EMPTY)
        with pytest.raises(ForcedMoveError):
            self.board.place(5, 4, Ball.RED)

        self.board.place(5, 4, Ball.BLUE)
        assert self.board.field(5, 4) == Ball(Ball.BLUE)
        assert self.board.field(4, 4) == Ball(Ball.BLUE)
    
    def test_it_places_fields_diagonally_up(self):
        assert self.board.field(5, 2) == Ball(Ball.EMPTY)
        with pytest.raises(ForcedMoveError):
            self.board.place(5, 2, Ball.RED)

        self.board.place(5, 2, Ball.BLUE)
        assert self.board.field(5, 2) == Ball(Ball.BLUE)
        assert self.board.field(4, 3) == Ball(Ball.BLUE)

        with pytest.raises(ForcedMoveError):
            self.board.place(2, 5, Ball.BLUE)

    def test_it_places_fields_diagonally_down(self):
        assert self.board.field(5, 5) == Ball(Ball.EMPTY)
        with pytest.raises(ForcedMoveError):
            self.board.place(5, 5, Ball.BLUE)
        
        self.board.place(5, 5, Ball.RED)
        assert self.board.field(5, 5) == Ball(Ball.RED)
        assert self.board.field(4, 4) == Ball(Ball.RED)

        with pytest.raises(ForcedMoveError):
            self.board.place(2, 2, Ball.RED)

    def test_it_takes_no_double_placements(self):
        self.board.place(3, 2, Ball.BLUE)

        with pytest.raises(AlreadyOccupiedError):
            self.board.place(3, 2, Ball.BLUE)

    def test_it_validates_given_coordinates_represent_a_field_on_board(self):
        with pytest.raises(AlreadyOccupiedError):
            self.board.place(-1, 0, Ball.RED)
        with pytest.raises(AlreadyOccupiedError):
            self.board.place(8, 8, Ball.RED)
        with pytest.raises(AlreadyOccupiedError):
            self.board.place('a', 'b', Ball.RED)

    def test_it_only_allows_adjacent_placements(self):
        with pytest.raises(NotAdjacentError):
            self.board.place(6, 2, Ball.GREEN)

        self.board.place(5, 3, Ball.RED)
        self.board.place(6, 2, Ball.GREEN)

        assert self.board.field(6, 2) == Ball(Ball.GREEN)
        assert self.board.field(5, 3) == Ball(Ball.GREEN)

    def test_it_allows_any_move_if_blocking_is_not_forced(self):
        with pytest.raises(ForcedMoveError):
            self.board.place(2, 2, Ball.YELLOW)

        self.board.place(5, 3, Ball.RED)
        self.board.place(2, 2, Ball.YELLOW)

    def test_an_edge_case(self):
        self.board.place(5, 5, Ball.RED)
        self.board.place(6, 6, Ball.GREEN)
        self.board.place(7, 7, Ball.RED)
        assert self.board.field(7, 7) == Ball(Ball.RED)

        self.board.place(7, 6, Ball.GREEN)
        assert self.board.field(7, 7) == Ball(Ball.RED)

    def test_an_edge_line(self):
        self.board.place(5, 5, Ball.RED)
        self.board.place(6, 6, Ball.GREEN)
        self.board.place(7, 7, Ball.RED)
        self.board.place(7, 6, Ball.GREEN)
        self.board.place(7, 5, Ball.RED)
        self.board.place(7, 4, Ball.GREEN)
        self.board.place(7, 3, Ball.RED)
        self.board.place(7, 2, Ball.GREEN)
        self.board.place(7, 1, Ball.RED)
        assert self.board.field(7, 7) == Ball(Ball.RED)

        self.board.place(7, 0, Ball.GREEN)
        assert self.board.field(7, 7) == Ball(Ball.RED)

        self.board.place(5, 3, Ball.RED)
        self.board.place(6, 0, Ball.GREEN)
        assert self.board.field(6, 0) == Ball(Ball.GREEN)

    def test_it_encodes(self):
        assert self.board.encode() == ""empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty red yellow empty empty empty empty empty empty blue green empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty""

    def test_it_decode(self):
        board = Board.decode(""empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty red yellow empty empty empty empty empty empty blue green empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty"")
        assert board.field(3, 3) == Ball(Ball.RED)
        assert board.field(3, 4) == Ball(Ball.BLUE)
        assert board.field(4, 3) == Ball(Ball.YELLOW)
        assert board.field(4, 4) == Ball(Ball.GREEN)
","
1from rolit.board import *
2from rolit.ball import Ball
3
4import pytest
5
6class TestBoard():
7
8    def setup_method(self, method):
9        self.board = Board()
10
11    def test_it_setups(self):
12
13    def test_it_places_fields_vertically(self):
14        with pytest.raises(ForcedMoveError):
15            self.board.place(3, 2, Ball.RED)
16
17        self.board.place(3, 2, Ball.BLUE)
18
19    def test_it_places_fields_horizontally(self):
20        with pytest.raises(ForcedMoveError):
21            self.board.place(5, 4, Ball.RED)
22
23        self.board.place(5, 4, Ball.BLUE)
24    
25    def test_it_places_fields_diagonally_up(self):
26        with pytest.raises(ForcedMoveError):
27            self.board.place(5, 2, Ball.RED)
28
29        self.board.place(5, 2, Ball.BLUE)
30
31        with pytest.raises(ForcedMoveError):
32            self.board.place(2, 5, Ball.BLUE)
33
34    def test_it_places_fields_diagonally_down(self):
35        with pytest.raises(ForcedMoveError):
36            self.board.place(5, 5, Ball.BLUE)
37        
38        self.board.place(5, 5, Ball.RED)
39
40        with pytest.raises(ForcedMoveError):
41            self.board.place(2, 2, Ball.RED)
42
43    def test_it_takes_no_double_placements(self):
44        self.board.place(3, 2, Ball.BLUE)
45
46        with pytest.raises(AlreadyOccupiedError):
47            self.board.place(3, 2, Ball.BLUE)
48
49    def test_it_validates_given_coordinates_represent_a_field_on_board(self):
50        with pytest.raises(AlreadyOccupiedError):
51            self.board.place(-1, 0, Ball.RED)
52        with pytest.raises(AlreadyOccupiedError):
53            self.board.place(8, 8, Ball.RED)
54        with pytest.raises(AlreadyOccupiedError):
55            self.board.place('a', 'b', Ball.RED)
56
57    def test_it_only_allows_adjacent_placements(self):
58        with pytest.raises(NotAdjacentError):
59            self.board.place(6, 2, Ball.GREEN)
60
61        self.board.place(5, 3, Ball.RED)
62        self.board.place(6, 2, Ball.GREEN)
63
64
65    def test_it_allows_any_move_if_blocking_is_not_forced(self):
66        with pytest.raises(ForcedMoveError):
67            self.board.place(2, 2, Ball.YELLOW)
68
69        self.board.place(5, 3, Ball.RED)
70        self.board.place(2, 2, Ball.YELLOW)
71
72    def test_an_edge_case(self):
73        self.board.place(5, 5, Ball.RED)
74        self.board.place(6, 6, Ball.GREEN)
75        self.board.place(7, 7, Ball.RED)
76
77        self.board.place(7, 6, Ball.GREEN)
78
79    def test_an_edge_line(self):
80        self.board.place(5, 5, Ball.RED)
81        self.board.place(6, 6, Ball.GREEN)
82        self.board.place(7, 7, Ball.RED)
83        self.board.place(7, 6, Ball.GREEN)
84        self.board.place(7, 5, Ball.RED)
85        self.board.place(7, 4, Ball.GREEN)
86        self.board.place(7, 3, Ball.RED)
87        self.board.place(7, 2, Ball.GREEN)
88        self.board.place(7, 1, Ball.RED)
89
90        self.board.place(7, 0, Ball.GREEN)
91
92        self.board.place(5, 3, Ball.RED)
93        self.board.place(6, 0, Ball.GREEN)
94
95    def test_it_encodes(self):
96
97    def test_it_decode(self):
98        board = Board.decode(""empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty red yellow empty empty empty empty empty empty blue green empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty"")
99","[['self.board.field(3', '==', 'True'], ['self.board.field(3', '==', 'True'], ['self.board.field(4', '==', 'True'], ['self.board.field(4', '==', 'True'], ['self.board.field(3', '==', 'True'], ['self.board.field(3', '==', 'True'], ['self.board.field(3', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(4', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(4', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(4', '==', 'True'], ['self.board.field(6', '==', 'True'], ['self.board.field(5', '==', 'True'], ['self.board.field(7', '==', 'True'], ['self.board.field(7', '==', 'True'], ['self.board.field(7', '==', 'True'], ['self.board.field(7', '==', 'True'], ['self.board.field(6', '==', 'True'], ['self.board.encode()', '==', '""empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty red yellow empty empty empty empty empty empty blue green empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty""'], ['board.field(3', '==', 'True'], ['board.field(3', '==', 'True'], ['board.field(4', '==', 'True'], ['board.field(4', '==', 'True']]",28,28,1.0,0.005137614678899,"['method', 'self.board', 'board']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['method', 'self.board', 'board']
*Code:

1from rolit.board import *
2from rolit.ball import Ball
3
4import pytest
5
6class TestBoard():
7
8    def setup_method(self, method):
9        self.board = Board()
10
11    def test_it_setups(self):
12
13    def test_it_places_fields_vertically(self):
14        with pytest.raises(ForcedMoveError):
15            self.board.place(3, 2, Ball.RED)
16
17        self.board.place(3, 2, Ball.BLUE)
18
19    def test_it_places_fields_horizontally(self):
20        with pytest.raises(ForcedMoveError):
21            self.board.place(5, 4, Ball.RED)
22
23        self.board.place(5, 4, Ball.BLUE)
24    
25    def test_it_places_fields_diagonally_up(self):
26        with pytest.raises(ForcedMoveError):
27            self.board.place(5, 2, Ball.RED)
28
29        self.board.place(5, 2, Ball.BLUE)
30
31        with pytest.raises(ForcedMoveError):
32            self.board.place(2, 5, Ball.BLUE)
33
34    def test_it_places_fields_diagonally_down(self):
35        with pytest.raises(ForcedMoveError):
36            self.board.place(5, 5, Ball.BLUE)
37        
38        self.board.place(5, 5, Ball.RED)
39
40        with pytest.raises(ForcedMoveError):
41            self.board.place(2, 2, Ball.RED)
42
43    def test_it_takes_no_double_placements(self):
44        self.board.place(3, 2, Ball.BLUE)
45
46        with pytest.raises(AlreadyOccupiedError):
47            self.board.place(3, 2, Ball.BLUE)
48
49    def test_it_validates_given_coordinates_represent_a_field_on_board(self):
50        with pytest.raises(AlreadyOccupiedError):
51            self.board.place(-1, 0, Ball.RED)
52        with pytest.raises(AlreadyOccupiedError):
53            self.board.place(8, 8, Ball.RED)
54        with pytest.raises(AlreadyOccupiedError):
55            self.board.place('a', 'b', Ball.RED)
56
57    def test_it_only_allows_adjacent_placements(self):
58        with pytest.raises(NotAdjacentError):
59            self.board.place(6, 2, Ball.GREEN)
60
61        self.board.place(5, 3, Ball.RED)
62        self.board.place(6, 2, Ball.GREEN)
63
64
65    def test_it_allows_any_move_if_blocking_is_not_forced(self):
66        with pytest.raises(ForcedMoveError):
67            self.board.place(2, 2, Ball.YELLOW)
68
69        self.board.place(5, 3, Ball.RED)
70        self.board.place(2, 2, Ball.YELLOW)
71
72    def test_an_edge_case(self):
73        self.board.place(5, 5, Ball.RED)
74        self.board.place(6, 6, Ball.GREEN)
75        self.board.place(7, 7, Ball.RED)
76
77        self.board.place(7, 6, Ball.GREEN)
78
79    def test_an_edge_line(self):
80        self.board.place(5, 5, Ball.RED)
81        self.board.place(6, 6, Ball.GREEN)
82        self.board.place(7, 7, Ball.RED)
83        self.board.place(7, 6, Ball.GREEN)
84        self.board.place(7, 5, Ball.RED)
85        self.board.place(7, 4, Ball.GREEN)
86        self.board.place(7, 3, Ball.RED)
87        self.board.place(7, 2, Ball.GREEN)
88        self.board.place(7, 1, Ball.RED)
89
90        self.board.place(7, 0, Ball.GREEN)
91
92        self.board.place(5, 3, Ball.RED)
93        self.board.place(6, 0, Ball.GREEN)
94
95    def test_it_encodes(self):
96
97    def test_it_decode(self):
98        board = Board.decode(""empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty red yellow empty empty empty empty empty empty blue green empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty empty"")
99",5079,"[[8, 'method', '!=', None, 'method input should be a viable function'],
 [15, 'self.board', '!=', None, 'the board object must exist before any actions can be performed on it'],
 [18, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [21, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [23, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [27, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [29, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [36, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [38, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [41, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [44, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [47, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [51, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [53, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [55, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [59, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [61, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [66, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [69, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [73, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [77, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [80, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [92, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [94, 'self.board', '!=', None, 'The board object must exist before a ball can be placed'],
 [98, 'board', '!=', None, 'The board object must exist to be decoded']]"
DominoTree/servo,"from _pytest.outcomes import Failed
import pytest
import sys


class TestRaises(object):

    def test_raises(self):
        source = ""int('qwe')""
        excinfo = pytest.raises(ValueError, source)
        code = excinfo.traceback[-1].frame.code
        s = str(code.fullsource)
        assert s == source

    def test_raises_exec(self):
        pytest.raises(ValueError, ""a,x = []"")

    def test_raises_syntax_error(self):
        pytest.raises(SyntaxError, ""qwe qwe qwe"")

    def test_raises_function(self):
        pytest.raises(ValueError, int, ""hello"")

    def test_raises_callable_no_exception(self):

        class A(object):

            def __call__(self):
                pass

        try:
            pytest.raises(ValueError, A())
        except pytest.raises.Exception:
            pass

    def test_raises_as_contextmanager(self, testdir):
        testdir.makepyfile(
            """"""
            from __future__ import with_statement
            import py, pytest
            import _pytest._code

            def test_simple():
                with pytest.raises(ZeroDivisionError) as excinfo:
                    assert isinstance(excinfo, _pytest._code.ExceptionInfo)
                    1/0
                print (excinfo)
                assert excinfo.type == ZeroDivisionError
                assert isinstance(excinfo.value, ZeroDivisionError)

            def test_noraise():
                with pytest.raises(pytest.raises.Exception):
                    with pytest.raises(ValueError):
                           int()

            def test_raise_wrong_exception_passes_by():
                with pytest.raises(ZeroDivisionError):
                    with pytest.raises(ValueError):
                           1/0
        """"""
        )
        result = testdir.runpytest()
        result.stdout.fnmatch_lines([""*3 passed*""])

    def test_noclass(self):
        with pytest.raises(TypeError):
            pytest.raises(""wrong"", lambda: None)

    def test_invalid_arguments_to_raises(self):
        with pytest.raises(TypeError, match=""unknown""):
            with pytest.raises(TypeError, unknown=""bogus""):
                raise ValueError()

    def test_tuple(self):
        with pytest.raises((KeyError, ValueError)):
            raise KeyError(""oops"")

    def test_no_raise_message(self):
        try:
            pytest.raises(ValueError, int, ""0"")
        except pytest.raises.Exception as e:
            assert e.msg == ""DID NOT RAISE {}"".format(repr(ValueError))
        else:
            assert False, ""Expected pytest.raises.Exception""

        try:
            with pytest.raises(ValueError):
                pass
        except pytest.raises.Exception as e:
            assert e.msg == ""DID NOT RAISE {}"".format(repr(ValueError))
        else:
            assert False, ""Expected pytest.raises.Exception""

    def test_custom_raise_message(self):
        message = ""TEST_MESSAGE""
        try:
            with pytest.raises(ValueError, message=message):
                pass
        except pytest.raises.Exception as e:
            assert e.msg == message
        else:
            assert False, ""Expected pytest.raises.Exception""

    @pytest.mark.parametrize(""method"", [""function"", ""with""])
    def test_raises_cyclic_reference(self, method):
        """"""
        Ensure pytest.raises does not leave a reference cycle (#1965).
        """"""
        import gc

        class T(object):

            def __call__(self):
                raise ValueError

        t = T()
        if method == ""function"":
            pytest.raises(ValueError, t)
        else:
            with pytest.raises(ValueError):
                t()

        # ensure both forms of pytest.raises don't leave exceptions in sys.exc_info()
        assert sys.exc_info() == (None, None, None)

        del t

        # ensure the t instance is not stuck in a cyclic reference
        for o in gc.get_objects():
            assert type(o) is not T

    def test_raises_match(self):
        msg = r""with base \d+""
        with pytest.raises(ValueError, match=msg):
            int(""asdf"")

        msg = ""with base 10""
        with pytest.raises(ValueError, match=msg):
            int(""asdf"")

        msg = ""with base 16""
        expr = r""Pattern '{}' not found in 'invalid literal for int\(\) with base 10: 'asdf''"".format(
            msg
        )
        with pytest.raises(AssertionError, match=expr):
            with pytest.raises(ValueError, match=msg):
                int(""asdf"", base=10)

    def test_raises_match_wrong_type(self):
        """"""Raising an exception with the wrong type and match= given.

        pytest should throw the unexpected exception - the pattern match is not
        really relevant if we got a different exception.
        """"""
        with pytest.raises(ValueError):
            with pytest.raises(IndexError, match=""nomatch""):
                int(""asdf"")

    def test_raises_exception_looks_iterable(self):
        from six import add_metaclass

        class Meta(type(object)):

            def __getitem__(self, item):
                return 1 / 0

            def __len__(self):
                return 1

        @add_metaclass(Meta)
        class ClassLooksIterableException(Exception):
            pass

        with pytest.raises(
            Failed, match=""DID NOT RAISE <class 'raises.ClassLooksIterableException'>""
        ):
            pytest.raises(ClassLooksIterableException, lambda: None)
","
1from _pytest.outcomes import Failed
2import pytest
3import sys
4
5
6class TestRaises(object):
7
8    def test_raises(self):
9        source = ""int('qwe')""
10        excinfo = pytest.raises(ValueError, source)
11        code = excinfo.traceback[-1].frame.code
12        s = str(code.fullsource)
13
14    def test_raises_exec(self):
15        pytest.raises(ValueError, ""a,x = []"")
16
17    def test_raises_syntax_error(self):
18        pytest.raises(SyntaxError, ""qwe qwe qwe"")
19
20    def test_raises_function(self):
21        pytest.raises(ValueError, int, ""hello"")
22
23    def test_raises_callable_no_exception(self):
24
25        class A(object):
26
27            def __call__(self):
28                pass
29
30        try:
31            pytest.raises(ValueError, A())
32        except pytest.raises.Exception:
33            pass
34
35    def test_raises_as_contextmanager(self, testdir):
36        testdir.makepyfile(
37            """"""
38            from __future__ import with_statement
39            import py, pytest
40            import _pytest._code
41
42            def test_simple():
43                with pytest.raises(ZeroDivisionError) as excinfo:
44                    1/0
45                print (excinfo)
46
47            def test_noraise():
48                with pytest.raises(pytest.raises.Exception):
49                    with pytest.raises(ValueError):
50                           int()
51
52            def test_raise_wrong_exception_passes_by():
53                with pytest.raises(ZeroDivisionError):
54                    with pytest.raises(ValueError):
55                           1/0
56        """"""
57        )
58        result = testdir.runpytest()
59        result.stdout.fnmatch_lines([""*3 passed*""])
60
61    def test_noclass(self):
62        with pytest.raises(TypeError):
63            pytest.raises(""wrong"", lambda: None)
64
65    def test_invalid_arguments_to_raises(self):
66        with pytest.raises(TypeError, match=""unknown""):
67            with pytest.raises(TypeError, unknown=""bogus""):
68                raise ValueError()
69
70    def test_tuple(self):
71        with pytest.raises((KeyError, ValueError)):
72            raise KeyError(""oops"")
73
74    def test_no_raise_message(self):
75        try:
76            pytest.raises(ValueError, int, ""0"")
77        except pytest.raises.Exception as e:
78        else:
79
80        try:
81            with pytest.raises(ValueError):
82                pass
83        except pytest.raises.Exception as e:
84        else:
85
86    def test_custom_raise_message(self):
87        message = ""TEST_MESSAGE""
88        try:
89            with pytest.raises(ValueError, message=message):
90                pass
91        except pytest.raises.Exception as e:
92        else:
93
94    @pytest.mark.parametrize(""method"", [""function"", ""with""])
95    def test_raises_cyclic_reference(self, method):
96        """"""
97        Ensure pytest.raises does not leave a reference cycle (#1965).
98        """"""
99        import gc
100
101        class T(object):
102
103            def __call__(self):
104                raise ValueError
105
106        t = T()
107        if method == ""function"":
108            pytest.raises(ValueError, t)
109        else:
110            with pytest.raises(ValueError):
111                t()
112
113        # ensure both forms of pytest.raises don't leave exceptions in sys.exc_info()
114
115        del t
116
117        # ensure the t instance is not stuck in a cyclic reference
118        for o in gc.get_objects():
119
120    def test_raises_match(self):
121        msg = r""with base \d+""
122        with pytest.raises(ValueError, match=msg):
123            int(""asdf"")
124
125        msg = ""with base 10""
126        with pytest.raises(ValueError, match=msg):
127            int(""asdf"")
128
129        msg = ""with base 16""
130        expr = r""Pattern '{}' not found in 'invalid literal for int\(\) with base 10: 'asdf''"".format(
131            msg
132        )
133        with pytest.raises(AssertionError, match=expr):
134            with pytest.raises(ValueError, match=msg):
135                int(""asdf"", base=10)
136
137    def test_raises_match_wrong_type(self):
138        """"""Raising an exception with the wrong type and match= given.
139
140        pytest should throw the unexpected exception - the pattern match is not
141        really relevant if we got a different exception.
142        """"""
143        with pytest.raises(ValueError):
144            with pytest.raises(IndexError, match=""nomatch""):
145                int(""asdf"")
146
147    def test_raises_exception_looks_iterable(self):
148        from six import add_metaclass
149
150        class Meta(type(object)):
151
152            def __getitem__(self, item):
153                return 1 / 0
154
155            def __len__(self):
156                return 1
157
158        @add_metaclass(Meta)
159        class ClassLooksIterableException(Exception):
160            pass
161
162        with pytest.raises(
163            Failed, match=""DID NOT RAISE <class 'raises.ClassLooksIterableException'>""
164        ):
165            pytest.raises(ClassLooksIterableException, lambda: None)
166","[['s', '==', 'source'], ['excinfo.type', '==', 'ZeroDivisionError'], ['e.msg', '==', '""DID NOT RAISE {}"".format(repr(ValueError))'], ['False', '==', 'True'], ['e.msg', '==', '""DID NOT RAISE {}"".format(repr(ValueError))'], ['False', '==', 'True'], ['e.msg', '==', 'message'], ['False', '==', 'True'], ['sys.exc_info()', '==', '(None'], ['type(o)', '==', 'not T']]",12,10,0.8333333333333334,0.0018331805682859,"['source', 'excinfo', 'code', 's', 'pytest.raises(ValueError', '""a', 'x', 'testdir', 'result', 'message', 'method', 't', 'msg', 'expr', 'item']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['source', 'excinfo', 'code', 's', 'pytest.raises(ValueError', '""a', 'x', 'testdir', 'result', 'message', 'method', 't', 'msg', 'expr', 'item']
*Code:

1from _pytest.outcomes import Failed
2import pytest
3import sys
4
5
6class TestRaises(object):
7
8    def test_raises(self):
9        source = ""int('qwe')""
10        excinfo = pytest.raises(ValueError, source)
11        code = excinfo.traceback[-1].frame.code
12        s = str(code.fullsource)
13
14    def test_raises_exec(self):
15        pytest.raises(ValueError, ""a,x = []"")
16
17    def test_raises_syntax_error(self):
18        pytest.raises(SyntaxError, ""qwe qwe qwe"")
19
20    def test_raises_function(self):
21        pytest.raises(ValueError, int, ""hello"")
22
23    def test_raises_callable_no_exception(self):
24
25        class A(object):
26
27            def __call__(self):
28                pass
29
30        try:
31            pytest.raises(ValueError, A())
32        except pytest.raises.Exception:
33            pass
34
35    def test_raises_as_contextmanager(self, testdir):
36        testdir.makepyfile(
37            """"""
38            from __future__ import with_statement
39            import py, pytest
40            import _pytest._code
41
42            def test_simple():
43                with pytest.raises(ZeroDivisionError) as excinfo:
44                    1/0
45                print (excinfo)
46
47            def test_noraise():
48                with pytest.raises(pytest.raises.Exception):
49                    with pytest.raises(ValueError):
50                           int()
51
52            def test_raise_wrong_exception_passes_by():
53                with pytest.raises(ZeroDivisionError):
54                    with pytest.raises(ValueError):
55                           1/0
56        """"""
57        )
58        result = testdir.runpytest()
59        result.stdout.fnmatch_lines([""*3 passed*""])
60
61    def test_noclass(self):
62        with pytest.raises(TypeError):
63            pytest.raises(""wrong"", lambda: None)
64
65    def test_invalid_arguments_to_raises(self):
66        with pytest.raises(TypeError, match=""unknown""):
67            with pytest.raises(TypeError, unknown=""bogus""):
68                raise ValueError()
69
70    def test_tuple(self):
71        with pytest.raises((KeyError, ValueError)):
72            raise KeyError(""oops"")
73
74    def test_no_raise_message(self):
75        try:
76            pytest.raises(ValueError, int, ""0"")
77        except pytest.raises.Exception as e:
78        else:
79
80        try:
81            with pytest.raises(ValueError):
82                pass
83        except pytest.raises.Exception as e:
84        else:
85
86    def test_custom_raise_message(self):
87        message = ""TEST_MESSAGE""
88        try:
89            with pytest.raises(ValueError, message=message):
90                pass
91        except pytest.raises.Exception as e:
92        else:
93
94    @pytest.mark.parametrize(""method"", [""function"", ""with""])
95    def test_raises_cyclic_reference(self, method):
96        """"""
97        Ensure pytest.raises does not leave a reference cycle (#1965).
98        """"""
99        import gc
100
101        class T(object):
102
103            def __call__(self):
104                raise ValueError
105
106        t = T()
107        if method == ""function"":
108            pytest.raises(ValueError, t)
109        else:
110            with pytest.raises(ValueError):
111                t()
112
113        # ensure both forms of pytest.raises don't leave exceptions in sys.exc_info()
114
115        del t
116
117        # ensure the t instance is not stuck in a cyclic reference
118        for o in gc.get_objects():
119
120    def test_raises_match(self):
121        msg = r""with base \d+""
122        with pytest.raises(ValueError, match=msg):
123            int(""asdf"")
124
125        msg = ""with base 10""
126        with pytest.raises(ValueError, match=msg):
127            int(""asdf"")
128
129        msg = ""with base 16""
130        expr = r""Pattern '{}' not found in 'invalid literal for int\(\) with base 10: 'asdf''"".format(
131            msg
132        )
133        with pytest.raises(AssertionError, match=expr):
134            with pytest.raises(ValueError, match=msg):
135                int(""asdf"", base=10)
136
137    def test_raises_match_wrong_type(self):
138        """"""Raising an exception with the wrong type and match= given.
139
140        pytest should throw the unexpected exception - the pattern match is not
141        really relevant if we got a different exception.
142        """"""
143        with pytest.raises(ValueError):
144            with pytest.raises(IndexError, match=""nomatch""):
145                int(""asdf"")
146
147    def test_raises_exception_looks_iterable(self):
148        from six import add_metaclass
149
150        class Meta(type(object)):
151
152            def __getitem__(self, item):
153                return 1 / 0
154
155            def __len__(self):
156                return 1
157
158        @add_metaclass(Meta)
159        class ClassLooksIterableException(Exception):
160            pass
161
162        with pytest.raises(
163            Failed, match=""DID NOT RAISE <class 'raises.ClassLooksIterableException'>""
164        ):
165            pytest.raises(ClassLooksIterableException, lambda: None)
166",6690,"[[9, 'source', '!=', None, 'source should be a non-null value'],
[10, 'excinfo', '!=', None, 'excinfo should be a non-null value'],
[11, 'code', '!=', None, 'code should be a non-null value'],
[12, 's', '!=', None, 's should be a non-null value'],
[35, 'testdir', '!=', None, 'testdir should be a non-null value'],
[58, 'result', '!=', None, 'result should be a non-null value'],
[87, 'message', '!=', None, 'message should be a non-null value'],
[96, 'method', '!=', None, 'method should be a non-null value'],
[106, 't', '!=', None, 't should be a non-null value'],
[121, 'msg', '!=', None, 'msg should be a non-null value'],
[125, 'msg', '!=', None, 'msg should be a non-null value'],
[129, 'msg', '!=', None, 'msg should be a non-null value'],
[130, 'expr', '!=', None, 'expr should be a non-null value']]"
ioram7/keystone-federado-pgid2013,"import os
import sys
from nose.tools import assert_raises
from paste.cgiapp import CGIApplication, CGIError
from paste.fixture import *

data_dir = os.path.join(os.path.dirname(__file__), 'cgiapp_data')

# these CGI scripts can't work on Windows or Jython
if sys.platform != 'win32' and not sys.platform.startswith('java'):
    def test_ok():
        app = TestApp(CGIApplication({}, script='ok.cgi', path=[data_dir]))
        res = app.get('')
        assert res.header('content-type') == 'text/html; charset=UTF-8'
        assert res.full_status == '200 Okay'
        assert 'This is the body' in res

    def test_form():
        app = TestApp(CGIApplication({}, script='form.cgi', path=[data_dir]))
        res = app.post('', params={'name': 'joe'},
                       upload_files=[('up', 'file.txt', 'x'*10000)])
        assert 'file.txt' in res
        assert 'joe' in res
        assert 'x'*10000 in res

    def test_error():
        app = TestApp(CGIApplication({}, script='error.cgi', path=[data_dir]))
        assert_raises(CGIError, app.get, '', status=500)

    def test_stderr():
        app = TestApp(CGIApplication({}, script='stderr.cgi', path=[data_dir]))
        res = app.get('', expect_errors=True)
        assert res.status == 500
        assert 'error' in res
        assert 'some data' in res.errors

","
1import os
2import sys
3from paste.cgiapp import CGIApplication, CGIError
4from paste.fixture import *
5
6data_dir = os.path.join(os.path.dirname(__file__), 'cgiapp_data')
7
8# these CGI scripts can't work on Windows or Jython
9if sys.platform != 'win32' and not sys.platform.startswith('java'):
10    def test_ok():
11        app = TestApp(CGIApplication({}, script='ok.cgi', path=[data_dir]))
12        res = app.get('')
13
14    def test_form():
15        app = TestApp(CGIApplication({}, script='form.cgi', path=[data_dir]))
16        res = app.post('', params={'name': 'joe'},
17                       upload_files=[('up', 'file.txt', 'x'*10000)])
18
19    def test_error():
20        app = TestApp(CGIApplication({}, script='error.cgi', path=[data_dir]))
21
22    def test_stderr():
23        app = TestApp(CGIApplication({}, script='stderr.cgi', path=[data_dir]))
24        res = app.get('', expect_errors=True)
25
26","[[""res.header('content-type')"", '==', ""'text/html; charset=UTF-8'""], ['res.full_status', '==', ""'200 Okay'""], ['res.status', '==', '500']]",11,3,0.2727272727272727,0.0022556390977443,"['data_dir', 'app', 'res']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['data_dir', 'app', 'res']
*Code:

1import os
2import sys
3from paste.cgiapp import CGIApplication, CGIError
4from paste.fixture import *
5
6data_dir = os.path.join(os.path.dirname(__file__), 'cgiapp_data')
7
8# these CGI scripts can't work on Windows or Jython
9if sys.platform != 'win32' and not sys.platform.startswith('java'):
10    def test_ok():
11        app = TestApp(CGIApplication({}, script='ok.cgi', path=[data_dir]))
12        res = app.get('')
13
14    def test_form():
15        app = TestApp(CGIApplication({}, script='form.cgi', path=[data_dir]))
16        res = app.post('', params={'name': 'joe'},
17                       upload_files=[('up', 'file.txt', 'x'*10000)])
18
19    def test_error():
20        app = TestApp(CGIApplication({}, script='error.cgi', path=[data_dir]))
21
22    def test_stderr():
23        app = TestApp(CGIApplication({}, script='stderr.cgi', path=[data_dir]))
24        res = app.get('', expect_errors=True)
25
26",2331,"[[6, 'data_dir', '!=', '', ""data_dir should not be an empty string""],
 [11, 'app', '!=', None, ""app object should not be None after creation""],
 [12, 'res', '!=', None, ""res object should not be None after request""],
 [15, 'app', '!=', None, ""app object should not be None after creation""],
 [16, 'res', '!=', None, ""res object should not be None after request""],
 [20, 'app', '!=', None, ""app object should not be None after creation""],
 [23, 'app', '!=', None, ""app object should not be None after creation""],
 [24, 'res', '!=', None, ""res object should not be None after request""]]"
maryklayne/funcoes,"#!/usr/bin/env python

""""""Quantum field theory example

* http://en.wikipedia.org/wiki/Quantum_field_theory

This particular example is a work in progress. Currently it calculates the
scattering amplitude of the process:

    electron + positron -> photon -> electron + positron

in QED (http://en.wikipedia.org/wiki/Quantum_electrodynamics). The aim
is to be able to do any kind of calculations in QED or standard model in
SymPy, but that's a long journey.

""""""

from sympy import Basic, exp, Symbol, sin, Rational, I, Mul, Matrix, \
    ones, sqrt, pprint, simplify, Eq, sympify

from sympy.physics import msigma, mgamma

# gamma^mu
gamma0 = mgamma(0)
gamma1 = mgamma(1)
gamma2 = mgamma(2)
gamma3 = mgamma(3)
gamma5 = mgamma(5)

# sigma_i
sigma1 = msigma(1)
sigma2 = msigma(2)
sigma3 = msigma(3)

E = Symbol(""E"", real=True)
m = Symbol(""m"", real=True)


def u(p, r):
    """""" p = (p1, p2, p3); r = 0,1 """"""
    if r not in [1, 2]:
        raise ValueError(""Value of r should lie between 1 and 2"")
    p1, p2, p3 = p
    if r == 1:
        ksi = Matrix([[1], [0]])
    else:
        ksi = Matrix([[0], [1]])
    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
    if a == 0:
        a = zeros(2, 1)
    return sqrt(E + m) *\
        Matrix([[ksi[0, 0]], [ksi[1, 0]], [a[0, 0]], [a[1, 0]]])


def v(p, r):
    """""" p = (p1, p2, p3); r = 0,1 """"""
    if r not in [1, 2]:
        raise ValueError(""Value of r should lie between 1 and 2"")
    p1, p2, p3 = p
    if r == 1:
        ksi = Matrix([[1], [0]])
    else:
        ksi = -Matrix([[0], [1]])
    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
    if a == 0:
        a = zeros(2, 1)
    return sqrt(E + m) *\
        Matrix([[a[0, 0]], [a[1, 0]], [ksi[0, 0]], [ksi[1, 0]]])


def pslash(p):
    p1, p2, p3 = p
    p0 = sqrt(m**2 + p1**2 + p2**2 + p3**2)
    return gamma0*p0 - gamma1*p1 - gamma2*p2 - gamma3*p3


def Tr(M):
    return M.trace()


def xprint(lhs, rhs):
    pprint(Eq(sympify(lhs), rhs))


def main():
    a = Symbol(""a"", real=True)
    b = Symbol(""b"", real=True)
    c = Symbol(""c"", real=True)

    p = (a, b, c)

    assert u(p, 1).D*u(p, 2) == Matrix(1, 1, [0])
    assert u(p, 2).D*u(p, 1) == Matrix(1, 1, [0])

    p1, p2, p3 = [Symbol(x, real=True) for x in [""p1"", ""p2"", ""p3""]]
    pp1, pp2, pp3 = [Symbol(x, real=True) for x in [""pp1"", ""pp2"", ""pp3""]]
    k1, k2, k3 = [Symbol(x, real=True) for x in [""k1"", ""k2"", ""k3""]]
    kp1, kp2, kp3 = [Symbol(x, real=True) for x in [""kp1"", ""kp2"", ""kp3""]]

    p = (p1, p2, p3)
    pp = (pp1, pp2, pp3)

    k = (k1, k2, k3)
    kp = (kp1, kp2, kp3)

    mu = Symbol(""mu"")

    e = (pslash(p) + m*ones(4))*(pslash(k) - m*ones(4))
    f = pslash(p) + m*ones(4)
    g = pslash(p) - m*ones(4)

    # pprint(e)
    xprint('Tr(f*g)', Tr(f*g))
    # print Tr(pslash(p)*pslash(k)).expand()

    M0 = [(v(pp, 1).D*mgamma(mu)*u(p, 1))*(u(k, 1).D*mgamma(mu, True) *
                                                 v(kp, 1)) for mu in range(4)]
    M = M0[0] + M0[1] + M0[2] + M0[3]
    M = M[0]
    if not isinstance(M, Basic):
        raise TypeError(""Invalid type of variable"")
    # print M
    # print simplify(M)

    d = Symbol(""d"", real=True)  # d=E+m

    xprint('M', M)
    print(""-""*40)
    M = ((M.subs(E, d - m)).expand()*d**2).expand()
    xprint('M2', 1 / (E + m)**2*M)
    print(""-""*40)
    x, y = M.as_real_imag()
    xprint('Re(M)', x)
    xprint('Im(M)', y)
    e = x**2 + y**2
    xprint('abs(M)**2', e)
    print(""-""*40)
    xprint('Expand(abs(M)**2)', e.expand())

    # print Pauli(1)*Pauli(1)
    # print Pauli(1)**2
    # print Pauli(1)*2*Pauli(1)

if __name__ == ""__main__"":
    main()
","
1#!/usr/bin/env python
2
3""""""Quantum field theory example
4
5* http://en.wikipedia.org/wiki/Quantum_field_theory
6
7This particular example is a work in progress. Currently it calculates the
8scattering amplitude of the process:
9
10    electron + positron -> photon -> electron + positron
11
12in QED (http://en.wikipedia.org/wiki/Quantum_electrodynamics). The aim
13is to be able to do any kind of calculations in QED or standard model in
14SymPy, but that's a long journey.
15
16""""""
17
18from sympy import Basic, exp, Symbol, sin, Rational, I, Mul, Matrix, \
19    ones, sqrt, pprint, simplify, Eq, sympify
20
21from sympy.physics import msigma, mgamma
22
23# gamma^mu
24gamma0 = mgamma(0)
25gamma1 = mgamma(1)
26gamma2 = mgamma(2)
27gamma3 = mgamma(3)
28gamma5 = mgamma(5)
29
30# sigma_i
31sigma1 = msigma(1)
32sigma2 = msigma(2)
33sigma3 = msigma(3)
34
35E = Symbol(""E"", real=True)
36m = Symbol(""m"", real=True)
37
38
39def u(p, r):
40    """""" p = (p1, p2, p3); r = 0,1 """"""
41    if r not in [1, 2]:
42        raise ValueError(""Value of r should lie between 1 and 2"")
43    p1, p2, p3 = p
44    if r == 1:
45        ksi = Matrix([[1], [0]])
46    else:
47        ksi = Matrix([[0], [1]])
48    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
49    if a == 0:
50        a = zeros(2, 1)
51    return sqrt(E + m) *\
52        Matrix([[ksi[0, 0]], [ksi[1, 0]], [a[0, 0]], [a[1, 0]]])
53
54
55def v(p, r):
56    """""" p = (p1, p2, p3); r = 0,1 """"""
57    if r not in [1, 2]:
58        raise ValueError(""Value of r should lie between 1 and 2"")
59    p1, p2, p3 = p
60    if r == 1:
61        ksi = Matrix([[1], [0]])
62    else:
63        ksi = -Matrix([[0], [1]])
64    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
65    if a == 0:
66        a = zeros(2, 1)
67    return sqrt(E + m) *\
68        Matrix([[a[0, 0]], [a[1, 0]], [ksi[0, 0]], [ksi[1, 0]]])
69
70
71def pslash(p):
72    p1, p2, p3 = p
73    p0 = sqrt(m**2 + p1**2 + p2**2 + p3**2)
74    return gamma0*p0 - gamma1*p1 - gamma2*p2 - gamma3*p3
75
76
77def Tr(M):
78    return M.trace()
79
80
81def xprint(lhs, rhs):
82    pprint(Eq(sympify(lhs), rhs))
83
84
85def main():
86    a = Symbol(""a"", real=True)
87    b = Symbol(""b"", real=True)
88    c = Symbol(""c"", real=True)
89
90    p = (a, b, c)
91
92
93    p1, p2, p3 = [Symbol(x, real=True) for x in [""p1"", ""p2"", ""p3""]]
94    pp1, pp2, pp3 = [Symbol(x, real=True) for x in [""pp1"", ""pp2"", ""pp3""]]
95    k1, k2, k3 = [Symbol(x, real=True) for x in [""k1"", ""k2"", ""k3""]]
96    kp1, kp2, kp3 = [Symbol(x, real=True) for x in [""kp1"", ""kp2"", ""kp3""]]
97
98    p = (p1, p2, p3)
99    pp = (pp1, pp2, pp3)
100
101    k = (k1, k2, k3)
102    kp = (kp1, kp2, kp3)
103
104    mu = Symbol(""mu"")
105
106    e = (pslash(p) + m*ones(4))*(pslash(k) - m*ones(4))
107    f = pslash(p) + m*ones(4)
108    g = pslash(p) - m*ones(4)
109
110    # pprint(e)
111    xprint('Tr(f*g)', Tr(f*g))
112    # print Tr(pslash(p)*pslash(k)).expand()
113
114    M0 = [(v(pp, 1).D*mgamma(mu)*u(p, 1))*(u(k, 1).D*mgamma(mu, True) *
115                                                 v(kp, 1)) for mu in range(4)]
116    M = M0[0] + M0[1] + M0[2] + M0[3]
117    M = M[0]
118    if not isinstance(M, Basic):
119        raise TypeError(""Invalid type of variable"")
120    # print M
121    # print simplify(M)
122
123    d = Symbol(""d"", real=True)  # d=E+m
124
125    xprint('M', M)
126    print(""-""*40)
127    M = ((M.subs(E, d - m)).expand()*d**2).expand()
128    xprint('M2', 1 / (E + m)**2*M)
129    print(""-""*40)
130    x, y = M.as_real_imag()
131    xprint('Re(M)', x)
132    xprint('Im(M)', y)
133    e = x**2 + y**2
134    xprint('abs(M)**2', e)
135    print(""-""*40)
136    xprint('Expand(abs(M)**2)', e.expand())
137
138    # print Pauli(1)*Pauli(1)
139    # print Pauli(1)**2
140    # print Pauli(1)*2*Pauli(1)
141
142if __name__ == ""__main__"":
143    main()
144","[['u(p', '==', 'True'], ['u(p', '==', 'True']]",2,2,1.0,0.0005520287054926,"['gamma0', 'gamma1', 'gamma2', 'gamma3', 'gamma5', 'sigma1', 'sigma2', 'sigma3', 'E', 'm', 'p', 'r', '"""""" p', 'p1', 'p2', 'p3', 'ksi', 'a', 'p0', 'M', 'lhs', 'rhs', 'b', 'c', 'pp1', 'pp2', 'pp3', 'k1', 'k2', 'k3', 'kp1', 'kp2', 'kp3', 'pp', 'k', 'kp', 'mu', 'e', 'f', 'g', 'M0', 'd', 'x', 'y']",44,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['gamma0', 'gamma1', 'gamma2', 'gamma3', 'gamma5', 'sigma1', 'sigma2', 'sigma3', 'E', 'm', 'p', 'r', '"""""" p', 'p1', 'p2', 'p3', 'ksi', 'a', 'p0', 'M', 'lhs', 'rhs', 'b', 'c', 'pp1', 'pp2', 'pp3', 'k1', 'k2', 'k3', 'kp1', 'kp2', 'kp3', 'pp', 'k', 'kp', 'mu', 'e', 'f', 'g', 'M0', 'd', 'x', 'y']
*Code:

1#!/usr/bin/env python
2
3""""""Quantum field theory example
4
5* http://en.wikipedia.org/wiki/Quantum_field_theory
6
7This particular example is a work in progress. Currently it calculates the
8scattering amplitude of the process:
9
10    electron + positron -> photon -> electron + positron
11
12in QED (http://en.wikipedia.org/wiki/Quantum_electrodynamics). The aim
13is to be able to do any kind of calculations in QED or standard model in
14SymPy, but that's a long journey.
15
16""""""
17
18from sympy import Basic, exp, Symbol, sin, Rational, I, Mul, Matrix, \
19    ones, sqrt, pprint, simplify, Eq, sympify
20
21from sympy.physics import msigma, mgamma
22
23# gamma^mu
24gamma0 = mgamma(0)
25gamma1 = mgamma(1)
26gamma2 = mgamma(2)
27gamma3 = mgamma(3)
28gamma5 = mgamma(5)
29
30# sigma_i
31sigma1 = msigma(1)
32sigma2 = msigma(2)
33sigma3 = msigma(3)
34
35E = Symbol(""E"", real=True)
36m = Symbol(""m"", real=True)
37
38
39def u(p, r):
40    """""" p = (p1, p2, p3); r = 0,1 """"""
41    if r not in [1, 2]:
42        raise ValueError(""Value of r should lie between 1 and 2"")
43    p1, p2, p3 = p
44    if r == 1:
45        ksi = Matrix([[1], [0]])
46    else:
47        ksi = Matrix([[0], [1]])
48    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
49    if a == 0:
50        a = zeros(2, 1)
51    return sqrt(E + m) *\
52        Matrix([[ksi[0, 0]], [ksi[1, 0]], [a[0, 0]], [a[1, 0]]])
53
54
55def v(p, r):
56    """""" p = (p1, p2, p3); r = 0,1 """"""
57    if r not in [1, 2]:
58        raise ValueError(""Value of r should lie between 1 and 2"")
59    p1, p2, p3 = p
60    if r == 1:
61        ksi = Matrix([[1], [0]])
62    else:
63        ksi = -Matrix([[0], [1]])
64    a = (sigma1*p1 + sigma2*p2 + sigma3*p3) / (E + m)*ksi
65    if a == 0:
66        a = zeros(2, 1)
67    return sqrt(E + m) *\
68        Matrix([[a[0, 0]], [a[1, 0]], [ksi[0, 0]], [ksi[1, 0]]])
69
70
71def pslash(p):
72    p1, p2, p3 = p
73    p0 = sqrt(m**2 + p1**2 + p2**2 + p3**2)
74    return gamma0*p0 - gamma1*p1 - gamma2*p2 - gamma3*p3
75
76
77def Tr(M):
78    return M.trace()
79
80
81def xprint(lhs, rhs):
82    pprint(Eq(sympify(lhs), rhs))
83
84
85def main():
86    a = Symbol(""a"", real=True)
87    b = Symbol(""b"", real=True)
88    c = Symbol(""c"", real=True)
89
90    p = (a, b, c)
91
92
93    p1, p2, p3 = [Symbol(x, real=True) for x in [""p1"", ""p2"", ""p3""]]
94    pp1, pp2, pp3 = [Symbol(x, real=True) for x in [""pp1"", ""pp2"", ""pp3""]]
95    k1, k2, k3 = [Symbol(x, real=True) for x in [""k1"", ""k2"", ""k3""]]
96    kp1, kp2, kp3 = [Symbol(x, real=True) for x in [""kp1"", ""kp2"", ""kp3""]]
97
98    p = (p1, p2, p3)
99    pp = (pp1, pp2, pp3)
100
101    k = (k1, k2, k3)
102    kp = (kp1, kp2, kp3)
103
104    mu = Symbol(""mu"")
105
106    e = (pslash(p) + m*ones(4))*(pslash(k) - m*ones(4))
107    f = pslash(p) + m*ones(4)
108    g = pslash(p) - m*ones(4)
109
110    # pprint(e)
111    xprint('Tr(f*g)', Tr(f*g))
112    # print Tr(pslash(p)*pslash(k)).expand()
113
114    M0 = [(v(pp, 1).D*mgamma(mu)*u(p, 1))*(u(k, 1).D*mgamma(mu, True) *
115                                                 v(kp, 1)) for mu in range(4)]
116    M = M0[0] + M0[1] + M0[2] + M0[3]
117    M = M[0]
118    if not isinstance(M, Basic):
119        raise TypeError(""Invalid type of variable"")
120    # print M
121    # print simplify(M)
122
123    d = Symbol(""d"", real=True)  # d=E+m
124
125    xprint('M', M)
126    print(""-""*40)
127    M = ((M.subs(E, d - m)).expand()*d**2).expand()
128    xprint('M2', 1 / (E + m)**2*M)
129    print(""-""*40)
130    x, y = M.as_real_imag()
131    xprint('Re(M)', x)
132    xprint('Im(M)', y)
133    e = x**2 + y**2
134    xprint('abs(M)**2', e)
135    print(""-""*40)
136    xprint('Expand(abs(M)**2)', e.expand())
137
138    # print Pauli(1)*Pauli(1)
139    # print Pauli(1)**2
140    # print Pauli(1)*2*Pauli(1)
141
142if __name__ == ""__main__"":
143    main()
144",5521,"[[39, 'p', '==', 3, ""p should be a tuple of three elements""],
[39, 'r', '>=', 1, ""r should be 1 or 2""],
[39, 'r', '<=', 2, ""r should be 1 or 2""],
[55, 'p', '==', 3, ""p should be a tuple of three elements""],
[55, 'r', '>=', 1, ""r should be 1 or 2""],
[55, 'r', '<=', 2, ""r should be 1 or 2""],
[71, 'p', '==', 3, ""p should be a tuple of three elements""],
[93, 'p1', '==', 'real', ""p1 should be a real number""],
[93, 'p2', '==', 'real', ""p2 should be a real number""],
[93, 'p3', '==', 'real', ""p3 should be a real number""],
[94, 'pp1', '==', 'real', ""pp1 should be a real number""],
[94, 'pp2', '==', 'real', ""pp2 should be a real number""],
[94, 'pp3', '==', 'real', ""pp3 should be a real number""],
[95, 'k1', '==', 'real', ""k1 should be a real number""],
[95, 'k2', '==', 'real', ""k2 should be a real number""],
[95, 'k3', '==', 'real', ""k3 should be a real number""],
[96, 'kp1', '==', 'real', ""kp1 should be a real number""],
[96, 'kp2', '==', 'real', ""kp2 should be a real number""],
[96, 'kp3', '==', 'real', ""kp3 should be a real number""],
[98, 'p', '==', 3, ""p should be a tuple of three elements""],
[99, 'pp', '==', 3, ""pp should be a tuple of three elements""],
[101, 'k', '==', 3, ""k should be a tuple of three elements""],
[102, 'kp', '==', 3, ""kp should be a tuple of three elements""]]"
bkeroack/elita,"__author__ = 'bkeroack'

import logging
import elita.util
import bson

class MongoService:
    # logspam
    #__metaclass__ = elita.util.LoggingMetaClass

    def __init__(self, db):
        '''
        @type db = pymongo.database.Database
        '''
        assert db
        self.db = db

    def create_new(self, collection, keys, classname, doc, remove_existing=True):
        '''
        Creates new document in collection. Optionally, remove any existing according to keys (which specify how the
        new document is unique)

        Returns id of new document
        '''
        assert elita.util.type_check.is_string(collection)
        assert elita.util.type_check.is_dictlike(keys)
        assert elita.util.type_check.is_optional_str(classname)
        assert elita.util.type_check.is_dictlike(doc)
        assert collection
        # keys/classname are only mandatory if remove_existing=True
        assert (keys and classname and remove_existing) or not remove_existing
        if classname:
            doc['_class'] = classname
        existing = None
        if remove_existing:
            existing = [d for d in self.db[collection].find(keys)]
            for k in keys:
                doc[k] = keys[k]
            if '_id' in doc:
                del doc['_id']
        id = self.db[collection].save(doc, fsync=True)
        logging.debug(""new id: {}"".format(id))
        if existing and remove_existing:
            logging.warning(""create_new found existing docs! deleting...(collection: {}, keys: {})"".format(collection, keys))
            keys['_id'] = {'$ne': id}
            self.db[collection].remove(keys)
        return id

    def modify(self, collection, keys, path, doc_or_obj):
        '''
        Modifies document with the keys in doc. Does so atomically but remember that any key will overwrite the existing
        key.

        doc_or_obj could be None, zero, etc.

        Returns boolean indicating success
        '''
        assert hasattr(path, '__iter__')
        assert path
        assert elita.util.type_check.is_string(collection)
        assert isinstance(keys, dict)
        assert collection and keys
        dlist = [d for d in self.db[collection].find(keys)]
        assert dlist
        canonical_id = dlist[0]['_id']
        if len(dlist) > 1:
            logging.warning(""Found duplicate entries for query {} in collection {}; using the first and removing others""
                            .format(keys, collection))
            keys['_id'] = {'$ne': canonical_id}
            self.db[collection].remove(keys)
        path_dot_notation = '.'.join(path)
        result = self.db[collection].update({'_id': canonical_id}, {'$set': {path_dot_notation: doc_or_obj}}, fsync=True)
        return result['n'] == 1 and result['updatedExisting'] and not result['err']

    def save(self, collection, doc):
        '''
        Replace a document completely with a new one. Must have an '_id' field
        '''
        assert collection
        assert elita.util.type_check.is_string(collection)
        assert elita.util.type_check.is_dictlike(doc)
        assert '_id' in doc

        return self.db[collection].save(doc)

    def delete(self, collection, keys):
        '''
        Drop a document from the collection

        Return whatever pymongo returns for deletion
        '''
        assert elita.util.type_check.is_string(collection)
        assert isinstance(keys, dict)
        assert collection and keys
        dlist = [d for d in self.db[collection].find(keys)]
        assert dlist
        if len(dlist) > 1:
            logging.warning(""Found duplicate entries for query {} in collection {}; removing all"".format(keys,
                                                                                                        collection))
        return self.db[collection].remove(keys, fsync=True)

    def update_roottree(self, path, collection, id, doc=None):
        '''
        Update the root tree at path [must be a tuple of indices: ('app', 'myapp', 'builds', '123-foo')] with DBRef
        Optional doc can be passed in which will be inserted into the tree after adding DBRef field

        Return boolean indicating success
        '''
        assert hasattr(path, '__iter__')
        assert elita.util.type_check.is_string(collection)
        assert id.__class__.__name__ == 'ObjectId'
        assert elita.util.type_check.is_optional_dict(doc)
        path_dot_notation = '.'.join(path)
        root_tree_doc = doc if doc else {}
        root_tree_doc['_doc'] = bson.DBRef(collection, id)
        result = self.db['root_tree'].update({}, {'$set': {path_dot_notation: root_tree_doc}}, fsync=True)
        return result['n'] == 1 and result['updatedExisting'] and not result['err']

    def rm_roottree(self, path):
        '''
        Delete/remove the root_tree reference at path
        '''
        assert hasattr(path, '__iter__')
        assert path
        path_dot_notation = '.'.join(path)
        result = self.db['root_tree'].update({}, {'$unset': {path_dot_notation: ''}}, fsync=True)
        return result['n'] == 1 and result['updatedExisting'] and not result['err']

    def get(self, collection, keys, multi=False, empty=False):
        '''
        Thin wrapper around find()
        Retrieve a document from Mongo, keyed by name. Optionally, if duplicates are found, delete all but the first.
        If empty, it's ok to return None if nothing matches

        Returns document
        @rtype: dict | list(dict) | None
        '''
        assert elita.util.type_check.is_string(collection)
        assert isinstance(keys, dict)
        assert collection
        dlist = [d for d in self.db[collection].find(keys)]
        assert dlist or empty
        if len(dlist) > 1 and not multi:
            logging.warning(""Found duplicate entries ({}) for query {} in collection {}; dropping all but the first""
                            .format(len(dlist), keys, collection))
            keys['_id'] = {'$ne': dlist[0]['_id']}
            self.db[collection].remove(keys)
        return dlist if multi else (dlist[0] if dlist else dlist)

    def dereference(self, dbref):
        '''
        Simple wrapper around db.dereference()
        Returns document pointed to by DBRef

        @type id: bson.DBRef
        '''
        assert dbref
        assert dbref.__class__.__name__ == 'DBRef'
        return self.db.dereference(dbref)

","
1__author__ = 'bkeroack'
2
3import logging
4import elita.util
5import bson
6
7class MongoService:
8    # logspam
9    #__metaclass__ = elita.util.LoggingMetaClass
10
11    def __init__(self, db):
12        '''
13        @type db = pymongo.database.Database
14        '''
15        self.db = db
16
17    def create_new(self, collection, keys, classname, doc, remove_existing=True):
18        '''
19        Creates new document in collection. Optionally, remove any existing according to keys (which specify how the
20        new document is unique)
21
22        Returns id of new document
23        '''
24        # keys/classname are only mandatory if remove_existing=True
25        if classname:
26            doc['_class'] = classname
27        existing = None
28        if remove_existing:
29            existing = [d for d in self.db[collection].find(keys)]
30            for k in keys:
31                doc[k] = keys[k]
32            if '_id' in doc:
33                del doc['_id']
34        id = self.db[collection].save(doc, fsync=True)
35        logging.debug(""new id: {}"".format(id))
36        if existing and remove_existing:
37            logging.warning(""create_new found existing docs! deleting...(collection: {}, keys: {})"".format(collection, keys))
38            keys['_id'] = {'$ne': id}
39            self.db[collection].remove(keys)
40        return id
41
42    def modify(self, collection, keys, path, doc_or_obj):
43        '''
44        Modifies document with the keys in doc. Does so atomically but remember that any key will overwrite the existing
45        key.
46
47        doc_or_obj could be None, zero, etc.
48
49        Returns boolean indicating success
50        '''
51        dlist = [d for d in self.db[collection].find(keys)]
52        canonical_id = dlist[0]['_id']
53        if len(dlist) > 1:
54            logging.warning(""Found duplicate entries for query {} in collection {}; using the first and removing others""
55                            .format(keys, collection))
56            keys['_id'] = {'$ne': canonical_id}
57            self.db[collection].remove(keys)
58        path_dot_notation = '.'.join(path)
59        result = self.db[collection].update({'_id': canonical_id}, {'$set': {path_dot_notation: doc_or_obj}}, fsync=True)
60        return result['n'] == 1 and result['updatedExisting'] and not result['err']
61
62    def save(self, collection, doc):
63        '''
64        Replace a document completely with a new one. Must have an '_id' field
65        '''
66
67        return self.db[collection].save(doc)
68
69    def delete(self, collection, keys):
70        '''
71        Drop a document from the collection
72
73        Return whatever pymongo returns for deletion
74        '''
75        dlist = [d for d in self.db[collection].find(keys)]
76        if len(dlist) > 1:
77            logging.warning(""Found duplicate entries for query {} in collection {}; removing all"".format(keys,
78                                                                                                        collection))
79        return self.db[collection].remove(keys, fsync=True)
80
81    def update_roottree(self, path, collection, id, doc=None):
82        '''
83        Update the root tree at path [must be a tuple of indices: ('app', 'myapp', 'builds', '123-foo')] with DBRef
84        Optional doc can be passed in which will be inserted into the tree after adding DBRef field
85
86        Return boolean indicating success
87        '''
88        path_dot_notation = '.'.join(path)
89        root_tree_doc = doc if doc else {}
90        root_tree_doc['_doc'] = bson.DBRef(collection, id)
91        result = self.db['root_tree'].update({}, {'$set': {path_dot_notation: root_tree_doc}}, fsync=True)
92        return result['n'] == 1 and result['updatedExisting'] and not result['err']
93
94    def rm_roottree(self, path):
95        '''
96        Delete/remove the root_tree reference at path
97        '''
98        path_dot_notation = '.'.join(path)
99        result = self.db['root_tree'].update({}, {'$unset': {path_dot_notation: ''}}, fsync=True)
100        return result['n'] == 1 and result['updatedExisting'] and not result['err']
101
102    def get(self, collection, keys, multi=False, empty=False):
103        '''
104        Thin wrapper around find()
105        Retrieve a document from Mongo, keyed by name. Optionally, if duplicates are found, delete all but the first.
106        If empty, it's ok to return None if nothing matches
107
108        Returns document
109        @rtype: dict | list(dict) | None
110        '''
111        dlist = [d for d in self.db[collection].find(keys)]
112        if len(dlist) > 1 and not multi:
113            logging.warning(""Found duplicate entries ({}) for query {} in collection {}; dropping all but the first""
114                            .format(len(dlist), keys, collection))
115            keys['_id'] = {'$ne': dlist[0]['_id']}
116            self.db[collection].remove(keys)
117        return dlist if multi else (dlist[0] if dlist else dlist)
118
119    def dereference(self, dbref):
120        '''
121        Simple wrapper around db.dereference()
122        Returns document pointed to by DBRef
123
124        @type id: bson.DBRef
125        '''
126        return self.db.dereference(dbref)
127
128","[['db', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['elita.util.type_check.is_dictlike(keys)', '==', 'True'], ['elita.util.type_check.is_optional_str(classname)', '==', 'True'], ['elita.util.type_check.is_dictlike(doc)', '==', 'True'], ['collection', '==', 'True'], ['hasattr(path', '==', 'True'], ['path', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['collection', '==', 'True'], ['keys', '==', 'True'], ['dlist', '==', 'True'], ['collection', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['elita.util.type_check.is_dictlike(doc)', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['collection', '==', 'True'], ['keys', '==', 'True'], ['dlist', '==', 'True'], ['hasattr(path', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['id.__class__.__name__', '==', ""'ObjectId'""], ['elita.util.type_check.is_optional_dict(doc)', '==', 'True'], ['hasattr(path', '==', 'True'], ['path', '==', 'True'], ['elita.util.type_check.is_string(collection)', '==', 'True'], ['collection', '==', 'True'], ['dbref', '==', 'True'], ['dbref.__class__.__name__', '==', ""'DBRef'""]]",33,29,0.8787878787878788,0.0045157271877919,"['__author__', '#__metaclass__', 'db', '@type db', 'self.db', 'collection', 'keys', 'classname', 'doc', 'remove_existing', ""doc['_class']"", 'existing', 'doc[k]', 'id', ""keys['_id']"", 'path', 'doc_or_obj', 'dlist', 'canonical_id', 'path_dot_notation', 'result', 'root_tree_doc', ""root_tree_doc['_doc']"", 'multi', 'empty', 'dbref']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', '#__metaclass__', 'db', '@type db', 'self.db', 'collection', 'keys', 'classname', 'doc', 'remove_existing', ""doc['_class']"", 'existing', 'doc[k]', 'id', ""keys['_id']"", 'path', 'doc_or_obj', 'dlist', 'canonical_id', 'path_dot_notation', 'result', 'root_tree_doc', ""root_tree_doc['_doc']"", 'multi', 'empty', 'dbref']
*Code:

1__author__ = 'bkeroack'
2
3import logging
4import elita.util
5import bson
6
7class MongoService:
8    # logspam
9    #__metaclass__ = elita.util.LoggingMetaClass
10
11    def __init__(self, db):
12        '''
13        @type db = pymongo.database.Database
14        '''
15        self.db = db
16
17    def create_new(self, collection, keys, classname, doc, remove_existing=True):
18        '''
19        Creates new document in collection. Optionally, remove any existing according to keys (which specify how the
20        new document is unique)
21
22        Returns id of new document
23        '''
24        # keys/classname are only mandatory if remove_existing=True
25        if classname:
26            doc['_class'] = classname
27        existing = None
28        if remove_existing:
29            existing = [d for d in self.db[collection].find(keys)]
30            for k in keys:
31                doc[k] = keys[k]
32            if '_id' in doc:
33                del doc['_id']
34        id = self.db[collection].save(doc, fsync=True)
35        logging.debug(""new id: {}"".format(id))
36        if existing and remove_existing:
37            logging.warning(""create_new found existing docs! deleting...(collection: {}, keys: {})"".format(collection, keys))
38            keys['_id'] = {'$ne': id}
39            self.db[collection].remove(keys)
40        return id
41
42    def modify(self, collection, keys, path, doc_or_obj):
43        '''
44        Modifies document with the keys in doc. Does so atomically but remember that any key will overwrite the existing
45        key.
46
47        doc_or_obj could be None, zero, etc.
48
49        Returns boolean indicating success
50        '''
51        dlist = [d for d in self.db[collection].find(keys)]
52        canonical_id = dlist[0]['_id']
53        if len(dlist) > 1:
54            logging.warning(""Found duplicate entries for query {} in collection {}; using the first and removing others""
55                            .format(keys, collection))
56            keys['_id'] = {'$ne': canonical_id}
57            self.db[collection].remove(keys)
58        path_dot_notation = '.'.join(path)
59        result = self.db[collection].update({'_id': canonical_id}, {'$set': {path_dot_notation: doc_or_obj}}, fsync=True)
60        return result['n'] == 1 and result['updatedExisting'] and not result['err']
61
62    def save(self, collection, doc):
63        '''
64        Replace a document completely with a new one. Must have an '_id' field
65        '''
66
67        return self.db[collection].save(doc)
68
69    def delete(self, collection, keys):
70        '''
71        Drop a document from the collection
72
73        Return whatever pymongo returns for deletion
74        '''
75        dlist = [d for d in self.db[collection].find(keys)]
76        if len(dlist) > 1:
77            logging.warning(""Found duplicate entries for query {} in collection {}; removing all"".format(keys,
78                                                                                                        collection))
79        return self.db[collection].remove(keys, fsync=True)
80
81    def update_roottree(self, path, collection, id, doc=None):
82        '''
83        Update the root tree at path [must be a tuple of indices: ('app', 'myapp', 'builds', '123-foo')] with DBRef
84        Optional doc can be passed in which will be inserted into the tree after adding DBRef field
85
86        Return boolean indicating success
87        '''
88        path_dot_notation = '.'.join(path)
89        root_tree_doc = doc if doc else {}
90        root_tree_doc['_doc'] = bson.DBRef(collection, id)
91        result = self.db['root_tree'].update({}, {'$set': {path_dot_notation: root_tree_doc}}, fsync=True)
92        return result['n'] == 1 and result['updatedExisting'] and not result['err']
93
94    def rm_roottree(self, path):
95        '''
96        Delete/remove the root_tree reference at path
97        '''
98        path_dot_notation = '.'.join(path)
99        result = self.db['root_tree'].update({}, {'$unset': {path_dot_notation: ''}}, fsync=True)
100        return result['n'] == 1 and result['updatedExisting'] and not result['err']
101
102    def get(self, collection, keys, multi=False, empty=False):
103        '''
104        Thin wrapper around find()
105        Retrieve a document from Mongo, keyed by name. Optionally, if duplicates are found, delete all but the first.
106        If empty, it's ok to return None if nothing matches
107
108        Returns document
109        @rtype: dict | list(dict) | None
110        '''
111        dlist = [d for d in self.db[collection].find(keys)]
112        if len(dlist) > 1 and not multi:
113            logging.warning(""Found duplicate entries ({}) for query {} in collection {}; dropping all but the first""
114                            .format(len(dlist), keys, collection))
115            keys['_id'] = {'$ne': dlist[0]['_id']}
116            self.db[collection].remove(keys)
117        return dlist if multi else (dlist[0] if dlist else dlist)
118
119    def dereference(self, dbref):
120        '''
121        Simple wrapper around db.dereference()
122        Returns document pointed to by DBRef
123
124        @type id: bson.DBRef
125        '''
126        return self.db.dereference(dbref)
127
128",7023,"[[11, 'db', '!=', None, 'database must be provided to the class initialization'],
 [17, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [17, 'keys', '!=', None, 'keys must be provided to fetch or perform operations on a document'],
 [17, 'doc', '!=', None, 'doc must be a valid JSON object to perform operations'],
 [42, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [42, 'keys', '!=', None, 'keys must be provided to fetch or perform operations on a document'],
 [42, 'path', '!=', None, 'path must be provided to modify a specific document field'],
 [62, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [62, 'doc', '!=', None, 'doc must be a valid JSON object to perform operations'],
 [69, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [69, 'keys', '!=', None, 'keys must be provided to fetch or perform operations on a document'],
 [81, 'path', '!=', None, 'path should be valid to fetch a particular field in a JSON document'],
 [81, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [81, 'id', '!=', None, 'id of a specific document must be passed to perform operations'],
 [94, 'path', '!=', None, 'path should be valid to fetch a particular field in a JSON document'],
 [102, 'collection', '!=', None, 'collection must be a valid reference to perform operations'],
 [102, 'keys', '!=', None, 'keys must be provided to fetch or perform operations on a document'],
 [119, 'dbref', '!=', None, 'dbref must be provided to dereference a document']]"
kohr-h/odl,"""""""Parallel 2D example for checking that orientations are handled correctly.

Due to differing axis conventions between ODL and the ray transform
back-ends, a check is needed to confirm that the translation steps are
done correctly.

Both pairs of plots of ODL projections and NumPy axis sums should look
the same in the sense that they should show the same features in the
right arrangement (not flipped, rotated, etc.).

This example is best run in Spyder section-by-section (CTRL-Enter).
""""""

# %% Set up the things that never change

import matplotlib.pyplot as plt
import numpy as np
import odl

# Set back-end here (for `None` the fastest available is chosen)
impl = None
# Set a volume shift. This should move the projections in the same direction.
shift = np.array([0.0, 25.0])

img_shape = (100, 150)
img_max_pt = np.array(img_shape, dtype=float) / 2
img_min_pt = -img_max_pt
reco_space = odl.uniform_discr(img_min_pt + shift, img_max_pt + shift,
                               img_shape, dtype='float32')
phantom = odl.phantom.indicate_proj_axis(reco_space)

assert np.allclose(reco_space.cell_sides, 1)

# Check projections at 0, 90, 180 and 270 degrees
grid = odl.RectGrid([0, np.pi / 2, np.pi, 3 * np.pi / 2])
angle_partition = odl.uniform_partition_fromgrid(grid)

# Make detector large enough to cover the object
det_size = np.floor(1.1 * np.sqrt(np.sum(np.square(img_shape))))
det_shape = int(det_size)
det_max_pt = det_size / 2
det_min_pt = -det_max_pt
detector_partition = odl.uniform_partition(det_min_pt, det_max_pt, det_shape)

assert np.allclose(detector_partition.cell_sides, 1)

# Sum manually using Numpy
sum_along_x = np.sum(phantom, axis=0)
sum_along_y = np.sum(phantom, axis=1)


# %% Test forward projection along y axis


geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)
# Check initial configuration
assert np.allclose(geometry.det_axis_init, [1, 0])
assert np.allclose(geometry.det_pos_init, [0, 1])

# Create projections
ray_trafo = odl.tomo.RayTransform(reco_space, geometry, impl=impl)
proj_data = ray_trafo(phantom)

# Axis in this image is x. This corresponds to 0 degrees.
proj_data.show(indices=[0, None],
               title='Projection at 0 Degrees ~ Sum Along Y Axis')
fig, ax = plt.subplots()
ax.plot(sum_along_y)
ax.set_xlabel('x')
plt.title('Sum Along Y Axis')
plt.show()
# Check axes in geometry
axis_sum_y = geometry.det_axis(np.deg2rad(0))
assert np.allclose(axis_sum_y, [1, 0])


# %% Test forward projection along x axis


# Axis in this image is y. This corresponds to 90 degrees.
proj_data.show(indices=[1, None],
               title='Projection at 90 Degrees ~ Sum Along X Axis')
fig, ax = plt.subplots()
ax.plot(sum_along_x)
ax.set_xlabel('y')
plt.title('Sum Along X Axis')
plt.show()
# Check axes in geometry
axis_sum_x = geometry.det_axis(np.deg2rad(90))
assert np.allclose(axis_sum_x, [0, 1])
","
1""""""Parallel 2D example for checking that orientations are handled correctly.
2
3Due to differing axis conventions between ODL and the ray transform
4back-ends, a check is needed to confirm that the translation steps are
5done correctly.
6
7Both pairs of plots of ODL projections and NumPy axis sums should look
8the same in the sense that they should show the same features in the
9right arrangement (not flipped, rotated, etc.).
10
11This example is best run in Spyder section-by-section (CTRL-Enter).
12""""""
13
14# %% Set up the things that never change
15
16import matplotlib.pyplot as plt
17import numpy as np
18import odl
19
20# Set back-end here (for `None` the fastest available is chosen)
21impl = None
22# Set a volume shift. This should move the projections in the same direction.
23shift = np.array([0.0, 25.0])
24
25img_shape = (100, 150)
26img_max_pt = np.array(img_shape, dtype=float) / 2
27img_min_pt = -img_max_pt
28reco_space = odl.uniform_discr(img_min_pt + shift, img_max_pt + shift,
29                               img_shape, dtype='float32')
30phantom = odl.phantom.indicate_proj_axis(reco_space)
31
32
33# Check projections at 0, 90, 180 and 270 degrees
34grid = odl.RectGrid([0, np.pi / 2, np.pi, 3 * np.pi / 2])
35angle_partition = odl.uniform_partition_fromgrid(grid)
36
37# Make detector large enough to cover the object
38det_size = np.floor(1.1 * np.sqrt(np.sum(np.square(img_shape))))
39det_shape = int(det_size)
40det_max_pt = det_size / 2
41det_min_pt = -det_max_pt
42detector_partition = odl.uniform_partition(det_min_pt, det_max_pt, det_shape)
43
44
45# Sum manually using Numpy
46sum_along_x = np.sum(phantom, axis=0)
47sum_along_y = np.sum(phantom, axis=1)
48
49
50# %% Test forward projection along y axis
51
52
53geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)
54# Check initial configuration
55
56# Create projections
57ray_trafo = odl.tomo.RayTransform(reco_space, geometry, impl=impl)
58proj_data = ray_trafo(phantom)
59
60# Axis in this image is x. This corresponds to 0 degrees.
61proj_data.show(indices=[0, None],
62               title='Projection at 0 Degrees ~ Sum Along Y Axis')
63fig, ax = plt.subplots()
64ax.plot(sum_along_y)
65ax.set_xlabel('x')
66plt.title('Sum Along Y Axis')
67plt.show()
68# Check axes in geometry
69axis_sum_y = geometry.det_axis(np.deg2rad(0))
70
71
72# %% Test forward projection along x axis
73
74
75# Axis in this image is y. This corresponds to 90 degrees.
76proj_data.show(indices=[1, None],
77               title='Projection at 90 Degrees ~ Sum Along X Axis')
78fig, ax = plt.subplots()
79ax.plot(sum_along_x)
80ax.set_xlabel('y')
81plt.title('Sum Along X Axis')
82plt.show()
83# Check axes in geometry
84axis_sum_x = geometry.det_axis(np.deg2rad(90))
85","[['np.allclose(reco_space.cell_sides', '==', 'True'], ['np.allclose(detector_partition.cell_sides', '==', 'True'], ['np.allclose(geometry.det_axis_init', '==', 'True'], ['np.allclose(geometry.det_pos_init', '==', 'True'], ['np.allclose(axis_sum_y', '==', 'True'], ['np.allclose(axis_sum_x', '==', 'True']]",6,6,1.0,0.0020840569642236,"['impl', 'shift', 'img_shape', 'img_max_pt', 'img_min_pt', 'reco_space', 'phantom', 'grid', 'angle_partition', 'det_size', 'det_shape', 'det_max_pt', 'det_min_pt', 'detector_partition', 'sum_along_x', 'sum_along_y', 'geometry', 'ray_trafo', 'proj_data', 'fig', 'ax', 'axis_sum_y', 'axis_sum_x']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['impl', 'shift', 'img_shape', 'img_max_pt', 'img_min_pt', 'reco_space', 'phantom', 'grid', 'angle_partition', 'det_size', 'det_shape', 'det_max_pt', 'det_min_pt', 'detector_partition', 'sum_along_x', 'sum_along_y', 'geometry', 'ray_trafo', 'proj_data', 'fig', 'ax', 'axis_sum_y', 'axis_sum_x']
*Code:

1""""""Parallel 2D example for checking that orientations are handled correctly.
2
3Due to differing axis conventions between ODL and the ray transform
4back-ends, a check is needed to confirm that the translation steps are
5done correctly.
6
7Both pairs of plots of ODL projections and NumPy axis sums should look
8the same in the sense that they should show the same features in the
9right arrangement (not flipped, rotated, etc.).
10
11This example is best run in Spyder section-by-section (CTRL-Enter).
12""""""
13
14# %% Set up the things that never change
15
16import matplotlib.pyplot as plt
17import numpy as np
18import odl
19
20# Set back-end here (for `None` the fastest available is chosen)
21impl = None
22# Set a volume shift. This should move the projections in the same direction.
23shift = np.array([0.0, 25.0])
24
25img_shape = (100, 150)
26img_max_pt = np.array(img_shape, dtype=float) / 2
27img_min_pt = -img_max_pt
28reco_space = odl.uniform_discr(img_min_pt + shift, img_max_pt + shift,
29                               img_shape, dtype='float32')
30phantom = odl.phantom.indicate_proj_axis(reco_space)
31
32
33# Check projections at 0, 90, 180 and 270 degrees
34grid = odl.RectGrid([0, np.pi / 2, np.pi, 3 * np.pi / 2])
35angle_partition = odl.uniform_partition_fromgrid(grid)
36
37# Make detector large enough to cover the object
38det_size = np.floor(1.1 * np.sqrt(np.sum(np.square(img_shape))))
39det_shape = int(det_size)
40det_max_pt = det_size / 2
41det_min_pt = -det_max_pt
42detector_partition = odl.uniform_partition(det_min_pt, det_max_pt, det_shape)
43
44
45# Sum manually using Numpy
46sum_along_x = np.sum(phantom, axis=0)
47sum_along_y = np.sum(phantom, axis=1)
48
49
50# %% Test forward projection along y axis
51
52
53geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)
54# Check initial configuration
55
56# Create projections
57ray_trafo = odl.tomo.RayTransform(reco_space, geometry, impl=impl)
58proj_data = ray_trafo(phantom)
59
60# Axis in this image is x. This corresponds to 0 degrees.
61proj_data.show(indices=[0, None],
62               title='Projection at 0 Degrees ~ Sum Along Y Axis')
63fig, ax = plt.subplots()
64ax.plot(sum_along_y)
65ax.set_xlabel('x')
66plt.title('Sum Along Y Axis')
67plt.show()
68# Check axes in geometry
69axis_sum_y = geometry.det_axis(np.deg2rad(0))
70
71
72# %% Test forward projection along x axis
73
74
75# Axis in this image is y. This corresponds to 90 degrees.
76proj_data.show(indices=[1, None],
77               title='Projection at 90 Degrees ~ Sum Along X Axis')
78fig, ax = plt.subplots()
79ax.plot(sum_along_x)
80ax.set_xlabel('y')
81plt.title('Sum Along X Axis')
82plt.show()
83# Check axes in geometry
84axis_sum_x = geometry.det_axis(np.deg2rad(90))
85",4438,"[[21, 'impl', '==', None, 'impl should be None for the fastest available choice'], 
 [23, 'shift', '==', [0.0,25.0], 'this should move the projections in the same direction'], 
 [25, 'img_shape', '==', [100,150], 'image shape should match the declared dimensions'], 
 [28, 'reco_space', '!=', None, 'reco_space should be initialized and not None'], 
 [30, 'phantom', '!=', None, 'phantom should be initialized and not None'],
 [34, 'grid', '==', [0, np.pi / 2, np.pi, 3 * np.pi / 2], 'grid values must match the given values'], 
 [38, 'det_size', '>=', 0, 'detector size should not be less than 0'], 
 [39, 'det_shape', '==', 'det_size', 'detector shape should be equal to detector size'], 
 [42, 'detector_partition', '!=', None, 'detector partition should be initialized'], 
 [49, 'sum_along_x', '!=', None, 'sum along x-axis must be calculated'], 
 [50, 'sum_along_y', '!=', None, 'sum along y-axis must be calculated'], 
 [57, 'ray_trafo', '!=', None, 'ray_trafo must be created successfully'], 
 [58, 'proj_data', '!=', None, 'projection data must be created successfully'], 
 [69, 'axis_sum_y', '!=', None, 'axis sum along y must be calculated'], 
 [84, 'axis_sum_x', '!=', None, 'axis sum along x must be calculated']]"
brianthelion/pyramid_swagger,"# -*- coding: utf-8 -*-
from pyramid.config import Configurator
from pyramid.view import view_config

import webob


@view_config(route_name='throw_400', renderer='json')
def throw_error(request):
    request.response.status = webob.exc.HTTPBadRequest.code
    return dict(error=dict(details='Throwing error!'))


@view_config(route_name='standard', renderer='json')
def standard(request, path_arg):
    return {
        'raw_response': 'foo',
        'logging_info': {},
    }


@view_config(route_name='sample_nonstring', renderer='json')
@view_config(route_name='get_with_non_string_query_args', renderer='json')
@view_config(route_name='post_with_primitive_body', renderer='json')
@view_config(route_name='sample_header', renderer='json')
@view_config(route_name='sample_post', renderer='json')
@view_config(route_name='post_with_form_params', renderer='json')
@view_config(route_name='post_with_file_upload', renderer='json')
def sample(request):
    if not request.registry.settings.get('skip_swagger_data_assert'):
        assert request.swagger_data
    return {}


def main(global_config, **settings):
    """""" Very basic pyramid app """"""
    config = Configurator(settings=settings)

    config.include('pyramid_swagger')

    config.add_route(
        'sample_nonstring',
        '/sample/nonstring/{int_arg}/{float_arg}/{boolean_arg}',
    )
    config.add_route('standard', '/sample/{path_arg}/resource')
    config.add_route(
        'get_with_non_string_query_args',
        '/get_with_non_string_query_args',
    )
    config.add_route('post_with_primitive_body', '/post_with_primitive_body')
    config.add_route('post_with_form_params', '/post_with_form_params')
    config.add_route('post_with_file_upload', '/post_with_file_upload')
    config.add_route('sample_post', '/sample')
    config.add_route('sample_header', '/sample/header')
    config.add_route('throw_400', '/throw_400')

    config.scan()
    return config.make_wsgi_app()
","
1# -*- coding: utf-8 -*-
2from pyramid.config import Configurator
3from pyramid.view import view_config
4
5import webob
6
7
8@view_config(route_name='throw_400', renderer='json')
9def throw_error(request):
10    request.response.status = webob.exc.HTTPBadRequest.code
11    return dict(error=dict(details='Throwing error!'))
12
13
14@view_config(route_name='standard', renderer='json')
15def standard(request, path_arg):
16    return {
17        'raw_response': 'foo',
18        'logging_info': {},
19    }
20
21
22@view_config(route_name='sample_nonstring', renderer='json')
23@view_config(route_name='get_with_non_string_query_args', renderer='json')
24@view_config(route_name='post_with_primitive_body', renderer='json')
25@view_config(route_name='sample_header', renderer='json')
26@view_config(route_name='sample_post', renderer='json')
27@view_config(route_name='post_with_form_params', renderer='json')
28@view_config(route_name='post_with_file_upload', renderer='json')
29def sample(request):
30    return {}
31
32
33def main(global_config, **settings):
34    """""" Very basic pyramid app """"""
35    config = Configurator(settings=settings)
36
37    config.include('pyramid_swagger')
38
39    config.add_route(
40        'sample_nonstring',
41        '/sample/nonstring/{int_arg}/{float_arg}/{boolean_arg}',
42    )
43    config.add_route('standard', '/sample/{path_arg}/resource')
44    config.add_route(
45        'get_with_non_string_query_args',
46        '/get_with_non_string_query_args',
47    )
48    config.add_route('post_with_primitive_body', '/post_with_primitive_body')
49    config.add_route('post_with_form_params', '/post_with_form_params')
50    config.add_route('post_with_file_upload', '/post_with_file_upload')
51    config.add_route('sample_post', '/sample')
52    config.add_route('sample_header', '/sample/header')
53    config.add_route('throw_400', '/throw_400')
54
55    config.scan()
56    return config.make_wsgi_app()
57","[['request.swagger_data', '==', 'True']]",2,1,0.5,0.0005115089514066,"['request', 'request.response.status', 'path_arg', 'global_config', '**settings', 'config']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['request', 'request.response.status', 'path_arg', 'global_config', '**settings', 'config']
*Code:

1# -*- coding: utf-8 -*-
2from pyramid.config import Configurator
3from pyramid.view import view_config
4
5import webob
6
7
8@view_config(route_name='throw_400', renderer='json')
9def throw_error(request):
10    request.response.status = webob.exc.HTTPBadRequest.code
11    return dict(error=dict(details='Throwing error!'))
12
13
14@view_config(route_name='standard', renderer='json')
15def standard(request, path_arg):
16    return {
17        'raw_response': 'foo',
18        'logging_info': {},
19    }
20
21
22@view_config(route_name='sample_nonstring', renderer='json')
23@view_config(route_name='get_with_non_string_query_args', renderer='json')
24@view_config(route_name='post_with_primitive_body', renderer='json')
25@view_config(route_name='sample_header', renderer='json')
26@view_config(route_name='sample_post', renderer='json')
27@view_config(route_name='post_with_form_params', renderer='json')
28@view_config(route_name='post_with_file_upload', renderer='json')
29def sample(request):
30    return {}
31
32
33def main(global_config, **settings):
34    """""" Very basic pyramid app """"""
35    config = Configurator(settings=settings)
36
37    config.include('pyramid_swagger')
38
39    config.add_route(
40        'sample_nonstring',
41        '/sample/nonstring/{int_arg}/{float_arg}/{boolean_arg}',
42    )
43    config.add_route('standard', '/sample/{path_arg}/resource')
44    config.add_route(
45        'get_with_non_string_query_args',
46        '/get_with_non_string_query_args',
47    )
48    config.add_route('post_with_primitive_body', '/post_with_primitive_body')
49    config.add_route('post_with_form_params', '/post_with_form_params')
50    config.add_route('post_with_file_upload', '/post_with_file_upload')
51    config.add_route('sample_post', '/sample')
52    config.add_route('sample_header', '/sample/header')
53    config.add_route('throw_400', '/throw_400')
54
55    config.scan()
56    return config.make_wsgi_app()
57",3426,"[[9, 'request', '!=', None, ""the function 'throw_error' requires a request""],
[9, 'request.response.status', '==', 400, ""'throw_error' changes the HTTP response code to 400""],
[10, 'request.response.status', '==', 400, ""The status has been modified and should remain 400 after exiting 'throw_error'""],
[15, 'request', '!=', None, ""the function 'standard' requires a request""],
[15, 'path_arg', '!=', None, ""'standard' requires a path argument""],
[23, 'request', '!=', None, ""the functions 'sample_nonstring', 'get_with_non_string_query_args', 'post_with_primitive_body', 'sample_header', 'sample_post', 'post_with_form_params', 'post_with_file_upload' require a request""],
[33, 'global_config', '!=', None, ""'main' requires a global_config""],
[33, '**settings', '!=', None, ""'main' requires settings""],
[35, 'config', '!=', None, ""'config' must not return None after being assigned by 'Configurator(settings=settings)' ""],
[56, 'config.make_wsgi_app()', '!=', None, ""the returned wsgi app must not be None""]]"
ioam/svn-history,"""""""
GeneratorSheet: a sheet with a pattern generator.


$Id$
""""""
__version__='$Revision: 7629 $'


import param
from topo.base.sheet import Sheet
from topo.base.patterngenerator import PatternGenerator,Constant
from topo.base.simulation import FunctionEvent, PeriodicEventSequence


# JLALERT: This sheet should have override_plasticity_state/restore_plasticity_state
# functions that call override_plasticity_state/restore_plasticty_state on the
# sheet output_fn and input_generator output_fn.
class GeneratorSheet(Sheet):
    """"""
    Sheet for generating a series of 2D patterns.

    Typically generates the patterns by choosing parameters from a
    random distribution, but can use any mechanism.
    """"""

    src_ports=['Activity']
    
    period = param.Number(default=1,bounds=(0,None), inclusive_bounds=(False, True), constant=True, doc=
        ""Delay (in Simulation time) between generating new input patterns."")
    
    phase  = param.Number(default=0.05,doc=
        """"""
        Delay after the start of the Simulation (at time zero) before
        generating an input pattern.  For a clocked, feedforward simulation, 
        one would typically want to use a small nonzero phase and use delays less
        than the user-visible step size (typically 1.0), so that inputs are
        generated and processed before this step is complete.
        """""")
    
    input_generator = param.ClassSelector(PatternGenerator,default=Constant(),
        doc=""""""Specifies a particular PatternGenerator type to use when creating patterns."""""")

    
    def __init__(self,**params):
        super(GeneratorSheet,self).__init__(**params)
        self.input_generator_stack = []
        self.set_input_generator(self.input_generator)


    def set_input_generator(self,new_ig,push_existing=False):
        """"""
        Set the input_generator, overwriting the existing one by default.

        If push_existing is false, the existing input_generator is
        discarded permanently.  Otherwise, the existing one is put
        onto a stack, and can later be restored by calling
        pop_input_generator.
        """"""

        if push_existing:
            self.push_input_generator()

        # CEBALERT: replaces any bounds specified for the
        # PatternGenerator with this sheet's own bounds. When
        # PatternGenerators can draw patterns into supplied
        # boundingboxes, should remove this.
        new_ig.set_matrix_dimensions(self.bounds, self.xdensity, self.ydensity)
        self.input_generator = new_ig


    def push_input_generator(self):
        """"""Push the current input_generator onto a stack for future retrieval.""""""
        self.input_generator_stack.append(self.input_generator)

        # CEBALERT: would be better to reorganize code so that
        # push_input_generator must be supplied with a new generator.
        # CEBALERT: presumably we can remove this import.
        from topo.base.patterngenerator import Constant
        self.set_input_generator(Constant()) 

               
    def pop_input_generator(self):
        """"""
        Discard the current input_generator, and retrieve the previous one from the stack.

        Warns if no input_generator is available on the stack.
        """"""
        if len(self.input_generator_stack) >= 1:
            self.set_input_generator(self.input_generator_stack.pop())
        else:
            self.warning('There is no previous input generator to restore.')

    def generate(self):
        """"""
        Generate the output and send it out the Activity port.
        """"""
        self.verbose(""Generating a new pattern"")

        # JABALERT: What does the [:] achieve here?  Copying the
        # values, instead of the pointer to the array?  Is that
        # guaranteed?
        self.activity[:] = self.input_generator()

        if self.apply_output_fns:
            for of in self.output_fns:
                of(self.activity)
        self.send_output(src_port='Activity',data=self.activity)
                                                        
              
    def start(self):
        assert self.simulation

        if self.period > 0:
            # if it has a positive period, then schedule a repeating event to trigger it
            e=FunctionEvent(0,self.generate)
            now = self.simulation.time()
            self.simulation.enqueue_event(PeriodicEventSequence(now+self.simulation.convert_to_time_type(self.phase),self.simulation.convert_to_time_type(self.period),[e]))

    def input_event(self,conn,data):
        raise NotImplementedError
","
1""""""
2GeneratorSheet: a sheet with a pattern generator.
3
4
5$Id$
6""""""
7__version__='$Revision: 7629 $'
8
9
10import param
11from topo.base.sheet import Sheet
12from topo.base.patterngenerator import PatternGenerator,Constant
13from topo.base.simulation import FunctionEvent, PeriodicEventSequence
14
15
16# JLALERT: This sheet should have override_plasticity_state/restore_plasticity_state
17# functions that call override_plasticity_state/restore_plasticty_state on the
18# sheet output_fn and input_generator output_fn.
19class GeneratorSheet(Sheet):
20    """"""
21    Sheet for generating a series of 2D patterns.
22
23    Typically generates the patterns by choosing parameters from a
24    random distribution, but can use any mechanism.
25    """"""
26
27    src_ports=['Activity']
28    
29    period = param.Number(default=1,bounds=(0,None), inclusive_bounds=(False, True), constant=True, doc=
30        ""Delay (in Simulation time) between generating new input patterns."")
31    
32    phase  = param.Number(default=0.05,doc=
33        """"""
34        Delay after the start of the Simulation (at time zero) before
35        generating an input pattern.  For a clocked, feedforward simulation, 
36        one would typically want to use a small nonzero phase and use delays less
37        than the user-visible step size (typically 1.0), so that inputs are
38        generated and processed before this step is complete.
39        """""")
40    
41    input_generator = param.ClassSelector(PatternGenerator,default=Constant(),
42        doc=""""""Specifies a particular PatternGenerator type to use when creating patterns."""""")
43
44    
45    def __init__(self,**params):
46        super(GeneratorSheet,self).__init__(**params)
47        self.input_generator_stack = []
48        self.set_input_generator(self.input_generator)
49
50
51    def set_input_generator(self,new_ig,push_existing=False):
52        """"""
53        Set the input_generator, overwriting the existing one by default.
54
55        If push_existing is false, the existing input_generator is
56        discarded permanently.  Otherwise, the existing one is put
57        onto a stack, and can later be restored by calling
58        pop_input_generator.
59        """"""
60
61        if push_existing:
62            self.push_input_generator()
63
64        # CEBALERT: replaces any bounds specified for the
65        # PatternGenerator with this sheet's own bounds. When
66        # PatternGenerators can draw patterns into supplied
67        # boundingboxes, should remove this.
68        new_ig.set_matrix_dimensions(self.bounds, self.xdensity, self.ydensity)
69        self.input_generator = new_ig
70
71
72    def push_input_generator(self):
73        """"""Push the current input_generator onto a stack for future retrieval.""""""
74        self.input_generator_stack.append(self.input_generator)
75
76        # CEBALERT: would be better to reorganize code so that
77        # push_input_generator must be supplied with a new generator.
78        # CEBALERT: presumably we can remove this import.
79        from topo.base.patterngenerator import Constant
80        self.set_input_generator(Constant()) 
81
82               
83    def pop_input_generator(self):
84        """"""
85        Discard the current input_generator, and retrieve the previous one from the stack.
86
87        Warns if no input_generator is available on the stack.
88        """"""
89        if len(self.input_generator_stack) >= 1:
90            self.set_input_generator(self.input_generator_stack.pop())
91        else:
92            self.warning('There is no previous input generator to restore.')
93
94    def generate(self):
95        """"""
96        Generate the output and send it out the Activity port.
97        """"""
98        self.verbose(""Generating a new pattern"")
99
100        # JABALERT: What does the [:] achieve here?  Copying the
101        # values, instead of the pointer to the array?  Is that
102        # guaranteed?
103        self.activity[:] = self.input_generator()
104
105        if self.apply_output_fns:
106            for of in self.output_fns:
107                of(self.activity)
108        self.send_output(src_port='Activity',data=self.activity)
109                                                        
110              
111    def start(self):
112
113        if self.period > 0:
114            # if it has a positive period, then schedule a repeating event to trigger it
115            e=FunctionEvent(0,self.generate)
116            now = self.simulation.time()
117            self.simulation.enqueue_event(PeriodicEventSequence(now+self.simulation.convert_to_time_type(self.phase),self.simulation.convert_to_time_type(self.period),[e]))
118
119    def input_event(self,conn,data):
120        raise NotImplementedError
121","[['self.simulation', '==', 'True']]",1,1,1.0,0.000219298245614,"['period', 'phase', 'input_generator', '**params', 'self.input_generator_stack', 'new_ig', 'push_existing', 'self.input_generator', 'self.activity[:]', 'now', 'conn', 'data']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['period', 'phase', 'input_generator', '**params', 'self.input_generator_stack', 'new_ig', 'push_existing', 'self.input_generator', 'self.activity[:]', 'now', 'conn', 'data']
*Code:

1""""""
2GeneratorSheet: a sheet with a pattern generator.
3
4
5$Id$
6""""""
7__version__='$Revision: 7629 $'
8
9
10import param
11from topo.base.sheet import Sheet
12from topo.base.patterngenerator import PatternGenerator,Constant
13from topo.base.simulation import FunctionEvent, PeriodicEventSequence
14
15
16# JLALERT: This sheet should have override_plasticity_state/restore_plasticity_state
17# functions that call override_plasticity_state/restore_plasticty_state on the
18# sheet output_fn and input_generator output_fn.
19class GeneratorSheet(Sheet):
20    """"""
21    Sheet for generating a series of 2D patterns.
22
23    Typically generates the patterns by choosing parameters from a
24    random distribution, but can use any mechanism.
25    """"""
26
27    src_ports=['Activity']
28    
29    period = param.Number(default=1,bounds=(0,None), inclusive_bounds=(False, True), constant=True, doc=
30        ""Delay (in Simulation time) between generating new input patterns."")
31    
32    phase  = param.Number(default=0.05,doc=
33        """"""
34        Delay after the start of the Simulation (at time zero) before
35        generating an input pattern.  For a clocked, feedforward simulation, 
36        one would typically want to use a small nonzero phase and use delays less
37        than the user-visible step size (typically 1.0), so that inputs are
38        generated and processed before this step is complete.
39        """""")
40    
41    input_generator = param.ClassSelector(PatternGenerator,default=Constant(),
42        doc=""""""Specifies a particular PatternGenerator type to use when creating patterns."""""")
43
44    
45    def __init__(self,**params):
46        super(GeneratorSheet,self).__init__(**params)
47        self.input_generator_stack = []
48        self.set_input_generator(self.input_generator)
49
50
51    def set_input_generator(self,new_ig,push_existing=False):
52        """"""
53        Set the input_generator, overwriting the existing one by default.
54
55        If push_existing is false, the existing input_generator is
56        discarded permanently.  Otherwise, the existing one is put
57        onto a stack, and can later be restored by calling
58        pop_input_generator.
59        """"""
60
61        if push_existing:
62            self.push_input_generator()
63
64        # CEBALERT: replaces any bounds specified for the
65        # PatternGenerator with this sheet's own bounds. When
66        # PatternGenerators can draw patterns into supplied
67        # boundingboxes, should remove this.
68        new_ig.set_matrix_dimensions(self.bounds, self.xdensity, self.ydensity)
69        self.input_generator = new_ig
70
71
72    def push_input_generator(self):
73        """"""Push the current input_generator onto a stack for future retrieval.""""""
74        self.input_generator_stack.append(self.input_generator)
75
76        # CEBALERT: would be better to reorganize code so that
77        # push_input_generator must be supplied with a new generator.
78        # CEBALERT: presumably we can remove this import.
79        from topo.base.patterngenerator import Constant
80        self.set_input_generator(Constant()) 
81
82               
83    def pop_input_generator(self):
84        """"""
85        Discard the current input_generator, and retrieve the previous one from the stack.
86
87        Warns if no input_generator is available on the stack.
88        """"""
89        if len(self.input_generator_stack) >= 1:
90            self.set_input_generator(self.input_generator_stack.pop())
91        else:
92            self.warning('There is no previous input generator to restore.')
93
94    def generate(self):
95        """"""
96        Generate the output and send it out the Activity port.
97        """"""
98        self.verbose(""Generating a new pattern"")
99
100        # JABALERT: What does the [:] achieve here?  Copying the
101        # values, instead of the pointer to the array?  Is that
102        # guaranteed?
103        self.activity[:] = self.input_generator()
104
105        if self.apply_output_fns:
106            for of in self.output_fns:
107                of(self.activity)
108        self.send_output(src_port='Activity',data=self.activity)
109                                                        
110              
111    def start(self):
112
113        if self.period > 0:
114            # if it has a positive period, then schedule a repeating event to trigger it
115            e=FunctionEvent(0,self.generate)
116            now = self.simulation.time()
117            self.simulation.enqueue_event(PeriodicEventSequence(now+self.simulation.convert_to_time_type(self.phase),self.simulation.convert_to_time_type(self.period),[e]))
118
119    def input_event(self,conn,data):
120        raise NotImplementedError
121",6339,"[[29, 'period', '>=', 0, ""Delay between generating new input patterns should be non-negative""],
[32, 'phase', '>=', 0, ""Delay after the start of the Simulation should be non-negative""],
[45, '**params', '!=', None, ""Parameters should not be None to properly initialize GeneratorSheet""],
[51, 'new_ig', '!=', None, ""Input generator should not be None to set the generator""],
[51, 'push_existing', '==', False, ""push_existing defaults to False to overwrite existing generator if not explicitly specified""],
[83, 'self.input_generator_stack', '!=', [], ""Input generator stack should not be empty for pop operation""],
[95, 'self.input_generator', '!=', None, ""Activity generator should not be None to generate output""],
[111, 'self.period', '>', 0, ""period should be positive to schedule a repeating event""],
[119, 'conn', '!=', None, ""Connection should not be None to handle input events""],
[119, 'data', '!=', None, ""Data should not be None to handle input events""]]"
michaupl/wordtester,"#-*- coding: utf-8 -*-

import unittest
from top.WordClass import Word


class  WordClassTestsTestCase(unittest.TestCase):
    def setUp(self):
        self.word1 = Word(""dog"",""pies, piesek"",""I walk my dog everyday"")
        self.word2 = Word(""what's up?"",""co jest?, co tam?, co słychać?"")
        self.word3 = Word(""language"",""język"")

    def testAsk(self):
        """"""Check if the ask method (and most of the others in this class) works fine""""""

        evalEr = ""wrong evaluation in the ask method: ""
        ansEr = ""ask returned wrong expected answer: ""

        ans1 = self.word1.ask(""piesek"")
        assert ans1[0] is True, evalEr
        assert ans1[1] == [""piesek""], ansEr + str(ans1[1])

        ans2 = self.word2.ask(""lala"")
        assert ans2[0] is False, evalEr
        assert ans2[1] == ""co jest?, co tam?, co słychać?"", ansEr + str(ans2[1])

        ans3 = self.word3.ask(""dialekt, język"")
        assert ans3[0] is True, evalEr
        assert ans3[1] == [""język""], ansEr + str(ans3[1])

    def testDifficulty(self):
        """"""Check if the difficulty is calculated right""""""
        word = Word(""a"",""b,c"")
        for i in range(7):
            word.ask(""b"")
        for i in range(3):
            word.ask(""sdsa"")
        assert word.getWeight() == 70.00, ""wrong calculation of weight:""
        assert word.calculateDifficulty() == 'MEDIUM', ""wrong difficulty returned""

if __name__ == '__main__':
    unittest.main()

","
1#-*- coding: utf-8 -*-
2
3import unittest
4from top.WordClass import Word
5
6
7class  WordClassTestsTestCase(unittest.TestCase):
8    def setUp(self):
9        self.word1 = Word(""dog"",""pies, piesek"",""I walk my dog everyday"")
10        self.word2 = Word(""what's up?"",""co jest?, co tam?, co słychać?"")
11        self.word3 = Word(""language"",""język"")
12
13    def testAsk(self):
14        """"""Check if the ask method (and most of the others in this class) works fine""""""
15
16        evalEr = ""wrong evaluation in the ask method: ""
17        ansEr = ""ask returned wrong expected answer: ""
18
19        ans1 = self.word1.ask(""piesek"")
20
21        ans2 = self.word2.ask(""lala"")
22
23        ans3 = self.word3.ask(""dialekt, język"")
24
25    def testDifficulty(self):
26        """"""Check if the difficulty is calculated right""""""
27        word = Word(""a"",""b,c"")
28        for i in range(7):
29            word.ask(""b"")
30        for i in range(3):
31            word.ask(""sdsa"")
32
33if __name__ == '__main__':
34    unittest.main()
35
36","[['ans1[0]', '==', 'True'], ['ans1[1]', '==', '[""piesek""]'], ['ans2[0]', '==', 'False'], ['ans2[1]', '==', '""co jest?'], ['ans3[0]', '==', 'True'], ['ans3[1]', '==', '[""język""]'], ['word.getWeight()', '==', '70.00'], ['word.calculateDifficulty()', '==', ""'MEDIUM'""]]",8,8,1.0,0.0055594162612925,"['self.word1', 'self.word2', 'self.word3', 'evalEr', 'ansEr', 'ans1', 'ans2', 'ans3', 'word']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.word1', 'self.word2', 'self.word3', 'evalEr', 'ansEr', 'ans1', 'ans2', 'ans3', 'word']
*Code:

1#-*- coding: utf-8 -*-
2
3import unittest
4from top.WordClass import Word
5
6
7class  WordClassTestsTestCase(unittest.TestCase):
8    def setUp(self):
9        self.word1 = Word(""dog"",""pies, piesek"",""I walk my dog everyday"")
10        self.word2 = Word(""what's up?"",""co jest?, co tam?, co słychać?"")
11        self.word3 = Word(""language"",""język"")
12
13    def testAsk(self):
14        """"""Check if the ask method (and most of the others in this class) works fine""""""
15
16        evalEr = ""wrong evaluation in the ask method: ""
17        ansEr = ""ask returned wrong expected answer: ""
18
19        ans1 = self.word1.ask(""piesek"")
20
21        ans2 = self.word2.ask(""lala"")
22
23        ans3 = self.word3.ask(""dialekt, język"")
24
25    def testDifficulty(self):
26        """"""Check if the difficulty is calculated right""""""
27        word = Word(""a"",""b,c"")
28        for i in range(7):
29            word.ask(""b"")
30        for i in range(3):
31            word.ask(""sdsa"")
32
33if __name__ == '__main__':
34    unittest.main()
35
36",2504,"[[9, 'self.word1', '!=', None, ""Word objects must be properly instantiated""],
 [10, 'self.word2', '!=', None, ""Word objects must be properly instantiated""],
 [11, 'self.word3', '!=', None, ""Word objects must be properly instantiated""],
 [19, 'ans1', '!=', None, ""ask method on Word objects must not return None""],
 [21, 'ans2', '!=', None, ""ask method on Word objects must not return None""],
 [23, 'ans3', '!=', None, ""ask method on Word objects must not return None""],
 [28, 'word', '!=', None, ""Word objects must be properly instantiated""]]"
NINAnor/QGIS,"# -*- coding: utf-8 -*-
""""""QGIS Unit tests for core QgsFontUtils class

From build dir: ctest -R PyQgsFontUtils -V

.. note:: This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
""""""
__author__ = 'Larry Shaffer'
__date__ = '2014/02/19'
__copyright__ = 'Copyright 2014, The QGIS Project'
# This will get replaced with a git SHA1 when you do a git archive
__revision__ = '$Format:%H$'

from qgis.core import QgsFontUtils
from qgis.testing import (
    start_app,
    unittest
)
from utilities import (
    getTestFontFamily,
    loadTestFonts
)

start_app()


class TestQgsFontUtils(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        cls._family = getTestFontFamily()
        cls._has_style = QgsFontUtils.fontFamilyHasStyle

    def test_loading_base_test_fonts(self):
        loadTestFonts()

    def test_loading_every_test_font(self):
        QgsFontUtils.loadStandardTestFonts(['All'])
        # styles = ''
        # for style in QFontDatabase().styles(self._family):
        #     styles += ' ' + style
        # print self._family + ' styles:' + styles

        res = (
            self._has_style(self._family, 'Roman')
            and self._has_style(self._family, 'Oblique')
            and self._has_style(self._family, 'Bold')
            and self._has_style(self._family, 'Bold Oblique')
        )
        msg = self._family + ' test font styles could not be loaded'
        assert res, msg

    def test_get_specific_test_font(self):
        # default returned is Roman at 12 pt
        f = QgsFontUtils.getStandardTestFont('Bold Oblique', 14)
        """""":type: QFont""""""
        res = (
            f.family() == self._family
            and f.bold()
            and f.italic()
            and f.pointSize() == 14
        )
        msg = self._family + ' test font Bold Oblique at 14 pt not retrieved'
        assert res, msg


if __name__ == '__main__':
    unittest.main()
","
1# -*- coding: utf-8 -*-
2""""""QGIS Unit tests for core QgsFontUtils class
3
4From build dir: ctest -R PyQgsFontUtils -V
5
6.. note:: This program is free software; you can redistribute it and/or modify
7it under the terms of the GNU General Public License as published by
8the Free Software Foundation; either version 2 of the License, or
9(at your option) any later version.
10""""""
11__author__ = 'Larry Shaffer'
12__date__ = '2014/02/19'
13__copyright__ = 'Copyright 2014, The QGIS Project'
14# This will get replaced with a git SHA1 when you do a git archive
15__revision__ = '$Format:%H$'
16
17from qgis.core import QgsFontUtils
18from qgis.testing import (
19    start_app,
20    unittest
21)
22from utilities import (
23    getTestFontFamily,
24    loadTestFonts
25)
26
27start_app()
28
29
30class TestQgsFontUtils(unittest.TestCase):
31
32    @classmethod
33    def setUpClass(cls):
34        cls._family = getTestFontFamily()
35        cls._has_style = QgsFontUtils.fontFamilyHasStyle
36
37    def test_loading_base_test_fonts(self):
38        loadTestFonts()
39
40    def test_loading_every_test_font(self):
41        QgsFontUtils.loadStandardTestFonts(['All'])
42        # styles = ''
43        # for style in QFontDatabase().styles(self._family):
44        #     styles += ' ' + style
45        # print self._family + ' styles:' + styles
46
47        res = (
48            self._has_style(self._family, 'Roman')
49            and self._has_style(self._family, 'Oblique')
50            and self._has_style(self._family, 'Bold')
51            and self._has_style(self._family, 'Bold Oblique')
52        )
53        msg = self._family + ' test font styles could not be loaded'
54
55    def test_get_specific_test_font(self):
56        # default returned is Roman at 12 pt
57        f = QgsFontUtils.getStandardTestFont('Bold Oblique', 14)
58        """""":type: QFont""""""
59        res = (
60            f.family() == self._family
61            and f.bold()
62            and f.italic()
63            and f.pointSize() == 14
64        )
65        msg = self._family + ' test font Bold Oblique at 14 pt not retrieved'
66
67
68if __name__ == '__main__':
69    unittest.main()
70","[['res', '==', 'True'], ['res', '==', 'True']]",2,2,1.0,0.0009546539379474,"['__author__', '__date__', '__copyright__', '__revision__', 'cls', 'cls._family', 'cls._has_style', '# styles', 'res', 'msg', 'f']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', '__date__', '__copyright__', '__revision__', 'cls', 'cls._family', 'cls._has_style', '# styles', 'res', 'msg', 'f']
*Code:

1# -*- coding: utf-8 -*-
2""""""QGIS Unit tests for core QgsFontUtils class
3
4From build dir: ctest -R PyQgsFontUtils -V
5
6.. note:: This program is free software; you can redistribute it and/or modify
7it under the terms of the GNU General Public License as published by
8the Free Software Foundation; either version 2 of the License, or
9(at your option) any later version.
10""""""
11__author__ = 'Larry Shaffer'
12__date__ = '2014/02/19'
13__copyright__ = 'Copyright 2014, The QGIS Project'
14# This will get replaced with a git SHA1 when you do a git archive
15__revision__ = '$Format:%H$'
16
17from qgis.core import QgsFontUtils
18from qgis.testing import (
19    start_app,
20    unittest
21)
22from utilities import (
23    getTestFontFamily,
24    loadTestFonts
25)
26
27start_app()
28
29
30class TestQgsFontUtils(unittest.TestCase):
31
32    @classmethod
33    def setUpClass(cls):
34        cls._family = getTestFontFamily()
35        cls._has_style = QgsFontUtils.fontFamilyHasStyle
36
37    def test_loading_base_test_fonts(self):
38        loadTestFonts()
39
40    def test_loading_every_test_font(self):
41        QgsFontUtils.loadStandardTestFonts(['All'])
42        # styles = ''
43        # for style in QFontDatabase().styles(self._family):
44        #     styles += ' ' + style
45        # print self._family + ' styles:' + styles
46
47        res = (
48            self._has_style(self._family, 'Roman')
49            and self._has_style(self._family, 'Oblique')
50            and self._has_style(self._family, 'Bold')
51            and self._has_style(self._family, 'Bold Oblique')
52        )
53        msg = self._family + ' test font styles could not be loaded'
54
55    def test_get_specific_test_font(self):
56        # default returned is Roman at 12 pt
57        f = QgsFontUtils.getStandardTestFont('Bold Oblique', 14)
58        """""":type: QFont""""""
59        res = (
60            f.family() == self._family
61            and f.bold()
62            and f.italic()
63            and f.pointSize() == 14
64        )
65        msg = self._family + ' test font Bold Oblique at 14 pt not retrieved'
66
67
68if __name__ == '__main__':
69    unittest.main()
70",3689,"Based on the provided code, the following assertions could be inserted:

[11, ""__author__"", ""=="", 'Larry Shaffer', ""to confirm the validity of the author""]
[12, ""__date__"", ""=="", '2014/02/19', ""to confirm the validity of the project's date""]
[13, ""__copyright__"", ""=="", 'Copyright 2014, The QGIS Project', ""to confirm the validity of the copyright notice""]
[32, ""cls"", ""!="", None, ""to confirm that cls is not None""]
[35, ""cls._family"", ""!="", None, ""to assert that family is not None""]
[35, ""cls._has_style"", ""!="", None, ""to assert that has_style is not None""]
[48, ""res"", ""=="", True, ""to validate that all font styles could be loaded""]
[60, ""res"", ""=="", True, ""to verify that specific font properties are correct""]
[65, ""msg"", ""=="", cls._family + ' test font Bold Oblique at 14 pt not retrieved', ""to confirm descriptive error message was properly formatted""]"
partofthething/home-assistant,"""""""Test the nexia config flow.""""""
from unittest.mock import MagicMock, patch

from requests.exceptions import ConnectTimeout, HTTPError

from homeassistant import config_entries, setup
from homeassistant.components.nexia.const import DOMAIN
from homeassistant.const import CONF_PASSWORD, CONF_USERNAME


async def test_form(hass):
    """"""Test we get the form.""""""
    await setup.async_setup_component(hass, ""persistent_notification"", {})
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    assert result[""type""] == ""form""
    assert result[""errors""] == {}

    with patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.get_name"",
        return_value=""myhouse"",
    ), patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
        side_effect=MagicMock(),
    ), patch(
        ""homeassistant.components.nexia.async_setup"", return_value=True
    ) as mock_setup, patch(
        ""homeassistant.components.nexia.async_setup_entry"",
        return_value=True,
    ) as mock_setup_entry:
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )
        await hass.async_block_till_done()

    assert result2[""type""] == ""create_entry""
    assert result2[""title""] == ""myhouse""
    assert result2[""data""] == {
        CONF_USERNAME: ""username"",
        CONF_PASSWORD: ""password"",
    }
    assert len(mock_setup.mock_calls) == 1
    assert len(mock_setup_entry.mock_calls) == 1


async def test_form_invalid_auth(hass):
    """"""Test we handle invalid auth.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(""homeassistant.components.nexia.config_flow.NexiaHome.login""):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""invalid_auth""}


async def test_form_cannot_connect(hass):
    """"""Test we handle cannot connect error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
        side_effect=ConnectTimeout,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""cannot_connect""}


async def test_form_invalid_auth_http_401(hass):
    """"""Test we handle invalid auth error from http 401.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    response_mock = MagicMock()
    type(response_mock).status_code = 401
    with patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
        side_effect=HTTPError(response=response_mock),
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""invalid_auth""}


async def test_form_cannot_connect_not_found(hass):
    """"""Test we handle cannot connect from an http not found error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    response_mock = MagicMock()
    type(response_mock).status_code = 404
    with patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
        side_effect=HTTPError(response=response_mock),
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""cannot_connect""}


async def test_form_broad_exception(hass):
    """"""Test we handle invalid auth error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    with patch(
        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
        side_effect=ValueError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
        )

    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""unknown""}
","
1""""""Test the nexia config flow.""""""
2from unittest.mock import MagicMock, patch
3
4from requests.exceptions import ConnectTimeout, HTTPError
5
6from homeassistant import config_entries, setup
7from homeassistant.components.nexia.const import DOMAIN
8from homeassistant.const import CONF_PASSWORD, CONF_USERNAME
9
10
11async def test_form(hass):
12    """"""Test we get the form.""""""
13    await setup.async_setup_component(hass, ""persistent_notification"", {})
14    result = await hass.config_entries.flow.async_init(
15        DOMAIN, context={""source"": config_entries.SOURCE_USER}
16    )
17
18    with patch(
19        ""homeassistant.components.nexia.config_flow.NexiaHome.get_name"",
20        return_value=""myhouse"",
21    ), patch(
22        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
23        side_effect=MagicMock(),
24    ), patch(
25        ""homeassistant.components.nexia.async_setup"", return_value=True
26    ) as mock_setup, patch(
27        ""homeassistant.components.nexia.async_setup_entry"",
28        return_value=True,
29    ) as mock_setup_entry:
30        result2 = await hass.config_entries.flow.async_configure(
31            result[""flow_id""],
32            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
33        )
34        await hass.async_block_till_done()
35
36        CONF_USERNAME: ""username"",
37        CONF_PASSWORD: ""password"",
38    }
39
40
41async def test_form_invalid_auth(hass):
42    """"""Test we handle invalid auth.""""""
43    result = await hass.config_entries.flow.async_init(
44        DOMAIN, context={""source"": config_entries.SOURCE_USER}
45    )
46
47    with patch(""homeassistant.components.nexia.config_flow.NexiaHome.login""):
48        result2 = await hass.config_entries.flow.async_configure(
49            result[""flow_id""],
50            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
51        )
52
53
54
55async def test_form_cannot_connect(hass):
56    """"""Test we handle cannot connect error.""""""
57    result = await hass.config_entries.flow.async_init(
58        DOMAIN, context={""source"": config_entries.SOURCE_USER}
59    )
60
61    with patch(
62        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
63        side_effect=ConnectTimeout,
64    ):
65        result2 = await hass.config_entries.flow.async_configure(
66            result[""flow_id""],
67            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
68        )
69
70
71
72async def test_form_invalid_auth_http_401(hass):
73    """"""Test we handle invalid auth error from http 401.""""""
74    result = await hass.config_entries.flow.async_init(
75        DOMAIN, context={""source"": config_entries.SOURCE_USER}
76    )
77
78    response_mock = MagicMock()
79    type(response_mock).status_code = 401
80    with patch(
81        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
82        side_effect=HTTPError(response=response_mock),
83    ):
84        result2 = await hass.config_entries.flow.async_configure(
85            result[""flow_id""],
86            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
87        )
88
89
90
91async def test_form_cannot_connect_not_found(hass):
92    """"""Test we handle cannot connect from an http not found error.""""""
93    result = await hass.config_entries.flow.async_init(
94        DOMAIN, context={""source"": config_entries.SOURCE_USER}
95    )
96
97    response_mock = MagicMock()
98    type(response_mock).status_code = 404
99    with patch(
100        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
101        side_effect=HTTPError(response=response_mock),
102    ):
103        result2 = await hass.config_entries.flow.async_configure(
104            result[""flow_id""],
105            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
106        )
107
108
109
110async def test_form_broad_exception(hass):
111    """"""Test we handle invalid auth error.""""""
112    result = await hass.config_entries.flow.async_init(
113        DOMAIN, context={""source"": config_entries.SOURCE_USER}
114    )
115
116    with patch(
117        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
118        side_effect=ValueError,
119    ):
120        result2 = await hass.config_entries.flow.async_configure(
121            result[""flow_id""],
122            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
123        )
124
125","[['result[""type""]', '==', '""form""'], ['result[""errors""]', '==', '{}'], ['result2[""type""]', '==', '""create_entry""'], ['result2[""title""]', '==', '""myhouse""'], ['result2[""data""]', '==', '{'], ['len(mock_setup.mock_calls)', '==', '1'], ['len(mock_setup_entry.mock_calls)', '==', '1'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""invalid_auth""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""invalid_auth""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""unknown""}']]",17,17,1.0,0.0035008237232289,"['hass', 'result', 'result2', 'response_mock', 'type(response_mock).status_code']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'result', 'result2', 'response_mock', 'type(response_mock).status_code']
*Code:

1""""""Test the nexia config flow.""""""
2from unittest.mock import MagicMock, patch
3
4from requests.exceptions import ConnectTimeout, HTTPError
5
6from homeassistant import config_entries, setup
7from homeassistant.components.nexia.const import DOMAIN
8from homeassistant.const import CONF_PASSWORD, CONF_USERNAME
9
10
11async def test_form(hass):
12    """"""Test we get the form.""""""
13    await setup.async_setup_component(hass, ""persistent_notification"", {})
14    result = await hass.config_entries.flow.async_init(
15        DOMAIN, context={""source"": config_entries.SOURCE_USER}
16    )
17
18    with patch(
19        ""homeassistant.components.nexia.config_flow.NexiaHome.get_name"",
20        return_value=""myhouse"",
21    ), patch(
22        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
23        side_effect=MagicMock(),
24    ), patch(
25        ""homeassistant.components.nexia.async_setup"", return_value=True
26    ) as mock_setup, patch(
27        ""homeassistant.components.nexia.async_setup_entry"",
28        return_value=True,
29    ) as mock_setup_entry:
30        result2 = await hass.config_entries.flow.async_configure(
31            result[""flow_id""],
32            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
33        )
34        await hass.async_block_till_done()
35
36        CONF_USERNAME: ""username"",
37        CONF_PASSWORD: ""password"",
38    }
39
40
41async def test_form_invalid_auth(hass):
42    """"""Test we handle invalid auth.""""""
43    result = await hass.config_entries.flow.async_init(
44        DOMAIN, context={""source"": config_entries.SOURCE_USER}
45    )
46
47    with patch(""homeassistant.components.nexia.config_flow.NexiaHome.login""):
48        result2 = await hass.config_entries.flow.async_configure(
49            result[""flow_id""],
50            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
51        )
52
53
54
55async def test_form_cannot_connect(hass):
56    """"""Test we handle cannot connect error.""""""
57    result = await hass.config_entries.flow.async_init(
58        DOMAIN, context={""source"": config_entries.SOURCE_USER}
59    )
60
61    with patch(
62        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
63        side_effect=ConnectTimeout,
64    ):
65        result2 = await hass.config_entries.flow.async_configure(
66            result[""flow_id""],
67            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
68        )
69
70
71
72async def test_form_invalid_auth_http_401(hass):
73    """"""Test we handle invalid auth error from http 401.""""""
74    result = await hass.config_entries.flow.async_init(
75        DOMAIN, context={""source"": config_entries.SOURCE_USER}
76    )
77
78    response_mock = MagicMock()
79    type(response_mock).status_code = 401
80    with patch(
81        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
82        side_effect=HTTPError(response=response_mock),
83    ):
84        result2 = await hass.config_entries.flow.async_configure(
85            result[""flow_id""],
86            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
87        )
88
89
90
91async def test_form_cannot_connect_not_found(hass):
92    """"""Test we handle cannot connect from an http not found error.""""""
93    result = await hass.config_entries.flow.async_init(
94        DOMAIN, context={""source"": config_entries.SOURCE_USER}
95    )
96
97    response_mock = MagicMock()
98    type(response_mock).status_code = 404
99    with patch(
100        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
101        side_effect=HTTPError(response=response_mock),
102    ):
103        result2 = await hass.config_entries.flow.async_configure(
104            result[""flow_id""],
105            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
106        )
107
108
109
110async def test_form_broad_exception(hass):
111    """"""Test we handle invalid auth error.""""""
112    result = await hass.config_entries.flow.async_init(
113        DOMAIN, context={""source"": config_entries.SOURCE_USER}
114    )
115
116    with patch(
117        ""homeassistant.components.nexia.config_flow.NexiaHome.login"",
118        side_effect=ValueError,
119    ):
120        result2 = await hass.config_entries.flow.async_configure(
121            result[""flow_id""],
122            {CONF_USERNAME: ""username"", CONF_PASSWORD: ""password""},
123        )
124
125",5836,"[[11, 'hass', '!=', None, ""Test function 'test_form' needs 'hass' to initiate setup component""],
 [13, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [29, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""],
 [41, 'hass', '!=', None, ""Test function 'test_form_invalid_auth' needs 'hass' to initiate setup component""],
 [43, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [47, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""],
 [55, 'hass', '!=', None, ""Test function 'test_form_cannot_connect' needs 'hass' to initiate setup component""],
 [57, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [63, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""],
 [72, 'hass', '!=', None, ""Test function 'test_form_invalid_auth_http_401' needs 'hass' to initiate setup component""],
 [74, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [78, 'response_mock', '!=', None, 'response_mock should be defined before being used'],
 [78, 'type(response_mock).status_code', '==', 401, ""status code for 'response_mock' should be 401""],
 [82, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""],
 [91, 'hass', '!=', None, ""Test function 'test_form_cannot_connect_not_found' needs 'hass' to initiate setup component""],
 [93, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [97, 'response_mock', '!=', None, 'response_mock should be defined before being used'],
 [97, 'type(response_mock).status_code', '==', 404, ""status code for 'response_mock' should be 404""],
 [101, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""],
 [110, 'hass', '!=', None, ""Test function 'test_form_broad_exception' needs 'hass' to initiate setup component""],
 [112, 'result', '!=', None, ""'result' must be defined after 'async_init'""],
 [118, 'result2', '!=', None, ""'result2' must be defined after 'async_configure'""]]"
yfried/ansible,"# -*- coding: utf-8 -*-
#
# Copyright (c) 2017 F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import sys

from nose.plugins.skip import SkipTest
if sys.version_info < (2, 7):
    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")

from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigip_ssl_certificate import ArgumentSpec
    from library.modules.bigip_ssl_certificate import ApiParameters
    from library.modules.bigip_ssl_certificate import ModuleParameters
    from library.modules.bigip_ssl_certificate import ModuleManager

    # In Ansible 2.8, Ansible changed import paths.
    from test.units.compat import unittest
    from test.units.compat.mock import Mock
    from test.units.compat.mock import patch

    from test.units.modules.utils import set_module_args
except ImportError:
    try:
        from ansible.modules.network.f5.bigip_ssl_certificate import ArgumentSpec
        from ansible.modules.network.f5.bigip_ssl_certificate import ApiParameters
        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleParameters
        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleManager

        # Ansible 2.8 imports
        from units.compat import unittest
        from units.compat.mock import Mock
        from units.compat.mock import patch

        from units.modules.utils import set_module_args
    except ImportError:
        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")

fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters_cert(self):
        cert_content = load_fixture('create_insecure_cert1.crt')
        args = dict(
            content=cert_content,
            name=""cert1"",
            partition=""Common"",
            state=""present"",
        )
        p = ModuleParameters(params=args)
        assert p.name == 'cert1'
        assert p.filename == 'cert1.crt'
        assert 'Signature Algorithm' in p.content
        assert '-----BEGIN CERTIFICATE-----' in p.content
        assert '-----END CERTIFICATE-----' in p.content
        assert p.checksum == '1e55aa57ee166a380e756b5aa4a835c5849490fe'
        assert p.state == 'present'

    def test_module_issuer_cert_key(self):
        args = dict(
            issuer_cert='foo',
            partition=""Common"",
        )
        p = ModuleParameters(params=args)
        assert p.issuer_cert == '/Common/foo.crt'

    def test_api_issuer_cert_key(self):
        args = load_fixture('load_sys_file_ssl_cert_with_issuer_cert.json')
        p = ApiParameters(params=args)
        assert p.issuer_cert == '/Common/intermediate.crt'


class TestCertificateManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()

    def test_import_certificate_and_key_no_key_passphrase(self, *args):
        set_module_args(dict(
            name='foo',
            content=load_fixture('cert1.crt'),
            state='present',
            password='password',
            server='localhost',
            user='admin'
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )

        # Override methods in the specific type of manager
        mm = ModuleManager(module=module)
        mm.exists = Mock(side_effect=[False, True])
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True

    def test_import_certificate_chain(self, *args):
        set_module_args(dict(
            name='foo',
            content=load_fixture('chain1.crt'),
            state='present',
            password='password',
            server='localhost',
            user='admin'
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )

        # Override methods in the specific type of manager
        mm = ModuleManager(module=module)
        mm.exists = Mock(side_effect=[False, True])
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
","
1# -*- coding: utf-8 -*-
2#
3# Copyright (c) 2017 F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import sys
12
13from nose.plugins.skip import SkipTest
14if sys.version_info < (2, 7):
15    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_ssl_certificate import ArgumentSpec
21    from library.modules.bigip_ssl_certificate import ApiParameters
22    from library.modules.bigip_ssl_certificate import ModuleParameters
23    from library.modules.bigip_ssl_certificate import ModuleManager
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    try:
33        from ansible.modules.network.f5.bigip_ssl_certificate import ArgumentSpec
34        from ansible.modules.network.f5.bigip_ssl_certificate import ApiParameters
35        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleParameters
36        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleManager
37
38        # Ansible 2.8 imports
39        from units.compat import unittest
40        from units.compat.mock import Mock
41        from units.compat.mock import patch
42
43        from units.modules.utils import set_module_args
44    except ImportError:
45        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
46
47fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
48fixture_data = {}
49
50
51def load_fixture(name):
52    path = os.path.join(fixture_path, name)
53
54    if path in fixture_data:
55        return fixture_data[path]
56
57    with open(path) as f:
58        data = f.read()
59
60    try:
61        data = json.loads(data)
62    except Exception:
63        pass
64
65    fixture_data[path] = data
66    return data
67
68
69class TestParameters(unittest.TestCase):
70    def test_module_parameters_cert(self):
71        cert_content = load_fixture('create_insecure_cert1.crt')
72        args = dict(
73            content=cert_content,
74            name=""cert1"",
75            partition=""Common"",
76            state=""present"",
77        )
78        p = ModuleParameters(params=args)
79
80    def test_module_issuer_cert_key(self):
81        args = dict(
82            issuer_cert='foo',
83            partition=""Common"",
84        )
85        p = ModuleParameters(params=args)
86
87    def test_api_issuer_cert_key(self):
88        args = load_fixture('load_sys_file_ssl_cert_with_issuer_cert.json')
89        p = ApiParameters(params=args)
90
91
92class TestCertificateManager(unittest.TestCase):
93
94    def setUp(self):
95        self.spec = ArgumentSpec()
96
97    def test_import_certificate_and_key_no_key_passphrase(self, *args):
98        set_module_args(dict(
99            name='foo',
100            content=load_fixture('cert1.crt'),
101            state='present',
102            password='password',
103            server='localhost',
104            user='admin'
105        ))
106
107        module = AnsibleModule(
108            argument_spec=self.spec.argument_spec,
109            supports_check_mode=self.spec.supports_check_mode
110        )
111
112        # Override methods in the specific type of manager
113        mm = ModuleManager(module=module)
114        mm.exists = Mock(side_effect=[False, True])
115        mm.create_on_device = Mock(return_value=True)
116
117        results = mm.exec_module()
118
119
120    def test_import_certificate_chain(self, *args):
121        set_module_args(dict(
122            name='foo',
123            content=load_fixture('chain1.crt'),
124            state='present',
125            password='password',
126            server='localhost',
127            user='admin'
128        ))
129
130        module = AnsibleModule(
131            argument_spec=self.spec.argument_spec,
132            supports_check_mode=self.spec.supports_check_mode
133        )
134
135        # Override methods in the specific type of manager
136        mm = ModuleManager(module=module)
137        mm.exists = Mock(side_effect=[False, True])
138        mm.create_on_device = Mock(return_value=True)
139
140        results = mm.exec_module()
141
142","[['p.name', '==', ""'cert1'""], ['p.filename', '==', ""'cert1.crt'""], ['p.checksum', '==', ""'1e55aa57ee166a380e756b5aa4a835c5849490fe'""], ['p.state', '==', ""'present'""], ['p.issuer_cert', '==', ""'/Common/foo.crt'""], ['p.issuer_cert', '==', ""'/Common/intermediate.crt'""], [""results['changed']"", '==', 'True'], [""results['changed']"", '==', 'True']]",11,8,0.7272727272727273,0.0016715419974926,"['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'cert_content', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'cert_content', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright (c) 2017 F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import sys
12
13from nose.plugins.skip import SkipTest
14if sys.version_info < (2, 7):
15    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_ssl_certificate import ArgumentSpec
21    from library.modules.bigip_ssl_certificate import ApiParameters
22    from library.modules.bigip_ssl_certificate import ModuleParameters
23    from library.modules.bigip_ssl_certificate import ModuleManager
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    try:
33        from ansible.modules.network.f5.bigip_ssl_certificate import ArgumentSpec
34        from ansible.modules.network.f5.bigip_ssl_certificate import ApiParameters
35        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleParameters
36        from ansible.modules.network.f5.bigip_ssl_certificate import ModuleManager
37
38        # Ansible 2.8 imports
39        from units.compat import unittest
40        from units.compat.mock import Mock
41        from units.compat.mock import patch
42
43        from units.modules.utils import set_module_args
44    except ImportError:
45        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
46
47fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
48fixture_data = {}
49
50
51def load_fixture(name):
52    path = os.path.join(fixture_path, name)
53
54    if path in fixture_data:
55        return fixture_data[path]
56
57    with open(path) as f:
58        data = f.read()
59
60    try:
61        data = json.loads(data)
62    except Exception:
63        pass
64
65    fixture_data[path] = data
66    return data
67
68
69class TestParameters(unittest.TestCase):
70    def test_module_parameters_cert(self):
71        cert_content = load_fixture('create_insecure_cert1.crt')
72        args = dict(
73            content=cert_content,
74            name=""cert1"",
75            partition=""Common"",
76            state=""present"",
77        )
78        p = ModuleParameters(params=args)
79
80    def test_module_issuer_cert_key(self):
81        args = dict(
82            issuer_cert='foo',
83            partition=""Common"",
84        )
85        p = ModuleParameters(params=args)
86
87    def test_api_issuer_cert_key(self):
88        args = load_fixture('load_sys_file_ssl_cert_with_issuer_cert.json')
89        p = ApiParameters(params=args)
90
91
92class TestCertificateManager(unittest.TestCase):
93
94    def setUp(self):
95        self.spec = ArgumentSpec()
96
97    def test_import_certificate_and_key_no_key_passphrase(self, *args):
98        set_module_args(dict(
99            name='foo',
100            content=load_fixture('cert1.crt'),
101            state='present',
102            password='password',
103            server='localhost',
104            user='admin'
105        ))
106
107        module = AnsibleModule(
108            argument_spec=self.spec.argument_spec,
109            supports_check_mode=self.spec.supports_check_mode
110        )
111
112        # Override methods in the specific type of manager
113        mm = ModuleManager(module=module)
114        mm.exists = Mock(side_effect=[False, True])
115        mm.create_on_device = Mock(return_value=True)
116
117        results = mm.exec_module()
118
119
120    def test_import_certificate_chain(self, *args):
121        set_module_args(dict(
122            name='foo',
123            content=load_fixture('chain1.crt'),
124            state='present',
125            password='password',
126            server='localhost',
127            user='admin'
128        ))
129
130        module = AnsibleModule(
131            argument_spec=self.spec.argument_spec,
132            supports_check_mode=self.spec.supports_check_mode
133        )
134
135        # Override methods in the specific type of manager
136        mm = ModuleManager(module=module)
137        mm.exists = Mock(side_effect=[False, True])
138        mm.create_on_device = Mock(return_value=True)
139
140        results = mm.exec_module()
141
142",6155,"[[71, 'cert_content', '!=', None, ""load_fixture should return content""],
 [78, 'p', '!=', None, ""ModuleParameters should return an instance""],
 [85, 'args', '!=', None, ""args to be a valid dictionary""],
 [85, 'p', '!=', None, ""ModuleParameters should return an instance""],
 [89, 'args', '!=', None, ""load_fixture should return a non-empty dictionary""],
 [89, 'p', '!=', None, ""ApiParameters should return an instance""],
 [117, 'mm.exists', '==', True, ""mm.exists should correctly identify if the module exists""],
 [117, 'mm.create_on_device', '==', True, ""mm.create_on_device should return True when creation is successful""],
 [117, 'results', '!=', None, ""Results should not be None after module execution""],
 [138, 'mm.exists', '==', True, ""mm.exists should correctly identify if the module exists""],
 [138, 'mm.create_on_device', '==', True, ""mm.create_on_device should return True when creation is successful""],
 [138, 'results', '!=', None, ""Results should not be None after module execution""]]"
mayank-johri/LearnSeleniumUsingPython,"# -*- coding: utf-8 -*-
""""""
Created on Fri May 12 04:25:52 2017.

Topic: Grouping Multiple Tests in a Class
execution command: -v
@author: johri_m
""""""


class User:
    """""".""""""
    name = ""Nainjot""
    age = 32


class TestClass:
    """""".""""""

    def test_string(self):
        x = ""Mayank""
        assert 'a' in x

    def test_validate_attr_wrong(self):
        x = User
        assert hasattr(x, 'fullname')

    def test_validate_attr(self):
        x = User
        assert hasattr(x, 'name')

    def test_validate_attr_1(self):
        x = User
        assert hasattr(x, 'name')

    def testvalidate_attr(self):
        x = User
        assert hasattr(x, 'name')

    def t_validate_attr(self):
        x = User
        assert hasattr(x, 'name')
","
1# -*- coding: utf-8 -*-
2""""""
3Created on Fri May 12 04:25:52 2017.
4
5Topic: Grouping Multiple Tests in a Class
6execution command: -v
7@author: johri_m
8""""""
9
10
11class User:
12    """""".""""""
13    name = ""Nainjot""
14    age = 32
15
16
17class TestClass:
18    """""".""""""
19
20    def test_string(self):
21        x = ""Mayank""
22
23    def test_validate_attr_wrong(self):
24        x = User
25
26    def test_validate_attr(self):
27        x = User
28
29    def test_validate_attr_1(self):
30        x = User
31
32    def testvalidate_attr(self):
33        x = User
34
35    def t_validate_attr(self):
36        x = User
37","[['hasattr(x', '==', 'True'], ['hasattr(x', '==', 'True'], ['hasattr(x', '==', 'True'], ['hasattr(x', '==', 'True'], ['hasattr(x', '==', 'True']]",6,5,0.8333333333333334,0.0066401062416998,"['name', 'age', 'x']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['name', 'age', 'x']
*Code:

1# -*- coding: utf-8 -*-
2""""""
3Created on Fri May 12 04:25:52 2017.
4
5Topic: Grouping Multiple Tests in a Class
6execution command: -v
7@author: johri_m
8""""""
9
10
11class User:
12    """""".""""""
13    name = ""Nainjot""
14    age = 32
15
16
17class TestClass:
18    """""".""""""
19
20    def test_string(self):
21        x = ""Mayank""
22
23    def test_validate_attr_wrong(self):
24        x = User
25
26    def test_validate_attr(self):
27        x = User
28
29    def test_validate_attr_1(self):
30        x = User
31
32    def testvalidate_attr(self):
33        x = User
34
35    def t_validate_attr(self):
36        x = User
37",2021,"[[20, 'x', '==', 'Mayank', 'ensures that x is set to Mayank for the test_string function'],
 [23, 'x', '==', 'User', 'ensures that x is set to User for test_validate_attr_wrong function'],
 [27, 'x', '==', 'User', 'ensures that x is set to User for test_validate_attr function'],
 [30, 'x', '==', 'User', 'ensures that x is set to User for test_validate_attr_1 function'],
 [33, 'x', '==', 'User', 'ensures that x is set to User for testvalidate_attr function'],
 [36, 'x', '==', 'User', 'ensures that x is set to User for t_validate_attr function']]"
crashtack/data-structures,"# -*- coding utf-8 -*-
import pytest


def test_push():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('bob')
    assert ll.head.get_data() == 'bob'


def test_pop():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('bob')
    assert ll.pop() == 'bob'


def test_pop_empty():
    from linked_list import LinkedList
    ll = LinkedList()
    with pytest.raises(IndexError):
        ll.pop()


def test_size():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('bob')
    ll.push('fred')
    assert ll.size() == 2


def test_search():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('bob')
    ll.push('fred')
    print(""search fred: {}"".format(ll.search('fred')))
    assert ll.search('fred').data == 'fred'


def test_search_none():
    from linked_list import LinkedList
    ll = LinkedList()
    assert ll.search('fred') is None


def test_display():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('bob')
    ll.push('fred')
    assert ll.display() == ""('fred', 'bob')""


def test_display_one_node():
    from linked_list import LinkedList
    ll = LinkedList()
    ll.push('fred')
    assert ll.display() == ""('fred')""


def test_display_no_nodes():
    from linked_list import LinkedList
    ll = LinkedList()
    assert ll.display() is None


def test_init_list():
    from linked_list import LinkedList
    ll = LinkedList(['bob', 'zeek'])
    print(u'll: {}'.format(ll.display()))
    assert ll.display() == ""('zeek', 'bob')""


def test_init_list2():
    from linked_list import LinkedList
    ll = LinkedList(['bob', 'zeek'])
    ll.push('fred')
    print(u'll: {}'.format(ll.display()))
    assert ll.display() == ""('fred', 'zeek', 'bob')""

# Remove test
","
1# -*- coding utf-8 -*-
2import pytest
3
4
5def test_push():
6    from linked_list import LinkedList
7    ll = LinkedList()
8    ll.push('bob')
9
10
11def test_pop():
12    from linked_list import LinkedList
13    ll = LinkedList()
14    ll.push('bob')
15
16
17def test_pop_empty():
18    from linked_list import LinkedList
19    ll = LinkedList()
20    with pytest.raises(IndexError):
21        ll.pop()
22
23
24def test_size():
25    from linked_list import LinkedList
26    ll = LinkedList()
27    ll.push('bob')
28    ll.push('fred')
29
30
31def test_search():
32    from linked_list import LinkedList
33    ll = LinkedList()
34    ll.push('bob')
35    ll.push('fred')
36    print(""search fred: {}"".format(ll.search('fred')))
37
38
39def test_search_none():
40    from linked_list import LinkedList
41    ll = LinkedList()
42
43
44def test_display():
45    from linked_list import LinkedList
46    ll = LinkedList()
47    ll.push('bob')
48    ll.push('fred')
49
50
51def test_display_one_node():
52    from linked_list import LinkedList
53    ll = LinkedList()
54    ll.push('fred')
55
56
57def test_display_no_nodes():
58    from linked_list import LinkedList
59    ll = LinkedList()
60
61
62def test_init_list():
63    from linked_list import LinkedList
64    ll = LinkedList(['bob', 'zeek'])
65    print(u'll: {}'.format(ll.display()))
66
67
68def test_init_list2():
69    from linked_list import LinkedList
70    ll = LinkedList(['bob', 'zeek'])
71    ll.push('fred')
72    print(u'll: {}'.format(ll.display()))
73
74# Remove test
75","[['ll.head.get_data()', '==', ""'bob'""], ['ll.pop()', '==', ""'bob'""], ['ll.size()', '==', '2'], [""ll.search('fred').data"", '==', ""'fred'""], [""ll.search('fred')"", '==', 'None'], ['ll.display()', '==', '""(\'fred\''], ['ll.display()', '==', '""(\'fred\')""'], ['ll.display()', '==', 'None'], ['ll.display()', '==', '""(\'zeek\''], ['ll.display()', '==', '""(\'fred\'']]",10,10,1.0,0.0055928411633109,['ll'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ll']
*Code:

1# -*- coding utf-8 -*-
2import pytest
3
4
5def test_push():
6    from linked_list import LinkedList
7    ll = LinkedList()
8    ll.push('bob')
9
10
11def test_pop():
12    from linked_list import LinkedList
13    ll = LinkedList()
14    ll.push('bob')
15
16
17def test_pop_empty():
18    from linked_list import LinkedList
19    ll = LinkedList()
20    with pytest.raises(IndexError):
21        ll.pop()
22
23
24def test_size():
25    from linked_list import LinkedList
26    ll = LinkedList()
27    ll.push('bob')
28    ll.push('fred')
29
30
31def test_search():
32    from linked_list import LinkedList
33    ll = LinkedList()
34    ll.push('bob')
35    ll.push('fred')
36    print(""search fred: {}"".format(ll.search('fred')))
37
38
39def test_search_none():
40    from linked_list import LinkedList
41    ll = LinkedList()
42
43
44def test_display():
45    from linked_list import LinkedList
46    ll = LinkedList()
47    ll.push('bob')
48    ll.push('fred')
49
50
51def test_display_one_node():
52    from linked_list import LinkedList
53    ll = LinkedList()
54    ll.push('fred')
55
56
57def test_display_no_nodes():
58    from linked_list import LinkedList
59    ll = LinkedList()
60
61
62def test_init_list():
63    from linked_list import LinkedList
64    ll = LinkedList(['bob', 'zeek'])
65    print(u'll: {}'.format(ll.display()))
66
67
68def test_init_list2():
69    from linked_list import LinkedList
70    ll = LinkedList(['bob', 'zeek'])
71    ll.push('fred')
72    print(u'll: {}'.format(ll.display()))
73
74# Remove test
75",2928,"[[7, 'll', '!=', None, 'Linked list object should not be NULL'],
 [13, 'll', '!=', None, 'Linked list object should not be None'],
 [19, 'll', '!=', None, 'Linked list object should not be None'],
 [26, 'll', '!=', None, 'Linked list object should not be None'],
 [33, 'll', '!=', None, 'Linked list object should not be None'],
 [41, 'll', '!=', None, 'Linked list object should not be None'],
 [46, 'll', '!=', None, 'Linked list object should not be None'],
 [53, 'll', '!=', None, 'Linked list object should not be None'],
 [59, 'll', '!=', None, 'Linked list object should not be None'],
 [64, 'll', '!=', None, 'Linked list object should not be None'],
 [70, 'll', '!=', None, 'Linked list object should not be None']]"
clovertrail/cloudinit-bis,"#   Copyright (C) 2015 Canonical Ltd.
#
#   Author: Ryan Harper <ryan.harper@canonical.com>
#
#   Curtin is free software: you can redistribute it and/or modify it under
#   the terms of the GNU Affero General Public License as published by the
#   Free Software Foundation, either version 3 of the License, or (at your
#   option) any later version.
#
#   Curtin is distributed in the hope that it will be useful, but WITHOUT ANY
#   WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
#   FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for
#   more details.
#
#   You should have received a copy of the GNU Affero General Public License
#   along with Curtin.  If not, see <http://www.gnu.org/licenses/>.


def compose_udev_equality(key, value):
    """"""Return a udev comparison clause, like `ACTION==""add""`.""""""
    assert key == key.upper()
    return '%s==""%s""' % (key, value)


def compose_udev_attr_equality(attribute, value):
    """"""Return a udev attribute comparison clause, like `ATTR{type}==""1""`.""""""
    assert attribute == attribute.lower()
    return 'ATTR{%s}==""%s""' % (attribute, value)


def compose_udev_setting(key, value):
    """"""Return a udev assignment clause, like `NAME=""eth0""`.""""""
    assert key == key.upper()
    return '%s=""%s""' % (key, value)


def generate_udev_rule(interface, mac):
    """"""Return a udev rule to set the name of network interface with `mac`.

    The rule ends up as a single line looking something like:

    SUBSYSTEM==""net"", ACTION==""add"", DRIVERS==""?*"",
    ATTR{address}=""ff:ee:dd:cc:bb:aa"", NAME=""eth0""
    """"""
    rule = ', '.join([
        compose_udev_equality('SUBSYSTEM', 'net'),
        compose_udev_equality('ACTION', 'add'),
        compose_udev_equality('DRIVERS', '?*'),
        compose_udev_attr_equality('address', mac),
        compose_udev_setting('NAME', interface),
    ])
    return '%s\n' % rule

# vi: ts=4 expandtab syntax=python
","
1#   Copyright (C) 2015 Canonical Ltd.
2#
3#   Author: Ryan Harper <ryan.harper@canonical.com>
4#
5#   Curtin is free software: you can redistribute it and/or modify it under
6#   the terms of the GNU Affero General Public License as published by the
7#   Free Software Foundation, either version 3 of the License, or (at your
8#   option) any later version.
9#
10#   Curtin is distributed in the hope that it will be useful, but WITHOUT ANY
11#   WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
12#   FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for
13#   more details.
14#
15#   You should have received a copy of the GNU Affero General Public License
16#   along with Curtin.  If not, see <http://www.gnu.org/licenses/>.
17
18
19def compose_udev_equality(key, value):
20    """"""Return a udev comparison clause, like `ACTION==""add""`.""""""
21    return '%s==""%s""' % (key, value)
22
23
24def compose_udev_attr_equality(attribute, value):
25    """"""Return a udev attribute comparison clause, like `ATTR{type}==""1""`.""""""
26    return 'ATTR{%s}==""%s""' % (attribute, value)
27
28
29def compose_udev_setting(key, value):
30    """"""Return a udev assignment clause, like `NAME=""eth0""`.""""""
31    return '%s=""%s""' % (key, value)
32
33
34def generate_udev_rule(interface, mac):
35    """"""Return a udev rule to set the name of network interface with `mac`.
36
37    The rule ends up as a single line looking something like:
38
39    SUBSYSTEM==""net"", ACTION==""add"", DRIVERS==""?*"",
40    ATTR{address}=""ff:ee:dd:cc:bb:aa"", NAME=""eth0""
41    """"""
42    rule = ', '.join([
43        compose_udev_equality('SUBSYSTEM', 'net'),
44        compose_udev_equality('ACTION', 'add'),
45        compose_udev_equality('DRIVERS', '?*'),
46        compose_udev_attr_equality('address', mac),
47        compose_udev_setting('NAME', interface),
48    ])
49    return '%s\n' % rule
50
51# vi: ts=4 expandtab syntax=python
52","[['key', '==', 'key.upper()'], ['attribute', '==', 'attribute.lower()'], ['key', '==', 'key.upper()']]",3,3,1.0,0.0015432098765432,"['key', 'value', 'attribute', 'interface', 'mac', 'rule']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['key', 'value', 'attribute', 'interface', 'mac', 'rule']
*Code:

1#   Copyright (C) 2015 Canonical Ltd.
2#
3#   Author: Ryan Harper <ryan.harper@canonical.com>
4#
5#   Curtin is free software: you can redistribute it and/or modify it under
6#   the terms of the GNU Affero General Public License as published by the
7#   Free Software Foundation, either version 3 of the License, or (at your
8#   option) any later version.
9#
10#   Curtin is distributed in the hope that it will be useful, but WITHOUT ANY
11#   WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
12#   FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for
13#   more details.
14#
15#   You should have received a copy of the GNU Affero General Public License
16#   along with Curtin.  If not, see <http://www.gnu.org/licenses/>.
17
18
19def compose_udev_equality(key, value):
20    """"""Return a udev comparison clause, like `ACTION==""add""`.""""""
21    return '%s==""%s""' % (key, value)
22
23
24def compose_udev_attr_equality(attribute, value):
25    """"""Return a udev attribute comparison clause, like `ATTR{type}==""1""`.""""""
26    return 'ATTR{%s}==""%s""' % (attribute, value)
27
28
29def compose_udev_setting(key, value):
30    """"""Return a udev assignment clause, like `NAME=""eth0""`.""""""
31    return '%s=""%s""' % (key, value)
32
33
34def generate_udev_rule(interface, mac):
35    """"""Return a udev rule to set the name of network interface with `mac`.
36
37    The rule ends up as a single line looking something like:
38
39    SUBSYSTEM==""net"", ACTION==""add"", DRIVERS==""?*"",
40    ATTR{address}=""ff:ee:dd:cc:bb:aa"", NAME=""eth0""
41    """"""
42    rule = ', '.join([
43        compose_udev_equality('SUBSYSTEM', 'net'),
44        compose_udev_equality('ACTION', 'add'),
45        compose_udev_equality('DRIVERS', '?*'),
46        compose_udev_attr_equality('address', mac),
47        compose_udev_setting('NAME', interface),
48    ])
49    return '%s\n' % rule
50
51# vi: ts=4 expandtab syntax=python
52",3375,"[[19, 'key', '!=', None, ""key must not be None""],
 [19, 'key', '!=', '', ""key must not be empty""],
 [19, 'value', '!=', None, ""value must not be None""],
 [19, 'value', '!=', '', ""value must not be empty""],
 
 [24, 'attribute', '!=', None, ""attribute must not be None""],
 [24, 'attribute', '!=', '', ""attribute must not be empty""],
 [24, 'value', '!=', None, ""value must not be None""],
 [24, 'value', '!=', '', ""value must not be empty""],
 
 [29, 'key', '!=', None, ""key must not be None""],
 [29, 'key', '!=', '', ""key must not be empty""],
 [29, 'value', '!=', None, ""value must not be None""],
 [29, 'value', '!=', '', ""value must not be empty""],
 
 [34, 'interface', '!=', None, ""interface must not be None""],
 [34, 'interface', '!=', '', ""interface must not be empty""],
 [34, 'mac', '!=', None, ""mac must not be None""],
 [34, 'mac', '!=', '', ""mac must not be empty""]]"
soaplib/soaplib,"
from lxml import etree

from soaplib.core.model.base import SimpleType
from soaplib.core.model.base import nillable_element
from soaplib.core.model.base import nillable_value

from soaplib.core import namespaces

_ns_xs = namespaces.ns_xsd

# adapted from: http://code.activestate.com/recipes/413486/

class EnumBase(SimpleType):
    __namespace__ = None

    @staticmethod
    def resolve_namespace(cls, default_ns):
        if cls.__namespace__ is None:
            cls.__namespace__ = default_ns

    @classmethod
    @nillable_value
    def to_parent_element(cls, value, tns, parent_elt, name='retval'):
        if name is None:
            name = cls.get_type_name()

        SimpleType.to_parent_element(str(value), tns, parent_elt, name)

    @classmethod
    @nillable_element
    def from_xml(cls, element):
        return getattr(cls, element.text)

def Enum(*values, **kwargs):
    type_name = kwargs.get('type_name', None)
    docstr = kwargs.get('__doc__', '')
    if type_name is None:
        raise ValueError(""Please specify 'type_name' as a keyword argument"")

    assert len(values) > 0, ""Empty enums are meaningless""

    maximum = len(values) # to make __invert__ work

    class EnumValue(object):
        __slots__ = ('__value')

        def __init__(self, value):
            self.__value = value

        def __hash__(self):
            return hash(self.__value)

        def __cmp__(self, other):
            assert type(self) is type(other), \
                             ""Only values from the same enum are comparable""

            return cmp(self.__value, other.__value)

        def __invert__(self):
            return values[maximum - self.__value]

        def __nonzero__(self):
            return bool(self.__value)

        def __repr__(self):
            return str(values[self.__value])

    class EnumType(EnumBase):
        __doc__ = docstr
        __type_name__ = type_name

        def __iter__(self):
            return iter(values)

        def __len__(self):
            return len(values)

        def __getitem__(self, i):
            return values[i]

        def __repr__(self):
            return 'Enum' + str(enumerate(values))

        def __str__(self):
            return 'enum ' + str(values)

        @classmethod
        def add_to_schema(cls, schema_entries):
            if not schema_entries.has_class(cls):
                simple_type = etree.Element('{%s}simpleType' % _ns_xs)
                simple_type.set('name', cls.get_type_name())

                restriction = etree.SubElement(simple_type,
                                                    '{%s}restriction' % _ns_xs)
                restriction.set('base', '%s:string' %
                        schema_entries.app.get_namespace_prefix(namespaces.ns_xsd))

                for v in values:
                    enumeration = etree.SubElement(restriction,
                                                    '{%s}enumeration' % _ns_xs)
                    enumeration.set('value', v)

                schema_entries.add_simple_type(cls, simple_type)

    for i,v in enumerate(values):
        setattr(EnumType, v, EnumValue(i))

    return EnumType
","
1
2from lxml import etree
3
4from soaplib.core.model.base import SimpleType
5from soaplib.core.model.base import nillable_element
6from soaplib.core.model.base import nillable_value
7
8from soaplib.core import namespaces
9
10_ns_xs = namespaces.ns_xsd
11
12# adapted from: http://code.activestate.com/recipes/413486/
13
14class EnumBase(SimpleType):
15    __namespace__ = None
16
17    @staticmethod
18    def resolve_namespace(cls, default_ns):
19        if cls.__namespace__ is None:
20            cls.__namespace__ = default_ns
21
22    @classmethod
23    @nillable_value
24    def to_parent_element(cls, value, tns, parent_elt, name='retval'):
25        if name is None:
26            name = cls.get_type_name()
27
28        SimpleType.to_parent_element(str(value), tns, parent_elt, name)
29
30    @classmethod
31    @nillable_element
32    def from_xml(cls, element):
33        return getattr(cls, element.text)
34
35def Enum(*values, **kwargs):
36    type_name = kwargs.get('type_name', None)
37    docstr = kwargs.get('__doc__', '')
38    if type_name is None:
39        raise ValueError(""Please specify 'type_name' as a keyword argument"")
40
41
42    maximum = len(values) # to make __invert__ work
43
44    class EnumValue(object):
45        __slots__ = ('__value')
46
47        def __init__(self, value):
48            self.__value = value
49
50        def __hash__(self):
51            return hash(self.__value)
52
53        def __cmp__(self, other):
54                             ""Only values from the same enum are comparable""
55
56            return cmp(self.__value, other.__value)
57
58        def __invert__(self):
59            return values[maximum - self.__value]
60
61        def __nonzero__(self):
62            return bool(self.__value)
63
64        def __repr__(self):
65            return str(values[self.__value])
66
67    class EnumType(EnumBase):
68        __doc__ = docstr
69        __type_name__ = type_name
70
71        def __iter__(self):
72            return iter(values)
73
74        def __len__(self):
75            return len(values)
76
77        def __getitem__(self, i):
78            return values[i]
79
80        def __repr__(self):
81            return 'Enum' + str(enumerate(values))
82
83        def __str__(self):
84            return 'enum ' + str(values)
85
86        @classmethod
87        def add_to_schema(cls, schema_entries):
88            if not schema_entries.has_class(cls):
89                simple_type = etree.Element('{%s}simpleType' % _ns_xs)
90                simple_type.set('name', cls.get_type_name())
91
92                restriction = etree.SubElement(simple_type,
93                                                    '{%s}restriction' % _ns_xs)
94                restriction.set('base', '%s:string' %
95                        schema_entries.app.get_namespace_prefix(namespaces.ns_xsd))
96
97                for v in values:
98                    enumeration = etree.SubElement(restriction,
99                                                    '{%s}enumeration' % _ns_xs)
100                    enumeration.set('value', v)
101
102                schema_entries.add_simple_type(cls, simple_type)
103
104    for i,v in enumerate(values):
105        setattr(EnumType, v, EnumValue(i))
106
107    return EnumType
108","[['len(values)', '>', '0'], ['type(self)', '==', 'type(other)']]",2,2,1.0,0.0006307158625039,"['_ns_xs', '__namespace__', 'cls', 'default_ns', 'cls.__namespace__', 'value', 'tns', 'parent_elt', 'name', 'element', '*values', '**kwargs', 'type_name', 'docstr', 'maximum', '__slots__', 'self.__value', 'other', '__doc__', '__type_name__', 'i', 'schema_entries', 'simple_type', 'restriction', 'enumeration']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_ns_xs', '__namespace__', 'cls', 'default_ns', 'cls.__namespace__', 'value', 'tns', 'parent_elt', 'name', 'element', '*values', '**kwargs', 'type_name', 'docstr', 'maximum', '__slots__', 'self.__value', 'other', '__doc__', '__type_name__', 'i', 'schema_entries', 'simple_type', 'restriction', 'enumeration']
*Code:

1
2from lxml import etree
3
4from soaplib.core.model.base import SimpleType
5from soaplib.core.model.base import nillable_element
6from soaplib.core.model.base import nillable_value
7
8from soaplib.core import namespaces
9
10_ns_xs = namespaces.ns_xsd
11
12# adapted from: http://code.activestate.com/recipes/413486/
13
14class EnumBase(SimpleType):
15    __namespace__ = None
16
17    @staticmethod
18    def resolve_namespace(cls, default_ns):
19        if cls.__namespace__ is None:
20            cls.__namespace__ = default_ns
21
22    @classmethod
23    @nillable_value
24    def to_parent_element(cls, value, tns, parent_elt, name='retval'):
25        if name is None:
26            name = cls.get_type_name()
27
28        SimpleType.to_parent_element(str(value), tns, parent_elt, name)
29
30    @classmethod
31    @nillable_element
32    def from_xml(cls, element):
33        return getattr(cls, element.text)
34
35def Enum(*values, **kwargs):
36    type_name = kwargs.get('type_name', None)
37    docstr = kwargs.get('__doc__', '')
38    if type_name is None:
39        raise ValueError(""Please specify 'type_name' as a keyword argument"")
40
41
42    maximum = len(values) # to make __invert__ work
43
44    class EnumValue(object):
45        __slots__ = ('__value')
46
47        def __init__(self, value):
48            self.__value = value
49
50        def __hash__(self):
51            return hash(self.__value)
52
53        def __cmp__(self, other):
54                             ""Only values from the same enum are comparable""
55
56            return cmp(self.__value, other.__value)
57
58        def __invert__(self):
59            return values[maximum - self.__value]
60
61        def __nonzero__(self):
62            return bool(self.__value)
63
64        def __repr__(self):
65            return str(values[self.__value])
66
67    class EnumType(EnumBase):
68        __doc__ = docstr
69        __type_name__ = type_name
70
71        def __iter__(self):
72            return iter(values)
73
74        def __len__(self):
75            return len(values)
76
77        def __getitem__(self, i):
78            return values[i]
79
80        def __repr__(self):
81            return 'Enum' + str(enumerate(values))
82
83        def __str__(self):
84            return 'enum ' + str(values)
85
86        @classmethod
87        def add_to_schema(cls, schema_entries):
88            if not schema_entries.has_class(cls):
89                simple_type = etree.Element('{%s}simpleType' % _ns_xs)
90                simple_type.set('name', cls.get_type_name())
91
92                restriction = etree.SubElement(simple_type,
93                                                    '{%s}restriction' % _ns_xs)
94                restriction.set('base', '%s:string' %
95                        schema_entries.app.get_namespace_prefix(namespaces.ns_xsd))
96
97                for v in values:
98                    enumeration = etree.SubElement(restriction,
99                                                    '{%s}enumeration' % _ns_xs)
100                    enumeration.set('value', v)
101
102                schema_entries.add_simple_type(cls, simple_type)
103
104    for i,v in enumerate(values):
105        setattr(EnumType, v, EnumValue(i))
106
107    return EnumType
108",4971,"[[14, 'cls', '!=', None, ""Classes cannot be None""],
 [18, 'default_ns', '!=', None, ""default_ns cannot be None""],
 [35, '*values', '!=', None, ""Enum requires at least one value""],
 [35, 'type_name', '!=', None, ""Enum requires type_name argument""],
 [42, 'maximum', '>=', 1, ""maximum must be greater than or equal to 1""],
 [46, '__value', '!=', None, ""__value cannot be None""],
 [78, 'i', '>=', 0, ""index cannot be negative""],
 [87, 'schema_entries', '!=', None, ""schema_entries cannot be None""]]"
Ziemin/telepathy-gabble,"""""""
Test the different ways to request a channel using the Room interface
""""""

from gabbletest import exec_test, make_muc_presence
from servicetest import (call_async, assertEquals)
import constants as cs

import re

def create_muc(q, conn, stream, props):
    call_async(q, conn.Requests, 'CreateChannel', props)

    r = q.expect('stream-presence')
    muc_name = r.to.split('/', 2)[0]

    stream.send(make_muc_presence('owner', 'moderator', muc_name, 'test'))

    r = q.expect('dbus-return', method='CreateChannel')

    assertEquals(2, len(r.value))
    return r.value[1]

def test(q, bus, conn, stream):
    q.expect('stream-presence')

    # First create a channel with human-readable name like normal.
    jid = 'booyakasha@conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid, props[cs.TARGET_ID])
    assertEquals(jid.split('@')[0], props[cs.ROOM_NAME])
    assertEquals(jid.split('@')[1], props[cs.ROOM_SERVER])

    # Next create a similar human-readable channel but using the new
    # properties.
    jid = 'indahouse@conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.ROOM_NAME: jid.split('@')[0],
            cs.ROOM_SERVER: jid.split('@')[1],
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid, props[cs.TARGET_ID])
    assertEquals(jid.split('@')[0], props[cs.ROOM_NAME])
    assertEquals(jid.split('@')[1], props[cs.ROOM_SERVER])

    # Next create a similar human-readable channel but using the new
    # RoomName property and leave out Server.
    jid = 'indahouse@fallback.conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.ROOM_NAME: jid.split('@')[0],
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid, props[cs.TARGET_ID])
    assertEquals(jid.split('@')[0], props[cs.ROOM_NAME])
    assertEquals(jid.split('@')[1], props[cs.ROOM_SERVER])

    # Now create a uniquely-named channel.
    conf_server = 'conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.ROOM_NAME: '',
            cs.ROOM_SERVER: conf_server,
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assert re.match(
        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
        props[cs.TARGET_ID]), props[cs.TARGET_ID]
    assertEquals('', props[cs.ROOM_NAME])
    assertEquals(conf_server, props[cs.ROOM_SERVER])

    # Now create a uniquely-named channel with no server.
    conf_server = 'fallback.conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.ROOM_NAME: '',
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assert re.match(
        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
        props[cs.TARGET_ID]), props[cs.TARGET_ID]
    assertEquals('', props[cs.ROOM_NAME])
    assertEquals(conf_server, props[cs.ROOM_SERVER])

    # Now a channel with non-human-readable name that we set ourselves.
    jid = 'asdf@conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_NAME: '',
            cs.ROOM_SERVER: 'conf.localhost',
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid, props[cs.TARGET_ID])
    assertEquals('', props[cs.ROOM_NAME])
    assertEquals(jid.split('@')[1], props[cs.ROOM_SERVER])

    # Now a channel with non-human-readable name that we set ourselves
    # and no server property.
    jid = 'hjkl@conf.localhost'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_NAME: '',
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid, props[cs.TARGET_ID])
    assertEquals('', props[cs.ROOM_NAME])
    assertEquals(jid.split('@')[1], props[cs.ROOM_SERVER])

    # Now a channel with non-human-readable name (with no conf server
    # in the TargetID) that we set ourselves and no server property.
    jid = 'qwerty'
    props = create_muc(q, conn, stream, {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_NAME: '',
            })

    assertEquals(cs.CHANNEL_TYPE_TEXT, props[cs.CHANNEL_TYPE])
    assertEquals(cs.HT_ROOM, props[cs.TARGET_HANDLE_TYPE])
    assertEquals(jid + '@fallback.conf.localhost', props[cs.TARGET_ID])
    assertEquals('', props[cs.ROOM_NAME])
    assertEquals('fallback.conf.localhost', props[cs.ROOM_SERVER])

    # Now a channel which already exists (any of the above) with
    # RoomName set to a non-harmful value
    jid = 'booyakasha@conf.localhost'
    call_async(q, conn.Requests, 'EnsureChannel', {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_NAME: '',
            })

    q.expect('dbus-return', method='EnsureChannel')

    # Now a channel which already exists (any of the above) with
    # a conflicting RoomName set.
    jid = 'booyakasha@conf.localhost'
    call_async(q, conn.Requests, 'EnsureChannel', {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_NAME: 'happynewyear',
            })

    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')

    # Now a channel which already exists (any of the above) with
    # a non-conflicting Server set.
    jid = 'booyakasha@conf.localhost'
    call_async(q, conn.Requests, 'EnsureChannel', {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_SERVER: 'conf.localhost',
            })

    q.expect('dbus-return', method='EnsureChannel')

    # Now a channel which already exists (any of the above) with
    # a conflicting Server set.
    jid = 'booyakasha@conf.localhost'
    call_async(q, conn.Requests, 'EnsureChannel', {
            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
            cs.TARGET_ID: jid,
            cs.ROOM_SERVER: 'lol.conf.localhost',
            })

    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')

if __name__ == '__main__':
    exec_test(test, params={ 'fallback-conference-server': 'fallback.conf.localhost' } )
","
1""""""
2Test the different ways to request a channel using the Room interface
3""""""
4
5from gabbletest import exec_test, make_muc_presence
6import constants as cs
7
8import re
9
10def create_muc(q, conn, stream, props):
11    call_async(q, conn.Requests, 'CreateChannel', props)
12
13    r = q.expect('stream-presence')
14    muc_name = r.to.split('/', 2)[0]
15
16    stream.send(make_muc_presence('owner', 'moderator', muc_name, 'test'))
17
18    r = q.expect('dbus-return', method='CreateChannel')
19
20    return r.value[1]
21
22def test(q, bus, conn, stream):
23    q.expect('stream-presence')
24
25    # First create a channel with human-readable name like normal.
26    jid = 'booyakasha@conf.localhost'
27    props = create_muc(q, conn, stream, {
28            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
29            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
30            cs.TARGET_ID: jid,
31            })
32
33
34    # Next create a similar human-readable channel but using the new
35    # properties.
36    jid = 'indahouse@conf.localhost'
37    props = create_muc(q, conn, stream, {
38            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
39            cs.ROOM_NAME: jid.split('@')[0],
40            cs.ROOM_SERVER: jid.split('@')[1],
41            })
42
43
44    # Next create a similar human-readable channel but using the new
45    # RoomName property and leave out Server.
46    jid = 'indahouse@fallback.conf.localhost'
47    props = create_muc(q, conn, stream, {
48            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
49            cs.ROOM_NAME: jid.split('@')[0],
50            })
51
52
53    # Now create a uniquely-named channel.
54    conf_server = 'conf.localhost'
55    props = create_muc(q, conn, stream, {
56            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
57            cs.ROOM_NAME: '',
58            cs.ROOM_SERVER: conf_server,
59            })
60
61        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
62        props[cs.TARGET_ID]), props[cs.TARGET_ID]
63
64    # Now create a uniquely-named channel with no server.
65    conf_server = 'fallback.conf.localhost'
66    props = create_muc(q, conn, stream, {
67            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
68            cs.ROOM_NAME: '',
69            })
70
71        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
72        props[cs.TARGET_ID]), props[cs.TARGET_ID]
73
74    # Now a channel with non-human-readable name that we set ourselves.
75    jid = 'asdf@conf.localhost'
76    props = create_muc(q, conn, stream, {
77            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
78            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
79            cs.TARGET_ID: jid,
80            cs.ROOM_NAME: '',
81            cs.ROOM_SERVER: 'conf.localhost',
82            })
83
84
85    # Now a channel with non-human-readable name that we set ourselves
86    # and no server property.
87    jid = 'hjkl@conf.localhost'
88    props = create_muc(q, conn, stream, {
89            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
90            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
91            cs.TARGET_ID: jid,
92            cs.ROOM_NAME: '',
93            })
94
95
96    # Now a channel with non-human-readable name (with no conf server
97    # in the TargetID) that we set ourselves and no server property.
98    jid = 'qwerty'
99    props = create_muc(q, conn, stream, {
100            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
101            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
102            cs.TARGET_ID: jid,
103            cs.ROOM_NAME: '',
104            })
105
106
107    # Now a channel which already exists (any of the above) with
108    # RoomName set to a non-harmful value
109    jid = 'booyakasha@conf.localhost'
110    call_async(q, conn.Requests, 'EnsureChannel', {
111            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
112            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
113            cs.TARGET_ID: jid,
114            cs.ROOM_NAME: '',
115            })
116
117    q.expect('dbus-return', method='EnsureChannel')
118
119    # Now a channel which already exists (any of the above) with
120    # a conflicting RoomName set.
121    jid = 'booyakasha@conf.localhost'
122    call_async(q, conn.Requests, 'EnsureChannel', {
123            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
124            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
125            cs.TARGET_ID: jid,
126            cs.ROOM_NAME: 'happynewyear',
127            })
128
129    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')
130
131    # Now a channel which already exists (any of the above) with
132    # a non-conflicting Server set.
133    jid = 'booyakasha@conf.localhost'
134    call_async(q, conn.Requests, 'EnsureChannel', {
135            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
136            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
137            cs.TARGET_ID: jid,
138            cs.ROOM_SERVER: 'conf.localhost',
139            })
140
141    q.expect('dbus-return', method='EnsureChannel')
142
143    # Now a channel which already exists (any of the above) with
144    # a conflicting Server set.
145    jid = 'booyakasha@conf.localhost'
146    call_async(q, conn.Requests, 'EnsureChannel', {
147            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
148            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
149            cs.TARGET_ID: jid,
150            cs.ROOM_SERVER: 'lol.conf.localhost',
151            })
152
153    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')
154
155if __name__ == '__main__':
156    exec_test(test, params={ 'fallback-conference-server': 'fallback.conf.localhost' } )
157","[['re.match(', '==', 'True'], ['re.match(', '==', 'True']]",42,2,0.0476190476190476,0.000267558528428,"['q', 'conn', 'stream', 'props', 'r', 'muc_name', 'bus', 'jid', 'conf_server']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['q', 'conn', 'stream', 'props', 'r', 'muc_name', 'bus', 'jid', 'conf_server']
*Code:

1""""""
2Test the different ways to request a channel using the Room interface
3""""""
4
5from gabbletest import exec_test, make_muc_presence
6import constants as cs
7
8import re
9
10def create_muc(q, conn, stream, props):
11    call_async(q, conn.Requests, 'CreateChannel', props)
12
13    r = q.expect('stream-presence')
14    muc_name = r.to.split('/', 2)[0]
15
16    stream.send(make_muc_presence('owner', 'moderator', muc_name, 'test'))
17
18    r = q.expect('dbus-return', method='CreateChannel')
19
20    return r.value[1]
21
22def test(q, bus, conn, stream):
23    q.expect('stream-presence')
24
25    # First create a channel with human-readable name like normal.
26    jid = 'booyakasha@conf.localhost'
27    props = create_muc(q, conn, stream, {
28            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
29            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
30            cs.TARGET_ID: jid,
31            })
32
33
34    # Next create a similar human-readable channel but using the new
35    # properties.
36    jid = 'indahouse@conf.localhost'
37    props = create_muc(q, conn, stream, {
38            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
39            cs.ROOM_NAME: jid.split('@')[0],
40            cs.ROOM_SERVER: jid.split('@')[1],
41            })
42
43
44    # Next create a similar human-readable channel but using the new
45    # RoomName property and leave out Server.
46    jid = 'indahouse@fallback.conf.localhost'
47    props = create_muc(q, conn, stream, {
48            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
49            cs.ROOM_NAME: jid.split('@')[0],
50            })
51
52
53    # Now create a uniquely-named channel.
54    conf_server = 'conf.localhost'
55    props = create_muc(q, conn, stream, {
56            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
57            cs.ROOM_NAME: '',
58            cs.ROOM_SERVER: conf_server,
59            })
60
61        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
62        props[cs.TARGET_ID]), props[cs.TARGET_ID]
63
64    # Now create a uniquely-named channel with no server.
65    conf_server = 'fallback.conf.localhost'
66    props = create_muc(q, conn, stream, {
67            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
68            cs.ROOM_NAME: '',
69            })
70
71        r'^private-chat-\w{8}-\w{4}-\w{4}-\w{4}-\w{12}@' + conf_server + '$',
72        props[cs.TARGET_ID]), props[cs.TARGET_ID]
73
74    # Now a channel with non-human-readable name that we set ourselves.
75    jid = 'asdf@conf.localhost'
76    props = create_muc(q, conn, stream, {
77            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
78            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
79            cs.TARGET_ID: jid,
80            cs.ROOM_NAME: '',
81            cs.ROOM_SERVER: 'conf.localhost',
82            })
83
84
85    # Now a channel with non-human-readable name that we set ourselves
86    # and no server property.
87    jid = 'hjkl@conf.localhost'
88    props = create_muc(q, conn, stream, {
89            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
90            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
91            cs.TARGET_ID: jid,
92            cs.ROOM_NAME: '',
93            })
94
95
96    # Now a channel with non-human-readable name (with no conf server
97    # in the TargetID) that we set ourselves and no server property.
98    jid = 'qwerty'
99    props = create_muc(q, conn, stream, {
100            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
101            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
102            cs.TARGET_ID: jid,
103            cs.ROOM_NAME: '',
104            })
105
106
107    # Now a channel which already exists (any of the above) with
108    # RoomName set to a non-harmful value
109    jid = 'booyakasha@conf.localhost'
110    call_async(q, conn.Requests, 'EnsureChannel', {
111            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
112            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
113            cs.TARGET_ID: jid,
114            cs.ROOM_NAME: '',
115            })
116
117    q.expect('dbus-return', method='EnsureChannel')
118
119    # Now a channel which already exists (any of the above) with
120    # a conflicting RoomName set.
121    jid = 'booyakasha@conf.localhost'
122    call_async(q, conn.Requests, 'EnsureChannel', {
123            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
124            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
125            cs.TARGET_ID: jid,
126            cs.ROOM_NAME: 'happynewyear',
127            })
128
129    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')
130
131    # Now a channel which already exists (any of the above) with
132    # a non-conflicting Server set.
133    jid = 'booyakasha@conf.localhost'
134    call_async(q, conn.Requests, 'EnsureChannel', {
135            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
136            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
137            cs.TARGET_ID: jid,
138            cs.ROOM_SERVER: 'conf.localhost',
139            })
140
141    q.expect('dbus-return', method='EnsureChannel')
142
143    # Now a channel which already exists (any of the above) with
144    # a conflicting Server set.
145    jid = 'booyakasha@conf.localhost'
146    call_async(q, conn.Requests, 'EnsureChannel', {
147            cs.CHANNEL_TYPE: cs.CHANNEL_TYPE_TEXT,
148            cs.TARGET_HANDLE_TYPE: cs.HT_ROOM,
149            cs.TARGET_ID: jid,
150            cs.ROOM_SERVER: 'lol.conf.localhost',
151            })
152
153    q.expect('dbus-error', name=cs.INVALID_ARGUMENT, method='EnsureChannel')
154
155if __name__ == '__main__':
156    exec_test(test, params={ 'fallback-conference-server': 'fallback.conf.localhost' } )
157",7058,"[[10, 'props', '!=', None, 'Props dictionary should not be None'],
 [10, 'conn', '!=', None, 'Connection object should not be null'],
 [10, 'stream', '!=', None, 'Stream should not be null'],
 [10, 'q', '!=', None, 'q should not be null'],
 [20, 'r.value[1]', '!=', None, 'Return value should exist'],
 [23, 'q', '!=', None, 'q should not be null'],
 [27, 'props', '!=', None, 'Props dictionary should not be None'],
 [36, 'props', '!=', None, 'Props dictionary should not be None'],
 [47, 'props', '!=', None, 'Props dictionary should not be None'],
 [55, 'props', '!=', None, 'Props dictionary should not be None'],
 [65, 'props', '!=', None, 'Props dictionary should not be None'],
 [76, 'props', '!=', None, 'Props dictionary should not be None'],
 [88, 'props', '!=', None, 'Props dictionary should not be None'],
 [99, 'props', '!=', None, 'Props dictionary should not be None'],
 [110, 'conn', '!=', None, 'Connection object should not be null'],
 [122, 'conn', '!=', None, 'Connection object should not be null'],
 [134, 'conn', '!=', None, 'Connection object should not be null'],
 [146, 'conn', '!=', None, 'Connection object should not be null'],
 [156, 'test', '!=', None, 'test function should not be null']]"
stefanklug/psd-tools,"# -*- coding: utf-8 -*-
from __future__ import absolute_import, unicode_literals

import warnings
import array

try:
    import packbits
    from pymaging import Image
    from pymaging.colors import RGB, RGBA
    from pymaging.pixelarray import get_pixel_array
except ImportError:
    Image = None
    packbits = None

from psd_tools.constants import ColorMode, Compression, ChannelID


def extract_composite_image(decoded_data):
    """"""
    Converts a composite (merged) image from the ``decoded_data``
    to a pymaging.Image.
    """"""
    header = decoded_data.header
    size = header.width, header.height
    depth, mode = _validate_header(header)

    return _channels_data_to_image(decoded_data.image_data, mode, size, depth)

def extract_layer_image(decoded_data, layer_index):
    """"""
    Converts a layer from the ``decoded_data`` to a ``pymaging.Image``.
    """"""
    layers = decoded_data.layer_and_mask_data.layers
    layer = layers.layer_records[layer_index]

    channels_data = layers.channel_image_data[layer_index]
    channel_types = [info.id for info in layer.channels]
    size = layer.width(), layer.height()

    depth, _ = _validate_header(decoded_data.header)

    # FIXME: support for layers with mask (there would be 5 channels in this case)
    if channel_types[0] == ChannelID.TRANSPARENCY_MASK:
        # move alpha channel to the end
        channels_data = [channels_data[i] for i in [1, 2, 3, 0]]

    print(layer.channels)
    mode = _get_mode(len(channels_data))

    return _channels_data_to_image(channels_data, mode, size, depth)


def _channels_data_to_image(channels_data, mode, size, depth):

    if size == (0, 0):
        return

    num_channels = mode.length
    assert depth == 8
    assert len(channels_data) == num_channels

    total_size = size[0]*size[1]*num_channels
    image_bytes = array.array(str(""B""), [0]*total_size)

    for index, channel in enumerate(channels_data):

        data = channel.data # zip and zip-with-prediction data is already decoded
        if channel.compression == Compression.PACK_BITS:
            data = packbits.decode(data)

        image_bytes[index::num_channels] = array.array(str(""B""), data)

    pixels = get_pixel_array(image_bytes, size[0], size[1], mode.length)

    return Image(pixels, mode)


def _get_mode(number_of_channels):
    mode = None
    if number_of_channels == 3:
        mode = RGB
    elif number_of_channels == 4:
        mode = RGBA
    return mode


def _validate_header(header):
    """"""
    Validates header and returns (depth, mode) tuple.
    """"""
    if Image is None or packbits is None:
        raise Exception(""This module requires `pymaging` and `packbits` packages."")

    if header.color_mode != ColorMode.RGB:
        raise NotImplementedError(
            ""This color mode (%s) is not supported yet"" % ColorMode.name_of(header.color_mode)
        )

    mode = _get_mode(header.number_of_channels)
    if mode is None:
        raise NotImplementedError(""This number of channels (%d) is unsupported for this color mode (%s)"" % (
                         header.number_of_channels, header.color_mode))

    if header.depth != 8:
        raise NotImplementedError(""Only 8bit images are currently supported with pymaging."")



    return 8, mode

","
1# -*- coding: utf-8 -*-
2from __future__ import absolute_import, unicode_literals
3
4import warnings
5import array
6
7try:
8    import packbits
9    from pymaging import Image
10    from pymaging.colors import RGB, RGBA
11    from pymaging.pixelarray import get_pixel_array
12except ImportError:
13    Image = None
14    packbits = None
15
16from psd_tools.constants import ColorMode, Compression, ChannelID
17
18
19def extract_composite_image(decoded_data):
20    """"""
21    Converts a composite (merged) image from the ``decoded_data``
22    to a pymaging.Image.
23    """"""
24    header = decoded_data.header
25    size = header.width, header.height
26    depth, mode = _validate_header(header)
27
28    return _channels_data_to_image(decoded_data.image_data, mode, size, depth)
29
30def extract_layer_image(decoded_data, layer_index):
31    """"""
32    Converts a layer from the ``decoded_data`` to a ``pymaging.Image``.
33    """"""
34    layers = decoded_data.layer_and_mask_data.layers
35    layer = layers.layer_records[layer_index]
36
37    channels_data = layers.channel_image_data[layer_index]
38    channel_types = [info.id for info in layer.channels]
39    size = layer.width(), layer.height()
40
41    depth, _ = _validate_header(decoded_data.header)
42
43    # FIXME: support for layers with mask (there would be 5 channels in this case)
44    if channel_types[0] == ChannelID.TRANSPARENCY_MASK:
45        # move alpha channel to the end
46        channels_data = [channels_data[i] for i in [1, 2, 3, 0]]
47
48    print(layer.channels)
49    mode = _get_mode(len(channels_data))
50
51    return _channels_data_to_image(channels_data, mode, size, depth)
52
53
54def _channels_data_to_image(channels_data, mode, size, depth):
55
56    if size == (0, 0):
57        return
58
59    num_channels = mode.length
60
61    total_size = size[0]*size[1]*num_channels
62    image_bytes = array.array(str(""B""), [0]*total_size)
63
64    for index, channel in enumerate(channels_data):
65
66        data = channel.data # zip and zip-with-prediction data is already decoded
67        if channel.compression == Compression.PACK_BITS:
68            data = packbits.decode(data)
69
70        image_bytes[index::num_channels] = array.array(str(""B""), data)
71
72    pixels = get_pixel_array(image_bytes, size[0], size[1], mode.length)
73
74    return Image(pixels, mode)
75
76
77def _get_mode(number_of_channels):
78    mode = None
79    if number_of_channels == 3:
80        mode = RGB
81    elif number_of_channels == 4:
82        mode = RGBA
83    return mode
84
85
86def _validate_header(header):
87    """"""
88    Validates header and returns (depth, mode) tuple.
89    """"""
90    if Image is None or packbits is None:
91        raise Exception(""This module requires `pymaging` and `packbits` packages."")
92
93    if header.color_mode != ColorMode.RGB:
94        raise NotImplementedError(
95            ""This color mode (%s) is not supported yet"" % ColorMode.name_of(header.color_mode)
96        )
97
98    mode = _get_mode(header.number_of_channels)
99    if mode is None:
100        raise NotImplementedError(""This number of channels (%d) is unsupported for this color mode (%s)"" % (
101                         header.number_of_channels, header.color_mode))
102
103    if header.depth != 8:
104        raise NotImplementedError(""Only 8bit images are currently supported with pymaging."")
105
106
107
108    return 8, mode
109
110","[['depth', '==', '8'], ['len(channels_data)', '==', 'num_channels']]",2,2,1.0,0.0006121824303642,"['Image', 'packbits', 'decoded_data', 'header', 'size', 'depth', 'mode', 'layer_index', 'layers', 'layer', 'channels_data', 'channel_types', '_', 'num_channels', 'total_size', 'image_bytes', 'data', 'image_bytes[index::num_channels]', 'pixels', 'number_of_channels']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['Image', 'packbits', 'decoded_data', 'header', 'size', 'depth', 'mode', 'layer_index', 'layers', 'layer', 'channels_data', 'channel_types', '_', 'num_channels', 'total_size', 'image_bytes', 'data', 'image_bytes[index::num_channels]', 'pixels', 'number_of_channels']
*Code:

1# -*- coding: utf-8 -*-
2from __future__ import absolute_import, unicode_literals
3
4import warnings
5import array
6
7try:
8    import packbits
9    from pymaging import Image
10    from pymaging.colors import RGB, RGBA
11    from pymaging.pixelarray import get_pixel_array
12except ImportError:
13    Image = None
14    packbits = None
15
16from psd_tools.constants import ColorMode, Compression, ChannelID
17
18
19def extract_composite_image(decoded_data):
20    """"""
21    Converts a composite (merged) image from the ``decoded_data``
22    to a pymaging.Image.
23    """"""
24    header = decoded_data.header
25    size = header.width, header.height
26    depth, mode = _validate_header(header)
27
28    return _channels_data_to_image(decoded_data.image_data, mode, size, depth)
29
30def extract_layer_image(decoded_data, layer_index):
31    """"""
32    Converts a layer from the ``decoded_data`` to a ``pymaging.Image``.
33    """"""
34    layers = decoded_data.layer_and_mask_data.layers
35    layer = layers.layer_records[layer_index]
36
37    channels_data = layers.channel_image_data[layer_index]
38    channel_types = [info.id for info in layer.channels]
39    size = layer.width(), layer.height()
40
41    depth, _ = _validate_header(decoded_data.header)
42
43    # FIXME: support for layers with mask (there would be 5 channels in this case)
44    if channel_types[0] == ChannelID.TRANSPARENCY_MASK:
45        # move alpha channel to the end
46        channels_data = [channels_data[i] for i in [1, 2, 3, 0]]
47
48    print(layer.channels)
49    mode = _get_mode(len(channels_data))
50
51    return _channels_data_to_image(channels_data, mode, size, depth)
52
53
54def _channels_data_to_image(channels_data, mode, size, depth):
55
56    if size == (0, 0):
57        return
58
59    num_channels = mode.length
60
61    total_size = size[0]*size[1]*num_channels
62    image_bytes = array.array(str(""B""), [0]*total_size)
63
64    for index, channel in enumerate(channels_data):
65
66        data = channel.data # zip and zip-with-prediction data is already decoded
67        if channel.compression == Compression.PACK_BITS:
68            data = packbits.decode(data)
69
70        image_bytes[index::num_channels] = array.array(str(""B""), data)
71
72    pixels = get_pixel_array(image_bytes, size[0], size[1], mode.length)
73
74    return Image(pixels, mode)
75
76
77def _get_mode(number_of_channels):
78    mode = None
79    if number_of_channels == 3:
80        mode = RGB
81    elif number_of_channels == 4:
82        mode = RGBA
83    return mode
84
85
86def _validate_header(header):
87    """"""
88    Validates header and returns (depth, mode) tuple.
89    """"""
90    if Image is None or packbits is None:
91        raise Exception(""This module requires `pymaging` and `packbits` packages."")
92
93    if header.color_mode != ColorMode.RGB:
94        raise NotImplementedError(
95            ""This color mode (%s) is not supported yet"" % ColorMode.name_of(header.color_mode)
96        )
97
98    mode = _get_mode(header.number_of_channels)
99    if mode is None:
100        raise NotImplementedError(""This number of channels (%d) is unsupported for this color mode (%s)"" % (
101                         header.number_of_channels, header.color_mode))
102
103    if header.depth != 8:
104        raise NotImplementedError(""Only 8bit images are currently supported with pymaging."")
105
106
107
108    return 8, mode
109
110",5068,"[[19, 'decoded_data', '!=', None, 'decoded_data must be provided for the function to complete the process'],
[30, 'decoded_data', '!=', None, 'decoded_data must be provided for the function to complete the process'],
[30, 'layer_index', '>=', 0, 'layer_index must be a non-negative integer to index layer'],
[54, 'channels_data', '!=', None, 'channels_data cannot be None to generate image'],
[54, 'mode', '!=', None, 'mode cannot be None for image processing'],
[54, 'size', '==', 2, 'the size tuple must have exactly two elements: width and height'],
[54, 'depth', '>=', 0, 'depth must be a non-negative number for image processing'],
[77, 'number_of_channels', '>=', 3, 'the number of channels should be 3 or 4 to generate RGB or RGBA mode'],
[86, 'header', '!=', None, 'header should not be None to validate it']]"
febert/DeepRL,"import pytest

def test_ddpg_replay(tmpdir):
  import ddpg
  import numpy as np
  np.set_printoptions(threshold=np.nan)

  ddpg.FLAGS.warmup = 10000
  ddpg.FLAGS.outdir = tmpdir.strpath
  # test replay memory
  a = ddpg.Agent([1],[1])
  a.reset([0])
  T = 10
  actions = []
  for t in range(0,T):
    actions.append(a.act())
    a.observe(t,False,[t+1])

  # print(a.rm)
  # print(a.rm.minibatch(5))
  # assert False



def test_replay_memory():
  from replay_memory import ReplayMemory
  s = 100
  rm = ReplayMemory(s,1,1)
  
  for i in range(0,100,1):
    rm.enqueue(i,i%3==0,i,i,i)
  
  for i in range(1000):
    o, a, r, o2, t2, info = rm.minibatch(10)
    assert all(o == o2-1),""error: o and o2""
    assert all(o != s-1) , ""error: o wrap over rm. o = ""+str(o) 
    assert all(o2 != 0) , ""error: o2 wrap over rm""","
1import pytest
2
3def test_ddpg_replay(tmpdir):
4  import ddpg
5  import numpy as np
6  np.set_printoptions(threshold=np.nan)
7
8  ddpg.FLAGS.warmup = 10000
9  ddpg.FLAGS.outdir = tmpdir.strpath
10  # test replay memory
11  a = ddpg.Agent([1],[1])
12  a.reset([0])
13  T = 10
14  actions = []
15  for t in range(0,T):
16    actions.append(a.act())
17    a.observe(t,False,[t+1])
18
19  # print(a.rm)
20  # print(a.rm.minibatch(5))
21
22
23
24def test_replay_memory():
25  from replay_memory import ReplayMemory
26  s = 100
27  rm = ReplayMemory(s,1,1)
28  
29  for i in range(0,100,1):
30    rm.enqueue(i,i%3==0,i,i,i)
31  
32  for i in range(1000):
33    o, a, r, o2, t2, info = rm.minibatch(10)","[['all(o', '==', 'o2-1)'], ['o2""', '==', 'True'], ['all(o', '!=', 's-1)'], ['all(o2', '!=', '0)']]",4,4,1.0,0.0049019607843137,"['tmpdir', 'ddpg.FLAGS.warmup', 'ddpg.FLAGS.outdir', 'a', 'T', 'actions', 's', 'rm', 'o', 'r', 'o2', 't2', 'info', 'assert all(o != s-1)', '""error: o wrap over rm. o']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tmpdir', 'ddpg.FLAGS.warmup', 'ddpg.FLAGS.outdir', 'a', 'T', 'actions', 's', 'rm', 'o', 'r', 'o2', 't2', 'info', 'assert all(o != s-1)', '""error: o wrap over rm. o']
*Code:

1import pytest
2
3def test_ddpg_replay(tmpdir):
4  import ddpg
5  import numpy as np
6  np.set_printoptions(threshold=np.nan)
7
8  ddpg.FLAGS.warmup = 10000
9  ddpg.FLAGS.outdir = tmpdir.strpath
10  # test replay memory
11  a = ddpg.Agent([1],[1])
12  a.reset([0])
13  T = 10
14  actions = []
15  for t in range(0,T):
16    actions.append(a.act())
17    a.observe(t,False,[t+1])
18
19  # print(a.rm)
20  # print(a.rm.minibatch(5))
21
22
23
24def test_replay_memory():
25  from replay_memory import ReplayMemory
26  s = 100
27  rm = ReplayMemory(s,1,1)
28  
29  for i in range(0,100,1):
30    rm.enqueue(i,i%3==0,i,i,i)
31  
32  for i in range(1000):
33    o, a, r, o2, t2, info = rm.minibatch(10)",2244,"[[3, 'tmpdir', '!=', None, ""tmpdir variable must be initialized""],
[8, 'ddpg.FLAGS.warmup', '>=', 0, ""warmup should be a non-negative value""],
[9, 'ddpg.FLAGS.outdir', '!=', None, ""outdir variable must be initialized""],
[11, 'a', '!=', None, ""agent must be initialized""],
[13, 'T', '>', 0, ""There must be at least one iteration""],
[24, 'ReplayMemory', '!=', None, ""ReplayMemory class must be available""],
[26, 's', '>', 0, ""Size of ReplayMemory must be greater than zero""],
[27, 'rm', '!=', None, ""ReplayMemory instance must be initialized""],
[33, 'o', '!=', None, ""o variable must be initialized""],
[33, 'a', '!=', None, ""a variable must be initialized""],
[33, 'r', '!=', None, ""r variable must be initialized""],
[33, 'o2', '!=', None, ""o2 variable must be initialized""],
[33, 't2', '!=', None, ""t2 variable must be initialized""],
[33, 'info', '!=', None, ""info variable must be initialized""]]"
novopl/sphinx-refdoc,"# -*- coding: utf-8 -*-
# pylint: disable=missing-docstring
from __future__ import absolute_import, unicode_literals

# stdlib imports
import os
import os.path
import shutil
import tempfile

# 3rd party imports
import pytest

# local imports
from refdoc import generate_docs


@pytest.fixture()
def tempdir():
    """""" Create a temp directory to store the generated files. """"""
    tempdir = tempfile.mkdtemp(prefix='sphinx-refdoc-e2e-tests')

    yield tempdir

    shutil.rmtree(tempdir)


def test_package_directory_exists(tempdir):
    generate_docs(['src/refdoc'], tempdir)

    pkg_path = os.path.join(tempdir, 'refdoc')
    assert os.path.exists(pkg_path)


def test_all_refdoc_submodules_exist(tempdir):
    generate_docs(['src/refdoc'], tempdir)

    files = os.listdir(os.path.join(tempdir, 'refdoc'))
    results = frozenset([f for f in files if f != 'index.rst'])
    expected = frozenset((
        'cli.rst',
        'logic.rst',
        'objects',
        'rst.rst',
        'toctree.rst',
        'util.rst'
    ))

    assert results == expected
","
1# -*- coding: utf-8 -*-
2# pylint: disable=missing-docstring
3from __future__ import absolute_import, unicode_literals
4
5# stdlib imports
6import os
7import os.path
8import shutil
9import tempfile
10
11# 3rd party imports
12import pytest
13
14# local imports
15from refdoc import generate_docs
16
17
18@pytest.fixture()
19def tempdir():
20    """""" Create a temp directory to store the generated files. """"""
21    tempdir = tempfile.mkdtemp(prefix='sphinx-refdoc-e2e-tests')
22
23    yield tempdir
24
25    shutil.rmtree(tempdir)
26
27
28def test_package_directory_exists(tempdir):
29    generate_docs(['src/refdoc'], tempdir)
30
31    pkg_path = os.path.join(tempdir, 'refdoc')
32
33
34def test_all_refdoc_submodules_exist(tempdir):
35    generate_docs(['src/refdoc'], tempdir)
36
37    files = os.listdir(os.path.join(tempdir, 'refdoc'))
38    results = frozenset([f for f in files if f != 'index.rst'])
39    expected = frozenset((
40        'cli.rst',
41        'logic.rst',
42        'objects',
43        'rst.rst',
44        'toctree.rst',
45        'util.rst'
46    ))
47
48","[['os.path.exists(pkg_path)', '==', 'True'], ['results', '==', 'expected']]",2,2,1.0,0.0018867924528301,"['tempdir', 'pkg_path', 'files', 'results', 'expected']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tempdir', 'pkg_path', 'files', 'results', 'expected']
*Code:

1# -*- coding: utf-8 -*-
2# pylint: disable=missing-docstring
3from __future__ import absolute_import, unicode_literals
4
5# stdlib imports
6import os
7import os.path
8import shutil
9import tempfile
10
11# 3rd party imports
12import pytest
13
14# local imports
15from refdoc import generate_docs
16
17
18@pytest.fixture()
19def tempdir():
20    """""" Create a temp directory to store the generated files. """"""
21    tempdir = tempfile.mkdtemp(prefix='sphinx-refdoc-e2e-tests')
22
23    yield tempdir
24
25    shutil.rmtree(tempdir)
26
27
28def test_package_directory_exists(tempdir):
29    generate_docs(['src/refdoc'], tempdir)
30
31    pkg_path = os.path.join(tempdir, 'refdoc')
32
33
34def test_all_refdoc_submodules_exist(tempdir):
35    generate_docs(['src/refdoc'], tempdir)
36
37    files = os.listdir(os.path.join(tempdir, 'refdoc'))
38    results = frozenset([f for f in files if f != 'index.rst'])
39    expected = frozenset((
40        'cli.rst',
41        'logic.rst',
42        'objects',
43        'rst.rst',
44        'toctree.rst',
45        'util.rst'
46    ))
47
48",2516,"[[28, 'tempdir', '!=', None, ""assert if the temporary directory has been successfully generated""],
 [33, 'pkg_path', '!=', None, ""assert if the package path has been successfully generated""],
 [37, 'files', '!=', None, ""assert if the files are successfully listed""],
 [38, 'results', '!=', None, ""assert if the results have been properly gathered from the files""],
 [46, 'expected', '==', len(files), ""assert if the expected results match the actual results""]]"
tiramisusolutions/carson,"# Example test to check if nginx is installed
def test_nginx_is_installed(host):
    nginx = host.package(""nginx"")
    assert nginx.is_installed
","
1# Example test to check if nginx is installed
2def test_nginx_is_installed(host):
3    nginx = host.package(""nginx"")
4","[['nginx.is_installed', '==', 'True']]",1,1,1.0,0.0068965517241379,"['host', 'nginx']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['host', 'nginx']
*Code:

1# Example test to check if nginx is installed
2def test_nginx_is_installed(host):
3    nginx = host.package(""nginx"")
4",1517,"[[2, 'host', '!=', None, ""the host should not be None""],
 [3, 'nginx', '!=', None, ""nginx package should exist after assignment""]]"
xiaonanln/myleetcode-python,"class Solution(object):
	def twoSum(self, nums, target):
		""""""
		:type nums: List[int]
		:type target: int
		:rtype: List[int]
		""""""
		N = len(nums)
		nums = [(n, i) for i, n in enumerate(nums)]
		nums.sort()
		i, j = 0, N-1

		while i < j:
			s = nums[i][0] + nums[j][0]
			if s == target:
				return [nums[i][1], nums[j][1]]
			elif s < target:
				i += 1
			else:
				j -= 1


# assert [0, 1] == [0, 1]
# assert Solution().twoSum([2,7,11,15], 9) == [0, 1]
assert Solution().twoSum([3,2,4], 6) == [1,2]","
1class Solution(object):
2	def twoSum(self, nums, target):
3		""""""
4		:type nums: List[int]
5		:type target: int
6		:rtype: List[int]
7		""""""
8		N = len(nums)
9		nums = [(n, i) for i, n in enumerate(nums)]
10		nums.sort()
11		i, j = 0, N-1
12
13		while i < j:
14			s = nums[i][0] + nums[j][0]
15			if s == target:
16				return [nums[i][1], nums[j][1]]
17			elif s < target:
18				i += 1
19			else:
20				j -= 1
21
22","[['Solution().twoSum([3', '==', 'True']]",3,1,0.3333333333333333,0.0019841269841269,"['nums', 'target', 'N', 'i', 'j', 's']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['nums', 'target', 'N', 'i', 'j', 's']
*Code:

1class Solution(object):
2	def twoSum(self, nums, target):
3		""""""
4		:type nums: List[int]
5		:type target: int
6		:rtype: List[int]
7		""""""
8		N = len(nums)
9		nums = [(n, i) for i, n in enumerate(nums)]
10		nums.sort()
11		i, j = 0, N-1
12
13		while i < j:
14			s = nums[i][0] + nums[j][0]
15			if s == target:
16				return [nums[i][1], nums[j][1]]
17			elif s < target:
18				i += 1
19			else:
20				j -= 1
21
22",1833,"[[2, 'nums', '!=', None, ""the list of numbers can't be None""],
[2, 'target', '!=', None, ""the target can't be None""],
[8, 'N', '==', len(nums), ""Check the length of the list""],
[11, 'i', '>=', 0, ""i can't be less than 0""],
[11, 'j', '>=', 'i', ""j can't be less than i""],
[14, 's', '>=', 'nums[i][0]', ""s should be greater than or equal to nums[i][0]""],
[16, len([nums[i][1], nums[j][1]]), '==', 2, ""returning list should contain 2 elements""]]"
OCA/carrier-delivery,"# -*- coding: utf-8 -*-
##############################################################################
#
#    Author: Yannick Vaucher
#    Copyright 2013 Camptocamp SA
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################
import openerp.tests.common as common
from openerp.addons import get_module_resource


class test_generate_labels(common.TransactionCase):

    """""" Test the wizard for delivery carrier label generation """"""

    def setUp(self):
        super(test_generate_labels, self).setUp()
        cr, uid = self.cr, self.uid

        self.Move = self.registry('stock.move')
        self.Picking = self.registry('stock.picking')
        self.ShippingLabel = self.registry('shipping.label')
        self.PickingDispatch = self.registry('picking.dispatch')
        self.DeliveryCarrierLabelGenerate = self.registry(
            'delivery.carrier.label.generate')

        picking_out_1_id = self.Picking.create(
            cr, uid,
            {'partner_id': self.ref('base.res_partner_12'),
             'type': 'out'})

        picking_out_2_id = self.Picking.create(
            cr, uid,
            {'partner_id': self.ref('base.res_partner_12'),
             'type': 'out'})

        self.picking_dispatch_id = self.PickingDispatch.create(
            cr, uid,
            {'name': 'demo_prep001',
             'picker_id': self.ref('base.user_demo'),
             })

        self.Move.create(
            cr, uid,
            {'name': '/',
             'picking_id': picking_out_1_id,
             'dispatch_id': self.picking_dispatch_id,
             'product_id': self.ref('product.product_product_33'),
             'product_uom': self.ref('product.product_uom_unit'),
             'product_qty': 2,
             'location_id': self.ref('stock.stock_location_14'),
             'location_dest_id': self.ref('stock.stock_location_7'),
             })

        self.Move.create(
            cr, uid,
            {'name': '/',
             'picking_id': picking_out_2_id,
             'dispatch_id': self.picking_dispatch_id,
             'product_id': self.ref('product.product_product_33'),
             'product_uom': self.ref('product.product_uom_unit'),
             'product_qty': 1,
             'location_id': self.ref('stock.stock_location_14'),
             'location_dest_id': self.ref('stock.stock_location_7'),
             })

        label = ''
        dummy_pdf_path = get_module_resource('delivery_carrier_label_dispatch',
                                             'tests', 'dummy.pdf')
        with file(dummy_pdf_path) as dummy_pdf:
            label = dummy_pdf.read()

        self.ShippingLabel.create(
            cr, uid,
            {'name': 'picking_out_1',
             'res_id': picking_out_1_id,
             'res_model': 'stock.picking.out',
             'datas': label.encode('base64'),
             'file_type': 'pdf',
             })

        self.ShippingLabel.create(
            cr, uid,
            {'name': 'picking_out_2',
             'res_id': picking_out_2_id,
             'res_model': 'stock.picking.out',
             'datas': label.encode('base64'),
             'file_type': 'pdf',
             })

    def test_00_action_generate_labels(self):
        """""" Check merging of pdf labels

        We don't test pdf generation as without dependancies the
        test would fail

        """"""
        cr, uid = self.cr, self.uid
        active_ids = [self.picking_dispatch_id]
        wizard_id = self.DeliveryCarrierLabelGenerate.create(
            cr, uid,
            {},
            context={'active_ids': active_ids,
                     'active_model': 'picking.dispatch'})
        wizard = self.DeliveryCarrierLabelGenerate.browse(
            cr, uid, [wizard_id], context=None)
        self.DeliveryCarrierLabelGenerate.action_generate_labels(
            cr, uid, [wizard_id], context={'active_ids': active_ids})
        wizard = self.DeliveryCarrierLabelGenerate.browse(
            cr, uid, wizard_id, context=None)
        assert wizard.label_pdf_file
","
1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    Author: Yannick Vaucher
5#    Copyright 2013 Camptocamp SA
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as
9#    published by the Free Software Foundation, either version 3 of the
10#    License, or (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21import openerp.tests.common as common
22from openerp.addons import get_module_resource
23
24
25class test_generate_labels(common.TransactionCase):
26
27    """""" Test the wizard for delivery carrier label generation """"""
28
29    def setUp(self):
30        super(test_generate_labels, self).setUp()
31        cr, uid = self.cr, self.uid
32
33        self.Move = self.registry('stock.move')
34        self.Picking = self.registry('stock.picking')
35        self.ShippingLabel = self.registry('shipping.label')
36        self.PickingDispatch = self.registry('picking.dispatch')
37        self.DeliveryCarrierLabelGenerate = self.registry(
38            'delivery.carrier.label.generate')
39
40        picking_out_1_id = self.Picking.create(
41            cr, uid,
42            {'partner_id': self.ref('base.res_partner_12'),
43             'type': 'out'})
44
45        picking_out_2_id = self.Picking.create(
46            cr, uid,
47            {'partner_id': self.ref('base.res_partner_12'),
48             'type': 'out'})
49
50        self.picking_dispatch_id = self.PickingDispatch.create(
51            cr, uid,
52            {'name': 'demo_prep001',
53             'picker_id': self.ref('base.user_demo'),
54             })
55
56        self.Move.create(
57            cr, uid,
58            {'name': '/',
59             'picking_id': picking_out_1_id,
60             'dispatch_id': self.picking_dispatch_id,
61             'product_id': self.ref('product.product_product_33'),
62             'product_uom': self.ref('product.product_uom_unit'),
63             'product_qty': 2,
64             'location_id': self.ref('stock.stock_location_14'),
65             'location_dest_id': self.ref('stock.stock_location_7'),
66             })
67
68        self.Move.create(
69            cr, uid,
70            {'name': '/',
71             'picking_id': picking_out_2_id,
72             'dispatch_id': self.picking_dispatch_id,
73             'product_id': self.ref('product.product_product_33'),
74             'product_uom': self.ref('product.product_uom_unit'),
75             'product_qty': 1,
76             'location_id': self.ref('stock.stock_location_14'),
77             'location_dest_id': self.ref('stock.stock_location_7'),
78             })
79
80        label = ''
81        dummy_pdf_path = get_module_resource('delivery_carrier_label_dispatch',
82                                             'tests', 'dummy.pdf')
83        with file(dummy_pdf_path) as dummy_pdf:
84            label = dummy_pdf.read()
85
86        self.ShippingLabel.create(
87            cr, uid,
88            {'name': 'picking_out_1',
89             'res_id': picking_out_1_id,
90             'res_model': 'stock.picking.out',
91             'datas': label.encode('base64'),
92             'file_type': 'pdf',
93             })
94
95        self.ShippingLabel.create(
96            cr, uid,
97            {'name': 'picking_out_2',
98             'res_id': picking_out_2_id,
99             'res_model': 'stock.picking.out',
100             'datas': label.encode('base64'),
101             'file_type': 'pdf',
102             })
103
104    def test_00_action_generate_labels(self):
105        """""" Check merging of pdf labels
106
107        We don't test pdf generation as without dependancies the
108        test would fail
109
110        """"""
111        cr, uid = self.cr, self.uid
112        active_ids = [self.picking_dispatch_id]
113        wizard_id = self.DeliveryCarrierLabelGenerate.create(
114            cr, uid,
115            {},
116            context={'active_ids': active_ids,
117                     'active_model': 'picking.dispatch'})
118        wizard = self.DeliveryCarrierLabelGenerate.browse(
119            cr, uid, [wizard_id], context=None)
120        self.DeliveryCarrierLabelGenerate.action_generate_labels(
121            cr, uid, [wizard_id], context={'active_ids': active_ids})
122        wizard = self.DeliveryCarrierLabelGenerate.browse(
123            cr, uid, wizard_id, context=None)
124","[['wizard.label_pdf_file', '==', 'True']]",1,1,1.0,0.0002109259649862,"['cr', 'uid', 'self.Move', 'self.Picking', 'self.ShippingLabel', 'self.PickingDispatch', 'self.DeliveryCarrierLabelGenerate', 'picking_out_1_id', 'picking_out_2_id', 'self.picking_dispatch_id', 'label', 'dummy_pdf_path', 'active_ids', 'wizard_id', 'wizard']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cr', 'uid', 'self.Move', 'self.Picking', 'self.ShippingLabel', 'self.PickingDispatch', 'self.DeliveryCarrierLabelGenerate', 'picking_out_1_id', 'picking_out_2_id', 'self.picking_dispatch_id', 'label', 'dummy_pdf_path', 'active_ids', 'wizard_id', 'wizard']
*Code:

1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    Author: Yannick Vaucher
5#    Copyright 2013 Camptocamp SA
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as
9#    published by the Free Software Foundation, either version 3 of the
10#    License, or (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21import openerp.tests.common as common
22from openerp.addons import get_module_resource
23
24
25class test_generate_labels(common.TransactionCase):
26
27    """""" Test the wizard for delivery carrier label generation """"""
28
29    def setUp(self):
30        super(test_generate_labels, self).setUp()
31        cr, uid = self.cr, self.uid
32
33        self.Move = self.registry('stock.move')
34        self.Picking = self.registry('stock.picking')
35        self.ShippingLabel = self.registry('shipping.label')
36        self.PickingDispatch = self.registry('picking.dispatch')
37        self.DeliveryCarrierLabelGenerate = self.registry(
38            'delivery.carrier.label.generate')
39
40        picking_out_1_id = self.Picking.create(
41            cr, uid,
42            {'partner_id': self.ref('base.res_partner_12'),
43             'type': 'out'})
44
45        picking_out_2_id = self.Picking.create(
46            cr, uid,
47            {'partner_id': self.ref('base.res_partner_12'),
48             'type': 'out'})
49
50        self.picking_dispatch_id = self.PickingDispatch.create(
51            cr, uid,
52            {'name': 'demo_prep001',
53             'picker_id': self.ref('base.user_demo'),
54             })
55
56        self.Move.create(
57            cr, uid,
58            {'name': '/',
59             'picking_id': picking_out_1_id,
60             'dispatch_id': self.picking_dispatch_id,
61             'product_id': self.ref('product.product_product_33'),
62             'product_uom': self.ref('product.product_uom_unit'),
63             'product_qty': 2,
64             'location_id': self.ref('stock.stock_location_14'),
65             'location_dest_id': self.ref('stock.stock_location_7'),
66             })
67
68        self.Move.create(
69            cr, uid,
70            {'name': '/',
71             'picking_id': picking_out_2_id,
72             'dispatch_id': self.picking_dispatch_id,
73             'product_id': self.ref('product.product_product_33'),
74             'product_uom': self.ref('product.product_uom_unit'),
75             'product_qty': 1,
76             'location_id': self.ref('stock.stock_location_14'),
77             'location_dest_id': self.ref('stock.stock_location_7'),
78             })
79
80        label = ''
81        dummy_pdf_path = get_module_resource('delivery_carrier_label_dispatch',
82                                             'tests', 'dummy.pdf')
83        with file(dummy_pdf_path) as dummy_pdf:
84            label = dummy_pdf.read()
85
86        self.ShippingLabel.create(
87            cr, uid,
88            {'name': 'picking_out_1',
89             'res_id': picking_out_1_id,
90             'res_model': 'stock.picking.out',
91             'datas': label.encode('base64'),
92             'file_type': 'pdf',
93             })
94
95        self.ShippingLabel.create(
96            cr, uid,
97            {'name': 'picking_out_2',
98             'res_id': picking_out_2_id,
99             'res_model': 'stock.picking.out',
100             'datas': label.encode('base64'),
101             'file_type': 'pdf',
102             })
103
104    def test_00_action_generate_labels(self):
105        """""" Check merging of pdf labels
106
107        We don't test pdf generation as without dependancies the
108        test would fail
109
110        """"""
111        cr, uid = self.cr, self.uid
112        active_ids = [self.picking_dispatch_id]
113        wizard_id = self.DeliveryCarrierLabelGenerate.create(
114            cr, uid,
115            {},
116            context={'active_ids': active_ids,
117                     'active_model': 'picking.dispatch'})
118        wizard = self.DeliveryCarrierLabelGenerate.browse(
119            cr, uid, [wizard_id], context=None)
120        self.DeliveryCarrierLabelGenerate.action_generate_labels(
121            cr, uid, [wizard_id], context={'active_ids': active_ids})
122        wizard = self.DeliveryCarrierLabelGenerate.browse(
123            cr, uid, wizard_id, context=None)
124",6606,"[[31, 'cr', '!=', None, 'the cursor can not be None'],
 [31, 'uid', '!=', None, 'the user id can not be None'],
 [33, 'self.Move', '!=', None, 'the registry on stock.move must exist'],
 [34, 'self.Picking', '!=', None, 'the registry on stock.picking must exist'],
 [35, 'self.ShippingLabel', '!=', None, 'the registry on shipping.label must exist'],
 [36, 'self.PickingDispatch', '!=', None, 'the registry on picking.dispatch must exist'],
 [40, 'picking_out_1_id', '!=', None, 'the record for first picking must have been created'],
 [45, 'picking_out_2_id', '!=', None, 'the record for second picking must have been created'],
 [50, 'self.picking_dispatch_id', '!=', None, 'the PickingDispatch record must have been created'],
 [80, 'label', '!=', None, 'label must be initialize'],
 [82, 'dummy_pdf_path', '!=', None, 'the path to the dummy pdf must exist'],
 [86, 'self.ShippingLabel', '!=', None, 'the record for first shipping label must have been created'],
 [95, 'self.ShippingLabel', '!=', None, 'the record for second shipping label must have been created'],
 [112, 'active_ids', '!=', None, 'the list cannot be empty'],
 [113, 'wizard_id', '!=', None, 'wizard record must have been created'],
 [116, 'wizard', '!=', None, 'wizard must exist']]"
michaelpacer/scikit-image,"import numpy as np
from numpy.testing import assert_equal, assert_raises
from skimage import img_as_int, img_as_float, \
                    img_as_uint, img_as_ubyte
from skimage.util.dtype import convert
from skimage._shared._warnings import expected_warnings


dtype_range = {np.uint8: (0, 255),
               np.uint16: (0, 65535),
               np.int8: (-128, 127),
               np.int16: (-32768, 32767),
               np.float32: (-1.0, 1.0),
               np.float64: (-1.0, 1.0)}


def _verify_range(msg, x, vmin, vmax, dtype):
    assert_equal(x[0], vmin)
    assert_equal(x[-1], vmax)
    assert x.dtype == dtype


def test_range():
    for dtype in dtype_range:
        imin, imax = dtype_range[dtype]
        x = np.linspace(imin, imax, 10).astype(dtype)

        for (f, dt) in [(img_as_int, np.int16),
                        (img_as_float, np.float64),
                        (img_as_uint, np.uint16),
                        (img_as_ubyte, np.ubyte)]:
            
            with expected_warnings(['precision loss|sign loss|\A\Z']):
                y = f(x)

            omin, omax = dtype_range[dt]

            if imin == 0 or omin == 0:
                omin = 0
                imin = 0

            yield (_verify_range,
                   ""From %s to %s"" % (np.dtype(dtype), np.dtype(dt)),
                   y, omin, omax, np.dtype(dt))


def test_range_extra_dtypes():
    """"""Test code paths that are not skipped by `test_range`""""""

    # Add non-standard data types that are allowed by the `convert` function.
    dtype_range_extra = dtype_range.copy()
    dtype_range_extra.update({np.int32: (-2147483648, 2147483647),
                              np.uint32: (0, 4294967295)})

    dtype_pairs = [(np.uint8, np.uint32),
                   (np.int8, np.uint32),
                   (np.int8, np.int32),
                   (np.int32, np.int8),
                   (np.float64, np.float32),
                   (np.int32, np.float32)]

    for dtype_in, dt in dtype_pairs:
        imin, imax = dtype_range_extra[dtype_in]
        x = np.linspace(imin, imax, 10).astype(dtype_in)
        
        with expected_warnings(['precision loss|sign loss|\A\Z']):
            y = convert(x, dt)

        omin, omax = dtype_range_extra[dt]
        yield (_verify_range,
               ""From %s to %s"" % (np.dtype(dtype_in), np.dtype(dt)),
               y, omin, omax, np.dtype(dt))


def test_unsupported_dtype():
    x = np.arange(10).astype(np.uint64)
    assert_raises(ValueError, img_as_int, x)


def test_float_out_of_range():
    too_high = np.array([2], dtype=np.float32)
    assert_raises(ValueError, img_as_int, too_high)
    too_low = np.array([-2], dtype=np.float32)
    assert_raises(ValueError, img_as_int, too_low)


def test_copy():
    x = np.array([1], dtype=np.float64)
    y = img_as_float(x)
    z = img_as_float(x, force_copy=True)

    assert y is x
    assert z is not x


def test_bool():
    img_ = np.zeros((10, 10), np.bool_)
    img8 = np.zeros((10, 10), np.bool8)
    img_[1, 1] = True
    img8[1, 1] = True
    for (func, dt) in [(img_as_int, np.int16),
                    (img_as_float, np.float64),
                    (img_as_uint, np.uint16),
                    (img_as_ubyte, np.ubyte)]:
        converted_ = func(img_)
        assert np.sum(converted_) == dtype_range[dt][1]
        converted8 = func(img8)
        assert np.sum(converted8) == dtype_range[dt][1]

if __name__ == '__main__':
    np.testing.run_module_suite()
","
1import numpy as np
2from skimage import img_as_int, img_as_float, \
3                    img_as_uint, img_as_ubyte
4from skimage.util.dtype import convert
5from skimage._shared._warnings import expected_warnings
6
7
8dtype_range = {np.uint8: (0, 255),
9               np.uint16: (0, 65535),
10               np.int8: (-128, 127),
11               np.int16: (-32768, 32767),
12               np.float32: (-1.0, 1.0),
13               np.float64: (-1.0, 1.0)}
14
15
16def _verify_range(msg, x, vmin, vmax, dtype):
17
18
19def test_range():
20    for dtype in dtype_range:
21        imin, imax = dtype_range[dtype]
22        x = np.linspace(imin, imax, 10).astype(dtype)
23
24        for (f, dt) in [(img_as_int, np.int16),
25                        (img_as_float, np.float64),
26                        (img_as_uint, np.uint16),
27                        (img_as_ubyte, np.ubyte)]:
28            
29            with expected_warnings(['precision loss|sign loss|\A\Z']):
30                y = f(x)
31
32            omin, omax = dtype_range[dt]
33
34            if imin == 0 or omin == 0:
35                omin = 0
36                imin = 0
37
38            yield (_verify_range,
39                   ""From %s to %s"" % (np.dtype(dtype), np.dtype(dt)),
40                   y, omin, omax, np.dtype(dt))
41
42
43def test_range_extra_dtypes():
44    """"""Test code paths that are not skipped by `test_range`""""""
45
46    # Add non-standard data types that are allowed by the `convert` function.
47    dtype_range_extra = dtype_range.copy()
48    dtype_range_extra.update({np.int32: (-2147483648, 2147483647),
49                              np.uint32: (0, 4294967295)})
50
51    dtype_pairs = [(np.uint8, np.uint32),
52                   (np.int8, np.uint32),
53                   (np.int8, np.int32),
54                   (np.int32, np.int8),
55                   (np.float64, np.float32),
56                   (np.int32, np.float32)]
57
58    for dtype_in, dt in dtype_pairs:
59        imin, imax = dtype_range_extra[dtype_in]
60        x = np.linspace(imin, imax, 10).astype(dtype_in)
61        
62        with expected_warnings(['precision loss|sign loss|\A\Z']):
63            y = convert(x, dt)
64
65        omin, omax = dtype_range_extra[dt]
66        yield (_verify_range,
67               ""From %s to %s"" % (np.dtype(dtype_in), np.dtype(dt)),
68               y, omin, omax, np.dtype(dt))
69
70
71def test_unsupported_dtype():
72    x = np.arange(10).astype(np.uint64)
73
74
75def test_float_out_of_range():
76    too_high = np.array([2], dtype=np.float32)
77    too_low = np.array([-2], dtype=np.float32)
78
79
80def test_copy():
81    x = np.array([1], dtype=np.float64)
82    y = img_as_float(x)
83    z = img_as_float(x, force_copy=True)
84
85
86
87def test_bool():
88    img_ = np.zeros((10, 10), np.bool_)
89    img8 = np.zeros((10, 10), np.bool8)
90    img_[1, 1] = True
91    img8[1, 1] = True
92    for (func, dt) in [(img_as_int, np.int16),
93                    (img_as_float, np.float64),
94                    (img_as_uint, np.uint16),
95                    (img_as_ubyte, np.ubyte)]:
96        converted_ = func(img_)
97        converted8 = func(img8)
98
99if __name__ == '__main__':
100    np.testing.run_module_suite()
101","[['x.dtype', '==', 'dtype'], ['y', '==', 'x'], ['z', '==', 'not x'], ['np.sum(converted_)', '==', 'dtype_range[dt][1]'], ['np.sum(converted8)', '==', 'dtype_range[dt][1]']]",11,5,0.4545454545454545,0.0014343086632243,"['dtype_range', 'msg', 'x', 'vmin', 'vmax', 'dtype', 'imin', 'imax', 'y', 'omin', 'omax', 'dtype_range_extra', 'dtype_pairs', 'too_high', 'too_low', 'z', 'img_', 'img8', 'img_[1', '1]', 'img8[1', 'converted_', 'converted8']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['dtype_range', 'msg', 'x', 'vmin', 'vmax', 'dtype', 'imin', 'imax', 'y', 'omin', 'omax', 'dtype_range_extra', 'dtype_pairs', 'too_high', 'too_low', 'z', 'img_', 'img8', 'img_[1', '1]', 'img8[1', 'converted_', 'converted8']
*Code:

1import numpy as np
2from skimage import img_as_int, img_as_float, \
3                    img_as_uint, img_as_ubyte
4from skimage.util.dtype import convert
5from skimage._shared._warnings import expected_warnings
6
7
8dtype_range = {np.uint8: (0, 255),
9               np.uint16: (0, 65535),
10               np.int8: (-128, 127),
11               np.int16: (-32768, 32767),
12               np.float32: (-1.0, 1.0),
13               np.float64: (-1.0, 1.0)}
14
15
16def _verify_range(msg, x, vmin, vmax, dtype):
17
18
19def test_range():
20    for dtype in dtype_range:
21        imin, imax = dtype_range[dtype]
22        x = np.linspace(imin, imax, 10).astype(dtype)
23
24        for (f, dt) in [(img_as_int, np.int16),
25                        (img_as_float, np.float64),
26                        (img_as_uint, np.uint16),
27                        (img_as_ubyte, np.ubyte)]:
28            
29            with expected_warnings(['precision loss|sign loss|\A\Z']):
30                y = f(x)
31
32            omin, omax = dtype_range[dt]
33
34            if imin == 0 or omin == 0:
35                omin = 0
36                imin = 0
37
38            yield (_verify_range,
39                   ""From %s to %s"" % (np.dtype(dtype), np.dtype(dt)),
40                   y, omin, omax, np.dtype(dt))
41
42
43def test_range_extra_dtypes():
44    """"""Test code paths that are not skipped by `test_range`""""""
45
46    # Add non-standard data types that are allowed by the `convert` function.
47    dtype_range_extra = dtype_range.copy()
48    dtype_range_extra.update({np.int32: (-2147483648, 2147483647),
49                              np.uint32: (0, 4294967295)})
50
51    dtype_pairs = [(np.uint8, np.uint32),
52                   (np.int8, np.uint32),
53                   (np.int8, np.int32),
54                   (np.int32, np.int8),
55                   (np.float64, np.float32),
56                   (np.int32, np.float32)]
57
58    for dtype_in, dt in dtype_pairs:
59        imin, imax = dtype_range_extra[dtype_in]
60        x = np.linspace(imin, imax, 10).astype(dtype_in)
61        
62        with expected_warnings(['precision loss|sign loss|\A\Z']):
63            y = convert(x, dt)
64
65        omin, omax = dtype_range_extra[dt]
66        yield (_verify_range,
67               ""From %s to %s"" % (np.dtype(dtype_in), np.dtype(dt)),
68               y, omin, omax, np.dtype(dt))
69
70
71def test_unsupported_dtype():
72    x = np.arange(10).astype(np.uint64)
73
74
75def test_float_out_of_range():
76    too_high = np.array([2], dtype=np.float32)
77    too_low = np.array([-2], dtype=np.float32)
78
79
80def test_copy():
81    x = np.array([1], dtype=np.float64)
82    y = img_as_float(x)
83    z = img_as_float(x, force_copy=True)
84
85
86
87def test_bool():
88    img_ = np.zeros((10, 10), np.bool_)
89    img8 = np.zeros((10, 10), np.bool8)
90    img_[1, 1] = True
91    img8[1, 1] = True
92    for (func, dt) in [(img_as_int, np.int16),
93                    (img_as_float, np.float64),
94                    (img_as_uint, np.uint16),
95                    (img_as_ubyte, np.ubyte)]:
96        converted_ = func(img_)
97        converted8 = func(img8)
98
99if __name__ == '__main__':
100    np.testing.run_module_suite()
101",4844,"[[16, 'x', '!=', None, 'x should not be None before testing range'],
[16, 'vmin', '!=', None, 'vmin should not be None before testing range'],
[16, 'vmax', '!=', None, 'vmax should not be None before testing range'],
[16, 'dtype', '!=', None, 'dtype should not be None before testing range'],
[29, 'x', '!=', None, 'x should not be None to avoid errors during precision or sign loss'],
[34, 'imin', '>=', 0, 'imin should be 0 when omin is 0 to avoid mismatch in range'],
[34, 'omin', '>=', 0, 'omin should be 0 when imin is 0 to avoid mismatch in range'],
[61, 'x', '!=', None, 'x should not be None to avoid errors during precision or sign loss'],
[79, 'too_high', '>', 1.0, 'Checking for a float out of range on higher side'],
[79, 'too_low', '<', -1.0, 'Checking for a float out of range on lower side'],
[81, 'x', '!=', None, 'x should not be None for operation'],
[87, 'img_', '!=', None, 'img_ should not be None for operation'],
[87, 'img8', '!=', None, 'img8 should not be None for operation'],
[95, 'converted_', '!=', None, 'converted_ must have a value after conversion'],
[95, 'converted8', '!=', None, 'converted8 must have a value after conversion']]"
finikorg/zephyr,"# Copyright (c) 2019 Intel Corporation
#
# SPDX-License-Identifier: Apache-2.0

# based on http://protips.readthedocs.io/link-roles.html

from __future__ import print_function
from __future__ import unicode_literals
import re
import subprocess
from docutils import nodes
try:
    import west.manifest
    try:
        west_manifest = west.manifest.Manifest.from_file()
    except west.util.WestNotFound:
        west_manifest = None
except ImportError:
    west_manifest = None


def get_github_rev():
    try:
        output = subprocess.check_output('git describe --exact-match',
                                         shell=True, stderr=subprocess.DEVNULL)
    except subprocess.CalledProcessError:
        return 'main'

    return output.strip().decode('utf-8')


def setup(app):
    rev = get_github_rev()

    # Try to get the zephyr repository's GitHub URL from the manifest.
    #
    # This allows building the docs in downstream Zephyr-based
    # software with forks of the zephyr repository, and getting
    # :zephyr_file: / :zephyr_raw: output that links to the fork,
    # instead of mainline zephyr.
    baseurl = None
    if west_manifest is not None:
        try:
            # This search tries to look up a project named 'zephyr'.
            # If zephyr is the manifest repository, this raises
            # ValueError, since there isn't any such project.
            baseurl = west_manifest.get_projects(['zephyr'],
                                                 allow_paths=False)[0].url
            # Spot check that we have a non-empty URL.
            assert baseurl
        except ValueError:
            pass

    # If the search failed, fall back on the mainline URL.
    if baseurl is None:
        baseurl = 'https://github.com/zephyrproject-rtos/zephyr'

    app.add_role('zephyr_file', autolink('{}/blob/{}/%s'.format(baseurl, rev)))
    app.add_role('zephyr_raw', autolink('{}/raw/{}/%s'.format(baseurl, rev)))

    # The role just creates new nodes based on information in the
    # arguments; its behavior doesn't depend on any other documents.
    return {
        'parallel_read_safe': True,
        'parallel_write_safe': True,
    }


def autolink(pattern):
    def role(name, rawtext, text, lineno, inliner, options={}, content=[]):
        m = re.search(r'(.*)\s*<(.*)>', text)
        if m:
            link_text = m.group(1)
            link = m.group(2)
        else:
            link_text = text
            link = text
        url = pattern % (link,)
        node = nodes.reference(rawtext, link_text, refuri=url, **options)
        return [node], []
    return role
","
1# Copyright (c) 2019 Intel Corporation
2#
3# SPDX-License-Identifier: Apache-2.0
4
5# based on http://protips.readthedocs.io/link-roles.html
6
7from __future__ import print_function
8from __future__ import unicode_literals
9import re
10import subprocess
11from docutils import nodes
12try:
13    import west.manifest
14    try:
15        west_manifest = west.manifest.Manifest.from_file()
16    except west.util.WestNotFound:
17        west_manifest = None
18except ImportError:
19    west_manifest = None
20
21
22def get_github_rev():
23    try:
24        output = subprocess.check_output('git describe --exact-match',
25                                         shell=True, stderr=subprocess.DEVNULL)
26    except subprocess.CalledProcessError:
27        return 'main'
28
29    return output.strip().decode('utf-8')
30
31
32def setup(app):
33    rev = get_github_rev()
34
35    # Try to get the zephyr repository's GitHub URL from the manifest.
36    #
37    # This allows building the docs in downstream Zephyr-based
38    # software with forks of the zephyr repository, and getting
39    # :zephyr_file: / :zephyr_raw: output that links to the fork,
40    # instead of mainline zephyr.
41    baseurl = None
42    if west_manifest is not None:
43        try:
44            # This search tries to look up a project named 'zephyr'.
45            # If zephyr is the manifest repository, this raises
46            # ValueError, since there isn't any such project.
47            baseurl = west_manifest.get_projects(['zephyr'],
48                                                 allow_paths=False)[0].url
49            # Spot check that we have a non-empty URL.
50        except ValueError:
51            pass
52
53    # If the search failed, fall back on the mainline URL.
54    if baseurl is None:
55        baseurl = 'https://github.com/zephyrproject-rtos/zephyr'
56
57    app.add_role('zephyr_file', autolink('{}/blob/{}/%s'.format(baseurl, rev)))
58    app.add_role('zephyr_raw', autolink('{}/raw/{}/%s'.format(baseurl, rev)))
59
60    # The role just creates new nodes based on information in the
61    # arguments; its behavior doesn't depend on any other documents.
62    return {
63        'parallel_read_safe': True,
64        'parallel_write_safe': True,
65    }
66
67
68def autolink(pattern):
69    def role(name, rawtext, text, lineno, inliner, options={}, content=[]):
70        m = re.search(r'(.*)\s*<(.*)>', text)
71        if m:
72            link_text = m.group(1)
73            link = m.group(2)
74        else:
75            link_text = text
76            link = text
77        url = pattern % (link,)
78        node = nodes.reference(rawtext, link_text, refuri=url, **options)
79        return [node], []
80    return role
81","[['baseurl', '==', 'True']]",1,1,1.0,0.0003818251240931,"['west_manifest', 'output', 'app', 'rev', 'baseurl', 'pattern', 'name', 'rawtext', 'text', 'lineno', 'inliner', 'options', 'content', 'm', 'link_text', 'link', 'url', 'node']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['west_manifest', 'output', 'app', 'rev', 'baseurl', 'pattern', 'name', 'rawtext', 'text', 'lineno', 'inliner', 'options', 'content', 'm', 'link_text', 'link', 'url', 'node']
*Code:

1# Copyright (c) 2019 Intel Corporation
2#
3# SPDX-License-Identifier: Apache-2.0
4
5# based on http://protips.readthedocs.io/link-roles.html
6
7from __future__ import print_function
8from __future__ import unicode_literals
9import re
10import subprocess
11from docutils import nodes
12try:
13    import west.manifest
14    try:
15        west_manifest = west.manifest.Manifest.from_file()
16    except west.util.WestNotFound:
17        west_manifest = None
18except ImportError:
19    west_manifest = None
20
21
22def get_github_rev():
23    try:
24        output = subprocess.check_output('git describe --exact-match',
25                                         shell=True, stderr=subprocess.DEVNULL)
26    except subprocess.CalledProcessError:
27        return 'main'
28
29    return output.strip().decode('utf-8')
30
31
32def setup(app):
33    rev = get_github_rev()
34
35    # Try to get the zephyr repository's GitHub URL from the manifest.
36    #
37    # This allows building the docs in downstream Zephyr-based
38    # software with forks of the zephyr repository, and getting
39    # :zephyr_file: / :zephyr_raw: output that links to the fork,
40    # instead of mainline zephyr.
41    baseurl = None
42    if west_manifest is not None:
43        try:
44            # This search tries to look up a project named 'zephyr'.
45            # If zephyr is the manifest repository, this raises
46            # ValueError, since there isn't any such project.
47            baseurl = west_manifest.get_projects(['zephyr'],
48                                                 allow_paths=False)[0].url
49            # Spot check that we have a non-empty URL.
50        except ValueError:
51            pass
52
53    # If the search failed, fall back on the mainline URL.
54    if baseurl is None:
55        baseurl = 'https://github.com/zephyrproject-rtos/zephyr'
56
57    app.add_role('zephyr_file', autolink('{}/blob/{}/%s'.format(baseurl, rev)))
58    app.add_role('zephyr_raw', autolink('{}/raw/{}/%s'.format(baseurl, rev)))
59
60    # The role just creates new nodes based on information in the
61    # arguments; its behavior doesn't depend on any other documents.
62    return {
63        'parallel_read_safe': True,
64        'parallel_write_safe': True,
65    }
66
67
68def autolink(pattern):
69    def role(name, rawtext, text, lineno, inliner, options={}, content=[]):
70        m = re.search(r'(.*)\s*<(.*)>', text)
71        if m:
72            link_text = m.group(1)
73            link = m.group(2)
74        else:
75            link_text = text
76            link = text
77        url = pattern % (link,)
78        node = nodes.reference(rawtext, link_text, refuri=url, **options)
79        return [node], []
80    return role
81",4300,"[[22, 'output', '!=', None, 'the output of subprocess should not be None'],
 [32, 'app', '!=', None, 'the app instance should be initialized'],
 [32, 'rev', '!=', None, 'the revision number from git should be retrieved'],
 [41, 'baseurl', '!=', None, 'baseurl must be assigned a value'],
 [68, 'pattern', '!=', None, 'input pattern should not be None'],
 [70, 'name', '!=', None, 'name for the role must be provided'],
 [70, 'rawtext', '!=', None, 'rawtext for the role must be provided'],
 [70, 'text', '!=', None, 'text for the role must be provided'],
 [70, 'inliner', '!=', None, 'inliner for processing inline markup must be provided'],
 [70, 'options', '!=', None, 'options dictionary must be provided'],
 [70, 'content', '!=', None, 'content list must be provided'],
 [72, 'm', '!=', None, 'matched object m should not be None'],
 [73, 'link_text', '!=', None, 'link_text must not be None'],
 [74, 'link', '!=', None, 'link must not be None'],
 [77, 'url', '!=', None, 'url formatted with pattern and link should not be None'],
 [78, 'node', '!=', None, 'node created as reference must not be None']]"
diorcety/translate,"# -*- coding: utf-8 -*-
#
# Copyright 2007 Zuza Software Foundation
#
# This file is part of translate.
#
# translate is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# translate is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/>.

import os
import os.path as path
import sys
from subprocess import call

from lxml import etree


schema = None


def xmllint(fullpath):
    return schema.validate(etree.parse(fullpath))


def setup_module(module):
    global schema
    os.chdir(path.dirname(__file__))
    schema = etree.XMLSchema(etree.parse('xliff-core-1.1.xsd'))


def find_files(base, check_ext):
    for dirpath, _dirnames, filenames in os.walk(base):
        for filename in filenames:
            fullpath = path.join(dirpath, filename)
            _namepath, ext = path.splitext(fullpath)
            if check_ext == ext:
                yield fullpath


def test_open_office_to_xliff():
    assert call(['oo2xliff', 'en-US.sdf', '-l', 'fr', 'fr']) == 0
    for filepath in find_files('fr', '.xlf'):
        assert xmllint(filepath)
    cleardir('fr')


def test_po_to_xliff():
    OUTPUT = 'af-pootle.xlf'
    assert call(['po2xliff', 'af-pootle.po', OUTPUT]) == 0
    assert xmllint(OUTPUT)


def teardown_module(module):
    pass


def cleardir(testdir):
    """"""removes the test directory""""""
    if os.path.exists(testdir):
        for dirpath, subdirs, filenames in os.walk(testdir, topdown=False):
            for name in filenames:
                os.remove(os.path.join(dirpath, name))
            for name in subdirs:
                os.rmdir(os.path.join(dirpath, name))
    if os.path.exists(testdir):
        os.rmdir(testdir)
    assert not os.path.exists(testdir)
","
1# -*- coding: utf-8 -*-
2#
3# Copyright 2007 Zuza Software Foundation
4#
5# This file is part of translate.
6#
7# translate is free software; you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation; either version 2 of the License, or
10# (at your option) any later version.
11#
12# translate is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with this program; if not, see <http://www.gnu.org/licenses/>.
19
20import os
21import os.path as path
22import sys
23from subprocess import call
24
25from lxml import etree
26
27
28schema = None
29
30
31def xmllint(fullpath):
32    return schema.validate(etree.parse(fullpath))
33
34
35def setup_module(module):
36    global schema
37    os.chdir(path.dirname(__file__))
38    schema = etree.XMLSchema(etree.parse('xliff-core-1.1.xsd'))
39
40
41def find_files(base, check_ext):
42    for dirpath, _dirnames, filenames in os.walk(base):
43        for filename in filenames:
44            fullpath = path.join(dirpath, filename)
45            _namepath, ext = path.splitext(fullpath)
46            if check_ext == ext:
47                yield fullpath
48
49
50def test_open_office_to_xliff():
51    for filepath in find_files('fr', '.xlf'):
52    cleardir('fr')
53
54
55def test_po_to_xliff():
56    OUTPUT = 'af-pootle.xlf'
57
58
59def teardown_module(module):
60    pass
61
62
63def cleardir(testdir):
64    """"""removes the test directory""""""
65    if os.path.exists(testdir):
66        for dirpath, subdirs, filenames in os.walk(testdir, topdown=False):
67            for name in filenames:
68                os.remove(os.path.join(dirpath, name))
69            for name in subdirs:
70                os.rmdir(os.path.join(dirpath, name))
71    if os.path.exists(testdir):
72        os.rmdir(testdir)
73","[[""call(['oo2xliff'"", '==', 'True'], ['xmllint(filepath)', '==', 'True'], [""call(['po2xliff'"", '==', 'True'], ['xmllint(OUTPUT)', '==', 'True'], ['os.path.exists(testdir)', '==', 'False']]",5,5,1.0,0.002286236854138,"['schema', 'fullpath', 'module', 'base', 'check_ext', '_namepath', 'ext', 'OUTPUT', 'testdir']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['schema', 'fullpath', 'module', 'base', 'check_ext', '_namepath', 'ext', 'OUTPUT', 'testdir']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright 2007 Zuza Software Foundation
4#
5# This file is part of translate.
6#
7# translate is free software; you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation; either version 2 of the License, or
10# (at your option) any later version.
11#
12# translate is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with this program; if not, see <http://www.gnu.org/licenses/>.
19
20import os
21import os.path as path
22import sys
23from subprocess import call
24
25from lxml import etree
26
27
28schema = None
29
30
31def xmllint(fullpath):
32    return schema.validate(etree.parse(fullpath))
33
34
35def setup_module(module):
36    global schema
37    os.chdir(path.dirname(__file__))
38    schema = etree.XMLSchema(etree.parse('xliff-core-1.1.xsd'))
39
40
41def find_files(base, check_ext):
42    for dirpath, _dirnames, filenames in os.walk(base):
43        for filename in filenames:
44            fullpath = path.join(dirpath, filename)
45            _namepath, ext = path.splitext(fullpath)
46            if check_ext == ext:
47                yield fullpath
48
49
50def test_open_office_to_xliff():
51    for filepath in find_files('fr', '.xlf'):
52    cleardir('fr')
53
54
55def test_po_to_xliff():
56    OUTPUT = 'af-pootle.xlf'
57
58
59def teardown_module(module):
60    pass
61
62
63def cleardir(testdir):
64    """"""removes the test directory""""""
65    if os.path.exists(testdir):
66        for dirpath, subdirs, filenames in os.walk(testdir, topdown=False):
67            for name in filenames:
68                os.remove(os.path.join(dirpath, name))
69            for name in subdirs:
70                os.rmdir(os.path.join(dirpath, name))
71    if os.path.exists(testdir):
72        os.rmdir(testdir)
73",3575,"[[31, 'fullpath', '!=', None, ""Function 'xmllint' requires a valid file path""],
 [35, 'module', '!=', None, ""Function 'setup_module' requires a valid module""],
 [41, 'base', '!=', None, ""Function 'find_files' requires a valid base directory""],
 [41, 'check_ext', '!=', None, ""Function 'find_files' requires a valid extension to check""],
 [50, 'OUTPUT', '!=', None, ""The OUTPUT filename must be defined for 'test_po_to_xliff' function to work""],
 [63, 'testdir', '!=', None, ""Function 'cleardir' requires a valid test directory to clear""]]"
wagoodman/bridgy,"import os
import mock
import pytest
import shlex

import bridgy.inventory
from bridgy.inventory import InventorySet, Instance, inventory, instances
from bridgy.inventory.aws import AwsInventory
from bridgy.config import Config


def test_set_inventory_bastion(mocker):
    test_dir = os.path.dirname(os.path.abspath(__file__))
    cache_dir = os.path.join(test_dir, 'aws_stubs')

    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
                           secret_access_key='secret_access_key', session_token='session_token',
                           region='region', bastion={'address': 'someaddr', 'user': 'someuser', 'options': 'someoptions'})


    assert aws_obj.bastion.destination == 'someuser@someaddr'
    assert aws_obj.bastion.options == 'someoptions'

def test_inclusion_filtering(mocker):
    test_dir = os.path.dirname(os.path.abspath(__file__))
    cache_dir = os.path.join(test_dir, 'aws_stubs')

    config = Config({
        'inventory': {
            'include_pattern': 'test.*'
        }
    })

    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
                           secret_access_key='secret_access_key', session_token='session_token',
                           region='region')
    inventorySet = InventorySet()
    inventorySet.add(aws_obj)

    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
    mock_inventory.return_value = inventorySet

    all_instances = instances(config)

    expected_instances = [Instance(name='test-forms', address='devbox', aliases=('devbox', 'ip-172-31-8-185.us-west-2.compute.internal', 'i-e54cbaeb'), source='aws', container_id=None, type='VM'),
                          Instance(name='test-account-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-139.us-west-2.compute.internal', 'i-f4d726fa'), source='aws', container_id=None, type='VM'),
                          Instance(name='test-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-141.us-west-2.compute.internal', 'i-f3d726fd'), source='aws', container_id=None, type='VM'),
                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-38.us-west-2.compute.internal', 'i-0f500447384e95942'), source='aws', container_id=None, type='VM'),
                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-39.us-west-2.compute.internal', 'i-0f500447384e95943'), source='aws', container_id=None, type='VM')]

    assert set(all_instances) == set(expected_instances)

def test_exclusion_filtering(mocker):
    test_dir = os.path.dirname(os.path.abspath(__file__))
    cache_dir = os.path.join(test_dir, 'aws_stubs')

    config = Config({
        'inventory': {
            'exclude_pattern': 'test.*'
        }
    })

    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
                           secret_access_key='secret_access_key', session_token='session_token',
                           region='region')
    inventorySet = InventorySet()
    inventorySet.add(aws_obj)

    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
    mock_inventory.return_value = inventorySet

    all_instances = instances(config)

    expected_instances = [Instance(name='devlab-forms', address='devbox', aliases=('devbox', 'ip-172-31-0-138.us-west-2.compute.internal', 'i-f7d726f9'), source='aws', container_id=None, type='VM'),
                          Instance(name='devlab-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-0-142.us-west-2.compute.internal', 'i-f5d726fb'), source='aws', container_id=None, type='VM'),
                          Instance(name='devlab-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-140.us-west-2.compute.internal', 'i-f2d726fc'), source='aws', container_id=None, type='VM')]

    assert set(all_instances) == set(expected_instances)","
1import os
2import mock
3import pytest
4import shlex
5
6import bridgy.inventory
7from bridgy.inventory import InventorySet, Instance, inventory, instances
8from bridgy.inventory.aws import AwsInventory
9from bridgy.config import Config
10
11
12def test_set_inventory_bastion(mocker):
13    test_dir = os.path.dirname(os.path.abspath(__file__))
14    cache_dir = os.path.join(test_dir, 'aws_stubs')
15
16    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
17                           secret_access_key='secret_access_key', session_token='session_token',
18                           region='region', bastion={'address': 'someaddr', 'user': 'someuser', 'options': 'someoptions'})
19
20
21
22def test_inclusion_filtering(mocker):
23    test_dir = os.path.dirname(os.path.abspath(__file__))
24    cache_dir = os.path.join(test_dir, 'aws_stubs')
25
26    config = Config({
27        'inventory': {
28            'include_pattern': 'test.*'
29        }
30    })
31
32    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
33                           secret_access_key='secret_access_key', session_token='session_token',
34                           region='region')
35    inventorySet = InventorySet()
36    inventorySet.add(aws_obj)
37
38    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
39    mock_inventory.return_value = inventorySet
40
41    all_instances = instances(config)
42
43    expected_instances = [Instance(name='test-forms', address='devbox', aliases=('devbox', 'ip-172-31-8-185.us-west-2.compute.internal', 'i-e54cbaeb'), source='aws', container_id=None, type='VM'),
44                          Instance(name='test-account-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-139.us-west-2.compute.internal', 'i-f4d726fa'), source='aws', container_id=None, type='VM'),
45                          Instance(name='test-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-141.us-west-2.compute.internal', 'i-f3d726fd'), source='aws', container_id=None, type='VM'),
46                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-38.us-west-2.compute.internal', 'i-0f500447384e95942'), source='aws', container_id=None, type='VM'),
47                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-39.us-west-2.compute.internal', 'i-0f500447384e95943'), source='aws', container_id=None, type='VM')]
48
49
50def test_exclusion_filtering(mocker):
51    test_dir = os.path.dirname(os.path.abspath(__file__))
52    cache_dir = os.path.join(test_dir, 'aws_stubs')
53
54    config = Config({
55        'inventory': {
56            'exclude_pattern': 'test.*'
57        }
58    })
59
60    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
61                           secret_access_key='secret_access_key', session_token='session_token',
62                           region='region')
63    inventorySet = InventorySet()
64    inventorySet.add(aws_obj)
65
66    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
67    mock_inventory.return_value = inventorySet
68
69    all_instances = instances(config)
70
71    expected_instances = [Instance(name='devlab-forms', address='devbox', aliases=('devbox', 'ip-172-31-0-138.us-west-2.compute.internal', 'i-f7d726f9'), source='aws', container_id=None, type='VM'),
72                          Instance(name='devlab-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-0-142.us-west-2.compute.internal', 'i-f5d726fb'), source='aws', container_id=None, type='VM'),
73                          Instance(name='devlab-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-140.us-west-2.compute.internal', 'i-f2d726fc'), source='aws', container_id=None, type='VM')]
74","[['aws_obj.bastion.destination', '==', ""'someuser@someaddr'""], ['aws_obj.bastion.options', '==', ""'someoptions'""], ['set(all_instances)', '==', 'set(expected_instances)'], ['set(all_instances)', '==', 'set(expected_instances)']]",4,4,1.0,0.0010211896859841,"['mocker', 'test_dir', 'cache_dir', 'aws_obj', 'config', 'inventorySet', 'mock_inventory', 'mock_inventory.return_value', 'all_instances', 'expected_instances']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mocker', 'test_dir', 'cache_dir', 'aws_obj', 'config', 'inventorySet', 'mock_inventory', 'mock_inventory.return_value', 'all_instances', 'expected_instances']
*Code:

1import os
2import mock
3import pytest
4import shlex
5
6import bridgy.inventory
7from bridgy.inventory import InventorySet, Instance, inventory, instances
8from bridgy.inventory.aws import AwsInventory
9from bridgy.config import Config
10
11
12def test_set_inventory_bastion(mocker):
13    test_dir = os.path.dirname(os.path.abspath(__file__))
14    cache_dir = os.path.join(test_dir, 'aws_stubs')
15
16    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
17                           secret_access_key='secret_access_key', session_token='session_token',
18                           region='region', bastion={'address': 'someaddr', 'user': 'someuser', 'options': 'someoptions'})
19
20
21
22def test_inclusion_filtering(mocker):
23    test_dir = os.path.dirname(os.path.abspath(__file__))
24    cache_dir = os.path.join(test_dir, 'aws_stubs')
25
26    config = Config({
27        'inventory': {
28            'include_pattern': 'test.*'
29        }
30    })
31
32    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
33                           secret_access_key='secret_access_key', session_token='session_token',
34                           region='region')
35    inventorySet = InventorySet()
36    inventorySet.add(aws_obj)
37
38    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
39    mock_inventory.return_value = inventorySet
40
41    all_instances = instances(config)
42
43    expected_instances = [Instance(name='test-forms', address='devbox', aliases=('devbox', 'ip-172-31-8-185.us-west-2.compute.internal', 'i-e54cbaeb'), source='aws', container_id=None, type='VM'),
44                          Instance(name='test-account-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-139.us-west-2.compute.internal', 'i-f4d726fa'), source='aws', container_id=None, type='VM'),
45                          Instance(name='test-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-141.us-west-2.compute.internal', 'i-f3d726fd'), source='aws', container_id=None, type='VM'),
46                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-38.us-west-2.compute.internal', 'i-0f500447384e95942'), source='aws', container_id=None, type='VM'),
47                          Instance(name='test-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-2-39.us-west-2.compute.internal', 'i-0f500447384e95943'), source='aws', container_id=None, type='VM')]
48
49
50def test_exclusion_filtering(mocker):
51    test_dir = os.path.dirname(os.path.abspath(__file__))
52    cache_dir = os.path.join(test_dir, 'aws_stubs')
53
54    config = Config({
55        'inventory': {
56            'exclude_pattern': 'test.*'
57        }
58    })
59
60    aws_obj = AwsInventory(cache_dir=cache_dir, access_key_id='access_key_id',
61                           secret_access_key='secret_access_key', session_token='session_token',
62                           region='region')
63    inventorySet = InventorySet()
64    inventorySet.add(aws_obj)
65
66    mock_inventory = mocker.patch.object(bridgy.inventory, 'inventory')
67    mock_inventory.return_value = inventorySet
68
69    all_instances = instances(config)
70
71    expected_instances = [Instance(name='devlab-forms', address='devbox', aliases=('devbox', 'ip-172-31-0-138.us-west-2.compute.internal', 'i-f7d726f9'), source='aws', container_id=None, type='VM'),
72                          Instance(name='devlab-pubsrv', address='devbox', aliases=('devbox', 'ip-172-31-0-142.us-west-2.compute.internal', 'i-f5d726fb'), source='aws', container_id=None, type='VM'),
73                          Instance(name='devlab-game-svc', address='devbox', aliases=('devbox', 'ip-172-31-0-140.us-west-2.compute.internal', 'i-f2d726fc'), source='aws', container_id=None, type='VM')]
74",5369,"[[13, ""test_dir"", ""!="", """", ""Test directory should not be empty""],
 [14, ""cache_dir"", ""!="", """", ""Cache directory should not be empty""],
 [17, ""aws_obj"", ""!="", """", ""AWS object initialization must not result to None""],
 [26, ""config"", ""!= "", """", ""Config dictionary must not be None""],
 [35, ""inventorySet"", ""!="", """", ""Inventory Set should not be None after instantiation""],
 [41, ""all_instances"", ""!= "", """", ""Instances captured must not be None""],
 [43, ""expected_instances"", ""=="", ""all_instances"", ""All instances obtained should match the expected instances""],
 [52, ""cache_dir"", ""!="", """", ""Cache directory should not be empty""],
 [62, ""aws_obj"", ""!="", """", ""AWS object initialization must not result to None""],
 [63, ""inventorySet"", ""!="", """", ""Inventory Set should not be None after instantiation""],
 [69, ""all_instances"", ""!= "", """", ""Instances captured must not be None""],
 [71, ""expected_instances"", ""=="", ""all_instances"", ""All instances obtained should match the expected instances""]]"
AICP/external_chromium_org,"# Copyright 2013 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
import json

from telemetry import value as value_module
from telemetry import perf_tests_helper

class HistogramValueBucket(object):
  def __init__(self, low, high, count=0):
    self.low = low
    self.high = high
    self.count = count

  def ToJSONString(self):
    return '{%s}' % ', '.join([
      '""low"": %i' % self.low,
      '""high"": %i' % self.high,
      '""count"": %i' % self.count])

class HistogramValue(value_module.Value):
  def __init__(self, page, name, units,
               raw_value=None, raw_value_json=None, important=True):
    super(HistogramValue, self).__init__(page, name, units, important)
    if raw_value_json:
      assert raw_value == None, 'Dont specify both raw_value and raw_value_json'
      raw_value = json.loads(raw_value_json)
    if raw_value:
      assert 'buckets' in raw_value
      assert isinstance(raw_value['buckets'], list)
      self.buckets = []
      for bucket in raw_value['buckets']:
        self.buckets.append(HistogramValueBucket(
          low=bucket['low'],
          high=bucket['high'],
          count=bucket['count']))
    else:
      self.buckets = []

  def __repr__(self):
    if self.page:
      page_name = self.page.url
    else:
      page_name = None
    return 'HistogramValue(%s, %s, %s, raw_json_string=""%s"", important=%s)' % (
      page_name,
      self.name, self.units,
      self.ToJSONString(),
      self.important)

  def GetBuildbotDataType(self, output_context):
    if self._IsImportantGivenOutputIntent(output_context):
      return 'histogram'
    return 'unimportant-histogram'

  def GetBuildbotValue(self):
    # More buildbot insanity: perf_tests_results_helper requires the histogram
    # to be an array of size one.
    return [self.ToJSONString()]

  def ToJSONString(self):
    # This has to hand-JSONify the histogram to ensure the order of keys
    # produced is stable across different systems.
    #
    # This is done because the buildbot unittests are string equality
    # assertions. Thus, tests that contain histograms require stable
    # stringification of the histogram.
    #
    # Sigh, buildbot, Y U gotta be that way.
    return '{""buckets"": [%s]}' % (
      ', '.join([b.ToJSONString() for b in self.buckets]))

  def GetRepresentativeNumber(self):
    (mean, _) = perf_tests_helper.GeomMeanAndStdDevFromHistogram(
        self.ToJSONString())
    return mean

  def GetRepresentativeString(self):
    return self.GetBuildbotValue()

  @classmethod
  def MergeLikeValuesFromSamePage(cls, values):
    assert len(values) > 0
    v0 = values[0]
    return HistogramValue(
        v0.page, v0.name, v0.units,
        raw_value_json=v0.ToJSONString(),
        important=v0.important)

  @classmethod
  def MergeLikeValuesFromDifferentPages(cls, values,
                                        group_by_name_suffix=False):
    # Histograms cannot be merged across pages, at least for now. It should be
    # theoretically possible, just requires more work. Instead, return None.
    # This signals to the merging code that the data is unmergable and it will
    # cope accordingly.
    return None
","
1# Copyright 2013 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4import json
5
6from telemetry import value as value_module
7from telemetry import perf_tests_helper
8
9class HistogramValueBucket(object):
10  def __init__(self, low, high, count=0):
11    self.low = low
12    self.high = high
13    self.count = count
14
15  def ToJSONString(self):
16    return '{%s}' % ', '.join([
17      '""low"": %i' % self.low,
18      '""high"": %i' % self.high,
19      '""count"": %i' % self.count])
20
21class HistogramValue(value_module.Value):
22  def __init__(self, page, name, units,
23               raw_value=None, raw_value_json=None, important=True):
24    super(HistogramValue, self).__init__(page, name, units, important)
25    if raw_value_json:
26      raw_value = json.loads(raw_value_json)
27    if raw_value:
28      self.buckets = []
29      for bucket in raw_value['buckets']:
30        self.buckets.append(HistogramValueBucket(
31          low=bucket['low'],
32          high=bucket['high'],
33          count=bucket['count']))
34    else:
35      self.buckets = []
36
37  def __repr__(self):
38    if self.page:
39      page_name = self.page.url
40    else:
41      page_name = None
42    return 'HistogramValue(%s, %s, %s, raw_json_string=""%s"", important=%s)' % (
43      page_name,
44      self.name, self.units,
45      self.ToJSONString(),
46      self.important)
47
48  def GetBuildbotDataType(self, output_context):
49    if self._IsImportantGivenOutputIntent(output_context):
50      return 'histogram'
51    return 'unimportant-histogram'
52
53  def GetBuildbotValue(self):
54    # More buildbot insanity: perf_tests_results_helper requires the histogram
55    # to be an array of size one.
56    return [self.ToJSONString()]
57
58  def ToJSONString(self):
59    # This has to hand-JSONify the histogram to ensure the order of keys
60    # produced is stable across different systems.
61    #
62    # This is done because the buildbot unittests are string equality
63    # stringification of the histogram.
64    #
65    # Sigh, buildbot, Y U gotta be that way.
66    return '{""buckets"": [%s]}' % (
67      ', '.join([b.ToJSONString() for b in self.buckets]))
68
69  def GetRepresentativeNumber(self):
70    (mean, _) = perf_tests_helper.GeomMeanAndStdDevFromHistogram(
71        self.ToJSONString())
72    return mean
73
74  def GetRepresentativeString(self):
75    return self.GetBuildbotValue()
76
77  @classmethod
78  def MergeLikeValuesFromSamePage(cls, values):
79    v0 = values[0]
80    return HistogramValue(
81        v0.page, v0.name, v0.units,
82        raw_value_json=v0.ToJSONString(),
83        important=v0.important)
84
85  @classmethod
86  def MergeLikeValuesFromDifferentPages(cls, values,
87                                        group_by_name_suffix=False):
88    # Histograms cannot be merged across pages, at least for now. It should be
89    # theoretically possible, just requires more work. Instead, return None.
90    # This signals to the merging code that the data is unmergable and it will
91    # cope accordingly.
92    return None
93","[['raw_value', '==', 'None'], [""raw_value_json'"", '==', 'True'], ['len(values)', '>', '0']]",5,3,0.6,0.0009177118384827,"['low', 'high', 'count', 'self.low', 'self.high', 'self.count', 'page', 'name', 'units', 'raw_value', 'self.buckets', 'page_name', 'output_context', '(mean', '_)', 'cls', 'values', 'v0']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['low', 'high', 'count', 'self.low', 'self.high', 'self.count', 'page', 'name', 'units', 'raw_value', 'self.buckets', 'page_name', 'output_context', '(mean', '_)', 'cls', 'values', 'v0']
*Code:

1# Copyright 2013 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4import json
5
6from telemetry import value as value_module
7from telemetry import perf_tests_helper
8
9class HistogramValueBucket(object):
10  def __init__(self, low, high, count=0):
11    self.low = low
12    self.high = high
13    self.count = count
14
15  def ToJSONString(self):
16    return '{%s}' % ', '.join([
17      '""low"": %i' % self.low,
18      '""high"": %i' % self.high,
19      '""count"": %i' % self.count])
20
21class HistogramValue(value_module.Value):
22  def __init__(self, page, name, units,
23               raw_value=None, raw_value_json=None, important=True):
24    super(HistogramValue, self).__init__(page, name, units, important)
25    if raw_value_json:
26      raw_value = json.loads(raw_value_json)
27    if raw_value:
28      self.buckets = []
29      for bucket in raw_value['buckets']:
30        self.buckets.append(HistogramValueBucket(
31          low=bucket['low'],
32          high=bucket['high'],
33          count=bucket['count']))
34    else:
35      self.buckets = []
36
37  def __repr__(self):
38    if self.page:
39      page_name = self.page.url
40    else:
41      page_name = None
42    return 'HistogramValue(%s, %s, %s, raw_json_string=""%s"", important=%s)' % (
43      page_name,
44      self.name, self.units,
45      self.ToJSONString(),
46      self.important)
47
48  def GetBuildbotDataType(self, output_context):
49    if self._IsImportantGivenOutputIntent(output_context):
50      return 'histogram'
51    return 'unimportant-histogram'
52
53  def GetBuildbotValue(self):
54    # More buildbot insanity: perf_tests_results_helper requires the histogram
55    # to be an array of size one.
56    return [self.ToJSONString()]
57
58  def ToJSONString(self):
59    # This has to hand-JSONify the histogram to ensure the order of keys
60    # produced is stable across different systems.
61    #
62    # This is done because the buildbot unittests are string equality
63    # stringification of the histogram.
64    #
65    # Sigh, buildbot, Y U gotta be that way.
66    return '{""buckets"": [%s]}' % (
67      ', '.join([b.ToJSONString() for b in self.buckets]))
68
69  def GetRepresentativeNumber(self):
70    (mean, _) = perf_tests_helper.GeomMeanAndStdDevFromHistogram(
71        self.ToJSONString())
72    return mean
73
74  def GetRepresentativeString(self):
75    return self.GetBuildbotValue()
76
77  @classmethod
78  def MergeLikeValuesFromSamePage(cls, values):
79    v0 = values[0]
80    return HistogramValue(
81        v0.page, v0.name, v0.units,
82        raw_value_json=v0.ToJSONString(),
83        important=v0.important)
84
85  @classmethod
86  def MergeLikeValuesFromDifferentPages(cls, values,
87                                        group_by_name_suffix=False):
88    # Histograms cannot be merged across pages, at least for now. It should be
89    # theoretically possible, just requires more work. Instead, return None.
90    # This signals to the merging code that the data is unmergable and it will
91    # cope accordingly.
92    return None
93",4748,"[[10, 'low', '!=', None, ""low limit of the bucket should not be None""],
 [10, 'high', '!=', None, ""high limit of the bucket should not be None""],
 [10, 'count', '>=', 0, ""count should be equal to or greater than 0""],
 [11, 'self.low', '==', 'low', ""self.low should be equal to the input low value""],
 [12, 'self.high', '==', 'high', ""self.high should be equal to the input high value""],
 [13, 'self.count', '==', 'count', ""self.count should be equal to the input count value""],
 [22, 'page', '!=', None, ""page should not be None""],
 [22, 'name', '!=', None, ""name should not be None""],
 [22, 'units', '!=', None, ""units should not be None""],
 [25, 'raw_value', '==', 'json.loads(raw_value_json)', ""should load the json if provided""],
 [54, 'self.ToJSONString()', '==', '[self.ToJSONString()]', ""It should be wrapped inside a list""]]
"
eeshangarg/zulip,"from argparse import ArgumentParser
from typing import Any, List

from zerver.lib.actions import (
    bulk_add_subscriptions,
    bulk_remove_subscriptions,
    do_deactivate_stream,
)
from zerver.lib.cache import cache_delete_many, to_dict_cache_key_id
from zerver.lib.management import ZulipBaseCommand
from zerver.models import Message, Subscription, get_stream


def bulk_delete_cache_keys(message_ids_to_clear: List[int]) -> None:
    while len(message_ids_to_clear) > 0:
        batch = message_ids_to_clear[0:5000]

        keys_to_delete = [to_dict_cache_key_id(message_id) for message_id in batch]
        cache_delete_many(keys_to_delete)

        message_ids_to_clear = message_ids_to_clear[5000:]


class Command(ZulipBaseCommand):
    help = """"""Merge two streams.""""""

    def add_arguments(self, parser: ArgumentParser) -> None:
        parser.add_argument(""stream_to_keep"", help=""name of stream to keep"")
        parser.add_argument(
            ""stream_to_destroy"", help=""name of stream to merge into the stream being kept""
        )
        self.add_realm_args(parser, required=True)

    def handle(self, *args: Any, **options: str) -> None:
        realm = self.get_realm(options)
        assert realm is not None  # Should be ensured by parser
        stream_to_keep = get_stream(options[""stream_to_keep""], realm)
        stream_to_destroy = get_stream(options[""stream_to_destroy""], realm)

        recipient_to_destroy = stream_to_destroy.recipient
        recipient_to_keep = stream_to_keep.recipient

        # The high-level approach here is to move all the messages to
        # the surviving stream, deactivate all the subscriptions on
        # the stream to be removed and deactivate the stream, and add
        # new subscriptions to the stream to keep for any users who
        # were only on the now-deactivated stream.

        # Move the messages, and delete the old copies from caches.
        message_ids_to_clear = list(
            Message.objects.filter(recipient=recipient_to_destroy).values_list(""id"", flat=True)
        )
        count = Message.objects.filter(recipient=recipient_to_destroy).update(
            recipient=recipient_to_keep
        )
        print(f""Moved {count} messages"")
        bulk_delete_cache_keys(message_ids_to_clear)

        # Move the Subscription objects.  This algorithm doesn't
        # preserve any stream settings/colors/etc. from the stream
        # being destroyed, but it's convenient.
        existing_subs = Subscription.objects.filter(recipient=recipient_to_keep)
        users_already_subscribed = {sub.user_profile_id: sub.active for sub in existing_subs}

        subs_to_deactivate = Subscription.objects.filter(
            recipient=recipient_to_destroy, active=True
        )
        users_to_activate = [
            sub.user_profile
            for sub in subs_to_deactivate
            if not users_already_subscribed.get(sub.user_profile_id, False)
        ]

        if len(subs_to_deactivate) > 0:
            print(f""Deactivating {len(subs_to_deactivate)} subscriptions"")
            bulk_remove_subscriptions(
                realm,
                [sub.user_profile for sub in subs_to_deactivate],
                [stream_to_destroy],
                acting_user=None,
            )
        do_deactivate_stream(stream_to_destroy, acting_user=None)
        if len(users_to_activate) > 0:
            print(f""Adding {len(users_to_activate)} subscriptions"")
            bulk_add_subscriptions(realm, [stream_to_keep], users_to_activate, acting_user=None)
","
1from argparse import ArgumentParser
2from typing import Any, List
3
4from zerver.lib.actions import (
5    bulk_add_subscriptions,
6    bulk_remove_subscriptions,
7    do_deactivate_stream,
8)
9from zerver.lib.cache import cache_delete_many, to_dict_cache_key_id
10from zerver.lib.management import ZulipBaseCommand
11from zerver.models import Message, Subscription, get_stream
12
13
14def bulk_delete_cache_keys(message_ids_to_clear: List[int]) -> None:
15    while len(message_ids_to_clear) > 0:
16        batch = message_ids_to_clear[0:5000]
17
18        keys_to_delete = [to_dict_cache_key_id(message_id) for message_id in batch]
19        cache_delete_many(keys_to_delete)
20
21        message_ids_to_clear = message_ids_to_clear[5000:]
22
23
24class Command(ZulipBaseCommand):
25    help = """"""Merge two streams.""""""
26
27    def add_arguments(self, parser: ArgumentParser) -> None:
28        parser.add_argument(""stream_to_keep"", help=""name of stream to keep"")
29        parser.add_argument(
30            ""stream_to_destroy"", help=""name of stream to merge into the stream being kept""
31        )
32        self.add_realm_args(parser, required=True)
33
34    def handle(self, *args: Any, **options: str) -> None:
35        realm = self.get_realm(options)
36        stream_to_keep = get_stream(options[""stream_to_keep""], realm)
37        stream_to_destroy = get_stream(options[""stream_to_destroy""], realm)
38
39        recipient_to_destroy = stream_to_destroy.recipient
40        recipient_to_keep = stream_to_keep.recipient
41
42        # The high-level approach here is to move all the messages to
43        # the surviving stream, deactivate all the subscriptions on
44        # the stream to be removed and deactivate the stream, and add
45        # new subscriptions to the stream to keep for any users who
46        # were only on the now-deactivated stream.
47
48        # Move the messages, and delete the old copies from caches.
49        message_ids_to_clear = list(
50            Message.objects.filter(recipient=recipient_to_destroy).values_list(""id"", flat=True)
51        )
52        count = Message.objects.filter(recipient=recipient_to_destroy).update(
53            recipient=recipient_to_keep
54        )
55        print(f""Moved {count} messages"")
56        bulk_delete_cache_keys(message_ids_to_clear)
57
58        # Move the Subscription objects.  This algorithm doesn't
59        # preserve any stream settings/colors/etc. from the stream
60        # being destroyed, but it's convenient.
61        existing_subs = Subscription.objects.filter(recipient=recipient_to_keep)
62        users_already_subscribed = {sub.user_profile_id: sub.active for sub in existing_subs}
63
64        subs_to_deactivate = Subscription.objects.filter(
65            recipient=recipient_to_destroy, active=True
66        )
67        users_to_activate = [
68            sub.user_profile
69            for sub in subs_to_deactivate
70            if not users_already_subscribed.get(sub.user_profile_id, False)
71        ]
72
73        if len(subs_to_deactivate) > 0:
74            print(f""Deactivating {len(subs_to_deactivate)} subscriptions"")
75            bulk_remove_subscriptions(
76                realm,
77                [sub.user_profile for sub in subs_to_deactivate],
78                [stream_to_destroy],
79                acting_user=None,
80            )
81        do_deactivate_stream(stream_to_destroy, acting_user=None)
82        if len(users_to_activate) > 0:
83            print(f""Adding {len(users_to_activate)} subscriptions"")
84            bulk_add_subscriptions(realm, [stream_to_keep], users_to_activate, acting_user=None)
85","[['realm', '==', 'not None']]",1,1,1.0,0.0002814522938361,"['message_ids_to_clear: List[int]', 'batch', 'keys_to_delete', 'message_ids_to_clear', 'help', 'parser: ArgumentParser', '*args: Any', '**options: str', 'realm', 'stream_to_keep', 'stream_to_destroy', 'recipient_to_destroy', 'recipient_to_keep', 'count', 'existing_subs', 'users_already_subscribed', 'subs_to_deactivate', 'users_to_activate']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['message_ids_to_clear: List[int]', 'batch', 'keys_to_delete', 'message_ids_to_clear', 'help', 'parser: ArgumentParser', '*args: Any', '**options: str', 'realm', 'stream_to_keep', 'stream_to_destroy', 'recipient_to_destroy', 'recipient_to_keep', 'count', 'existing_subs', 'users_already_subscribed', 'subs_to_deactivate', 'users_to_activate']
*Code:

1from argparse import ArgumentParser
2from typing import Any, List
3
4from zerver.lib.actions import (
5    bulk_add_subscriptions,
6    bulk_remove_subscriptions,
7    do_deactivate_stream,
8)
9from zerver.lib.cache import cache_delete_many, to_dict_cache_key_id
10from zerver.lib.management import ZulipBaseCommand
11from zerver.models import Message, Subscription, get_stream
12
13
14def bulk_delete_cache_keys(message_ids_to_clear: List[int]) -> None:
15    while len(message_ids_to_clear) > 0:
16        batch = message_ids_to_clear[0:5000]
17
18        keys_to_delete = [to_dict_cache_key_id(message_id) for message_id in batch]
19        cache_delete_many(keys_to_delete)
20
21        message_ids_to_clear = message_ids_to_clear[5000:]
22
23
24class Command(ZulipBaseCommand):
25    help = """"""Merge two streams.""""""
26
27    def add_arguments(self, parser: ArgumentParser) -> None:
28        parser.add_argument(""stream_to_keep"", help=""name of stream to keep"")
29        parser.add_argument(
30            ""stream_to_destroy"", help=""name of stream to merge into the stream being kept""
31        )
32        self.add_realm_args(parser, required=True)
33
34    def handle(self, *args: Any, **options: str) -> None:
35        realm = self.get_realm(options)
36        stream_to_keep = get_stream(options[""stream_to_keep""], realm)
37        stream_to_destroy = get_stream(options[""stream_to_destroy""], realm)
38
39        recipient_to_destroy = stream_to_destroy.recipient
40        recipient_to_keep = stream_to_keep.recipient
41
42        # The high-level approach here is to move all the messages to
43        # the surviving stream, deactivate all the subscriptions on
44        # the stream to be removed and deactivate the stream, and add
45        # new subscriptions to the stream to keep for any users who
46        # were only on the now-deactivated stream.
47
48        # Move the messages, and delete the old copies from caches.
49        message_ids_to_clear = list(
50            Message.objects.filter(recipient=recipient_to_destroy).values_list(""id"", flat=True)
51        )
52        count = Message.objects.filter(recipient=recipient_to_destroy).update(
53            recipient=recipient_to_keep
54        )
55        print(f""Moved {count} messages"")
56        bulk_delete_cache_keys(message_ids_to_clear)
57
58        # Move the Subscription objects.  This algorithm doesn't
59        # preserve any stream settings/colors/etc. from the stream
60        # being destroyed, but it's convenient.
61        existing_subs = Subscription.objects.filter(recipient=recipient_to_keep)
62        users_already_subscribed = {sub.user_profile_id: sub.active for sub in existing_subs}
63
64        subs_to_deactivate = Subscription.objects.filter(
65            recipient=recipient_to_destroy, active=True
66        )
67        users_to_activate = [
68            sub.user_profile
69            for sub in subs_to_deactivate
70            if not users_already_subscribed.get(sub.user_profile_id, False)
71        ]
72
73        if len(subs_to_deactivate) > 0:
74            print(f""Deactivating {len(subs_to_deactivate)} subscriptions"")
75            bulk_remove_subscriptions(
76                realm,
77                [sub.user_profile for sub in subs_to_deactivate],
78                [stream_to_destroy],
79                acting_user=None,
80            )
81        do_deactivate_stream(stream_to_destroy, acting_user=None)
82        if len(users_to_activate) > 0:
83            print(f""Adding {len(users_to_activate)} subscriptions"")
84            bulk_add_subscriptions(realm, [stream_to_keep], users_to_activate, acting_user=None)
85",5373,"[[14, 'message_ids_to_clear', '!=', None, 'list of id to be cleared should not be null'],
 [25, 'stream_to_keep', '!=', '', 'stream to keep should not be empty'],
 [30, 'stream_to_destroy', '!=', '', 'stream to destroy should not be empty'],
 [35, 'realm', '!=', None, 'realm should be defined'],
 [36, 'stream_to_keep', '!=', None, 'stream to keep should not be None'],
 [37, 'stream_to_destroy', '!=', None, 'stream to destroy should not be None'],
 [39, 'recipient_to_destroy', '!=', None, 'recipient to destroy should not be None'],
 [40, 'recipient_to_keep', '!=', None, 'recipient to keep should not be None'],
 [55, 'count', '>=', 0, 'moved messages count should be non-negative'],
 [62, 'users_already_subscribed', '!=', None, 'users already subscribed should not be None'],
 [64, 'subs_to_deactivate', '!=', None, 'subscriptions to deactivate should not be None'],
 [67, 'users_to_activate', '!=', None, 'users to activate should not be None']]"
sunny94/temp,"""""""Tests for sparse distributed modules. """"""

from sympy.polys.distributedmodules import (
    sdm_monomial_mul, sdm_monomial_deg, sdm_monomial_divides,
    sdm_add, sdm_LM, sdm_LT, sdm_mul_term, sdm_zero, sdm_deg,
    sdm_LC, sdm_from_dict, sdm_to_dict,
    sdm_spoly, sdm_ecart, sdm_nf_mora, sdm_groebner,
    sdm_from_vector, sdm_to_vector, sdm_monomial_lcm
)

from sympy.polys.orderings import lex, grlex, InverseOrder
from sympy.polys.domains import QQ

from sympy.abc import x, y, z


def test_sdm_monomial_mul():
    assert sdm_monomial_mul((1, 1, 0), (1, 3)) == (1, 2, 3)


def test_sdm_monomial_deg():
    assert sdm_monomial_deg((5, 2, 1)) == 3


def test_sdm_monomial_lcm():
    assert sdm_monomial_lcm((1, 2, 3), (1, 5, 0)) == (1, 5, 3)


def test_sdm_monomial_divides():
    assert sdm_monomial_divides((1, 0, 0), (1, 0, 0)) is True
    assert sdm_monomial_divides((1, 0, 0), (1, 2, 1)) is True
    assert sdm_monomial_divides((5, 1, 1), (5, 2, 1)) is True

    assert sdm_monomial_divides((1, 0, 0), (2, 0, 0)) is False
    assert sdm_monomial_divides((1, 1, 0), (1, 0, 0)) is False
    assert sdm_monomial_divides((5, 1, 2), (5, 0, 1)) is False


def test_sdm_LC():
    assert sdm_LC([((1, 2, 3), QQ(5))], QQ) == QQ(5)


def test_sdm_from_dict():
    dic = {(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1), (1, 0, 2, 1): QQ(1),
           (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)}
    assert sdm_from_dict(dic, grlex) == \
        [((1, 2, 1, 1), QQ(1)), ((1, 1, 2, 1), QQ(1)),
         ((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))]

# TODO test to_dict?


def test_sdm_add():
    assert sdm_add([((1, 1, 1), QQ(1))], [((2, 0, 0), QQ(1))], lex, QQ) == \
        [((2, 0, 0), QQ(1)), ((1, 1, 1), QQ(1))]
    assert sdm_add([((1, 1, 1), QQ(1))], [((1, 1, 1), QQ(-1))], lex, QQ) == []
    assert sdm_add([((1, 0, 0), QQ(1))], [((1, 0, 0), QQ(2))], lex, QQ) == \
        [((1, 0, 0), QQ(3))]
    assert sdm_add([((1, 0, 1), QQ(1))], [((1, 1, 0), QQ(1))], lex, QQ) == \
        [((1, 1, 0), QQ(1)), ((1, 0, 1), QQ(1))]


def test_sdm_LM():
    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(1), (4, 0, 1): QQ(1)}
    assert sdm_LM(sdm_from_dict(dic, lex)) == (4, 0, 1)


def test_sdm_LT():
    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(2), (4, 0, 1): QQ(3)}
    assert sdm_LT(sdm_from_dict(dic, lex)) == ((4, 0, 1), QQ(3))


def test_sdm_mul_term():
    assert sdm_mul_term([((1, 0, 0), QQ(1))], ((0, 0), QQ(0)), lex, QQ) == []
    assert sdm_mul_term([], ((1, 0), QQ(1)), lex, QQ) == []
    assert sdm_mul_term([((1, 0, 0), QQ(1))], ((1, 0), QQ(1)), lex, QQ) == \
        [((1, 1, 0), QQ(1))]
    f = [((2, 0, 1), QQ(4)), ((1, 1, 0), QQ(3))]
    assert sdm_mul_term(f, ((1, 1), QQ(2)), lex, QQ) == \
        [((2, 1, 2), QQ(8)), ((1, 2, 1), QQ(6))]


def test_sdm_zero():
    assert sdm_zero() == []


def test_sdm_deg():
    assert sdm_deg([((1, 2, 3), 1), ((10, 0, 1), 1), ((2, 3, 4), 4)]) == 7


def test_sdm_spoly():
    f = [((2, 1, 1), QQ(1)), ((1, 0, 1), QQ(1))]
    g = [((2, 3, 0), QQ(1))]
    h = [((1, 2, 3), QQ(1))]
    assert sdm_spoly(f, h, lex, QQ) == []
    assert sdm_spoly(f, g, lex, QQ) == [((1, 2, 1), QQ(1))]


def test_sdm_ecart():
    assert sdm_ecart([((1, 2, 3), 1), ((1, 0, 1), 1)]) == 0
    assert sdm_ecart([((2, 2, 1), 1), ((1, 5, 1), 1)]) == 3


def test_sdm_nf_mora():
    f = sdm_from_dict({(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1),
                (1, 0, 2, 1): QQ(1), (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)},
        grlex)
    f1 = sdm_from_dict({(1, 1, 1, 0): QQ(1), (1, 0, 2, 0): QQ(1),
                        (1, 0, 0, 0): QQ(-1)}, grlex)
    f2 = sdm_from_dict({(1, 1, 1, 0): QQ(1)}, grlex)
    (id0, id1, id2) = [sdm_from_dict({(i, 0, 0, 0): QQ(1)}, grlex)
                       for i in range(3)]

    assert sdm_nf_mora(f, [f1, f2], grlex, QQ, phantom=(id0, [id1, id2])) == \
        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1)),
          ((1, 1, 0, 1), QQ(1))],
         [((1, 1, 0, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])
    assert sdm_nf_mora(f, [f2, f1], grlex, QQ, phantom=(id0, [id2, id1])) == \
        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))],
         [((2, 1, 0, 1), QQ(-1)), ((2, 0, 1, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])

    f = sdm_from_vector([x*z, y**2 + y*z - z, y], lex, QQ, gens=[x, y, z])
    f1 = sdm_from_vector([x, y, 1], lex, QQ, gens=[x, y, z])
    f2 = sdm_from_vector([x*y, z, z**2], lex, QQ, gens=[x, y, z])
    assert sdm_nf_mora(f, [f1, f2], lex, QQ) == \
        sdm_nf_mora(f, [f2, f1], lex, QQ) == \
        [((1, 0, 1, 1), QQ(1)), ((1, 0, 0, 1), QQ(-1)), ((0, 1, 1, 0), QQ(-1)),
         ((0, 1, 0, 1), QQ(1))]


def test_conversion():
    f = [x**2 + y**2, 2*z]
    g = [((1, 0, 0, 1), QQ(2)), ((0, 2, 0, 0), QQ(1)), ((0, 0, 2, 0), QQ(1))]
    assert sdm_to_vector(g, [x, y, z], QQ) == f
    assert sdm_from_vector(f, lex, QQ) == g
    assert sdm_from_vector(
        [x, 1], lex, QQ) == [((1, 0), QQ(1)), ((0, 1), QQ(1))]
    assert sdm_to_vector([((1, 1, 0, 0), 1)], [x, y, z], QQ, n=3) == [0, x, 0]
    assert sdm_from_vector([0, 0], lex, QQ, gens=[x, y]) == sdm_zero()


def test_nontrivial():
    gens = [x, y, z]

    def contains(I, f):
        S = [sdm_from_vector([g], lex, QQ, gens=gens) for g in I]
        G = sdm_groebner(S, sdm_nf_mora, lex, QQ)
        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
                           G, lex, QQ) == sdm_zero()

    assert contains([x, y], x)
    assert contains([x, y], x + y)
    assert not contains([x, y], 1)
    assert not contains([x, y], z)
    assert contains([x**2 + y, x**2 + x], x - y)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x**2)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**3)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**4)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x*y**2)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**4 + y**3 + 2*z*y*x)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x*y*z)
    assert contains([x, 1 + x + y, 5 - 7*y], 1)
    assert contains(
        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
        x**3)
    assert not contains(
        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
        x**2 + y**2)

    # compare local order
    assert not contains([x*(1 + x + y), y*(1 + z)], x)
    assert not contains([x*(1 + x + y), y*(1 + z)], x + y)


def test_local():
    igrlex = InverseOrder(grlex)
    gens = [x, y, z]

    def contains(I, f):
        S = [sdm_from_vector([g], igrlex, QQ, gens=gens) for g in I]
        G = sdm_groebner(S, sdm_nf_mora, igrlex, QQ)
        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
                           G, lex, QQ) == sdm_zero()
    assert contains([x, y], x)
    assert contains([x, y], x + y)
    assert not contains([x, y], 1)
    assert not contains([x, y], z)
    assert contains([x**2 + y, x**2 + x], x - y)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x**2)
    assert contains([x*(1 + x + y), y*(1 + z)], x)
    assert contains([x*(1 + x + y), y*(1 + z)], x + y)


def test_uncovered_line():
    gens = [x, y]
    f1 = sdm_zero()
    f2 = sdm_from_vector([x, 0], lex, QQ, gens=gens)
    f3 = sdm_from_vector([0, y], lex, QQ, gens=gens)

    assert sdm_spoly(f1, f2, lex, QQ) == sdm_zero()
    assert sdm_spoly(f3, f2, lex, QQ) == sdm_zero()


def test_chain_criterion():
    gens = [x]
    f1 = sdm_from_vector([1, x], grlex, QQ, gens=gens)
    f2 = sdm_from_vector([0, x - 2], grlex, QQ, gens=gens)
    assert len(sdm_groebner([f1, f2], sdm_nf_mora, grlex, QQ)) == 2
","
1""""""Tests for sparse distributed modules. """"""
2
3from sympy.polys.distributedmodules import (
4    sdm_monomial_mul, sdm_monomial_deg, sdm_monomial_divides,
5    sdm_add, sdm_LM, sdm_LT, sdm_mul_term, sdm_zero, sdm_deg,
6    sdm_LC, sdm_from_dict, sdm_to_dict,
7    sdm_spoly, sdm_ecart, sdm_nf_mora, sdm_groebner,
8    sdm_from_vector, sdm_to_vector, sdm_monomial_lcm
9)
10
11from sympy.polys.orderings import lex, grlex, InverseOrder
12from sympy.polys.domains import QQ
13
14from sympy.abc import x, y, z
15
16
17def test_sdm_monomial_mul():
18
19
20def test_sdm_monomial_deg():
21
22
23def test_sdm_monomial_lcm():
24
25
26def test_sdm_monomial_divides():
27
28
29
30def test_sdm_LC():
31
32
33def test_sdm_from_dict():
34    dic = {(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1), (1, 0, 2, 1): QQ(1),
35           (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)}
36        [((1, 2, 1, 1), QQ(1)), ((1, 1, 2, 1), QQ(1)),
37         ((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))]
38
39# TODO test to_dict?
40
41
42def test_sdm_add():
43        [((2, 0, 0), QQ(1)), ((1, 1, 1), QQ(1))]
44        [((1, 0, 0), QQ(3))]
45        [((1, 1, 0), QQ(1)), ((1, 0, 1), QQ(1))]
46
47
48def test_sdm_LM():
49    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(1), (4, 0, 1): QQ(1)}
50
51
52def test_sdm_LT():
53    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(2), (4, 0, 1): QQ(3)}
54
55
56def test_sdm_mul_term():
57        [((1, 1, 0), QQ(1))]
58    f = [((2, 0, 1), QQ(4)), ((1, 1, 0), QQ(3))]
59        [((2, 1, 2), QQ(8)), ((1, 2, 1), QQ(6))]
60
61
62def test_sdm_zero():
63
64
65def test_sdm_deg():
66
67
68def test_sdm_spoly():
69    f = [((2, 1, 1), QQ(1)), ((1, 0, 1), QQ(1))]
70    g = [((2, 3, 0), QQ(1))]
71    h = [((1, 2, 3), QQ(1))]
72
73
74def test_sdm_ecart():
75
76
77def test_sdm_nf_mora():
78    f = sdm_from_dict({(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1),
79                (1, 0, 2, 1): QQ(1), (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)},
80        grlex)
81    f1 = sdm_from_dict({(1, 1, 1, 0): QQ(1), (1, 0, 2, 0): QQ(1),
82                        (1, 0, 0, 0): QQ(-1)}, grlex)
83    f2 = sdm_from_dict({(1, 1, 1, 0): QQ(1)}, grlex)
84    (id0, id1, id2) = [sdm_from_dict({(i, 0, 0, 0): QQ(1)}, grlex)
85                       for i in range(3)]
86
87        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1)),
88          ((1, 1, 0, 1), QQ(1))],
89         [((1, 1, 0, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])
90        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))],
91         [((2, 1, 0, 1), QQ(-1)), ((2, 0, 1, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])
92
93    f = sdm_from_vector([x*z, y**2 + y*z - z, y], lex, QQ, gens=[x, y, z])
94    f1 = sdm_from_vector([x, y, 1], lex, QQ, gens=[x, y, z])
95    f2 = sdm_from_vector([x*y, z, z**2], lex, QQ, gens=[x, y, z])
96        sdm_nf_mora(f, [f2, f1], lex, QQ) == \
97        [((1, 0, 1, 1), QQ(1)), ((1, 0, 0, 1), QQ(-1)), ((0, 1, 1, 0), QQ(-1)),
98         ((0, 1, 0, 1), QQ(1))]
99
100
101def test_conversion():
102    f = [x**2 + y**2, 2*z]
103    g = [((1, 0, 0, 1), QQ(2)), ((0, 2, 0, 0), QQ(1)), ((0, 0, 2, 0), QQ(1))]
104        [x, 1], lex, QQ) == [((1, 0), QQ(1)), ((0, 1), QQ(1))]
105
106
107def test_nontrivial():
108    gens = [x, y, z]
109
110    def contains(I, f):
111        S = [sdm_from_vector([g], lex, QQ, gens=gens) for g in I]
112        G = sdm_groebner(S, sdm_nf_mora, lex, QQ)
113        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
114                           G, lex, QQ) == sdm_zero()
115
116        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
117        x**3)
118        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
119        x**2 + y**2)
120
121    # compare local order
122
123
124def test_local():
125    igrlex = InverseOrder(grlex)
126    gens = [x, y, z]
127
128    def contains(I, f):
129        S = [sdm_from_vector([g], igrlex, QQ, gens=gens) for g in I]
130        G = sdm_groebner(S, sdm_nf_mora, igrlex, QQ)
131        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
132                           G, lex, QQ) == sdm_zero()
133
134
135def test_uncovered_line():
136    gens = [x, y]
137    f1 = sdm_zero()
138    f2 = sdm_from_vector([x, 0], lex, QQ, gens=gens)
139    f3 = sdm_from_vector([0, y], lex, QQ, gens=gens)
140
141
142
143def test_chain_criterion():
144    gens = [x]
145    f1 = sdm_from_vector([1, x], grlex, QQ, gens=gens)
146    f2 = sdm_from_vector([0, x - 2], grlex, QQ, gens=gens)
147","[['sdm_monomial_mul((1', '==', 'True'], ['sdm_monomial_deg((5', '==', 'True'], ['sdm_monomial_lcm((1', '==', 'True'], ['sdm_monomial_divides((1', '==', 'True'], ['sdm_monomial_divides((1', '==', 'True'], ['sdm_monomial_divides((5', '==', 'True'], ['sdm_monomial_divides((1', '==', 'True'], ['sdm_monomial_divides((1', '==', 'True'], ['sdm_monomial_divides((5', '==', 'True'], ['sdm_LC([((1', '==', 'True'], ['sdm_from_dict(dic', '==', 'True'], ['sdm_add([((1', '==', 'True'], ['sdm_add([((1', '==', 'True'], ['sdm_add([((1', '==', 'True'], ['sdm_add([((1', '==', 'True'], ['sdm_LM(sdm_from_dict(dic', '==', 'True'], ['sdm_LT(sdm_from_dict(dic', '==', 'True'], ['sdm_mul_term([((1', '==', 'True'], ['sdm_mul_term([]', '==', 'True'], ['sdm_mul_term([((1', '==', 'True'], ['sdm_mul_term(f', '==', 'True'], ['sdm_zero()', '==', '[]'], ['sdm_deg([((1', '==', 'True'], ['sdm_spoly(f', '==', 'True'], ['sdm_spoly(f', '==', 'True'], ['sdm_ecart([((1', '==', 'True'], ['sdm_ecart([((2', '==', 'True'], ['sdm_nf_mora(f', '==', 'True'], ['sdm_nf_mora(f', '==', 'True'], ['sdm_nf_mora(f', '==', 'True'], ['sdm_to_vector(g', '==', 'True'], ['sdm_from_vector(f', '==', 'True'], ['sdm_from_vector(', '==', 'True'], ['sdm_to_vector([((1', '==', 'True'], ['sdm_from_vector([0', '==', 'True'], ['contains([x', '==', 'True'], ['contains([x', '==', 'True'], ['contains([x', '==', 'False'], ['contains([x', '==', 'False'], ['contains([x**2', '+', 'y'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '==', 'True'], ['contains(', '==', 'True'], ['contains(', '==', 'False'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x', '==', 'True'], ['contains([x', '==', 'True'], ['contains([x', '==', 'False'], ['contains([x', '==', 'False'], ['contains([x**2', '+', 'y'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['sdm_spoly(f1', '==', 'True'], ['sdm_spoly(f3', '==', 'True'], ['len(sdm_groebner([f1', '==', 'True']]",62,62,1.0,0.0081024568740198,"['dic', 'f', 'g', 'h', 'f1', 'f2', '(id0', 'id1', 'id2)', 'gens', 'I', 'S', 'G', 'igrlex', 'f3']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['dic', 'f', 'g', 'h', 'f1', 'f2', '(id0', 'id1', 'id2)', 'gens', 'I', 'S', 'G', 'igrlex', 'f3']
*Code:

1""""""Tests for sparse distributed modules. """"""
2
3from sympy.polys.distributedmodules import (
4    sdm_monomial_mul, sdm_monomial_deg, sdm_monomial_divides,
5    sdm_add, sdm_LM, sdm_LT, sdm_mul_term, sdm_zero, sdm_deg,
6    sdm_LC, sdm_from_dict, sdm_to_dict,
7    sdm_spoly, sdm_ecart, sdm_nf_mora, sdm_groebner,
8    sdm_from_vector, sdm_to_vector, sdm_monomial_lcm
9)
10
11from sympy.polys.orderings import lex, grlex, InverseOrder
12from sympy.polys.domains import QQ
13
14from sympy.abc import x, y, z
15
16
17def test_sdm_monomial_mul():
18
19
20def test_sdm_monomial_deg():
21
22
23def test_sdm_monomial_lcm():
24
25
26def test_sdm_monomial_divides():
27
28
29
30def test_sdm_LC():
31
32
33def test_sdm_from_dict():
34    dic = {(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1), (1, 0, 2, 1): QQ(1),
35           (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)}
36        [((1, 2, 1, 1), QQ(1)), ((1, 1, 2, 1), QQ(1)),
37         ((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))]
38
39# TODO test to_dict?
40
41
42def test_sdm_add():
43        [((2, 0, 0), QQ(1)), ((1, 1, 1), QQ(1))]
44        [((1, 0, 0), QQ(3))]
45        [((1, 1, 0), QQ(1)), ((1, 0, 1), QQ(1))]
46
47
48def test_sdm_LM():
49    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(1), (4, 0, 1): QQ(1)}
50
51
52def test_sdm_LT():
53    dic = {(1, 2, 3): QQ(1), (4, 0, 0): QQ(2), (4, 0, 1): QQ(3)}
54
55
56def test_sdm_mul_term():
57        [((1, 1, 0), QQ(1))]
58    f = [((2, 0, 1), QQ(4)), ((1, 1, 0), QQ(3))]
59        [((2, 1, 2), QQ(8)), ((1, 2, 1), QQ(6))]
60
61
62def test_sdm_zero():
63
64
65def test_sdm_deg():
66
67
68def test_sdm_spoly():
69    f = [((2, 1, 1), QQ(1)), ((1, 0, 1), QQ(1))]
70    g = [((2, 3, 0), QQ(1))]
71    h = [((1, 2, 3), QQ(1))]
72
73
74def test_sdm_ecart():
75
76
77def test_sdm_nf_mora():
78    f = sdm_from_dict({(1, 2, 1, 1): QQ(1), (1, 1, 2, 1): QQ(1),
79                (1, 0, 2, 1): QQ(1), (1, 0, 0, 3): QQ(1), (1, 1, 1, 0): QQ(1)},
80        grlex)
81    f1 = sdm_from_dict({(1, 1, 1, 0): QQ(1), (1, 0, 2, 0): QQ(1),
82                        (1, 0, 0, 0): QQ(-1)}, grlex)
83    f2 = sdm_from_dict({(1, 1, 1, 0): QQ(1)}, grlex)
84    (id0, id1, id2) = [sdm_from_dict({(i, 0, 0, 0): QQ(1)}, grlex)
85                       for i in range(3)]
86
87        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1)),
88          ((1, 1, 0, 1), QQ(1))],
89         [((1, 1, 0, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])
90        ([((1, 0, 2, 1), QQ(1)), ((1, 0, 0, 3), QQ(1)), ((1, 1, 1, 0), QQ(1))],
91         [((2, 1, 0, 1), QQ(-1)), ((2, 0, 1, 1), QQ(-1)), ((0, 0, 0, 0), QQ(1))])
92
93    f = sdm_from_vector([x*z, y**2 + y*z - z, y], lex, QQ, gens=[x, y, z])
94    f1 = sdm_from_vector([x, y, 1], lex, QQ, gens=[x, y, z])
95    f2 = sdm_from_vector([x*y, z, z**2], lex, QQ, gens=[x, y, z])
96        sdm_nf_mora(f, [f2, f1], lex, QQ) == \
97        [((1, 0, 1, 1), QQ(1)), ((1, 0, 0, 1), QQ(-1)), ((0, 1, 1, 0), QQ(-1)),
98         ((0, 1, 0, 1), QQ(1))]
99
100
101def test_conversion():
102    f = [x**2 + y**2, 2*z]
103    g = [((1, 0, 0, 1), QQ(2)), ((0, 2, 0, 0), QQ(1)), ((0, 0, 2, 0), QQ(1))]
104        [x, 1], lex, QQ) == [((1, 0), QQ(1)), ((0, 1), QQ(1))]
105
106
107def test_nontrivial():
108    gens = [x, y, z]
109
110    def contains(I, f):
111        S = [sdm_from_vector([g], lex, QQ, gens=gens) for g in I]
112        G = sdm_groebner(S, sdm_nf_mora, lex, QQ)
113        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
114                           G, lex, QQ) == sdm_zero()
115
116        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
117        x**3)
118        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
119        x**2 + y**2)
120
121    # compare local order
122
123
124def test_local():
125    igrlex = InverseOrder(grlex)
126    gens = [x, y, z]
127
128    def contains(I, f):
129        S = [sdm_from_vector([g], igrlex, QQ, gens=gens) for g in I]
130        G = sdm_groebner(S, sdm_nf_mora, igrlex, QQ)
131        return sdm_nf_mora(sdm_from_vector([f], lex, QQ, gens=gens),
132                           G, lex, QQ) == sdm_zero()
133
134
135def test_uncovered_line():
136    gens = [x, y]
137    f1 = sdm_zero()
138    f2 = sdm_from_vector([x, 0], lex, QQ, gens=gens)
139    f3 = sdm_from_vector([0, y], lex, QQ, gens=gens)
140
141
142
143def test_chain_criterion():
144    gens = [x]
145    f1 = sdm_from_vector([1, x], grlex, QQ, gens=gens)
146    f2 = sdm_from_vector([0, x - 2], grlex, QQ, gens=gens)
147",5989,"[[33, 'dic', '==', 5, ""ensure dictionary 'dic' has correct number of items""],
 [48, 'dic', '==', 3, ""ensure dictionary 'dic' has correct number of items""],
 [52, 'dic', '==', 3, ""ensure dictionary 'dic' has correct number of items""],
 [58, 'f', '==', 2, ""ensure list 'f' has correct number of items""],
 [77, 'f', '==', 5, ""ensure list 'f' has correct number of items""],
 [78, 'f1', '==', 3, ""ensure list 'f1' has correct number of items""],
 [79, 'f2', '==', 1, ""ensure list 'f2' has correct number of items""],
 [80, '(id0, id1, id2)', '==', 3, ""ensure tuple '(id0, id1, id2)' has correct number of elements""],
 [93, 'f', '==', 3, ""ensure list 'f' has correct number of items""],
 [94, 'f1', '==', 3, ""ensure list 'f1' has correct number of items""],
 [95, 'f2', '==', 3, ""ensure list 'f2' has correct number of items""],
 [102, 'f', '==', 2, ""ensure list 'f' has correct number of items""],
 [103, 'g', '==', 3, ""ensure list 'g' has correct number of items""],
 [136, 'gens', '==', 2, ""ensure list 'gens' has correct number of items""],
 [138, 'f2', '==', 2, ""ensure list 'f2' has correct number of items""],
 [139, 'f3', '==', 2, ""ensure list 'f3' has correct number of items""],
 [143, 'gens', '==', 1, ""ensure list 'gens' has correct number of items""],
 [145, 'f1', '==', 2, ""ensure list 'f1' has correct number of items""],
 [146, 'f2', '==', 2, ""ensure list 'f2' has correct number of items""]]"
Elandril/Sick-Beard,"from lib.hachoir_core.tools import makeUnicode, normalizeNewline
from lib.hachoir_core.error import HACHOIR_ERRORS
from lib.hachoir_metadata import config
from lib.hachoir_metadata.setter import normalizeString

MIN_PRIORITY = 100
MAX_PRIORITY = 999

QUALITY_FASTEST = 0.0
QUALITY_FAST = 0.25
QUALITY_NORMAL = 0.5
QUALITY_GOOD = 0.75
QUALITY_BEST = 1.0

class DataValue:
    def __init__(self, value, text):
        self.value = value
        self.text = text

class Data:
    def __init__(self, key, priority, description,
    text_handler=None, type=None, filter=None, conversion=None):
        """"""
        handler is only used if value is not string nor unicode, prototype:
           def handler(value) -> str/unicode
        """"""
        assert MIN_PRIORITY <= priority <= MAX_PRIORITY
        assert isinstance(description, unicode)
        self.metadata = None
        self.key = key
        self.description = description
        self.values = []
        if type and not isinstance(type, (tuple, list)):
            type = (type,)
        self.type = type
        self.text_handler = text_handler
        self.filter = filter
        self.priority = priority
        self.conversion = conversion

    def _createItem(self, value, text=None):
        if text is None:
            if isinstance(value, unicode):
                text = value
            elif self.text_handler:
                text = self.text_handler(value)
                assert isinstance(text, unicode)
            else:
                text = makeUnicode(value)
        return DataValue(value, text)

    def add(self, value):
        if isinstance(value, tuple):
            if len(value) != 2:
                raise ValueError(""Data.add() only accept tuple of 2 elements: (value,text)"")
            value, text = value
        else:
            text = None

        # Skip value 'None'
        if value is None:
            return

        if isinstance(value, (str, unicode)):
            value = normalizeString(value)
            if not value:
                return

        # Convert string to Unicode string using charset ISO-8859-1
        if self.conversion:
            try:
                new_value = self.conversion(self.metadata, self.key, value)
            except HACHOIR_ERRORS, err:
                self.metadata.warning(""Error during conversion of %r value: %s"" % (
                    self.key, err))
                return
            if new_value is None:
                dest_types = "" or "".join(str(item.__name__) for item in self.type)
                self.metadata.warning(""Unable to convert %s=%r (%s) to %s"" % (
                    self.key, value, type(value).__name__, dest_types))
                return
            if isinstance(new_value, tuple):
                if text:
                    value = new_value[0]
                else:
                    value, text = new_value
            else:
                value = new_value
        elif isinstance(value, str):
            value = unicode(value, ""ISO-8859-1"")

        if self.type and not isinstance(value, self.type):
            dest_types = "" or "".join(str(item.__name__) for item in self.type)
            self.metadata.warning(""Key %r: value %r type (%s) is not %s"" % (
                self.key, value, type(value).__name__, dest_types))
            return

        # Skip empty strings
        if isinstance(value, unicode):
            value = normalizeNewline(value)
            if config.MAX_STR_LENGTH \
            and config.MAX_STR_LENGTH < len(value):
                value = value[:config.MAX_STR_LENGTH] + ""(...)""

        # Skip duplicates
        if value in self:
            return

        # Use filter
        if self.filter and not self.filter(value):
            self.metadata.warning(""Skip value %s=%r (filter)"" % (self.key, value))
            return

        # For string, if you have ""verlongtext"" and ""verylo"",
        # keep the longer value
        if isinstance(value, unicode):
            for index, item in enumerate(self.values):
                item = item.value
                if not isinstance(item, unicode):
                    continue
                if value.startswith(item):
                    # Find longer value, replace the old one
                    self.values[index] = self._createItem(value, text)
                    return
                if item.startswith(value):
                    # Find truncated value, skip it
                    return

        # Add new value
        self.values.append(self._createItem(value, text))

    def __len__(self):
        return len(self.values)

    def __getitem__(self, index):
        return self.values[index]

    def __contains__(self, value):
        for item in self.values:
            if value == item.value:
                return True
        return False

    def __cmp__(self, other):
        return cmp(self.priority, other.priority)

","
1from lib.hachoir_core.tools import makeUnicode, normalizeNewline
2from lib.hachoir_core.error import HACHOIR_ERRORS
3from lib.hachoir_metadata import config
4from lib.hachoir_metadata.setter import normalizeString
5
6MIN_PRIORITY = 100
7MAX_PRIORITY = 999
8
9QUALITY_FASTEST = 0.0
10QUALITY_FAST = 0.25
11QUALITY_NORMAL = 0.5
12QUALITY_GOOD = 0.75
13QUALITY_BEST = 1.0
14
15class DataValue:
16    def __init__(self, value, text):
17        self.value = value
18        self.text = text
19
20class Data:
21    def __init__(self, key, priority, description,
22    text_handler=None, type=None, filter=None, conversion=None):
23        """"""
24        handler is only used if value is not string nor unicode, prototype:
25           def handler(value) -> str/unicode
26        """"""
27        self.metadata = None
28        self.key = key
29        self.description = description
30        self.values = []
31        if type and not isinstance(type, (tuple, list)):
32            type = (type,)
33        self.type = type
34        self.text_handler = text_handler
35        self.filter = filter
36        self.priority = priority
37        self.conversion = conversion
38
39    def _createItem(self, value, text=None):
40        if text is None:
41            if isinstance(value, unicode):
42                text = value
43            elif self.text_handler:
44                text = self.text_handler(value)
45            else:
46                text = makeUnicode(value)
47        return DataValue(value, text)
48
49    def add(self, value):
50        if isinstance(value, tuple):
51            if len(value) != 2:
52                raise ValueError(""Data.add() only accept tuple of 2 elements: (value,text)"")
53            value, text = value
54        else:
55            text = None
56
57        # Skip value 'None'
58        if value is None:
59            return
60
61        if isinstance(value, (str, unicode)):
62            value = normalizeString(value)
63            if not value:
64                return
65
66        # Convert string to Unicode string using charset ISO-8859-1
67        if self.conversion:
68            try:
69                new_value = self.conversion(self.metadata, self.key, value)
70            except HACHOIR_ERRORS, err:
71                self.metadata.warning(""Error during conversion of %r value: %s"" % (
72                    self.key, err))
73                return
74            if new_value is None:
75                dest_types = "" or "".join(str(item.__name__) for item in self.type)
76                self.metadata.warning(""Unable to convert %s=%r (%s) to %s"" % (
77                    self.key, value, type(value).__name__, dest_types))
78                return
79            if isinstance(new_value, tuple):
80                if text:
81                    value = new_value[0]
82                else:
83                    value, text = new_value
84            else:
85                value = new_value
86        elif isinstance(value, str):
87            value = unicode(value, ""ISO-8859-1"")
88
89        if self.type and not isinstance(value, self.type):
90            dest_types = "" or "".join(str(item.__name__) for item in self.type)
91            self.metadata.warning(""Key %r: value %r type (%s) is not %s"" % (
92                self.key, value, type(value).__name__, dest_types))
93            return
94
95        # Skip empty strings
96        if isinstance(value, unicode):
97            value = normalizeNewline(value)
98            if config.MAX_STR_LENGTH \
99            and config.MAX_STR_LENGTH < len(value):
100                value = value[:config.MAX_STR_LENGTH] + ""(...)""
101
102        # Skip duplicates
103        if value in self:
104            return
105
106        # Use filter
107        if self.filter and not self.filter(value):
108            self.metadata.warning(""Skip value %s=%r (filter)"" % (self.key, value))
109            return
110
111        # For string, if you have ""verlongtext"" and ""verylo"",
112        # keep the longer value
113        if isinstance(value, unicode):
114            for index, item in enumerate(self.values):
115                item = item.value
116                if not isinstance(item, unicode):
117                    continue
118                if value.startswith(item):
119                    # Find longer value, replace the old one
120                    self.values[index] = self._createItem(value, text)
121                    return
122                if item.startswith(value):
123                    # Find truncated value, skip it
124                    return
125
126        # Add new value
127        self.values.append(self._createItem(value, text))
128
129    def __len__(self):
130        return len(self.values)
131
132    def __getitem__(self, index):
133        return self.values[index]
134
135    def __contains__(self, value):
136        for item in self.values:
137            if value == item.value:
138                return True
139        return False
140
141    def __cmp__(self, other):
142        return cmp(self.priority, other.priority)
143
144","[['MIN_PRIORITY', '<=', 'priority <= MAX_PRIORITY']]",3,1,0.3333333333333333,0.0002034174125305,"['MIN_PRIORITY', 'MAX_PRIORITY', 'QUALITY_FASTEST', 'QUALITY_FAST', 'QUALITY_NORMAL', 'QUALITY_GOOD', 'QUALITY_BEST', 'value', 'text', 'self.value', 'self.text', 'key', 'priority', 'description', 'self.metadata', 'self.key', 'self.description', 'self.values', 'type', 'self.type', 'self.text_handler', 'self.filter', 'self.priority', 'self.conversion', 'new_value', 'dest_types', 'item', 'self.values[index]', 'index', 'other']",30,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['MIN_PRIORITY', 'MAX_PRIORITY', 'QUALITY_FASTEST', 'QUALITY_FAST', 'QUALITY_NORMAL', 'QUALITY_GOOD', 'QUALITY_BEST', 'value', 'text', 'self.value', 'self.text', 'key', 'priority', 'description', 'self.metadata', 'self.key', 'self.description', 'self.values', 'type', 'self.type', 'self.text_handler', 'self.filter', 'self.priority', 'self.conversion', 'new_value', 'dest_types', 'item', 'self.values[index]', 'index', 'other']
*Code:

1from lib.hachoir_core.tools import makeUnicode, normalizeNewline
2from lib.hachoir_core.error import HACHOIR_ERRORS
3from lib.hachoir_metadata import config
4from lib.hachoir_metadata.setter import normalizeString
5
6MIN_PRIORITY = 100
7MAX_PRIORITY = 999
8
9QUALITY_FASTEST = 0.0
10QUALITY_FAST = 0.25
11QUALITY_NORMAL = 0.5
12QUALITY_GOOD = 0.75
13QUALITY_BEST = 1.0
14
15class DataValue:
16    def __init__(self, value, text):
17        self.value = value
18        self.text = text
19
20class Data:
21    def __init__(self, key, priority, description,
22    text_handler=None, type=None, filter=None, conversion=None):
23        """"""
24        handler is only used if value is not string nor unicode, prototype:
25           def handler(value) -> str/unicode
26        """"""
27        self.metadata = None
28        self.key = key
29        self.description = description
30        self.values = []
31        if type and not isinstance(type, (tuple, list)):
32            type = (type,)
33        self.type = type
34        self.text_handler = text_handler
35        self.filter = filter
36        self.priority = priority
37        self.conversion = conversion
38
39    def _createItem(self, value, text=None):
40        if text is None:
41            if isinstance(value, unicode):
42                text = value
43            elif self.text_handler:
44                text = self.text_handler(value)
45            else:
46                text = makeUnicode(value)
47        return DataValue(value, text)
48
49    def add(self, value):
50        if isinstance(value, tuple):
51            if len(value) != 2:
52                raise ValueError(""Data.add() only accept tuple of 2 elements: (value,text)"")
53            value, text = value
54        else:
55            text = None
56
57        # Skip value 'None'
58        if value is None:
59            return
60
61        if isinstance(value, (str, unicode)):
62            value = normalizeString(value)
63            if not value:
64                return
65
66        # Convert string to Unicode string using charset ISO-8859-1
67        if self.conversion:
68            try:
69                new_value = self.conversion(self.metadata, self.key, value)
70            except HACHOIR_ERRORS, err:
71                self.metadata.warning(""Error during conversion of %r value: %s"" % (
72                    self.key, err))
73                return
74            if new_value is None:
75                dest_types = "" or "".join(str(item.__name__) for item in self.type)
76                self.metadata.warning(""Unable to convert %s=%r (%s) to %s"" % (
77                    self.key, value, type(value).__name__, dest_types))
78                return
79            if isinstance(new_value, tuple):
80                if text:
81                    value = new_value[0]
82                else:
83                    value, text = new_value
84            else:
85                value = new_value
86        elif isinstance(value, str):
87            value = unicode(value, ""ISO-8859-1"")
88
89        if self.type and not isinstance(value, self.type):
90            dest_types = "" or "".join(str(item.__name__) for item in self.type)
91            self.metadata.warning(""Key %r: value %r type (%s) is not %s"" % (
92                self.key, value, type(value).__name__, dest_types))
93            return
94
95        # Skip empty strings
96        if isinstance(value, unicode):
97            value = normalizeNewline(value)
98            if config.MAX_STR_LENGTH \
99            and config.MAX_STR_LENGTH < len(value):
100                value = value[:config.MAX_STR_LENGTH] + ""(...)""
101
102        # Skip duplicates
103        if value in self:
104            return
105
106        # Use filter
107        if self.filter and not self.filter(value):
108            self.metadata.warning(""Skip value %s=%r (filter)"" % (self.key, value))
109            return
110
111        # For string, if you have ""verlongtext"" and ""verylo"",
112        # keep the longer value
113        if isinstance(value, unicode):
114            for index, item in enumerate(self.values):
115                item = item.value
116                if not isinstance(item, unicode):
117                    continue
118                if value.startswith(item):
119                    # Find longer value, replace the old one
120                    self.values[index] = self._createItem(value, text)
121                    return
122                if item.startswith(value):
123                    # Find truncated value, skip it
124                    return
125
126        # Add new value
127        self.values.append(self._createItem(value, text))
128
129    def __len__(self):
130        return len(self.values)
131
132    def __getitem__(self, index):
133        return self.values[index]
134
135    def __contains__(self, value):
136        for item in self.values:
137            if value == item.value:
138                return True
139        return False
140
141    def __cmp__(self, other):
142        return cmp(self.priority, other.priority)
143
144",6895,"[[16, 'value', '!=', 'None', ""value passed to init should not be None""],
 [16, 'text', '!=', 'None', ""text passed to init should not be None""],
 [21, 'key', '!=', 'None', ""key passed to init should not be None""],
 [21, 'priority', '>=', 'MIN_PRIORITY', ""priority should not be less than MIN_PRIORITY""],
 [21, 'priority', '<=', 'MAX_PRIORITY', ""priority should not exceed MAX_PRIORITY""],
 [21, 'description', '!=', 'None', ""description passed to init should not be None""],
 [32, 'type', '!=', 'None', ""type should not be None""],
 [39, 'value', '!=', 'None', ""_createItem should not have none value""],
 [41, 'text', '!=', 'None', ""text should not be None""],
 [70, 'new_value', '!=', 'None', ""new_value should not be None""],
 [79, 'dest_types', '!=', 'None', ""dest_types should not be None""],
 [85, 'value', '!=', 'None', ""value should not be None""],
 [90, 'dest_types', '!=', 'None', ""dest_types should not be None""],
 [100, 'value', '!=', 'None', ""value should not be None""],
 [115, 'item', '!=', 'None', ""item should not be None""],
 [120, 'self.values[index]', '!=', 'None', ""self.values[index] should not be None""],
 [127, 'value', '!=', 'None', ""value should not be None""],
 [129, 'self.values', '>=', 1, ""self.values should not be empty""],
 [132, 'self.values[index]', '!=', 'None', ""self.values[index] should not be None""],
 [136, 'value', '!=', 'None', ""value must not be None""],
 [141, 'other', '!=', 'None', ""other must not be None""]]"
ammarkhann/FinalSeniorCode,"from __future__ import division

import pytest
from pandas import Interval
import pandas.util.testing as tm


class TestInterval(object):
    def setup_method(self, method):
        self.interval = Interval(0, 1)

    def test_properties(self):
        assert self.interval.closed == 'right'
        assert self.interval.left == 0
        assert self.interval.right == 1
        assert self.interval.mid == 0.5

    def test_repr(self):
        assert repr(self.interval) == ""Interval(0, 1, closed='right')""
        assert str(self.interval) == ""(0, 1]""

        interval_left = Interval(0, 1, closed='left')
        assert repr(interval_left) == ""Interval(0, 1, closed='left')""
        assert str(interval_left) == ""[0, 1)""

    def test_contains(self):
        assert 0.5 in self.interval
        assert 1 in self.interval
        assert 0 not in self.interval
        pytest.raises(TypeError, lambda: self.interval in self.interval)

        interval = Interval(0, 1, closed='both')
        assert 0 in interval
        assert 1 in interval

        interval = Interval(0, 1, closed='neither')
        assert 0 not in interval
        assert 0.5 in interval
        assert 1 not in interval

    def test_equal(self):
        assert Interval(0, 1) == Interval(0, 1, closed='right')
        assert Interval(0, 1) != Interval(0, 1, closed='left')
        assert Interval(0, 1) != 0

    def test_comparison(self):
        with tm.assert_raises_regex(TypeError, 'unorderable types'):
            Interval(0, 1) < 2

        assert Interval(0, 1) < Interval(1, 2)
        assert Interval(0, 1) < Interval(0, 2)
        assert Interval(0, 1) < Interval(0.5, 1.5)
        assert Interval(0, 1) <= Interval(0, 1)
        assert Interval(0, 1) > Interval(-1, 2)
        assert Interval(0, 1) >= Interval(0, 1)

    def test_hash(self):
        # should not raise
        hash(self.interval)

    def test_math_add(self):
        expected = Interval(1, 2)
        actual = self.interval + 1
        assert expected == actual

        expected = Interval(1, 2)
        actual = 1 + self.interval
        assert expected == actual

        actual = self.interval
        actual += 1
        assert expected == actual

        with pytest.raises(TypeError):
            self.interval + Interval(1, 2)

        with pytest.raises(TypeError):
            self.interval + 'foo'

    def test_math_sub(self):
        expected = Interval(-1, 0)
        actual = self.interval - 1
        assert expected == actual

        actual = self.interval
        actual -= 1
        assert expected == actual

        with pytest.raises(TypeError):
            self.interval - Interval(1, 2)

        with pytest.raises(TypeError):
            self.interval - 'foo'

    def test_math_mult(self):
        expected = Interval(0, 2)
        actual = self.interval * 2
        assert expected == actual

        expected = Interval(0, 2)
        actual = 2 * self.interval
        assert expected == actual

        actual = self.interval
        actual *= 2
        assert expected == actual

        with pytest.raises(TypeError):
            self.interval * Interval(1, 2)

        with pytest.raises(TypeError):
            self.interval * 'foo'

    def test_math_div(self):
        expected = Interval(0, 0.5)
        actual = self.interval / 2.0
        assert expected == actual

        actual = self.interval
        actual /= 2.0
        assert expected == actual

        with pytest.raises(TypeError):
            self.interval / Interval(1, 2)

        with pytest.raises(TypeError):
            self.interval / 'foo'
","
1from __future__ import division
2
3import pytest
4from pandas import Interval
5import pandas.util.testing as tm
6
7
8class TestInterval(object):
9    def setup_method(self, method):
10        self.interval = Interval(0, 1)
11
12    def test_properties(self):
13
14    def test_repr(self):
15
16        interval_left = Interval(0, 1, closed='left')
17
18    def test_contains(self):
19        pytest.raises(TypeError, lambda: self.interval in self.interval)
20
21        interval = Interval(0, 1, closed='both')
22
23        interval = Interval(0, 1, closed='neither')
24
25    def test_equal(self):
26
27    def test_comparison(self):
28            Interval(0, 1) < 2
29
30
31    def test_hash(self):
32        # should not raise
33        hash(self.interval)
34
35    def test_math_add(self):
36        expected = Interval(1, 2)
37        actual = self.interval + 1
38
39        expected = Interval(1, 2)
40        actual = 1 + self.interval
41
42        actual = self.interval
43        actual += 1
44
45        with pytest.raises(TypeError):
46            self.interval + Interval(1, 2)
47
48        with pytest.raises(TypeError):
49            self.interval + 'foo'
50
51    def test_math_sub(self):
52        expected = Interval(-1, 0)
53        actual = self.interval - 1
54
55        actual = self.interval
56        actual -= 1
57
58        with pytest.raises(TypeError):
59            self.interval - Interval(1, 2)
60
61        with pytest.raises(TypeError):
62            self.interval - 'foo'
63
64    def test_math_mult(self):
65        expected = Interval(0, 2)
66        actual = self.interval * 2
67
68        expected = Interval(0, 2)
69        actual = 2 * self.interval
70
71        actual = self.interval
72        actual *= 2
73
74        with pytest.raises(TypeError):
75            self.interval * Interval(1, 2)
76
77        with pytest.raises(TypeError):
78            self.interval * 'foo'
79
80    def test_math_div(self):
81        expected = Interval(0, 0.5)
82        actual = self.interval / 2.0
83
84        actual = self.interval
85        actual /= 2.0
86
87        with pytest.raises(TypeError):
88            self.interval / Interval(1, 2)
89
90        with pytest.raises(TypeError):
91            self.interval / 'foo'
92","[['self.interval.closed', '==', ""'right'""], ['self.interval.left', '==', '0'], ['self.interval.right', '==', '1'], ['self.interval.mid', '==', '0.5'], ['repr(self.interval)', '==', '""Interval(0'], ['str(self.interval)', '==', '""(0'], ['repr(interval_left)', '==', '""Interval(0'], ['str(interval_left)', '==', '""[0'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['Interval(0', '==', 'True'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual'], ['expected', '==', 'actual']]",36,27,0.75,0.0074875207986688,"['method', 'self.interval', 'interval_left', 'interval', 'expected', 'actual']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['method', 'self.interval', 'interval_left', 'interval', 'expected', 'actual']
*Code:

1from __future__ import division
2
3import pytest
4from pandas import Interval
5import pandas.util.testing as tm
6
7
8class TestInterval(object):
9    def setup_method(self, method):
10        self.interval = Interval(0, 1)
11
12    def test_properties(self):
13
14    def test_repr(self):
15
16        interval_left = Interval(0, 1, closed='left')
17
18    def test_contains(self):
19        pytest.raises(TypeError, lambda: self.interval in self.interval)
20
21        interval = Interval(0, 1, closed='both')
22
23        interval = Interval(0, 1, closed='neither')
24
25    def test_equal(self):
26
27    def test_comparison(self):
28            Interval(0, 1) < 2
29
30
31    def test_hash(self):
32        # should not raise
33        hash(self.interval)
34
35    def test_math_add(self):
36        expected = Interval(1, 2)
37        actual = self.interval + 1
38
39        expected = Interval(1, 2)
40        actual = 1 + self.interval
41
42        actual = self.interval
43        actual += 1
44
45        with pytest.raises(TypeError):
46            self.interval + Interval(1, 2)
47
48        with pytest.raises(TypeError):
49            self.interval + 'foo'
50
51    def test_math_sub(self):
52        expected = Interval(-1, 0)
53        actual = self.interval - 1
54
55        actual = self.interval
56        actual -= 1
57
58        with pytest.raises(TypeError):
59            self.interval - Interval(1, 2)
60
61        with pytest.raises(TypeError):
62            self.interval - 'foo'
63
64    def test_math_mult(self):
65        expected = Interval(0, 2)
66        actual = self.interval * 2
67
68        expected = Interval(0, 2)
69        actual = 2 * self.interval
70
71        actual = self.interval
72        actual *= 2
73
74        with pytest.raises(TypeError):
75            self.interval * Interval(1, 2)
76
77        with pytest.raises(TypeError):
78            self.interval * 'foo'
79
80    def test_math_div(self):
81        expected = Interval(0, 0.5)
82        actual = self.interval / 2.0
83
84        actual = self.interval
85        actual /= 2.0
86
87        with pytest.raises(TypeError):
88            self.interval / Interval(1, 2)
89
90        with pytest.raises(TypeError):
91            self.interval / 'foo'
92",3718,"[[9, 'method', '!=', None, ""The setup method needs a non-None method to function properly""],
[16, 'interval_left', '!=', None, ""Creation of interval_left must not result to None""],
[21, 'interval', '!=', None, ""Creation of interval must not result to None""],
[23, 'interval', '!=', None, ""Re-assigning of interval must not result to None""],
[37, 'actual', '==', 'expected', ""Actual result of addition must equal the expected result""],
[40, 'actual', '==', 'expected', ""Actual result of addition (reversed operands) must equal the expected result""],
[53, 'actual', '==', 'expected', ""Actual result of subtraction must equal the expected result""],
[66, 'actual', '==', 'expected', ""Actual result of multiplication must equal the expected result""],
[69, 'actual', '==', 'expected', ""Actual result of multiplication (reversed operands) must equal the expected result""],
[82, 'actual', '==', 'expected', ""Actual result of division must equal the expected result""]]"
jeffery-do/Vizdoombot,"import numpy as np
from skimage.morphology import skeletonize, medial_axis
import numpy.testing
from skimage import draw
from scipy.ndimage import correlate
from skimage.io import imread
from skimage import data_dir
import os.path


class TestSkeletonize():
    def test_skeletonize_no_foreground(self):
        im = np.zeros((5, 5))
        result = skeletonize(im)
        numpy.testing.assert_array_equal(result, np.zeros((5, 5)))

    def test_skeletonize_wrong_dim1(self):
        im = np.zeros((5))
        numpy.testing.assert_raises(ValueError, skeletonize, im)

    def test_skeletonize_wrong_dim2(self):
        im = np.zeros((5, 5, 5))
        numpy.testing.assert_raises(ValueError, skeletonize, im)

    def test_skeletonize_not_binary(self):
        im = np.zeros((5, 5))
        im[0, 0] = 1
        im[0, 1] = 2
        numpy.testing.assert_raises(ValueError, skeletonize, im)

    def test_skeletonize_unexpected_value(self):
        im = np.zeros((5, 5))
        im[0, 0] = 2
        numpy.testing.assert_raises(ValueError, skeletonize, im)

    def test_skeletonize_all_foreground(self):
        im = np.ones((3, 4))
        skeletonize(im)

    def test_skeletonize_single_point(self):
        im = np.zeros((5, 5), np.uint8)
        im[3, 3] = 1
        result = skeletonize(im)
        numpy.testing.assert_array_equal(result, im)

    def test_skeletonize_already_thinned(self):
        im = np.zeros((5, 5), np.uint8)
        im[3, 1:-1] = 1
        im[2, -1] = 1
        im[4, 0] = 1
        result = skeletonize(im)
        numpy.testing.assert_array_equal(result, im)

    def test_skeletonize_output(self):
        im = imread(os.path.join(data_dir, ""bw_text.png""), as_grey=True)

        # make black the foreground
        im = (im == 0)
        result = skeletonize(im)

        expected = np.load(os.path.join(data_dir, ""bw_text_skeleton.npy""))
        numpy.testing.assert_array_equal(result, expected)

    def test_skeletonize_num_neighbours(self):
        # an empty image
        image = np.zeros((300, 300))

        # foreground object 1
        image[10:-10, 10:100] = 1
        image[-100:-10, 10:-10] = 1
        image[10:-10, -100:-10] = 1

        # foreground object 2
        rs, cs = draw.line(250, 150, 10, 280)
        for i in range(10):
            image[rs + i, cs] = 1
        rs, cs = draw.line(10, 150, 250, 280)
        for i in range(20):
            image[rs + i, cs] = 1

        # foreground object 3
        ir, ic = np.indices(image.shape)
        circle1 = (ic - 135)**2 + (ir - 150)**2 < 30**2
        circle2 = (ic - 135)**2 + (ir - 150)**2 < 20**2
        image[circle1] = 1
        image[circle2] = 0
        result = skeletonize(image)

        # there should never be a 2x2 block of foreground pixels in a skeleton
        mask = np.array([[1,  1],
                         [1,  1]], np.uint8)
        blocks = correlate(result, mask, mode='constant')
        assert not numpy.any(blocks == 4)

    def test_lut_fix(self):
        im = np.zeros((6, 6), np.uint8)
        im[1, 2] = 1
        im[2, 2] = 1
        im[2, 3] = 1
        im[3, 3] = 1
        im[3, 4] = 1
        im[4, 4] = 1
        im[4, 5] = 1
        result = skeletonize(im)
        expected = np.array([[0, 0, 0, 0, 0, 0],
                             [0, 0, 1, 0, 0, 0],
                             [0, 0, 0, 1, 0, 0],
                             [0, 0, 0, 0, 1, 0],
                             [0, 0, 0, 0, 0, 1],
                             [0, 0, 0, 0, 0, 0]], dtype=np.uint8)
        assert np.all(result == expected)


class TestMedialAxis():
    def test_00_00_zeros(self):
        '''Test skeletonize on an array of all zeros'''
        result = medial_axis(np.zeros((10, 10), bool))
        assert np.all(result == False)

    def test_00_01_zeros_masked(self):
        '''Test skeletonize on an array that is completely masked'''
        result = medial_axis(np.zeros((10, 10), bool),
                                   np.zeros((10, 10), bool))
        assert np.all(result == False)

    def test_01_01_rectangle(self):
        '''Test skeletonize on a rectangle'''
        image = np.zeros((9, 15), bool)
        image[1:-1, 1:-1] = True
        #
        # The result should be four diagonals from the
        # corners, meeting in a horizontal line
        #
        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
                             [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
                             bool)
        result = medial_axis(image)
        assert np.all(result == expected)
        result, distance = medial_axis(image, return_distance=True)
        assert distance.max() == 4

    def test_01_02_hole(self):
        '''Test skeletonize on a rectangle with a hole in the middle'''
        image = np.zeros((9, 15), bool)
        image[1:-1, 1:-1] = True
        image[4, 4:-4] = False
        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
                             bool)
        result = medial_axis(image)
        assert np.all(result == expected)

    def test_narrow_image(self):
        """"""Test skeletonize on a 1-pixel thin strip""""""
        image = np.zeros((1, 5), bool)
        image[:, 1:-1] = True
        result = medial_axis(image)
        assert np.all(result == image)


if __name__ == '__main__':
    np.testing.run_module_suite()
","
1import numpy as np
2from skimage.morphology import skeletonize, medial_axis
3import numpy.testing
4from skimage import draw
5from scipy.ndimage import correlate
6from skimage.io import imread
7from skimage import data_dir
8import os.path
9
10
11class TestSkeletonize():
12    def test_skeletonize_no_foreground(self):
13        im = np.zeros((5, 5))
14        result = skeletonize(im)
15
16    def test_skeletonize_wrong_dim1(self):
17        im = np.zeros((5))
18
19    def test_skeletonize_wrong_dim2(self):
20        im = np.zeros((5, 5, 5))
21
22    def test_skeletonize_not_binary(self):
23        im = np.zeros((5, 5))
24        im[0, 0] = 1
25        im[0, 1] = 2
26
27    def test_skeletonize_unexpected_value(self):
28        im = np.zeros((5, 5))
29        im[0, 0] = 2
30
31    def test_skeletonize_all_foreground(self):
32        im = np.ones((3, 4))
33        skeletonize(im)
34
35    def test_skeletonize_single_point(self):
36        im = np.zeros((5, 5), np.uint8)
37        im[3, 3] = 1
38        result = skeletonize(im)
39
40    def test_skeletonize_already_thinned(self):
41        im = np.zeros((5, 5), np.uint8)
42        im[3, 1:-1] = 1
43        im[2, -1] = 1
44        im[4, 0] = 1
45        result = skeletonize(im)
46
47    def test_skeletonize_output(self):
48        im = imread(os.path.join(data_dir, ""bw_text.png""), as_grey=True)
49
50        # make black the foreground
51        im = (im == 0)
52        result = skeletonize(im)
53
54        expected = np.load(os.path.join(data_dir, ""bw_text_skeleton.npy""))
55
56    def test_skeletonize_num_neighbours(self):
57        # an empty image
58        image = np.zeros((300, 300))
59
60        # foreground object 1
61        image[10:-10, 10:100] = 1
62        image[-100:-10, 10:-10] = 1
63        image[10:-10, -100:-10] = 1
64
65        # foreground object 2
66        rs, cs = draw.line(250, 150, 10, 280)
67        for i in range(10):
68            image[rs + i, cs] = 1
69        rs, cs = draw.line(10, 150, 250, 280)
70        for i in range(20):
71            image[rs + i, cs] = 1
72
73        # foreground object 3
74        ir, ic = np.indices(image.shape)
75        circle1 = (ic - 135)**2 + (ir - 150)**2 < 30**2
76        circle2 = (ic - 135)**2 + (ir - 150)**2 < 20**2
77        image[circle1] = 1
78        image[circle2] = 0
79        result = skeletonize(image)
80
81        # there should never be a 2x2 block of foreground pixels in a skeleton
82        mask = np.array([[1,  1],
83                         [1,  1]], np.uint8)
84        blocks = correlate(result, mask, mode='constant')
85
86    def test_lut_fix(self):
87        im = np.zeros((6, 6), np.uint8)
88        im[1, 2] = 1
89        im[2, 2] = 1
90        im[2, 3] = 1
91        im[3, 3] = 1
92        im[3, 4] = 1
93        im[4, 4] = 1
94        im[4, 5] = 1
95        result = skeletonize(im)
96        expected = np.array([[0, 0, 0, 0, 0, 0],
97                             [0, 0, 1, 0, 0, 0],
98                             [0, 0, 0, 1, 0, 0],
99                             [0, 0, 0, 0, 1, 0],
100                             [0, 0, 0, 0, 0, 1],
101                             [0, 0, 0, 0, 0, 0]], dtype=np.uint8)
102
103
104class TestMedialAxis():
105    def test_00_00_zeros(self):
106        '''Test skeletonize on an array of all zeros'''
107        result = medial_axis(np.zeros((10, 10), bool))
108
109    def test_00_01_zeros_masked(self):
110        '''Test skeletonize on an array that is completely masked'''
111        result = medial_axis(np.zeros((10, 10), bool),
112                                   np.zeros((10, 10), bool))
113
114    def test_01_01_rectangle(self):
115        '''Test skeletonize on a rectangle'''
116        image = np.zeros((9, 15), bool)
117        image[1:-1, 1:-1] = True
118        #
119        # The result should be four diagonals from the
120        # corners, meeting in a horizontal line
121        #
122        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
123                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
124                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
125                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
126                             [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
127                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
128                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
129                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
130                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
131                             bool)
132        result = medial_axis(image)
133        result, distance = medial_axis(image, return_distance=True)
134
135    def test_01_02_hole(self):
136        '''Test skeletonize on a rectangle with a hole in the middle'''
137        image = np.zeros((9, 15), bool)
138        image[1:-1, 1:-1] = True
139        image[4, 4:-4] = False
140        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
141                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
142                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
143                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
144                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
145                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
146                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
147                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
148                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
149                             bool)
150        result = medial_axis(image)
151
152    def test_narrow_image(self):
153        """"""Test skeletonize on a 1-pixel thin strip""""""
154        image = np.zeros((1, 5), bool)
155        image[:, 1:-1] = True
156        result = medial_axis(image)
157
158
159if __name__ == '__main__':
160    np.testing.run_module_suite()
161","[['numpy.any(blocks', '==', '4)'], ['np.all(result', '==', 'expected)'], ['np.all(result', '==', 'False)'], ['np.all(result', '==', 'False)'], ['np.all(result', '==', 'expected)'], ['distance.max()', '==', '4'], ['np.all(result', '==', 'expected)'], ['np.all(result', '==', 'image)']]",16,8,0.5,0.0012271820831415,"['im', 'result', 'im[0', '0]', '1]', 'im[3', '3]', '1:-1]', 'im[2', '-1]', 'im[4', 'expected', 'image', 'image[10:-10', '10:100]', 'image[-100:-10', '10:-10]', '-100:-10]', 'rs', 'cs', 'image[rs + i', 'cs]', 'ir', 'ic', 'circle1', 'circle2', 'image[circle1]', 'image[circle2]', 'mask', 'blocks', 'im[1', '2]', '4]', '5]', 'image[1:-1', 'distance', 'image[4', '4:-4]', 'image[:']",39,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['im', 'result', 'im[0', '0]', '1]', 'im[3', '3]', '1:-1]', 'im[2', '-1]', 'im[4', 'expected', 'image', 'image[10:-10', '10:100]', 'image[-100:-10', '10:-10]', '-100:-10]', 'rs', 'cs', 'image[rs + i', 'cs]', 'ir', 'ic', 'circle1', 'circle2', 'image[circle1]', 'image[circle2]', 'mask', 'blocks', 'im[1', '2]', '4]', '5]', 'image[1:-1', 'distance', 'image[4', '4:-4]', 'image[:']
*Code:

1import numpy as np
2from skimage.morphology import skeletonize, medial_axis
3import numpy.testing
4from skimage import draw
5from scipy.ndimage import correlate
6from skimage.io import imread
7from skimage import data_dir
8import os.path
9
10
11class TestSkeletonize():
12    def test_skeletonize_no_foreground(self):
13        im = np.zeros((5, 5))
14        result = skeletonize(im)
15
16    def test_skeletonize_wrong_dim1(self):
17        im = np.zeros((5))
18
19    def test_skeletonize_wrong_dim2(self):
20        im = np.zeros((5, 5, 5))
21
22    def test_skeletonize_not_binary(self):
23        im = np.zeros((5, 5))
24        im[0, 0] = 1
25        im[0, 1] = 2
26
27    def test_skeletonize_unexpected_value(self):
28        im = np.zeros((5, 5))
29        im[0, 0] = 2
30
31    def test_skeletonize_all_foreground(self):
32        im = np.ones((3, 4))
33        skeletonize(im)
34
35    def test_skeletonize_single_point(self):
36        im = np.zeros((5, 5), np.uint8)
37        im[3, 3] = 1
38        result = skeletonize(im)
39
40    def test_skeletonize_already_thinned(self):
41        im = np.zeros((5, 5), np.uint8)
42        im[3, 1:-1] = 1
43        im[2, -1] = 1
44        im[4, 0] = 1
45        result = skeletonize(im)
46
47    def test_skeletonize_output(self):
48        im = imread(os.path.join(data_dir, ""bw_text.png""), as_grey=True)
49
50        # make black the foreground
51        im = (im == 0)
52        result = skeletonize(im)
53
54        expected = np.load(os.path.join(data_dir, ""bw_text_skeleton.npy""))
55
56    def test_skeletonize_num_neighbours(self):
57        # an empty image
58        image = np.zeros((300, 300))
59
60        # foreground object 1
61        image[10:-10, 10:100] = 1
62        image[-100:-10, 10:-10] = 1
63        image[10:-10, -100:-10] = 1
64
65        # foreground object 2
66        rs, cs = draw.line(250, 150, 10, 280)
67        for i in range(10):
68            image[rs + i, cs] = 1
69        rs, cs = draw.line(10, 150, 250, 280)
70        for i in range(20):
71            image[rs + i, cs] = 1
72
73        # foreground object 3
74        ir, ic = np.indices(image.shape)
75        circle1 = (ic - 135)**2 + (ir - 150)**2 < 30**2
76        circle2 = (ic - 135)**2 + (ir - 150)**2 < 20**2
77        image[circle1] = 1
78        image[circle2] = 0
79        result = skeletonize(image)
80
81        # there should never be a 2x2 block of foreground pixels in a skeleton
82        mask = np.array([[1,  1],
83                         [1,  1]], np.uint8)
84        blocks = correlate(result, mask, mode='constant')
85
86    def test_lut_fix(self):
87        im = np.zeros((6, 6), np.uint8)
88        im[1, 2] = 1
89        im[2, 2] = 1
90        im[2, 3] = 1
91        im[3, 3] = 1
92        im[3, 4] = 1
93        im[4, 4] = 1
94        im[4, 5] = 1
95        result = skeletonize(im)
96        expected = np.array([[0, 0, 0, 0, 0, 0],
97                             [0, 0, 1, 0, 0, 0],
98                             [0, 0, 0, 1, 0, 0],
99                             [0, 0, 0, 0, 1, 0],
100                             [0, 0, 0, 0, 0, 1],
101                             [0, 0, 0, 0, 0, 0]], dtype=np.uint8)
102
103
104class TestMedialAxis():
105    def test_00_00_zeros(self):
106        '''Test skeletonize on an array of all zeros'''
107        result = medial_axis(np.zeros((10, 10), bool))
108
109    def test_00_01_zeros_masked(self):
110        '''Test skeletonize on an array that is completely masked'''
111        result = medial_axis(np.zeros((10, 10), bool),
112                                   np.zeros((10, 10), bool))
113
114    def test_01_01_rectangle(self):
115        '''Test skeletonize on a rectangle'''
116        image = np.zeros((9, 15), bool)
117        image[1:-1, 1:-1] = True
118        #
119        # The result should be four diagonals from the
120        # corners, meeting in a horizontal line
121        #
122        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
123                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
124                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
125                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
126                             [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
127                             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
128                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
129                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
130                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
131                             bool)
132        result = medial_axis(image)
133        result, distance = medial_axis(image, return_distance=True)
134
135    def test_01_02_hole(self):
136        '''Test skeletonize on a rectangle with a hole in the middle'''
137        image = np.zeros((9, 15), bool)
138        image[1:-1, 1:-1] = True
139        image[4, 4:-4] = False
140        expected = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
141                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
142                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
143                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
144                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
145                             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
146                             [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
147                             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
148                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
149                             bool)
150        result = medial_axis(image)
151
152    def test_narrow_image(self):
153        """"""Test skeletonize on a 1-pixel thin strip""""""
154        image = np.zeros((1, 5), bool)
155        image[:, 1:-1] = True
156        result = medial_axis(image)
157
158
159if __name__ == '__main__':
160    np.testing.run_module_suite()
161",7841,"[[13, 'im', '==', 'result', 'the result of skeletonizing a null image should be a null image'],
 [18, 'im', '==', 'result', 'skeletonizing a one-dimensional image should return the same image'],
 [38, 'im[3', '3]', '==', 'result', 'the result of skeletonizing a single point image should be that point'],
 [45, 'im', '==', 'result', 'the result of skeletonizing a thinned image should be the same image'],
 [54, 'expected', '==', 'result', 'the result of skeletonizing should match the expected output'], 
 [79, 'mask', '!=', 'blocks', 'there should never be a 2x2 block of foreground pixels in a skeleton'],
 [95, 'im', '!=', 'result', 'skeletonizing an image with lines should not yield the same image'],
 [101, 'expected', '==', 'result', 'the result of skeletonizing should match the expected output'],
 [108, 'result', '==', 0, 'the skeletonize operation on an array of all zeros should give a null result'],
 [112, 'result', '==', 'im', 'skeletonize operation on an array that is completely masked should not change the image'],
 [132, 'expected', '==', 'result', 'the result of skeletonizing should match the expected output'],
 [134, 'distance', '>=', 1, 'distance in medial_axis function should be at least 1'],
 [150, 'expected', '==', 'result', 'the result of skeletonizing should match the expected output'],
 [156, 'result', '==', 'image', 'the result of skeletonizing a 1-pixel thin strip should be the same strip']]"
pixelated-project/pixelated-user-agent,"#
# Copyright (c) 2014 ThoughtWorks, Inc.
#
# Pixelated is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Pixelated is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with Pixelated. If not, see <http://www.gnu.org/licenses/>.
from behave import when
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException

from common import (
    find_element_by_class_name,
    find_element_by_css_selector,
    wait_for_user_alert_to_disapear)


def click_first_element_with_class(context, classname):
    element = find_element_by_class_name(context, classname)
    element.click()


def is_side_nav_expanded(context):
    e = find_element_by_class_name(context, 'content')
    return u'move-right' in e.get_attribute(""class"")


def expand_side_nav(context):
    if is_side_nav_expanded(context):
        return

    find_element_by_css_selector(context, '.side-nav-toggle-icon i').click()


@when('I select the tag \'{tag}\'')
def select_tag(context, tag):
    wait_for_user_alert_to_disapear(context)
    expand_side_nav(context)

    # try this multiple times as there are some race conditions
    try_again = 2
    success = False
    while (not success) and (try_again > 0):
        try:
            find_element_by_css_selector(context, '#tag-%s' % tag)

            e = find_element_by_css_selector(context, '#tag-%s .tag-label' % tag)
            e.click()

            find_element_by_css_selector(context, "".mail-list-entry__item[href*='%s']"" % tag)
            success = True
        except (TimeoutException, StaleElementReferenceException):
            pass
        finally:
            try_again -= 1

    assert success
","
1#
2# Copyright (c) 2014 ThoughtWorks, Inc.
3#
4# Pixelated is free software: you can redistribute it and/or modify
5# it under the terms of the GNU Affero General Public License as published by
6# the Free Software Foundation, either version 3 of the License, or
7# (at your option) any later version.
8#
9# Pixelated is distributed in the hope that it will be useful,
10# but WITHOUT ANY WARRANTY; without even the implied warranty of
11# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12# GNU Affero General Public License for more details.
13#
14# You should have received a copy of the GNU Affero General Public License
15# along with Pixelated. If not, see <http://www.gnu.org/licenses/>.
16from behave import when
17from selenium.common.exceptions import TimeoutException, StaleElementReferenceException
18
19from common import (
20    find_element_by_class_name,
21    find_element_by_css_selector,
22    wait_for_user_alert_to_disapear)
23
24
25def click_first_element_with_class(context, classname):
26    element = find_element_by_class_name(context, classname)
27    element.click()
28
29
30def is_side_nav_expanded(context):
31    e = find_element_by_class_name(context, 'content')
32    return u'move-right' in e.get_attribute(""class"")
33
34
35def expand_side_nav(context):
36    if is_side_nav_expanded(context):
37        return
38
39    find_element_by_css_selector(context, '.side-nav-toggle-icon i').click()
40
41
42@when('I select the tag \'{tag}\'')
43def select_tag(context, tag):
44    wait_for_user_alert_to_disapear(context)
45    expand_side_nav(context)
46
47    # try this multiple times as there are some race conditions
48    try_again = 2
49    success = False
50    while (not success) and (try_again > 0):
51        try:
52            find_element_by_css_selector(context, '#tag-%s' % tag)
53
54            e = find_element_by_css_selector(context, '#tag-%s .tag-label' % tag)
55            e.click()
56
57            find_element_by_css_selector(context, "".mail-list-entry__item[href*='%s']"" % tag)
58            success = True
59        except (TimeoutException, StaleElementReferenceException):
60            pass
61        finally:
62            try_again -= 1
63
64","[['success', '==', 'True']]",1,1,1.0,0.0004721435316336,"['context', 'classname', 'element', 'e', 'tag', 'try_again', 'success']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['context', 'classname', 'element', 'e', 'tag', 'try_again', 'success']
*Code:

1#
2# Copyright (c) 2014 ThoughtWorks, Inc.
3#
4# Pixelated is free software: you can redistribute it and/or modify
5# it under the terms of the GNU Affero General Public License as published by
6# the Free Software Foundation, either version 3 of the License, or
7# (at your option) any later version.
8#
9# Pixelated is distributed in the hope that it will be useful,
10# but WITHOUT ANY WARRANTY; without even the implied warranty of
11# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12# GNU Affero General Public License for more details.
13#
14# You should have received a copy of the GNU Affero General Public License
15# along with Pixelated. If not, see <http://www.gnu.org/licenses/>.
16from behave import when
17from selenium.common.exceptions import TimeoutException, StaleElementReferenceException
18
19from common import (
20    find_element_by_class_name,
21    find_element_by_css_selector,
22    wait_for_user_alert_to_disapear)
23
24
25def click_first_element_with_class(context, classname):
26    element = find_element_by_class_name(context, classname)
27    element.click()
28
29
30def is_side_nav_expanded(context):
31    e = find_element_by_class_name(context, 'content')
32    return u'move-right' in e.get_attribute(""class"")
33
34
35def expand_side_nav(context):
36    if is_side_nav_expanded(context):
37        return
38
39    find_element_by_css_selector(context, '.side-nav-toggle-icon i').click()
40
41
42@when('I select the tag \'{tag}\'')
43def select_tag(context, tag):
44    wait_for_user_alert_to_disapear(context)
45    expand_side_nav(context)
46
47    # try this multiple times as there are some race conditions
48    try_again = 2
49    success = False
50    while (not success) and (try_again > 0):
51        try:
52            find_element_by_css_selector(context, '#tag-%s' % tag)
53
54            e = find_element_by_css_selector(context, '#tag-%s .tag-label' % tag)
55            e.click()
56
57            find_element_by_css_selector(context, "".mail-list-entry__item[href*='%s']"" % tag)
58            success = True
59        except (TimeoutException, StaleElementReferenceException):
60            pass
61        finally:
62            try_again -= 1
63
64",3670,"[[25, 'context', '!=', None, 'context should not be None for function to run'],
[25, 'classname', '!=', None, 'classname should not be None for function to run'],
[30, 'context', '!=', None, 'context should not be None for function to run'],
[35, 'context', '!=', None, 'context should not be None for function to run'],
[43, 'context', '!=', None, 'context should not be None for function to run'],
[43, 'tag', '!=', None, 'tag should not be None for function to run'],
[48, 'try_again', '>=', 0, 'try_again cannot be negative'],
[54, 'e', '!=', None, 'e should not be None for click method to run'],
[57, 'success', '==', True, 'the function should have successfully found the element']]"
jakesyl/BitTornado,"from .CurrentRateMeasure import Measure


class Upload:
    def __init__(self, connection, ratelimiter, totalup, choker, storage,
                 picker, config):
        self.connection = connection
        self.ratelimiter = ratelimiter
        self.totalup = totalup
        self.choker = choker
        self.storage = storage
        self.picker = picker
        self.config = config
        self.max_slice_length = config['max_slice_length']
        self.choked = True
        self.cleared = True
        self.interested = False
        self.super_seeding = False
        self.buffer = []
        self.measure = Measure(config['max_rate_period'],
                               config['upload_rate_fudge'])
        self.was_ever_interested = False
        if storage.get_amount_left() == 0:
            if choker.super_seed:
                self.super_seeding = True   # flag, and don't send bitfield
                self.seed_have_list = []    # set from piecepicker
                self.skipped_count = 0
            else:
                if config['breakup_seed_bitfield']:
                    bitfield, msgs = storage.get_have_list_cloaked()
                    connection.send_bitfield(bitfield)
                    for have in msgs:
                        connection.send_have(have)
                else:
                    connection.send_bitfield(storage.get_have_list())
        else:
            if storage.do_I_have_anything():
                connection.send_bitfield(storage.get_have_list())
        self.piecedl = None
        self.piecebuf = None

    def got_not_interested(self):
        if self.interested:
            self.interested = False
            del self.buffer[:]
            self.piecedl = None
            if self.piecebuf:
                self.piecebuf.release()
            self.piecebuf = None
            self.choker.not_interested(self.connection)

    def got_interested(self):
        if not self.interested:
            self.interested = True
            self.was_ever_interested = True
            self.choker.interested(self.connection)

    def get_upload_chunk(self):
        if self.choked or not self.buffer:
            return None
        index, begin, length = self.buffer.pop(0)
        if self.config['buffer_reads']:
            if index != self.piecedl:
                if self.piecebuf:
                    self.piecebuf.release()
                self.piecedl = index
                self.piecebuf = self.storage.get_piece(index, 0, -1)
            try:
                piece = self.piecebuf[begin:begin + length]
                assert len(piece) == length
            except (AssertionError, AttributeError):
                # fails if storage.get_piece returns None or if out of range
                self.connection.close()
                return None
        else:
            if self.piecebuf:
                self.piecebuf.release()
                self.piecedl = None
            piece = self.storage.get_piece(index, begin, length)
            if piece is None:
                self.connection.close()
                return None
        self.measure.update_rate(len(piece))
        self.totalup.update_rate(len(piece))
        return (index, begin, piece)

    def got_request(self, index, begin, length):
        if self.super_seeding and index not in self.seed_have_list or \
                not self.interested or length > self.max_slice_length:
            self.connection.close()
            return
        if not self.cleared:
            self.buffer.append((index, begin, length))
        if not self.choked and self.connection.next_upload is None:
                self.ratelimiter.queue(self.connection)

    def got_cancel(self, index, begin, length):
        try:
            self.buffer.remove((index, begin, length))
        except ValueError:
            pass

    def choke(self):
        if not self.choked:
            self.choked = True
            self.connection.send_choke()
        self.piecedl = None
        if self.piecebuf:
            self.piecebuf.release()
            self.piecebuf = None

    def choke_sent(self):
        del self.buffer[:]
        self.cleared = True

    def unchoke(self):
        if self.choked:
            self.choked = False
            self.cleared = False
            self.connection.send_unchoke()

    def disconnected(self):
        if self.piecebuf:
            self.piecebuf.release()
            self.piecebuf = None

    def is_choked(self):
        return self.choked

    def is_interested(self):
        return self.interested

    def has_queries(self):
        return not self.choked and len(self.buffer) > 0

    def get_rate(self):
        return self.measure.get_rate()
","
1from .CurrentRateMeasure import Measure
2
3
4class Upload:
5    def __init__(self, connection, ratelimiter, totalup, choker, storage,
6                 picker, config):
7        self.connection = connection
8        self.ratelimiter = ratelimiter
9        self.totalup = totalup
10        self.choker = choker
11        self.storage = storage
12        self.picker = picker
13        self.config = config
14        self.max_slice_length = config['max_slice_length']
15        self.choked = True
16        self.cleared = True
17        self.interested = False
18        self.super_seeding = False
19        self.buffer = []
20        self.measure = Measure(config['max_rate_period'],
21                               config['upload_rate_fudge'])
22        self.was_ever_interested = False
23        if storage.get_amount_left() == 0:
24            if choker.super_seed:
25                self.super_seeding = True   # flag, and don't send bitfield
26                self.seed_have_list = []    # set from piecepicker
27                self.skipped_count = 0
28            else:
29                if config['breakup_seed_bitfield']:
30                    bitfield, msgs = storage.get_have_list_cloaked()
31                    connection.send_bitfield(bitfield)
32                    for have in msgs:
33                        connection.send_have(have)
34                else:
35                    connection.send_bitfield(storage.get_have_list())
36        else:
37            if storage.do_I_have_anything():
38                connection.send_bitfield(storage.get_have_list())
39        self.piecedl = None
40        self.piecebuf = None
41
42    def got_not_interested(self):
43        if self.interested:
44            self.interested = False
45            del self.buffer[:]
46            self.piecedl = None
47            if self.piecebuf:
48                self.piecebuf.release()
49            self.piecebuf = None
50            self.choker.not_interested(self.connection)
51
52    def got_interested(self):
53        if not self.interested:
54            self.interested = True
55            self.was_ever_interested = True
56            self.choker.interested(self.connection)
57
58    def get_upload_chunk(self):
59        if self.choked or not self.buffer:
60            return None
61        index, begin, length = self.buffer.pop(0)
62        if self.config['buffer_reads']:
63            if index != self.piecedl:
64                if self.piecebuf:
65                    self.piecebuf.release()
66                self.piecedl = index
67                self.piecebuf = self.storage.get_piece(index, 0, -1)
68            try:
69                piece = self.piecebuf[begin:begin + length]
70            except (AssertionError, AttributeError):
71                # fails if storage.get_piece returns None or if out of range
72                self.connection.close()
73                return None
74        else:
75            if self.piecebuf:
76                self.piecebuf.release()
77                self.piecedl = None
78            piece = self.storage.get_piece(index, begin, length)
79            if piece is None:
80                self.connection.close()
81                return None
82        self.measure.update_rate(len(piece))
83        self.totalup.update_rate(len(piece))
84        return (index, begin, piece)
85
86    def got_request(self, index, begin, length):
87        if self.super_seeding and index not in self.seed_have_list or \
88                not self.interested or length > self.max_slice_length:
89            self.connection.close()
90            return
91        if not self.cleared:
92            self.buffer.append((index, begin, length))
93        if not self.choked and self.connection.next_upload is None:
94                self.ratelimiter.queue(self.connection)
95
96    def got_cancel(self, index, begin, length):
97        try:
98            self.buffer.remove((index, begin, length))
99        except ValueError:
100            pass
101
102    def choke(self):
103        if not self.choked:
104            self.choked = True
105            self.connection.send_choke()
106        self.piecedl = None
107        if self.piecebuf:
108            self.piecebuf.release()
109            self.piecebuf = None
110
111    def choke_sent(self):
112        del self.buffer[:]
113        self.cleared = True
114
115    def unchoke(self):
116        if self.choked:
117            self.choked = False
118            self.cleared = False
119            self.connection.send_unchoke()
120
121    def disconnected(self):
122        if self.piecebuf:
123            self.piecebuf.release()
124            self.piecebuf = None
125
126    def is_choked(self):
127        return self.choked
128
129    def is_interested(self):
130        return self.interested
131
132    def has_queries(self):
133        return not self.choked and len(self.buffer) > 0
134
135    def get_rate(self):
136        return self.measure.get_rate()
137","[['len(piece)', '==', 'length']]",1,1,1.0,0.0002122241086587,"['connection', 'ratelimiter', 'totalup', 'choker', 'storage', 'self.connection', 'self.ratelimiter', 'self.totalup', 'self.choker', 'self.storage', 'self.picker', 'self.config', 'self.max_slice_length', 'self.choked', 'self.cleared', 'self.interested', 'self.super_seeding', 'self.buffer', 'self.measure', 'self.was_ever_interested', 'self.seed_have_list', 'self.skipped_count', 'bitfield', 'msgs', 'self.piecedl', 'self.piecebuf', 'index', 'begin', 'length', 'piece']",30,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['connection', 'ratelimiter', 'totalup', 'choker', 'storage', 'self.connection', 'self.ratelimiter', 'self.totalup', 'self.choker', 'self.storage', 'self.picker', 'self.config', 'self.max_slice_length', 'self.choked', 'self.cleared', 'self.interested', 'self.super_seeding', 'self.buffer', 'self.measure', 'self.was_ever_interested', 'self.seed_have_list', 'self.skipped_count', 'bitfield', 'msgs', 'self.piecedl', 'self.piecebuf', 'index', 'begin', 'length', 'piece']
*Code:

1from .CurrentRateMeasure import Measure
2
3
4class Upload:
5    def __init__(self, connection, ratelimiter, totalup, choker, storage,
6                 picker, config):
7        self.connection = connection
8        self.ratelimiter = ratelimiter
9        self.totalup = totalup
10        self.choker = choker
11        self.storage = storage
12        self.picker = picker
13        self.config = config
14        self.max_slice_length = config['max_slice_length']
15        self.choked = True
16        self.cleared = True
17        self.interested = False
18        self.super_seeding = False
19        self.buffer = []
20        self.measure = Measure(config['max_rate_period'],
21                               config['upload_rate_fudge'])
22        self.was_ever_interested = False
23        if storage.get_amount_left() == 0:
24            if choker.super_seed:
25                self.super_seeding = True   # flag, and don't send bitfield
26                self.seed_have_list = []    # set from piecepicker
27                self.skipped_count = 0
28            else:
29                if config['breakup_seed_bitfield']:
30                    bitfield, msgs = storage.get_have_list_cloaked()
31                    connection.send_bitfield(bitfield)
32                    for have in msgs:
33                        connection.send_have(have)
34                else:
35                    connection.send_bitfield(storage.get_have_list())
36        else:
37            if storage.do_I_have_anything():
38                connection.send_bitfield(storage.get_have_list())
39        self.piecedl = None
40        self.piecebuf = None
41
42    def got_not_interested(self):
43        if self.interested:
44            self.interested = False
45            del self.buffer[:]
46            self.piecedl = None
47            if self.piecebuf:
48                self.piecebuf.release()
49            self.piecebuf = None
50            self.choker.not_interested(self.connection)
51
52    def got_interested(self):
53        if not self.interested:
54            self.interested = True
55            self.was_ever_interested = True
56            self.choker.interested(self.connection)
57
58    def get_upload_chunk(self):
59        if self.choked or not self.buffer:
60            return None
61        index, begin, length = self.buffer.pop(0)
62        if self.config['buffer_reads']:
63            if index != self.piecedl:
64                if self.piecebuf:
65                    self.piecebuf.release()
66                self.piecedl = index
67                self.piecebuf = self.storage.get_piece(index, 0, -1)
68            try:
69                piece = self.piecebuf[begin:begin + length]
70            except (AssertionError, AttributeError):
71                # fails if storage.get_piece returns None or if out of range
72                self.connection.close()
73                return None
74        else:
75            if self.piecebuf:
76                self.piecebuf.release()
77                self.piecedl = None
78            piece = self.storage.get_piece(index, begin, length)
79            if piece is None:
80                self.connection.close()
81                return None
82        self.measure.update_rate(len(piece))
83        self.totalup.update_rate(len(piece))
84        return (index, begin, piece)
85
86    def got_request(self, index, begin, length):
87        if self.super_seeding and index not in self.seed_have_list or \
88                not self.interested or length > self.max_slice_length:
89            self.connection.close()
90            return
91        if not self.cleared:
92            self.buffer.append((index, begin, length))
93        if not self.choked and self.connection.next_upload is None:
94                self.ratelimiter.queue(self.connection)
95
96    def got_cancel(self, index, begin, length):
97        try:
98            self.buffer.remove((index, begin, length))
99        except ValueError:
100            pass
101
102    def choke(self):
103        if not self.choked:
104            self.choked = True
105            self.connection.send_choke()
106        self.piecedl = None
107        if self.piecebuf:
108            self.piecebuf.release()
109            self.piecebuf = None
110
111    def choke_sent(self):
112        del self.buffer[:]
113        self.cleared = True
114
115    def unchoke(self):
116        if self.choked:
117            self.choked = False
118            self.cleared = False
119            self.connection.send_unchoke()
120
121    def disconnected(self):
122        if self.piecebuf:
123            self.piecebuf.release()
124            self.piecebuf = None
125
126    def is_choked(self):
127        return self.choked
128
129    def is_interested(self):
130        return self.interested
131
132    def has_queries(self):
133        return not self.choked and len(self.buffer) > 0
134
135    def get_rate(self):
136        return self.measure.get_rate()
137",6820,"[[6, 'connection', '!=', None, ""connection can't be None for the class Upload to work""],
 [6, 'ratelimiter', '!=', None, ""ratelimiter can't be None for the class Upload to work""],
 [6, 'totalup', '!=', None, ""totalup can't be None for the class Upload to work""],
 [6, 'choker', '!=', None, ""choker can't be None for the class Upload to work""],
 [6, 'storage', '!=', None, ""storage can't be None for the class Upload to work""],
 [6, 'picker', '!=', None, ""picker can't be None for the class Upload to work""],
 [6, 'config', '!=', None, ""config can't be None for the class Upload to work""],
 [14, 'self.max_slice_length', '>=', 0, ""max_slice_length should be non negative""],
 [81, 'len(piece)', '>', 0, ""Length of uploaded piece should always be more than zero""],
 [86, 'length', '<=', 'self.max_slice_length', ""requested length shouldn't be more than max_slice_length""],
 [86, 'length', '>=', 0, ""requested length should be non negative""],
 [86, 'index', '>=', 0, ""index should be non negative""],
 [86, 'begin', '>=', 0, ""begin should be non negative""],
 [96, 'length', '<=', 'self.max_slice_length', ""cancel length shouldn't be more than max_slice_length""],
 [96, 'length', '>=', 0, ""cancel length should be non negative""],
 [96, 'index', '>=', 0, ""index should be non negative""],
 [96, 'begin', '>=', 0, ""begin should be non negative""]]"
fbradyirl/home-assistant,"""""""The tests for the Logger component.""""""
from collections import namedtuple
import logging
import unittest

from homeassistant.setup import setup_component
from homeassistant.components import logger

from tests.common import get_test_home_assistant

RECORD = namedtuple(""record"", (""name"", ""levelno""))

NO_DEFAULT_CONFIG = {""logger"": {}}
NO_LOGS_CONFIG = {""logger"": {""default"": ""info""}}
TEST_CONFIG = {""logger"": {""default"": ""warning"", ""logs"": {""test"": ""info""}}}


class TestUpdater(unittest.TestCase):
    """"""Test logger component.""""""

    def setUp(self):
        """"""Set up things to be run when tests are started.""""""
        self.hass = get_test_home_assistant()
        self.log_filter = None

    def tearDown(self):
        """"""Stop everything that was started.""""""
        del logging.root.handlers[-1]
        self.hass.stop()

    def setup_logger(self, config):
        """"""Set up logger and save log filter.""""""
        setup_component(self.hass, logger.DOMAIN, config)
        self.log_filter = logging.root.handlers[-1].filters[0]

    def assert_logged(self, name, level):
        """"""Assert that a certain record was logged.""""""
        assert self.log_filter.filter(RECORD(name, level))

    def assert_not_logged(self, name, level):
        """"""Assert that a certain record was not logged.""""""
        assert not self.log_filter.filter(RECORD(name, level))

    def test_logger_setup(self):
        """"""Use logger to create a logging filter.""""""
        self.setup_logger(TEST_CONFIG)

        assert len(logging.root.handlers) > 0
        handler = logging.root.handlers[-1]

        assert len(handler.filters) == 1
        log_filter = handler.filters[0].logfilter

        assert log_filter[""default""] == logging.WARNING
        assert log_filter[""logs""][""test""] == logging.INFO

    def test_logger_test_filters(self):
        """"""Test resulting filter operation.""""""
        self.setup_logger(TEST_CONFIG)

        # Blocked default record
        self.assert_not_logged(""asdf"", logging.DEBUG)

        # Allowed default record
        self.assert_logged(""asdf"", logging.WARNING)

        # Blocked named record
        self.assert_not_logged(""test"", logging.DEBUG)

        # Allowed named record
        self.assert_logged(""test"", logging.INFO)

    def test_set_filter_empty_config(self):
        """"""Test change log level from empty configuration.""""""
        self.setup_logger(NO_LOGS_CONFIG)

        self.assert_not_logged(""test"", logging.DEBUG)

        self.hass.services.call(logger.DOMAIN, ""set_level"", {""test"": ""debug""})
        self.hass.block_till_done()

        self.assert_logged(""test"", logging.DEBUG)

    def test_set_filter(self):
        """"""Test change log level of existing filter.""""""
        self.setup_logger(TEST_CONFIG)

        self.assert_not_logged(""asdf"", logging.DEBUG)
        self.assert_logged(""dummy"", logging.WARNING)

        self.hass.services.call(
            logger.DOMAIN, ""set_level"", {""asdf"": ""debug"", ""dummy"": ""info""}
        )
        self.hass.block_till_done()

        self.assert_logged(""asdf"", logging.DEBUG)
        self.assert_logged(""dummy"", logging.WARNING)

    def test_set_default_filter_empty_config(self):
        """"""Test change default log level from empty configuration.""""""
        self.setup_logger(NO_DEFAULT_CONFIG)

        self.assert_logged(""test"", logging.DEBUG)

        self.hass.services.call(
            logger.DOMAIN, ""set_default_level"", {""level"": ""warning""}
        )
        self.hass.block_till_done()

        self.assert_not_logged(""test"", logging.DEBUG)

    def test_set_default_filter(self):
        """"""Test change default log level with existing default.""""""
        self.setup_logger(TEST_CONFIG)

        self.assert_not_logged(""asdf"", logging.DEBUG)
        self.assert_logged(""dummy"", logging.WARNING)

        self.hass.services.call(logger.DOMAIN, ""set_default_level"", {""level"": ""debug""})
        self.hass.block_till_done()

        self.assert_logged(""asdf"", logging.DEBUG)
        self.assert_logged(""dummy"", logging.WARNING)
","
1""""""The tests for the Logger component.""""""
2from collections import namedtuple
3import logging
4import unittest
5
6from homeassistant.setup import setup_component
7from homeassistant.components import logger
8
9from tests.common import get_test_home_assistant
10
11RECORD = namedtuple(""record"", (""name"", ""levelno""))
12
13NO_DEFAULT_CONFIG = {""logger"": {}}
14NO_LOGS_CONFIG = {""logger"": {""default"": ""info""}}
15TEST_CONFIG = {""logger"": {""default"": ""warning"", ""logs"": {""test"": ""info""}}}
16
17
18class TestUpdater(unittest.TestCase):
19    """"""Test logger component.""""""
20
21    def setUp(self):
22        """"""Set up things to be run when tests are started.""""""
23        self.hass = get_test_home_assistant()
24        self.log_filter = None
25
26    def tearDown(self):
27        """"""Stop everything that was started.""""""
28        del logging.root.handlers[-1]
29        self.hass.stop()
30
31    def setup_logger(self, config):
32        """"""Set up logger and save log filter.""""""
33        setup_component(self.hass, logger.DOMAIN, config)
34        self.log_filter = logging.root.handlers[-1].filters[0]
35
36        """"""Assert that a certain record was logged.""""""
37
38        """"""Assert that a certain record was not logged.""""""
39
40    def test_logger_setup(self):
41        """"""Use logger to create a logging filter.""""""
42        self.setup_logger(TEST_CONFIG)
43
44        handler = logging.root.handlers[-1]
45
46        log_filter = handler.filters[0].logfilter
47
48
49    def test_logger_test_filters(self):
50        """"""Test resulting filter operation.""""""
51        self.setup_logger(TEST_CONFIG)
52
53        # Blocked default record
54
55        # Allowed default record
56
57        # Blocked named record
58
59        # Allowed named record
60
61    def test_set_filter_empty_config(self):
62        """"""Test change log level from empty configuration.""""""
63        self.setup_logger(NO_LOGS_CONFIG)
64
65
66        self.hass.services.call(logger.DOMAIN, ""set_level"", {""test"": ""debug""})
67        self.hass.block_till_done()
68
69
70    def test_set_filter(self):
71        """"""Test change log level of existing filter.""""""
72        self.setup_logger(TEST_CONFIG)
73
74
75        self.hass.services.call(
76            logger.DOMAIN, ""set_level"", {""asdf"": ""debug"", ""dummy"": ""info""}
77        )
78        self.hass.block_till_done()
79
80
81    def test_set_default_filter_empty_config(self):
82        """"""Test change default log level from empty configuration.""""""
83        self.setup_logger(NO_DEFAULT_CONFIG)
84
85
86        self.hass.services.call(
87            logger.DOMAIN, ""set_default_level"", {""level"": ""warning""}
88        )
89        self.hass.block_till_done()
90
91
92    def test_set_default_filter(self):
93        """"""Test change default log level with existing default.""""""
94        self.setup_logger(TEST_CONFIG)
95
96
97        self.hass.services.call(logger.DOMAIN, ""set_default_level"", {""level"": ""debug""})
98        self.hass.block_till_done()
99
100","[['self.log_filter.filter(RECORD(name', '==', 'True'], ['self.log_filter.filter(RECORD(name', '==', 'False'], ['len(logging.root.h', '==', 'True'], ['lers)', '>', '0'], ['len(h', '==', 'True'], ['ler.filters)', '==', '1'], ['log_filter[""default""]', '==', 'logging.WARNING'], ['log_filter[""logs""][""test""]', '==', 'logging.INFO']]",24,8,0.3333333333333333,0.0019856043683296,"['RECORD', 'NO_DEFAULT_CONFIG', 'NO_LOGS_CONFIG', 'TEST_CONFIG', 'self.hass', 'self.log_filter', 'config', 'name', 'level', 'handler', 'log_filter']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['RECORD', 'NO_DEFAULT_CONFIG', 'NO_LOGS_CONFIG', 'TEST_CONFIG', 'self.hass', 'self.log_filter', 'config', 'name', 'level', 'handler', 'log_filter']
*Code:

1""""""The tests for the Logger component.""""""
2from collections import namedtuple
3import logging
4import unittest
5
6from homeassistant.setup import setup_component
7from homeassistant.components import logger
8
9from tests.common import get_test_home_assistant
10
11RECORD = namedtuple(""record"", (""name"", ""levelno""))
12
13NO_DEFAULT_CONFIG = {""logger"": {}}
14NO_LOGS_CONFIG = {""logger"": {""default"": ""info""}}
15TEST_CONFIG = {""logger"": {""default"": ""warning"", ""logs"": {""test"": ""info""}}}
16
17
18class TestUpdater(unittest.TestCase):
19    """"""Test logger component.""""""
20
21    def setUp(self):
22        """"""Set up things to be run when tests are started.""""""
23        self.hass = get_test_home_assistant()
24        self.log_filter = None
25
26    def tearDown(self):
27        """"""Stop everything that was started.""""""
28        del logging.root.handlers[-1]
29        self.hass.stop()
30
31    def setup_logger(self, config):
32        """"""Set up logger and save log filter.""""""
33        setup_component(self.hass, logger.DOMAIN, config)
34        self.log_filter = logging.root.handlers[-1].filters[0]
35
36        """"""Assert that a certain record was logged.""""""
37
38        """"""Assert that a certain record was not logged.""""""
39
40    def test_logger_setup(self):
41        """"""Use logger to create a logging filter.""""""
42        self.setup_logger(TEST_CONFIG)
43
44        handler = logging.root.handlers[-1]
45
46        log_filter = handler.filters[0].logfilter
47
48
49    def test_logger_test_filters(self):
50        """"""Test resulting filter operation.""""""
51        self.setup_logger(TEST_CONFIG)
52
53        # Blocked default record
54
55        # Allowed default record
56
57        # Blocked named record
58
59        # Allowed named record
60
61    def test_set_filter_empty_config(self):
62        """"""Test change log level from empty configuration.""""""
63        self.setup_logger(NO_LOGS_CONFIG)
64
65
66        self.hass.services.call(logger.DOMAIN, ""set_level"", {""test"": ""debug""})
67        self.hass.block_till_done()
68
69
70    def test_set_filter(self):
71        """"""Test change log level of existing filter.""""""
72        self.setup_logger(TEST_CONFIG)
73
74
75        self.hass.services.call(
76            logger.DOMAIN, ""set_level"", {""asdf"": ""debug"", ""dummy"": ""info""}
77        )
78        self.hass.block_till_done()
79
80
81    def test_set_default_filter_empty_config(self):
82        """"""Test change default log level from empty configuration.""""""
83        self.setup_logger(NO_DEFAULT_CONFIG)
84
85
86        self.hass.services.call(
87            logger.DOMAIN, ""set_default_level"", {""level"": ""warning""}
88        )
89        self.hass.block_till_done()
90
91
92    def test_set_default_filter(self):
93        """"""Test change default log level with existing default.""""""
94        self.setup_logger(TEST_CONFIG)
95
96
97        self.hass.services.call(logger.DOMAIN, ""set_default_level"", {""level"": ""debug""})
98        self.hass.block_till_done()
99
100",4502,"[[23, 'self.hass', '!=', None, ""Home assistant instance should exist before starting tests""],
[24, 'self.log_filter', '==', None, ""Log filter should be None initially""],
[32, 'config', '!=', None, ""Configuration should be available for setting up logger""],
[33, 'self.hass', '!=', None, ""Home assistant instance should be available for setting up logger""],
[34, 'self.log_filter', '!=', None, ""Log filter should be set after setup""],
[44, 'handler', '!=', None, ""Handler should be defined after logger setup""],
[66, 'self.hass', '!=', None, ""Home assistant instance should exist before making service calls""],
[76, 'self.hass', '!=', None, ""Home assistant instance should exist before making service calls""],
[86, 'self.hass', '!=', None, ""Home assistant instance should exist before making service calls""],
[97, 'self.hass', '!=', None, ""Home assistant instance should exist before making service calls""]]"
rishita/mxnet,"import numpy as np
import mxnet as mx

def reldiff(a, b):
    diff = np.sum(np.abs(a - b))
    norm = np.sum(np.abs(a))
    if diff == 0:
        return 0
    reldiff = diff  / norm
    return reldiff

def test_chain():
    n = 2
    data1 = mx.sym.Variable('data1')
    data2 = mx.sym.Variable('data2')
    with mx.AttrScope(ctx_group='dev1'):
        net = data1 + data2
        net = net * 3

    with mx.AttrScope(ctx_group='dev2'):
        net = net + data1

    with mx.Context(mx.cpu(0)):
        shape = (4, 5)
        arr = [mx.nd.empty(shape) for i in range(n)]
        arr_grad = [mx.nd.empty(shape) for i in range(n)]

    exec1 = net.bind(mx.cpu(),
                     args=arr,
                     args_grad=arr_grad,
                     group2ctx={'dev1': mx.cpu(0), 'dev2': mx.cpu(1)})
    arr[0][:] = 1.0
    arr[1][:] = 2.0
    arr2 = [a.copyto(mx.cpu()) for a in arr]
    arr_grad2 = [a.copyto(mx.cpu()) for a in arr_grad]
    exec2 = net.bind(mx.cpu(),
                     args=arr2,
                     args_grad=arr_grad2)

    # Show the execution plan that involves copynode
    print(exec1.debug_str())
    exec1.forward()
    exec2.forward()
    assert reldiff(exec1.outputs[0].asnumpy(), exec2.outputs[0].asnumpy()) < 1e-6
    out_grad = mx.nd.empty(shape, mx.cpu(1))
    out_grad[:] = 1.0
    exec1.backward([out_grad])
    exec2.backward([out_grad.copyto(mx.cpu())])
    for a, b in zip(arr_grad, arr_grad2):
        assert reldiff(a.asnumpy(), b.asnumpy()) < 1e-6


if __name__ == '__main__':
    test_chain()
","
1import numpy as np
2import mxnet as mx
3
4def reldiff(a, b):
5    diff = np.sum(np.abs(a - b))
6    norm = np.sum(np.abs(a))
7    if diff == 0:
8        return 0
9    reldiff = diff  / norm
10    return reldiff
11
12def test_chain():
13    n = 2
14    data1 = mx.sym.Variable('data1')
15    data2 = mx.sym.Variable('data2')
16    with mx.AttrScope(ctx_group='dev1'):
17        net = data1 + data2
18        net = net * 3
19
20    with mx.AttrScope(ctx_group='dev2'):
21        net = net + data1
22
23    with mx.Context(mx.cpu(0)):
24        shape = (4, 5)
25        arr = [mx.nd.empty(shape) for i in range(n)]
26        arr_grad = [mx.nd.empty(shape) for i in range(n)]
27
28    exec1 = net.bind(mx.cpu(),
29                     args=arr,
30                     args_grad=arr_grad,
31                     group2ctx={'dev1': mx.cpu(0), 'dev2': mx.cpu(1)})
32    arr[0][:] = 1.0
33    arr[1][:] = 2.0
34    arr2 = [a.copyto(mx.cpu()) for a in arr]
35    arr_grad2 = [a.copyto(mx.cpu()) for a in arr_grad]
36    exec2 = net.bind(mx.cpu(),
37                     args=arr2,
38                     args_grad=arr_grad2)
39
40    # Show the execution plan that involves copynode
41    print(exec1.debug_str())
42    exec1.forward()
43    exec2.forward()
44    out_grad = mx.nd.empty(shape, mx.cpu(1))
45    out_grad[:] = 1.0
46    exec1.backward([out_grad])
47    exec2.backward([out_grad.copyto(mx.cpu())])
48    for a, b in zip(arr_grad, arr_grad2):
49
50
51if __name__ == '__main__':
52    test_chain()
53","[['reldiff(exec1.outputs[0].asnumpy()', '==', 'True'], ['reldiff(a.asnumpy()', '==', 'True']]",2,2,1.0,0.001294498381877,"['a', 'b', 'diff', 'norm', 'reldiff', 'n', 'data1', 'data2', 'net', 'shape', 'arr', 'arr_grad', 'exec1', 'arr[0][:]', 'arr[1][:]', 'arr2', 'arr_grad2', 'exec2', 'out_grad', 'out_grad[:]']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['a', 'b', 'diff', 'norm', 'reldiff', 'n', 'data1', 'data2', 'net', 'shape', 'arr', 'arr_grad', 'exec1', 'arr[0][:]', 'arr[1][:]', 'arr2', 'arr_grad2', 'exec2', 'out_grad', 'out_grad[:]']
*Code:

1import numpy as np
2import mxnet as mx
3
4def reldiff(a, b):
5    diff = np.sum(np.abs(a - b))
6    norm = np.sum(np.abs(a))
7    if diff == 0:
8        return 0
9    reldiff = diff  / norm
10    return reldiff
11
12def test_chain():
13    n = 2
14    data1 = mx.sym.Variable('data1')
15    data2 = mx.sym.Variable('data2')
16    with mx.AttrScope(ctx_group='dev1'):
17        net = data1 + data2
18        net = net * 3
19
20    with mx.AttrScope(ctx_group='dev2'):
21        net = net + data1
22
23    with mx.Context(mx.cpu(0)):
24        shape = (4, 5)
25        arr = [mx.nd.empty(shape) for i in range(n)]
26        arr_grad = [mx.nd.empty(shape) for i in range(n)]
27
28    exec1 = net.bind(mx.cpu(),
29                     args=arr,
30                     args_grad=arr_grad,
31                     group2ctx={'dev1': mx.cpu(0), 'dev2': mx.cpu(1)})
32    arr[0][:] = 1.0
33    arr[1][:] = 2.0
34    arr2 = [a.copyto(mx.cpu()) for a in arr]
35    arr_grad2 = [a.copyto(mx.cpu()) for a in arr_grad]
36    exec2 = net.bind(mx.cpu(),
37                     args=arr2,
38                     args_grad=arr_grad2)
39
40    # Show the execution plan that involves copynode
41    print(exec1.debug_str())
42    exec1.forward()
43    exec2.forward()
44    out_grad = mx.nd.empty(shape, mx.cpu(1))
45    out_grad[:] = 1.0
46    exec1.backward([out_grad])
47    exec2.backward([out_grad.copyto(mx.cpu())])
48    for a, b in zip(arr_grad, arr_grad2):
49
50
51if __name__ == '__main__':
52    test_chain()
53",3072,"[[4, 'a', '!=', None, ""The variable 'a' must not be None""], 
 [4, 'b', '!=', None, ""The variable 'b' must not be None""], 
 [13, 'n', '==', 2, ""'n' must always be 2 in this function""], 
 [24, 'shape', '==', (4, 5), ""Shape must always be (4, 5) for this function""], 
 [32, 'arr[0][:]', '!=', None, ""The elements of 'arr[0]' must not be None""], 
 [33, 'arr[1][:]', '!=', None, ""The elements of 'arr[1]' must not be None""], 
 [44, 'out_grad', '!=', None, ""'out_grad' must not be None""], 
 [48, 'a', '!=', None, ""'a' must not be None in the backward execution""], 
 [48, 'b', '!=', None, ""'b' must not be None in the backward execution""]]"
barentsen/surveytools,"""""""Tests the surveytools.footprint module.""""""
import numpy as np

from surveytools.footprint import VphasFootprint, VphasOffset

def test_vphas_offset_coordinates():
    """"""Test the offset pattern, which is expected to equal
    ra -0, dec +0 arcsec for the ""a"" pointing;
    ra -588, dec +660 arcsec for the ""b"" pointing;
    ra -300, dec +350 arcsec for the ""c"" pointing.
    """"""
    vf = VphasFootprint()
    np.testing.assert_almost_equal(vf.offsets['0001a']['ra'], 97.2192513369)
    np.testing.assert_almost_equal(vf.offsets['0001a']['dec'], 0)
    np.testing.assert_almost_equal(vf.offsets['0001b']['ra'], 97.2192513369 - 588/3600.)
    np.testing.assert_almost_equal(vf.offsets['0001b']['dec'], 0 + 660/3600.)
    np.testing.assert_almost_equal(vf.offsets['0001c']['ra'], 97.2192513369 - 300/3600.)
    np.testing.assert_almost_equal(vf.offsets['0001c']['dec'], 0 + 350/3600.)


def test_vphas_offset_pattern():
    vf = VphasFootprint()
    for field in ['0500', '1000', '2000']:
        ra, dec = vf.offsets[field+'a']['ra'], vf.offsets[field+'a']['dec']
        np.testing.assert_almost_equal(vf.offsets[field+'b']['ra'],
                                       ra - (588/3600.) / np.cos(np.radians(dec)))
        np.testing.assert_almost_equal(vf.offsets[field+'b']['dec'],
                                       dec + 660/3600.)
    

def test_vphas_filenames():
    """"""Ensure the right filename is returned for a given band/offset.""""""
    assert VphasOffset('1122a').image_filenames['ha'] == 'o20120330_00032.fit'
    assert VphasOffset('1122b').image_filenames['ha'] == 'o20120330_00034.fit'
    assert VphasOffset('1122c').image_filenames['ha'] == 'o20120330_00033.fit'
    assert VphasOffset('1842a').image_filenames['r'] == 'o20130314_00061.fit'
    assert VphasOffset('1842b').image_filenames['r'] == 'o20130314_00062.fit'
    assert VphasOffset('0765a').image_filenames['g'] == 'o20130413_00024.fit'
    assert VphasOffset('0765b').image_filenames['g'] == 'o20130413_00026.fit'
    assert VphasOffset('0765c').image_filenames['g'] == 'o20130413_00025.fit'


if __name__ == '__main__':
    test_vphas_filenames()","
1""""""Tests the surveytools.footprint module.""""""
2import numpy as np
3
4from surveytools.footprint import VphasFootprint, VphasOffset
5
6def test_vphas_offset_coordinates():
7    """"""Test the offset pattern, which is expected to equal
8    ra -0, dec +0 arcsec for the ""a"" pointing;
9    ra -588, dec +660 arcsec for the ""b"" pointing;
10    ra -300, dec +350 arcsec for the ""c"" pointing.
11    """"""
12    vf = VphasFootprint()
13
14
15def test_vphas_offset_pattern():
16    vf = VphasFootprint()
17    for field in ['0500', '1000', '2000']:
18        ra, dec = vf.offsets[field+'a']['ra'], vf.offsets[field+'a']['dec']
19                                       ra - (588/3600.) / np.cos(np.radians(dec)))
20                                       dec + 660/3600.)
21    
22
23def test_vphas_filenames():
24    """"""Ensure the right filename is returned for a given band/offset.""""""
25
26
27if __name__ == '__main__':
28    test_vphas_filenames()","[[""VphasOffset('1122a').image_filenames['ha']"", '==', ""'o20120330_00032.fit'""], [""VphasOffset('1122b').image_filenames['ha']"", '==', ""'o20120330_00034.fit'""], [""VphasOffset('1122c').image_filenames['ha']"", '==', ""'o20120330_00033.fit'""], [""VphasOffset('1842a').image_filenames['r']"", '==', ""'o20130314_00061.fit'""], [""VphasOffset('1842b').image_filenames['r']"", '==', ""'o20130314_00062.fit'""], [""VphasOffset('0765a').image_filenames['g']"", '==', ""'o20130413_00024.fit'""], [""VphasOffset('0765b').image_filenames['g']"", '==', ""'o20130413_00026.fit'""], [""VphasOffset('0765c').image_filenames['g']"", '==', ""'o20130413_00025.fit'""]]",16,8,0.5,0.0037558685446009,"['vf', 'ra', 'dec']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['vf', 'ra', 'dec']
*Code:

1""""""Tests the surveytools.footprint module.""""""
2import numpy as np
3
4from surveytools.footprint import VphasFootprint, VphasOffset
5
6def test_vphas_offset_coordinates():
7    """"""Test the offset pattern, which is expected to equal
8    ra -0, dec +0 arcsec for the ""a"" pointing;
9    ra -588, dec +660 arcsec for the ""b"" pointing;
10    ra -300, dec +350 arcsec for the ""c"" pointing.
11    """"""
12    vf = VphasFootprint()
13
14
15def test_vphas_offset_pattern():
16    vf = VphasFootprint()
17    for field in ['0500', '1000', '2000']:
18        ra, dec = vf.offsets[field+'a']['ra'], vf.offsets[field+'a']['dec']
19                                       ra - (588/3600.) / np.cos(np.radians(dec)))
20                                       dec + 660/3600.)
21    
22
23def test_vphas_filenames():
24    """"""Ensure the right filename is returned for a given band/offset.""""""
25
26
27if __name__ == '__main__':
28    test_vphas_filenames()",2336,"[[12, 'vf', '!=', None, ""VphasFootprint instance should not be None""], 
 [16, 'vf', '!=', None, ""VphasFootprint instance should not be None""], 
 [18, 'ra', '!=', None, ""RA coordinate should not be None""], 
 [18, 'dec', '!=', None, ""DEC coordinate should not be None""]]"
reahl/reahl,"# Copyright 2016-2021 Reahl Software Services (Pty) Ltd. All rights reserved.
#
#    This file is part of Reahl.
#
#    Reahl is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation; version 3 of the License.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.



from reahl.tofu import Fixture, uses
from reahl.tofu.pytestsupport import with_fixtures

from reahl.browsertools.browsertools import XPath

from reahl.component.modelinterface import ExposedNames, BooleanField

from reahl.web.bootstrap.ui import Div, P
from reahl.web.bootstrap.forms import Form, FormLayout, CheckboxInput
from reahl.web.bootstrap.popups import PopupA, CheckCheckboxScript

from reahl.web_dev.fixtures import WebFixture


@uses(web_fixture=WebFixture)
class PopupAFixture(Fixture):

    # (note that this xpath ensures that the p is the ONLY content of the dialog)
    poppedup_contents = ""//div[@class='modal-body' and count(*)=1]/p[@id='contents']""

    def is_popped_up(self):
        return self.web_fixture.driver_browser.is_visible(self.poppedup_contents)


@with_fixtures(WebFixture, PopupAFixture)
def test_default_behaviour(web_fixture, popup_a_fixture):
    """"""If you click on the A, a popupwindow opens with its contents the specified
       element on the target page.""""""

    class PopupTestPanel(Div):
        def __init__(self, view):
            super().__init__(view)
            self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
            popup_contents.set_id('contents')

    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
    web_fixture.reahl_server.set_app(wsgi_app)
    browser = web_fixture.driver_browser
    browser.open('/')

    # The A is rendered correctly
    assert browser.is_element_present(""//a[@title='Home page' and text()='Home page' and @href='/']"")

    # subsequent behaviour
    browser.click(XPath.link().with_text('Home page'))
    browser.wait_for(popup_a_fixture.is_popped_up)

    #check some bootstrap attributes
    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog']/div[@class='modal-content']""
    assert browser.is_element_present(dialog_xpath)

    browser.click(XPath.button_labelled('Close'))
    browser.wait_for_not(popup_a_fixture.is_popped_up)


@with_fixtures(WebFixture, PopupAFixture)
def test_customising_dialog_buttons(web_fixture, popup_a_fixture):
    """"""The buttons of the dialog can be customised.""""""

    class PopupTestPanel(Div):
        def __init__(self, view):
            super().__init__(view)
            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
            popup_a.add_js_button('Butt1')
            popup_a.add_js_button('Butt2')
            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
            popup_contents.set_id('contents')

    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
    web_fixture.reahl_server.set_app(wsgi_app)
    browser = web_fixture.driver_browser

    button1_xpath = XPath.button_labelled('Butt1')
    button2_xpath = XPath.button_labelled('Butt2')

    browser.open('/')

    browser.click(XPath.link().with_text('Home page'))
    browser.wait_for(popup_a_fixture.is_popped_up)

    assert browser.is_element_present(button1_xpath)
    assert browser.is_element_present(button2_xpath)


@with_fixtures(WebFixture, PopupAFixture)
def test_workings_of_check_checkbox_button(web_fixture, popup_a_fixture):
    """"""A CheckCheckBoxButton checks the checkbox on the original page when clicked.""""""

    class PopupTestPanel(Div):
        fields = ExposedNames()
        fields.field = lambda i: BooleanField(label='a checkbox')

        def __init__(self, view):
            super().__init__(view)
            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
            popup_contents.set_id('contents')
            form = self.add_child(Form(view, 'aform')).use_layout(FormLayout())
            checkbox = form.layout.add_input(CheckboxInput(form, self.fields.field))

            popup_a.add_js_button('Checkit', CheckCheckboxScript(checkbox))

    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
    web_fixture.reahl_server.set_app(wsgi_app)
    browser = web_fixture.driver_browser
    browser.open('/')

    browser.click(XPath.link().with_text('Home page'))
    browser.wait_for(popup_a_fixture.is_popped_up)

    browser.click(XPath.button_labelled('Checkit'))
    browser.wait_for_not(popup_a_fixture.is_popped_up)

    assert browser.is_selected(XPath.input_labelled('a checkbox'))


@with_fixtures(WebFixture, PopupAFixture)
def test_centering_dialog_vertically(web_fixture, popup_a_fixture):
    """"""The dialog can be centered vertically.""""""

    class PopupTestPanel(Div):
        def __init__(self, view):
            super().__init__(view)
            self.add_child(PopupA(view, view.as_bookmark(), '#contents', center_vertically=True))
            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
            popup_contents.set_id('contents')

    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
    web_fixture.reahl_server.set_app(wsgi_app)
    browser = web_fixture.driver_browser
    browser.open('/')

    browser.click(XPath.link().with_text('Home page'))
    browser.wait_for(popup_a_fixture.is_popped_up)

    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog modal-dialog-centered']/div[@class='modal-content']""
    assert browser.is_element_present(dialog_xpath)
","
1# Copyright 2016-2021 Reahl Software Services (Pty) Ltd. All rights reserved.
2#
3#    This file is part of Reahl.
4#
5#    Reahl is free software: you can redistribute it and/or modify
6#    it under the terms of the GNU Affero General Public License as
7#    published by the Free Software Foundation; version 3 of the License.
8#
9#    This program is distributed in the hope that it will be useful,
10#    but WITHOUT ANY WARRANTY; without even the implied warranty of
11#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12#    GNU Affero General Public License for more details.
13#
14#    You should have received a copy of the GNU Affero General Public License
15#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
16
17
18
19from reahl.tofu import Fixture, uses
20from reahl.tofu.pytestsupport import with_fixtures
21
22from reahl.browsertools.browsertools import XPath
23
24from reahl.component.modelinterface import ExposedNames, BooleanField
25
26from reahl.web.bootstrap.ui import Div, P
27from reahl.web.bootstrap.forms import Form, FormLayout, CheckboxInput
28from reahl.web.bootstrap.popups import PopupA, CheckCheckboxScript
29
30from reahl.web_dev.fixtures import WebFixture
31
32
33@uses(web_fixture=WebFixture)
34class PopupAFixture(Fixture):
35
36    # (note that this xpath ensures that the p is the ONLY content of the dialog)
37    poppedup_contents = ""//div[@class='modal-body' and count(*)=1]/p[@id='contents']""
38
39    def is_popped_up(self):
40        return self.web_fixture.driver_browser.is_visible(self.poppedup_contents)
41
42
43@with_fixtures(WebFixture, PopupAFixture)
44def test_default_behaviour(web_fixture, popup_a_fixture):
45    """"""If you click on the A, a popupwindow opens with its contents the specified
46       element on the target page.""""""
47
48    class PopupTestPanel(Div):
49        def __init__(self, view):
50            super().__init__(view)
51            self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
52            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
53            popup_contents.set_id('contents')
54
55    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
56    web_fixture.reahl_server.set_app(wsgi_app)
57    browser = web_fixture.driver_browser
58    browser.open('/')
59
60    # The A is rendered correctly
61
62    # subsequent behaviour
63    browser.click(XPath.link().with_text('Home page'))
64    browser.wait_for(popup_a_fixture.is_popped_up)
65
66    #check some bootstrap attributes
67    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog']/div[@class='modal-content']""
68
69    browser.click(XPath.button_labelled('Close'))
70    browser.wait_for_not(popup_a_fixture.is_popped_up)
71
72
73@with_fixtures(WebFixture, PopupAFixture)
74def test_customising_dialog_buttons(web_fixture, popup_a_fixture):
75    """"""The buttons of the dialog can be customised.""""""
76
77    class PopupTestPanel(Div):
78        def __init__(self, view):
79            super().__init__(view)
80            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
81            popup_a.add_js_button('Butt1')
82            popup_a.add_js_button('Butt2')
83            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
84            popup_contents.set_id('contents')
85
86    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
87    web_fixture.reahl_server.set_app(wsgi_app)
88    browser = web_fixture.driver_browser
89
90    button1_xpath = XPath.button_labelled('Butt1')
91    button2_xpath = XPath.button_labelled('Butt2')
92
93    browser.open('/')
94
95    browser.click(XPath.link().with_text('Home page'))
96    browser.wait_for(popup_a_fixture.is_popped_up)
97
98
99
100@with_fixtures(WebFixture, PopupAFixture)
101def test_workings_of_check_checkbox_button(web_fixture, popup_a_fixture):
102    """"""A CheckCheckBoxButton checks the checkbox on the original page when clicked.""""""
103
104    class PopupTestPanel(Div):
105        fields = ExposedNames()
106        fields.field = lambda i: BooleanField(label='a checkbox')
107
108        def __init__(self, view):
109            super().__init__(view)
110            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
111            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
112            popup_contents.set_id('contents')
113            form = self.add_child(Form(view, 'aform')).use_layout(FormLayout())
114            checkbox = form.layout.add_input(CheckboxInput(form, self.fields.field))
115
116            popup_a.add_js_button('Checkit', CheckCheckboxScript(checkbox))
117
118    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
119    web_fixture.reahl_server.set_app(wsgi_app)
120    browser = web_fixture.driver_browser
121    browser.open('/')
122
123    browser.click(XPath.link().with_text('Home page'))
124    browser.wait_for(popup_a_fixture.is_popped_up)
125
126    browser.click(XPath.button_labelled('Checkit'))
127    browser.wait_for_not(popup_a_fixture.is_popped_up)
128
129
130
131@with_fixtures(WebFixture, PopupAFixture)
132def test_centering_dialog_vertically(web_fixture, popup_a_fixture):
133    """"""The dialog can be centered vertically.""""""
134
135    class PopupTestPanel(Div):
136        def __init__(self, view):
137            super().__init__(view)
138            self.add_child(PopupA(view, view.as_bookmark(), '#contents', center_vertically=True))
139            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
140            popup_contents.set_id('contents')
141
142    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
143    web_fixture.reahl_server.set_app(wsgi_app)
144    browser = web_fixture.driver_browser
145    browser.open('/')
146
147    browser.click(XPath.link().with_text('Home page'))
148    browser.wait_for(popup_a_fixture.is_popped_up)
149
150    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog modal-dialog-centered']/div[@class='modal-content']""
151","[['browser.is_element_present(""//a[@title=\'Home', ""page'""], [""text()='Home"", ""page'""], ['@href=\'/\']"")', '==', 'True'], ['browser.is_element_present(dialog_xpath)', '==', 'True'], ['browser.is_element_present(button1_xpath)', '==', 'True'], ['browser.is_element_present(button2_xpath)', '==', 'True'], [""browser.is_selected(XPath.input_labelled('a"", ""checkbox'))""], ['browser.is_element_present(dialog_xpath)', '==', 'True']]",6,8,1.3333333333333333,0.0012616306576249,"['poppedup_contents', 'web_fixture', 'popup_a_fixture', 'view', 'popup_contents', 'wsgi_app', 'browser', 'dialog_xpath', 'popup_a', 'button1_xpath', 'button2_xpath', 'fields', 'fields.field', 'form', 'checkbox']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['poppedup_contents', 'web_fixture', 'popup_a_fixture', 'view', 'popup_contents', 'wsgi_app', 'browser', 'dialog_xpath', 'popup_a', 'button1_xpath', 'button2_xpath', 'fields', 'fields.field', 'form', 'checkbox']
*Code:

1# Copyright 2016-2021 Reahl Software Services (Pty) Ltd. All rights reserved.
2#
3#    This file is part of Reahl.
4#
5#    Reahl is free software: you can redistribute it and/or modify
6#    it under the terms of the GNU Affero General Public License as
7#    published by the Free Software Foundation; version 3 of the License.
8#
9#    This program is distributed in the hope that it will be useful,
10#    but WITHOUT ANY WARRANTY; without even the implied warranty of
11#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12#    GNU Affero General Public License for more details.
13#
14#    You should have received a copy of the GNU Affero General Public License
15#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
16
17
18
19from reahl.tofu import Fixture, uses
20from reahl.tofu.pytestsupport import with_fixtures
21
22from reahl.browsertools.browsertools import XPath
23
24from reahl.component.modelinterface import ExposedNames, BooleanField
25
26from reahl.web.bootstrap.ui import Div, P
27from reahl.web.bootstrap.forms import Form, FormLayout, CheckboxInput
28from reahl.web.bootstrap.popups import PopupA, CheckCheckboxScript
29
30from reahl.web_dev.fixtures import WebFixture
31
32
33@uses(web_fixture=WebFixture)
34class PopupAFixture(Fixture):
35
36    # (note that this xpath ensures that the p is the ONLY content of the dialog)
37    poppedup_contents = ""//div[@class='modal-body' and count(*)=1]/p[@id='contents']""
38
39    def is_popped_up(self):
40        return self.web_fixture.driver_browser.is_visible(self.poppedup_contents)
41
42
43@with_fixtures(WebFixture, PopupAFixture)
44def test_default_behaviour(web_fixture, popup_a_fixture):
45    """"""If you click on the A, a popupwindow opens with its contents the specified
46       element on the target page.""""""
47
48    class PopupTestPanel(Div):
49        def __init__(self, view):
50            super().__init__(view)
51            self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
52            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
53            popup_contents.set_id('contents')
54
55    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
56    web_fixture.reahl_server.set_app(wsgi_app)
57    browser = web_fixture.driver_browser
58    browser.open('/')
59
60    # The A is rendered correctly
61
62    # subsequent behaviour
63    browser.click(XPath.link().with_text('Home page'))
64    browser.wait_for(popup_a_fixture.is_popped_up)
65
66    #check some bootstrap attributes
67    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog']/div[@class='modal-content']""
68
69    browser.click(XPath.button_labelled('Close'))
70    browser.wait_for_not(popup_a_fixture.is_popped_up)
71
72
73@with_fixtures(WebFixture, PopupAFixture)
74def test_customising_dialog_buttons(web_fixture, popup_a_fixture):
75    """"""The buttons of the dialog can be customised.""""""
76
77    class PopupTestPanel(Div):
78        def __init__(self, view):
79            super().__init__(view)
80            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
81            popup_a.add_js_button('Butt1')
82            popup_a.add_js_button('Butt2')
83            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
84            popup_contents.set_id('contents')
85
86    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
87    web_fixture.reahl_server.set_app(wsgi_app)
88    browser = web_fixture.driver_browser
89
90    button1_xpath = XPath.button_labelled('Butt1')
91    button2_xpath = XPath.button_labelled('Butt2')
92
93    browser.open('/')
94
95    browser.click(XPath.link().with_text('Home page'))
96    browser.wait_for(popup_a_fixture.is_popped_up)
97
98
99
100@with_fixtures(WebFixture, PopupAFixture)
101def test_workings_of_check_checkbox_button(web_fixture, popup_a_fixture):
102    """"""A CheckCheckBoxButton checks the checkbox on the original page when clicked.""""""
103
104    class PopupTestPanel(Div):
105        fields = ExposedNames()
106        fields.field = lambda i: BooleanField(label='a checkbox')
107
108        def __init__(self, view):
109            super().__init__(view)
110            popup_a = self.add_child(PopupA(view, view.as_bookmark(), '#contents'))
111            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
112            popup_contents.set_id('contents')
113            form = self.add_child(Form(view, 'aform')).use_layout(FormLayout())
114            checkbox = form.layout.add_input(CheckboxInput(form, self.fields.field))
115
116            popup_a.add_js_button('Checkit', CheckCheckboxScript(checkbox))
117
118    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
119    web_fixture.reahl_server.set_app(wsgi_app)
120    browser = web_fixture.driver_browser
121    browser.open('/')
122
123    browser.click(XPath.link().with_text('Home page'))
124    browser.wait_for(popup_a_fixture.is_popped_up)
125
126    browser.click(XPath.button_labelled('Checkit'))
127    browser.wait_for_not(popup_a_fixture.is_popped_up)
128
129
130
131@with_fixtures(WebFixture, PopupAFixture)
132def test_centering_dialog_vertically(web_fixture, popup_a_fixture):
133    """"""The dialog can be centered vertically.""""""
134
135    class PopupTestPanel(Div):
136        def __init__(self, view):
137            super().__init__(view)
138            self.add_child(PopupA(view, view.as_bookmark(), '#contents', center_vertically=True))
139            popup_contents = self.add_child(P(view, text='this is the content of the popup'))
140            popup_contents.set_id('contents')
141
142    wsgi_app = web_fixture.new_wsgi_app(enable_js=True, child_factory=PopupTestPanel.factory())
143    web_fixture.reahl_server.set_app(wsgi_app)
144    browser = web_fixture.driver_browser
145    browser.open('/')
146
147    browser.click(XPath.link().with_text('Home page'))
148    browser.wait_for(popup_a_fixture.is_popped_up)
149
150    dialog_xpath = ""//div[@class='modal fade show' and @tabindex='-1']/div[@class='modal-dialog modal-dialog-centered']/div[@class='modal-content']""
151",7899,"[34, 'web_fixture', '!=', None, ""web_fixture should be defined for the functioning of the PopupAFixture""],
[49, 'view', '!=', None, ""view should be initialized for the PopupA to be created""],
[51, 'popup_a', '!=', None, ""popup_a variable should be initialized""],
[53, 'popup_contents', '!=', None, ""popup_contents variable should be initialized""],
[55, 'wsgi_app', '!=', None, ""wsgi_app should be initialized for the web_fixture""],
[78, 'view', '!=', None, ""view should be initialized for the PopupA to be created""],
[80, 'popup_a', '!=', None, ""popup_a created should not be null""],
[83, 'popup_contents', '!=', None, ""popup_contents should be initialized for the popup_a""],
[86, 'wsgi_app', '!=', None, ""wsgi_app should be initialized for the web_fixture""],
[104, 'fields', '!=', None, ""fields should be initialized""],
[109, 'view', '!=', None, ""view should be initialized for the PopupA to be created""],
[111, 'popup_contents', '!=', None, ""popup_contents should be initialized""],
[113, 'form', '!=', None, ""form should be initialized before adding into layout""],
[114, 'checkbox', '!=', None, ""checkbox should be initialized before passing to CheckCheckboxScript""],
[116, 'popup_a', '!=', None, ""popup_a created should not be null""],
[118, 'wsgi_app', '!=', None, ""wsgi_app should be initialized for the web_fixture""],
[136, 'view', '!=', None, ""view should be initialized for the PopupA to be created""],
[139, 'popup_contents', '!=', None, ""popup_contents should be initialized""],
[142, 'wsgi_app', '!=', None, ""wsgi_app should be initialized for the web_fixture""]"
shaunstanislaus/magic-wormhole,"from hashlib import sha256, sha1
import hmac
import six

def HKDF(SKM, dkLen, XTS=None, CTXinfo=b"""", digest=sha256,
         _test_expected_PRK=None):
    assert isinstance(SKM, six.binary_type)
    assert isinstance(XTS, (six.binary_type,type(None)))
    assert isinstance(CTXinfo, six.binary_type)
    hlen = len(digest(b"""").digest())
    assert dkLen <= hlen*255
    if XTS is None:
        XTS = b""\x00""*hlen
    # extract
    PRK = hmac.new(XTS, SKM, digest).digest()
    if _test_expected_PRK and _test_expected_PRK != PRK:
        raise ValueError(""test failed"")
    # expand
    blocks = []
    counter = 1
    t = b""""
    while hlen*len(blocks) < dkLen:
        t = hmac.new(PRK, t+CTXinfo+six.int2byte(counter), digest).digest()
        blocks.append(t)
        counter += 1
    return b"""".join(blocks)[:dkLen]

def power_on_self_test():
    from binascii import hexlify, unhexlify

    def _test(IKM, salt, info, L, PRK, OKM, digest=sha256):
        def remove_prefix(prefix, s):
            assert s.startswith(prefix)
            return s[len(prefix):]
        ikm = unhexlify(remove_prefix(""0x"", IKM))
        salt = unhexlify(remove_prefix(""0x"", salt))
        info = unhexlify(remove_prefix(""0x"", info))
        prk = unhexlify(remove_prefix(""0x"", PRK))
        okm = unhexlify(remove_prefix(""0x"", OKM))
        if digest is None:
            out = HKDF(ikm, L, salt, info, _test_expected_PRK=prk)
        else:
            out = HKDF(ikm, L, salt, info, digest=digest,
                       _test_expected_PRK=prk)
        if okm != out:
            raise ValueError(""got %s, expected %s"" % (hexlify(out), hexlify(okm)))

    # test vectors from RFC5869
    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
          salt=""0x000102030405060708090a0b0c"",
          info=""0xf0f1f2f3f4f5f6f7f8f9"",
          L=42,
          PRK=(""0x077709362c2e32df0ddc3f0dc47bba63""
               ""90b6c73bb50f9c3122ec844ad7c2b3e5""),
          OKM=(""0x3cb25f25faacd57a90434f64d0362f2a""
               ""2d2d0a90cf1a5a4c5db02d56ecc4c5bf""
               ""34007208d5b887185865""))

    _test(IKM=(""0x000102030405060708090a0b0c0d0e0f""
               ""101112131415161718191a1b1c1d1e1f""
               ""202122232425262728292a2b2c2d2e2f""
               ""303132333435363738393a3b3c3d3e3f""
               ""404142434445464748494a4b4c4d4e4f""),
          salt=(""0x606162636465666768696a6b6c6d6e6f""
                ""707172737475767778797a7b7c7d7e7f""
                ""808182838485868788898a8b8c8d8e8f""
                ""909192939495969798999a9b9c9d9e9f""
                ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
          info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
                ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
                ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
                ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
                ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
          L=82,
          PRK=(""0x06a6b88c5853361a06104c9ceb35b45c""
               ""ef760014904671014a193f40c15fc244""),
          OKM=(""0xb11e398dc80327a1c8e7f78c596a4934""
               ""4f012eda2d4efad8a050cc4c19afa97c""
               ""59045a99cac7827271cb41c65e590e09""
               ""da3275600c2f09b8367793a9aca3db71""
               ""cc30c58179ec3e87c14c01d5c1f3434f""
               ""1d87""))

    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
          salt=""0x"",
          info=""0x"",
          L=42,
          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
               ""96596776afdb6377ac434c1c293ccb04""),
          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
               ""9d201395faa4b61a96c8""))

    _test(digest=sha1,
          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b"",
          salt=""0x000102030405060708090a0b0c"",
          info=""0xf0f1f2f3f4f5f6f7f8f9"",
          L=42,
          PRK=""0x9b6c18c432a7bf8f0e71c8eb88f4b30baa2ba243"",
          OKM=(""0x085a01ea1b10f36933068b56efa5ad81""
               ""a4f14b822f5b091568a9cdd4f155fda2""
               ""c22e422478d305f3f896""))
    _test(digest=sha1,
       IKM=(""0x000102030405060708090a0b0c0d0e0f""
            ""101112131415161718191a1b1c1d1e1f""
            ""202122232425262728292a2b2c2d2e2f""
            ""303132333435363738393a3b3c3d3e3f""
            ""404142434445464748494a4b4c4d4e4f""),
       salt=(""0x606162636465666768696a6b6c6d6e6f""
             ""707172737475767778797a7b7c7d7e7f""
             ""808182838485868788898a8b8c8d8e8f""
             ""909192939495969798999a9b9c9d9e9f""
             ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
       info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
             ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
             ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
             ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
             ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
       L=82,
       PRK=""0x8adae09a2a307059478d309b26c4115a224cfaf6"",
       OKM=(""0x0bd770a74d1160f7c9f12cd5912a06eb""
            ""ff6adcae899d92191fe4305673ba2ffe""
            ""8fa3f1a4e5ad79f3f334b3b202b2173c""
            ""486ea37ce3d397ed034c7f9dfeb15c5e""
            ""927336d0441f4c4300e2cff0d0900b52""
            ""d3b4""))
    _test(digest=sha1,
          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
          salt=""0x"",
          info=""0x"",
          L=42,
          PRK=""0xda8c8a73c7fa77288ec6f5e7c297786aa0d32d01"",
          OKM=(""0x0ac1af7002b3d761d1e55298da9d0506""
               ""b9ae52057220a306e07b6b87e8df21d0""
               ""ea00033de03984d34918""))

    _test(digest=sha1,
          IKM=""0x0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c"",
          salt=""0x"",
          info=""0x"",
          L=42,
          PRK=""0x2adccada18779e7c2077ad2eb19d3f3e731385dd"",
          OKM=(""0x2c91117204d745f3500d636a62f64f0a""
               ""b3bae548aa53d423b0d1f27ebba6f5e5""
               ""673a081d70cce7acfc48""))

    # finally test that HKDF() without a digest= uses SHA256

    _test(digest=None,
          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
          salt=""0x"",
          info=""0x"",
          L=42,
          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
               ""96596776afdb6377ac434c1c293ccb04""),
          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
               ""9d201395faa4b61a96c8""))
    #print ""all test passed""

power_on_self_test()
","
1from hashlib import sha256, sha1
2import hmac
3import six
4
5def HKDF(SKM, dkLen, XTS=None, CTXinfo=b"""", digest=sha256,
6         _test_expected_PRK=None):
7    hlen = len(digest(b"""").digest())
8    if XTS is None:
9        XTS = b""\x00""*hlen
10    # extract
11    PRK = hmac.new(XTS, SKM, digest).digest()
12    if _test_expected_PRK and _test_expected_PRK != PRK:
13        raise ValueError(""test failed"")
14    # expand
15    blocks = []
16    counter = 1
17    t = b""""
18    while hlen*len(blocks) < dkLen:
19        t = hmac.new(PRK, t+CTXinfo+six.int2byte(counter), digest).digest()
20        blocks.append(t)
21        counter += 1
22    return b"""".join(blocks)[:dkLen]
23
24def power_on_self_test():
25    from binascii import hexlify, unhexlify
26
27    def _test(IKM, salt, info, L, PRK, OKM, digest=sha256):
28        def remove_prefix(prefix, s):
29            return s[len(prefix):]
30        ikm = unhexlify(remove_prefix(""0x"", IKM))
31        salt = unhexlify(remove_prefix(""0x"", salt))
32        info = unhexlify(remove_prefix(""0x"", info))
33        prk = unhexlify(remove_prefix(""0x"", PRK))
34        okm = unhexlify(remove_prefix(""0x"", OKM))
35        if digest is None:
36            out = HKDF(ikm, L, salt, info, _test_expected_PRK=prk)
37        else:
38            out = HKDF(ikm, L, salt, info, digest=digest,
39                       _test_expected_PRK=prk)
40        if okm != out:
41            raise ValueError(""got %s, expected %s"" % (hexlify(out), hexlify(okm)))
42
43    # test vectors from RFC5869
44    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
45          salt=""0x000102030405060708090a0b0c"",
46          info=""0xf0f1f2f3f4f5f6f7f8f9"",
47          L=42,
48          PRK=(""0x077709362c2e32df0ddc3f0dc47bba63""
49               ""90b6c73bb50f9c3122ec844ad7c2b3e5""),
50          OKM=(""0x3cb25f25faacd57a90434f64d0362f2a""
51               ""2d2d0a90cf1a5a4c5db02d56ecc4c5bf""
52               ""34007208d5b887185865""))
53
54    _test(IKM=(""0x000102030405060708090a0b0c0d0e0f""
55               ""101112131415161718191a1b1c1d1e1f""
56               ""202122232425262728292a2b2c2d2e2f""
57               ""303132333435363738393a3b3c3d3e3f""
58               ""404142434445464748494a4b4c4d4e4f""),
59          salt=(""0x606162636465666768696a6b6c6d6e6f""
60                ""707172737475767778797a7b7c7d7e7f""
61                ""808182838485868788898a8b8c8d8e8f""
62                ""909192939495969798999a9b9c9d9e9f""
63                ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
64          info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
65                ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
66                ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
67                ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
68                ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
69          L=82,
70          PRK=(""0x06a6b88c5853361a06104c9ceb35b45c""
71               ""ef760014904671014a193f40c15fc244""),
72          OKM=(""0xb11e398dc80327a1c8e7f78c596a4934""
73               ""4f012eda2d4efad8a050cc4c19afa97c""
74               ""59045a99cac7827271cb41c65e590e09""
75               ""da3275600c2f09b8367793a9aca3db71""
76               ""cc30c58179ec3e87c14c01d5c1f3434f""
77               ""1d87""))
78
79    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
80          salt=""0x"",
81          info=""0x"",
82          L=42,
83          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
84               ""96596776afdb6377ac434c1c293ccb04""),
85          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
86               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
87               ""9d201395faa4b61a96c8""))
88
89    _test(digest=sha1,
90          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b"",
91          salt=""0x000102030405060708090a0b0c"",
92          info=""0xf0f1f2f3f4f5f6f7f8f9"",
93          L=42,
94          PRK=""0x9b6c18c432a7bf8f0e71c8eb88f4b30baa2ba243"",
95          OKM=(""0x085a01ea1b10f36933068b56efa5ad81""
96               ""a4f14b822f5b091568a9cdd4f155fda2""
97               ""c22e422478d305f3f896""))
98    _test(digest=sha1,
99       IKM=(""0x000102030405060708090a0b0c0d0e0f""
100            ""101112131415161718191a1b1c1d1e1f""
101            ""202122232425262728292a2b2c2d2e2f""
102            ""303132333435363738393a3b3c3d3e3f""
103            ""404142434445464748494a4b4c4d4e4f""),
104       salt=(""0x606162636465666768696a6b6c6d6e6f""
105             ""707172737475767778797a7b7c7d7e7f""
106             ""808182838485868788898a8b8c8d8e8f""
107             ""909192939495969798999a9b9c9d9e9f""
108             ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
109       info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
110             ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
111             ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
112             ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
113             ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
114       L=82,
115       PRK=""0x8adae09a2a307059478d309b26c4115a224cfaf6"",
116       OKM=(""0x0bd770a74d1160f7c9f12cd5912a06eb""
117            ""ff6adcae899d92191fe4305673ba2ffe""
118            ""8fa3f1a4e5ad79f3f334b3b202b2173c""
119            ""486ea37ce3d397ed034c7f9dfeb15c5e""
120            ""927336d0441f4c4300e2cff0d0900b52""
121            ""d3b4""))
122    _test(digest=sha1,
123          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
124          salt=""0x"",
125          info=""0x"",
126          L=42,
127          PRK=""0xda8c8a73c7fa77288ec6f5e7c297786aa0d32d01"",
128          OKM=(""0x0ac1af7002b3d761d1e55298da9d0506""
129               ""b9ae52057220a306e07b6b87e8df21d0""
130               ""ea00033de03984d34918""))
131
132    _test(digest=sha1,
133          IKM=""0x0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c"",
134          salt=""0x"",
135          info=""0x"",
136          L=42,
137          PRK=""0x2adccada18779e7c2077ad2eb19d3f3e731385dd"",
138          OKM=(""0x2c91117204d745f3500d636a62f64f0a""
139               ""b3bae548aa53d423b0d1f27ebba6f5e5""
140               ""673a081d70cce7acfc48""))
141
142    # finally test that HKDF() without a digest= uses SHA256
143
144    _test(digest=None,
145          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
146          salt=""0x"",
147          info=""0x"",
148          L=42,
149          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
150               ""96596776afdb6377ac434c1c293ccb04""),
151          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
152               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
153               ""9d201395faa4b61a96c8""))
154    #print ""all test passed""
155
156power_on_self_test()
157","[['dkLen', '<=', 'hlen*255'], ['s.startswith(prefix)', '==', 'True']]",5,2,0.4,0.0003187759005419,"['SKM', 'dkLen', 'XTS', 'CTXinfo', 'digest', 'hlen', 'PRK', 'blocks', 'counter', 't', 'IKM', 'salt', 'info', 'L', 'OKM', 'prefix', 's', 'ikm', 'prk', 'okm', 'out']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['SKM', 'dkLen', 'XTS', 'CTXinfo', 'digest', 'hlen', 'PRK', 'blocks', 'counter', 't', 'IKM', 'salt', 'info', 'L', 'OKM', 'prefix', 's', 'ikm', 'prk', 'okm', 'out']
*Code:

1from hashlib import sha256, sha1
2import hmac
3import six
4
5def HKDF(SKM, dkLen, XTS=None, CTXinfo=b"""", digest=sha256,
6         _test_expected_PRK=None):
7    hlen = len(digest(b"""").digest())
8    if XTS is None:
9        XTS = b""\x00""*hlen
10    # extract
11    PRK = hmac.new(XTS, SKM, digest).digest()
12    if _test_expected_PRK and _test_expected_PRK != PRK:
13        raise ValueError(""test failed"")
14    # expand
15    blocks = []
16    counter = 1
17    t = b""""
18    while hlen*len(blocks) < dkLen:
19        t = hmac.new(PRK, t+CTXinfo+six.int2byte(counter), digest).digest()
20        blocks.append(t)
21        counter += 1
22    return b"""".join(blocks)[:dkLen]
23
24def power_on_self_test():
25    from binascii import hexlify, unhexlify
26
27    def _test(IKM, salt, info, L, PRK, OKM, digest=sha256):
28        def remove_prefix(prefix, s):
29            return s[len(prefix):]
30        ikm = unhexlify(remove_prefix(""0x"", IKM))
31        salt = unhexlify(remove_prefix(""0x"", salt))
32        info = unhexlify(remove_prefix(""0x"", info))
33        prk = unhexlify(remove_prefix(""0x"", PRK))
34        okm = unhexlify(remove_prefix(""0x"", OKM))
35        if digest is None:
36            out = HKDF(ikm, L, salt, info, _test_expected_PRK=prk)
37        else:
38            out = HKDF(ikm, L, salt, info, digest=digest,
39                       _test_expected_PRK=prk)
40        if okm != out:
41            raise ValueError(""got %s, expected %s"" % (hexlify(out), hexlify(okm)))
42
43    # test vectors from RFC5869
44    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
45          salt=""0x000102030405060708090a0b0c"",
46          info=""0xf0f1f2f3f4f5f6f7f8f9"",
47          L=42,
48          PRK=(""0x077709362c2e32df0ddc3f0dc47bba63""
49               ""90b6c73bb50f9c3122ec844ad7c2b3e5""),
50          OKM=(""0x3cb25f25faacd57a90434f64d0362f2a""
51               ""2d2d0a90cf1a5a4c5db02d56ecc4c5bf""
52               ""34007208d5b887185865""))
53
54    _test(IKM=(""0x000102030405060708090a0b0c0d0e0f""
55               ""101112131415161718191a1b1c1d1e1f""
56               ""202122232425262728292a2b2c2d2e2f""
57               ""303132333435363738393a3b3c3d3e3f""
58               ""404142434445464748494a4b4c4d4e4f""),
59          salt=(""0x606162636465666768696a6b6c6d6e6f""
60                ""707172737475767778797a7b7c7d7e7f""
61                ""808182838485868788898a8b8c8d8e8f""
62                ""909192939495969798999a9b9c9d9e9f""
63                ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
64          info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
65                ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
66                ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
67                ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
68                ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
69          L=82,
70          PRK=(""0x06a6b88c5853361a06104c9ceb35b45c""
71               ""ef760014904671014a193f40c15fc244""),
72          OKM=(""0xb11e398dc80327a1c8e7f78c596a4934""
73               ""4f012eda2d4efad8a050cc4c19afa97c""
74               ""59045a99cac7827271cb41c65e590e09""
75               ""da3275600c2f09b8367793a9aca3db71""
76               ""cc30c58179ec3e87c14c01d5c1f3434f""
77               ""1d87""))
78
79    _test(IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
80          salt=""0x"",
81          info=""0x"",
82          L=42,
83          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
84               ""96596776afdb6377ac434c1c293ccb04""),
85          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
86               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
87               ""9d201395faa4b61a96c8""))
88
89    _test(digest=sha1,
90          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b"",
91          salt=""0x000102030405060708090a0b0c"",
92          info=""0xf0f1f2f3f4f5f6f7f8f9"",
93          L=42,
94          PRK=""0x9b6c18c432a7bf8f0e71c8eb88f4b30baa2ba243"",
95          OKM=(""0x085a01ea1b10f36933068b56efa5ad81""
96               ""a4f14b822f5b091568a9cdd4f155fda2""
97               ""c22e422478d305f3f896""))
98    _test(digest=sha1,
99       IKM=(""0x000102030405060708090a0b0c0d0e0f""
100            ""101112131415161718191a1b1c1d1e1f""
101            ""202122232425262728292a2b2c2d2e2f""
102            ""303132333435363738393a3b3c3d3e3f""
103            ""404142434445464748494a4b4c4d4e4f""),
104       salt=(""0x606162636465666768696a6b6c6d6e6f""
105             ""707172737475767778797a7b7c7d7e7f""
106             ""808182838485868788898a8b8c8d8e8f""
107             ""909192939495969798999a9b9c9d9e9f""
108             ""a0a1a2a3a4a5a6a7a8a9aaabacadaeaf""),
109       info=(""0xb0b1b2b3b4b5b6b7b8b9babbbcbdbebf""
110             ""c0c1c2c3c4c5c6c7c8c9cacbcccdcecf""
111             ""d0d1d2d3d4d5d6d7d8d9dadbdcdddedf""
112             ""e0e1e2e3e4e5e6e7e8e9eaebecedeeef""
113             ""f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff""),
114       L=82,
115       PRK=""0x8adae09a2a307059478d309b26c4115a224cfaf6"",
116       OKM=(""0x0bd770a74d1160f7c9f12cd5912a06eb""
117            ""ff6adcae899d92191fe4305673ba2ffe""
118            ""8fa3f1a4e5ad79f3f334b3b202b2173c""
119            ""486ea37ce3d397ed034c7f9dfeb15c5e""
120            ""927336d0441f4c4300e2cff0d0900b52""
121            ""d3b4""))
122    _test(digest=sha1,
123          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
124          salt=""0x"",
125          info=""0x"",
126          L=42,
127          PRK=""0xda8c8a73c7fa77288ec6f5e7c297786aa0d32d01"",
128          OKM=(""0x0ac1af7002b3d761d1e55298da9d0506""
129               ""b9ae52057220a306e07b6b87e8df21d0""
130               ""ea00033de03984d34918""))
131
132    _test(digest=sha1,
133          IKM=""0x0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c0c"",
134          salt=""0x"",
135          info=""0x"",
136          L=42,
137          PRK=""0x2adccada18779e7c2077ad2eb19d3f3e731385dd"",
138          OKM=(""0x2c91117204d745f3500d636a62f64f0a""
139               ""b3bae548aa53d423b0d1f27ebba6f5e5""
140               ""673a081d70cce7acfc48""))
141
142    # finally test that HKDF() without a digest= uses SHA256
143
144    _test(digest=None,
145          IKM=""0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b"",
146          salt=""0x"",
147          info=""0x"",
148          L=42,
149          PRK=(""0x19ef24a32c717b167f33a91d6f648bdf""
150               ""96596776afdb6377ac434c1c293ccb04""),
151          OKM=(""0x8da4e775a563c18f715f802a063c5a31""
152               ""b8a11f5c5ee1879ec3454e5f3c738d2d""
153               ""9d201395faa4b61a96c8""))
154    #print ""all test passed""
155
156power_on_self_test()
157",7963,"[[6, 'SKM', '!=', None, 'Secret key must be provided'],
 [6, 'dkLen', '>=', 0, 'Derived key length should be greater than zero'],
 [18, 'blocks', '==', 0, 'Blocks must be empty before calculation'],
 [18, 'counter', '==', 1, 'Counter must be initialized to 1'],
 [18, 't', '==', '', 'Initial t value must be an empty string'],
 [33, 'info', '!=' , None, 'Info must be provided'],
 [36, 'L', '>', 0, 'Output Key Material length should be greater than zero'],
 [36, 'ikm', '!=', None, 'Input Key Material should be provided'],
 [38, 'prk', '!=', None, 'Pseudo Random Key should be provided'],
 [40, 'okm', '!=', None, 'Output Key Material must be provided']]"
snowflakedb/snowflake-sqlalchemy,"#
# Copyright (c) 2012-2022 Snowflake Computing Inc. All rights reserved.
#
import urllib.parse

from snowflake.sqlalchemy import URL


def test_url():
    assert (
        URL(account=""testaccount"", user=""admin"", password=""test"", warehouse=""testwh"")
        == ""snowflake://admin:test@testaccount/?warehouse=testwh""
    )

    assert (
        URL(account=""testaccount"", user=""admin"", password=""test"")
        == ""snowflake://admin:test@testaccount/""
    )

    assert (
        URL(
            account=""testaccount"",
            user=""admin"",
            password=""1-pass 2-pass 3-: 4-@ 5-/ 6-pass"",
        )
        == ""snowflake://admin:1-pass 2-pass 3-%3A 4-%40 5-%2F 6-pass@testaccount/""
    )

    quoted_password = urllib.parse.quote(""kx@% jj5/g"")
    assert (
        URL(
            account=""testaccount"",
            user=""admin"",
            password=quoted_password,
        )
        == ""snowflake://admin:kx%40%25%20jj5%2Fg@testaccount/""
    )

    assert (
        URL(account=""testaccount"", user=""admin"", password=""test"", database=""testdb"")
        == ""snowflake://admin:test@testaccount/testdb""
    )

    assert (
        URL(
            account=""testaccount"",
            user=""admin"",
            password=""test"",
            database=""testdb"",
            schema=""testschema"",
        )
        == ""snowflake://admin:test@testaccount/testdb/testschema""
    )

    assert (
        URL(
            account=""testaccount"",
            user=""admin"",
            password=""test"",
            database=""testdb"",
            schema=""testschema"",
            warehouse=""testwh"",
        )
        == ""snowflake://admin:test@testaccount/testdb/testschema?warehouse""
        ""=testwh""
    )

    assert (
        URL(
            host=""snowflake.reg.local"",
            account=""testaccount"",
            user=""admin"",
            password=""test"",
            database=""testdb"",
            schema=""testschema"",
        )
        == ""snowflake://admin:test@snowflake.reg.local:443/testdb""
        ""/testschema?account=testaccount""
    )

    assert URL(
        user=""admin"", account=""testaccount"", password=""test"", region=""eu-central-1""
    ) == (""snowflake://admin:test@testaccount.eu-central-1/"")

    assert URL(
        user=""admin"",
        account=""testaccount"",
        password=""test"",
        region=""eu-central-1.azure"",
    ) == (""snowflake://admin:test@testaccount.eu-central-1.azure/"")

    assert URL(
        host=""testaccount.eu-central-1.snowflakecomputing.com"",
        user=""admin"",
        account=""testaccount"",
        password=""test"",
    ) == (
        ""snowflake://admin:test@testaccount.eu-central-1""
        "".snowflakecomputing.com:443/?account=testaccount""
    )

    # empty password should be acceptable in URL utility. The validation will
    # happen in Python connector anyway.
    assert URL(
        host=""testaccount.eu-central-1.snowflakecomputing.com"",
        user=""admin"",
        account=""testaccount"",
    ) == (
        ""snowflake://admin:@testaccount.eu-central-1""
        "".snowflakecomputing.com:443/?account=testaccount""
    )

    # authenticator=externalbrowser doesn't require a password.
    assert URL(
        host=""testaccount.eu-central-1.snowflakecomputing.com"",
        user=""admin"",
        account=""testaccount"",
        authenticator=""externalbrowser"",
    ) == (
        ""snowflake://admin:@testaccount.eu-central-1""
        "".snowflakecomputing.com:443/?account=testaccount""
        ""&authenticator=externalbrowser""
    )

    # authenticator=oktaurl support
    assert URL(
        user=""testuser"",
        account=""testaccount"",
        password=""test"",
        authenticator=""https://testokta.okta.com"",
    ) == (
        ""snowflake://testuser:test@testaccount""
        ""/?authenticator=https%3A%2F%2Ftestokta.okta.com""
    )
","
1#
2# Copyright (c) 2012-2022 Snowflake Computing Inc. All rights reserved.
3#
4import urllib.parse
5
6from snowflake.sqlalchemy import URL
7
8
9def test_url():
10        URL(account=""testaccount"", user=""admin"", password=""test"", warehouse=""testwh"")
11        == ""snowflake://admin:test@testaccount/?warehouse=testwh""
12    )
13
14        URL(account=""testaccount"", user=""admin"", password=""test"")
15        == ""snowflake://admin:test@testaccount/""
16    )
17
18        URL(
19            account=""testaccount"",
20            user=""admin"",
21            password=""1-pass 2-pass 3-: 4-@ 5-/ 6-pass"",
22        )
23        == ""snowflake://admin:1-pass 2-pass 3-%3A 4-%40 5-%2F 6-pass@testaccount/""
24    )
25
26    quoted_password = urllib.parse.quote(""kx@% jj5/g"")
27        URL(
28            account=""testaccount"",
29            user=""admin"",
30            password=quoted_password,
31        )
32        == ""snowflake://admin:kx%40%25%20jj5%2Fg@testaccount/""
33    )
34
35        URL(account=""testaccount"", user=""admin"", password=""test"", database=""testdb"")
36        == ""snowflake://admin:test@testaccount/testdb""
37    )
38
39        URL(
40            account=""testaccount"",
41            user=""admin"",
42            password=""test"",
43            database=""testdb"",
44            schema=""testschema"",
45        )
46        == ""snowflake://admin:test@testaccount/testdb/testschema""
47    )
48
49        URL(
50            account=""testaccount"",
51            user=""admin"",
52            password=""test"",
53            database=""testdb"",
54            schema=""testschema"",
55            warehouse=""testwh"",
56        )
57        == ""snowflake://admin:test@testaccount/testdb/testschema?warehouse""
58        ""=testwh""
59    )
60
61        URL(
62            host=""snowflake.reg.local"",
63            account=""testaccount"",
64            user=""admin"",
65            password=""test"",
66            database=""testdb"",
67            schema=""testschema"",
68        )
69        == ""snowflake://admin:test@snowflake.reg.local:443/testdb""
70        ""/testschema?account=testaccount""
71    )
72
73        user=""admin"", account=""testaccount"", password=""test"", region=""eu-central-1""
74    ) == (""snowflake://admin:test@testaccount.eu-central-1/"")
75
76        user=""admin"",
77        account=""testaccount"",
78        password=""test"",
79        region=""eu-central-1.azure"",
80    ) == (""snowflake://admin:test@testaccount.eu-central-1.azure/"")
81
82        host=""testaccount.eu-central-1.snowflakecomputing.com"",
83        user=""admin"",
84        account=""testaccount"",
85        password=""test"",
86    ) == (
87        ""snowflake://admin:test@testaccount.eu-central-1""
88        "".snowflakecomputing.com:443/?account=testaccount""
89    )
90
91    # empty password should be acceptable in URL utility. The validation will
92    # happen in Python connector anyway.
93        host=""testaccount.eu-central-1.snowflakecomputing.com"",
94        user=""admin"",
95        account=""testaccount"",
96    ) == (
97        ""snowflake://admin:@testaccount.eu-central-1""
98        "".snowflakecomputing.com:443/?account=testaccount""
99    )
100
101    # authenticator=externalbrowser doesn't require a password.
102        host=""testaccount.eu-central-1.snowflakecomputing.com"",
103        user=""admin"",
104        account=""testaccount"",
105        authenticator=""externalbrowser"",
106    ) == (
107        ""snowflake://admin:@testaccount.eu-central-1""
108        "".snowflakecomputing.com:443/?account=testaccount""
109        ""&authenticator=externalbrowser""
110    )
111
112    # authenticator=oktaurl support
113        user=""testuser"",
114        account=""testaccount"",
115        password=""test"",
116        authenticator=""https://testokta.okta.com"",
117    ) == (
118        ""snowflake://testuser:test@testaccount""
119        ""/?authenticator=https%3A%2F%2Ftestokta.okta.com""
120    )
121","[['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['URL(', '==', 'True'], ['URL(', '==', 'True'], ['URL(', '==', 'True'], ['URL(', '==', 'True'], ['URL(', '==', 'True'], ['URL(', '==', 'True']]",14,14,1.0,0.0036735764891104,['quoted_password'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['quoted_password']
*Code:

1#
2# Copyright (c) 2012-2022 Snowflake Computing Inc. All rights reserved.
3#
4import urllib.parse
5
6from snowflake.sqlalchemy import URL
7
8
9def test_url():
10        URL(account=""testaccount"", user=""admin"", password=""test"", warehouse=""testwh"")
11        == ""snowflake://admin:test@testaccount/?warehouse=testwh""
12    )
13
14        URL(account=""testaccount"", user=""admin"", password=""test"")
15        == ""snowflake://admin:test@testaccount/""
16    )
17
18        URL(
19            account=""testaccount"",
20            user=""admin"",
21            password=""1-pass 2-pass 3-: 4-@ 5-/ 6-pass"",
22        )
23        == ""snowflake://admin:1-pass 2-pass 3-%3A 4-%40 5-%2F 6-pass@testaccount/""
24    )
25
26    quoted_password = urllib.parse.quote(""kx@% jj5/g"")
27        URL(
28            account=""testaccount"",
29            user=""admin"",
30            password=quoted_password,
31        )
32        == ""snowflake://admin:kx%40%25%20jj5%2Fg@testaccount/""
33    )
34
35        URL(account=""testaccount"", user=""admin"", password=""test"", database=""testdb"")
36        == ""snowflake://admin:test@testaccount/testdb""
37    )
38
39        URL(
40            account=""testaccount"",
41            user=""admin"",
42            password=""test"",
43            database=""testdb"",
44            schema=""testschema"",
45        )
46        == ""snowflake://admin:test@testaccount/testdb/testschema""
47    )
48
49        URL(
50            account=""testaccount"",
51            user=""admin"",
52            password=""test"",
53            database=""testdb"",
54            schema=""testschema"",
55            warehouse=""testwh"",
56        )
57        == ""snowflake://admin:test@testaccount/testdb/testschema?warehouse""
58        ""=testwh""
59    )
60
61        URL(
62            host=""snowflake.reg.local"",
63            account=""testaccount"",
64            user=""admin"",
65            password=""test"",
66            database=""testdb"",
67            schema=""testschema"",
68        )
69        == ""snowflake://admin:test@snowflake.reg.local:443/testdb""
70        ""/testschema?account=testaccount""
71    )
72
73        user=""admin"", account=""testaccount"", password=""test"", region=""eu-central-1""
74    ) == (""snowflake://admin:test@testaccount.eu-central-1/"")
75
76        user=""admin"",
77        account=""testaccount"",
78        password=""test"",
79        region=""eu-central-1.azure"",
80    ) == (""snowflake://admin:test@testaccount.eu-central-1.azure/"")
81
82        host=""testaccount.eu-central-1.snowflakecomputing.com"",
83        user=""admin"",
84        account=""testaccount"",
85        password=""test"",
86    ) == (
87        ""snowflake://admin:test@testaccount.eu-central-1""
88        "".snowflakecomputing.com:443/?account=testaccount""
89    )
90
91    # empty password should be acceptable in URL utility. The validation will
92    # happen in Python connector anyway.
93        host=""testaccount.eu-central-1.snowflakecomputing.com"",
94        user=""admin"",
95        account=""testaccount"",
96    ) == (
97        ""snowflake://admin:@testaccount.eu-central-1""
98        "".snowflakecomputing.com:443/?account=testaccount""
99    )
100
101    # authenticator=externalbrowser doesn't require a password.
102        host=""testaccount.eu-central-1.snowflakecomputing.com"",
103        user=""admin"",
104        account=""testaccount"",
105        authenticator=""externalbrowser"",
106    ) == (
107        ""snowflake://admin:@testaccount.eu-central-1""
108        "".snowflakecomputing.com:443/?account=testaccount""
109        ""&authenticator=externalbrowser""
110    )
111
112    # authenticator=oktaurl support
113        user=""testuser"",
114        account=""testaccount"",
115        password=""test"",
116        authenticator=""https://testokta.okta.com"",
117    ) == (
118        ""snowflake://testuser:test@testaccount""
119        ""/?authenticator=https%3A%2F%2Ftestokta.okta.com""
120    )
121",5266,"[26, 'quoted_password', '==', 'urllib.parse.quote(""kx@% jj5/g"")', 'Ensure the password is properly quoted for URL use']"
edmundgentle/schoolscript,"from importlib import _bootstrap
from importlib import machinery
from .. import util
from . import util as import_util
import imp
import os
import sys
import tempfile
from test import support
from types import MethodType
import unittest


class FinderTests(unittest.TestCase):

    """"""Tests for PathFinder.""""""

    def test_failure(self):
        # Test None returned upon not finding a suitable finder.
        module = '<test module>'
        with util.import_state():
            self.assertTrue(machinery.PathFinder.find_module(module) is None)

    def test_sys_path(self):
        # Test that sys.path is used when 'path' is None.
        # Implicitly tests that sys.path_importer_cache is used.
        module = '<test module>'
        path = '<test path>'
        importer = util.mock_modules(module)
        with util.import_state(path_importer_cache={path: importer},
                               path=[path]):
            loader = machinery.PathFinder.find_module(module)
            self.assertTrue(loader is importer)

    def test_path(self):
        # Test that 'path' is used when set.
        # Implicitly tests that sys.path_importer_cache is used.
        module = '<test module>'
        path = '<test path>'
        importer = util.mock_modules(module)
        with util.import_state(path_importer_cache={path: importer}):
            loader = machinery.PathFinder.find_module(module, [path])
            self.assertTrue(loader is importer)

    def test_path_hooks(self):
        # Test that sys.path_hooks is used.
        # Test that sys.path_importer_cache is set.
        module = '<test module>'
        path = '<test path>'
        importer = util.mock_modules(module)
        hook = import_util.mock_path_hook(path, importer=importer)
        with util.import_state(path_hooks=[hook]):
            loader = machinery.PathFinder.find_module(module, [path])
            self.assertTrue(loader is importer)
            self.assertTrue(path in sys.path_importer_cache)
            self.assertTrue(sys.path_importer_cache[path] is importer)

    def test_path_importer_cache_has_None(self):
        # Test that if sys.path_importer_cache has None that None is returned.
        clear_cache = {path: None for path in sys.path}
        with util.import_state(path_importer_cache=clear_cache):
            for name in ('asynchat', 'sys', '<test module>'):
                self.assertTrue(machinery.PathFinder.find_module(name) is None)

    def test_path_importer_cache_has_None_continues(self):
        # Test that having None in sys.path_importer_cache causes the search to
        # continue.
        path = '<test path>'
        module = '<test module>'
        importer = util.mock_modules(module)
        with util.import_state(path=['1', '2'],
                            path_importer_cache={'1': None, '2': importer}):
            loader = machinery.PathFinder.find_module(module)
            self.assertTrue(loader is importer)



class DefaultPathFinderTests(unittest.TestCase):

    """"""Test importlib._bootstrap._DefaultPathFinder.""""""

    def test_implicit_hooks(self):
        # Test that the implicit path hooks are used.
        bad_path = '<path>'
        module = '<module>'
        assert not os.path.exists(bad_path)
        existing_path = tempfile.mkdtemp()
        try:
            with util.import_state():
                nothing = _bootstrap._DefaultPathFinder.find_module(module,
                                                        path=[existing_path])
                self.assertTrue(nothing is None)
                self.assertTrue(existing_path in sys.path_importer_cache)
                result = isinstance(sys.path_importer_cache[existing_path],
                                    imp.NullImporter)
                self.assertFalse(result)
                nothing = _bootstrap._DefaultPathFinder.find_module(module,
                                                            path=[bad_path])
                self.assertTrue(nothing is None)
                self.assertTrue(bad_path in sys.path_importer_cache)
                self.assertTrue(isinstance(sys.path_importer_cache[bad_path],
                                           imp.NullImporter))
        finally:
            os.rmdir(existing_path)


    def test_path_importer_cache_has_None(self):
        # Test that the default hook is used when sys.path_importer_cache
        # contains None for a path.
        module = '<test module>'
        importer = util.mock_modules(module)
        path = '<test path>'
        # XXX Not blackbox.
        original_hook = _bootstrap._DEFAULT_PATH_HOOK
        mock_hook = import_util.mock_path_hook(path, importer=importer)
        _bootstrap._DEFAULT_PATH_HOOK = mock_hook
        try:
            with util.import_state(path_importer_cache={path: None}):
                loader = _bootstrap._DefaultPathFinder.find_module(module,
                                                                    path=[path])
                self.assertTrue(loader is importer)
        finally:
            _bootstrap._DEFAULT_PATH_HOOK = original_hook


def test_main():
    from test.support import run_unittest
    run_unittest(FinderTests, DefaultPathFinderTests)

if __name__ == '__main__':
    test_main()
","
1from importlib import _bootstrap
2from importlib import machinery
3from .. import util
4from . import util as import_util
5import imp
6import os
7import sys
8import tempfile
9from test import support
10from types import MethodType
11import unittest
12
13
14class FinderTests(unittest.TestCase):
15
16    """"""Tests for PathFinder.""""""
17
18    def test_failure(self):
19        # Test None returned upon not finding a suitable finder.
20        module = '<test module>'
21        with util.import_state():
22
23    def test_sys_path(self):
24        # Test that sys.path is used when 'path' is None.
25        # Implicitly tests that sys.path_importer_cache is used.
26        module = '<test module>'
27        path = '<test path>'
28        importer = util.mock_modules(module)
29        with util.import_state(path_importer_cache={path: importer},
30                               path=[path]):
31            loader = machinery.PathFinder.find_module(module)
32
33    def test_path(self):
34        # Test that 'path' is used when set.
35        # Implicitly tests that sys.path_importer_cache is used.
36        module = '<test module>'
37        path = '<test path>'
38        importer = util.mock_modules(module)
39        with util.import_state(path_importer_cache={path: importer}):
40            loader = machinery.PathFinder.find_module(module, [path])
41
42    def test_path_hooks(self):
43        # Test that sys.path_hooks is used.
44        # Test that sys.path_importer_cache is set.
45        module = '<test module>'
46        path = '<test path>'
47        importer = util.mock_modules(module)
48        hook = import_util.mock_path_hook(path, importer=importer)
49        with util.import_state(path_hooks=[hook]):
50            loader = machinery.PathFinder.find_module(module, [path])
51
52    def test_path_importer_cache_has_None(self):
53        # Test that if sys.path_importer_cache has None that None is returned.
54        clear_cache = {path: None for path in sys.path}
55        with util.import_state(path_importer_cache=clear_cache):
56            for name in ('asynchat', 'sys', '<test module>'):
57
58    def test_path_importer_cache_has_None_continues(self):
59        # Test that having None in sys.path_importer_cache causes the search to
60        # continue.
61        path = '<test path>'
62        module = '<test module>'
63        importer = util.mock_modules(module)
64        with util.import_state(path=['1', '2'],
65                            path_importer_cache={'1': None, '2': importer}):
66            loader = machinery.PathFinder.find_module(module)
67
68
69
70class DefaultPathFinderTests(unittest.TestCase):
71
72    """"""Test importlib._bootstrap._DefaultPathFinder.""""""
73
74    def test_implicit_hooks(self):
75        # Test that the implicit path hooks are used.
76        bad_path = '<path>'
77        module = '<module>'
78        existing_path = tempfile.mkdtemp()
79        try:
80            with util.import_state():
81                nothing = _bootstrap._DefaultPathFinder.find_module(module,
82                                                        path=[existing_path])
83                result = isinstance(sys.path_importer_cache[existing_path],
84                                    imp.NullImporter)
85                nothing = _bootstrap._DefaultPathFinder.find_module(module,
86                                                            path=[bad_path])
87                                           imp.NullImporter))
88        finally:
89            os.rmdir(existing_path)
90
91
92    def test_path_importer_cache_has_None(self):
93        # Test that the default hook is used when sys.path_importer_cache
94        # contains None for a path.
95        module = '<test module>'
96        importer = util.mock_modules(module)
97        path = '<test path>'
98        # XXX Not blackbox.
99        original_hook = _bootstrap._DEFAULT_PATH_HOOK
100        mock_hook = import_util.mock_path_hook(path, importer=importer)
101        _bootstrap._DEFAULT_PATH_HOOK = mock_hook
102        try:
103            with util.import_state(path_importer_cache={path: None}):
104                loader = _bootstrap._DefaultPathFinder.find_module(module,
105                                                                    path=[path])
106        finally:
107            _bootstrap._DEFAULT_PATH_HOOK = original_hook
108
109
110def test_main():
111    from test.support import run_unittest
112    run_unittest(FinderTests, DefaultPathFinderTests)
113
114if __name__ == '__main__':
115    test_main()
116","[['os.path.exists(bad_path)', '==', 'False']]",16,1,0.0625,0.00018539117538,"['module', 'path', 'importer', 'loader', 'hook', 'clear_cache', 'bad_path', 'existing_path', 'nothing', 'result', 'original_hook', 'mock_hook', '_bootstrap._DEFAULT_PATH_HOOK']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['module', 'path', 'importer', 'loader', 'hook', 'clear_cache', 'bad_path', 'existing_path', 'nothing', 'result', 'original_hook', 'mock_hook', '_bootstrap._DEFAULT_PATH_HOOK']
*Code:

1from importlib import _bootstrap
2from importlib import machinery
3from .. import util
4from . import util as import_util
5import imp
6import os
7import sys
8import tempfile
9from test import support
10from types import MethodType
11import unittest
12
13
14class FinderTests(unittest.TestCase):
15
16    """"""Tests for PathFinder.""""""
17
18    def test_failure(self):
19        # Test None returned upon not finding a suitable finder.
20        module = '<test module>'
21        with util.import_state():
22
23    def test_sys_path(self):
24        # Test that sys.path is used when 'path' is None.
25        # Implicitly tests that sys.path_importer_cache is used.
26        module = '<test module>'
27        path = '<test path>'
28        importer = util.mock_modules(module)
29        with util.import_state(path_importer_cache={path: importer},
30                               path=[path]):
31            loader = machinery.PathFinder.find_module(module)
32
33    def test_path(self):
34        # Test that 'path' is used when set.
35        # Implicitly tests that sys.path_importer_cache is used.
36        module = '<test module>'
37        path = '<test path>'
38        importer = util.mock_modules(module)
39        with util.import_state(path_importer_cache={path: importer}):
40            loader = machinery.PathFinder.find_module(module, [path])
41
42    def test_path_hooks(self):
43        # Test that sys.path_hooks is used.
44        # Test that sys.path_importer_cache is set.
45        module = '<test module>'
46        path = '<test path>'
47        importer = util.mock_modules(module)
48        hook = import_util.mock_path_hook(path, importer=importer)
49        with util.import_state(path_hooks=[hook]):
50            loader = machinery.PathFinder.find_module(module, [path])
51
52    def test_path_importer_cache_has_None(self):
53        # Test that if sys.path_importer_cache has None that None is returned.
54        clear_cache = {path: None for path in sys.path}
55        with util.import_state(path_importer_cache=clear_cache):
56            for name in ('asynchat', 'sys', '<test module>'):
57
58    def test_path_importer_cache_has_None_continues(self):
59        # Test that having None in sys.path_importer_cache causes the search to
60        # continue.
61        path = '<test path>'
62        module = '<test module>'
63        importer = util.mock_modules(module)
64        with util.import_state(path=['1', '2'],
65                            path_importer_cache={'1': None, '2': importer}):
66            loader = machinery.PathFinder.find_module(module)
67
68
69
70class DefaultPathFinderTests(unittest.TestCase):
71
72    """"""Test importlib._bootstrap._DefaultPathFinder.""""""
73
74    def test_implicit_hooks(self):
75        # Test that the implicit path hooks are used.
76        bad_path = '<path>'
77        module = '<module>'
78        existing_path = tempfile.mkdtemp()
79        try:
80            with util.import_state():
81                nothing = _bootstrap._DefaultPathFinder.find_module(module,
82                                                        path=[existing_path])
83                result = isinstance(sys.path_importer_cache[existing_path],
84                                    imp.NullImporter)
85                nothing = _bootstrap._DefaultPathFinder.find_module(module,
86                                                            path=[bad_path])
87                                           imp.NullImporter))
88        finally:
89            os.rmdir(existing_path)
90
91
92    def test_path_importer_cache_has_None(self):
93        # Test that the default hook is used when sys.path_importer_cache
94        # contains None for a path.
95        module = '<test module>'
96        importer = util.mock_modules(module)
97        path = '<test path>'
98        # XXX Not blackbox.
99        original_hook = _bootstrap._DEFAULT_PATH_HOOK
100        mock_hook = import_util.mock_path_hook(path, importer=importer)
101        _bootstrap._DEFAULT_PATH_HOOK = mock_hook
102        try:
103            with util.import_state(path_importer_cache={path: None}):
104                loader = _bootstrap._DefaultPathFinder.find_module(module,
105                                                                    path=[path])
106        finally:
107            _bootstrap._DEFAULT_PATH_HOOK = original_hook
108
109
110def test_main():
111    from test.support import run_unittest
112    run_unittest(FinderTests, DefaultPathFinderTests)
113
114if __name__ == '__main__':
115    test_main()
116",6237,"[[18, 'module', '!=', '', ""Module name shouldn't be empty""],
[23, 'module', '!=', '', ""Module name shouldn't be empty""],
[27, 'path', '!=', '', ""Path shouldn't be empty""],
[33, 'module', '!=', '', ""Module name shouldn't be empty""],
[37, 'path', '!=', '', ""Path shouldn't be empty""],
[42, 'module', '!=', '', ""Module name shouldn't be empty""],
[46, 'path', '!=', '', ""Path shouldn't be empty""],
[61, 'path', '!=', '', ""Path shouldn't be empty""],
[62, 'module', '!=', '', ""Module name shouldn't be empty""],
[76, 'bad_path', '!=', '', ""Bad path shouldn't be empty""],
[77, 'module', '!=', '', ""Module name shouldn't be empty""],
[92, 'module', '!=', '', ""Module name shouldn't be empty""],
[97, 'path', '!=', '', ""Path shouldn't be empty""]]"
poliastro/poliastro,"""""""
@author: Dhruv Jain, Multi-Body Dynamics Research Group, Purdue University
""""""
from astropy import units as u

from poliastro.core.threebody.cr3bp_quantities_calculations import (
    calculate_mu,
    calculate_tstar,
)


class SystemChars:
    """"""Computes and stores the properties (mu, l*, t*) of a CR3BP system
    'mu': mass ratio of P1-P2 primary bodies
    'l*': characterisitic lenght of P1-P2 system
    't*': characterisitic time of P1-P2 system
    If P2 is more massive than P1 then swap the Pi, so that P1 is the more massive body
    """"""

    def __init__(self, name, mu, lstar, tstar):
        """"""
        Constructor

        Parameters
        ----------
        name: string
            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
        mu: float, dimensionless
           mass ratio of P1-P2 primary bodies
        lstar: float, km
           Characterisitc length of P1-P2 system
        tstar: float, sec
            Characterisitc time of P1-P2 system
        """"""
        self._name = name
        self._mu = mu
        self._lstar = lstar
        self._tstar = tstar

    @classmethod
    def from_primaries(cls, p1, p2):
        """"""
        Computes and sets the characteristic quanitites based on p1 and p2 bodies

        Parameters
        ----------
        p1: ~poliastro.bodies.Body
        p2: ~poliastro.bodies.Body
        """"""
        name, mu, lstar, tstar = cls.bodies_char_compute(p1, p2)
        return cls(name, mu, lstar, tstar)

    @classmethod
    def bodies_char_compute(self, p1, p2):
        """"""
        Calculates mu, lstar, and tstar of the 'p1' and 'p2' system

        Also, if M2>M1, then swaps p1 and p2, so that M1>M2

        Parameters
        ----------
        p1: ~poliastro.bodies.Body
        p2: ~poliastro.bodies.Body

        Returns
        -------
        name: string
            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
        mu: float, dimensionless
           mass ratio of P1-P2 primary bodies
        lstar: float, km
           Characterisitc length of P1-P2 system
        tstar: float, sec
            Characterisitc time of P1-P2 system
        """"""

        assert (
            p1 == p2.parent or p2 == p1.parent
        ) is True, (
            ""P1 and P2 are not part of the same system. Recheck body.parent""
        )

        if p1.k < p2.k:
            # swap p1 and p2, as p1 should be the more massive body
            p1, p2 = p2, p1

        name = p1.name + p2.name

        mu = calculate_mu(
            p1.k.to(u.km**3 * u.s**-2), p2.k.to(u.km**3 * u.s**-2)
        )
        lstar = p2.mean_a
        tstar = calculate_tstar(
            p1.k.to(u.km**3 * u.s**-2),
            p2.k.to(u.km**3 * u.s**-2),
            lstar,
        )

        return name, mu, lstar, tstar

    # All the attributes are made private to make them constant and avoid being mistakenly changed
    @property
    def name(self):
        """"""Name of P1-P2 system""""""
        return self._name

    @property
    def mu(self):
        """"""Mass ratio of P1-P2 primary bodies in CR3BP""""""
        return self._mu

    @property
    def lstar(self):
        """"""Characterisitc length of P1-P2 system""""""
        return self._lstar

    @property
    def tstar(self):
        """"""Characterisitc time of P1-P2 system""""""
        return self._tstar
","
1""""""
2@author: Dhruv Jain, Multi-Body Dynamics Research Group, Purdue University
3""""""
4from astropy import units as u
5
6from poliastro.core.threebody.cr3bp_quantities_calculations import (
7    calculate_mu,
8    calculate_tstar,
9)
10
11
12class SystemChars:
13    """"""Computes and stores the properties (mu, l*, t*) of a CR3BP system
14    'mu': mass ratio of P1-P2 primary bodies
15    'l*': characterisitic lenght of P1-P2 system
16    't*': characterisitic time of P1-P2 system
17    If P2 is more massive than P1 then swap the Pi, so that P1 is the more massive body
18    """"""
19
20    def __init__(self, name, mu, lstar, tstar):
21        """"""
22        Constructor
23
24        Parameters
25        ----------
26        name: string
27            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
28        mu: float, dimensionless
29           mass ratio of P1-P2 primary bodies
30        lstar: float, km
31           Characterisitc length of P1-P2 system
32        tstar: float, sec
33            Characterisitc time of P1-P2 system
34        """"""
35        self._name = name
36        self._mu = mu
37        self._lstar = lstar
38        self._tstar = tstar
39
40    @classmethod
41    def from_primaries(cls, p1, p2):
42        """"""
43        Computes and sets the characteristic quanitites based on p1 and p2 bodies
44
45        Parameters
46        ----------
47        p1: ~poliastro.bodies.Body
48        p2: ~poliastro.bodies.Body
49        """"""
50        name, mu, lstar, tstar = cls.bodies_char_compute(p1, p2)
51        return cls(name, mu, lstar, tstar)
52
53    @classmethod
54    def bodies_char_compute(self, p1, p2):
55        """"""
56        Calculates mu, lstar, and tstar of the 'p1' and 'p2' system
57
58        Also, if M2>M1, then swaps p1 and p2, so that M1>M2
59
60        Parameters
61        ----------
62        p1: ~poliastro.bodies.Body
63        p2: ~poliastro.bodies.Body
64
65        Returns
66        -------
67        name: string
68            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
69        mu: float, dimensionless
70           mass ratio of P1-P2 primary bodies
71        lstar: float, km
72           Characterisitc length of P1-P2 system
73        tstar: float, sec
74            Characterisitc time of P1-P2 system
75        """"""
76
77            p1 == p2.parent or p2 == p1.parent
78        ) is True, (
79            ""P1 and P2 are not part of the same system. Recheck body.parent""
80        )
81
82        if p1.k < p2.k:
83            # swap p1 and p2, as p1 should be the more massive body
84            p1, p2 = p2, p1
85
86        name = p1.name + p2.name
87
88        mu = calculate_mu(
89            p1.k.to(u.km**3 * u.s**-2), p2.k.to(u.km**3 * u.s**-2)
90        )
91        lstar = p2.mean_a
92        tstar = calculate_tstar(
93            p1.k.to(u.km**3 * u.s**-2),
94            p2.k.to(u.km**3 * u.s**-2),
95            lstar,
96        )
97
98        return name, mu, lstar, tstar
99
100    # All the attributes are made private to make them constant and avoid being mistakenly changed
101    @property
102    def name(self):
103        """"""Name of P1-P2 system""""""
104        return self._name
105
106    @property
107    def mu(self):
108        """"""Mass ratio of P1-P2 primary bodies in CR3BP""""""
109        return self._mu
110
111    @property
112    def lstar(self):
113        """"""Characterisitc length of P1-P2 system""""""
114        return self._lstar
115
116    @property
117    def tstar(self):
118        """"""Characterisitc time of P1-P2 system""""""
119        return self._tstar
120","[['(', '==', 'True']]",1,1,1.0,0.0002983293556085,"['name', 'mu', 'lstar', 'tstar', 'self._name', 'self._mu', 'self._lstar', 'self._tstar', 'cls', 'p1', 'p2']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['name', 'mu', 'lstar', 'tstar', 'self._name', 'self._mu', 'self._lstar', 'self._tstar', 'cls', 'p1', 'p2']
*Code:

1""""""
2@author: Dhruv Jain, Multi-Body Dynamics Research Group, Purdue University
3""""""
4from astropy import units as u
5
6from poliastro.core.threebody.cr3bp_quantities_calculations import (
7    calculate_mu,
8    calculate_tstar,
9)
10
11
12class SystemChars:
13    """"""Computes and stores the properties (mu, l*, t*) of a CR3BP system
14    'mu': mass ratio of P1-P2 primary bodies
15    'l*': characterisitic lenght of P1-P2 system
16    't*': characterisitic time of P1-P2 system
17    If P2 is more massive than P1 then swap the Pi, so that P1 is the more massive body
18    """"""
19
20    def __init__(self, name, mu, lstar, tstar):
21        """"""
22        Constructor
23
24        Parameters
25        ----------
26        name: string
27            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
28        mu: float, dimensionless
29           mass ratio of P1-P2 primary bodies
30        lstar: float, km
31           Characterisitc length of P1-P2 system
32        tstar: float, sec
33            Characterisitc time of P1-P2 system
34        """"""
35        self._name = name
36        self._mu = mu
37        self._lstar = lstar
38        self._tstar = tstar
39
40    @classmethod
41    def from_primaries(cls, p1, p2):
42        """"""
43        Computes and sets the characteristic quanitites based on p1 and p2 bodies
44
45        Parameters
46        ----------
47        p1: ~poliastro.bodies.Body
48        p2: ~poliastro.bodies.Body
49        """"""
50        name, mu, lstar, tstar = cls.bodies_char_compute(p1, p2)
51        return cls(name, mu, lstar, tstar)
52
53    @classmethod
54    def bodies_char_compute(self, p1, p2):
55        """"""
56        Calculates mu, lstar, and tstar of the 'p1' and 'p2' system
57
58        Also, if M2>M1, then swaps p1 and p2, so that M1>M2
59
60        Parameters
61        ----------
62        p1: ~poliastro.bodies.Body
63        p2: ~poliastro.bodies.Body
64
65        Returns
66        -------
67        name: string
68            System name, format: 'Body1Body2', e.g. 'EarthMoon', 'SunEarth'
69        mu: float, dimensionless
70           mass ratio of P1-P2 primary bodies
71        lstar: float, km
72           Characterisitc length of P1-P2 system
73        tstar: float, sec
74            Characterisitc time of P1-P2 system
75        """"""
76
77            p1 == p2.parent or p2 == p1.parent
78        ) is True, (
79            ""P1 and P2 are not part of the same system. Recheck body.parent""
80        )
81
82        if p1.k < p2.k:
83            # swap p1 and p2, as p1 should be the more massive body
84            p1, p2 = p2, p1
85
86        name = p1.name + p2.name
87
88        mu = calculate_mu(
89            p1.k.to(u.km**3 * u.s**-2), p2.k.to(u.km**3 * u.s**-2)
90        )
91        lstar = p2.mean_a
92        tstar = calculate_tstar(
93            p1.k.to(u.km**3 * u.s**-2),
94            p2.k.to(u.km**3 * u.s**-2),
95            lstar,
96        )
97
98        return name, mu, lstar, tstar
99
100    # All the attributes are made private to make them constant and avoid being mistakenly changed
101    @property
102    def name(self):
103        """"""Name of P1-P2 system""""""
104        return self._name
105
106    @property
107    def mu(self):
108        """"""Mass ratio of P1-P2 primary bodies in CR3BP""""""
109        return self._mu
110
111    @property
112    def lstar(self):
113        """"""Characterisitc length of P1-P2 system""""""
114        return self._lstar
115
116    @property
117    def tstar(self):
118        """"""Characterisitc time of P1-P2 system""""""
119        return self._tstar
120",5075,"[[20, 'name', '!=', None, ""name must not be None as it will cause error during concatenation""], 
 [20, 'mu', '>=', 0, ""mu must be a positive value""], 
 [20, 'lstar', '>=', 0, ""lstar must be a positive value""], 
 [20, 'tstar', '>=', 0, ""tstar must be a positive value""], 
 [40, 'p1', '!=', None, ""p1 must not be None""], 
 [40, 'p2', '!=', None, ""p2 must not be None""], 
 [53, 'p1', '!=', None, ""p1 must not be None""], 
 [53, 'p2', '!=', None, ""p2 must not be None""], 
 [82, 'p1.k', '>=', 'p2.k', ""p1 should be the more massive one""]]"
spulec/freezegun,"from importlib import reload
from unittest import SkipTest, mock

from freezegun import api
from tests import utils


@mock.patch('platform.python_implementation', lambda: 'CPython')
def test_should_not_skip_cpython():
    reload(api)
    reload(utils)
    function_mock = mock.MagicMock(__name__='function')
    try:
        utils.cpython_only(function_mock)()
    except SkipTest:
        raise AssertionError(""Test was skipped in CPython"")
    assert function_mock.called


@mock.patch('platform.python_implementation', lambda: 'not-CPython')
def test_should_skip_non_cpython():
    reload(api)
    reload(utils)
    function_mock = mock.MagicMock(__name__='function', skipped=False)
    try:
        utils.cpython_only(function_mock)()
    except SkipTest:
        function_mock.skipped = True
    assert not function_mock.called
    assert function_mock.skipped
","
1from importlib import reload
2from unittest import SkipTest, mock
3
4from freezegun import api
5from tests import utils
6
7
8@mock.patch('platform.python_implementation', lambda: 'CPython')
9def test_should_not_skip_cpython():
10    reload(api)
11    reload(utils)
12    function_mock = mock.MagicMock(__name__='function')
13    try:
14        utils.cpython_only(function_mock)()
15    except SkipTest:
16        raise AssertionError(""Test was skipped in CPython"")
17
18
19@mock.patch('platform.python_implementation', lambda: 'not-CPython')
20def test_should_skip_non_cpython():
21    reload(api)
22    reload(utils)
23    function_mock = mock.MagicMock(__name__='function', skipped=False)
24    try:
25        utils.cpython_only(function_mock)()
26    except SkipTest:
27        function_mock.skipped = True
28","[['function_mock.called', '==', 'True'], ['function_mock.called', '==', 'False'], ['function_mock.skipped', '==', 'True']]",3,3,1.0,0.0034602076124567,"['function_mock', 'function_mock.skipped']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['function_mock', 'function_mock.skipped']
*Code:

1from importlib import reload
2from unittest import SkipTest, mock
3
4from freezegun import api
5from tests import utils
6
7
8@mock.patch('platform.python_implementation', lambda: 'CPython')
9def test_should_not_skip_cpython():
10    reload(api)
11    reload(utils)
12    function_mock = mock.MagicMock(__name__='function')
13    try:
14        utils.cpython_only(function_mock)()
15    except SkipTest:
16        raise AssertionError(""Test was skipped in CPython"")
17
18
19@mock.patch('platform.python_implementation', lambda: 'not-CPython')
20def test_should_skip_non_cpython():
21    reload(api)
22    reload(utils)
23    function_mock = mock.MagicMock(__name__='function', skipped=False)
24    try:
25        utils.cpython_only(function_mock)()
26    except SkipTest:
27        function_mock.skipped = True
28",2236,"[[12, 'function_mock', '!=', None, ""the function_mock object should exist before being passed as input to the cpython_only function""],
[23, 'function_mock', '!=', None, ""the function_mock object should exist before being passed as input to the cpython_only function""],
[23, 'function_mock.skipped', '==', False, ""the function_mock.skipped attribute should be False at start of test_should_skip_non_cpython test""] ]"
hiteshgarg14/openstates,"from openstates.scrape import Scraper, Person
import re
import lxml.html


def get_field(doc, key):
    # get text_content of parent of the element containing the key
    # elem = doc.xpath('//div[@id=""member-info""]/p/strong[text()=""%s""]/..' % key)
    elem = doc.xpath('//li[contains(@class,""column"")]/h4[text()=""%s""]/../p')
    if elem:
        return elem[0].text_content().strip()
    else:
        return """"


class DCPersonScraper(Scraper):
    def scrape(self):
        council_url = ""http://dccouncil.us/councilmembers/""
        data = self.get(council_url).text
        doc = lxml.html.fromstring(data)
        doc.make_links_absolute(council_url)
        # page should have 13 unique council URLs
        urls = set(doc.xpath('//a[contains(@href, ""dccouncil.us/council/"")]/@href'))
        # print '\n'.join(urls)
        assert len(urls) <= 13, ""should have 13 unique councilmember URLs""

        for url in urls:
            data = self.get(url).text
            doc = lxml.html.fromstring(data)
            doc.make_links_absolute(url)

            descriptor = doc.xpath(
                '//div[contains(@class,""media-object-section"")]/'
                'p[contains(@class,""h4"")]/text()'
            )[0]
            title_name = doc.xpath(
                '//div[contains(@class,""media-object-section"")]/h1/text()'
            )[0]

            # removes the title that is prepended to the name
            name = re.sub(r""^Councilmember "", """", title_name)

            if ""chairman"" in descriptor.lower():
                district = ""Chairman""
            elif ""at-large"" in descriptor.lower():
                district = ""At-Large""
            else:
                district = descriptor.split(""&bullet;"")[1].strip()

            # party
            party = get_field(doc, ""Political Affiliation"")
            if ""Democratic"" in party:
                party = ""Democratic""
            elif ""Republican"" in party:
                party = ""Republican""
            else:
                party = ""Independent""

            photo_url = doc.xpath(""//figure/a/img/@src"")
            if photo_url:
                photo_url = photo_url[0]
            else:
                photo_url = """"

            office_address = get_field(doc, ""Office"")

            faxes = doc.xpath('//p[@class=""byline""]/text()')
            fax = faxes[-1].strip()

            email = (
                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[0]
                .text_content()
                .strip()
            )
            phone = (
                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[1]
                .text_content()
                .strip()
            )

            bio = ""\n"".join(
                doc.xpath('//div[contains(@class,""js-hide"")]/p/text()')
            ).strip()
            if doc.xpath('//p[contains(@class,""page-summary"")]'):
                short_bio = (
                    doc.xpath('//p[contains(@class,""page-summary"")]')[0]
                    .text_content()
                    .strip()
                )

            person = Person(
                name=name,
                party=party,
                image=photo_url,
                primary_org=""legislature"",
                district=str(district),
                biography=bio,
                summary=short_bio,
            )

            person.add_source(url)
            person.add_link(url)

            if office_address:
                person.add_contact_detail(
                    type=""address"", value=office_address, note=""Capitol Office""
                )
            if phone:
                person.add_contact_detail(
                    type=""voice"", value=phone, note=""Capitol Office""
                )
            if fax:
                person.add_contact_detail(type=""fax"", value=fax, note=""Capitol Office"")
            if email:
                person.add_contact_detail(
                    type=""email"", value=email, note=""Capitol Office""
                )

            yield person
","
1from openstates.scrape import Scraper, Person
2import re
3import lxml.html
4
5
6def get_field(doc, key):
7    # get text_content of parent of the element containing the key
8    # elem = doc.xpath('//div[@id=""member-info""]/p/strong[text()=""%s""]/..' % key)
9    elem = doc.xpath('//li[contains(@class,""column"")]/h4[text()=""%s""]/../p')
10    if elem:
11        return elem[0].text_content().strip()
12    else:
13        return """"
14
15
16class DCPersonScraper(Scraper):
17    def scrape(self):
18        council_url = ""http://dccouncil.us/councilmembers/""
19        data = self.get(council_url).text
20        doc = lxml.html.fromstring(data)
21        doc.make_links_absolute(council_url)
22        # page should have 13 unique council URLs
23        urls = set(doc.xpath('//a[contains(@href, ""dccouncil.us/council/"")]/@href'))
24        # print '\n'.join(urls)
25
26        for url in urls:
27            data = self.get(url).text
28            doc = lxml.html.fromstring(data)
29            doc.make_links_absolute(url)
30
31            descriptor = doc.xpath(
32                '//div[contains(@class,""media-object-section"")]/'
33                'p[contains(@class,""h4"")]/text()'
34            )[0]
35            title_name = doc.xpath(
36                '//div[contains(@class,""media-object-section"")]/h1/text()'
37            )[0]
38
39            # removes the title that is prepended to the name
40            name = re.sub(r""^Councilmember "", """", title_name)
41
42            if ""chairman"" in descriptor.lower():
43                district = ""Chairman""
44            elif ""at-large"" in descriptor.lower():
45                district = ""At-Large""
46            else:
47                district = descriptor.split(""&bullet;"")[1].strip()
48
49            # party
50            party = get_field(doc, ""Political Affiliation"")
51            if ""Democratic"" in party:
52                party = ""Democratic""
53            elif ""Republican"" in party:
54                party = ""Republican""
55            else:
56                party = ""Independent""
57
58            photo_url = doc.xpath(""//figure/a/img/@src"")
59            if photo_url:
60                photo_url = photo_url[0]
61            else:
62                photo_url = """"
63
64            office_address = get_field(doc, ""Office"")
65
66            faxes = doc.xpath('//p[@class=""byline""]/text()')
67            fax = faxes[-1].strip()
68
69            email = (
70                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[0]
71                .text_content()
72                .strip()
73            )
74            phone = (
75                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[1]
76                .text_content()
77                .strip()
78            )
79
80            bio = ""\n"".join(
81                doc.xpath('//div[contains(@class,""js-hide"")]/p/text()')
82            ).strip()
83            if doc.xpath('//p[contains(@class,""page-summary"")]'):
84                short_bio = (
85                    doc.xpath('//p[contains(@class,""page-summary"")]')[0]
86                    .text_content()
87                    .strip()
88                )
89
90            person = Person(
91                name=name,
92                party=party,
93                image=photo_url,
94                primary_org=""legislature"",
95                district=str(district),
96                biography=bio,
97                summary=short_bio,
98            )
99
100            person.add_source(url)
101            person.add_link(url)
102
103            if office_address:
104                person.add_contact_detail(
105                    type=""address"", value=office_address, note=""Capitol Office""
106                )
107            if phone:
108                person.add_contact_detail(
109                    type=""voice"", value=phone, note=""Capitol Office""
110                )
111            if fax:
112                person.add_contact_detail(type=""fax"", value=fax, note=""Capitol Office"")
113            if email:
114                person.add_contact_detail(
115                    type=""email"", value=email, note=""Capitol Office""
116                )
117
118            yield person
119","[['len(urls)', '<=', '13']]",1,1,1.0,0.0002480774001488,"['doc', 'key', '# elem', 'elem', 'council_url', 'data', 'urls', 'descriptor', 'title_name', 'name', 'district', 'party', 'photo_url', 'office_address', 'faxes', 'fax', 'email', 'phone', 'bio', 'short_bio', 'person']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['doc', 'key', '# elem', 'elem', 'council_url', 'data', 'urls', 'descriptor', 'title_name', 'name', 'district', 'party', 'photo_url', 'office_address', 'faxes', 'fax', 'email', 'phone', 'bio', 'short_bio', 'person']
*Code:

1from openstates.scrape import Scraper, Person
2import re
3import lxml.html
4
5
6def get_field(doc, key):
7    # get text_content of parent of the element containing the key
8    # elem = doc.xpath('//div[@id=""member-info""]/p/strong[text()=""%s""]/..' % key)
9    elem = doc.xpath('//li[contains(@class,""column"")]/h4[text()=""%s""]/../p')
10    if elem:
11        return elem[0].text_content().strip()
12    else:
13        return """"
14
15
16class DCPersonScraper(Scraper):
17    def scrape(self):
18        council_url = ""http://dccouncil.us/councilmembers/""
19        data = self.get(council_url).text
20        doc = lxml.html.fromstring(data)
21        doc.make_links_absolute(council_url)
22        # page should have 13 unique council URLs
23        urls = set(doc.xpath('//a[contains(@href, ""dccouncil.us/council/"")]/@href'))
24        # print '\n'.join(urls)
25
26        for url in urls:
27            data = self.get(url).text
28            doc = lxml.html.fromstring(data)
29            doc.make_links_absolute(url)
30
31            descriptor = doc.xpath(
32                '//div[contains(@class,""media-object-section"")]/'
33                'p[contains(@class,""h4"")]/text()'
34            )[0]
35            title_name = doc.xpath(
36                '//div[contains(@class,""media-object-section"")]/h1/text()'
37            )[0]
38
39            # removes the title that is prepended to the name
40            name = re.sub(r""^Councilmember "", """", title_name)
41
42            if ""chairman"" in descriptor.lower():
43                district = ""Chairman""
44            elif ""at-large"" in descriptor.lower():
45                district = ""At-Large""
46            else:
47                district = descriptor.split(""&bullet;"")[1].strip()
48
49            # party
50            party = get_field(doc, ""Political Affiliation"")
51            if ""Democratic"" in party:
52                party = ""Democratic""
53            elif ""Republican"" in party:
54                party = ""Republican""
55            else:
56                party = ""Independent""
57
58            photo_url = doc.xpath(""//figure/a/img/@src"")
59            if photo_url:
60                photo_url = photo_url[0]
61            else:
62                photo_url = """"
63
64            office_address = get_field(doc, ""Office"")
65
66            faxes = doc.xpath('//p[@class=""byline""]/text()')
67            fax = faxes[-1].strip()
68
69            email = (
70                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[0]
71                .text_content()
72                .strip()
73            )
74            phone = (
75                doc.xpath('//p[@class=""byline""]/a[@class=""contact-link""]')[1]
76                .text_content()
77                .strip()
78            )
79
80            bio = ""\n"".join(
81                doc.xpath('//div[contains(@class,""js-hide"")]/p/text()')
82            ).strip()
83            if doc.xpath('//p[contains(@class,""page-summary"")]'):
84                short_bio = (
85                    doc.xpath('//p[contains(@class,""page-summary"")]')[0]
86                    .text_content()
87                    .strip()
88                )
89
90            person = Person(
91                name=name,
92                party=party,
93                image=photo_url,
94                primary_org=""legislature"",
95                district=str(district),
96                biography=bio,
97                summary=short_bio,
98            )
99
100            person.add_source(url)
101            person.add_link(url)
102
103            if office_address:
104                person.add_contact_detail(
105                    type=""address"", value=office_address, note=""Capitol Office""
106                )
107            if phone:
108                person.add_contact_detail(
109                    type=""voice"", value=phone, note=""Capitol Office""
110                )
111            if fax:
112                person.add_contact_detail(type=""fax"", value=fax, note=""Capitol Office"")
113            if email:
114                person.add_contact_detail(
115                    type=""email"", value=email, note=""Capitol Office""
116                )
117
118            yield person
119",5801,"[[16, 'Scraper', '==', 'Scraper', 'To ensure that the class DCPersonScraper is a Scraper'], 
[21, 'council_url', '==', 'council_url', 'Asserting that the council_url is correctly identified'],
[23, '# elem', '<=', 13, 'The webpage should have 13 unique council URLs'],
[39, 'name', '!=', '', 'name should not be an empty string'], 
[47, 'district', '!=', '', 'district should not be an empty string'],
[56, 'party', '!=', '', 'party should not be an empty string'], 
[62, 'photo_url', '!=', '', 'photo_url should not be an empty string'],
[64, 'office_address', '!=', '', 'office_address should not be an empty string'],
[78, 'phone', '!=', '', 'phone should not be an empty string'],
[81, 'bio', '!=', '', 'bio should not be an empty string'], 
[89, 'short_bio', '!=', '', 'short_bio should not be an empty string'], 
[90, 'person', '==', 'person', 'Asserting that the person information is correctly compiled'], 
[107, 'phone', '!=', '', 'Asserting that the phone details are not empty'], 
[111, 'fax', '!=', '', 'Asserting that the fax details are not empty'],
[115, 'email', '!=', '', 'Asserting that the email details are not empty']]"
eduNEXT/edx-platform,"""""""  # lint-amnesty, pylint: disable=django-not-configured
Tests of the update_fixtures management command for bok-choy test database
initialization.
""""""


import os

import pytest
from django.contrib.sites.models import Site
from django.core.management import call_command


@pytest.fixture(scope='function')
def sites(db):  # lint-amnesty, pylint: disable=unused-argument
    Site.objects.create(name='cms', domain='localhost:8031')
    Site.objects.create(name='lms', domain='localhost:8003')


def test_localhost(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
    monkeypatch.delitem(os.environ, 'BOK_CHOY_HOSTNAME', raising=False)
    call_command('update_fixtures')
    assert Site.objects.get(name='cms').domain == 'localhost:8031'
    assert Site.objects.get(name='lms').domain == 'localhost:8003'


def test_devstack_cms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.cms')
    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
    call_command('update_fixtures')
    assert Site.objects.get(name='cms').domain == 'edx.devstack.cms:18031'
    assert Site.objects.get(name='lms').domain == 'edx.devstack.cms:18003'


def test_devstack_lms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.lms')
    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
    call_command('update_fixtures')
    assert Site.objects.get(name='cms').domain == 'edx.devstack.lms:18031'
    assert Site.objects.get(name='lms').domain == 'edx.devstack.lms:18003'
","
1""""""  # lint-amnesty, pylint: disable=django-not-configured
2Tests of the update_fixtures management command for bok-choy test database
3initialization.
4""""""
5
6
7import os
8
9import pytest
10from django.contrib.sites.models import Site
11from django.core.management import call_command
12
13
14@pytest.fixture(scope='function')
15def sites(db):  # lint-amnesty, pylint: disable=unused-argument
16    Site.objects.create(name='cms', domain='localhost:8031')
17    Site.objects.create(name='lms', domain='localhost:8003')
18
19
20def test_localhost(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
21    monkeypatch.delitem(os.environ, 'BOK_CHOY_HOSTNAME', raising=False)
22    call_command('update_fixtures')
23
24
25def test_devstack_cms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
26    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.cms')
27    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
28    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
29    call_command('update_fixtures')
30
31
32def test_devstack_lms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
33    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.lms')
34    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
35    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
36    call_command('update_fixtures')
37","[[""Site.objects.get(name='cms').domain"", '==', ""'localhost:8031'""], [""Site.objects.get(name='lms').domain"", '==', ""'localhost:8003'""], [""Site.objects.get(name='cms').domain"", '==', ""'edx.devstack.cms:18031'""], [""Site.objects.get(name='lms').domain"", '==', ""'edx.devstack.cms:18003'""], [""Site.objects.get(name='cms').domain"", '==', ""'edx.devstack.lms:18031'""], [""Site.objects.get(name='lms').domain"", '==', ""'edx.devstack.lms:18003'""]]",6,6,1.0,0.003183023872679,"['db', 'monkeypatch', 'sites']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['db', 'monkeypatch', 'sites']
*Code:

1""""""  # lint-amnesty, pylint: disable=django-not-configured
2Tests of the update_fixtures management command for bok-choy test database
3initialization.
4""""""
5
6
7import os
8
9import pytest
10from django.contrib.sites.models import Site
11from django.core.management import call_command
12
13
14@pytest.fixture(scope='function')
15def sites(db):  # lint-amnesty, pylint: disable=unused-argument
16    Site.objects.create(name='cms', domain='localhost:8031')
17    Site.objects.create(name='lms', domain='localhost:8003')
18
19
20def test_localhost(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
21    monkeypatch.delitem(os.environ, 'BOK_CHOY_HOSTNAME', raising=False)
22    call_command('update_fixtures')
23
24
25def test_devstack_cms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
26    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.cms')
27    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
28    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
29    call_command('update_fixtures')
30
31
32def test_devstack_lms(db, monkeypatch, sites):  # lint-amnesty, pylint: disable=redefined-outer-name, unused-argument
33    monkeypatch.setitem(os.environ, 'BOK_CHOY_HOSTNAME', 'edx.devstack.lms')
34    monkeypatch.setitem(os.environ, 'BOK_CHOY_CMS_PORT', '18031')
35    monkeypatch.setitem(os.environ, 'BOK_CHOY_LMS_PORT', '18003')
36    call_command('update_fixtures')
37",2927,"Based on the input provided, the following assertions are proposed:

[14, 'db', '!=', None, ""db is needed for database operations.""]
[14, 'monkeypatch', '!=', None, ""monkeypatch is used in the test functions, it should not be None.""]
[14, 'sites', '!=', None, ""sites is used in the test functions, it should not be None.""]"
iotile/coretools,"import msgpack
from datetime import datetime
from iotile.core.hw.reports import FlexibleDictionaryReport


def test_decoding_flexible_report():
    """"""Make sure we can decode a msgpack encoded report.""""""

    data = {
        ""format"": ""v100"",
        ""device"": 10,
        ""streamer_index"": 100,
        ""streamer_selector"": 65536,
        ""device_sent_timestamp"": 1,
        ""incremental_id"": 1,
        ""lowest_id"": 2,
        ""highest_id"": 3,
        ""events"": [
            {
                ""stream"": ""5020"",
                ""device_timestamp"": None,
                ""timestamp"": ""2018-01-20T00:00:00Z"",
                ""streamer_local_id"": 2,
                ""dirty_ts"": False,
                ""extra_data"": {
                    ""axis"": ""z"",
                    ""peak"": 45.41939932879673,
                    ""duration"": 15,
                    ""delta_v_x"": 0.0,
                    ""delta_v_y"": 0.0,
                    ""delta_v_z"": 0.0
                }
            },
            {
                ""stream"": ""5020"",
                ""device_timestamp"": None,
                ""timestamp"": ""2018-01-20T01:12:00Z"",
                ""streamer_local_id"": 3,
                ""dirty_ts"": False,
                ""extra_data"": {
                    ""axis"": ""z"",
                    ""peak"": 58.13753330123034,
                    ""duration"": 15,
                    ""delta_v_x"": 0.0,
                    ""delta_v_y"": 0.0,
                    ""delta_v_z"": 0.0
                }
            }
        ]
    }

    encoded = msgpack.packb(data)
    decoded = msgpack.unpackb(encoded)
    report = FlexibleDictionaryReport(encoded, False, False)

    assert len(report.visible_readings) == 0
    assert len(report.visible_events) == 2

    ev1 = report.visible_events[0]
    ev2 = report.visible_events[1]

    assert isinstance(ev1.reading_time, datetime)
    assert isinstance(ev2.reading_time, datetime)

    assert ev1.summary_data == {
        ""axis"": ""z"",
        ""peak"": 45.41939932879673,
        ""duration"": 15,
        ""delta_v_x"": 0.0,
        ""delta_v_y"": 0.0,
        ""delta_v_z"": 0.0
    }

    assert ev2.summary_data == {
        ""axis"": ""z"",
        ""peak"": 58.13753330123034,
        ""duration"": 15,
        ""delta_v_x"": 0.0,
        ""delta_v_y"": 0.0,
        ""delta_v_z"": 0.0
    }
","
1import msgpack
2from datetime import datetime
3from iotile.core.hw.reports import FlexibleDictionaryReport
4
5
6def test_decoding_flexible_report():
7    """"""Make sure we can decode a msgpack encoded report.""""""
8
9    data = {
10        ""format"": ""v100"",
11        ""device"": 10,
12        ""streamer_index"": 100,
13        ""streamer_selector"": 65536,
14        ""device_sent_timestamp"": 1,
15        ""incremental_id"": 1,
16        ""lowest_id"": 2,
17        ""highest_id"": 3,
18        ""events"": [
19            {
20                ""stream"": ""5020"",
21                ""device_timestamp"": None,
22                ""timestamp"": ""2018-01-20T00:00:00Z"",
23                ""streamer_local_id"": 2,
24                ""dirty_ts"": False,
25                ""extra_data"": {
26                    ""axis"": ""z"",
27                    ""peak"": 45.41939932879673,
28                    ""duration"": 15,
29                    ""delta_v_x"": 0.0,
30                    ""delta_v_y"": 0.0,
31                    ""delta_v_z"": 0.0
32                }
33            },
34            {
35                ""stream"": ""5020"",
36                ""device_timestamp"": None,
37                ""timestamp"": ""2018-01-20T01:12:00Z"",
38                ""streamer_local_id"": 3,
39                ""dirty_ts"": False,
40                ""extra_data"": {
41                    ""axis"": ""z"",
42                    ""peak"": 58.13753330123034,
43                    ""duration"": 15,
44                    ""delta_v_x"": 0.0,
45                    ""delta_v_y"": 0.0,
46                    ""delta_v_z"": 0.0
47                }
48            }
49        ]
50    }
51
52    encoded = msgpack.packb(data)
53    decoded = msgpack.unpackb(encoded)
54    report = FlexibleDictionaryReport(encoded, False, False)
55
56
57    ev1 = report.visible_events[0]
58    ev2 = report.visible_events[1]
59
60
61        ""axis"": ""z"",
62        ""peak"": 45.41939932879673,
63        ""duration"": 15,
64        ""delta_v_x"": 0.0,
65        ""delta_v_y"": 0.0,
66        ""delta_v_z"": 0.0
67    }
68
69        ""axis"": ""z"",
70        ""peak"": 58.13753330123034,
71        ""duration"": 15,
72        ""delta_v_x"": 0.0,
73        ""delta_v_y"": 0.0,
74        ""delta_v_z"": 0.0
75    }
76","[['len(report.visible_readings)', '==', '0'], ['len(report.visible_events)', '==', '2'], ['ev1.summary_data', '==', '{'], ['ev2.summary_data', '==', '{']]",6,4,0.6666666666666666,0.0017421602787456,"['data', 'encoded', 'decoded', 'report', 'ev1', 'ev2']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['data', 'encoded', 'decoded', 'report', 'ev1', 'ev2']
*Code:

1import msgpack
2from datetime import datetime
3from iotile.core.hw.reports import FlexibleDictionaryReport
4
5
6def test_decoding_flexible_report():
7    """"""Make sure we can decode a msgpack encoded report.""""""
8
9    data = {
10        ""format"": ""v100"",
11        ""device"": 10,
12        ""streamer_index"": 100,
13        ""streamer_selector"": 65536,
14        ""device_sent_timestamp"": 1,
15        ""incremental_id"": 1,
16        ""lowest_id"": 2,
17        ""highest_id"": 3,
18        ""events"": [
19            {
20                ""stream"": ""5020"",
21                ""device_timestamp"": None,
22                ""timestamp"": ""2018-01-20T00:00:00Z"",
23                ""streamer_local_id"": 2,
24                ""dirty_ts"": False,
25                ""extra_data"": {
26                    ""axis"": ""z"",
27                    ""peak"": 45.41939932879673,
28                    ""duration"": 15,
29                    ""delta_v_x"": 0.0,
30                    ""delta_v_y"": 0.0,
31                    ""delta_v_z"": 0.0
32                }
33            },
34            {
35                ""stream"": ""5020"",
36                ""device_timestamp"": None,
37                ""timestamp"": ""2018-01-20T01:12:00Z"",
38                ""streamer_local_id"": 3,
39                ""dirty_ts"": False,
40                ""extra_data"": {
41                    ""axis"": ""z"",
42                    ""peak"": 58.13753330123034,
43                    ""duration"": 15,
44                    ""delta_v_x"": 0.0,
45                    ""delta_v_y"": 0.0,
46                    ""delta_v_z"": 0.0
47                }
48            }
49        ]
50    }
51
52    encoded = msgpack.packb(data)
53    decoded = msgpack.unpackb(encoded)
54    report = FlexibleDictionaryReport(encoded, False, False)
55
56
57    ev1 = report.visible_events[0]
58    ev2 = report.visible_events[1]
59
60
61        ""axis"": ""z"",
62        ""peak"": 45.41939932879673,
63        ""duration"": 15,
64        ""delta_v_x"": 0.0,
65        ""delta_v_y"": 0.0,
66        ""delta_v_z"": 0.0
67    }
68
69        ""axis"": ""z"",
70        ""peak"": 58.13753330123034,
71        ""duration"": 15,
72        ""delta_v_x"": 0.0,
73        ""delta_v_y"": 0.0,
74        ""delta_v_z"": 0.0
75    }
76",3620,"[[52, 'encoded', '!=', None, 'ensure encoding was successful'],
 [53, 'decoded', '!=', None, 'ensure decoding was successful'],
 [54, 'report', '!=', None, 'ensure report was successfully created'],
 [56, 'ev1', '!=', None, 'ensure first event is not empty'],
 [57, 'ev2', '!=', None, 'ensure second event is not empty']]"
mmcco/Verified-BPF,"#!/usr/bin/python
import sys

def read_constraints(file):
    lines = file.readlines()

    nodes = set()
    edges = set()

    last = None
    for ln in lines:
        ln = ln.replace(';', '')
        parts = ln.split()
        if len(parts) == 3:
            last = parts[0]
        elif len(parts) == 2:
            parts = [last, parts[0], parts[1]]
        else:
            assert False
            
        st = parts[0].strip()
        en = parts[2].strip()
        nodes.add(st)
        nodes.add(en)
        edges.add((st,en,parts[1].strip()))

    return (nodes, edges)

def dump_smt(nodes, edges, out=sys.stdout):
    def name_of(n):
        return n.replace('.', '_')

    for n in nodes:
        out.write(""(define %s::int)\n"" % name_of(n))
    out.write(""\n"")
    for (st, en, op) in edges:
        out.write(""(assert (%s %s %s))\n"" % (op, name_of(st), name_of(en)))
        
    out.write(""(exit)\n"")

if __name__ == '__main__':
    (nodes, edges) = read_constraints(sys.stdin)

    dump_smt(nodes, edges)
","
1#!/usr/bin/python
2import sys
3
4def read_constraints(file):
5    lines = file.readlines()
6
7    nodes = set()
8    edges = set()
9
10    last = None
11    for ln in lines:
12        ln = ln.replace(';', '')
13        parts = ln.split()
14        if len(parts) == 3:
15            last = parts[0]
16        elif len(parts) == 2:
17            parts = [last, parts[0], parts[1]]
18        else:
19            
20        st = parts[0].strip()
21        en = parts[2].strip()
22        nodes.add(st)
23        nodes.add(en)
24        edges.add((st,en,parts[1].strip()))
25
26    return (nodes, edges)
27
28def dump_smt(nodes, edges, out=sys.stdout):
29    def name_of(n):
30        return n.replace('.', '_')
31
32    for n in nodes:
33        out.write(""(define %s::int)\n"" % name_of(n))
34    out.write(""\n"")
35    for (st, en, op) in edges:
36        
37    out.write(""(exit)\n"")
38
39if __name__ == '__main__':
40    (nodes, edges) = read_constraints(sys.stdin)
41
42    dump_smt(nodes, edges)
43","[['False', '==', 'True']]",2,1,0.5,0.0009775171065493,"['file', 'lines', 'nodes', 'edges', 'last', 'ln', 'parts', 'st', 'en', 'out', 'n', '(nodes', 'edges)']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['file', 'lines', 'nodes', 'edges', 'last', 'ln', 'parts', 'st', 'en', 'out', 'n', '(nodes', 'edges)']
*Code:

1#!/usr/bin/python
2import sys
3
4def read_constraints(file):
5    lines = file.readlines()
6
7    nodes = set()
8    edges = set()
9
10    last = None
11    for ln in lines:
12        ln = ln.replace(';', '')
13        parts = ln.split()
14        if len(parts) == 3:
15            last = parts[0]
16        elif len(parts) == 2:
17            parts = [last, parts[0], parts[1]]
18        else:
19            
20        st = parts[0].strip()
21        en = parts[2].strip()
22        nodes.add(st)
23        nodes.add(en)
24        edges.add((st,en,parts[1].strip()))
25
26    return (nodes, edges)
27
28def dump_smt(nodes, edges, out=sys.stdout):
29    def name_of(n):
30        return n.replace('.', '_')
31
32    for n in nodes:
33        out.write(""(define %s::int)\n"" % name_of(n))
34    out.write(""\n"")
35    for (st, en, op) in edges:
36        
37    out.write(""(exit)\n"")
38
39if __name__ == '__main__':
40    (nodes, edges) = read_constraints(sys.stdin)
41
42    dump_smt(nodes, edges)
43",2482,"[[5, 'lines', '!=', None, 'file.readlines() should not return None'],
 [14, 'parts', '==', 3, 'parts should always be of length 3 after splitting'],
 [17, 'parts', '==', 3, 'parts should always be of length 3 after adjusting'],
 [26, '(nodes, edges)', '!=', None, 'function should not return None'],
 [29, 'n', '!=', None, 'the function parameter should not be None'],
 [33, 'n', '!=', None, 'the function parameter should not be None'],
 [35, '(st, en, op)', '!=', None, 'each element in the set edges should be a tuple of length 3'],
 [40, '(nodes, edges)', '!=', None, 'read_constraints function should not return None']]"
AMOSoft/fabtools,"import pytest

from fabtools.files import is_file


pytestmark = pytest.mark.network


@pytest.fixture(scope='module', autouse=True)
def skip_all():
        pytest.skip(""Currently unmaintained"")


def test_require_default_jdk_version():

    from fabtools.oracle_jdk import version, DEFAULT_VERSION
    from fabtools.require.oracle_jdk import installed

    installed()

    assert is_file('/opt/jdk/bin/java')
    assert version() == DEFAULT_VERSION


def test_require_jdk_version_6():

    from fabtools.oracle_jdk import version
    from fabtools.require.oracle_jdk import installed

    installed('6u45-b06')

    assert is_file('/opt/jdk/bin/java')
    assert version() == '6u45-b06'
","
1import pytest
2
3from fabtools.files import is_file
4
5
6pytestmark = pytest.mark.network
7
8
9@pytest.fixture(scope='module', autouse=True)
10def skip_all():
11        pytest.skip(""Currently unmaintained"")
12
13
14def test_require_default_jdk_version():
15
16    from fabtools.oracle_jdk import version, DEFAULT_VERSION
17    from fabtools.require.oracle_jdk import installed
18
19    installed()
20
21
22
23def test_require_jdk_version_6():
24
25    from fabtools.oracle_jdk import version
26    from fabtools.require.oracle_jdk import installed
27
28    installed('6u45-b06')
29
30","[[""is_file('/opt/jdk/bin/java')"", '==', 'True'], ['version()', '==', 'DEFAULT_VERSION'], [""is_file('/opt/jdk/bin/java')"", '==', 'True'], ['version()', '==', ""'6u45-b06'""]]",4,4,1.0,0.0058055152394775,['pytestmark'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pytestmark']
*Code:

1import pytest
2
3from fabtools.files import is_file
4
5
6pytestmark = pytest.mark.network
7
8
9@pytest.fixture(scope='module', autouse=True)
10def skip_all():
11        pytest.skip(""Currently unmaintained"")
12
13
14def test_require_default_jdk_version():
15
16    from fabtools.oracle_jdk import version, DEFAULT_VERSION
17    from fabtools.require.oracle_jdk import installed
18
19    installed()
20
21
22
23def test_require_jdk_version_6():
24
25    from fabtools.oracle_jdk import version
26    from fabtools.require.oracle_jdk import installed
27
28    installed('6u45-b06')
29
30",1980,"There are no assertions to be made in this code. The pytest commands are used for testing outside the actual code, and there are no calculations, conditionals, or other similar coding components that could lead to knots so no assumptions to assert are necessary."
souravsingh/sympy,"from __future__ import division

from sympy import I, Rational, Symbol, pi, sqrt
from sympy.geometry import Line, Point, Point2D, Point3D, Line3D
from sympy.geometry.entity import rotate, scale, translate
from sympy.matrices import Matrix
from sympy.utilities.pytest import raises


def test_point():
    x = Symbol('x', real=True)
    y = Symbol('y', real=True)
    x1 = Symbol('x1', real=True)
    x2 = Symbol('x2', real=True)
    y1 = Symbol('y1', real=True)
    y2 = Symbol('y2', real=True)
    half = Rational(1, 2)
    p1 = Point(x1, x2)
    p2 = Point(y1, y2)
    p3 = Point(0, 0)
    p4 = Point(1, 1)
    p5 = Point(0, 1)

    assert p1 in p1
    assert p1 not in p2
    assert p2.y == y2
    assert (p3 + p4) == p4
    assert (p2 - p1) == Point(y1 - x1, y2 - x2)
    assert p4*5 == Point(5, 5)
    assert -p2 == Point(-y1, -y2)
    raises(ValueError, lambda: Point(3, I))
    raises(ValueError, lambda: Point(2*I, I))
    raises(ValueError, lambda: Point(3 + I, I))

    assert Point(34.05, sqrt(3)) == Point(Rational(681, 20), sqrt(3))
    assert Point.midpoint(p3, p4) == Point(half, half)
    assert Point.midpoint(p1, p4) == Point(half + half*x1, half + half*x2)
    assert Point.midpoint(p2, p2) == p2
    assert p2.midpoint(p2) == p2

    assert Point.distance(p3, p4) == sqrt(2)
    assert Point.distance(p1, p1) == 0
    assert Point.distance(p3, p2) == sqrt(p2.x**2 + p2.y**2)

    assert Point.taxicab_distance(p4, p3) == 2

    p1_1 = Point(x1, x1)
    p1_2 = Point(y2, y2)
    p1_3 = Point(x1 + 1, x1)
    assert Point.is_collinear(p3)
    assert Point.is_collinear(p3, p4)
    assert Point.is_collinear(p3, p4, p1_1, p1_2)
    assert Point.is_collinear(p3, p4, p1_1, p1_3) is False
    assert Point.is_collinear(p3, p3, p4, p5) is False
    line = Line(Point(1,0), slope = 1)
    raises(TypeError, lambda: Point.is_collinear(line))
    raises(TypeError, lambda: p1_1.is_collinear(line))

    assert p3.intersection(Point(0, 0)) == [p3]
    assert p3.intersection(p4) == []

    x_pos = Symbol('x', real=True, positive=True)
    p2_1 = Point(x_pos, 0)
    p2_2 = Point(0, x_pos)
    p2_3 = Point(-x_pos, 0)
    p2_4 = Point(0, -x_pos)
    p2_5 = Point(x_pos, 5)
    assert Point.is_concyclic(p2_1)
    assert Point.is_concyclic(p2_1, p2_2)
    assert Point.is_concyclic(p2_1, p2_2, p2_3, p2_4)
    assert Point.is_concyclic(p2_1, p2_2, p2_3, p2_5) is False
    assert Point.is_concyclic(p4, p4 * 2, p4 * 3) is False

    assert p4.scale(2, 3) == Point(2, 3)
    assert p3.scale(2, 3) == p3

    assert p4.rotate(pi, Point(0.5, 0.5)) == p3
    assert p1.__radd__(p2) == p1.midpoint(p2).scale(2, 2)
    assert (-p3).__rsub__(p4) == p3.midpoint(p4).scale(2, 2)

    assert p4 * 5 == Point(5, 5)
    assert p4 / 5 == Point(0.2, 0.2)

    raises(ValueError, lambda: Point(0, 0) + 10)

    # Point differences should be simplified
    assert Point(x*(x - 1), y) - Point(x**2 - x, y + 1) == Point(0, -1)

    a, b = Rational(1, 2), Rational(1, 3)
    assert Point(a, b).evalf(2) == \
        Point(a.n(2), b.n(2))
    raises(ValueError, lambda: Point(1, 2) + 1)

    # test transformations
    p = Point(1, 0)
    assert p.rotate(pi/2) == Point(0, 1)
    assert p.rotate(pi/2, p) == p
    p = Point(1, 1)
    assert p.scale(2, 3) == Point(2, 3)
    assert p.translate(1, 2) == Point(2, 3)
    assert p.translate(1) == Point(2, 1)
    assert p.translate(y=1) == Point(1, 2)
    assert p.translate(*p.args) == Point(2, 2)

    # Check invalid input for transform
    raises(ValueError, lambda: p3.transform(p3))
    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))


def test_point3D():
    x = Symbol('x', real=True)
    y = Symbol('y', real=True)
    x1 = Symbol('x1', real=True)
    x2 = Symbol('x2', real=True)
    x3 = Symbol('x3', real=True)
    y1 = Symbol('y1', real=True)
    y2 = Symbol('y2', real=True)
    y3 = Symbol('y3', real=True)
    half = Rational(1, 2)
    p1 = Point3D(x1, x2, x3)
    p2 = Point3D(y1, y2, y3)
    p3 = Point3D(0, 0, 0)
    p4 = Point3D(1, 1, 1)
    p5 = Point3D(0, 1, 2)

    assert p1 in p1
    assert p1 not in p2
    assert p2.y == y2
    assert (p3 + p4) == p4
    assert (p2 - p1) == Point3D(y1 - x1, y2 - x2, y3 - x3)
    assert p4*5 == Point3D(5, 5, 5)
    assert -p2 == Point3D(-y1, -y2, -y3)

    assert Point(34.05, sqrt(3)) == Point(Rational(681, 20), sqrt(3))
    assert Point3D.midpoint(p3, p4) == Point3D(half, half, half)
    assert Point3D.midpoint(p1, p4) == Point3D(half + half*x1, half + half*x2,
                                         half + half*x3)
    assert Point3D.midpoint(p2, p2) == p2
    assert p2.midpoint(p2) == p2

    assert Point3D.distance(p3, p4) == sqrt(3)
    assert Point3D.distance(p1, p1) == 0
    assert Point3D.distance(p3, p2) == sqrt(p2.x**2 + p2.y**2 + p2.z**2)

    p1_1 = Point3D(x1, x1, x1)
    p1_2 = Point3D(y2, y2, y2)
    p1_3 = Point3D(x1 + 1, x1, x1)
    # according to the description in the docs, points are collinear
    # if they like on a single line.  Thus a single point should always
    # be collinear
    assert Point3D.are_collinear(p3)
    assert Point3D.are_collinear(p3, p4)
    assert Point3D.are_collinear(p3, p4, p1_1, p1_2)
    assert Point3D.are_collinear(p3, p4, p1_1, p1_3) is False
    assert Point3D.are_collinear(p3, p3, p4, p5) is False

    assert p3.intersection(Point3D(0, 0, 0)) == [p3]
    assert p3.intersection(p4) == []


    assert p4 * 5 == Point3D(5, 5, 5)
    assert p4 / 5 == Point3D(0.2, 0.2, 0.2)

    raises(ValueError, lambda: Point3D(0, 0, 0) + 10)

    # Point differences should be simplified
    assert Point3D(x*(x - 1), y, 2) - Point3D(x**2 - x, y + 1, 1) == \
        Point3D(0, -1, 1)

    a, b = Rational(1, 2), Rational(1, 3)
    assert Point(a, b).evalf(2) == \
        Point(a.n(2), b.n(2))
    raises(ValueError, lambda: Point(1, 2) + 1)

    # test transformations
    p = Point3D(1, 1, 1)
    assert p.scale(2, 3) == Point3D(2, 3, 1)
    assert p.translate(1, 2) == Point3D(2, 3, 1)
    assert p.translate(1) == Point3D(2, 1, 1)
    assert p.translate(z=1) == Point3D(1, 1, 2)
    assert p.translate(*p.args) == Point3D(2, 2, 2)

    # Test __new__
    assert Point3D(Point3D(1, 2, 3), 4, 5, evaluate=False) ==  Point3D(1, 2, 3)


    # Test length property returns correctly
    assert p.length == 0
    assert p1_1.length == 0
    assert p1_2.length == 0

    # Test are_colinear type error
    raises(TypeError, lambda: Point3D.are_collinear(p, x))

    # Test are_coplanar
    planar2 = Point3D(1, -1, 1)
    planar3 = Point3D(-1, 1, 1)
    assert Point3D.are_coplanar(p, planar2, planar3) == True
    assert Point3D.are_coplanar(p, planar2, planar3, p3) == False
    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2))
    planar2 = Point3D(1, 1, 2)
    planar3 = Point3D(1, 1, 3)
    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2, planar3))

    # Test Intersection
    assert planar2.intersection(Line3D(p, planar3)) == [Point3D(1, 1, 2)]

    # Test Scale
    assert planar2.scale(1, 1, 1) == planar2
    assert planar2.scale(2, 2, 2, planar3) == Point3D(1, 1, 1)
    assert planar2.scale(1, 1, 1, p3) == planar2

    # Test Transform
    identity = Matrix([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
    assert p.transform(identity) == p
    trans = Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])
    assert p.transform(trans) == Point3D(2, 2, 2)
    raises(ValueError, lambda: p.transform(p))
    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))

    # Test Equals
    assert p.equals(x1) == False

    # Test __sub__
    p_2d = Point(0, 0)
    raises(ValueError, lambda: (p - p_2d))


def test_Point2D():

    # Test Distance
    p1 = Point2D(1, 5)
    p2 = Point2D(4, 2.5)
    p3 = (6, 3)
    assert p1.distance(p2) == sqrt(61)/2
    assert p2.distance(p3) == sqrt(17)/2


def test_issue_9214():
    p1 = Point3D(4, -2, 6)
    p2 = Point3D(1, 2, 3)
    p3 = Point3D(7, 2, 3)

    assert Point3D.are_collinear(p1, p2, p3) is False

def test_issue_11617():
    p1 = Point3D(1,0,2)
    p2 = Point2D(2,0)

    assert p1.distance(p2) == sqrt(5)

def test_transform():
    p = Point(1, 1)
    assert p.transform(rotate(pi/2)) == Point(-1, 1)
    assert p.transform(scale(3, 2)) == Point(3, 2)
    assert p.transform(translate(1, 2)) == Point(2, 3)
    assert Point(1, 1).scale(2, 3, (4, 5)) == \
        Point(-2, -7)
    assert Point(1, 1).translate(4, 5) == \
        Point(5, 6)


def test_concyclic_doctest_bug():
    p1, p2 = Point(-1, 0), Point(1, 0)
    p3, p4 = Point(0, 1), Point(-1, 2)
    assert Point.is_concyclic(p1, p2, p3)
    assert not Point.is_concyclic(p1, p2, p3, p4)
","
1from __future__ import division
2
3from sympy import I, Rational, Symbol, pi, sqrt
4from sympy.geometry import Line, Point, Point2D, Point3D, Line3D
5from sympy.geometry.entity import rotate, scale, translate
6from sympy.matrices import Matrix
7from sympy.utilities.pytest import raises
8
9
10def test_point():
11    x = Symbol('x', real=True)
12    y = Symbol('y', real=True)
13    x1 = Symbol('x1', real=True)
14    x2 = Symbol('x2', real=True)
15    y1 = Symbol('y1', real=True)
16    y2 = Symbol('y2', real=True)
17    half = Rational(1, 2)
18    p1 = Point(x1, x2)
19    p2 = Point(y1, y2)
20    p3 = Point(0, 0)
21    p4 = Point(1, 1)
22    p5 = Point(0, 1)
23
24    raises(ValueError, lambda: Point(3, I))
25    raises(ValueError, lambda: Point(2*I, I))
26    raises(ValueError, lambda: Point(3 + I, I))
27
28
29
30
31    p1_1 = Point(x1, x1)
32    p1_2 = Point(y2, y2)
33    p1_3 = Point(x1 + 1, x1)
34    line = Line(Point(1,0), slope = 1)
35    raises(TypeError, lambda: Point.is_collinear(line))
36    raises(TypeError, lambda: p1_1.is_collinear(line))
37
38
39    x_pos = Symbol('x', real=True, positive=True)
40    p2_1 = Point(x_pos, 0)
41    p2_2 = Point(0, x_pos)
42    p2_3 = Point(-x_pos, 0)
43    p2_4 = Point(0, -x_pos)
44    p2_5 = Point(x_pos, 5)
45
46
47
48
49    raises(ValueError, lambda: Point(0, 0) + 10)
50
51    # Point differences should be simplified
52
53    a, b = Rational(1, 2), Rational(1, 3)
54        Point(a.n(2), b.n(2))
55    raises(ValueError, lambda: Point(1, 2) + 1)
56
57    # test transformations
58    p = Point(1, 0)
59    p = Point(1, 1)
60
61    # Check invalid input for transform
62    raises(ValueError, lambda: p3.transform(p3))
63    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))
64
65
66def test_point3D():
67    x = Symbol('x', real=True)
68    y = Symbol('y', real=True)
69    x1 = Symbol('x1', real=True)
70    x2 = Symbol('x2', real=True)
71    x3 = Symbol('x3', real=True)
72    y1 = Symbol('y1', real=True)
73    y2 = Symbol('y2', real=True)
74    y3 = Symbol('y3', real=True)
75    half = Rational(1, 2)
76    p1 = Point3D(x1, x2, x3)
77    p2 = Point3D(y1, y2, y3)
78    p3 = Point3D(0, 0, 0)
79    p4 = Point3D(1, 1, 1)
80    p5 = Point3D(0, 1, 2)
81
82
83                                         half + half*x3)
84
85
86    p1_1 = Point3D(x1, x1, x1)
87    p1_2 = Point3D(y2, y2, y2)
88    p1_3 = Point3D(x1 + 1, x1, x1)
89    # according to the description in the docs, points are collinear
90    # if they like on a single line.  Thus a single point should always
91    # be collinear
92
93
94
95
96    raises(ValueError, lambda: Point3D(0, 0, 0) + 10)
97
98    # Point differences should be simplified
99        Point3D(0, -1, 1)
100
101    a, b = Rational(1, 2), Rational(1, 3)
102        Point(a.n(2), b.n(2))
103    raises(ValueError, lambda: Point(1, 2) + 1)
104
105    # test transformations
106    p = Point3D(1, 1, 1)
107
108    # Test __new__
109
110
111    # Test length property returns correctly
112
113    # Test are_colinear type error
114    raises(TypeError, lambda: Point3D.are_collinear(p, x))
115
116    # Test are_coplanar
117    planar2 = Point3D(1, -1, 1)
118    planar3 = Point3D(-1, 1, 1)
119    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2))
120    planar2 = Point3D(1, 1, 2)
121    planar3 = Point3D(1, 1, 3)
122    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2, planar3))
123
124    # Test Intersection
125
126    # Test Scale
127
128    # Test Transform
129    identity = Matrix([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
130    trans = Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])
131    raises(ValueError, lambda: p.transform(p))
132    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))
133
134    # Test Equals
135
136    # Test __sub__
137    p_2d = Point(0, 0)
138    raises(ValueError, lambda: (p - p_2d))
139
140
141def test_Point2D():
142
143    # Test Distance
144    p1 = Point2D(1, 5)
145    p2 = Point2D(4, 2.5)
146    p3 = (6, 3)
147
148
149def test_issue_9214():
150    p1 = Point3D(4, -2, 6)
151    p2 = Point3D(1, 2, 3)
152    p3 = Point3D(7, 2, 3)
153
154
155def test_issue_11617():
156    p1 = Point3D(1,0,2)
157    p2 = Point2D(2,0)
158
159
160def test_transform():
161    p = Point(1, 1)
162        Point(-2, -7)
163        Point(5, 6)
164
165
166def test_concyclic_doctest_bug():
167    p1, p2 = Point(-1, 0), Point(1, 0)
168    p3, p4 = Point(0, 1), Point(-1, 2)
169","[['p2.y', '==', 'y2'], ['(p3 + p4)', '==', 'p4'], ['(p2 - p1)', '==', 'Point(y1 - x1'], ['p4*5', '==', 'Point(5'], ['-p2', '==', 'Point(-y1'], ['Point(34.05', '==', 'True'], ['Point.midpoint(p3', '==', 'True'], ['Point.midpoint(p1', '==', 'True'], ['Point.midpoint(p2', '==', 'True'], ['p2.midpoint(p2)', '==', 'p2'], ['Point.distance(p3', '==', 'True'], ['Point.distance(p1', '==', 'True'], ['Point.distance(p3', '==', 'True'], ['Point.taxicab_distance(p4', '==', 'True'], ['Point.is_collinear(p3)', '==', 'True'], ['Point.is_collinear(p3', '==', 'True'], ['Point.is_collinear(p3', '==', 'True'], ['Point.is_collinear(p3', '==', 'True'], ['Point.is_collinear(p3', '==', 'True'], ['p3.intersection(Point(0', '==', 'True'], ['p3.intersection(p4)', '==', '[]'], ['Point.is_concyclic(p2_1)', '==', 'True'], ['Point.is_concyclic(p2_1', '==', 'True'], ['Point.is_concyclic(p2_1', '==', 'True'], ['Point.is_concyclic(p2_1', '==', 'True'], ['Point.is_concyclic(p4', '==', 'True'], ['p4.scale(2', '==', 'True'], ['p3.scale(2', '==', 'True'], ['p4.rotate(pi', '==', 'True'], ['p1.__radd__(p2)', '==', 'p1.midpoint(p2).scale(2'], ['(-p3).__rsub__(p4)', '==', 'p3.midpoint(p4).scale(2'], ['p4 * 5', '==', 'Point(5'], ['p4 / 5', '==', 'Point(0.2'], ['Point(x*(x', '-', '1)'], ['Point(a', '==', 'True'], ['p.rotate(pi/2)', '==', 'Point(0'], ['p.rotate(pi/2', '==', 'True'], ['p.scale(2', '==', 'True'], ['p.translate(1', '==', 'True'], ['p.translate(1)', '==', 'Point(2'], ['p.translate(y=1)', '==', 'Point(1'], ['p.translate(*p.args)', '==', 'Point(2'], ['p2.y', '==', 'y2'], ['(p3 + p4)', '==', 'p4'], ['(p2 - p1)', '==', 'Point3D(y1 - x1'], ['p4*5', '==', 'Point3D(5'], ['-p2', '==', 'Point3D(-y1'], ['Point(34.05', '==', 'True'], ['Point3D.midpoint(p3', '==', 'True'], ['Point3D.midpoint(p1', '==', 'True'], ['Point3D.midpoint(p2', '==', 'True'], ['p2.midpoint(p2)', '==', 'p2'], ['Point3D.distance(p3', '==', 'True'], ['Point3D.distance(p1', '==', 'True'], ['Point3D.distance(p3', '==', 'True'], ['Point3D.are_collinear(p3)', '==', 'True'], ['Point3D.are_collinear(p3', '==', 'True'], ['Point3D.are_collinear(p3', '==', 'True'], ['Point3D.are_collinear(p3', '==', 'True'], ['Point3D.are_collinear(p3', '==', 'True'], ['p3.intersection(Point3D(0', '==', 'True'], ['p3.intersection(p4)', '==', '[]'], ['p4 * 5', '==', 'Point3D(5'], ['p4 / 5', '==', 'Point3D(0.2'], ['Point3D(x*(x', '-', '1)'], ['Point(a', '==', 'True'], ['p.scale(2', '==', 'True'], ['p.translate(1', '==', 'True'], ['p.translate(1)', '==', 'Point3D(2'], ['p.translate(z=1)', '==', 'Point3D(1'], ['p.translate(*p.args)', '==', 'Point3D(2'], ['Point3D(Point3D(1', '==', 'True'], ['p.length', '==', '0'], ['p1_1.length', '==', '0'], ['p1_2.length', '==', '0'], ['Point3D.are_coplanar(p', '==', 'True'], ['Point3D.are_coplanar(p', '==', 'True'], ['planar2.intersection(Line3D(p', '==', 'True'], ['planar2.scale(1', '==', 'True'], ['planar2.scale(2', '==', 'True'], ['planar2.scale(1', '==', 'True'], ['p.transform(identity)', '==', 'p'], ['p.transform(trans)', '==', 'Point3D(2'], ['p.equals(x1)', '==', 'False'], ['p1.distance(p2)', '==', 'sqrt(61)/2'], ['p2.distance(p3)', '==', 'sqrt(17)/2'], ['Point3D.are_collinear(p1', '==', 'True'], ['p1.distance(p2)', '==', 'sqrt(5)'], ['p.transform(rotate(pi/2))', '==', 'Point(-1'], ['p.transform(scale(3', '==', 'True'], ['p.transform(translate(1', '==', 'True'], ['Point(1', '==', 'True'], ['Point(1', '==', 'True'], ['Point.is_concyclic(p1', '==', 'True'], ['Point.is_concyclic(p1', '==', 'False']]",99,95,0.9595959595959596,0.0109877399953735,"['x', 'y', 'x1', 'x2', 'y1', 'y2', 'half', 'p1', 'p2', 'p3', 'p4', 'p5', 'p1_1', 'p1_2', 'p1_3', 'line', 'x_pos', 'p2_1', 'p2_2', 'p2_3', 'p2_4', 'p2_5', 'a', 'b', 'p', 'x3', 'y3', 'planar2', 'planar3', 'identity', 'trans', 'p_2d']",32,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'y', 'x1', 'x2', 'y1', 'y2', 'half', 'p1', 'p2', 'p3', 'p4', 'p5', 'p1_1', 'p1_2', 'p1_3', 'line', 'x_pos', 'p2_1', 'p2_2', 'p2_3', 'p2_4', 'p2_5', 'a', 'b', 'p', 'x3', 'y3', 'planar2', 'planar3', 'identity', 'trans', 'p_2d']
*Code:

1from __future__ import division
2
3from sympy import I, Rational, Symbol, pi, sqrt
4from sympy.geometry import Line, Point, Point2D, Point3D, Line3D
5from sympy.geometry.entity import rotate, scale, translate
6from sympy.matrices import Matrix
7from sympy.utilities.pytest import raises
8
9
10def test_point():
11    x = Symbol('x', real=True)
12    y = Symbol('y', real=True)
13    x1 = Symbol('x1', real=True)
14    x2 = Symbol('x2', real=True)
15    y1 = Symbol('y1', real=True)
16    y2 = Symbol('y2', real=True)
17    half = Rational(1, 2)
18    p1 = Point(x1, x2)
19    p2 = Point(y1, y2)
20    p3 = Point(0, 0)
21    p4 = Point(1, 1)
22    p5 = Point(0, 1)
23
24    raises(ValueError, lambda: Point(3, I))
25    raises(ValueError, lambda: Point(2*I, I))
26    raises(ValueError, lambda: Point(3 + I, I))
27
28
29
30
31    p1_1 = Point(x1, x1)
32    p1_2 = Point(y2, y2)
33    p1_3 = Point(x1 + 1, x1)
34    line = Line(Point(1,0), slope = 1)
35    raises(TypeError, lambda: Point.is_collinear(line))
36    raises(TypeError, lambda: p1_1.is_collinear(line))
37
38
39    x_pos = Symbol('x', real=True, positive=True)
40    p2_1 = Point(x_pos, 0)
41    p2_2 = Point(0, x_pos)
42    p2_3 = Point(-x_pos, 0)
43    p2_4 = Point(0, -x_pos)
44    p2_5 = Point(x_pos, 5)
45
46
47
48
49    raises(ValueError, lambda: Point(0, 0) + 10)
50
51    # Point differences should be simplified
52
53    a, b = Rational(1, 2), Rational(1, 3)
54        Point(a.n(2), b.n(2))
55    raises(ValueError, lambda: Point(1, 2) + 1)
56
57    # test transformations
58    p = Point(1, 0)
59    p = Point(1, 1)
60
61    # Check invalid input for transform
62    raises(ValueError, lambda: p3.transform(p3))
63    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))
64
65
66def test_point3D():
67    x = Symbol('x', real=True)
68    y = Symbol('y', real=True)
69    x1 = Symbol('x1', real=True)
70    x2 = Symbol('x2', real=True)
71    x3 = Symbol('x3', real=True)
72    y1 = Symbol('y1', real=True)
73    y2 = Symbol('y2', real=True)
74    y3 = Symbol('y3', real=True)
75    half = Rational(1, 2)
76    p1 = Point3D(x1, x2, x3)
77    p2 = Point3D(y1, y2, y3)
78    p3 = Point3D(0, 0, 0)
79    p4 = Point3D(1, 1, 1)
80    p5 = Point3D(0, 1, 2)
81
82
83                                         half + half*x3)
84
85
86    p1_1 = Point3D(x1, x1, x1)
87    p1_2 = Point3D(y2, y2, y2)
88    p1_3 = Point3D(x1 + 1, x1, x1)
89    # according to the description in the docs, points are collinear
90    # if they like on a single line.  Thus a single point should always
91    # be collinear
92
93
94
95
96    raises(ValueError, lambda: Point3D(0, 0, 0) + 10)
97
98    # Point differences should be simplified
99        Point3D(0, -1, 1)
100
101    a, b = Rational(1, 2), Rational(1, 3)
102        Point(a.n(2), b.n(2))
103    raises(ValueError, lambda: Point(1, 2) + 1)
104
105    # test transformations
106    p = Point3D(1, 1, 1)
107
108    # Test __new__
109
110
111    # Test length property returns correctly
112
113    # Test are_colinear type error
114    raises(TypeError, lambda: Point3D.are_collinear(p, x))
115
116    # Test are_coplanar
117    planar2 = Point3D(1, -1, 1)
118    planar3 = Point3D(-1, 1, 1)
119    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2))
120    planar2 = Point3D(1, 1, 2)
121    planar3 = Point3D(1, 1, 3)
122    raises(ValueError, lambda: Point3D.are_coplanar(p, planar2, planar3))
123
124    # Test Intersection
125
126    # Test Scale
127
128    # Test Transform
129    identity = Matrix([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
130    trans = Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])
131    raises(ValueError, lambda: p.transform(p))
132    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))
133
134    # Test Equals
135
136    # Test __sub__
137    p_2d = Point(0, 0)
138    raises(ValueError, lambda: (p - p_2d))
139
140
141def test_Point2D():
142
143    # Test Distance
144    p1 = Point2D(1, 5)
145    p2 = Point2D(4, 2.5)
146    p3 = (6, 3)
147
148
149def test_issue_9214():
150    p1 = Point3D(4, -2, 6)
151    p2 = Point3D(1, 2, 3)
152    p3 = Point3D(7, 2, 3)
153
154
155def test_issue_11617():
156    p1 = Point3D(1,0,2)
157    p2 = Point2D(2,0)
158
159
160def test_transform():
161    p = Point(1, 1)
162        Point(-2, -7)
163        Point(5, 6)
164
165
166def test_concyclic_doctest_bug():
167    p1, p2 = Point(-1, 0), Point(1, 0)
168    p3, p4 = Point(0, 1), Point(-1, 2)
169",6095,"[[10, 'x', '!=', None, ""x shouldn't be a None value""],
[10, 'y', '!=', None, ""y shouldn't be a None value""],
[11, 'x1', '!=', None, ""x1 shouldn't be a None value""],
[12, 'x2', '!=', None, ""x2 shouldn't be a None value""],
[13, 'y1', '!=', None, ""y1 shouldn't be a None value""],
[14, 'y2', '!=', None, ""y2 shouldn't be a None value""],
[16, 'half', '==', 0.5, ""half should be equal to 0.5""],
[18, 'p1', '!=', None, ""Point instance p1 shouldn't be a None value""],
[19, 'p2', '!=', None, ""Point instance p2 shouldn't be a None value""],
[66, 'x3', '!=', None, ""x3 shouldn't be a None value""],
[67, 'y3', '!=', None, ""y3 shouldn't be a None value""],
[74, 'y3', '!=', None, ""y3 shouldn't be a None value""],
[75, 'half', '==', 0.5, ""half should be equal to 0.5""],
[77, 'p1', '!=', None, ""Point3D instance p1 shouldn't be a None value""],
[78, 'p2', '!=', None, ""Point3D instance p2 shouldn't be a None value""],
[130, 'identity', '!=', None, ""Matrix instance identity shouldn't be a None value""],
[131, 'trans', '!=', None, ""Matrix instance trans shouldn't be a None value""],
[137, 'p_2d', '!=', None, ""Point instance p_2d shouldn't be a None value""]]"
captain-pool/GSOC,"from absl import logging
import os
from lib import dataset
from libs import settings
import tensorflow as tf


def generate_tf_record(
        data_dir,
        raw_data=False,
        tfrecord_path=""serialized_dataset"",
        num_shards=8):

  teacher_sett = settings.Settings(use_student_settings=False)
  student_sett = settings.Settings(use_student_settings=True)
  dataset_args = teacher_sett[""dataset""]
  if dataset_args[""name""].lower().strip() == ""div2k"":
    assert len(data_dir) == 2
    ds = dataset.load_div2k_dataset(
        data_dir[0],
        data_dir[1],
        student_sett[""hr_size""],
        shuffle=True)
  elif raw_data:
    ds = dataset.load_dataset_directory(
        dataset_args[""name""],
        data_dir,
        dataset.scale_down(
            method=dataset_args[""scale_method""],
            size=student_sett[""hr_size""]))
  else:
    ds = dataset.load_dataset(
        dataset_args[""name""],
        dataset.scale_down(
            method=dataset_args[""scale_method""],
            size=student_sett[""hr_size""]),
        data_dir=data_dir)
  to_tfrecord(ds, tfrecord_path, num_shards)


def load_dataset(tfrecord_path, lr_size, hr_size):
  def _parse_tf_record(serialized_example):
    features = {
        ""low_res_image"": tf.io.FixedLenFeature([], dtype=tf.string),
        ""high_res_image"": tf.io.FixedLenFeature([], dtype=tf.string)}
    example = tf.io.parse_single_example(serialized_example, features)
    lr_image = tf.io.parse_tensor(
        example[""low_res_image""],
        out_type=tf.float32)
    lr_image = tf.reshape(lr_image, lr_size)
    hr_image = tf.io.parse_tensor(
        example[""high_res_image""],
        out_type=tf.float32)
    hr_image = tf.reshape(hr_image, hr_size)
    return lr_image, hr_image
  files = tf.io.gfile.glob(
      os.path.join(tfrecord_path, ""*.tfrecord""))
  if len(files) == 0:
    raise ValueError(""Path Doesn't contain any file"")
  ds = tf.data.TFRecordDataset(files).map(_parse_tf_record)
  if len(files) == 1:
    option = tf.data.Options()
    option.auto_shard = False
    ds.with_options(ds)
  ds = ds.shuffle(128, reshuffle_each_iteration=True)
  return ds


def to_tfrecord(ds, tfrecord_path, num_shards=8):
  def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

  def serialize_to_string(image_lr, image_hr):
    features = {
        ""low_res_image"": _bytes_feature(
            tf.io.serialize_tensor(image_lr).numpy()),
        ""high_res_image"": _bytes_feature(
            tf.io.serialize_tensor(image_hr).numpy())}
    example_proto = tf.train.Example(
        features=tf.train.Features(feature=features))
    return example_proto.SerializeToString()

  def write_to_tfrecord(shard_id, ds):
    filename = tf.strings.join(
        [tfrecord_path, ""/dataset."", tf.strings.as_string(shard_id),
         "".tfrecord""])
    writer = tf.data.experimental.TFRecordWriter(filename)
    writer.write(ds.map(lambda _, x: x))
    return tf.data.Dataset.from_tensors(filename)

  def map_serialize_to_string(image_lr, image_hr):
    map_fn = tf.py_function(
        serialize_to_string,
        (image_lr, image_hr),
        tf.string)
    return tf.reshape(map_fn, ())
  ds = ds.map(map_serialize_to_string)
  ds = ds.enumerate()
  ds = ds.apply(tf.data.experimental.group_by_window(
      lambda i, _: i % num_shards,
      write_to_tfrecord,
      tf.int64.max))
  for data in ds:
    logging.info(""Written to: %s"" % data.numpy())
","
1from absl import logging
2import os
3from lib import dataset
4from libs import settings
5import tensorflow as tf
6
7
8def generate_tf_record(
9        data_dir,
10        raw_data=False,
11        tfrecord_path=""serialized_dataset"",
12        num_shards=8):
13
14  teacher_sett = settings.Settings(use_student_settings=False)
15  student_sett = settings.Settings(use_student_settings=True)
16  dataset_args = teacher_sett[""dataset""]
17  if dataset_args[""name""].lower().strip() == ""div2k"":
18    ds = dataset.load_div2k_dataset(
19        data_dir[0],
20        data_dir[1],
21        student_sett[""hr_size""],
22        shuffle=True)
23  elif raw_data:
24    ds = dataset.load_dataset_directory(
25        dataset_args[""name""],
26        data_dir,
27        dataset.scale_down(
28            method=dataset_args[""scale_method""],
29            size=student_sett[""hr_size""]))
30  else:
31    ds = dataset.load_dataset(
32        dataset_args[""name""],
33        dataset.scale_down(
34            method=dataset_args[""scale_method""],
35            size=student_sett[""hr_size""]),
36        data_dir=data_dir)
37  to_tfrecord(ds, tfrecord_path, num_shards)
38
39
40def load_dataset(tfrecord_path, lr_size, hr_size):
41  def _parse_tf_record(serialized_example):
42    features = {
43        ""low_res_image"": tf.io.FixedLenFeature([], dtype=tf.string),
44        ""high_res_image"": tf.io.FixedLenFeature([], dtype=tf.string)}
45    example = tf.io.parse_single_example(serialized_example, features)
46    lr_image = tf.io.parse_tensor(
47        example[""low_res_image""],
48        out_type=tf.float32)
49    lr_image = tf.reshape(lr_image, lr_size)
50    hr_image = tf.io.parse_tensor(
51        example[""high_res_image""],
52        out_type=tf.float32)
53    hr_image = tf.reshape(hr_image, hr_size)
54    return lr_image, hr_image
55  files = tf.io.gfile.glob(
56      os.path.join(tfrecord_path, ""*.tfrecord""))
57  if len(files) == 0:
58    raise ValueError(""Path Doesn't contain any file"")
59  ds = tf.data.TFRecordDataset(files).map(_parse_tf_record)
60  if len(files) == 1:
61    option = tf.data.Options()
62    option.auto_shard = False
63    ds.with_options(ds)
64  ds = ds.shuffle(128, reshuffle_each_iteration=True)
65  return ds
66
67
68def to_tfrecord(ds, tfrecord_path, num_shards=8):
69  def _bytes_feature(value):
70    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
71
72  def serialize_to_string(image_lr, image_hr):
73    features = {
74        ""low_res_image"": _bytes_feature(
75            tf.io.serialize_tensor(image_lr).numpy()),
76        ""high_res_image"": _bytes_feature(
77            tf.io.serialize_tensor(image_hr).numpy())}
78    example_proto = tf.train.Example(
79        features=tf.train.Features(feature=features))
80    return example_proto.SerializeToString()
81
82  def write_to_tfrecord(shard_id, ds):
83    filename = tf.strings.join(
84        [tfrecord_path, ""/dataset."", tf.strings.as_string(shard_id),
85         "".tfrecord""])
86    writer = tf.data.experimental.TFRecordWriter(filename)
87    writer.write(ds.map(lambda _, x: x))
88    return tf.data.Dataset.from_tensors(filename)
89
90  def map_serialize_to_string(image_lr, image_hr):
91    map_fn = tf.py_function(
92        serialize_to_string,
93        (image_lr, image_hr),
94        tf.string)
95    return tf.reshape(map_fn, ())
96  ds = ds.map(map_serialize_to_string)
97  ds = ds.enumerate()
98  ds = ds.apply(tf.data.experimental.group_by_window(
99      lambda i, _: i % num_shards,
100      write_to_tfrecord,
101      tf.int64.max))
102  for data in ds:
103    logging.info(""Written to: %s"" % data.numpy())
104","[['len(data_dir)', '==', '2']]",1,1,1.0,0.0002886836027713,"['teacher_sett', 'student_sett', 'dataset_args', 'ds', 'tfrecord_path', 'lr_size', 'hr_size', 'serialized_example', 'features', 'example', 'lr_image', 'hr_image', 'files', 'option', 'option.auto_shard', 'num_shards', 'value', 'image_lr', 'image_hr', 'example_proto', 'shard_id', 'filename', 'writer', 'map_fn']",24,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['teacher_sett', 'student_sett', 'dataset_args', 'ds', 'tfrecord_path', 'lr_size', 'hr_size', 'serialized_example', 'features', 'example', 'lr_image', 'hr_image', 'files', 'option', 'option.auto_shard', 'num_shards', 'value', 'image_lr', 'image_hr', 'example_proto', 'shard_id', 'filename', 'writer', 'map_fn']
*Code:

1from absl import logging
2import os
3from lib import dataset
4from libs import settings
5import tensorflow as tf
6
7
8def generate_tf_record(
9        data_dir,
10        raw_data=False,
11        tfrecord_path=""serialized_dataset"",
12        num_shards=8):
13
14  teacher_sett = settings.Settings(use_student_settings=False)
15  student_sett = settings.Settings(use_student_settings=True)
16  dataset_args = teacher_sett[""dataset""]
17  if dataset_args[""name""].lower().strip() == ""div2k"":
18    ds = dataset.load_div2k_dataset(
19        data_dir[0],
20        data_dir[1],
21        student_sett[""hr_size""],
22        shuffle=True)
23  elif raw_data:
24    ds = dataset.load_dataset_directory(
25        dataset_args[""name""],
26        data_dir,
27        dataset.scale_down(
28            method=dataset_args[""scale_method""],
29            size=student_sett[""hr_size""]))
30  else:
31    ds = dataset.load_dataset(
32        dataset_args[""name""],
33        dataset.scale_down(
34            method=dataset_args[""scale_method""],
35            size=student_sett[""hr_size""]),
36        data_dir=data_dir)
37  to_tfrecord(ds, tfrecord_path, num_shards)
38
39
40def load_dataset(tfrecord_path, lr_size, hr_size):
41  def _parse_tf_record(serialized_example):
42    features = {
43        ""low_res_image"": tf.io.FixedLenFeature([], dtype=tf.string),
44        ""high_res_image"": tf.io.FixedLenFeature([], dtype=tf.string)}
45    example = tf.io.parse_single_example(serialized_example, features)
46    lr_image = tf.io.parse_tensor(
47        example[""low_res_image""],
48        out_type=tf.float32)
49    lr_image = tf.reshape(lr_image, lr_size)
50    hr_image = tf.io.parse_tensor(
51        example[""high_res_image""],
52        out_type=tf.float32)
53    hr_image = tf.reshape(hr_image, hr_size)
54    return lr_image, hr_image
55  files = tf.io.gfile.glob(
56      os.path.join(tfrecord_path, ""*.tfrecord""))
57  if len(files) == 0:
58    raise ValueError(""Path Doesn't contain any file"")
59  ds = tf.data.TFRecordDataset(files).map(_parse_tf_record)
60  if len(files) == 1:
61    option = tf.data.Options()
62    option.auto_shard = False
63    ds.with_options(ds)
64  ds = ds.shuffle(128, reshuffle_each_iteration=True)
65  return ds
66
67
68def to_tfrecord(ds, tfrecord_path, num_shards=8):
69  def _bytes_feature(value):
70    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
71
72  def serialize_to_string(image_lr, image_hr):
73    features = {
74        ""low_res_image"": _bytes_feature(
75            tf.io.serialize_tensor(image_lr).numpy()),
76        ""high_res_image"": _bytes_feature(
77            tf.io.serialize_tensor(image_hr).numpy())}
78    example_proto = tf.train.Example(
79        features=tf.train.Features(feature=features))
80    return example_proto.SerializeToString()
81
82  def write_to_tfrecord(shard_id, ds):
83    filename = tf.strings.join(
84        [tfrecord_path, ""/dataset."", tf.strings.as_string(shard_id),
85         "".tfrecord""])
86    writer = tf.data.experimental.TFRecordWriter(filename)
87    writer.write(ds.map(lambda _, x: x))
88    return tf.data.Dataset.from_tensors(filename)
89
90  def map_serialize_to_string(image_lr, image_hr):
91    map_fn = tf.py_function(
92        serialize_to_string,
93        (image_lr, image_hr),
94        tf.string)
95    return tf.reshape(map_fn, ())
96  ds = ds.map(map_serialize_to_string)
97  ds = ds.enumerate()
98  ds = ds.apply(tf.data.experimental.group_by_window(
99      lambda i, _: i % num_shards,
100      write_to_tfrecord,
101      tf.int64.max))
102  for data in ds:
103    logging.info(""Written to: %s"" % data.numpy())
104",5329,"[[9, 'data_dir', '!=', None, 'data_dir should not be None'],
 [11, 'tfrecord_path', '!=', None, 'tfrecord_path should not be None'],
 [12, 'num_shards', '>=', 1, 'At least one shard is necessary'],
 [40, 'tfrecord_path', '!=', None, 'tfrecord_path should not be None'],
 [40, 'lr_size', '>=', 1, 'Low resolution size should be greater than or equal to 1'],
 [40, 'hr_size', '>=', lr_size, 'The High resolution size should be greater than or equal to the Low Resolution size'],
 [55, 'files', '!=', None, 'Files should not be None'],
 [58, 'files', '!=', [], 'There should be some files in the directory'],
 [68, 'ds', '!=', None, 'Data set should not be None'],
 [68, 'tfrecord_path', '!=', None, 'tfrecord_path should not be None'],
 [68, 'num_shards', '>=', 1, 'num_shards must be greater than or equal 0'],
 [83, 'shard_id', '>=', 0, 'shard_id should not be negative'],
 [86, 'writer', '!=', None, 'Writer should not be None'],
 [87, 'ds', '!=', None, 'Data set should not be None'],
 [99, 'num_shards', '>=', 0, 'num_shards should not be negative']]"
datastore/datastore.mongo,"# NOTE: make sure you run monogod first

import pymongo
import unittest

from . import MongoDatastore
from datastore.core.test.test_basic import TestDatastore
from datastore.core import Key, Query


class TestMongoDatastore(TestDatastore):

  def setUp(self):
    self.conn = pymongo.Connection()
    self.conn.drop_database('datastore_testdb')

  def tearDown(self):
    self.conn.drop_database('datastore_testdb')
    del self.conn

  def test_mongo(self):
    ms = MongoDatastore(self.conn.datastore_testdb)
    self.subtest_simple([ms], numelems=500)

  def test_query(self):
    ms = MongoDatastore(self.conn.datastore_testdb)
    pk = Key('/users')

    a_key = pk.instance('a')
    a = {'key': str(a_key), 'name': 'A', 'age': 35}
    ms.put(a_key, a)

    b_key = pk.instance('b')
    b = {'key': str(b_key), 'name': 'B', 'age': 29}
    ms.put(b_key, b)

    res = list(ms.query(Query(pk).filter('age','>',30)))
    assert res == [a]

    res = list(ms.query(Query(pk).filter('age','>',30).filter('age','<',30)))
    assert res == []

    res = list(ms.query(Query(pk).filter('age','=',35)))
    assert res == [a]

    try:
      res = list(ms.query(Query(pk).filter('age','>',30).filter('age','=',30)))
      assert False
    except ValueError:
      pass

    res = list(ms.query(Query(pk).filter('name','!=','A')))
    assert res == [b]


if __name__ == '__main__':
  unittest.main()
","
1# NOTE: make sure you run monogod first
2
3import pymongo
4import unittest
5
6from . import MongoDatastore
7from datastore.core.test.test_basic import TestDatastore
8from datastore.core import Key, Query
9
10
11class TestMongoDatastore(TestDatastore):
12
13  def setUp(self):
14    self.conn = pymongo.Connection()
15    self.conn.drop_database('datastore_testdb')
16
17  def tearDown(self):
18    self.conn.drop_database('datastore_testdb')
19    del self.conn
20
21  def test_mongo(self):
22    ms = MongoDatastore(self.conn.datastore_testdb)
23    self.subtest_simple([ms], numelems=500)
24
25  def test_query(self):
26    ms = MongoDatastore(self.conn.datastore_testdb)
27    pk = Key('/users')
28
29    a_key = pk.instance('a')
30    a = {'key': str(a_key), 'name': 'A', 'age': 35}
31    ms.put(a_key, a)
32
33    b_key = pk.instance('b')
34    b = {'key': str(b_key), 'name': 'B', 'age': 29}
35    ms.put(b_key, b)
36
37    res = list(ms.query(Query(pk).filter('age','>',30)))
38
39    res = list(ms.query(Query(pk).filter('age','>',30).filter('age','<',30)))
40
41    res = list(ms.query(Query(pk).filter('age','=',35)))
42
43    try:
44      res = list(ms.query(Query(pk).filter('age','>',30).filter('age','=',30)))
45    except ValueError:
46      pass
47
48    res = list(ms.query(Query(pk).filter('name','!=','A')))
49
50
51if __name__ == '__main__':
52  unittest.main()
53","[['res', '==', '[a]'], ['res', '==', '[]'], ['res', '==', '[a]'], ['False', '==', 'True'], ['res', '==', '[b]']]",5,5,1.0,0.003586800573888,"['self.conn', 'ms', 'pk', 'a_key', 'a', 'b_key', 'b', 'res']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.conn', 'ms', 'pk', 'a_key', 'a', 'b_key', 'b', 'res']
*Code:

1# NOTE: make sure you run monogod first
2
3import pymongo
4import unittest
5
6from . import MongoDatastore
7from datastore.core.test.test_basic import TestDatastore
8from datastore.core import Key, Query
9
10
11class TestMongoDatastore(TestDatastore):
12
13  def setUp(self):
14    self.conn = pymongo.Connection()
15    self.conn.drop_database('datastore_testdb')
16
17  def tearDown(self):
18    self.conn.drop_database('datastore_testdb')
19    del self.conn
20
21  def test_mongo(self):
22    ms = MongoDatastore(self.conn.datastore_testdb)
23    self.subtest_simple([ms], numelems=500)
24
25  def test_query(self):
26    ms = MongoDatastore(self.conn.datastore_testdb)
27    pk = Key('/users')
28
29    a_key = pk.instance('a')
30    a = {'key': str(a_key), 'name': 'A', 'age': 35}
31    ms.put(a_key, a)
32
33    b_key = pk.instance('b')
34    b = {'key': str(b_key), 'name': 'B', 'age': 29}
35    ms.put(b_key, b)
36
37    res = list(ms.query(Query(pk).filter('age','>',30)))
38
39    res = list(ms.query(Query(pk).filter('age','>',30).filter('age','<',30)))
40
41    res = list(ms.query(Query(pk).filter('age','=',35)))
42
43    try:
44      res = list(ms.query(Query(pk).filter('age','>',30).filter('age','=',30)))
45    except ValueError:
46      pass
47
48    res = list(ms.query(Query(pk).filter('name','!=','A')))
49
50
51if __name__ == '__main__':
52  unittest.main()
53",2826,"[[13, 'self.conn', '!=', None, 'Asserts that connection is established'],
[22, 'ms', '!=', None, 'Asserts that MongoDB datastore is setup successfully'],
[31, 'a', '==', dict, 'Asserts that the data is a dictionary'],
[35, 'b', '==', dict, 'Asserts that the data is a dictionary'],
[37, 'res', '==', list, 'Asserts that the result is a list'],
[39, 'res', '==', list, 'Asserts that the result is a list'],
[41, 'res', '==', list, 'Asserts that the result is a list'],
[48, 'res', '==', list, 'Asserts that the result is a list']]"
uber/thriftrw-python,"# Copyright (c) 2016 Uber Technologies, Inc.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the ""Software""), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

from __future__ import absolute_import, unicode_literals, print_function

import pytest

from thriftrw.errors import ThriftCompilerError


@pytest.fixture
def test_unknown_type(loads):
    with pytest.raises(ThriftCompilerError) as exc_info:
        loads('''
            struct Foo { 1: optional Bar bar }
            struct Bar { 1: optional Baz baz }
        ''')

    assert 'Unknown type ""Baz""' in str(exc_info)


def test_duplicate_type_names(loads):
    with pytest.raises(ThriftCompilerError) as exc_info:
        loads('''
            typedef string foo

            struct foo { 1: required string bar }
        ''')

    assert 'Cannot define type ""foo""' in str(exc_info)
    assert 'type with that name already exists' in str(exc_info)


def test_constant_type_conflict(loads):
    with pytest.raises(ThriftCompilerError) as exc_info:
        loads('''
            const string foo = ""foo""

            struct foo { 1: required string bar }
        ''')

    assert 'Cannot define ""foo""' in str(exc_info)
    assert 'name has already been used' in str(exc_info)


def test_service_type_conflict(loads):
    with pytest.raises(ThriftCompilerError) as exc_info:
        loads('''
            struct foo { 1: required string bar }
            service foo {}
        ''')

    assert 'Cannot define ""foo""' in str(exc_info)
    assert 'name has already been used' in str(exc_info)


def test_services_and_types(loads):
    s = '''
        struct Foo {}
        union Bar {}

        service A {}
        service B {}

        const list<i32> z = [x, y];
        const i32 x = 42;
        const i32 y = 123;
    '''
    m = loads(s)

    assert {
        'z': [m.x, m.y],
        'x': 42,
        'y': 123,
    } == m.__constants__

    assert (
        m.__types__ == (m.Foo, m.Bar) or
        m.__types__ == (m.Bar, m.Foo)
    )

    assert (
        m.__services__ == (m.A, m.B) or
        m.__services__ == (m.B, m.A)
    )

    assert m.__thrift_source__ == s
","
1# Copyright (c) 2016 Uber Technologies, Inc.
2#
3# Permission is hereby granted, free of charge, to any person obtaining a copy
4# of this software and associated documentation files (the ""Software""), to deal
5# in the Software without restriction, including without limitation the rights
6# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
7# copies of the Software, and to permit persons to whom the Software is
8# furnished to do so, subject to the following conditions:
9#
10# The above copyright notice and this permission notice shall be included in
11# all copies or substantial portions of the Software.
12#
13# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
14# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
15# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
16# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
17# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
18# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
19# THE SOFTWARE.
20
21from __future__ import absolute_import, unicode_literals, print_function
22
23import pytest
24
25from thriftrw.errors import ThriftCompilerError
26
27
28@pytest.fixture
29def test_unknown_type(loads):
30    with pytest.raises(ThriftCompilerError) as exc_info:
31        loads('''
32            struct Foo { 1: optional Bar bar }
33            struct Bar { 1: optional Baz baz }
34        ''')
35
36
37
38def test_duplicate_type_names(loads):
39    with pytest.raises(ThriftCompilerError) as exc_info:
40        loads('''
41            typedef string foo
42
43            struct foo { 1: required string bar }
44        ''')
45
46
47
48def test_constant_type_conflict(loads):
49    with pytest.raises(ThriftCompilerError) as exc_info:
50        loads('''
51            const string foo = ""foo""
52
53            struct foo { 1: required string bar }
54        ''')
55
56
57
58def test_service_type_conflict(loads):
59    with pytest.raises(ThriftCompilerError) as exc_info:
60        loads('''
61            struct foo { 1: required string bar }
62            service foo {}
63        ''')
64
65
66
67def test_services_and_types(loads):
68    s = '''
69        struct Foo {}
70        union Bar {}
71
72        service A {}
73        service B {}
74
75        const list<i32> z = [x, y];
76        const i32 x = 42;
77        const i32 y = 123;
78    '''
79    m = loads(s)
80
81        'z': [m.x, m.y],
82        'x': 42,
83        'y': 123,
84    } == m.__constants__
85
86        m.__types__ == (m.Foo, m.Bar) or
87        m.__types__ == (m.Bar, m.Foo)
88    )
89
90        m.__services__ == (m.A, m.B) or
91        m.__services__ == (m.B, m.A)
92    )
93
94","[['{', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['m.__thrift_source__', '==', 's']]",11,4,0.3636363636363636,0.0013012361743656,"['loads', 'typedef string fo', 'const string foo', 's', 'const list<i32> z', 'const i32 x', 'const i32 y', 'm']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['loads', 'typedef string fo', 'const string foo', 's', 'const list<i32> z', 'const i32 x', 'const i32 y', 'm']
*Code:

1# Copyright (c) 2016 Uber Technologies, Inc.
2#
3# Permission is hereby granted, free of charge, to any person obtaining a copy
4# of this software and associated documentation files (the ""Software""), to deal
5# in the Software without restriction, including without limitation the rights
6# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
7# copies of the Software, and to permit persons to whom the Software is
8# furnished to do so, subject to the following conditions:
9#
10# The above copyright notice and this permission notice shall be included in
11# all copies or substantial portions of the Software.
12#
13# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
14# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
15# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
16# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
17# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
18# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
19# THE SOFTWARE.
20
21from __future__ import absolute_import, unicode_literals, print_function
22
23import pytest
24
25from thriftrw.errors import ThriftCompilerError
26
27
28@pytest.fixture
29def test_unknown_type(loads):
30    with pytest.raises(ThriftCompilerError) as exc_info:
31        loads('''
32            struct Foo { 1: optional Bar bar }
33            struct Bar { 1: optional Baz baz }
34        ''')
35
36
37
38def test_duplicate_type_names(loads):
39    with pytest.raises(ThriftCompilerError) as exc_info:
40        loads('''
41            typedef string foo
42
43            struct foo { 1: required string bar }
44        ''')
45
46
47
48def test_constant_type_conflict(loads):
49    with pytest.raises(ThriftCompilerError) as exc_info:
50        loads('''
51            const string foo = ""foo""
52
53            struct foo { 1: required string bar }
54        ''')
55
56
57
58def test_service_type_conflict(loads):
59    with pytest.raises(ThriftCompilerError) as exc_info:
60        loads('''
61            struct foo { 1: required string bar }
62            service foo {}
63        ''')
64
65
66
67def test_services_and_types(loads):
68    s = '''
69        struct Foo {}
70        union Bar {}
71
72        service A {}
73        service B {}
74
75        const list<i32> z = [x, y];
76        const i32 x = 42;
77        const i32 y = 123;
78    '''
79    m = loads(s)
80
81        'z': [m.x, m.y],
82        'x': 42,
83        'y': 123,
84    } == m.__constants__
85
86        m.__types__ == (m.Foo, m.Bar) or
87        m.__types__ == (m.Bar, m.Foo)
88    )
89
90        m.__services__ == (m.A, m.B) or
91        m.__services__ == (m.B, m.A)
92    )
93
94",4287,"The following list of assertions is generated in regards to the variables defined in the provided code. No function definitions are given within the code, and the variables mentioned are not used outside comment or string content, thus, no conditions are provided for input and output sizes for function calls. The variables are not operated on, hence no restrictions due to operations are necessary. The only checks conducted on these variables might be to confirm their existence or their type.

```
[
[29, 'loads', '!=', None, 'loads function object should exist'],
[67, 'loads', '!=', None, 'loads function object should exist'],
[38, 'loads', '!=', None, 'loads function object should exist'],
[48, 'loads', '!=', None, 'loads function object should exist'],
[58, 'loads', '!=', None, 'loads function object should exist'],
[79, 's', '==', str, 's variable should be a type of string'],
[79, 'loads', '!=', None, 'loads function object should exist'],
[79, 'm', '!=', None, 'm variable should be created by loads function']
]
```"
deepmind/sonnet,"# Copyright 2019 The Sonnet Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
""""""DNC util ops and modules.""""""

import numpy as np
import tensorflow as tf
import tree


def segment_dim(inputs, dim, shapes):
  """"""Returns tuple of Tensors output from segmenting input Tensor along dim.

  The returned tuple of Tensors produced by 'segmenting' the Tensor along a
  certain dimension can be transformed to specified shapes.

  Example:
      input_tensor = tf.placeholder([2, 14, 3])
      one, two = segment_dim(input_tensor, dim=1,
                             shapes=[TensorShape([3, 3]), TensorShape([5])])
      # one is a [2, 3, 3, 3] Tensor and two is a [2, 5, 3] Tensor.

  Args:
    inputs: `Tensor` to segment.
    dim: dimension of the Tensor to operate on. Negative numbers count back from
      the end of the dimensions.
    shapes: list of TensorShapes of the output 'segments' to produce.

  Returns:
    Tuple with resulting Tensors.

  Raises:
    ValueError: if the dim used at initialization is invalid. The valid range is
    (-d, d], where d is the number of dimensions of the input tensor.
  """"""
  inputs_shape = inputs.shape
  ndims = inputs_shape.ndims
  dynamic_shape = tf.shape(inputs)
  shape_as_list = [
      dynamic_shape[i] if s is None else s
      for i, s in enumerate(inputs_shape.as_list())
  ]

  if dim >= ndims or dim < -ndims:
    message = 'Invalid dims ({:d})'.format(dim)
    raise ValueError(message)

  pre_shape = shape_as_list[:dim]
  if dim == -1:
    post_shape = []
  else:
    post_shape = shape_as_list[(dim + 1):]

  slice_begin = [0] * ndims
  slice_size = [-1] * ndims

  segments = []
  for shape in shapes:
    num_elements = shape.num_elements()
    slice_size[dim] = num_elements
    flat_slice = tf.slice(inputs, slice_begin, slice_size)

    final_shape = pre_shape + shape.as_list() + post_shape
    segments.append(tf.reshape(flat_slice, final_shape))
    slice_begin[dim] += num_elements

  return tuple(segments)


def batch_invert_permutation(permutations):
  """"""Returns batched `tf.invert_permutation` for every row in `permutations`.""""""
  unpacked = tf.unstack(permutations)
  inverses = [
      tf.math.invert_permutation(permutation) for permutation in unpacked
  ]
  return tf.stack(inverses)


def batch_gather(values, indices):
  """"""Returns batched `tf.gather` for every row in the input.""""""
  unpacked = zip(tf.unstack(values), tf.unstack(indices))
  result = [tf.gather(value, index) for value, index in unpacked]
  return tf.stack(result)


def one_hot(length, index):
  """"""Return an nd array of given `length` filled with 0s and a 1 at `index`.""""""
  result = np.zeros(length)
  result[index] = 1
  return result


def apply_linear(inputs, linear_modules, activation=tf.identity):
  """"""Computes linear, allowing for tuple inputs (processed in parallel).

  If inputs is a tuple, the linear modules must be a tuple or list of the same
  length.

  Args:
    inputs: tensor or list / tuple of 2 tensors.
    linear_modules: sonnet module, or list / tuple of 2 sonnet modules.
    activation: function to call as activation, default is identity.

  Returns:
    output Tensor from one / both linear modules.
  """"""
  tree.assert_same_structure(inputs, linear_modules)
  if isinstance(inputs, (tuple, list)):
    assert len(inputs) == len(linear_modules) == 2, (
        'if inputs is a list, must be length 2 and match length of linears')
    return apply_split_linear(
        linear_modules[0],
        linear_modules[1],
        inputs[0],
        inputs[1],
        activation=activation)
  else:
    return activation(linear_modules(inputs))


def apply_split_linear(lin_module_1,
                       lin_module_2,
                       input1,
                       input2,
                       activation=None):
  """"""Returns a linear output of two inputs, run independently and summed.""""""
  output_1 = lin_module_1(input1)
  output_2 = lin_module_2(input2)
  summed_output = output_1 + output_2
  if activation is not None:
    summed_output = activation(summed_output)
  return summed_output
","
1# Copyright 2019 The Sonnet Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14# ============================================================================
15""""""DNC util ops and modules.""""""
16
17import numpy as np
18import tensorflow as tf
19import tree
20
21
22def segment_dim(inputs, dim, shapes):
23  """"""Returns tuple of Tensors output from segmenting input Tensor along dim.
24
25  The returned tuple of Tensors produced by 'segmenting' the Tensor along a
26  certain dimension can be transformed to specified shapes.
27
28  Example:
29      input_tensor = tf.placeholder([2, 14, 3])
30      one, two = segment_dim(input_tensor, dim=1,
31                             shapes=[TensorShape([3, 3]), TensorShape([5])])
32      # one is a [2, 3, 3, 3] Tensor and two is a [2, 5, 3] Tensor.
33
34  Args:
35    inputs: `Tensor` to segment.
36    dim: dimension of the Tensor to operate on. Negative numbers count back from
37      the end of the dimensions.
38    shapes: list of TensorShapes of the output 'segments' to produce.
39
40  Returns:
41    Tuple with resulting Tensors.
42
43  Raises:
44    ValueError: if the dim used at initialization is invalid. The valid range is
45    (-d, d], where d is the number of dimensions of the input tensor.
46  """"""
47  inputs_shape = inputs.shape
48  ndims = inputs_shape.ndims
49  dynamic_shape = tf.shape(inputs)
50  shape_as_list = [
51      dynamic_shape[i] if s is None else s
52      for i, s in enumerate(inputs_shape.as_list())
53  ]
54
55  if dim >= ndims or dim < -ndims:
56    message = 'Invalid dims ({:d})'.format(dim)
57    raise ValueError(message)
58
59  pre_shape = shape_as_list[:dim]
60  if dim == -1:
61    post_shape = []
62  else:
63    post_shape = shape_as_list[(dim + 1):]
64
65  slice_begin = [0] * ndims
66  slice_size = [-1] * ndims
67
68  segments = []
69  for shape in shapes:
70    num_elements = shape.num_elements()
71    slice_size[dim] = num_elements
72    flat_slice = tf.slice(inputs, slice_begin, slice_size)
73
74    final_shape = pre_shape + shape.as_list() + post_shape
75    segments.append(tf.reshape(flat_slice, final_shape))
76    slice_begin[dim] += num_elements
77
78  return tuple(segments)
79
80
81def batch_invert_permutation(permutations):
82  """"""Returns batched `tf.invert_permutation` for every row in `permutations`.""""""
83  unpacked = tf.unstack(permutations)
84  inverses = [
85      tf.math.invert_permutation(permutation) for permutation in unpacked
86  ]
87  return tf.stack(inverses)
88
89
90def batch_gather(values, indices):
91  """"""Returns batched `tf.gather` for every row in the input.""""""
92  unpacked = zip(tf.unstack(values), tf.unstack(indices))
93  result = [tf.gather(value, index) for value, index in unpacked]
94  return tf.stack(result)
95
96
97def one_hot(length, index):
98  """"""Return an nd array of given `length` filled with 0s and a 1 at `index`.""""""
99  result = np.zeros(length)
100  result[index] = 1
101  return result
102
103
104def apply_linear(inputs, linear_modules, activation=tf.identity):
105  """"""Computes linear, allowing for tuple inputs (processed in parallel).
106
107  If inputs is a tuple, the linear modules must be a tuple or list of the same
108  length.
109
110  Args:
111    inputs: tensor or list / tuple of 2 tensors.
112    linear_modules: sonnet module, or list / tuple of 2 sonnet modules.
113    activation: function to call as activation, default is identity.
114
115  Returns:
116    output Tensor from one / both linear modules.
117  """"""
118  if isinstance(inputs, (tuple, list)):
119        'if inputs is a list, must be length 2 and match length of linears')
120    return apply_split_linear(
121        linear_modules[0],
122        linear_modules[1],
123        inputs[0],
124        inputs[1],
125        activation=activation)
126  else:
127    return activation(linear_modules(inputs))
128
129
130def apply_split_linear(lin_module_1,
131                       lin_module_2,
132                       input1,
133                       input2,
134                       activation=None):
135  """"""Returns a linear output of two inputs, run independently and summed.""""""
136  output_1 = lin_module_1(input1)
137  output_2 = lin_module_2(input2)
138  summed_output = output_1 + output_2
139  if activation is not None:
140    summed_output = activation(summed_output)
141  return summed_output
142","[['len(inputs)', '==', 'len(linear_modules) == 2']]",2,1,0.5,0.0002136295663319,"['inputs', 'dim', 'shapes', 'input_tensor', 'one', 'two', 'inputs_shape', 'ndims', 'dynamic_shape', 'shape_as_list', 'message', 'pre_shape', 'post_shape', 'slice_begin', 'slice_size', 'segments', 'num_elements', 'slice_size[dim]', 'flat_slice', 'final_shape', 'permutations', 'unpacked', 'inverses', 'values', 'indices', 'result', 'length', 'index', 'result[index]', 'linear_modules', 'activation', 'lin_module_1', 'output_1', 'output_2', 'summed_output']",35,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['inputs', 'dim', 'shapes', 'input_tensor', 'one', 'two', 'inputs_shape', 'ndims', 'dynamic_shape', 'shape_as_list', 'message', 'pre_shape', 'post_shape', 'slice_begin', 'slice_size', 'segments', 'num_elements', 'slice_size[dim]', 'flat_slice', 'final_shape', 'permutations', 'unpacked', 'inverses', 'values', 'indices', 'result', 'length', 'index', 'result[index]', 'linear_modules', 'activation', 'lin_module_1', 'output_1', 'output_2', 'summed_output']
*Code:

1# Copyright 2019 The Sonnet Authors. All Rights Reserved.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14# ============================================================================
15""""""DNC util ops and modules.""""""
16
17import numpy as np
18import tensorflow as tf
19import tree
20
21
22def segment_dim(inputs, dim, shapes):
23  """"""Returns tuple of Tensors output from segmenting input Tensor along dim.
24
25  The returned tuple of Tensors produced by 'segmenting' the Tensor along a
26  certain dimension can be transformed to specified shapes.
27
28  Example:
29      input_tensor = tf.placeholder([2, 14, 3])
30      one, two = segment_dim(input_tensor, dim=1,
31                             shapes=[TensorShape([3, 3]), TensorShape([5])])
32      # one is a [2, 3, 3, 3] Tensor and two is a [2, 5, 3] Tensor.
33
34  Args:
35    inputs: `Tensor` to segment.
36    dim: dimension of the Tensor to operate on. Negative numbers count back from
37      the end of the dimensions.
38    shapes: list of TensorShapes of the output 'segments' to produce.
39
40  Returns:
41    Tuple with resulting Tensors.
42
43  Raises:
44    ValueError: if the dim used at initialization is invalid. The valid range is
45    (-d, d], where d is the number of dimensions of the input tensor.
46  """"""
47  inputs_shape = inputs.shape
48  ndims = inputs_shape.ndims
49  dynamic_shape = tf.shape(inputs)
50  shape_as_list = [
51      dynamic_shape[i] if s is None else s
52      for i, s in enumerate(inputs_shape.as_list())
53  ]
54
55  if dim >= ndims or dim < -ndims:
56    message = 'Invalid dims ({:d})'.format(dim)
57    raise ValueError(message)
58
59  pre_shape = shape_as_list[:dim]
60  if dim == -1:
61    post_shape = []
62  else:
63    post_shape = shape_as_list[(dim + 1):]
64
65  slice_begin = [0] * ndims
66  slice_size = [-1] * ndims
67
68  segments = []
69  for shape in shapes:
70    num_elements = shape.num_elements()
71    slice_size[dim] = num_elements
72    flat_slice = tf.slice(inputs, slice_begin, slice_size)
73
74    final_shape = pre_shape + shape.as_list() + post_shape
75    segments.append(tf.reshape(flat_slice, final_shape))
76    slice_begin[dim] += num_elements
77
78  return tuple(segments)
79
80
81def batch_invert_permutation(permutations):
82  """"""Returns batched `tf.invert_permutation` for every row in `permutations`.""""""
83  unpacked = tf.unstack(permutations)
84  inverses = [
85      tf.math.invert_permutation(permutation) for permutation in unpacked
86  ]
87  return tf.stack(inverses)
88
89
90def batch_gather(values, indices):
91  """"""Returns batched `tf.gather` for every row in the input.""""""
92  unpacked = zip(tf.unstack(values), tf.unstack(indices))
93  result = [tf.gather(value, index) for value, index in unpacked]
94  return tf.stack(result)
95
96
97def one_hot(length, index):
98  """"""Return an nd array of given `length` filled with 0s and a 1 at `index`.""""""
99  result = np.zeros(length)
100  result[index] = 1
101  return result
102
103
104def apply_linear(inputs, linear_modules, activation=tf.identity):
105  """"""Computes linear, allowing for tuple inputs (processed in parallel).
106
107  If inputs is a tuple, the linear modules must be a tuple or list of the same
108  length.
109
110  Args:
111    inputs: tensor or list / tuple of 2 tensors.
112    linear_modules: sonnet module, or list / tuple of 2 sonnet modules.
113    activation: function to call as activation, default is identity.
114
115  Returns:
116    output Tensor from one / both linear modules.
117  """"""
118  if isinstance(inputs, (tuple, list)):
119        'if inputs is a list, must be length 2 and match length of linears')
120    return apply_split_linear(
121        linear_modules[0],
122        linear_modules[1],
123        inputs[0],
124        inputs[1],
125        activation=activation)
126  else:
127    return activation(linear_modules(inputs))
128
129
130def apply_split_linear(lin_module_1,
131                       lin_module_2,
132                       input1,
133                       input2,
134                       activation=None):
135  """"""Returns a linear output of two inputs, run independently and summed.""""""
136  output_1 = lin_module_1(input1)
137  output_2 = lin_module_2(input2)
138  summed_output = output_1 + output_2
139  if activation is not None:
140    summed_output = activation(summed_output)
141  return summed_output
142",6728,"[[22, 'inputs', '!=', None, 'inputs for segment_dim must be non-None'],
 [22, 'dim', '!=', None, 'dim for segment_dim must be non-None'],
 [22, 'shapes', '!=', None, 'shapes for segment_dim must be non-None'],
 [81, 'permutations', '!=', None, 'permutations for batch_invert_permutation must be non-None'],
 [90, 'values', '!=', None, 'values for batch_gather must be non-None'],
 [90, 'indices', '!=', None, 'indices for batch_gather must be non-None'],
 [97, 'length', '>=', 0, 'length for one_hot must be non-negative'],
 [97, 'index', '>=', 0, 'index for one_hot must be non-negative'],
 [104, 'inputs', '!=', None, 'inputs for apply_linear must be non-None'],
 [104, 'linear_modules', '!=', None, 'linear_modules for apply_linear must be non-None'],
 [130, 'lin_module_1', '!=', None, 'lin_module_1 for apply_split_linear must be non-None'],
 [130, 'lin_module_2', '!=', None, 'lin_module_2 for apply_split_linear must be non-None'],
 [130, 'input1', '!=', None, 'input1 for apply_split_linear must be non-None'],
 [130, 'input2', '!=', None, 'input2 for apply_split_linear must be non-None']]"
shsingh/ansible,"# Copyright 2019 Fortinet, Inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <https://www.gnu.org/licenses/>.

# Make coding more python3-ish
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
from mock import ANY
from ansible.module_utils.network.fortios.fortios import FortiOSHandler

try:
    from ansible.modules.network.fortios import fortios_system_virtual_wan_link
except ImportError:
    pytest.skip(""Could not load required modules for testing"", allow_module_level=True)


@pytest.fixture(autouse=True)
def connection_mock(mocker):
    connection_class_mock = mocker.patch('ansible.modules.network.fortios.fortios_system_virtual_wan_link.Connection')
    return connection_class_mock


fos_instance = FortiOSHandler(connection_mock)


def test_system_virtual_wan_link_creation(mocker):
    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')

    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)

    input_data = {
        'username': 'admin',
        'state': 'present',
        'system_virtual_wan_link': {'fail_detect': 'enable',
                                    'load_balance_mode': 'source-ip-based',
                                    'status': 'disable'
                                    },
        'vdom': 'root'}

    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)

    expected_data = {'fail-detect': 'enable',
                     'load-balance-mode': 'source-ip-based',
                     'status': 'disable'
                     }

    set_method_mock.assert_called_with('system', 'virtual-wan-link', data=expected_data, vdom='root')
    schema_method_mock.assert_not_called()
    assert not is_error
    assert changed
    assert response['status'] == 'success'
    assert response['http_status'] == 200


def test_system_virtual_wan_link_creation_fails(mocker):
    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')

    set_method_result = {'status': 'error', 'http_method': 'POST', 'http_status': 500}
    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)

    input_data = {
        'username': 'admin',
        'state': 'present',
        'system_virtual_wan_link': {'fail_detect': 'enable',
                                    'load_balance_mode': 'source-ip-based',
                                    'status': 'disable'
                                    },
        'vdom': 'root'}

    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)

    expected_data = {'fail-detect': 'enable',
                     'load-balance-mode': 'source-ip-based',
                     'status': 'disable'
                     }

    set_method_mock.assert_called_with('system', 'virtual-wan-link', data=expected_data, vdom='root')
    schema_method_mock.assert_not_called()
    assert is_error
    assert not changed
    assert response['status'] == 'error'
    assert response['http_status'] == 500


def test_system_virtual_wan_link_idempotent(mocker):
    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')

    set_method_result = {'status': 'error', 'http_method': 'DELETE', 'http_status': 404}
    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)

    input_data = {
        'username': 'admin',
        'state': 'present',
        'system_virtual_wan_link': {'fail_detect': 'enable',
                                    'load_balance_mode': 'source-ip-based',
                                    'status': 'disable'
                                    },
        'vdom': 'root'}

    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)

    expected_data = {'fail-detect': 'enable',
                     'load-balance-mode': 'source-ip-based',
                     'status': 'disable'
                     }

    set_method_mock.assert_called_with('system', 'virtual-wan-link', data=expected_data, vdom='root')
    schema_method_mock.assert_not_called()
    assert not is_error
    assert not changed
    assert response['status'] == 'error'
    assert response['http_status'] == 404


def test_system_virtual_wan_link_filter_foreign_attributes(mocker):
    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')

    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)

    input_data = {
        'username': 'admin',
        'state': 'present',
        'system_virtual_wan_link': {
            'random_attribute_not_valid': 'tag', 'fail_detect': 'enable',
            'load_balance_mode': 'source-ip-based',
            'status': 'disable'
        },
        'vdom': 'root'}

    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)

    expected_data = {'fail-detect': 'enable',
                     'load-balance-mode': 'source-ip-based',
                     'status': 'disable'
                     }

    set_method_mock.assert_called_with('system', 'virtual-wan-link', data=expected_data, vdom='root')
    schema_method_mock.assert_not_called()
    assert not is_error
    assert changed
    assert response['status'] == 'success'
    assert response['http_status'] == 200
","
1# Copyright 2019 Fortinet, Inc.
2#
3# This program is free software: you can redistribute it and/or modify
4# it under the terms of the GNU General Public License as published by
5# the Free Software Foundation, either version 3 of the License, or
6# (at your option) any later version.
7#
8# This program is distributed in the hope that it will be useful,
9# but WITHOUT ANY WARRANTY; without even the implied warranty of
10# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
11# GNU General Public License for more details.
12#
13# You should have received a copy of the GNU General Public License
14# along with Ansible.  If not, see <https://www.gnu.org/licenses/>.
15
16# Make coding more python3-ish
17from __future__ import (absolute_import, division, print_function)
18__metaclass__ = type
19
20import os
21import json
22import pytest
23from mock import ANY
24from ansible.module_utils.network.fortios.fortios import FortiOSHandler
25
26try:
27    from ansible.modules.network.fortios import fortios_system_virtual_wan_link
28except ImportError:
29    pytest.skip(""Could not load required modules for testing"", allow_module_level=True)
30
31
32@pytest.fixture(autouse=True)
33def connection_mock(mocker):
34    connection_class_mock = mocker.patch('ansible.modules.network.fortios.fortios_system_virtual_wan_link.Connection')
35    return connection_class_mock
36
37
38fos_instance = FortiOSHandler(connection_mock)
39
40
41def test_system_virtual_wan_link_creation(mocker):
42    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
43
44    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
45    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
46
47    input_data = {
48        'username': 'admin',
49        'state': 'present',
50        'system_virtual_wan_link': {'fail_detect': 'enable',
51                                    'load_balance_mode': 'source-ip-based',
52                                    'status': 'disable'
53                                    },
54        'vdom': 'root'}
55
56    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
57
58    expected_data = {'fail-detect': 'enable',
59                     'load-balance-mode': 'source-ip-based',
60                     'status': 'disable'
61                     }
62
63
64
65def test_system_virtual_wan_link_creation_fails(mocker):
66    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
67
68    set_method_result = {'status': 'error', 'http_method': 'POST', 'http_status': 500}
69    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
70
71    input_data = {
72        'username': 'admin',
73        'state': 'present',
74        'system_virtual_wan_link': {'fail_detect': 'enable',
75                                    'load_balance_mode': 'source-ip-based',
76                                    'status': 'disable'
77                                    },
78        'vdom': 'root'}
79
80    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
81
82    expected_data = {'fail-detect': 'enable',
83                     'load-balance-mode': 'source-ip-based',
84                     'status': 'disable'
85                     }
86
87
88
89def test_system_virtual_wan_link_idempotent(mocker):
90    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
91
92    set_method_result = {'status': 'error', 'http_method': 'DELETE', 'http_status': 404}
93    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
94
95    input_data = {
96        'username': 'admin',
97        'state': 'present',
98        'system_virtual_wan_link': {'fail_detect': 'enable',
99                                    'load_balance_mode': 'source-ip-based',
100                                    'status': 'disable'
101                                    },
102        'vdom': 'root'}
103
104    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
105
106    expected_data = {'fail-detect': 'enable',
107                     'load-balance-mode': 'source-ip-based',
108                     'status': 'disable'
109                     }
110
111
112
113def test_system_virtual_wan_link_filter_foreign_attributes(mocker):
114    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
115
116    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
117    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
118
119    input_data = {
120        'username': 'admin',
121        'state': 'present',
122        'system_virtual_wan_link': {
123            'random_attribute_not_valid': 'tag', 'fail_detect': 'enable',
124            'load_balance_mode': 'source-ip-based',
125            'status': 'disable'
126        },
127        'vdom': 'root'}
128
129    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
130
131    expected_data = {'fail-detect': 'enable',
132                     'load-balance-mode': 'source-ip-based',
133                     'status': 'disable'
134                     }
135
136","[['is_error', '==', 'False'], ['changed', '==', 'True'], [""response['status']"", '==', ""'success'""], [""response['http_status']"", '==', '200'], ['is_error', '==', 'True'], ['changed', '==', 'False'], [""response['status']"", '==', ""'error'""], [""response['http_status']"", '==', '500'], ['is_error', '==', 'False'], ['changed', '==', 'False'], [""response['status']"", '==', ""'error'""], [""response['http_status']"", '==', '404'], ['is_error', '==', 'False'], ['changed', '==', 'True'], [""response['status']"", '==', ""'success'""], [""response['http_status']"", '==', '200']]",24,16,0.6666666666666666,0.0024786986831913,"['__metaclass__', 'mocker', 'connection_class_mock', 'fos_instance', 'schema_method_mock', 'set_method_result', 'set_method_mock', 'input_data', 'is_error', 'changed', 'response', 'expected_data']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'mocker', 'connection_class_mock', 'fos_instance', 'schema_method_mock', 'set_method_result', 'set_method_mock', 'input_data', 'is_error', 'changed', 'response', 'expected_data']
*Code:

1# Copyright 2019 Fortinet, Inc.
2#
3# This program is free software: you can redistribute it and/or modify
4# it under the terms of the GNU General Public License as published by
5# the Free Software Foundation, either version 3 of the License, or
6# (at your option) any later version.
7#
8# This program is distributed in the hope that it will be useful,
9# but WITHOUT ANY WARRANTY; without even the implied warranty of
10# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
11# GNU General Public License for more details.
12#
13# You should have received a copy of the GNU General Public License
14# along with Ansible.  If not, see <https://www.gnu.org/licenses/>.
15
16# Make coding more python3-ish
17from __future__ import (absolute_import, division, print_function)
18__metaclass__ = type
19
20import os
21import json
22import pytest
23from mock import ANY
24from ansible.module_utils.network.fortios.fortios import FortiOSHandler
25
26try:
27    from ansible.modules.network.fortios import fortios_system_virtual_wan_link
28except ImportError:
29    pytest.skip(""Could not load required modules for testing"", allow_module_level=True)
30
31
32@pytest.fixture(autouse=True)
33def connection_mock(mocker):
34    connection_class_mock = mocker.patch('ansible.modules.network.fortios.fortios_system_virtual_wan_link.Connection')
35    return connection_class_mock
36
37
38fos_instance = FortiOSHandler(connection_mock)
39
40
41def test_system_virtual_wan_link_creation(mocker):
42    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
43
44    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
45    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
46
47    input_data = {
48        'username': 'admin',
49        'state': 'present',
50        'system_virtual_wan_link': {'fail_detect': 'enable',
51                                    'load_balance_mode': 'source-ip-based',
52                                    'status': 'disable'
53                                    },
54        'vdom': 'root'}
55
56    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
57
58    expected_data = {'fail-detect': 'enable',
59                     'load-balance-mode': 'source-ip-based',
60                     'status': 'disable'
61                     }
62
63
64
65def test_system_virtual_wan_link_creation_fails(mocker):
66    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
67
68    set_method_result = {'status': 'error', 'http_method': 'POST', 'http_status': 500}
69    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
70
71    input_data = {
72        'username': 'admin',
73        'state': 'present',
74        'system_virtual_wan_link': {'fail_detect': 'enable',
75                                    'load_balance_mode': 'source-ip-based',
76                                    'status': 'disable'
77                                    },
78        'vdom': 'root'}
79
80    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
81
82    expected_data = {'fail-detect': 'enable',
83                     'load-balance-mode': 'source-ip-based',
84                     'status': 'disable'
85                     }
86
87
88
89def test_system_virtual_wan_link_idempotent(mocker):
90    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
91
92    set_method_result = {'status': 'error', 'http_method': 'DELETE', 'http_status': 404}
93    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
94
95    input_data = {
96        'username': 'admin',
97        'state': 'present',
98        'system_virtual_wan_link': {'fail_detect': 'enable',
99                                    'load_balance_mode': 'source-ip-based',
100                                    'status': 'disable'
101                                    },
102        'vdom': 'root'}
103
104    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
105
106    expected_data = {'fail-detect': 'enable',
107                     'load-balance-mode': 'source-ip-based',
108                     'status': 'disable'
109                     }
110
111
112
113def test_system_virtual_wan_link_filter_foreign_attributes(mocker):
114    schema_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.schema')
115
116    set_method_result = {'status': 'success', 'http_method': 'POST', 'http_status': 200}
117    set_method_mock = mocker.patch('ansible.module_utils.network.fortios.fortios.FortiOSHandler.set', return_value=set_method_result)
118
119    input_data = {
120        'username': 'admin',
121        'state': 'present',
122        'system_virtual_wan_link': {
123            'random_attribute_not_valid': 'tag', 'fail_detect': 'enable',
124            'load_balance_mode': 'source-ip-based',
125            'status': 'disable'
126        },
127        'vdom': 'root'}
128
129    is_error, changed, response = fortios_system_virtual_wan_link.fortios_system(input_data, fos_instance)
130
131    expected_data = {'fail-detect': 'enable',
132                     'load-balance-mode': 'source-ip-based',
133                     'status': 'disable'
134                     }
135
136",7240,"[32, 'mocker', '!=', None, ""mocker is necessary for mocking""],
[38, 'connection_mock', '!=', None, ""connection_mock is a required variable""],
[42, 'mocker', '!=', None, ""mocker is necessary for mocking""],
[45, 'set_method_result', '==', {'status': 'success', 'http_method': 'POST', 'http_status': 200}, ""set_method_result's success status and http status are verified""],
[56, 'is_error', '==', False, ""is_error should be false for the function to execute properly""],
[56, 'changed', '!=', None, ""changed should not be None""],
[56, 'response', '!=', None, ""response should not be None""],
[56, 'fos_instance', '!=', None, ""fos_instance is required for successful execution""],
[66, 'mocker', '!=', None, ""mocker is necessary for mocking""],
[68, 'set_method_result', '==', {'status': 'error', 'http_method': 'POST', 'http_status': 500}, ""set_method_result's error status and http status are verified""],
[80, 'is_error', '==', True, ""is_error should be True when creation fails""],
[80, 'changed', '!=', None, ""changed should not be None""],
[80, 'response', '!=', None, ""response should not be None""],
[80, 'fos_instance', '!=', None, ""fos_instance is required for successful execution""],
[90, 'mocker', '!=', None, ""mocker is necessary for mocking""],
[92, 'set_method_result', '==', {'status': 'error', 'http_method': 'DELETE', 'http_status': 404}, ""set_method_result's error status and http status are verified""],
[104, 'is_error', '==', True, ""is_error should be True when deletion fails""],
[104, 'changed', '!=', None, ""changed should not be None""],
[104, 'response', '!=', None, ""response should not be None""],
[104, 'fos_instance', '!=', None, ""fos_instance is required for successful execution""],
[114, 'mocker', '!=', None, ""mocker is necessary for mocking""],
[116, 'set_method_result', '==', {'status': 'success', 'http_method': 'POST', 'http_status': 200}, ""set_method_result's success status and http status are verified""],
[129, 'is_error', '==', False, ""is_error should be false for successful execution""],
[129, 'changed', '!=', None, ""changed should not be None""],
[129, 'response', '!=', None, ""response should not be None""],
[129, 'fos_instance', '!=', None, ""fos_instance is required for successful execution""]"
brainix/pottery,"# --------------------------------------------------------------------------- #
#   test_dict.py                                                              #
#                                                                             #
#   Copyright © 2015-2022, Rajiv Bakulesh Shah, original author.              #
#                                                                             #
#   Licensed under the Apache License, Version 2.0 (the ""License"");           #
#   you may not use this file except in compliance with the License.          #
#   You may obtain a copy of the License at:                                  #
#       http://www.apache.org/licenses/LICENSE-2.0                            #
#                                                                             #
#   Unless required by applicable law or agreed to in writing, software       #
#   distributed under the License is distributed on an ""AS IS"" BASIS,         #
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  #
#   See the License for the specific language governing permissions and       #
#   limitations under the License.                                            #
# --------------------------------------------------------------------------- #
'''These tests come from these examples:
    https://docs.python.org/3/tutorial/datastructures.html#dictionaries
'''


import collections
import json

import pytest
from redis import Redis

from pottery import KeyExistsError
from pottery import RedisDict


def test_keyexistserror_raised(redis: Redis) -> None:
    d = RedisDict(
        redis=redis,
        key='pottery:tel',
        sape=4139,
        guido=4127,
        jack=4098,
    )
    d   # Workaround for Pyflakes.  :-(
    with pytest.raises(KeyExistsError):
        RedisDict(
            redis=redis,
            key='pottery:tel',
            sape=4139,
            guido=4127,
            jack=4098,
        )


def test_keyexistserror_repr(redis: Redis) -> None:
    d = RedisDict(
        redis=redis,
        key='pottery:tel',
        sape=4139,
        guido=4127,
        jack=4098,
    )
    d   # Workaround for Pyflakes.  :-(
    try:
        RedisDict(
            redis=redis,
            key='pottery:tel',
            sape=4139,
            guido=4127,
            jack=4098,
        )
    except KeyExistsError as wtf:
        redis_db = redis.get_connection_kwargs()['db']  # type: ignore
        assert repr(wtf) == (
            f""KeyExistsError(redis=Redis<ConnectionPool<Connection<host=localhost,port=6379,db={redis_db}>>>, ""
            ""key='pottery:tel')""
        )
    else:  # pragma: no cover
        pytest.fail(msg='KeyExistsError not raised')


def test_basic_usage(redis: Redis) -> None:
    tel = RedisDict(redis=redis, jack=4098, sape=4139)
    tel['guido'] = 4127
    assert tel == {'sape': 4139, 'guido': 4127, 'jack': 4098}
    assert tel['jack'] == 4098
    del tel['sape']
    tel['irv'] = 4127
    assert tel == {'guido': 4127, 'irv': 4127, 'jack': 4098}
    assert sorted(tel) == ['guido', 'irv', 'jack']
    assert 'guido' in tel
    assert not 'jack' not in tel


def test_init_with_key_value_pairs(redis: Redis) -> None:
    d = RedisDict([('sape', 4139), ('guido', 4127), ('jack', 4098)], redis=redis)
    assert d == {'sape': 4139, 'jack': 4098, 'guido': 4127}


def test_init_with_kwargs(redis: Redis) -> None:
    d = RedisDict(redis=redis, sape=4139, guido=4127, jack=4098)
    assert d == {'sape': 4139, 'jack': 4098, 'guido': 4127}

# The following tests come from these examples:
#   https://docs.python.org/3.4/library/stdtypes.html#mapping-types-dict


def test_more_construction_options(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    b = {'one': 1, 'two': 2, 'three': 3}
    c = RedisDict(zip(['one', 'two', 'three'], [1, 2, 3]), redis=redis)
    d = RedisDict([('two', 2), ('one', 1), ('three', 3)], redis=redis)
    e = RedisDict({'three': 3, 'one': 1, 'two': 2}, redis=redis)  # type: ignore
    assert a == b == c == d == e


def test_len(redis: Redis) -> None:
    a = RedisDict(redis=redis)
    assert len(a) == 0
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert len(a) == 3
    a['four'] = 4
    assert len(a) == 4
    del a['four']
    assert len(a) == 3


def test_repr(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2)
    assert repr(a) in {
        ""RedisDict{'one': 1, 'two': 2}"",
        ""RedisDict{'two': 2, 'one': 1}"",
    }


def test_update(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    a.update()
    assert a == {'one': 1, 'two': 2, 'three': 3}

    a.update({'four': 4, 'five': 5})  # type: ignore
    assert a == {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}

    a.update((('six', 6), ('seven', 7)))
    assert a == {
        'one': 1,
        'two': 2,
        'three': 3,
        'four': 4,
        'five': 5,
        'six': 6,
        'seven': 7,
    }

    a.update(eight=8, nine=9)
    assert a == {
        'one': 1,
        'two': 2,
        'three': 3,
        'four': 4,
        'five': 5,
        'six': 6,
        'seven': 7,
        'eight': 8,
        'nine': 9,
    }


def test_keyerror(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert a['one'] == 1
    assert a['two'] == 2
    assert a['three'] == 3
    with pytest.raises(KeyError):
        a['four']


def test_key_assignment(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=2)
    assert a['three'] == 2
    a['three'] = 3
    assert a['three'] == 3
    a['four'] = 4
    assert a['four'] == 4


def test_key_deletion(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert sorted(a) == ['one', 'three', 'two']
    a['four'] = 4
    assert sorted(a) == ['four', 'one', 'three', 'two']
    with pytest.raises(KeyError):
        del a['five']
    del a['four']
    assert sorted(a) == ['one', 'three', 'two']
    del a['three']
    assert sorted(a) == ['one', 'two']
    del a['two']
    assert sorted(a) == ['one']
    del a['one']
    assert sorted(a) == []
    with pytest.raises(KeyError):
        del a['one']


def test_key_membership(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert 'one' in a
    assert 'four' not in a
    assert not 'four' in a
    a['four'] = 4
    assert 'four' in a
    del a['four']
    assert 'four' not in a
    assert not 'four' in a


def test_clear(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert sorted(a) == ['one', 'three', 'two']
    assert a.clear() is None  # type: ignore
    assert sorted(a) == []
    assert a.clear() is None  # type: ignore
    assert sorted(a) == []


def test_get(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert a.get('one') == 1
    assert a.get('one', 42) == 1
    assert a.get('two') == 2
    assert a.get('two', 42) == 2
    assert a.get('three') == 3
    assert a.get('three', 42) == 3
    assert a.get('four') is None
    assert a.get('four', 42) == 42
    a['four'] = 4
    assert a.get('four') == 4
    assert a.get('four', 42) == 4
    del a['four']
    assert a.get('four') is None
    assert a.get('four', 42) == 42


def test_items(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert isinstance(a.items(), collections.abc.ItemsView)
    assert len(a) == 3
    assert set(a.items()) == {('one', 1), ('two', 2), ('three', 3)}
    assert ('one', 1) in a.items()
    assert ('four', 4) not in a.items()


def test_keys(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert isinstance(a.keys(), collections.abc.KeysView)
    assert len(a) == 3
    assert set(a.keys()) == {'one', 'two', 'three'}
    assert 'one' in a.keys()
    assert 'four' not in a.keys()


def test_values(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert isinstance(a.values(), collections.abc.ValuesView)
    assert len(a) == 3
    assert set(a.values()) == {1, 2, 3}
    assert 1 in a.values()
    assert 4 not in a.values()


def test_membership_for_non_jsonifyable_element(redis: Redis) -> None:
    redis_dict = RedisDict(redis=redis)
    assert not BaseException in redis_dict


def test_json_dumps(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    assert json.dumps(a) == '{""one"": 1, ""two"": 2, ""three"": 3}'


def test_eq_same_redis_database_and_key(redis: Redis) -> None:
    a = RedisDict(redis=redis, one=1, two=2, three=3)
    b = RedisDict(redis=a.redis, key=a.key)
    assert a == b
","
1# --------------------------------------------------------------------------- #
2#   test_dict.py                                                              #
3#                                                                             #
4#   Copyright © 2015-2022, Rajiv Bakulesh Shah, original author.              #
5#                                                                             #
6#   Licensed under the Apache License, Version 2.0 (the ""License"");           #
7#   you may not use this file except in compliance with the License.          #
8#   You may obtain a copy of the License at:                                  #
9#       http://www.apache.org/licenses/LICENSE-2.0                            #
10#                                                                             #
11#   Unless required by applicable law or agreed to in writing, software       #
12#   distributed under the License is distributed on an ""AS IS"" BASIS,         #
13#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  #
14#   See the License for the specific language governing permissions and       #
15#   limitations under the License.                                            #
16# --------------------------------------------------------------------------- #
17'''These tests come from these examples:
18    https://docs.python.org/3/tutorial/datastructures.html#dictionaries
19'''
20
21
22import collections
23import json
24
25import pytest
26from redis import Redis
27
28from pottery import KeyExistsError
29from pottery import RedisDict
30
31
32def test_keyexistserror_raised(redis: Redis) -> None:
33    d = RedisDict(
34        redis=redis,
35        key='pottery:tel',
36        sape=4139,
37        guido=4127,
38        jack=4098,
39    )
40    d   # Workaround for Pyflakes.  :-(
41    with pytest.raises(KeyExistsError):
42        RedisDict(
43            redis=redis,
44            key='pottery:tel',
45            sape=4139,
46            guido=4127,
47            jack=4098,
48        )
49
50
51def test_keyexistserror_repr(redis: Redis) -> None:
52    d = RedisDict(
53        redis=redis,
54        key='pottery:tel',
55        sape=4139,
56        guido=4127,
57        jack=4098,
58    )
59    d   # Workaround for Pyflakes.  :-(
60    try:
61        RedisDict(
62            redis=redis,
63            key='pottery:tel',
64            sape=4139,
65            guido=4127,
66            jack=4098,
67        )
68    except KeyExistsError as wtf:
69        redis_db = redis.get_connection_kwargs()['db']  # type: ignore
70            f""KeyExistsError(redis=Redis<ConnectionPool<Connection<host=localhost,port=6379,db={redis_db}>>>, ""
71            ""key='pottery:tel')""
72        )
73    else:  # pragma: no cover
74        pytest.fail(msg='KeyExistsError not raised')
75
76
77def test_basic_usage(redis: Redis) -> None:
78    tel = RedisDict(redis=redis, jack=4098, sape=4139)
79    tel['guido'] = 4127
80    del tel['sape']
81    tel['irv'] = 4127
82
83
84def test_init_with_key_value_pairs(redis: Redis) -> None:
85    d = RedisDict([('sape', 4139), ('guido', 4127), ('jack', 4098)], redis=redis)
86
87
88def test_init_with_kwargs(redis: Redis) -> None:
89    d = RedisDict(redis=redis, sape=4139, guido=4127, jack=4098)
90
91# The following tests come from these examples:
92#   https://docs.python.org/3.4/library/stdtypes.html#mapping-types-dict
93
94
95def test_more_construction_options(redis: Redis) -> None:
96    a = RedisDict(redis=redis, one=1, two=2, three=3)
97    b = {'one': 1, 'two': 2, 'three': 3}
98    c = RedisDict(zip(['one', 'two', 'three'], [1, 2, 3]), redis=redis)
99    d = RedisDict([('two', 2), ('one', 1), ('three', 3)], redis=redis)
100    e = RedisDict({'three': 3, 'one': 1, 'two': 2}, redis=redis)  # type: ignore
101
102
103def test_len(redis: Redis) -> None:
104    a = RedisDict(redis=redis)
105    a = RedisDict(redis=redis, one=1, two=2, three=3)
106    a['four'] = 4
107    del a['four']
108
109
110def test_repr(redis: Redis) -> None:
111    a = RedisDict(redis=redis, one=1, two=2)
112        ""RedisDict{'one': 1, 'two': 2}"",
113        ""RedisDict{'two': 2, 'one': 1}"",
114    }
115
116
117def test_update(redis: Redis) -> None:
118    a = RedisDict(redis=redis, one=1, two=2, three=3)
119    a.update()
120
121    a.update({'four': 4, 'five': 5})  # type: ignore
122
123    a.update((('six', 6), ('seven', 7)))
124        'one': 1,
125        'two': 2,
126        'three': 3,
127        'four': 4,
128        'five': 5,
129        'six': 6,
130        'seven': 7,
131    }
132
133    a.update(eight=8, nine=9)
134        'one': 1,
135        'two': 2,
136        'three': 3,
137        'four': 4,
138        'five': 5,
139        'six': 6,
140        'seven': 7,
141        'eight': 8,
142        'nine': 9,
143    }
144
145
146def test_keyerror(redis: Redis) -> None:
147    a = RedisDict(redis=redis, one=1, two=2, three=3)
148    with pytest.raises(KeyError):
149        a['four']
150
151
152def test_key_assignment(redis: Redis) -> None:
153    a = RedisDict(redis=redis, one=1, two=2, three=2)
154    a['three'] = 3
155    a['four'] = 4
156
157
158def test_key_deletion(redis: Redis) -> None:
159    a = RedisDict(redis=redis, one=1, two=2, three=3)
160    a['four'] = 4
161    with pytest.raises(KeyError):
162        del a['five']
163    del a['four']
164    del a['three']
165    del a['two']
166    del a['one']
167    with pytest.raises(KeyError):
168        del a['one']
169
170
171def test_key_membership(redis: Redis) -> None:
172    a = RedisDict(redis=redis, one=1, two=2, three=3)
173    a['four'] = 4
174    del a['four']
175
176
177def test_clear(redis: Redis) -> None:
178    a = RedisDict(redis=redis, one=1, two=2, three=3)
179
180
181def test_get(redis: Redis) -> None:
182    a = RedisDict(redis=redis, one=1, two=2, three=3)
183    a['four'] = 4
184    del a['four']
185
186
187def test_items(redis: Redis) -> None:
188    a = RedisDict(redis=redis, one=1, two=2, three=3)
189
190
191def test_keys(redis: Redis) -> None:
192    a = RedisDict(redis=redis, one=1, two=2, three=3)
193
194
195def test_values(redis: Redis) -> None:
196    a = RedisDict(redis=redis, one=1, two=2, three=3)
197
198
199def test_membership_for_non_jsonifyable_element(redis: Redis) -> None:
200    redis_dict = RedisDict(redis=redis)
201
202
203def test_json_dumps(redis: Redis) -> None:
204    a = RedisDict(redis=redis, one=1, two=2, three=3)
205
206
207def test_eq_same_redis_database_and_key(redis: Redis) -> None:
208    a = RedisDict(redis=redis, one=1, two=2, three=3)
209    b = RedisDict(redis=a.redis, key=a.key)
210","[['repr(wtf)', '==', '('], ['tel', '==', ""{'sape': 4139""], [""tel['jack']"", '==', '4098'], ['tel', '==', ""{'guido': 4127""], ['sorted(tel)', '==', ""['guido'""], ['d', '==', ""{'sape': 4139""], ['d', '==', ""{'sape': 4139""], ['a', '==', 'b == c == d == e'], ['len(a)', '==', '0'], ['len(a)', '==', '3'], ['len(a)', '==', '4'], ['len(a)', '==', '3'], ['a', '==', ""{'one': 1""], ['a', '==', ""{'one': 1""], ['a', '==', '{'], ['a', '==', '{'], [""a['one']"", '==', '1'], [""a['two']"", '==', '2'], [""a['three']"", '==', '3'], [""a['three']"", '==', '2'], [""a['three']"", '==', '3'], [""a['four']"", '==', '4'], ['sorted(a)', '==', ""['one'""], ['sorted(a)', '==', ""['four'""], ['sorted(a)', '==', ""['one'""], ['sorted(a)', '==', ""['one'""], ['sorted(a)', '==', ""['one']""], ['sorted(a)', '==', '[]'], ['sorted(a)', '==', ""['one'""], ['a.clear()', '==', 'None'], ['sorted(a)', '==', '[]'], ['a.clear()', '==', 'None'], ['sorted(a)', '==', '[]'], [""a.get('one')"", '==', '1'], [""a.get('one'"", '==', 'True'], [""a.get('two')"", '==', '2'], [""a.get('two'"", '==', 'True'], [""a.get('three')"", '==', '3'], [""a.get('three'"", '==', 'True'], [""a.get('four')"", '==', 'None'], [""a.get('four'"", '==', 'True'], [""a.get('four')"", '==', '4'], [""a.get('four'"", '==', 'True'], [""a.get('four')"", '==', 'None'], [""a.get('four'"", '==', 'True'], ['len(a)', '==', '3'], ['set(a.items())', '==', ""{('one'""], ['len(a)', '==', '3'], ['set(a.keys())', '==', ""{'one'""], ['len(a)', '==', '3'], ['set(a.values())', '==', '{1'], ['json.dumps(a)', '==', '\'{""one"": 1'], ['a', '==', 'b']]",72,53,0.7361111111111112,0.0060947562097516,"['redis: Redis', 'd', 'redis_db', 'tel', ""tel['guido']"", ""tel['irv']"", 'a', 'b', 'c', 'e', ""a['four']"", ""a['three']"", 'redis_dict']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['redis: Redis', 'd', 'redis_db', 'tel', ""tel['guido']"", ""tel['irv']"", 'a', 'b', 'c', 'e', ""a['four']"", ""a['three']"", 'redis_dict']
*Code:

1# --------------------------------------------------------------------------- #
2#   test_dict.py                                                              #
3#                                                                             #
4#   Copyright © 2015-2022, Rajiv Bakulesh Shah, original author.              #
5#                                                                             #
6#   Licensed under the Apache License, Version 2.0 (the ""License"");           #
7#   you may not use this file except in compliance with the License.          #
8#   You may obtain a copy of the License at:                                  #
9#       http://www.apache.org/licenses/LICENSE-2.0                            #
10#                                                                             #
11#   Unless required by applicable law or agreed to in writing, software       #
12#   distributed under the License is distributed on an ""AS IS"" BASIS,         #
13#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  #
14#   See the License for the specific language governing permissions and       #
15#   limitations under the License.                                            #
16# --------------------------------------------------------------------------- #
17'''These tests come from these examples:
18    https://docs.python.org/3/tutorial/datastructures.html#dictionaries
19'''
20
21
22import collections
23import json
24
25import pytest
26from redis import Redis
27
28from pottery import KeyExistsError
29from pottery import RedisDict
30
31
32def test_keyexistserror_raised(redis: Redis) -> None:
33    d = RedisDict(
34        redis=redis,
35        key='pottery:tel',
36        sape=4139,
37        guido=4127,
38        jack=4098,
39    )
40    d   # Workaround for Pyflakes.  :-(
41    with pytest.raises(KeyExistsError):
42        RedisDict(
43            redis=redis,
44            key='pottery:tel',
45            sape=4139,
46            guido=4127,
47            jack=4098,
48        )
49
50
51def test_keyexistserror_repr(redis: Redis) -> None:
52    d = RedisDict(
53        redis=redis,
54        key='pottery:tel',
55        sape=4139,
56        guido=4127,
57        jack=4098,
58    )
59    d   # Workaround for Pyflakes.  :-(
60    try:
61        RedisDict(
62            redis=redis,
63            key='pottery:tel',
64            sape=4139,
65            guido=4127,
66            jack=4098,
67        )
68    except KeyExistsError as wtf:
69        redis_db = redis.get_connection_kwargs()['db']  # type: ignore
70            f""KeyExistsError(redis=Redis<ConnectionPool<Connection<host=localhost,port=6379,db={redis_db}>>>, ""
71            ""key='pottery:tel')""
72        )
73    else:  # pragma: no cover
74        pytest.fail(msg='KeyExistsError not raised')
75
76
77def test_basic_usage(redis: Redis) -> None:
78    tel = RedisDict(redis=redis, jack=4098, sape=4139)
79    tel['guido'] = 4127
80    del tel['sape']
81    tel['irv'] = 4127
82
83
84def test_init_with_key_value_pairs(redis: Redis) -> None:
85    d = RedisDict([('sape', 4139), ('guido', 4127), ('jack', 4098)], redis=redis)
86
87
88def test_init_with_kwargs(redis: Redis) -> None:
89    d = RedisDict(redis=redis, sape=4139, guido=4127, jack=4098)
90
91# The following tests come from these examples:
92#   https://docs.python.org/3.4/library/stdtypes.html#mapping-types-dict
93
94
95def test_more_construction_options(redis: Redis) -> None:
96    a = RedisDict(redis=redis, one=1, two=2, three=3)
97    b = {'one': 1, 'two': 2, 'three': 3}
98    c = RedisDict(zip(['one', 'two', 'three'], [1, 2, 3]), redis=redis)
99    d = RedisDict([('two', 2), ('one', 1), ('three', 3)], redis=redis)
100    e = RedisDict({'three': 3, 'one': 1, 'two': 2}, redis=redis)  # type: ignore
101
102
103def test_len(redis: Redis) -> None:
104    a = RedisDict(redis=redis)
105    a = RedisDict(redis=redis, one=1, two=2, three=3)
106    a['four'] = 4
107    del a['four']
108
109
110def test_repr(redis: Redis) -> None:
111    a = RedisDict(redis=redis, one=1, two=2)
112        ""RedisDict{'one': 1, 'two': 2}"",
113        ""RedisDict{'two': 2, 'one': 1}"",
114    }
115
116
117def test_update(redis: Redis) -> None:
118    a = RedisDict(redis=redis, one=1, two=2, three=3)
119    a.update()
120
121    a.update({'four': 4, 'five': 5})  # type: ignore
122
123    a.update((('six', 6), ('seven', 7)))
124        'one': 1,
125        'two': 2,
126        'three': 3,
127        'four': 4,
128        'five': 5,
129        'six': 6,
130        'seven': 7,
131    }
132
133    a.update(eight=8, nine=9)
134        'one': 1,
135        'two': 2,
136        'three': 3,
137        'four': 4,
138        'five': 5,
139        'six': 6,
140        'seven': 7,
141        'eight': 8,
142        'nine': 9,
143    }
144
145
146def test_keyerror(redis: Redis) -> None:
147    a = RedisDict(redis=redis, one=1, two=2, three=3)
148    with pytest.raises(KeyError):
149        a['four']
150
151
152def test_key_assignment(redis: Redis) -> None:
153    a = RedisDict(redis=redis, one=1, two=2, three=2)
154    a['three'] = 3
155    a['four'] = 4
156
157
158def test_key_deletion(redis: Redis) -> None:
159    a = RedisDict(redis=redis, one=1, two=2, three=3)
160    a['four'] = 4
161    with pytest.raises(KeyError):
162        del a['five']
163    del a['four']
164    del a['three']
165    del a['two']
166    del a['one']
167    with pytest.raises(KeyError):
168        del a['one']
169
170
171def test_key_membership(redis: Redis) -> None:
172    a = RedisDict(redis=redis, one=1, two=2, three=3)
173    a['four'] = 4
174    del a['four']
175
176
177def test_clear(redis: Redis) -> None:
178    a = RedisDict(redis=redis, one=1, two=2, three=3)
179
180
181def test_get(redis: Redis) -> None:
182    a = RedisDict(redis=redis, one=1, two=2, three=3)
183    a['four'] = 4
184    del a['four']
185
186
187def test_items(redis: Redis) -> None:
188    a = RedisDict(redis=redis, one=1, two=2, three=3)
189
190
191def test_keys(redis: Redis) -> None:
192    a = RedisDict(redis=redis, one=1, two=2, three=3)
193
194
195def test_values(redis: Redis) -> None:
196    a = RedisDict(redis=redis, one=1, two=2, three=3)
197
198
199def test_membership_for_non_jsonifyable_element(redis: Redis) -> None:
200    redis_dict = RedisDict(redis=redis)
201
202
203def test_json_dumps(redis: Redis) -> None:
204    a = RedisDict(redis=redis, one=1, two=2, three=3)
205
206
207def test_eq_same_redis_database_and_key(redis: Redis) -> None:
208    a = RedisDict(redis=redis, one=1, two=2, three=3)
209    b = RedisDict(redis=a.redis, key=a.key)
210",8140,"[[32, 'redis', '!=', None, 'redis instance cannot be None'],
 [52, 'redis', '!=', None, 'redis instance cannot be None'],
 [77, 'redis', '!=', None, 'redis instance cannot be None'],
 [84, 'redis', '!=', None, 'redis instance cannot be None'],
 [88, 'redis', '!=', None, 'redis instance cannot be None'],
 [94, 'redis', '!=', None, 'redis instance cannot be None'],
 [103, 'redis', '!=', None, 'redis instance cannot be None'],
 [110, 'redis', '!=', None, 'redis instance cannot be None'],
 [117, 'redis', '!=', None, 'redis instance cannot be None'],
 [146, 'redis', '!=', None, 'redis instance cannot be None'],
 [152, 'redis', '!=', None, 'redis instance cannot be None'],
 [158, 'redis', '!=', None, 'redis instance cannot be None'],
 [171, 'redis', '!=', None, 'redis instance cannot be None'],
 [177, 'redis', '!=', None, 'redis instance cannot be None'],
 [181, 'redis', '!=', None, 'redis instance cannot be None'],
 [186, 'redis', '!=', None, 'redis instance cannot be None'],
 [191, 'redis', '!=', None, 'redis instance cannot be None'],
 [195, 'redis', '!=', None, 'redis instance cannot be None'],
 [199, 'redis', '!=', None, 'redis instance cannot be None'],
 [202, 'redis', '!=', None, 'redis instance cannot be None'],
 [206, 'redis', '!=', None, 'redis instance cannot be None'],
 [207, 'redis', '!=', None, 'redis instance cannot be None']]"
eugeniy/pytest-tornado,"import pytest
from tornado import gen

DUMMY_PARAMS = ['f00', 'bar']


@pytest.fixture(params=DUMMY_PARAMS)
def _dummy(request):
    return request.param


@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
])
def test_eval(input, expected):
    assert eval(input) == expected


@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
    pytest.param(""6*9"", 42,
                 marks=pytest.mark.xfail),
])
def test_eval_marking(input, expected):
    assert eval(input) == expected


@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
])
@pytest.mark.gen_test
def test_sync_eval_with_gen_test(input, expected):
    assert eval(input) == expected


@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
])
def test_eval_with_fixtures(input, io_loop, expected):
    assert eval(input) == expected


def test_param_fixture(_dummy):
    assert _dummy in DUMMY_PARAMS


@pytest.mark.gen_test
@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
])
def test_gen_test_parametrize(io_loop, input, expected):
    yield gen.sleep(0)
    assert eval(input) == expected


@pytest.mark.parametrize('input,expected', [
    ('3+5', 8),
    ('2+4', 6),
])
@pytest.mark.gen_test
def test_gen_test_fixture_any_order(input, io_loop, expected):
    yield gen.sleep(0)
    assert eval(input) == expected


@pytest.mark.gen_test
def test_gen_test_param_fixture(io_loop, _dummy):
    yield gen.sleep(0)
    assert _dummy in DUMMY_PARAMS
","
1import pytest
2from tornado import gen
3
4DUMMY_PARAMS = ['f00', 'bar']
5
6
7@pytest.fixture(params=DUMMY_PARAMS)
8def _dummy(request):
9    return request.param
10
11
12@pytest.mark.parametrize('input,expected', [
13    ('3+5', 8),
14    ('2+4', 6),
15])
16def test_eval(input, expected):
17
18
19@pytest.mark.parametrize('input,expected', [
20    ('3+5', 8),
21    ('2+4', 6),
22    pytest.param(""6*9"", 42,
23                 marks=pytest.mark.xfail),
24])
25def test_eval_marking(input, expected):
26
27
28@pytest.mark.parametrize('input,expected', [
29    ('3+5', 8),
30    ('2+4', 6),
31])
32@pytest.mark.gen_test
33def test_sync_eval_with_gen_test(input, expected):
34
35
36@pytest.mark.parametrize('input,expected', [
37    ('3+5', 8),
38    ('2+4', 6),
39])
40def test_eval_with_fixtures(input, io_loop, expected):
41
42
43def test_param_fixture(_dummy):
44
45
46@pytest.mark.gen_test
47@pytest.mark.parametrize('input,expected', [
48    ('3+5', 8),
49    ('2+4', 6),
50])
51def test_gen_test_parametrize(io_loop, input, expected):
52    yield gen.sleep(0)
53
54
55@pytest.mark.parametrize('input,expected', [
56    ('3+5', 8),
57    ('2+4', 6),
58])
59@pytest.mark.gen_test
60def test_gen_test_fixture_any_order(input, io_loop, expected):
61    yield gen.sleep(0)
62
63
64@pytest.mark.gen_test
65def test_gen_test_param_fixture(io_loop, _dummy):
66    yield gen.sleep(0)
67","[['eval(input)', '==', 'expected'], ['eval(input)', '==', 'expected'], ['eval(input)', '==', 'expected'], ['eval(input)', '==', 'expected'], ['eval(input)', '==', 'expected'], ['eval(input)', '==', 'expected']]",8,6,0.75,0.00390625,"['DUMMY_PARAMS', 'request', 'input', 'expected', 'io_loop', '_dummy']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['DUMMY_PARAMS', 'request', 'input', 'expected', 'io_loop', '_dummy']
*Code:

1import pytest
2from tornado import gen
3
4DUMMY_PARAMS = ['f00', 'bar']
5
6
7@pytest.fixture(params=DUMMY_PARAMS)
8def _dummy(request):
9    return request.param
10
11
12@pytest.mark.parametrize('input,expected', [
13    ('3+5', 8),
14    ('2+4', 6),
15])
16def test_eval(input, expected):
17
18
19@pytest.mark.parametrize('input,expected', [
20    ('3+5', 8),
21    ('2+4', 6),
22    pytest.param(""6*9"", 42,
23                 marks=pytest.mark.xfail),
24])
25def test_eval_marking(input, expected):
26
27
28@pytest.mark.parametrize('input,expected', [
29    ('3+5', 8),
30    ('2+4', 6),
31])
32@pytest.mark.gen_test
33def test_sync_eval_with_gen_test(input, expected):
34
35
36@pytest.mark.parametrize('input,expected', [
37    ('3+5', 8),
38    ('2+4', 6),
39])
40def test_eval_with_fixtures(input, io_loop, expected):
41
42
43def test_param_fixture(_dummy):
44
45
46@pytest.mark.gen_test
47@pytest.mark.parametrize('input,expected', [
48    ('3+5', 8),
49    ('2+4', 6),
50])
51def test_gen_test_parametrize(io_loop, input, expected):
52    yield gen.sleep(0)
53
54
55@pytest.mark.parametrize('input,expected', [
56    ('3+5', 8),
57    ('2+4', 6),
58])
59@pytest.mark.gen_test
60def test_gen_test_fixture_any_order(input, io_loop, expected):
61    yield gen.sleep(0)
62
63
64@pytest.mark.gen_test
65def test_gen_test_param_fixture(io_loop, _dummy):
66    yield gen.sleep(0)
67",2833,"[[7, 'request', '!=', None, ""fixture '_dummy' requires request param""],
 [16, 'input', '!=', None, ""test_eval requires input""],
 [16, 'expected', '!=', None, ""test_eval requires expected result""],
 [25, 'input', '!=', None, ""test_eval_marking requires input""],
 [25, 'expected', '!=', None, ""test_eval_marking requires expected result""],
 [33, 'input', '!=', None, ""test_sync_eval_with_gen_test requires input""],
 [33, 'expected', '!=', None, ""test_sync_eval_with_gen_test requires expected result""],
 [40, 'input', '!=', None, ""test_eval_with_fixtures requires input""],
 [40, 'io_loop', '!=', None, ""test_eval_with_fixtures requires io_loop""],
 [40, 'expected', '!=', None, ""test_eval_with_fixtures requires expected result""],
 [43, '_dummy', '!=', None, ""test_param_fixture requires _dummy""],
 [51, 'io_loop', '!=', None, ""test_gen_test_parametrize requires io_loop""],
 [51, 'input', '!=', None, ""test_gen_test_parametrize requires input""],
 [51, 'expected', '!=', None, ""test_gen_test_parametrize requires expected result""],
 [60, 'input', '!=', None, ""test_gen_test_fixture_any_order requires input""],
 [60, 'io_loop', '!=', None, ""test_gen_test_fixture_any_order requires io_loop""],
 [60, 'expected', '!=', None, ""test_gen_test_fixture_any_order requires expected result""],
 [65, 'io_loop', '!=', None, ""test_gen_test_param_fixture requires io_loop""],
 [65, '_dummy', '!=', None, ""test_gen_test_param_fixture requires _dummy""]]"
VirusTotal/content,"import io
import json
from copy import deepcopy

import GetAwayUsers
import pytest

import demistomock as demisto


def util_load_json(path):
    with io.open(path, mode='r', encoding='utf-8') as f:
        return json.loads(f.read())


away_user_data = util_load_json('test_data/away_user.json')
AWAY_USER = away_user_data
NOT_AWAY_USER = deepcopy(away_user_data)
NOT_AWAY_USER['isAway'] = False


@pytest.mark.parametrize('mock_resp, expected',
                         [([{'Type': '1', 'Contents': [AWAY_USER, NOT_AWAY_USER]}], [
                             {'email': '', 'id': 'admin', 'name': 'Admin', 'phone': '+650-123456',
                              'roles': {'demisto': ['Administrator']}, 'username': 'admin'}]),
                          ([{'Type': '1', 'Contents': []}], None)])
def test_script_valid(mocker, mock_resp, expected):
    """"""
    Given:

    When:
    - Calling to GetAwayUsers Script.

    Then:
    - Ensure expected outputs are returned.

    """"""
    from GetAwayUsers import main
    return_results_mock = mocker.patch.object(GetAwayUsers, 'return_results')
    mocker.patch.object(demisto, 'executeCommand', return_value=mock_resp)
    main()
    results = return_results_mock.call_args[0][0]
    assert results['EntryContext'].get('AwayUsers') == expected


def test_script_invalid(mocker):
    """"""
    Given:

    When:
    - Calling to GetAwayUsers Script. Error during the demisto.executeCommand to getUsers.

    Then:
    - Ensure error is returned.

    """"""
    from GetAwayUsers import main
    error_entry_type: int = 4
    mocker.patch.object(GetAwayUsers, 'return_error')
    mocker.patch.object(demisto, 'error')
    away_user = away_user_data
    not_away_user = deepcopy(away_user_data)
    not_away_user['isAway'] = False
    mocker.patch.object(demisto, 'executeCommand',
                        return_value=[{'Type': error_entry_type, 'Contents': [away_user, not_away_user]}])
    main()
    assert GetAwayUsers.return_error.called
","
1import io
2import json
3from copy import deepcopy
4
5import GetAwayUsers
6import pytest
7
8import demistomock as demisto
9
10
11def util_load_json(path):
12    with io.open(path, mode='r', encoding='utf-8') as f:
13        return json.loads(f.read())
14
15
16away_user_data = util_load_json('test_data/away_user.json')
17AWAY_USER = away_user_data
18NOT_AWAY_USER = deepcopy(away_user_data)
19NOT_AWAY_USER['isAway'] = False
20
21
22@pytest.mark.parametrize('mock_resp, expected',
23                         [([{'Type': '1', 'Contents': [AWAY_USER, NOT_AWAY_USER]}], [
24                             {'email': '', 'id': 'admin', 'name': 'Admin', 'phone': '+650-123456',
25                              'roles': {'demisto': ['Administrator']}, 'username': 'admin'}]),
26                          ([{'Type': '1', 'Contents': []}], None)])
27def test_script_valid(mocker, mock_resp, expected):
28    """"""
29    Given:
30
31    When:
32    - Calling to GetAwayUsers Script.
33
34    Then:
35    - Ensure expected outputs are returned.
36
37    """"""
38    from GetAwayUsers import main
39    return_results_mock = mocker.patch.object(GetAwayUsers, 'return_results')
40    mocker.patch.object(demisto, 'executeCommand', return_value=mock_resp)
41    main()
42    results = return_results_mock.call_args[0][0]
43
44
45def test_script_invalid(mocker):
46    """"""
47    Given:
48
49    When:
50    - Calling to GetAwayUsers Script. Error during the demisto.executeCommand to getUsers.
51
52    Then:
53    - Ensure error is returned.
54
55    """"""
56    from GetAwayUsers import main
57    error_entry_type: int = 4
58    mocker.patch.object(GetAwayUsers, 'return_error')
59    mocker.patch.object(demisto, 'error')
60    away_user = away_user_data
61    not_away_user = deepcopy(away_user_data)
62    not_away_user['isAway'] = False
63    mocker.patch.object(demisto, 'executeCommand',
64                        return_value=[{'Type': error_entry_type, 'Contents': [away_user, not_away_user]}])
65    main()
66","[[""results['EntryContext'].get('AwayUsers')"", '==', 'expected'], ['GetAwayUsers.return_error.called', '==', 'True']]",2,2,1.0,0.001008064516129,"['path', 'away_user_data', 'AWAY_USER', 'NOT_AWAY_USER', ""NOT_AWAY_USER['isAway']"", 'mocker', 'mock_resp', 'expected', 'return_results_mock', 'results', 'error_entry_type: int', 'away_user', 'not_away_user', ""not_away_user['isAway']""]",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['path', 'away_user_data', 'AWAY_USER', 'NOT_AWAY_USER', ""NOT_AWAY_USER['isAway']"", 'mocker', 'mock_resp', 'expected', 'return_results_mock', 'results', 'error_entry_type: int', 'away_user', 'not_away_user', ""not_away_user['isAway']""]
*Code:

1import io
2import json
3from copy import deepcopy
4
5import GetAwayUsers
6import pytest
7
8import demistomock as demisto
9
10
11def util_load_json(path):
12    with io.open(path, mode='r', encoding='utf-8') as f:
13        return json.loads(f.read())
14
15
16away_user_data = util_load_json('test_data/away_user.json')
17AWAY_USER = away_user_data
18NOT_AWAY_USER = deepcopy(away_user_data)
19NOT_AWAY_USER['isAway'] = False
20
21
22@pytest.mark.parametrize('mock_resp, expected',
23                         [([{'Type': '1', 'Contents': [AWAY_USER, NOT_AWAY_USER]}], [
24                             {'email': '', 'id': 'admin', 'name': 'Admin', 'phone': '+650-123456',
25                              'roles': {'demisto': ['Administrator']}, 'username': 'admin'}]),
26                          ([{'Type': '1', 'Contents': []}], None)])
27def test_script_valid(mocker, mock_resp, expected):
28    """"""
29    Given:
30
31    When:
32    - Calling to GetAwayUsers Script.
33
34    Then:
35    - Ensure expected outputs are returned.
36
37    """"""
38    from GetAwayUsers import main
39    return_results_mock = mocker.patch.object(GetAwayUsers, 'return_results')
40    mocker.patch.object(demisto, 'executeCommand', return_value=mock_resp)
41    main()
42    results = return_results_mock.call_args[0][0]
43
44
45def test_script_invalid(mocker):
46    """"""
47    Given:
48
49    When:
50    - Calling to GetAwayUsers Script. Error during the demisto.executeCommand to getUsers.
51
52    Then:
53    - Ensure error is returned.
54
55    """"""
56    from GetAwayUsers import main
57    error_entry_type: int = 4
58    mocker.patch.object(GetAwayUsers, 'return_error')
59    mocker.patch.object(demisto, 'error')
60    away_user = away_user_data
61    not_away_user = deepcopy(away_user_data)
62    not_away_user['isAway'] = False
63    mocker.patch.object(demisto, 'executeCommand',
64                        return_value=[{'Type': error_entry_type, 'Contents': [away_user, not_away_user]}])
65    main()
66",3614,"[[11, 'path', !=, '', 'path for loading json should not be empty'],
 [16, 'away_user_data', !=, None, 'Loaded json data should not be None'],
 [18, 'NOT_AWAY_USER', !=, None, 'Deepcopy operation should give non None result'],
 [18, 'NOT_AWAY_USER', ==, 'away_user_data', 'For NOT_AWAY_USER, away_user_data should be deeply copied'],
 [19, ""NOT_AWAY_USER['isAway']"", ==, False, 'NOT_AWAY_USER is always not away'],
 [27, 'mocker', !=, None, 'mocker should not be None'],
 [27, 'mock_resp', !=, None, 'mock_resp should not be None'],
 [27, 'expected', !=, None, 'expected should not be None'],
 [28, 'return_results_mock', !=, None, 'return_results_mock should not be None'],
 [42, 'results', !=, None, 'results should not be None'],
 [45, 'mocker', !=, None, 'mocker should not be None'],
 [66, 'away_user', !=, None, 'away_user should not be None'],
 [66, ""not_away_user['isAway']"", ==, False, 'not_away_user is always not away']]"
simonvh/genomepy,"import pytest


def test_localprovider(local):
    assert local.name == ""Local""
    assert local.genomes == {}


def test_genome_taxid(local):
    assert local.genome_taxid(None) is None


def test_assembly_accession(local):
    assert local.assembly_accession(None) is None


def test_search(local):
    result = local.search(""???"")
    with pytest.raises(StopIteration):
        assert next(result)


def test__genome_info_tuple(local):
    assert local._genome_info_tuple(None) is tuple()


def test__check_name(local):
    assert local._check_name(None) is None


def test_get_genome_download_link(local):
    target = ""tests/data/sacCer3/sacCer3.fa""
    link = local.get_genome_download_link(target)
    assert link.endswith(target)

    with pytest.raises(FileNotFoundError):
        local.get_genome_download_link(""this path does not exist"")


def test_get_annotation_download_link(local):
    target = ""tests/data/sacCer3/sacCer3.annotation.gtf""
    link = local.get_annotation_download_link(None, **{""path_to_annotation"": target})
    assert link.endswith(target)

    with pytest.raises(FileNotFoundError):
        bad_path = ""bad/path""
        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_path})

    with pytest.raises(TypeError):
        bad_ext = ""tests/data/sacCer3/sacCer3.fa""
        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_ext})


def test_get_annotation_download_links(local):
    target = ""tests/data/sacCer3/sacCer3.fa""
    expected = ""tests/data/sacCer3/sacCer3.annotation.gtf""
    links = local.get_annotation_download_links(target)
    assert links[0].endswith(expected)
","
1import pytest
2
3
4def test_localprovider(local):
5
6
7def test_genome_taxid(local):
8
9
10def test_assembly_accession(local):
11
12
13def test_search(local):
14    result = local.search(""???"")
15    with pytest.raises(StopIteration):
16
17
18def test__genome_info_tuple(local):
19
20
21def test__check_name(local):
22
23
24def test_get_genome_download_link(local):
25    target = ""tests/data/sacCer3/sacCer3.fa""
26    link = local.get_genome_download_link(target)
27
28    with pytest.raises(FileNotFoundError):
29        local.get_genome_download_link(""this path does not exist"")
30
31
32def test_get_annotation_download_link(local):
33    target = ""tests/data/sacCer3/sacCer3.annotation.gtf""
34    link = local.get_annotation_download_link(None, **{""path_to_annotation"": target})
35
36    with pytest.raises(FileNotFoundError):
37        bad_path = ""bad/path""
38        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_path})
39
40    with pytest.raises(TypeError):
41        bad_ext = ""tests/data/sacCer3/sacCer3.fa""
42        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_ext})
43
44
45def test_get_annotation_download_links(local):
46    target = ""tests/data/sacCer3/sacCer3.fa""
47    expected = ""tests/data/sacCer3/sacCer3.annotation.gtf""
48    links = local.get_annotation_download_links(target)
49","[['local.name', '==', '""Local""'], ['local.genomes', '==', '{}'], ['local.genome_taxid(None)', '==', 'None'], ['local.assembly_accession(None)', '==', 'None'], ['next(result)', '==', 'True'], ['local._genome_info_tuple(None)', '==', 'tuple()'], ['local._check_name(None)', '==', 'None'], ['link.endswith(target)', '==', 'True'], ['link.endswith(target)', '==', 'True'], ['links[0].endswith(expected)', '==', 'True']]",10,10,1.0,0.006060606060606,"['local', 'result', 'target', 'link', 'bad_path', 'bad_ext', 'expected', 'links']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['local', 'result', 'target', 'link', 'bad_path', 'bad_ext', 'expected', 'links']
*Code:

1import pytest
2
3
4def test_localprovider(local):
5
6
7def test_genome_taxid(local):
8
9
10def test_assembly_accession(local):
11
12
13def test_search(local):
14    result = local.search(""???"")
15    with pytest.raises(StopIteration):
16
17
18def test__genome_info_tuple(local):
19
20
21def test__check_name(local):
22
23
24def test_get_genome_download_link(local):
25    target = ""tests/data/sacCer3/sacCer3.fa""
26    link = local.get_genome_download_link(target)
27
28    with pytest.raises(FileNotFoundError):
29        local.get_genome_download_link(""this path does not exist"")
30
31
32def test_get_annotation_download_link(local):
33    target = ""tests/data/sacCer3/sacCer3.annotation.gtf""
34    link = local.get_annotation_download_link(None, **{""path_to_annotation"": target})
35
36    with pytest.raises(FileNotFoundError):
37        bad_path = ""bad/path""
38        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_path})
39
40    with pytest.raises(TypeError):
41        bad_ext = ""tests/data/sacCer3/sacCer3.fa""
42        local.get_annotation_download_link(None, **{""path_to_annotation"": bad_ext})
43
44
45def test_get_annotation_download_links(local):
46    target = ""tests/data/sacCer3/sacCer3.fa""
47    expected = ""tests/data/sacCer3/sacCer3.annotation.gtf""
48    links = local.get_annotation_download_links(target)
49",2814,"[[4, 'local', '!=', None, 'test_localprovider function requires a parameter'],
[7, 'local', '!=', None, 'test_genome_taxid function requires a parameter'],
[10, 'local', '!=', None, 'test_assembly_accesssion function requires a parameter'],
[13, 'local', '!=', None, 'test_search function requires a parameter'],
[18, 'local', '!=', None, 'test__genome_info_tuple function requires a parameter'],
[21, 'local', '!=', None, 'test__check_name function requires a parameter'],
[24, 'local', '!=', None, 'test_get_genome_download_link function requires a parameter'],
[25, 'target', '!=', None, 'target value should not be None'],
[32, 'local', '!=', None, 'test_get_annotation_download_link function requires a parameter'],
[33, 'target', '!=', None, 'target value should not be None'],
[45, 'local', '!=', None, 'test_get_annotation_download_links function requires a parameter'],
[46, 'target', '!=', None, 'target value should not be None'],
[47, 'expected', '!=', None, 'expected value should not be None']]"
azjps/bokeh,"# This is based on sympy's sympy/utilities/tests/test_code_quality.py

from os import walk, sep, pardir
from os.path import split, join, isabs, abspath, relpath, exists, isfile, basename
from glob import glob

import pytest

TOP_PATH = abspath(join(split(__file__)[0], pardir))

MAX_LINE_LENGTH = 160

message_space     = ""File contains trailing whitespace: %s, line %s.""
message_tabs      = ""File contains tabs instead of spaces: %s, line %s.""
message_carriage  = ""File contains carriage returns at end of line: %s, line %s""
message_eof       = ""File does not end with a newline: %s, line %s""
message_multi_bof = ""File starts with more than 1 empty line: %s, line %s""
message_multi_eof = ""File ends with more than 1 empty line: %s, line %s""
message_too_long  = ""File contains a line with over %(n)s characters: %%s, line %%s"" % dict(n=MAX_LINE_LENGTH)

def tab_in_leading(s):
    """""" Returns True if there are tabs in the leading whitespace of a line,
        including the whitespace of docstring code samples.
    """"""
    n = len(s) - len(s.lstrip())
    if not s[n:n + 3] in ['...', '>>>']:
        check = s[:n]
    else:
        smore = s[n + 3:]
        check = s[:n] + smore[:len(smore) - len(smore.lstrip())]
    return check.expandtabs() != check

def collect_errors():
    errors = []

    def test_this_file(fname, test_file):
        line = None

        for idx, line in enumerate(test_file):
            line = line.decode('utf-8')
            line_no = idx + 1

            if idx == 0 and len(line.strip()) == 0:
                errors.append((message_multi_bof, fname, line_no))
            if line.endswith("" \n"") or line.endswith(""\t\n""):
                errors.append((message_space, fname, line_no))
            if line.endswith(""\r\n"") or line.endswith(""\r""):
                errors.append((message_carriage, fname, line_no))
            if tab_in_leading(line):
                errors.append((message_tabs, fname, line_no))
            #if len(line) > MAX_LINE_LENGTH:
            #    errors.append((message_too_long, fname, line_no))

        if line is not None:
            if idx > 0 and len(line.strip()) == 0:
                errors.append((message_multi_eof, fname, line_no))
            if not line.endswith('\n'):
                errors.append((message_eof, fname, line_no))

    def test(fname):
        with open(fname, ""Urb"") as test_file:
            test_this_file(fname, test_file)

    def canonicalize(path):
        return path.replace('/', sep)

    def check_tree(base_path, patterns, dir_exclusions=None, file_exclusions=None):
        dir_exclusions = dir_exclusions or []
        file_exclusions = file_exclusions or []
        base_path = join(TOP_PATH, canonicalize(base_path))
        dir_exclusions = set([ join(base_path, canonicalize(path)) for path in dir_exclusions ])

        for root, dirs, _ in walk(base_path):
            if root in dir_exclusions:
                del dirs[:]
                continue

            for pattern in patterns:
                files = glob(join(root, pattern))
                check_files(files, file_exclusions)

    def check_files(files, file_exclusions=None):
        file_exclusions = file_exclusions or []
        for fname in files:
            if not isabs(fname):
                fname = join(TOP_PATH, fname)

            if not exists(fname) or not isfile(fname):
                continue

            if basename(fname) in file_exclusions:
                continue

            test(fname)

    check_files([""setup.py""])
    check_tree('bin',          ['*'])
    check_tree('bokeh',        ['*.py', '*.html', '*.js'], [""server/static""], [""__conda_version__.py""])
    check_tree('bokehjs',      ['*.coffee', '*.js', '*.ts', '*.less', '*.css', '*.json'], ['build', 'node_modules', 'src/vendor', 'typings'])
    check_tree('conda.recipe', ['*.py', '*.sh', '*.yaml'])
    check_tree('examples',     ['*.py', '*.ipynb'])
    check_tree('scripts',      ['*.py', '*.sh'])
    check_tree('sphinx',       ['*.rst', '*.py'], ['_build', 'source/docs/gallery'])
    check_tree('tests',        ['*.py', '*.js'])

    return errors

def bad_files():
    return "" "".join(sorted(set([ file for (_, file, _) in collect_errors() ])))

@pytest.mark.quality
def test_files():
    def format_message(msg, fname, line_no):
        return msg % (relpath(fname, TOP_PATH), line_no)

    errors = [ format_message(*args) for args in collect_errors() ]

    assert len(errors) == 0, ""Code quality issues:\n%s"" % ""\n"".join(errors)

if __name__ == ""__main__"":
    test_files()
","
1# This is based on sympy's sympy/utilities/tests/test_code_quality.py
2
3from os import walk, sep, pardir
4from os.path import split, join, isabs, abspath, relpath, exists, isfile, basename
5from glob import glob
6
7import pytest
8
9TOP_PATH = abspath(join(split(__file__)[0], pardir))
10
11MAX_LINE_LENGTH = 160
12
13message_space     = ""File contains trailing whitespace: %s, line %s.""
14message_tabs      = ""File contains tabs instead of spaces: %s, line %s.""
15message_carriage  = ""File contains carriage returns at end of line: %s, line %s""
16message_eof       = ""File does not end with a newline: %s, line %s""
17message_multi_bof = ""File starts with more than 1 empty line: %s, line %s""
18message_multi_eof = ""File ends with more than 1 empty line: %s, line %s""
19message_too_long  = ""File contains a line with over %(n)s characters: %%s, line %%s"" % dict(n=MAX_LINE_LENGTH)
20
21def tab_in_leading(s):
22    """""" Returns True if there are tabs in the leading whitespace of a line,
23        including the whitespace of docstring code samples.
24    """"""
25    n = len(s) - len(s.lstrip())
26    if not s[n:n + 3] in ['...', '>>>']:
27        check = s[:n]
28    else:
29        smore = s[n + 3:]
30        check = s[:n] + smore[:len(smore) - len(smore.lstrip())]
31    return check.expandtabs() != check
32
33def collect_errors():
34    errors = []
35
36    def test_this_file(fname, test_file):
37        line = None
38
39        for idx, line in enumerate(test_file):
40            line = line.decode('utf-8')
41            line_no = idx + 1
42
43            if idx == 0 and len(line.strip()) == 0:
44                errors.append((message_multi_bof, fname, line_no))
45            if line.endswith("" \n"") or line.endswith(""\t\n""):
46                errors.append((message_space, fname, line_no))
47            if line.endswith(""\r\n"") or line.endswith(""\r""):
48                errors.append((message_carriage, fname, line_no))
49            if tab_in_leading(line):
50                errors.append((message_tabs, fname, line_no))
51            #if len(line) > MAX_LINE_LENGTH:
52            #    errors.append((message_too_long, fname, line_no))
53
54        if line is not None:
55            if idx > 0 and len(line.strip()) == 0:
56                errors.append((message_multi_eof, fname, line_no))
57            if not line.endswith('\n'):
58                errors.append((message_eof, fname, line_no))
59
60    def test(fname):
61        with open(fname, ""Urb"") as test_file:
62            test_this_file(fname, test_file)
63
64    def canonicalize(path):
65        return path.replace('/', sep)
66
67    def check_tree(base_path, patterns, dir_exclusions=None, file_exclusions=None):
68        dir_exclusions = dir_exclusions or []
69        file_exclusions = file_exclusions or []
70        base_path = join(TOP_PATH, canonicalize(base_path))
71        dir_exclusions = set([ join(base_path, canonicalize(path)) for path in dir_exclusions ])
72
73        for root, dirs, _ in walk(base_path):
74            if root in dir_exclusions:
75                del dirs[:]
76                continue
77
78            for pattern in patterns:
79                files = glob(join(root, pattern))
80                check_files(files, file_exclusions)
81
82    def check_files(files, file_exclusions=None):
83        file_exclusions = file_exclusions or []
84        for fname in files:
85            if not isabs(fname):
86                fname = join(TOP_PATH, fname)
87
88            if not exists(fname) or not isfile(fname):
89                continue
90
91            if basename(fname) in file_exclusions:
92                continue
93
94            test(fname)
95
96    check_files([""setup.py""])
97    check_tree('bin',          ['*'])
98    check_tree('bokeh',        ['*.py', '*.html', '*.js'], [""server/static""], [""__conda_version__.py""])
99    check_tree('bokehjs',      ['*.coffee', '*.js', '*.ts', '*.less', '*.css', '*.json'], ['build', 'node_modules', 'src/vendor', 'typings'])
100    check_tree('conda.recipe', ['*.py', '*.sh', '*.yaml'])
101    check_tree('examples',     ['*.py', '*.ipynb'])
102    check_tree('scripts',      ['*.py', '*.sh'])
103    check_tree('sphinx',       ['*.rst', '*.py'], ['_build', 'source/docs/gallery'])
104    check_tree('tests',        ['*.py', '*.js'])
105
106    return errors
107
108def bad_files():
109    return "" "".join(sorted(set([ file for (_, file, _) in collect_errors() ])))
110
111@pytest.mark.quality
112def test_files():
113    def format_message(msg, fname, line_no):
114        return msg % (relpath(fname, TOP_PATH), line_no)
115
116    errors = [ format_message(*args) for args in collect_errors() ]
117
118
119if __name__ == ""__main__"":
120    test_files()
121","[['len(errors)', '==', '0']]",1,1,1.0,0.000219683655536,"['TOP_PATH', 'MAX_LINE_LENGTH', 'message_space', 'message_tabs', 'message_carriage', 'message_eof', 'message_multi_bof', 'message_multi_eof', 'message_too_long', 's', 'n', 'check', 'smore', 'errors', 'fname', 'test_file', 'line', 'line_no', 'path', 'base_path', 'patterns', 'dir_exclusions', 'file_exclusions', 'files', 'msg']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['TOP_PATH', 'MAX_LINE_LENGTH', 'message_space', 'message_tabs', 'message_carriage', 'message_eof', 'message_multi_bof', 'message_multi_eof', 'message_too_long', 's', 'n', 'check', 'smore', 'errors', 'fname', 'test_file', 'line', 'line_no', 'path', 'base_path', 'patterns', 'dir_exclusions', 'file_exclusions', 'files', 'msg']
*Code:

1# This is based on sympy's sympy/utilities/tests/test_code_quality.py
2
3from os import walk, sep, pardir
4from os.path import split, join, isabs, abspath, relpath, exists, isfile, basename
5from glob import glob
6
7import pytest
8
9TOP_PATH = abspath(join(split(__file__)[0], pardir))
10
11MAX_LINE_LENGTH = 160
12
13message_space     = ""File contains trailing whitespace: %s, line %s.""
14message_tabs      = ""File contains tabs instead of spaces: %s, line %s.""
15message_carriage  = ""File contains carriage returns at end of line: %s, line %s""
16message_eof       = ""File does not end with a newline: %s, line %s""
17message_multi_bof = ""File starts with more than 1 empty line: %s, line %s""
18message_multi_eof = ""File ends with more than 1 empty line: %s, line %s""
19message_too_long  = ""File contains a line with over %(n)s characters: %%s, line %%s"" % dict(n=MAX_LINE_LENGTH)
20
21def tab_in_leading(s):
22    """""" Returns True if there are tabs in the leading whitespace of a line,
23        including the whitespace of docstring code samples.
24    """"""
25    n = len(s) - len(s.lstrip())
26    if not s[n:n + 3] in ['...', '>>>']:
27        check = s[:n]
28    else:
29        smore = s[n + 3:]
30        check = s[:n] + smore[:len(smore) - len(smore.lstrip())]
31    return check.expandtabs() != check
32
33def collect_errors():
34    errors = []
35
36    def test_this_file(fname, test_file):
37        line = None
38
39        for idx, line in enumerate(test_file):
40            line = line.decode('utf-8')
41            line_no = idx + 1
42
43            if idx == 0 and len(line.strip()) == 0:
44                errors.append((message_multi_bof, fname, line_no))
45            if line.endswith("" \n"") or line.endswith(""\t\n""):
46                errors.append((message_space, fname, line_no))
47            if line.endswith(""\r\n"") or line.endswith(""\r""):
48                errors.append((message_carriage, fname, line_no))
49            if tab_in_leading(line):
50                errors.append((message_tabs, fname, line_no))
51            #if len(line) > MAX_LINE_LENGTH:
52            #    errors.append((message_too_long, fname, line_no))
53
54        if line is not None:
55            if idx > 0 and len(line.strip()) == 0:
56                errors.append((message_multi_eof, fname, line_no))
57            if not line.endswith('\n'):
58                errors.append((message_eof, fname, line_no))
59
60    def test(fname):
61        with open(fname, ""Urb"") as test_file:
62            test_this_file(fname, test_file)
63
64    def canonicalize(path):
65        return path.replace('/', sep)
66
67    def check_tree(base_path, patterns, dir_exclusions=None, file_exclusions=None):
68        dir_exclusions = dir_exclusions or []
69        file_exclusions = file_exclusions or []
70        base_path = join(TOP_PATH, canonicalize(base_path))
71        dir_exclusions = set([ join(base_path, canonicalize(path)) for path in dir_exclusions ])
72
73        for root, dirs, _ in walk(base_path):
74            if root in dir_exclusions:
75                del dirs[:]
76                continue
77
78            for pattern in patterns:
79                files = glob(join(root, pattern))
80                check_files(files, file_exclusions)
81
82    def check_files(files, file_exclusions=None):
83        file_exclusions = file_exclusions or []
84        for fname in files:
85            if not isabs(fname):
86                fname = join(TOP_PATH, fname)
87
88            if not exists(fname) or not isfile(fname):
89                continue
90
91            if basename(fname) in file_exclusions:
92                continue
93
94            test(fname)
95
96    check_files([""setup.py""])
97    check_tree('bin',          ['*'])
98    check_tree('bokeh',        ['*.py', '*.html', '*.js'], [""server/static""], [""__conda_version__.py""])
99    check_tree('bokehjs',      ['*.coffee', '*.js', '*.ts', '*.less', '*.css', '*.json'], ['build', 'node_modules', 'src/vendor', 'typings'])
100    check_tree('conda.recipe', ['*.py', '*.sh', '*.yaml'])
101    check_tree('examples',     ['*.py', '*.ipynb'])
102    check_tree('scripts',      ['*.py', '*.sh'])
103    check_tree('sphinx',       ['*.rst', '*.py'], ['_build', 'source/docs/gallery'])
104    check_tree('tests',        ['*.py', '*.js'])
105
106    return errors
107
108def bad_files():
109    return "" "".join(sorted(set([ file for (_, file, _) in collect_errors() ])))
110
111@pytest.mark.quality
112def test_files():
113    def format_message(msg, fname, line_no):
114        return msg % (relpath(fname, TOP_PATH), line_no)
115
116    errors = [ format_message(*args) for args in collect_errors() ]
117
118
119if __name__ == ""__main__"":
120    test_files()
121",6438,"[[21, 's', '!=', None, 'Function tab_in_leading takes non-null string input'],
 [25, 's', '!=', '', 's should be non-empty to calculate leading whitespaces in s'],
 [34, 'errors', '==', [], 'Initial errors list should be empty'],
 [37, 'fname', '!=', None, 'Filenames should be non-null for testing file quality'],
 [37, 'test_file', '!=', None, 'Test_file should be non-null for testing file quality'],
 [40, 'line', '!=', None, 'read lines should be non-null to process'],
 [54, 'line', '!=', None, 'Last line should be non-null to process'],
 [60, 'fname', '!=', None, 'Filenames should be non-null for testing file quality'],
 [67, 'base_path', '!=', None, 'base_path should be non-null to check quality in a tree'],
 [67, 'patterns', '!=', [], 'Patterns should be non-empty to check files for quality'],
 [68, 'dir_exclusions', '!=', [], 'dir_exclusions should not be None to exclude directories in quality check'],
 [69, 'file_exclusions', '!=', [], 'file_exclusions should not be None to exclude files in quality check'],
 [83, 'files', '!=', [], 'Files list should be non-empty to check files for quality'],
 [89, 'fname', '!=', None, 'Filenames should be non-null for testing file quality'],
 [114, 'msg', '!=', None, 'Error messages should be non-null for formatting'],
 [114, 'fname', '!=', None, 'Filenames should be non-null for error formatting'],
 [114, 'line_no', '>=', 1, 'line_no should be greater than or equal to 1']]"
dr-bigfatnoob/quirk,"from __future__ import print_function, division
import sys
import os
sys.path.append(os.path.abspath("".""))
sys.dont_write_bytecode = True

__author__ = ""bigfatnoob""

import matplotlib.pyplot as plt
import matplotlib.lines as mlines
from utils.lib import mkdir


def plot_pareto(generations, colors, markers, labels, x_label, y_label, title, fig_name):
  assert len(generations) == len(colors) == len(markers) == len(labels)
  for i in xrange(len(generations)):
    gen = generations[i]
    x_axis, y_axis = [], []
    for j in xrange(len(gen)):
       x_axis.append(gen[j][0])
       y_axis.append(gen[j][1])
    plt.plot(x_axis, y_axis, color=colors[i], marker=markers[i], label=labels[i], linestyle='')
  plt.xlabel(x_label)
  plt.ylabel(y_label)
  plt.title(title)
  directory = fig_name.rsplit(""/"", 1)[0]
  mkdir(directory)
  plt.savefig(fig_name, bbox_inches='tight')


def med_spread_plot(data, obj_names, fig_name=""temp.png""):
  fig = plt.figure(1)
  fig.subplots_adjust(hspace=0.5)
  directory = fig_name.rsplit(""/"", 1)[0]
  mkdir(directory)
  for i, (key, data_map) in enumerate(data.items()):
    meds = data_map[""meds""]
    iqrs = data_map.get(""iqrs"", None)
    if iqrs:
      x = range(len(meds))
      index = int(str(len(data)) + ""1"" + str(i + 1))
      plt.subplot(index)
      plt.title(obj_names[key])
      plt.plot(x, meds, 'b-', x, iqrs, 'r-')
      # plt.ylim((min(iqrs) - 1, max(meds) + 1))
    else:
      x = range(len(meds))
      index = int(str(len(data)) + ""1"" + str(i + 1))
      plt.subplot(index)
      plt.title(obj_names[key])
      plt.plot(x, meds, 'b-')
      # plt.ylim((min(meds) - 1, max(meds) + 1))
  blue_line = mlines.Line2D([], [], color='blue', label='Median')
  red_line = mlines.Line2D([], [], color='red', label='IQR')
  plt.figlegend((blue_line, red_line), ('Median', 'IQR'), loc=9, bbox_to_anchor=(0.5, 0.075), ncol=2)
  plt.savefig(fig_name, bbox_inches='tight')
  plt.clf()
","
1from __future__ import print_function, division
2import sys
3import os
4sys.path.append(os.path.abspath("".""))
5sys.dont_write_bytecode = True
6
7__author__ = ""bigfatnoob""
8
9import matplotlib.pyplot as plt
10import matplotlib.lines as mlines
11from utils.lib import mkdir
12
13
14def plot_pareto(generations, colors, markers, labels, x_label, y_label, title, fig_name):
15  for i in xrange(len(generations)):
16    gen = generations[i]
17    x_axis, y_axis = [], []
18    for j in xrange(len(gen)):
19       x_axis.append(gen[j][0])
20       y_axis.append(gen[j][1])
21    plt.plot(x_axis, y_axis, color=colors[i], marker=markers[i], label=labels[i], linestyle='')
22  plt.xlabel(x_label)
23  plt.ylabel(y_label)
24  plt.title(title)
25  directory = fig_name.rsplit(""/"", 1)[0]
26  mkdir(directory)
27  plt.savefig(fig_name, bbox_inches='tight')
28
29
30def med_spread_plot(data, obj_names, fig_name=""temp.png""):
31  fig = plt.figure(1)
32  fig.subplots_adjust(hspace=0.5)
33  directory = fig_name.rsplit(""/"", 1)[0]
34  mkdir(directory)
35  for i, (key, data_map) in enumerate(data.items()):
36    meds = data_map[""meds""]
37    iqrs = data_map.get(""iqrs"", None)
38    if iqrs:
39      x = range(len(meds))
40      index = int(str(len(data)) + ""1"" + str(i + 1))
41      plt.subplot(index)
42      plt.title(obj_names[key])
43      plt.plot(x, meds, 'b-', x, iqrs, 'r-')
44      # plt.ylim((min(iqrs) - 1, max(meds) + 1))
45    else:
46      x = range(len(meds))
47      index = int(str(len(data)) + ""1"" + str(i + 1))
48      plt.subplot(index)
49      plt.title(obj_names[key])
50      plt.plot(x, meds, 'b-')
51      # plt.ylim((min(meds) - 1, max(meds) + 1))
52  blue_line = mlines.Line2D([], [], color='blue', label='Median')
53  red_line = mlines.Line2D([], [], color='red', label='IQR')
54  plt.figlegend((blue_line, red_line), ('Median', 'IQR'), loc=9, bbox_to_anchor=(0.5, 0.075), ncol=2)
55  plt.savefig(fig_name, bbox_inches='tight')
56  plt.clf()
57","[['len(generations)', '==', 'len(colors) == len(markers) == len(labels)']]",1,1,1.0,0.0005194805194805,"['sys.dont_write_bytecode', '__author__', 'generations', 'colors', 'markers', 'labels', 'x_label', 'y_label', 'title', 'fig_name', 'gen', 'x_axis', 'y_axis', 'directory', 'data', 'obj_names', 'fig', 'meds', 'iqrs', 'x', 'index', 'blue_line', 'red_line']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['sys.dont_write_bytecode', '__author__', 'generations', 'colors', 'markers', 'labels', 'x_label', 'y_label', 'title', 'fig_name', 'gen', 'x_axis', 'y_axis', 'directory', 'data', 'obj_names', 'fig', 'meds', 'iqrs', 'x', 'index', 'blue_line', 'red_line']
*Code:

1from __future__ import print_function, division
2import sys
3import os
4sys.path.append(os.path.abspath("".""))
5sys.dont_write_bytecode = True
6
7__author__ = ""bigfatnoob""
8
9import matplotlib.pyplot as plt
10import matplotlib.lines as mlines
11from utils.lib import mkdir
12
13
14def plot_pareto(generations, colors, markers, labels, x_label, y_label, title, fig_name):
15  for i in xrange(len(generations)):
16    gen = generations[i]
17    x_axis, y_axis = [], []
18    for j in xrange(len(gen)):
19       x_axis.append(gen[j][0])
20       y_axis.append(gen[j][1])
21    plt.plot(x_axis, y_axis, color=colors[i], marker=markers[i], label=labels[i], linestyle='')
22  plt.xlabel(x_label)
23  plt.ylabel(y_label)
24  plt.title(title)
25  directory = fig_name.rsplit(""/"", 1)[0]
26  mkdir(directory)
27  plt.savefig(fig_name, bbox_inches='tight')
28
29
30def med_spread_plot(data, obj_names, fig_name=""temp.png""):
31  fig = plt.figure(1)
32  fig.subplots_adjust(hspace=0.5)
33  directory = fig_name.rsplit(""/"", 1)[0]
34  mkdir(directory)
35  for i, (key, data_map) in enumerate(data.items()):
36    meds = data_map[""meds""]
37    iqrs = data_map.get(""iqrs"", None)
38    if iqrs:
39      x = range(len(meds))
40      index = int(str(len(data)) + ""1"" + str(i + 1))
41      plt.subplot(index)
42      plt.title(obj_names[key])
43      plt.plot(x, meds, 'b-', x, iqrs, 'r-')
44      # plt.ylim((min(iqrs) - 1, max(meds) + 1))
45    else:
46      x = range(len(meds))
47      index = int(str(len(data)) + ""1"" + str(i + 1))
48      plt.subplot(index)
49      plt.title(obj_names[key])
50      plt.plot(x, meds, 'b-')
51      # plt.ylim((min(meds) - 1, max(meds) + 1))
52  blue_line = mlines.Line2D([], [], color='blue', label='Median')
53  red_line = mlines.Line2D([], [], color='red', label='IQR')
54  plt.figlegend((blue_line, red_line), ('Median', 'IQR'), loc=9, bbox_to_anchor=(0.5, 0.075), ncol=2)
55  plt.savefig(fig_name, bbox_inches='tight')
56  plt.clf()
57",3592,"[[14, 'generations', '!=', None, ""Generations cannot be None""],
[14, 'colors', '!=', None, ""Colors cannot be None""],
[14, 'markers', '!=', None, ""Markers cannot be None""],
[14, 'labels', '!=', None, ""Labels cannot be None""],
[14, 'x_label', '!=', None, ""X_Label cannot be None""],
[14, 'y_label', '!=', None, ""Y_Label cannot be None""],
[14, 'title', '!=', None, ""Title cannot be None""],
[14, 'fig_name', '!=', None, ""Fig_name cannot be None""],
[30, 'data', '!=', None, ""Data cannot be None""],
[30, 'obj_names', '!=', None, ""Obj_names cannot be None""]]"
barykaed/Pelican-Test,"""""""develop tests
""""""
import os
import types

import pytest

import pkg_resources
import setuptools.sandbox
from setuptools.sandbox import DirectorySandbox, SandboxViolation


class TestSandbox:

    def test_devnull(self, tmpdir):
        sandbox = DirectorySandbox(str(tmpdir))
        sandbox.run(self._file_writer(os.devnull))

    @staticmethod
    def _file_writer(path):
        def do_write():
            with open(path, 'w') as f:
                f.write('xxx')
        return do_write

    def test_win32com(self, tmpdir):
        """"""
        win32com should not be prevented from caching COM interfaces
        in gen_py.
        """"""
        win32com = pytest.importorskip('win32com')
        gen_py = win32com.__gen_path__
        target = os.path.join(gen_py, 'test_write')
        sandbox = DirectorySandbox(str(tmpdir))
        try:
            try:
                sandbox.run(self._file_writer(target))
            except SandboxViolation:
                self.fail(""Could not create gen_py file due to SandboxViolation"")
        finally:
            if os.path.exists(target):
                os.remove(target)

    def test_setup_py_with_BOM(self):
        """"""
        It should be possible to execute a setup.py with a Byte Order Mark
        """"""
        target = pkg_resources.resource_filename(__name__,
            'script-with-bom.py')
        namespace = types.ModuleType('namespace')
        setuptools.sandbox._execfile(target, vars(namespace))
        assert namespace.result == 'passed'

    def test_setup_py_with_CRLF(self, tmpdir):
        setup_py = tmpdir / 'setup.py'
        with setup_py.open('wb') as stream:
            stream.write(b'""degenerate script""\r\n')
        setuptools.sandbox._execfile(str(setup_py), globals())
","
1""""""develop tests
2""""""
3import os
4import types
5
6import pytest
7
8import pkg_resources
9import setuptools.sandbox
10from setuptools.sandbox import DirectorySandbox, SandboxViolation
11
12
13class TestSandbox:
14
15    def test_devnull(self, tmpdir):
16        sandbox = DirectorySandbox(str(tmpdir))
17        sandbox.run(self._file_writer(os.devnull))
18
19    @staticmethod
20    def _file_writer(path):
21        def do_write():
22            with open(path, 'w') as f:
23                f.write('xxx')
24        return do_write
25
26    def test_win32com(self, tmpdir):
27        """"""
28        win32com should not be prevented from caching COM interfaces
29        in gen_py.
30        """"""
31        win32com = pytest.importorskip('win32com')
32        gen_py = win32com.__gen_path__
33        target = os.path.join(gen_py, 'test_write')
34        sandbox = DirectorySandbox(str(tmpdir))
35        try:
36            try:
37                sandbox.run(self._file_writer(target))
38            except SandboxViolation:
39                self.fail(""Could not create gen_py file due to SandboxViolation"")
40        finally:
41            if os.path.exists(target):
42                os.remove(target)
43
44    def test_setup_py_with_BOM(self):
45        """"""
46        It should be possible to execute a setup.py with a Byte Order Mark
47        """"""
48        target = pkg_resources.resource_filename(__name__,
49            'script-with-bom.py')
50        namespace = types.ModuleType('namespace')
51        setuptools.sandbox._execfile(target, vars(namespace))
52
53    def test_setup_py_with_CRLF(self, tmpdir):
54        setup_py = tmpdir / 'setup.py'
55        with setup_py.open('wb') as stream:
56            stream.write(b'""degenerate script""\r\n')
57        setuptools.sandbox._execfile(str(setup_py), globals())
58","[['namespace.result', '==', ""'passed'""]]",1,1,1.0,0.0005672149744753,"['tmpdir', 'sandbox', 'path', 'win32com', 'gen_py', 'target', 'namespace', 'setup_py']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tmpdir', 'sandbox', 'path', 'win32com', 'gen_py', 'target', 'namespace', 'setup_py']
*Code:

1""""""develop tests
2""""""
3import os
4import types
5
6import pytest
7
8import pkg_resources
9import setuptools.sandbox
10from setuptools.sandbox import DirectorySandbox, SandboxViolation
11
12
13class TestSandbox:
14
15    def test_devnull(self, tmpdir):
16        sandbox = DirectorySandbox(str(tmpdir))
17        sandbox.run(self._file_writer(os.devnull))
18
19    @staticmethod
20    def _file_writer(path):
21        def do_write():
22            with open(path, 'w') as f:
23                f.write('xxx')
24        return do_write
25
26    def test_win32com(self, tmpdir):
27        """"""
28        win32com should not be prevented from caching COM interfaces
29        in gen_py.
30        """"""
31        win32com = pytest.importorskip('win32com')
32        gen_py = win32com.__gen_path__
33        target = os.path.join(gen_py, 'test_write')
34        sandbox = DirectorySandbox(str(tmpdir))
35        try:
36            try:
37                sandbox.run(self._file_writer(target))
38            except SandboxViolation:
39                self.fail(""Could not create gen_py file due to SandboxViolation"")
40        finally:
41            if os.path.exists(target):
42                os.remove(target)
43
44    def test_setup_py_with_BOM(self):
45        """"""
46        It should be possible to execute a setup.py with a Byte Order Mark
47        """"""
48        target = pkg_resources.resource_filename(__name__,
49            'script-with-bom.py')
50        namespace = types.ModuleType('namespace')
51        setuptools.sandbox._execfile(target, vars(namespace))
52
53    def test_setup_py_with_CRLF(self, tmpdir):
54        setup_py = tmpdir / 'setup.py'
55        with setup_py.open('wb') as stream:
56            stream.write(b'""degenerate script""\r\n')
57        setuptools.sandbox._execfile(str(setup_py), globals())
58",3293,"[[15, 'tmpdir', '!=', None, 'tmpdir must be defined in order to be used as a sandbox directory'],
[26, 'tmpdir', '!=', None, 'tmpdir must be defined in order to be used as a sandbox directory'],
[32, 'win32com', '!=', None, 'win32com should be importable to write COM interfaces in gen_py'],
[33, 'gen_py', '!=', None, 'gen_py should be defined to store the path of COM interfaces'],
[34, 'tmpdir', '!=', None, 'tmpdir must be defined in order to be used as a sandbox directory'],
[53, 'tmpdir', '!=', None, 'tmpdir must be defined to use as the location for setup.py'],
[54, 'setup_py', '!=', None, 'setup_py must be defined to use as the script file']]"
xupingmao/xnote,"# -*- coding:utf-8 -*-
""""""
@Author       : xupingmao
@email        : 578749341@qq.com
@Date         : 2022-05-14 14:53:37
@LastEditors  : xupingmao
@LastEditTime : 2022-05-17 23:05:24
@FilePath     : /xnote/xutils/db/shard.py
@Description  : 数据库分片
""""""

import json
from xutils import netutil

# 多路读取分页实现


class ShardCursor:
    """"""分片游标，负责从固定的一个分片读写数据""""""

    def __init__(self, url, params):
        self.url = url
        self._has_next = True
        self.data = []
        self.params = params
        self.offset = 0
        self.limit = 20
        self._debug = False

    def set_debug(self, debug):
        self._debug = debug

    def has_next(self):
        return self._has_next

    def first(self):
        assert len(self.data) > 0, ""Must call after check cursor.has_next()""
        return self.data[0]

    def next(self):
        assert len(self.data) > 0
        self.data = self.data[1:]

    def check_and_read(self):
        if not self._has_next:
            return
        if len(self.data) > 0:
            return
        self.data = self._read_from_server()
        if len(self.data) == 0:
            self._has_next = False

    def _read_from_server(self):
        """"""从服务器读取数据
        TODO: 这个可以做成异步的，在wait_read_done里面等待异步完成，这样多个分片就可以并行查询""""""
        params = dict(
            offset=self.offset,
            limit=self.limit,
            data=self.params,
        )

        raw_data = netutil.http_post(self.url, body=json.dumps(params))
        result = json.loads(raw_data)
        if result.get(""code"") == 0:
            data = result.get(""data"")
            if self._debug:
                print(""url:"", self.url, ""data:"", data)
            self.offset += len(data)
            return data
        print(""read failed:"", result)
        raise Exception(""read failed, code:%s"" % result.get(""code""))

    def wait_read_done(self):
        pass


class ShardManager:
    """"""分片管理器，负责从多个分片读写数据""""""

    def __init__(self):
        self.shards = []
        self._debug = False

    def add_shard(self, url):
        self.shards.append(url)

    def set_debug(self, debug):
        self._debug = debug

    def has_next(self, cursors):
        for cursor in cursors:
            if cursor.has_next():
                return True
        return False

    def check_and_read(self, cursors):
        for cursor in cursors:
            assert isinstance(cursor, ShardCursor)
            cursor.check_and_read()

        for cursor in cursors:
            assert isinstance(cursor, ShardCursor)
            cursor.wait_read_done()

    def read_min_value(self, cursors):
        min_value = None
        min_cursor = None

        for cursor in cursors:
            assert isinstance(cursor, ShardCursor)

            if not cursor.has_next():
                continue

            value = cursor.first()
            assert value != None

            if min_value == None:
                min_value = value
                min_cursor = cursor
            elif value[""key""] < min_value[""key""]:
                min_value = value
                min_cursor = cursor

        if min_cursor != None:
            min_cursor.next()

        return min_value

    def query_page(self, page_no, page_size, params):
        assert len(self.shards) > 0, ""No available shards""
        assert isinstance(params, dict), ""Params must be dict""

        cursors = []
        for shard in self.shards:
            cursor = ShardCursor(shard, params)
            if self._debug:
                cursor.set_debug(True)
            cursors.append(cursor)

        page = 1
        while page <= page_no:
            data = []
            while len(data) < page_size:
                self.check_and_read(cursors)

                if not self.has_next(cursors):
                    return data

                min_value = self.read_min_value(cursors)
                assert min_value != None
                data.append(min_value)

            if page == page_no:
                return data
            page += 1
    
    def get_by_key(self, key):
        raise NotImplementedError(""待实现"")
    
    def put_by_key(self, key, value):
        raise NotImplementedError(""待实现"")
    
    def delete_by_key(self, key):
        raise NotImplementedError(""待实现"")
","
1# -*- coding:utf-8 -*-
2""""""
3@Author       : xupingmao
4@email        : 578749341@qq.com
5@Date         : 2022-05-14 14:53:37
6@LastEditors  : xupingmao
7@LastEditTime : 2022-05-17 23:05:24
8@FilePath     : /xnote/xutils/db/shard.py
9@Description  : 数据库分片
10""""""
11
12import json
13from xutils import netutil
14
15# 多路读取分页实现
16
17
18class ShardCursor:
19    """"""分片游标，负责从固定的一个分片读写数据""""""
20
21    def __init__(self, url, params):
22        self.url = url
23        self._has_next = True
24        self.data = []
25        self.params = params
26        self.offset = 0
27        self.limit = 20
28        self._debug = False
29
30    def set_debug(self, debug):
31        self._debug = debug
32
33    def has_next(self):
34        return self._has_next
35
36    def first(self):
37        return self.data[0]
38
39    def next(self):
40        self.data = self.data[1:]
41
42    def check_and_read(self):
43        if not self._has_next:
44            return
45        if len(self.data) > 0:
46            return
47        self.data = self._read_from_server()
48        if len(self.data) == 0:
49            self._has_next = False
50
51    def _read_from_server(self):
52        """"""从服务器读取数据
53        TODO: 这个可以做成异步的，在wait_read_done里面等待异步完成，这样多个分片就可以并行查询""""""
54        params = dict(
55            offset=self.offset,
56            limit=self.limit,
57            data=self.params,
58        )
59
60        raw_data = netutil.http_post(self.url, body=json.dumps(params))
61        result = json.loads(raw_data)
62        if result.get(""code"") == 0:
63            data = result.get(""data"")
64            if self._debug:
65                print(""url:"", self.url, ""data:"", data)
66            self.offset += len(data)
67            return data
68        print(""read failed:"", result)
69        raise Exception(""read failed, code:%s"" % result.get(""code""))
70
71    def wait_read_done(self):
72        pass
73
74
75class ShardManager:
76    """"""分片管理器，负责从多个分片读写数据""""""
77
78    def __init__(self):
79        self.shards = []
80        self._debug = False
81
82    def add_shard(self, url):
83        self.shards.append(url)
84
85    def set_debug(self, debug):
86        self._debug = debug
87
88    def has_next(self, cursors):
89        for cursor in cursors:
90            if cursor.has_next():
91                return True
92        return False
93
94    def check_and_read(self, cursors):
95        for cursor in cursors:
96            cursor.check_and_read()
97
98        for cursor in cursors:
99            cursor.wait_read_done()
100
101    def read_min_value(self, cursors):
102        min_value = None
103        min_cursor = None
104
105        for cursor in cursors:
106
107            if not cursor.has_next():
108                continue
109
110            value = cursor.first()
111
112            if min_value == None:
113                min_value = value
114                min_cursor = cursor
115            elif value[""key""] < min_value[""key""]:
116                min_value = value
117                min_cursor = cursor
118
119        if min_cursor != None:
120            min_cursor.next()
121
122        return min_value
123
124    def query_page(self, page_no, page_size, params):
125
126        cursors = []
127        for shard in self.shards:
128            cursor = ShardCursor(shard, params)
129            if self._debug:
130                cursor.set_debug(True)
131            cursors.append(cursor)
132
133        page = 1
134        while page <= page_no:
135            data = []
136            while len(data) < page_size:
137                self.check_and_read(cursors)
138
139                if not self.has_next(cursors):
140                    return data
141
142                min_value = self.read_min_value(cursors)
143                data.append(min_value)
144
145            if page == page_no:
146                return data
147            page += 1
148    
149    def get_by_key(self, key):
150        raise NotImplementedError(""待实现"")
151    
152    def put_by_key(self, key, value):
153        raise NotImplementedError(""待实现"")
154    
155    def delete_by_key(self, key):
156        raise NotImplementedError(""待实现"")
157","[['len(self.data)', '>', '0'], ['len(self.data)', '>', '0'], ['value', '!=', 'None'], ['len(self.shards)', '>', '0'], ['min_value', '!=', 'None']]",9,5,0.5555555555555556,0.001175917215428,"['url', 'params', 'self.url', 'self._has_next', 'self.data', 'self.params', 'self.offset', 'self.limit', 'self._debug', 'debug', 'raw_data', 'result', 'data', 'self.shards', 'cursors', 'min_value', 'min_cursor', 'value', 'page_no', 'page_size', 'cursor', 'page', 'key']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['url', 'params', 'self.url', 'self._has_next', 'self.data', 'self.params', 'self.offset', 'self.limit', 'self._debug', 'debug', 'raw_data', 'result', 'data', 'self.shards', 'cursors', 'min_value', 'min_cursor', 'value', 'page_no', 'page_size', 'cursor', 'page', 'key']
*Code:

1# -*- coding:utf-8 -*-
2""""""
3@Author       : xupingmao
4@email        : 578749341@qq.com
5@Date         : 2022-05-14 14:53:37
6@LastEditors  : xupingmao
7@LastEditTime : 2022-05-17 23:05:24
8@FilePath     : /xnote/xutils/db/shard.py
9@Description  : 数据库分片
10""""""
11
12import json
13from xutils import netutil
14
15# 多路读取分页实现
16
17
18class ShardCursor:
19    """"""分片游标，负责从固定的一个分片读写数据""""""
20
21    def __init__(self, url, params):
22        self.url = url
23        self._has_next = True
24        self.data = []
25        self.params = params
26        self.offset = 0
27        self.limit = 20
28        self._debug = False
29
30    def set_debug(self, debug):
31        self._debug = debug
32
33    def has_next(self):
34        return self._has_next
35
36    def first(self):
37        return self.data[0]
38
39    def next(self):
40        self.data = self.data[1:]
41
42    def check_and_read(self):
43        if not self._has_next:
44            return
45        if len(self.data) > 0:
46            return
47        self.data = self._read_from_server()
48        if len(self.data) == 0:
49            self._has_next = False
50
51    def _read_from_server(self):
52        """"""从服务器读取数据
53        TODO: 这个可以做成异步的，在wait_read_done里面等待异步完成，这样多个分片就可以并行查询""""""
54        params = dict(
55            offset=self.offset,
56            limit=self.limit,
57            data=self.params,
58        )
59
60        raw_data = netutil.http_post(self.url, body=json.dumps(params))
61        result = json.loads(raw_data)
62        if result.get(""code"") == 0:
63            data = result.get(""data"")
64            if self._debug:
65                print(""url:"", self.url, ""data:"", data)
66            self.offset += len(data)
67            return data
68        print(""read failed:"", result)
69        raise Exception(""read failed, code:%s"" % result.get(""code""))
70
71    def wait_read_done(self):
72        pass
73
74
75class ShardManager:
76    """"""分片管理器，负责从多个分片读写数据""""""
77
78    def __init__(self):
79        self.shards = []
80        self._debug = False
81
82    def add_shard(self, url):
83        self.shards.append(url)
84
85    def set_debug(self, debug):
86        self._debug = debug
87
88    def has_next(self, cursors):
89        for cursor in cursors:
90            if cursor.has_next():
91                return True
92        return False
93
94    def check_and_read(self, cursors):
95        for cursor in cursors:
96            cursor.check_and_read()
97
98        for cursor in cursors:
99            cursor.wait_read_done()
100
101    def read_min_value(self, cursors):
102        min_value = None
103        min_cursor = None
104
105        for cursor in cursors:
106
107            if not cursor.has_next():
108                continue
109
110            value = cursor.first()
111
112            if min_value == None:
113                min_value = value
114                min_cursor = cursor
115            elif value[""key""] < min_value[""key""]:
116                min_value = value
117                min_cursor = cursor
118
119        if min_cursor != None:
120            min_cursor.next()
121
122        return min_value
123
124    def query_page(self, page_no, page_size, params):
125
126        cursors = []
127        for shard in self.shards:
128            cursor = ShardCursor(shard, params)
129            if self._debug:
130                cursor.set_debug(True)
131            cursors.append(cursor)
132
133        page = 1
134        while page <= page_no:
135            data = []
136            while len(data) < page_size:
137                self.check_and_read(cursors)
138
139                if not self.has_next(cursors):
140                    return data
141
142                min_value = self.read_min_value(cursors)
143                data.append(min_value)
144
145            if page == page_no:
146                return data
147            page += 1
148    
149    def get_by_key(self, key):
150        raise NotImplementedError(""待实现"")
151    
152    def put_by_key(self, key, value):
153        raise NotImplementedError(""待实现"")
154    
155    def delete_by_key(self, key):
156        raise NotImplementedError(""待实现"")
157",5805,"[[21, 'url', '!=', '', ""A url is necessary to make network requests""],
[21, 'params', '!=', None, ""Parameters can't be None""],
[30, 'debug', '==', bool, ""Debug should be a boolean value""],
[42, 'self.data', '>=', 0, ""The data property should always be an array, thus of length >= 0""],
[40, 'self.data', '!=', None, ""Data shouldn't be None""],
[59, 'self.offset', '>=', 0, ""Offset should be a non-negative integer""],
[59, 'self.limit', '>=', 0, ""Limit should be a non-negative integer""],
[59, 'self.params', '!=', None, ""Params can't be None""],
[63, 'data', '!=', None, ""Data from server shouldn't be None""],
[82, 'url', '!=', '', ""A url is necessary to add a shard""],
[85, 'debug', '==', bool, ""Debug should be a boolean value""],
[124, 'page_no', '>=', 1, ""pageNumber should be a positive""],
[126, 'params', '!=', None, ""Query params can't be None""],
[135, 'data', '>=', 0, ""Data list should always be at least empty""],
[142, 'min_value', '!=', None, ""Min_value can't be None""]]"
byterom/android_external_chromium_org,"# Copyright 2012 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
import os

from telemetry.page.actions import page_action


class ScrollAction(page_action.PageAction):
  # TODO(chrishenry): Ignore attributes, to be deleted when usage in
  # other repo is cleaned up.
  def __init__(self, selector=None, text=None, element_function=None,
               left_start_ratio=0.5, top_start_ratio=0.5, direction='down',
               distance=None, distance_expr=None,
               speed_in_pixels_per_second=800, use_touch=False):
    super(ScrollAction, self).__init__()
    if direction not in ['down', 'up', 'left', 'right']:
      raise page_action.PageActionNotSupported(
          'Invalid scroll direction: %s' % self.direction)
    self._selector = selector
    self._text = text
    self._element_function = element_function
    self._left_start_ratio = left_start_ratio
    self._top_start_ratio = top_start_ratio
    self._direction = direction
    self._speed = speed_in_pixels_per_second
    self._use_touch = use_touch

    self._distance_func = 'null'
    if distance:
      assert not distance_expr
      distance_expr = str(distance)
    if distance_expr:
      self._distance_func = ('function() { return 0 + %s; }' %
                             distance_expr)

  def WillRunAction(self, tab):
    for js_file in ['gesture_common.js', 'scroll.js']:
      with open(os.path.join(os.path.dirname(__file__), js_file)) as f:
        js = f.read()
        tab.ExecuteJavaScript(js)

    # Fail if browser doesn't support synthetic scroll gestures.
    if not tab.EvaluateJavaScript('window.__ScrollAction_SupportedByBrowser()'):
      raise page_action.PageActionNotSupported(
          'Synthetic scroll not supported for this browser')

    # Fail if this action requires touch and we can't send touch events.
    if self._use_touch:
      if not page_action.IsGestureSourceTypeSupported(tab, 'touch'):
        raise page_action.PageActionNotSupported(
            'Touch scroll not supported for this browser')

      if (page_action.GetGestureSourceTypeFromOptions(tab) ==
          'chrome.gpuBenchmarking.MOUSE_INPUT'):
        raise page_action.PageActionNotSupported(
            'Scroll requires touch on this page but mouse input was requested')

    done_callback = 'function() { window.__scrollActionDone = true; }'
    tab.ExecuteJavaScript(""""""
        window.__scrollActionDone = false;
        window.__scrollAction = new __ScrollAction(%s, %s);""""""
        % (done_callback, self._distance_func))

  def RunAction(self, tab):
    if (self._selector is None and self._text is None and
        self._element_function is None):
      self._element_function = 'document.body'

    gesture_source_type = page_action.GetGestureSourceTypeFromOptions(tab)
    if self._use_touch:
      gesture_source_type = 'chrome.gpuBenchmarking.TOUCH_INPUT'

    code = '''
        function(element, info) {
          if (!element) {
            throw Error('Cannot find element: ' + info);
          }
          window.__scrollAction.start({
            element: element,
            left_start_ratio: %s,
            top_start_ratio: %s,
            direction: '%s',
            speed: %s,
            gesture_source_type: %s
          });
        }''' % (self._left_start_ratio,
                self._top_start_ratio,
                self._direction,
                self._speed,
                gesture_source_type)
    page_action.EvaluateCallbackWithElement(
        tab, code, selector=self._selector, text=self._text,
        element_function=self._element_function)
    tab.WaitForJavaScriptExpression('window.__scrollActionDone', 60)
","
1# Copyright 2012 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4import os
5
6from telemetry.page.actions import page_action
7
8
9class ScrollAction(page_action.PageAction):
10  # TODO(chrishenry): Ignore attributes, to be deleted when usage in
11  # other repo is cleaned up.
12  def __init__(self, selector=None, text=None, element_function=None,
13               left_start_ratio=0.5, top_start_ratio=0.5, direction='down',
14               distance=None, distance_expr=None,
15               speed_in_pixels_per_second=800, use_touch=False):
16    super(ScrollAction, self).__init__()
17    if direction not in ['down', 'up', 'left', 'right']:
18      raise page_action.PageActionNotSupported(
19          'Invalid scroll direction: %s' % self.direction)
20    self._selector = selector
21    self._text = text
22    self._element_function = element_function
23    self._left_start_ratio = left_start_ratio
24    self._top_start_ratio = top_start_ratio
25    self._direction = direction
26    self._speed = speed_in_pixels_per_second
27    self._use_touch = use_touch
28
29    self._distance_func = 'null'
30    if distance:
31      distance_expr = str(distance)
32    if distance_expr:
33      self._distance_func = ('function() { return 0 + %s; }' %
34                             distance_expr)
35
36  def WillRunAction(self, tab):
37    for js_file in ['gesture_common.js', 'scroll.js']:
38      with open(os.path.join(os.path.dirname(__file__), js_file)) as f:
39        js = f.read()
40        tab.ExecuteJavaScript(js)
41
42    # Fail if browser doesn't support synthetic scroll gestures.
43    if not tab.EvaluateJavaScript('window.__ScrollAction_SupportedByBrowser()'):
44      raise page_action.PageActionNotSupported(
45          'Synthetic scroll not supported for this browser')
46
47    # Fail if this action requires touch and we can't send touch events.
48    if self._use_touch:
49      if not page_action.IsGestureSourceTypeSupported(tab, 'touch'):
50        raise page_action.PageActionNotSupported(
51            'Touch scroll not supported for this browser')
52
53      if (page_action.GetGestureSourceTypeFromOptions(tab) ==
54          'chrome.gpuBenchmarking.MOUSE_INPUT'):
55        raise page_action.PageActionNotSupported(
56            'Scroll requires touch on this page but mouse input was requested')
57
58    done_callback = 'function() { window.__scrollActionDone = true; }'
59    tab.ExecuteJavaScript(""""""
60        window.__scrollActionDone = false;
61        window.__scrollAction = new __ScrollAction(%s, %s);""""""
62        % (done_callback, self._distance_func))
63
64  def RunAction(self, tab):
65    if (self._selector is None and self._text is None and
66        self._element_function is None):
67      self._element_function = 'document.body'
68
69    gesture_source_type = page_action.GetGestureSourceTypeFromOptions(tab)
70    if self._use_touch:
71      gesture_source_type = 'chrome.gpuBenchmarking.TOUCH_INPUT'
72
73    code = '''
74        function(element, info) {
75          if (!element) {
76            throw Error('Cannot find element: ' + info);
77          }
78          window.__scrollAction.start({
79            element: element,
80            left_start_ratio: %s,
81            top_start_ratio: %s,
82            direction: '%s',
83            speed: %s,
84            gesture_source_type: %s
85          });
86        }''' % (self._left_start_ratio,
87                self._top_start_ratio,
88                self._direction,
89                self._speed,
90                gesture_source_type)
91    page_action.EvaluateCallbackWithElement(
92        tab, code, selector=self._selector, text=self._text,
93        element_function=self._element_function)
94    tab.WaitForJavaScriptExpression('window.__scrollActionDone', 60)
95","[['distance_expr', '==', 'False']]",1,1,1.0,0.0002668801708033,"['selector', 'text', 'element_function', 'self._selector', 'self._text', 'self._element_function', 'self._left_start_ratio', 'self._top_start_ratio', 'self._direction', 'self._speed', 'self._use_touch', 'self._distance_func', 'distance_expr', 'tab', 'js', 'done_callback', 'window.__scrollActionDone', 'window.__scrollAction', 'gesture_source_type', 'code']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['selector', 'text', 'element_function', 'self._selector', 'self._text', 'self._element_function', 'self._left_start_ratio', 'self._top_start_ratio', 'self._direction', 'self._speed', 'self._use_touch', 'self._distance_func', 'distance_expr', 'tab', 'js', 'done_callback', 'window.__scrollActionDone', 'window.__scrollAction', 'gesture_source_type', 'code']
*Code:

1# Copyright 2012 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4import os
5
6from telemetry.page.actions import page_action
7
8
9class ScrollAction(page_action.PageAction):
10  # TODO(chrishenry): Ignore attributes, to be deleted when usage in
11  # other repo is cleaned up.
12  def __init__(self, selector=None, text=None, element_function=None,
13               left_start_ratio=0.5, top_start_ratio=0.5, direction='down',
14               distance=None, distance_expr=None,
15               speed_in_pixels_per_second=800, use_touch=False):
16    super(ScrollAction, self).__init__()
17    if direction not in ['down', 'up', 'left', 'right']:
18      raise page_action.PageActionNotSupported(
19          'Invalid scroll direction: %s' % self.direction)
20    self._selector = selector
21    self._text = text
22    self._element_function = element_function
23    self._left_start_ratio = left_start_ratio
24    self._top_start_ratio = top_start_ratio
25    self._direction = direction
26    self._speed = speed_in_pixels_per_second
27    self._use_touch = use_touch
28
29    self._distance_func = 'null'
30    if distance:
31      distance_expr = str(distance)
32    if distance_expr:
33      self._distance_func = ('function() { return 0 + %s; }' %
34                             distance_expr)
35
36  def WillRunAction(self, tab):
37    for js_file in ['gesture_common.js', 'scroll.js']:
38      with open(os.path.join(os.path.dirname(__file__), js_file)) as f:
39        js = f.read()
40        tab.ExecuteJavaScript(js)
41
42    # Fail if browser doesn't support synthetic scroll gestures.
43    if not tab.EvaluateJavaScript('window.__ScrollAction_SupportedByBrowser()'):
44      raise page_action.PageActionNotSupported(
45          'Synthetic scroll not supported for this browser')
46
47    # Fail if this action requires touch and we can't send touch events.
48    if self._use_touch:
49      if not page_action.IsGestureSourceTypeSupported(tab, 'touch'):
50        raise page_action.PageActionNotSupported(
51            'Touch scroll not supported for this browser')
52
53      if (page_action.GetGestureSourceTypeFromOptions(tab) ==
54          'chrome.gpuBenchmarking.MOUSE_INPUT'):
55        raise page_action.PageActionNotSupported(
56            'Scroll requires touch on this page but mouse input was requested')
57
58    done_callback = 'function() { window.__scrollActionDone = true; }'
59    tab.ExecuteJavaScript(""""""
60        window.__scrollActionDone = false;
61        window.__scrollAction = new __ScrollAction(%s, %s);""""""
62        % (done_callback, self._distance_func))
63
64  def RunAction(self, tab):
65    if (self._selector is None and self._text is None and
66        self._element_function is None):
67      self._element_function = 'document.body'
68
69    gesture_source_type = page_action.GetGestureSourceTypeFromOptions(tab)
70    if self._use_touch:
71      gesture_source_type = 'chrome.gpuBenchmarking.TOUCH_INPUT'
72
73    code = '''
74        function(element, info) {
75          if (!element) {
76            throw Error('Cannot find element: ' + info);
77          }
78          window.__scrollAction.start({
79            element: element,
80            left_start_ratio: %s,
81            top_start_ratio: %s,
82            direction: '%s',
83            speed: %s,
84            gesture_source_type: %s
85          });
86        }''' % (self._left_start_ratio,
87                self._top_start_ratio,
88                self._direction,
89                self._speed,
90                gesture_source_type)
91    page_action.EvaluateCallbackWithElement(
92        tab, code, selector=self._selector, text=self._text,
93        element_function=self._element_function)
94    tab.WaitForJavaScriptExpression('window.__scrollActionDone', 60)
95",5635,"[[12, 'selector', '==', None, ""assert that 'selector' is None by default""],
[12, 'text', '==', None, ""assert that 'text' is None by default""],
[12, 'element_function', '==', None, ""assert that 'element_function' is None by default""],
[13, 'left_start_ratio', '==', 0.5, ""assert that 'left_start_ratio' is 0.5 by default""],
[13, 'top_start_ratio', '==', 0.5, ""assert that 'top_start_ratio' is 0.5 by default""],
[13, 'direction', '==', 'down', ""assert that 'direction' is 'down' by default""],
[14, 'distance', '==', None, ""assert that 'distance' is None by default""],
[14, 'distance_expr', '==', None, ""assert that 'distance_expr' is None by default""],
[15, 'speed_in_pixels_per_second', '==', 800, ""assert that 'speed_in_pixels_per_second' is 800 by default""],
[15, 'use_touch', '==', False, ""assert that 'use_touch' is False by default""],
[36, 'tab', '!=', None, ""assert that the 'tab' parameter is not None, it is necessary for the action to take place""],
[64, 'tab', '!=', None, ""assert that the 'tab' parameter is not None, it is necessary for the action to take place""]]"
mrocklin/distributed,"from mock import Mock

from tornado import gen
from tornado.ioloop import IOLoop
from distributed.submit import RemoteClient, _submit, _remote
from distributed.utils_test import (  # noqa: F401
    valid_python_script,
    invalid_python_script,
    loop,
)


def test_dask_submit_cli_writes_result_to_stdout(loop, tmpdir, valid_python_script):
    @gen.coroutine
    def test():
        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
        yield remote_client._start()

        out, err = yield _submit(
            ""127.0.0.1:{0}"".format(remote_client.port), str(valid_python_script)
        )
        assert b""hello world!"" in out
        yield remote_client._close()

    loop.run_sync(test, timeout=5)


def test_dask_submit_cli_writes_traceback_to_stdout(
    loop, tmpdir, invalid_python_script
):
    @gen.coroutine
    def test():
        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
        yield remote_client._start()

        out, err = yield _submit(
            ""127.0.0.1:{0}"".format(remote_client.port), str(invalid_python_script)
        )
        assert b""Traceback"" in err
        yield remote_client._close()

    loop.run_sync(test, timeout=5)


def test_cli_runs_remote_client():
    mock_remote_client = Mock(spec=RemoteClient)
    mock_ioloop = Mock(spec=IOLoop.current())

    _remote(""127.0.0.1:8799"", 8788, loop=mock_ioloop, client=mock_remote_client)

    mock_remote_client.assert_called_once_with(ip=""127.0.0.1"", loop=mock_ioloop)
    mock_remote_client().start.assert_called_once_with(port=8799)

    assert mock_ioloop.start.called
    assert mock_ioloop.close.called
    assert mock_remote_client().stop.called
","
1from mock import Mock
2
3from tornado import gen
4from tornado.ioloop import IOLoop
5from distributed.submit import RemoteClient, _submit, _remote
6from distributed.utils_test import (  # noqa: F401
7    valid_python_script,
8    invalid_python_script,
9    loop,
10)
11
12
13def test_dask_submit_cli_writes_result_to_stdout(loop, tmpdir, valid_python_script):
14    @gen.coroutine
15    def test():
16        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
17        yield remote_client._start()
18
19        out, err = yield _submit(
20            ""127.0.0.1:{0}"".format(remote_client.port), str(valid_python_script)
21        )
22        yield remote_client._close()
23
24    loop.run_sync(test, timeout=5)
25
26
27def test_dask_submit_cli_writes_traceback_to_stdout(
28    loop, tmpdir, invalid_python_script
29):
30    @gen.coroutine
31    def test():
32        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
33        yield remote_client._start()
34
35        out, err = yield _submit(
36            ""127.0.0.1:{0}"".format(remote_client.port), str(invalid_python_script)
37        )
38        yield remote_client._close()
39
40    loop.run_sync(test, timeout=5)
41
42
43def test_cli_runs_remote_client():
44    mock_remote_client = Mock(spec=RemoteClient)
45    mock_ioloop = Mock(spec=IOLoop.current())
46
47    _remote(""127.0.0.1:8799"", 8788, loop=mock_ioloop, client=mock_remote_client)
48
49
50","[['mock_ioloop.start.called', '==', 'True'], ['mock_ioloop.close.called', '==', 'True'], ['mock_remote_client().stop.called', '==', 'True']]",7,3,0.4285714285714285,0.0017740981667652,"['loop', 'tmpdir', 'valid_python_script', 'remote_client', 'out', 'err', 'mock_remote_client', 'mock_ioloop']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['loop', 'tmpdir', 'valid_python_script', 'remote_client', 'out', 'err', 'mock_remote_client', 'mock_ioloop']
*Code:

1from mock import Mock
2
3from tornado import gen
4from tornado.ioloop import IOLoop
5from distributed.submit import RemoteClient, _submit, _remote
6from distributed.utils_test import (  # noqa: F401
7    valid_python_script,
8    invalid_python_script,
9    loop,
10)
11
12
13def test_dask_submit_cli_writes_result_to_stdout(loop, tmpdir, valid_python_script):
14    @gen.coroutine
15    def test():
16        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
17        yield remote_client._start()
18
19        out, err = yield _submit(
20            ""127.0.0.1:{0}"".format(remote_client.port), str(valid_python_script)
21        )
22        yield remote_client._close()
23
24    loop.run_sync(test, timeout=5)
25
26
27def test_dask_submit_cli_writes_traceback_to_stdout(
28    loop, tmpdir, invalid_python_script
29):
30    @gen.coroutine
31    def test():
32        remote_client = RemoteClient(ip=""127.0.0.1"", local_dir=str(tmpdir))
33        yield remote_client._start()
34
35        out, err = yield _submit(
36            ""127.0.0.1:{0}"".format(remote_client.port), str(invalid_python_script)
37        )
38        yield remote_client._close()
39
40    loop.run_sync(test, timeout=5)
41
42
43def test_cli_runs_remote_client():
44    mock_remote_client = Mock(spec=RemoteClient)
45    mock_ioloop = Mock(spec=IOLoop.current())
46
47    _remote(""127.0.0.1:8799"", 8788, loop=mock_ioloop, client=mock_remote_client)
48
49
50",2936,"[[13, 'loop', '!=', None, ""loop should not be None""],
[13, 'tmpdir', '!=', None, ""tmpdir should not be None""],
[13, 'valid_python_script', '!=', None, ""valid_python_script should not be None""],
[16, 'remote_client', '!=', None, ""remote_client should be initialized""],
[19, 'out', '!=', None, ""out should be initialized""],
[19, 'err', '!=', None, ""err should be initialized""],
[28, 'invalid_python_script', '!=', None, ""invalid_python_script should not be None""],
[32, 'remote_client', '!=', None, ""remote_client should be initialized""],
[35, 'out', '!=', None, ""out should be initialized""],
[35, 'err', '!=', None, ""err should be initialized""],
[44, 'mock_remote_client', '!=', None, ""mock_remote_client should be initialised""],
[45, 'mock_ioloop', '!=', None, ""mock_ioloop should be initialised""]]"
otsaloma/gaupol,"# -*- coding: utf-8 -*-

# Copyright (C) 2006 Osmo Salomaa
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import aeidon


class TestModule(aeidon.TestCase):

    def test_atomic_open__existing_file(self):
        path = self.new_subrip_file()
        with aeidon.util.atomic_open(path, ""w"") as f:
            f.write(""test\n"")
        text = open(path, ""r"").read()
        assert text == ""test\n""

    def test_atomic_open__no_existing_file(self):
        path = aeidon.temp.create()
        with aeidon.util.atomic_open(path, ""w"") as f:
            f.write(""test\n"")
        text = open(path, ""r"").read()
        assert text == ""test\n""

    def test_compare_versions(self):
        assert aeidon.util.compare_versions(""0.1.1"", ""0.1""  ) ==  1
        assert aeidon.util.compare_versions(""0.2""  , ""0.1""  ) ==  1
        assert aeidon.util.compare_versions(""0.3""  , ""0.3""  ) ==  0
        assert aeidon.util.compare_versions(""0.4""  , ""0.4.1"") == -1
        assert aeidon.util.compare_versions(""0.4""  , ""0.5""  ) == -1

    def test_detect_format(self):
        for format in aeidon.formats:
            path = self.new_temp_file(format)
            assert aeidon.util.detect_format(path, ""ascii"") == format

    def test_detect_newlines__mac(self):
        path = aeidon.temp.create()
        open(path, ""w"", newline="""").write(""a\rb\rc\r"")
        newlines = aeidon.util.detect_newlines(path)
        assert newlines == aeidon.newlines.MAC

    def test_detect_newlines__unix(self):
        path = aeidon.temp.create()
        open(path, ""w"", newline="""").write(""a\nb\nc\n"")
        newlines = aeidon.util.detect_newlines(path)
        assert newlines == aeidon.newlines.UNIX

    def test_detect_newlines__windows(self):
        path = aeidon.temp.create()
        open(path, ""w"", newline="""").write(""a\r\nb\r\nc\r\n"")
        newlines = aeidon.util.detect_newlines(path)
        assert newlines == aeidon.newlines.WINDOWS

    def test_flatten(self):
        lst = [1, 2, [3, 4, [5, 6, [7]], 8], 9]
        lst = aeidon.util.flatten(lst)
        assert lst == [1, 2, 3, 4, 5, 6, 7, 8, 9]

    def test_get_default_encoding(self):
        assert aeidon.util.get_default_encoding()

    def test_get_default_newline(self):
        assert aeidon.util.get_default_newline()

    def test_get_encoding_alias(self):
        assert aeidon.util.get_encoding_alias(""utf8"") == ""utf_8""
        assert aeidon.util.get_encoding_alias(""johab"") == ""johab""

    def test_get_ranges(self):
        lst = [0, 0, 4, 5, 3, 7, 8, 2, 7]
        lst = aeidon.util.get_ranges(lst)
        assert lst == [[0], [2, 3, 4, 5], [7, 8]]

    def test_get_unique__first(self):
        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
        lst = aeidon.util.get_unique(lst)
        assert lst == [4, 1, 5, 3, 6]

    def test_get_unique__last(self):
        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
        lst = aeidon.util.get_unique(lst, keep_last=True)
        assert lst == [5, 1, 3, 6, 4]

    def test_read__basic(self):
        path = self.new_subrip_file()
        text = open(path, ""r"", encoding=""ascii"").read().strip()
        assert aeidon.util.read(path) == text

    def test_read__fallback(self):
        path = self.new_subrip_file()
        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
        assert aeidon.util.read(path, ""ascii"") == ""\xc3\xb6""

    def test_readlines__basic(self):
        path = self.new_subrip_file()
        lines = [x.rstrip() for x in open(path, ""r"").readlines()]
        assert aeidon.util.readlines(path) == lines

    def test_readlines__fallback(self):
        path = self.new_subrip_file()
        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
        assert aeidon.util.readlines(path, ""ascii"") == [""\xc3\xb6""]

    def test_write__basic(self):
        text = ""test\ntest\n""
        path = self.new_subrip_file()
        aeidon.util.write(path, text)
        f = open(path, ""r"", encoding=""ascii"")
        assert f.read() == text

    def test_write__fallback(self):
        text = ""\xc3\xb6\n""
        path = self.new_subrip_file()
        aeidon.util.write(path, text, ""ascii"")
        f = open(path, ""r"", encoding=""utf_8"")
        assert f.read() == text

    def test_writelines__basic(self):
        lines = (""test"", ""test"")
        path = self.new_subrip_file()
        aeidon.util.writelines(path, lines)
        f = open(path, ""r"", encoding=""ascii"")
        assert f.read() == ""test\ntest\n""

    def test_writelines__fallback(self):
        text = ""\xc3\xb6""
        path = self.new_subrip_file()
        aeidon.util.writelines(path, (text,), ""ascii"")
        f = open(path, ""r"", encoding=""utf_8"")
        assert f.read() == text + ""\n""
","
1# -*- coding: utf-8 -*-
2
3# Copyright (C) 2006 Osmo Salomaa
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with this program. If not, see <http://www.gnu.org/licenses/>.
17
18import aeidon
19
20
21class TestModule(aeidon.TestCase):
22
23    def test_atomic_open__existing_file(self):
24        path = self.new_subrip_file()
25        with aeidon.util.atomic_open(path, ""w"") as f:
26            f.write(""test\n"")
27        text = open(path, ""r"").read()
28
29    def test_atomic_open__no_existing_file(self):
30        path = aeidon.temp.create()
31        with aeidon.util.atomic_open(path, ""w"") as f:
32            f.write(""test\n"")
33        text = open(path, ""r"").read()
34
35    def test_compare_versions(self):
36
37    def test_detect_format(self):
38        for format in aeidon.formats:
39            path = self.new_temp_file(format)
40
41    def test_detect_newlines__mac(self):
42        path = aeidon.temp.create()
43        open(path, ""w"", newline="""").write(""a\rb\rc\r"")
44        newlines = aeidon.util.detect_newlines(path)
45
46    def test_detect_newlines__unix(self):
47        path = aeidon.temp.create()
48        open(path, ""w"", newline="""").write(""a\nb\nc\n"")
49        newlines = aeidon.util.detect_newlines(path)
50
51    def test_detect_newlines__windows(self):
52        path = aeidon.temp.create()
53        open(path, ""w"", newline="""").write(""a\r\nb\r\nc\r\n"")
54        newlines = aeidon.util.detect_newlines(path)
55
56    def test_flatten(self):
57        lst = [1, 2, [3, 4, [5, 6, [7]], 8], 9]
58        lst = aeidon.util.flatten(lst)
59
60    def test_get_default_encoding(self):
61
62    def test_get_default_newline(self):
63
64    def test_get_encoding_alias(self):
65
66    def test_get_ranges(self):
67        lst = [0, 0, 4, 5, 3, 7, 8, 2, 7]
68        lst = aeidon.util.get_ranges(lst)
69
70    def test_get_unique__first(self):
71        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
72        lst = aeidon.util.get_unique(lst)
73
74    def test_get_unique__last(self):
75        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
76        lst = aeidon.util.get_unique(lst, keep_last=True)
77
78    def test_read__basic(self):
79        path = self.new_subrip_file()
80        text = open(path, ""r"", encoding=""ascii"").read().strip()
81
82    def test_read__fallback(self):
83        path = self.new_subrip_file()
84        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
85
86    def test_readlines__basic(self):
87        path = self.new_subrip_file()
88        lines = [x.rstrip() for x in open(path, ""r"").readlines()]
89
90    def test_readlines__fallback(self):
91        path = self.new_subrip_file()
92        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
93
94    def test_write__basic(self):
95        text = ""test\ntest\n""
96        path = self.new_subrip_file()
97        aeidon.util.write(path, text)
98        f = open(path, ""r"", encoding=""ascii"")
99
100    def test_write__fallback(self):
101        text = ""\xc3\xb6\n""
102        path = self.new_subrip_file()
103        aeidon.util.write(path, text, ""ascii"")
104        f = open(path, ""r"", encoding=""utf_8"")
105
106    def test_writelines__basic(self):
107        lines = (""test"", ""test"")
108        path = self.new_subrip_file()
109        aeidon.util.writelines(path, lines)
110        f = open(path, ""r"", encoding=""ascii"")
111
112    def test_writelines__fallback(self):
113        text = ""\xc3\xb6""
114        path = self.new_subrip_file()
115        aeidon.util.writelines(path, (text,), ""ascii"")
116        f = open(path, ""r"", encoding=""utf_8"")
117","[['text', '==', '""test\\n""'], ['text', '==', '""test\\n""'], ['aeidon.util.compare_versions(""0.1.1""', '==', 'True'], ['aeidon.util.compare_versions(""0.2""', '==', 'True'], ['aeidon.util.compare_versions(""0.3""', '==', 'True'], ['aeidon.util.compare_versions(""0.4""', '==', 'True'], ['aeidon.util.compare_versions(""0.4""', '==', 'True'], ['aeidon.util.detect_format(path', '==', 'True'], ['newlines', '==', 'aeidon.newlines.MAC'], ['newlines', '==', 'aeidon.newlines.UNIX'], ['newlines', '==', 'aeidon.newlines.WINDOWS'], ['lst', '==', '[1'], ['aeidon.util.get_default_encoding()', '==', 'True'], ['aeidon.util.get_default_newline()', '==', 'True'], ['aeidon.util.get_encoding_alias(""utf8"")', '==', '""utf_8""'], ['aeidon.util.get_encoding_alias(""johab"")', '==', '""johab""'], ['lst', '==', '[[0]'], ['lst', '==', '[4'], ['lst', '==', '[5'], ['aeidon.util.read(path)', '==', 'text'], ['aeidon.util.read(path', '==', 'True'], ['aeidon.util.readlines(path)', '==', 'lines'], ['aeidon.util.readlines(path', '==', 'True'], ['f.read()', '==', 'text'], ['f.read()', '==', 'text'], ['f.read()', '==', '""test\\ntest\\n""'], ['f.read()', '==', 'text + ""\\n""']]",27,27,1.0,0.0051418777375737,"['path', 'text', 'newlines', 'lst', 'lines', 'f']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['path', 'text', 'newlines', 'lst', 'lines', 'f']
*Code:

1# -*- coding: utf-8 -*-
2
3# Copyright (C) 2006 Osmo Salomaa
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with this program. If not, see <http://www.gnu.org/licenses/>.
17
18import aeidon
19
20
21class TestModule(aeidon.TestCase):
22
23    def test_atomic_open__existing_file(self):
24        path = self.new_subrip_file()
25        with aeidon.util.atomic_open(path, ""w"") as f:
26            f.write(""test\n"")
27        text = open(path, ""r"").read()
28
29    def test_atomic_open__no_existing_file(self):
30        path = aeidon.temp.create()
31        with aeidon.util.atomic_open(path, ""w"") as f:
32            f.write(""test\n"")
33        text = open(path, ""r"").read()
34
35    def test_compare_versions(self):
36
37    def test_detect_format(self):
38        for format in aeidon.formats:
39            path = self.new_temp_file(format)
40
41    def test_detect_newlines__mac(self):
42        path = aeidon.temp.create()
43        open(path, ""w"", newline="""").write(""a\rb\rc\r"")
44        newlines = aeidon.util.detect_newlines(path)
45
46    def test_detect_newlines__unix(self):
47        path = aeidon.temp.create()
48        open(path, ""w"", newline="""").write(""a\nb\nc\n"")
49        newlines = aeidon.util.detect_newlines(path)
50
51    def test_detect_newlines__windows(self):
52        path = aeidon.temp.create()
53        open(path, ""w"", newline="""").write(""a\r\nb\r\nc\r\n"")
54        newlines = aeidon.util.detect_newlines(path)
55
56    def test_flatten(self):
57        lst = [1, 2, [3, 4, [5, 6, [7]], 8], 9]
58        lst = aeidon.util.flatten(lst)
59
60    def test_get_default_encoding(self):
61
62    def test_get_default_newline(self):
63
64    def test_get_encoding_alias(self):
65
66    def test_get_ranges(self):
67        lst = [0, 0, 4, 5, 3, 7, 8, 2, 7]
68        lst = aeidon.util.get_ranges(lst)
69
70    def test_get_unique__first(self):
71        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
72        lst = aeidon.util.get_unique(lst)
73
74    def test_get_unique__last(self):
75        lst = [4, 1, 5, 5, 1, 1, 3, 6, 4, 4]
76        lst = aeidon.util.get_unique(lst, keep_last=True)
77
78    def test_read__basic(self):
79        path = self.new_subrip_file()
80        text = open(path, ""r"", encoding=""ascii"").read().strip()
81
82    def test_read__fallback(self):
83        path = self.new_subrip_file()
84        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
85
86    def test_readlines__basic(self):
87        path = self.new_subrip_file()
88        lines = [x.rstrip() for x in open(path, ""r"").readlines()]
89
90    def test_readlines__fallback(self):
91        path = self.new_subrip_file()
92        open(path, ""w"", encoding=""utf_8"").write(""\xc3\xb6\n"")
93
94    def test_write__basic(self):
95        text = ""test\ntest\n""
96        path = self.new_subrip_file()
97        aeidon.util.write(path, text)
98        f = open(path, ""r"", encoding=""ascii"")
99
100    def test_write__fallback(self):
101        text = ""\xc3\xb6\n""
102        path = self.new_subrip_file()
103        aeidon.util.write(path, text, ""ascii"")
104        f = open(path, ""r"", encoding=""utf_8"")
105
106    def test_writelines__basic(self):
107        lines = (""test"", ""test"")
108        path = self.new_subrip_file()
109        aeidon.util.writelines(path, lines)
110        f = open(path, ""r"", encoding=""ascii"")
111
112    def test_writelines__fallback(self):
113        text = ""\xc3\xb6""
114        path = self.new_subrip_file()
115        aeidon.util.writelines(path, (text,), ""ascii"")
116        f = open(path, ""r"", encoding=""utf_8"")
117",5526,"[[24, 'path', '!=', None, 'A path should be specified for the file'],
[25, 'f', '!=', None, 'File object should be properly initialized'],
[26, 'text', '!=', None, 'Text to be written should not be None'],
[30, 'path', '!=', None, 'A path should be specified for the new file'],
[31, 'f', '!=', None, 'File object should be properly initialized for new file'],
[32, 'text', '!=', None, 'Text to be written to new file should not be None'],
[42, 'path', '!=', None, 'A path should be specified for MAC newlines test file'],
[43, 'newlines', '!=', None, 'The detected newlines for MAC should not be None'],
[47, 'path', '!=', None, 'A path should be specified for Unix newlines test file'],
[48, 'newlines', '!=', None, 'The detected newlines for Unix should not be None'],
[52, 'path', '!=', None, 'A path should be specified for Windows newlines test file'],
[53, 'newlines', '!=', None, 'The detected newlines for Windows should not be None'],
[57, 'lst', '!=', None, ""A list must be specified for the flatten function""],
[58, 'lst', '!=', None, ""The flattened list shouldn't be None""],
[67, 'lst', '!=', None, ""A list must be specified for the get_ranges function""],
[68, 'lst', '!=', None, ""The list of ranges shouldn't be None""],
[71, 'lst', '!=', None, ""A list must be specified for the get_unique function""],
[72, 'lst', '!=', None, ""The list of unique elements shouldn't be None""],
[75, 'lst', '!=', None, ""A list must be specified for the get_unique function for last element""],
[76, 'lst', '!=', None, ""The list of unique elements for last element shouldn't be None""],
[79, 'path', '!=', None, 'A path should be specified for the file in basic read test'],
[80, 'text', '!=', None, 'Text read from the file in basic read test should not be None'],
[83, 'path', '!=', None, 'A path should be specified for the file in fallback read test'],
[88, 'path', '!=', None, 'A path should be specified for the file in basic readlines test'],
[88, 'lines', '!=', None, 'Lines read from the file in basic readlines test should not be None'],
[94, 'text', '!=', None, 'Text to be written in basic write test should not be None'],
[95, 'path', '!=', None, 'A path should be specified for the file in basic write test'],
[97, 'f', '!=', None, 'File object should be properly initialized in basic write test'],
[100, 'text', '!=', None, 'Text to be written in fallback write test should not be None'],
[101, 'path', '!=', None, 'A path should be specified for the file in fallback write test'],
[103, 'f', '!=', None, 'File object should be properly initialized in fallback write test'],
[106, 'lines', '!=', None, 'Lines to be written in basic writelines test should not be None'],
[107, 'path', '!=', None, 'A path should be specified for the file in basic writelines test'],
[109, 'f', '!=', None, 'File object should be properly initialized in basic writelines test'],
[112, 'text', '!=', None, 'Text to be written in fallback writelines test should not be None'],
[113, 'path', '!=', None, 'A path should be specified for the file in fallback writelines test'],
[115, 'f', '!=', None, 'File object should be properly initialized in fallback writelines test']]"
adamhaney/airflow,"# -*- coding: utf-8 -*-
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# ""License""); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
from __future__ import print_function

import airflow
from airflow import DAG
from airflow.operators.python_operator import PythonOperator

args = {
    'owner': 'airflow',
    'start_date': airflow.utils.dates.days_ago(2),
    'provide_context': True,
}

dag = DAG('example_xcom', schedule_interval=""@once"", default_args=args)

value_1 = [1, 2, 3]
value_2 = {'a': 'b'}


def push(**kwargs):
    """"""Pushes an XCom without a specific target""""""
    kwargs['ti'].xcom_push(key='value from pusher 1', value=value_1)


def push_by_returning(**kwargs):
    """"""Pushes an XCom without a specific target, just by returning it""""""
    return value_2


def puller(**kwargs):
    ti = kwargs['ti']

    # get value_1
    v1 = ti.xcom_pull(key=None, task_ids='push')
    assert v1 == value_1

    # get value_2
    v2 = ti.xcom_pull(task_ids='push_by_returning')
    assert v2 == value_2

    # get both value_1 and value_2
    v1, v2 = ti.xcom_pull(key=None, task_ids=['push', 'push_by_returning'])
    assert (v1, v2) == (value_1, value_2)


push1 = PythonOperator(
    task_id='push',
    dag=dag,
    python_callable=push,
)

push2 = PythonOperator(
    task_id='push_by_returning',
    dag=dag,
    python_callable=push_by_returning,
)

pull = PythonOperator(
    task_id='puller',
    dag=dag,
    python_callable=puller,
)

pull << [push1, push2]
","
1# -*- coding: utf-8 -*-
2#
3# Licensed to the Apache Software Foundation (ASF) under one
4# or more contributor license agreements.  See the NOTICE file
5# distributed with this work for additional information
6# regarding copyright ownership.  The ASF licenses this file
7# to you under the Apache License, Version 2.0 (the
8# ""License""); you may not use this file except in compliance
9# with the License.  You may obtain a copy of the License at
10#
11#   http://www.apache.org/licenses/LICENSE-2.0
12#
13# Unless required by applicable law or agreed to in writing,
14# software distributed under the License is distributed on an
15# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
16# KIND, either express or implied.  See the License for the
17# specific language governing permissions and limitations
18# under the License.
19from __future__ import print_function
20
21import airflow
22from airflow import DAG
23from airflow.operators.python_operator import PythonOperator
24
25args = {
26    'owner': 'airflow',
27    'start_date': airflow.utils.dates.days_ago(2),
28    'provide_context': True,
29}
30
31dag = DAG('example_xcom', schedule_interval=""@once"", default_args=args)
32
33value_1 = [1, 2, 3]
34value_2 = {'a': 'b'}
35
36
37def push(**kwargs):
38    """"""Pushes an XCom without a specific target""""""
39    kwargs['ti'].xcom_push(key='value from pusher 1', value=value_1)
40
41
42def push_by_returning(**kwargs):
43    """"""Pushes an XCom without a specific target, just by returning it""""""
44    return value_2
45
46
47def puller(**kwargs):
48    ti = kwargs['ti']
49
50    # get value_1
51    v1 = ti.xcom_pull(key=None, task_ids='push')
52
53    # get value_2
54    v2 = ti.xcom_pull(task_ids='push_by_returning')
55
56    # get both value_1 and value_2
57    v1, v2 = ti.xcom_pull(key=None, task_ids=['push', 'push_by_returning'])
58
59
60push1 = PythonOperator(
61    task_id='push',
62    dag=dag,
63    python_callable=push,
64)
65
66push2 = PythonOperator(
67    task_id='push_by_returning',
68    dag=dag,
69    python_callable=push_by_returning,
70)
71
72pull = PythonOperator(
73    task_id='puller',
74    dag=dag,
75    python_callable=puller,
76)
77
78pull << [push1, push2]
79","[['v1', '==', 'value_1'], ['v2', '==', 'value_2'], ['(v1', '==', 'True']]",3,3,1.0,0.00139470013947,"['args', 'dag', 'value_1', 'value_2', '**kwargs', 'ti', 'v1', 'v2', 'push1', 'push2', 'pull']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['args', 'dag', 'value_1', 'value_2', '**kwargs', 'ti', 'v1', 'v2', 'push1', 'push2', 'pull']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Licensed to the Apache Software Foundation (ASF) under one
4# or more contributor license agreements.  See the NOTICE file
5# distributed with this work for additional information
6# regarding copyright ownership.  The ASF licenses this file
7# to you under the Apache License, Version 2.0 (the
8# ""License""); you may not use this file except in compliance
9# with the License.  You may obtain a copy of the License at
10#
11#   http://www.apache.org/licenses/LICENSE-2.0
12#
13# Unless required by applicable law or agreed to in writing,
14# software distributed under the License is distributed on an
15# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
16# KIND, either express or implied.  See the License for the
17# specific language governing permissions and limitations
18# under the License.
19from __future__ import print_function
20
21import airflow
22from airflow import DAG
23from airflow.operators.python_operator import PythonOperator
24
25args = {
26    'owner': 'airflow',
27    'start_date': airflow.utils.dates.days_ago(2),
28    'provide_context': True,
29}
30
31dag = DAG('example_xcom', schedule_interval=""@once"", default_args=args)
32
33value_1 = [1, 2, 3]
34value_2 = {'a': 'b'}
35
36
37def push(**kwargs):
38    """"""Pushes an XCom without a specific target""""""
39    kwargs['ti'].xcom_push(key='value from pusher 1', value=value_1)
40
41
42def push_by_returning(**kwargs):
43    """"""Pushes an XCom without a specific target, just by returning it""""""
44    return value_2
45
46
47def puller(**kwargs):
48    ti = kwargs['ti']
49
50    # get value_1
51    v1 = ti.xcom_pull(key=None, task_ids='push')
52
53    # get value_2
54    v2 = ti.xcom_pull(task_ids='push_by_returning')
55
56    # get both value_1 and value_2
57    v1, v2 = ti.xcom_pull(key=None, task_ids=['push', 'push_by_returning'])
58
59
60push1 = PythonOperator(
61    task_id='push',
62    dag=dag,
63    python_callable=push,
64)
65
66push2 = PythonOperator(
67    task_id='push_by_returning',
68    dag=dag,
69    python_callable=push_by_returning,
70)
71
72pull = PythonOperator(
73    task_id='puller',
74    dag=dag,
75    python_callable=puller,
76)
77
78pull << [push1, push2]
79",3682,"[38, '**kwargs', '!=', None, 'kwargs should not be None to push values'],
[43, '**kwargs', '!=', None, 'kwargs should not be None to push values by returning'],
[48, '**kwargs', '!=', None, 'kwargs should not be None to pull values'],
[34, 'value_2', '==', {'a': 'b'}, 'value_2 is expected to be a dictionary with keys a'],
[33, 'value_1', '==', [1, 2, 3], 'value_1 is expected to be a list with values 1, 2, 3'],
[61, 'dag', '!=', None, 'dag should not be None for PythonOperator'],
[67, 'dag', '!=', None, 'dag should not be None for PythonOperator'],
[73, 'dag', '!=', None, 'dag should not be None for PythonOperator']"
Zord13appdesa/python-for-android,"#! /usr/bin/env python3

""""""
combinerefs path

A helper for analyzing PYTHONDUMPREFS output.

When the PYTHONDUMPREFS envar is set in a debug build, at Python shutdown
time Py_Finalize() prints the list of all live objects twice:  first it
prints the repr() of each object while the interpreter is still fully intact.
After cleaning up everything it can, it prints all remaining live objects
again, but the second time just prints their addresses, refcounts, and type
names (because the interpreter has been torn down, calling repr methods at
this point can get into infinite loops or blow up).

Save all this output into a file, then run this script passing the path to
that file.  The script finds both output chunks, combines them, then prints
a line of output for each object still alive at the end:

    address refcnt typename repr

address is the address of the object, in whatever format the platform C
produces for a %p format code.

refcnt is of the form

    ""["" ref ""]""

when the object's refcount is the same in both PYTHONDUMPREFS output blocks,
or

    ""["" ref_before ""->"" ref_after ""]""

if the refcount changed.

typename is object->ob_type->tp_name, extracted from the second PYTHONDUMPREFS
output block.

repr is repr(object), extracted from the first PYTHONDUMPREFS output block.
CAUTION:  If object is a container type, it may not actually contain all the
objects shown in the repr:  the repr was captured from the first output block,
and some of the containees may have been released since then.  For example,
it's common for the line showing the dict of interned strings to display
strings that no longer exist at the end of Py_Finalize; this can be recognized
(albeit painfully) because such containees don't have a line of their own.

The objects are listed in allocation order, with most-recently allocated
printed first, and the first object allocated printed last.


Simple examples:

    00857060 [14] str '__len__'

The str object '__len__' is alive at shutdown time, and both PYTHONDUMPREFS
output blocks said there were 14 references to it.  This is probably due to
C modules that intern the string ""__len__"" and keep a reference to it in a
file static.

    00857038 [46->5] tuple ()

46-5 = 41 references to the empty tuple were removed by the cleanup actions
between the times PYTHONDUMPREFS produced output.

    00858028 [1025->1456] str '<dummy key>'

The string '<dummy key>', which is used in dictobject.c to overwrite a real
key that gets deleted, grew several hundred references during cleanup.  It
suggests that stuff did get removed from dicts by cleanup, but that the dicts
themselves are staying alive for some reason. """"""

import re
import sys

# Generate lines from fileiter.  If whilematch is true, continue reading
# while the regexp object pat matches line.  If whilematch is false, lines
# are read so long as pat doesn't match them.  In any case, the first line
# that doesn't match pat (when whilematch is true), or that does match pat
# (when whilematch is false), is lost, and fileiter will resume at the line
# following it.
def read(fileiter, pat, whilematch):
    for line in fileiter:
        if bool(pat.match(line)) == whilematch:
            yield line
        else:
            break

def combine(fname):
    f = open(fname)

    fi = iter(f)

    for line in read(fi, re.compile(r'^Remaining objects:$'), False):
        pass

    crack = re.compile(r'([a-zA-Z\d]+) \[(\d+)\] (.*)')
    addr2rc = {}
    addr2guts = {}
    before = 0
    for line in read(fi, re.compile(r'^Remaining object addresses:$'), False):
        m = crack.match(line)
        if m:
            addr, addr2rc[addr], addr2guts[addr] = m.groups()
            before += 1
        else:
            print('??? skipped:', line)

    after = 0
    for line in read(fi, crack, True):
        after += 1
        m = crack.match(line)
        assert m
        addr, rc, guts = m.groups() # guts is type name here
        if addr not in addr2rc:
            print('??? new object created while tearing down:', line.rstrip())
            continue
        print(addr, end=' ')
        if rc == addr2rc[addr]:
            print('[%s]' % rc, end=' ')
        else:
            print('[%s->%s]' % (addr2rc[addr], rc), end=' ')
        print(guts, addr2guts[addr])

    f.close()
    print(""%d objects before, %d after"" % (before, after))

if __name__ == '__main__':
    combine(sys.argv[1])
","
1#! /usr/bin/env python3
2
3""""""
4combinerefs path
5
6A helper for analyzing PYTHONDUMPREFS output.
7
8When the PYTHONDUMPREFS envar is set in a debug build, at Python shutdown
9time Py_Finalize() prints the list of all live objects twice:  first it
10prints the repr() of each object while the interpreter is still fully intact.
11After cleaning up everything it can, it prints all remaining live objects
12again, but the second time just prints their addresses, refcounts, and type
13names (because the interpreter has been torn down, calling repr methods at
14this point can get into infinite loops or blow up).
15
16Save all this output into a file, then run this script passing the path to
17that file.  The script finds both output chunks, combines them, then prints
18a line of output for each object still alive at the end:
19
20    address refcnt typename repr
21
22address is the address of the object, in whatever format the platform C
23produces for a %p format code.
24
25refcnt is of the form
26
27    ""["" ref ""]""
28
29when the object's refcount is the same in both PYTHONDUMPREFS output blocks,
30or
31
32    ""["" ref_before ""->"" ref_after ""]""
33
34if the refcount changed.
35
36typename is object->ob_type->tp_name, extracted from the second PYTHONDUMPREFS
37output block.
38
39repr is repr(object), extracted from the first PYTHONDUMPREFS output block.
40CAUTION:  If object is a container type, it may not actually contain all the
41objects shown in the repr:  the repr was captured from the first output block,
42and some of the containees may have been released since then.  For example,
43it's common for the line showing the dict of interned strings to display
44strings that no longer exist at the end of Py_Finalize; this can be recognized
45(albeit painfully) because such containees don't have a line of their own.
46
47The objects are listed in allocation order, with most-recently allocated
48printed first, and the first object allocated printed last.
49
50
51Simple examples:
52
53    00857060 [14] str '__len__'
54
55The str object '__len__' is alive at shutdown time, and both PYTHONDUMPREFS
56output blocks said there were 14 references to it.  This is probably due to
57C modules that intern the string ""__len__"" and keep a reference to it in a
58file static.
59
60    00857038 [46->5] tuple ()
61
6246-5 = 41 references to the empty tuple were removed by the cleanup actions
63between the times PYTHONDUMPREFS produced output.
64
65    00858028 [1025->1456] str '<dummy key>'
66
67The string '<dummy key>', which is used in dictobject.c to overwrite a real
68key that gets deleted, grew several hundred references during cleanup.  It
69suggests that stuff did get removed from dicts by cleanup, but that the dicts
70themselves are staying alive for some reason. """"""
71
72import re
73import sys
74
75# Generate lines from fileiter.  If whilematch is true, continue reading
76# while the regexp object pat matches line.  If whilematch is false, lines
77# are read so long as pat doesn't match them.  In any case, the first line
78# that doesn't match pat (when whilematch is true), or that does match pat
79# (when whilematch is false), is lost, and fileiter will resume at the line
80# following it.
81def read(fileiter, pat, whilematch):
82    for line in fileiter:
83        if bool(pat.match(line)) == whilematch:
84            yield line
85        else:
86            break
87
88def combine(fname):
89    f = open(fname)
90
91    fi = iter(f)
92
93    for line in read(fi, re.compile(r'^Remaining objects:$'), False):
94        pass
95
96    crack = re.compile(r'([a-zA-Z\d]+) \[(\d+)\] (.*)')
97    addr2rc = {}
98    addr2guts = {}
99    before = 0
100    for line in read(fi, re.compile(r'^Remaining object addresses:$'), False):
101        m = crack.match(line)
102        if m:
103            addr, addr2rc[addr], addr2guts[addr] = m.groups()
104            before += 1
105        else:
106            print('??? skipped:', line)
107
108    after = 0
109    for line in read(fi, crack, True):
110        after += 1
111        m = crack.match(line)
112        addr, rc, guts = m.groups() # guts is type name here
113        if addr not in addr2rc:
114            print('??? new object created while tearing down:', line.rstrip())
115            continue
116        print(addr, end=' ')
117        if rc == addr2rc[addr]:
118            print('[%s]' % rc, end=' ')
119        else:
120            print('[%s->%s]' % (addr2rc[addr], rc), end=' ')
121        print(guts, addr2guts[addr])
122
123    f.close()
124    print(""%d objects before, %d after"" % (before, after))
125
126if __name__ == '__main__':
127    combine(sys.argv[1])
128","[['m', '==', 'True']]",1,1,1.0,0.0002265518803806,"['46-5', 'fileiter', 'pat', 'whilematch', 'fname', 'f', 'fi', 'crack', 'addr2rc', 'addr2guts', 'before', 'm', 'addr', 'addr2rc[addr]', 'addr2guts[addr]', 'after', 'rc', 'guts']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['46-5', 'fileiter', 'pat', 'whilematch', 'fname', 'f', 'fi', 'crack', 'addr2rc', 'addr2guts', 'before', 'm', 'addr', 'addr2rc[addr]', 'addr2guts[addr]', 'after', 'rc', 'guts']
*Code:

1#! /usr/bin/env python3
2
3""""""
4combinerefs path
5
6A helper for analyzing PYTHONDUMPREFS output.
7
8When the PYTHONDUMPREFS envar is set in a debug build, at Python shutdown
9time Py_Finalize() prints the list of all live objects twice:  first it
10prints the repr() of each object while the interpreter is still fully intact.
11After cleaning up everything it can, it prints all remaining live objects
12again, but the second time just prints their addresses, refcounts, and type
13names (because the interpreter has been torn down, calling repr methods at
14this point can get into infinite loops or blow up).
15
16Save all this output into a file, then run this script passing the path to
17that file.  The script finds both output chunks, combines them, then prints
18a line of output for each object still alive at the end:
19
20    address refcnt typename repr
21
22address is the address of the object, in whatever format the platform C
23produces for a %p format code.
24
25refcnt is of the form
26
27    ""["" ref ""]""
28
29when the object's refcount is the same in both PYTHONDUMPREFS output blocks,
30or
31
32    ""["" ref_before ""->"" ref_after ""]""
33
34if the refcount changed.
35
36typename is object->ob_type->tp_name, extracted from the second PYTHONDUMPREFS
37output block.
38
39repr is repr(object), extracted from the first PYTHONDUMPREFS output block.
40CAUTION:  If object is a container type, it may not actually contain all the
41objects shown in the repr:  the repr was captured from the first output block,
42and some of the containees may have been released since then.  For example,
43it's common for the line showing the dict of interned strings to display
44strings that no longer exist at the end of Py_Finalize; this can be recognized
45(albeit painfully) because such containees don't have a line of their own.
46
47The objects are listed in allocation order, with most-recently allocated
48printed first, and the first object allocated printed last.
49
50
51Simple examples:
52
53    00857060 [14] str '__len__'
54
55The str object '__len__' is alive at shutdown time, and both PYTHONDUMPREFS
56output blocks said there were 14 references to it.  This is probably due to
57C modules that intern the string ""__len__"" and keep a reference to it in a
58file static.
59
60    00857038 [46->5] tuple ()
61
6246-5 = 41 references to the empty tuple were removed by the cleanup actions
63between the times PYTHONDUMPREFS produced output.
64
65    00858028 [1025->1456] str '<dummy key>'
66
67The string '<dummy key>', which is used in dictobject.c to overwrite a real
68key that gets deleted, grew several hundred references during cleanup.  It
69suggests that stuff did get removed from dicts by cleanup, but that the dicts
70themselves are staying alive for some reason. """"""
71
72import re
73import sys
74
75# Generate lines from fileiter.  If whilematch is true, continue reading
76# while the regexp object pat matches line.  If whilematch is false, lines
77# are read so long as pat doesn't match them.  In any case, the first line
78# that doesn't match pat (when whilematch is true), or that does match pat
79# (when whilematch is false), is lost, and fileiter will resume at the line
80# following it.
81def read(fileiter, pat, whilematch):
82    for line in fileiter:
83        if bool(pat.match(line)) == whilematch:
84            yield line
85        else:
86            break
87
88def combine(fname):
89    f = open(fname)
90
91    fi = iter(f)
92
93    for line in read(fi, re.compile(r'^Remaining objects:$'), False):
94        pass
95
96    crack = re.compile(r'([a-zA-Z\d]+) \[(\d+)\] (.*)')
97    addr2rc = {}
98    addr2guts = {}
99    before = 0
100    for line in read(fi, re.compile(r'^Remaining object addresses:$'), False):
101        m = crack.match(line)
102        if m:
103            addr, addr2rc[addr], addr2guts[addr] = m.groups()
104            before += 1
105        else:
106            print('??? skipped:', line)
107
108    after = 0
109    for line in read(fi, crack, True):
110        after += 1
111        m = crack.match(line)
112        addr, rc, guts = m.groups() # guts is type name here
113        if addr not in addr2rc:
114            print('??? new object created while tearing down:', line.rstrip())
115            continue
116        print(addr, end=' ')
117        if rc == addr2rc[addr]:
118            print('[%s]' % rc, end=' ')
119        else:
120            print('[%s->%s]' % (addr2rc[addr], rc), end=' ')
121        print(guts, addr2guts[addr])
122
123    f.close()
124    print(""%d objects before, %d after"" % (before, after))
125
126if __name__ == '__main__':
127    combine(sys.argv[1])
128",6230,"[[88, 'fname', '!=', """", ""File name must be non-empty for opening file""],
 [96, 'addr2rc', '==', {}, 'addr2rc should be empty before usage'],
 [96, 'addr2guts', '==', {}, 'addr2guts should be empty before usage'],
 [96, 'before', '==', 0, 'before should be zero before usage'],
 [102, 'm', '!=', None, 'Match object must be valid'],
 [104, 'before', '>=', 1, 'Before count should increment with valid match'],
 [108, 'after', '==', 0, 'After should be zero before usage'],
 [113, 'addr', 'in', 'addr2rc.keys()', 'Assert that addr is in the keys of addr2rc']]"
petermalcolm/osf.io,"from website.models import Node
from framework.auth import Auth
from tests.base import OsfTestCase
from tests.factories import ProjectFactory, UserFactory, NodeFactory
from scripts.migrate_registration_and_fork_log import (
    get_parent, get_all_parents
)


class TestMigrateLogs(OsfTestCase):

    def tearDown(self):
        OsfTestCase.tearDown(self)
        Node.remove()

    def test_get_parent(self):
        user = UserFactory()
        auth = Auth(user=user)
        project1 = ProjectFactory(creator=user)
        project2 = project1.fork_node(auth=auth)
        forked_from = get_parent(project2)

        assert forked_from is project1

        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
        registered_from = get_parent(project3)

        assert registered_from is project2

    def test_get_all_parents(self):
        user = UserFactory()
        auth = Auth(user=user)
        project1 = ProjectFactory(creator=user)
        project2 = project1.fork_node(auth=auth)
        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
        parent_list = get_all_parents(project3)

        assert len(parent_list) is 2
        assert project1 in parent_list
        assert project2 in parent_list","
1from website.models import Node
2from framework.auth import Auth
3from tests.base import OsfTestCase
4from tests.factories import ProjectFactory, UserFactory, NodeFactory
5from scripts.migrate_registration_and_fork_log import (
6    get_parent, get_all_parents
7)
8
9
10class TestMigrateLogs(OsfTestCase):
11
12    def tearDown(self):
13        OsfTestCase.tearDown(self)
14        Node.remove()
15
16    def test_get_parent(self):
17        user = UserFactory()
18        auth = Auth(user=user)
19        project1 = ProjectFactory(creator=user)
20        project2 = project1.fork_node(auth=auth)
21        forked_from = get_parent(project2)
22
23
24        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
25        registered_from = get_parent(project3)
26
27
28    def test_get_all_parents(self):
29        user = UserFactory()
30        auth = Auth(user=user)
31        project1 = ProjectFactory(creator=user)
32        project2 = project1.fork_node(auth=auth)
33        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
34        parent_list = get_all_parents(project3)
35","[['forked_from', '==', 'project1'], ['registered_from', '==', 'project2'], ['len(parent_list)', '==', '2']]",5,3,0.6,0.0023310023310023,"['user', 'auth', 'project1', 'project2', 'forked_from', 'project3', 'registered_from', 'parent_list']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['user', 'auth', 'project1', 'project2', 'forked_from', 'project3', 'registered_from', 'parent_list']
*Code:

1from website.models import Node
2from framework.auth import Auth
3from tests.base import OsfTestCase
4from tests.factories import ProjectFactory, UserFactory, NodeFactory
5from scripts.migrate_registration_and_fork_log import (
6    get_parent, get_all_parents
7)
8
9
10class TestMigrateLogs(OsfTestCase):
11
12    def tearDown(self):
13        OsfTestCase.tearDown(self)
14        Node.remove()
15
16    def test_get_parent(self):
17        user = UserFactory()
18        auth = Auth(user=user)
19        project1 = ProjectFactory(creator=user)
20        project2 = project1.fork_node(auth=auth)
21        forked_from = get_parent(project2)
22
23
24        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
25        registered_from = get_parent(project3)
26
27
28    def test_get_all_parents(self):
29        user = UserFactory()
30        auth = Auth(user=user)
31        project1 = ProjectFactory(creator=user)
32        project2 = project1.fork_node(auth=auth)
33        project3 = project2.register_node(schema=None, auth=auth, template=""foo"", data=""bar"")
34        parent_list = get_all_parents(project3)
35",2633,"[[17, 'user', '!=', None, ""User should be defined before its usage""],
 [18, 'auth', '!=', None, ""Auth should be defined before its usage""],
 [19, 'project1', '!=', None, ""project1 should be defined and validated before its usage""],
 [21, 'forked_from', '==', 'project1', ""forked_from is expected to be the same as its original project""],
 [24, 'project3', '!=', None, ""project3 should be defined and validated before its usage""],
 [26, 'registered_from', '==', 'project2', ""registered_from is expected to be project2 that registered project3""],
 [34, 'parent_list', '!=', None, ""parent_list should be defined and validated before its usage""]]"
retomerz/intellij-community,"# Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

""""""Fixer for execfile.

This converts usages of the execfile function into calls to the built-in
exec() function.
""""""

from .. import fixer_base
from ..fixer_util import (Comma, Name, Call, LParen, RParen, Dot, Node,
                          ArgList, String, syms)


class FixExecfile(fixer_base.BaseFix):
    BM_compatible = True

    PATTERN = """"""
    power< 'execfile' trailer< '(' arglist< filename=any [',' globals=any [',' locals=any ] ] > ')' > >
    |
    power< 'execfile' trailer< '(' filename=any ')' > >
    """"""

    def transform(self, node, results):
        assert results
        filename = results[""filename""]
        globals = results.get(""globals"")
        locals = results.get(""locals"")

        # Copy over the prefix from the right parentheses end of the execfile
        # call.
        execfile_paren = node.children[-1].children[-1].clone()
        # Construct open().read().
        open_args = ArgList([filename.clone()], rparen=execfile_paren)
        open_call = Node(syms.power, [Name(u""open""), open_args])
        read = [Node(syms.trailer, [Dot(), Name(u'read')]),
                Node(syms.trailer, [LParen(), RParen()])]
        open_expr = [open_call] + read
        # Wrap the open call in a compile call. This is so the filename will be
        # preserved in the execed code.
        filename_arg = filename.clone()
        filename_arg.prefix = u"" ""
        exec_str = String(u""'exec'"", u"" "")
        compile_args = open_expr + [Comma(), filename_arg, Comma(), exec_str]
        compile_call = Call(Name(u""compile""), compile_args, u"""")
        # Finally, replace the execfile call with an exec call.
        args = [compile_call]
        if globals is not None:
            args.extend([Comma(), globals.clone()])
        if locals is not None:
            args.extend([Comma(), locals.clone()])
        return Call(Name(u""exec""), args, prefix=node.prefix)
","
1# Copyright 2006 Google, Inc. All Rights Reserved.
2# Licensed to PSF under a Contributor Agreement.
3
4""""""Fixer for execfile.
5
6This converts usages of the execfile function into calls to the built-in
7exec() function.
8""""""
9
10from .. import fixer_base
11from ..fixer_util import (Comma, Name, Call, LParen, RParen, Dot, Node,
12                          ArgList, String, syms)
13
14
15class FixExecfile(fixer_base.BaseFix):
16    BM_compatible = True
17
18    PATTERN = """"""
19    power< 'execfile' trailer< '(' arglist< filename=any [',' globals=any [',' locals=any ] ] > ')' > >
20    |
21    power< 'execfile' trailer< '(' filename=any ')' > >
22    """"""
23
24    def transform(self, node, results):
25        filename = results[""filename""]
26        globals = results.get(""globals"")
27        locals = results.get(""locals"")
28
29        # Copy over the prefix from the right parentheses end of the execfile
30        # call.
31        execfile_paren = node.children[-1].children[-1].clone()
32        # Construct open().read().
33        open_args = ArgList([filename.clone()], rparen=execfile_paren)
34        open_call = Node(syms.power, [Name(u""open""), open_args])
35        read = [Node(syms.trailer, [Dot(), Name(u'read')]),
36                Node(syms.trailer, [LParen(), RParen()])]
37        open_expr = [open_call] + read
38        # Wrap the open call in a compile call. This is so the filename will be
39        # preserved in the execed code.
40        filename_arg = filename.clone()
41        filename_arg.prefix = u"" ""
42        exec_str = String(u""'exec'"", u"" "")
43        compile_args = open_expr + [Comma(), filename_arg, Comma(), exec_str]
44        compile_call = Call(Name(u""compile""), compile_args, u"""")
45        # Finally, replace the execfile call with an exec call.
46        args = [compile_call]
47        if globals is not None:
48            args.extend([Comma(), globals.clone()])
49        if locals is not None:
50            args.extend([Comma(), locals.clone()])
51        return Call(Name(u""exec""), args, prefix=node.prefix)
52","[['results', '==', 'True']]",1,1,1.0,0.0005005005005005,"['BM_compatible', 'PATTERN', 'node', 'results', 'filename', 'globals', 'locals', 'execfile_paren', 'open_args', 'open_call', 'read', 'open_expr', 'filename_arg', 'filename_arg.prefix', 'exec_str', 'compile_args', 'compile_call', 'args']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['BM_compatible', 'PATTERN', 'node', 'results', 'filename', 'globals', 'locals', 'execfile_paren', 'open_args', 'open_call', 'read', 'open_expr', 'filename_arg', 'filename_arg.prefix', 'exec_str', 'compile_args', 'compile_call', 'args']
*Code:

1# Copyright 2006 Google, Inc. All Rights Reserved.
2# Licensed to PSF under a Contributor Agreement.
3
4""""""Fixer for execfile.
5
6This converts usages of the execfile function into calls to the built-in
7exec() function.
8""""""
9
10from .. import fixer_base
11from ..fixer_util import (Comma, Name, Call, LParen, RParen, Dot, Node,
12                          ArgList, String, syms)
13
14
15class FixExecfile(fixer_base.BaseFix):
16    BM_compatible = True
17
18    PATTERN = """"""
19    power< 'execfile' trailer< '(' arglist< filename=any [',' globals=any [',' locals=any ] ] > ')' > >
20    |
21    power< 'execfile' trailer< '(' filename=any ')' > >
22    """"""
23
24    def transform(self, node, results):
25        filename = results[""filename""]
26        globals = results.get(""globals"")
27        locals = results.get(""locals"")
28
29        # Copy over the prefix from the right parentheses end of the execfile
30        # call.
31        execfile_paren = node.children[-1].children[-1].clone()
32        # Construct open().read().
33        open_args = ArgList([filename.clone()], rparen=execfile_paren)
34        open_call = Node(syms.power, [Name(u""open""), open_args])
35        read = [Node(syms.trailer, [Dot(), Name(u'read')]),
36                Node(syms.trailer, [LParen(), RParen()])]
37        open_expr = [open_call] + read
38        # Wrap the open call in a compile call. This is so the filename will be
39        # preserved in the execed code.
40        filename_arg = filename.clone()
41        filename_arg.prefix = u"" ""
42        exec_str = String(u""'exec'"", u"" "")
43        compile_args = open_expr + [Comma(), filename_arg, Comma(), exec_str]
44        compile_call = Call(Name(u""compile""), compile_args, u"""")
45        # Finally, replace the execfile call with an exec call.
46        args = [compile_call]
47        if globals is not None:
48            args.extend([Comma(), globals.clone()])
49        if locals is not None:
50            args.extend([Comma(), locals.clone()])
51        return Call(Name(u""exec""), args, prefix=node.prefix)
52",3687,"[[15, 'BM_compatible', '==', True, ""BM_compatible flag should always be True for compatibility""],
 [23, 'node', '!=', None, ""node should not be None""],
 [23, 'results', '!=', None, ""results should not be None""],
 [24, 'filename', '!=', None, ""filename should not be None in results dict""],
 [45, 'args', '!=', None, ""args should not be None before entering in exec call""],
 [47, 'globals', '!=', None, ""globals should not be None before extending in args""],
 [49, 'locals', '!=', None, ""locals should not be None before extending in args""]]"
MalloyPower/parsing-python,""""""" Python 'bz2_codec' Codec - bz2 compression encoding

    Unlike most of the other codecs which target Unicode, this codec
    will return Python string objects for both encode and decode.

    Adapted by Raymond Hettinger from zlib_codec.py which was written
    by Marc-Andre Lemburg (mal@lemburg.com).

""""""
import codecs
import bz2 # this codec needs the optional bz2 module !

### Codec APIs

def bz2_encode(input,errors='strict'):

    """""" Encodes the object input and returns a tuple (output
        object, length consumed).

        errors defines the error handling to apply. It defaults to
        'strict' handling which is the only currently supported
        error handling for this codec.

    """"""
    assert errors == 'strict'
    output = bz2.compress(input)
    return (output, len(input))

def bz2_decode(input,errors='strict'):

    """""" Decodes the object input and returns a tuple (output
        object, length consumed).

        input must be an object which provides the bf_getreadbuf
        buffer slot. Python strings, buffer objects and memory
        mapped files are examples of objects providing this slot.

        errors defines the error handling to apply. It defaults to
        'strict' handling which is the only currently supported
        error handling for this codec.

    """"""
    assert errors == 'strict'
    output = bz2.decompress(input)
    return (output, len(input))

class Codec(codecs.Codec):

    def encode(self, input, errors='strict'):
        return bz2_encode(input, errors)
    def decode(self, input, errors='strict'):
        return bz2_decode(input, errors)

class StreamWriter(Codec,codecs.StreamWriter):
    pass

class StreamReader(Codec,codecs.StreamReader):
    pass

### encodings module API

def getregentry():

    return (bz2_encode,bz2_decode,StreamReader,StreamWriter)
","
1"""""" Python 'bz2_codec' Codec - bz2 compression encoding
2
3    Unlike most of the other codecs which target Unicode, this codec
4    will return Python string objects for both encode and decode.
5
6    Adapted by Raymond Hettinger from zlib_codec.py which was written
7    by Marc-Andre Lemburg (mal@lemburg.com).
8
9""""""
10import codecs
11import bz2 # this codec needs the optional bz2 module !
12
13### Codec APIs
14
15def bz2_encode(input,errors='strict'):
16
17    """""" Encodes the object input and returns a tuple (output
18        object, length consumed).
19
20        errors defines the error handling to apply. It defaults to
21        'strict' handling which is the only currently supported
22        error handling for this codec.
23
24    """"""
25    output = bz2.compress(input)
26    return (output, len(input))
27
28def bz2_decode(input,errors='strict'):
29
30    """""" Decodes the object input and returns a tuple (output
31        object, length consumed).
32
33        input must be an object which provides the bf_getreadbuf
34        buffer slot. Python strings, buffer objects and memory
35        mapped files are examples of objects providing this slot.
36
37        errors defines the error handling to apply. It defaults to
38        'strict' handling which is the only currently supported
39        error handling for this codec.
40
41    """"""
42    output = bz2.decompress(input)
43    return (output, len(input))
44
45class Codec(codecs.Codec):
46
47    def encode(self, input, errors='strict'):
48        return bz2_encode(input, errors)
49    def decode(self, input, errors='strict'):
50        return bz2_decode(input, errors)
51
52class StreamWriter(Codec,codecs.StreamWriter):
53    pass
54
55class StreamReader(Codec,codecs.StreamReader):
56    pass
57
58### encodings module API
59
60def getregentry():
61
62    return (bz2_encode,bz2_decode,StreamReader,StreamWriter)
63","[['errors', '==', ""'strict'""], ['errors', '==', ""'strict'""]]",2,2,1.0,0.0010851871947911,"['input', 'errors', 'output']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['input', 'errors', 'output']
*Code:

1"""""" Python 'bz2_codec' Codec - bz2 compression encoding
2
3    Unlike most of the other codecs which target Unicode, this codec
4    will return Python string objects for both encode and decode.
5
6    Adapted by Raymond Hettinger from zlib_codec.py which was written
7    by Marc-Andre Lemburg (mal@lemburg.com).
8
9""""""
10import codecs
11import bz2 # this codec needs the optional bz2 module !
12
13### Codec APIs
14
15def bz2_encode(input,errors='strict'):
16
17    """""" Encodes the object input and returns a tuple (output
18        object, length consumed).
19
20        errors defines the error handling to apply. It defaults to
21        'strict' handling which is the only currently supported
22        error handling for this codec.
23
24    """"""
25    output = bz2.compress(input)
26    return (output, len(input))
27
28def bz2_decode(input,errors='strict'):
29
30    """""" Decodes the object input and returns a tuple (output
31        object, length consumed).
32
33        input must be an object which provides the bf_getreadbuf
34        buffer slot. Python strings, buffer objects and memory
35        mapped files are examples of objects providing this slot.
36
37        errors defines the error handling to apply. It defaults to
38        'strict' handling which is the only currently supported
39        error handling for this codec.
40
41    """"""
42    output = bz2.decompress(input)
43    return (output, len(input))
44
45class Codec(codecs.Codec):
46
47    def encode(self, input, errors='strict'):
48        return bz2_encode(input, errors)
49    def decode(self, input, errors='strict'):
50        return bz2_decode(input, errors)
51
52class StreamWriter(Codec,codecs.StreamWriter):
53    pass
54
55class StreamReader(Codec,codecs.StreamReader):
56    pass
57
58### encodings module API
59
60def getregentry():
61
62    return (bz2_encode,bz2_decode,StreamReader,StreamWriter)
63",3310,"[15, 'input', '!=', None, ""function bz2_encode requires an input object to be compressed""], 
[15, 'errors', '==', 'strict', ""this codec currently only supports 'strict' error handling""], 
[28, 'input', '!=', None, ""function bz2_decode requires an input object to be decompressed""],
[28, 'errors', '==', 'strict', ""this codec currently only supports 'strict' error handling""],
[47, 'input', '!=', None, ""method encode requires an input object to be compressed""], 
[47, 'errors', '==', 'strict', ""this codec currently only supports 'strict' error handling""], 
[49, 'input', '!=', None, ""method decode requires an input object to be decompressed""],
[49, 'errors', '==', 'strict', ""this codec currently only supports 'strict' error handling""]"
UnrememberMe/pants,"# coding=utf-8
# Copyright 2015 Pants project contributors (see CONTRIBUTORS.md).
# Licensed under the Apache License, Version 2.0 (see LICENSE).

from __future__ import (absolute_import, division, generators, nested_scopes, print_function,
                        unicode_literals, with_statement)

from pants.pantsd.service.pants_service import PantsService
from pants_test.base_test import BaseTest


class RunnableTestService(PantsService):
  def run(self): pass


class TestPantsService(BaseTest):
  def setUp(self):
    BaseTest.setUp(self)
    self.service = RunnableTestService()

  def test_init(self):
    self.assertTrue(self.service.name)

  def test_run_abstract(self):
    with self.assertRaises(TypeError):
      PantsService()

  def test_terminate(self):
    self.service.terminate()
    assert self.service.is_killed
","
1# coding=utf-8
2# Copyright 2015 Pants project contributors (see CONTRIBUTORS.md).
3# Licensed under the Apache License, Version 2.0 (see LICENSE).
4
5from __future__ import (absolute_import, division, generators, nested_scopes, print_function,
6                        unicode_literals, with_statement)
7
8from pants.pantsd.service.pants_service import PantsService
9from pants_test.base_test import BaseTest
10
11
12class RunnableTestService(PantsService):
13  def run(self): pass
14
15
16class TestPantsService(BaseTest):
17  def setUp(self):
18    BaseTest.setUp(self)
19    self.service = RunnableTestService()
20
21  def test_init(self):
22
23  def test_run_abstract(self):
24      PantsService()
25
26  def test_terminate(self):
27    self.service.terminate()
28","[['self.service.is_killed', '==', 'True']]",3,1,0.3333333333333333,0.0011976047904191,['self.service'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.service']
*Code:

1# coding=utf-8
2# Copyright 2015 Pants project contributors (see CONTRIBUTORS.md).
3# Licensed under the Apache License, Version 2.0 (see LICENSE).
4
5from __future__ import (absolute_import, division, generators, nested_scopes, print_function,
6                        unicode_literals, with_statement)
7
8from pants.pantsd.service.pants_service import PantsService
9from pants_test.base_test import BaseTest
10
11
12class RunnableTestService(PantsService):
13  def run(self): pass
14
15
16class TestPantsService(BaseTest):
17  def setUp(self):
18    BaseTest.setUp(self)
19    self.service = RunnableTestService()
20
21  def test_init(self):
22
23  def test_run_abstract(self):
24      PantsService()
25
26  def test_terminate(self):
27    self.service.terminate()
28",2167,"[[18, ""self.service"", ""=="", None, ""Ensure the service is initialized before testing""],
[27, ""self.service"", ""!="", None, ""Service should exist before being terminated""]]"
rnestler/LibrePCB,"#!/usr/bin/env python
# -*- coding: utf-8 -*-

""""""
Test creating a symbol with the library editor
""""""


def test(library_editor, helpers):
    """"""
    Create new symbol
    """"""
    le = library_editor

    # Open ""New Library Element"" wizard
    le.action('libraryEditorActionNewElement').trigger(blocking=False)

    # Choose type of element
    le.widget('libraryEditorNewElementWizardChooseTypeSymbolButton').click()

    # Enter metadata
    widget_properties = {
        ('NameEdit', 'text'): 'New Symbol',
        ('DescriptionEdit', 'plainText'): 'Foo Bar',
        ('KeywordsEdit', 'text'): '',
        ('AuthorEdit', 'text'): 'Functional Test',
        ('VersionEdit', 'text'): '1.2.3',
    }
    for (widget, property), value in widget_properties.items():
        le.widget('libraryEditorNewElementWizardMetadata' + widget).set_property(property, value)

    # Finish
    dialog = le.widget('libraryEditorNewElementWizard')
    le.widget('libraryEditorNewElementWizardFinishButton').click()
    helpers.wait_until_widget_hidden(dialog)

    # Check if a new tab is opened (indicates that the element was created)
    tab_props = le.widget('libraryEditorStackedWidget').properties()
    assert tab_props['count'] == 2
    assert tab_props['currentIndex'] == 1

    # Check metadata
    assert le.widget('libraryEditorSymbolNameEdit').properties()['text'] == 'New Symbol'
    assert le.widget('libraryEditorSymbolDescriptionEdit').properties()['plainText'] == 'Foo Bar'
    assert le.widget('libraryEditorSymbolKeywordsEdit').properties()['text'] == ''
    assert le.widget('libraryEditorSymbolAuthorEdit').properties()['text'] == 'Functional Test'
    assert le.widget('libraryEditorSymbolVersionEdit').properties()['text'] == '1.2.3'
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4""""""
5Test creating a symbol with the library editor
6""""""
7
8
9def test(library_editor, helpers):
10    """"""
11    Create new symbol
12    """"""
13    le = library_editor
14
15    # Open ""New Library Element"" wizard
16    le.action('libraryEditorActionNewElement').trigger(blocking=False)
17
18    # Choose type of element
19    le.widget('libraryEditorNewElementWizardChooseTypeSymbolButton').click()
20
21    # Enter metadata
22    widget_properties = {
23        ('NameEdit', 'text'): 'New Symbol',
24        ('DescriptionEdit', 'plainText'): 'Foo Bar',
25        ('KeywordsEdit', 'text'): '',
26        ('AuthorEdit', 'text'): 'Functional Test',
27        ('VersionEdit', 'text'): '1.2.3',
28    }
29    for (widget, property), value in widget_properties.items():
30        le.widget('libraryEditorNewElementWizardMetadata' + widget).set_property(property, value)
31
32    # Finish
33    dialog = le.widget('libraryEditorNewElementWizard')
34    le.widget('libraryEditorNewElementWizardFinishButton').click()
35    helpers.wait_until_widget_hidden(dialog)
36
37    # Check if a new tab is opened (indicates that the element was created)
38    tab_props = le.widget('libraryEditorStackedWidget').properties()
39
40    # Check metadata
41","[[""tab_props['count']"", '==', '2'], [""tab_props['currentIndex']"", '==', '1'], [""le.widget('libraryEditorSymbolNameEdit').properties()['text']"", '==', ""'New Symbol'""], [""le.widget('libraryEditorSymbolDescriptionEdit').properties()['plainText']"", '==', ""'Foo Bar'""], [""le.widget('libraryEditorSymbolKeywordsEdit').properties()['text']"", '==', ""''""], [""le.widget('libraryEditorSymbolAuthorEdit').properties()['text']"", '==', ""'Functional Test'""], [""le.widget('libraryEditorSymbolVersionEdit').properties()['text']"", '==', ""'1.2.3'""]]",7,7,1.0,0.0040137614678899,"['library_editor', 'helpers', 'le', 'widget_properties', 'dialog', 'tab_props']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['library_editor', 'helpers', 'le', 'widget_properties', 'dialog', 'tab_props']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4""""""
5Test creating a symbol with the library editor
6""""""
7
8
9def test(library_editor, helpers):
10    """"""
11    Create new symbol
12    """"""
13    le = library_editor
14
15    # Open ""New Library Element"" wizard
16    le.action('libraryEditorActionNewElement').trigger(blocking=False)
17
18    # Choose type of element
19    le.widget('libraryEditorNewElementWizardChooseTypeSymbolButton').click()
20
21    # Enter metadata
22    widget_properties = {
23        ('NameEdit', 'text'): 'New Symbol',
24        ('DescriptionEdit', 'plainText'): 'Foo Bar',
25        ('KeywordsEdit', 'text'): '',
26        ('AuthorEdit', 'text'): 'Functional Test',
27        ('VersionEdit', 'text'): '1.2.3',
28    }
29    for (widget, property), value in widget_properties.items():
30        le.widget('libraryEditorNewElementWizardMetadata' + widget).set_property(property, value)
31
32    # Finish
33    dialog = le.widget('libraryEditorNewElementWizard')
34    le.widget('libraryEditorNewElementWizardFinishButton').click()
35    helpers.wait_until_widget_hidden(dialog)
36
37    # Check if a new tab is opened (indicates that the element was created)
38    tab_props = le.widget('libraryEditorStackedWidget').properties()
39
40    # Check metadata
41",2747,"[[9, 'library_editor', '!=', None, ""the function requires a library editor to perform operations""],
[9, 'helpers', '!=', None, ""helper libraries are required to assist with functions""],
[15, 'le', '!=', None, ""the local equivalent of library_editor is required""],
[32, 'dialog', '!=', None, ""dialog widget is used to interact with the user""],
[38, 'tab_props', '!=', None, ""tab properties required to check GUI elements""]]"
deepmind/dm_nevis,"# Copyright 2022 DeepMind Technologies Limited
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""UMD handler.""""""

import os

from dm_nevis.datasets_storage.handlers import extraction_utils as utils
from dm_nevis.datasets_storage.handlers import splits
from dm_nevis.datasets_storage.handlers import types

from tensorflow.io import gfile

_NUM_CLASSES = 25
_IGNORED_FILES_REGEX = r'.*\.db$'


def _label_from_filename(filename: str) -> int:
  """"""Extracts a label given a filename for the UMD dataset.""""""
  label = int(os.path.split(os.path.split(filename)[0])[1])
  label -= 1
  assert  0 <= label <= _NUM_CLASSES-1
  return label


def umd_handler(dataset_path: str) -> types.HandlerOutput:
  """"""Imports UMD Texture dataset.

  The dataset home page is at
  http://users.umiacs.umd.edu/~fer/website-texture/texture.htm.
  The dataset comes with two zip files containing 12 and 13 directories
  (one per class) for a total of 25 classes.
  We define the mapping from directory name to labels by subtracting one from it
  as the class directories start from 1 (and go to 25).
  The dataset does not come with a pre-defined train/ val/ test splits. We
  define those ourselves.

  Args:
    dataset_path: Path with downloaded artifacts.

  Returns:
    Metadata and generator functions.
  """"""
  ds_files = gfile.listdir(dataset_path)
  assert len(ds_files) == 2

  metadata = types.DatasetMetaData(
      num_classes=_NUM_CLASSES,
      num_channels=1,
      image_shape=(),  # Ignored for now.
      additional_metadata=dict(
          task_type='classification',
          image_type='texture'))

  def make_gen_fn():
    return utils.generate_images_from_zip_files(
        dataset_path,
        ds_files,
        path_to_label_fn=_label_from_filename,
        ignored_files_regex=_IGNORED_FILES_REGEX)

  per_split_gen = splits.random_split_generator_into_splits_with_fractions(
      make_gen_fn, splits.SPLIT_WITH_FRACTIONS_FOR_ALL_DATA,
      splits.MERGED_TRAIN_AND_DEV)
  return metadata, per_split_gen


umd_dataset = types.DownloadableDataset(
    name='umd',
    download_urls=[
        types.DownloadableArtefact(
            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-1.zip',
            checksum='818b5b13035374cffd4db604e718ddbf'),
        types.DownloadableArtefact(
            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-2.zip',
            checksum='e9853d0f7eaa9e57c4756e9017d0cbc9')
    ],
    website_url='http://users.umiacs.umd.edu/~fer/website-texture/texture.htm',
    paper_title='A projective invariant for textures',
    authors='Yong Xu and Hui Ji and Cornelia Fermuller',
    year='2006',
    handler=umd_handler,
)
","
1# Copyright 2022 DeepMind Technologies Limited
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#      http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15""""""UMD handler.""""""
16
17import os
18
19from dm_nevis.datasets_storage.handlers import extraction_utils as utils
20from dm_nevis.datasets_storage.handlers import splits
21from dm_nevis.datasets_storage.handlers import types
22
23from tensorflow.io import gfile
24
25_NUM_CLASSES = 25
26_IGNORED_FILES_REGEX = r'.*\.db$'
27
28
29def _label_from_filename(filename: str) -> int:
30  """"""Extracts a label given a filename for the UMD dataset.""""""
31  label = int(os.path.split(os.path.split(filename)[0])[1])
32  label -= 1
33  return label
34
35
36def umd_handler(dataset_path: str) -> types.HandlerOutput:
37  """"""Imports UMD Texture dataset.
38
39  The dataset home page is at
40  http://users.umiacs.umd.edu/~fer/website-texture/texture.htm.
41  The dataset comes with two zip files containing 12 and 13 directories
42  (one per class) for a total of 25 classes.
43  We define the mapping from directory name to labels by subtracting one from it
44  as the class directories start from 1 (and go to 25).
45  The dataset does not come with a pre-defined train/ val/ test splits. We
46  define those ourselves.
47
48  Args:
49    dataset_path: Path with downloaded artifacts.
50
51  Returns:
52    Metadata and generator functions.
53  """"""
54  ds_files = gfile.listdir(dataset_path)
55
56  metadata = types.DatasetMetaData(
57      num_classes=_NUM_CLASSES,
58      num_channels=1,
59      image_shape=(),  # Ignored for now.
60      additional_metadata=dict(
61          task_type='classification',
62          image_type='texture'))
63
64  def make_gen_fn():
65    return utils.generate_images_from_zip_files(
66        dataset_path,
67        ds_files,
68        path_to_label_fn=_label_from_filename,
69        ignored_files_regex=_IGNORED_FILES_REGEX)
70
71  per_split_gen = splits.random_split_generator_into_splits_with_fractions(
72      make_gen_fn, splits.SPLIT_WITH_FRACTIONS_FOR_ALL_DATA,
73      splits.MERGED_TRAIN_AND_DEV)
74  return metadata, per_split_gen
75
76
77umd_dataset = types.DownloadableDataset(
78    name='umd',
79    download_urls=[
80        types.DownloadableArtefact(
81            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-1.zip',
82            checksum='818b5b13035374cffd4db604e718ddbf'),
83        types.DownloadableArtefact(
84            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-2.zip',
85            checksum='e9853d0f7eaa9e57c4756e9017d0cbc9')
86    ],
87    website_url='http://users.umiacs.umd.edu/~fer/website-texture/texture.htm',
88    paper_title='A projective invariant for textures',
89    authors='Yong Xu and Hui Ji and Cornelia Fermuller',
90    year='2006',
91    handler=umd_handler,
92)
93","[['0', '<=', 'label <= _NUM_CLASSES-1'], ['len(ds_files)', '==', '2']]",2,2,1.0,0.0006238303181534,"['_NUM_CLASSES', '_IGNORED_FILES_REGEX', 'filename: str', 'label', 'dataset_path: str', 'ds_files', 'metadata', 'per_split_gen', 'umd_dataset']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_NUM_CLASSES', '_IGNORED_FILES_REGEX', 'filename: str', 'label', 'dataset_path: str', 'ds_files', 'metadata', 'per_split_gen', 'umd_dataset']
*Code:

1# Copyright 2022 DeepMind Technologies Limited
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#      http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15""""""UMD handler.""""""
16
17import os
18
19from dm_nevis.datasets_storage.handlers import extraction_utils as utils
20from dm_nevis.datasets_storage.handlers import splits
21from dm_nevis.datasets_storage.handlers import types
22
23from tensorflow.io import gfile
24
25_NUM_CLASSES = 25
26_IGNORED_FILES_REGEX = r'.*\.db$'
27
28
29def _label_from_filename(filename: str) -> int:
30  """"""Extracts a label given a filename for the UMD dataset.""""""
31  label = int(os.path.split(os.path.split(filename)[0])[1])
32  label -= 1
33  return label
34
35
36def umd_handler(dataset_path: str) -> types.HandlerOutput:
37  """"""Imports UMD Texture dataset.
38
39  The dataset home page is at
40  http://users.umiacs.umd.edu/~fer/website-texture/texture.htm.
41  The dataset comes with two zip files containing 12 and 13 directories
42  (one per class) for a total of 25 classes.
43  We define the mapping from directory name to labels by subtracting one from it
44  as the class directories start from 1 (and go to 25).
45  The dataset does not come with a pre-defined train/ val/ test splits. We
46  define those ourselves.
47
48  Args:
49    dataset_path: Path with downloaded artifacts.
50
51  Returns:
52    Metadata and generator functions.
53  """"""
54  ds_files = gfile.listdir(dataset_path)
55
56  metadata = types.DatasetMetaData(
57      num_classes=_NUM_CLASSES,
58      num_channels=1,
59      image_shape=(),  # Ignored for now.
60      additional_metadata=dict(
61          task_type='classification',
62          image_type='texture'))
63
64  def make_gen_fn():
65    return utils.generate_images_from_zip_files(
66        dataset_path,
67        ds_files,
68        path_to_label_fn=_label_from_filename,
69        ignored_files_regex=_IGNORED_FILES_REGEX)
70
71  per_split_gen = splits.random_split_generator_into_splits_with_fractions(
72      make_gen_fn, splits.SPLIT_WITH_FRACTIONS_FOR_ALL_DATA,
73      splits.MERGED_TRAIN_AND_DEV)
74  return metadata, per_split_gen
75
76
77umd_dataset = types.DownloadableDataset(
78    name='umd',
79    download_urls=[
80        types.DownloadableArtefact(
81            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-1.zip',
82            checksum='818b5b13035374cffd4db604e718ddbf'),
83        types.DownloadableArtefact(
84            url='http://users.umiacs.umd.edu/~fer/High-resolution-data-base/textures-2.zip',
85            checksum='e9853d0f7eaa9e57c4756e9017d0cbc9')
86    ],
87    website_url='http://users.umiacs.umd.edu/~fer/website-texture/texture.htm',
88    paper_title='A projective invariant for textures',
89    authors='Yong Xu and Hui Ji and Cornelia Fermuller',
90    year='2006',
91    handler=umd_handler,
92)
93",4840,"[[29, 'filename: str', '!=', '', 'filename should not be empty because it is needed for identifying unique files'],
 [36, 'dataset_path: str', '!=', '', 'dataset_path should not be empty as it is the directory of the data files'],
 [57, 'metadata.num_classes', '==', '_NUM_CLASSES', 'the number of classes in the metadata should match _NUM_CLASSES definition'],
 [58, 'metadata.num_channels', '>=', 1, 'number of channels in metadata should be greater or equal to 1, because each image should have at least one channel (black and white)'],
 [71, 'per_split_gen', '!=', None, 'per_split_gen should not be None to ensure the data is split properly'],
 [77, 'umd_dataset.name', '!=', '', 'umd_dataset name should not be empty as this name is used for data identification'],
 [91, 'umd_dataset.handler', '==', 'umd_handler', 'the handler of the umd_dataset should be umd_handler to handle UMD dataset properly']]"
tallforasmurf/PPQT2,"__license__ = '''
 License (GPL-3.0) :
    This file is part of PPQT Version 2.
    PPQT is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You can find a copy of the GNU General Public License in the file
    extras/COPYING.TXT included in the distribution of this program, or see:
    <http://www.gnu.org/licenses/>.
'''
__version__ = ""2.0.0""
__author__  = ""David Cortesi""
__copyright__ = ""Copyright 2013, 2014 David Cortesi""
__maintainer__ = ""David Cortesi""
__email__ = ""tallforasmurf@yahoo.com""

'''
Unit test for helpview.py
'''
assert 'implemented' == 'not yet'
","
1__license__ = '''
2 License (GPL-3.0) :
3    This file is part of PPQT Version 2.
4    PPQT is free software: you can redistribute it and/or modify
5    it under the terms of the GNU General Public License as published by
6    the Free Software Foundation, either version 3 of the License, or
7    (at your option) any later version.
8
9    This program is distributed in the hope that it will be useful,
10    but WITHOUT ANY WARRANTY; without even the implied warranty of
11    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12    GNU General Public License for more details.
13
14    You can find a copy of the GNU General Public License in the file
15    extras/COPYING.TXT included in the distribution of this program, or see:
16    <http://www.gnu.org/licenses/>.
17'''
18__version__ = ""2.0.0""
19__author__  = ""David Cortesi""
20__copyright__ = ""Copyright 2013, 2014 David Cortesi""
21__maintainer__ = ""David Cortesi""
22__email__ = ""tallforasmurf@yahoo.com""
23
24'''
25Unit test for helpview.py
26'''
27","[[""'implemented'"", '==', ""'not yet'""]]",1,1,1.0,0.0009881422924901,"['__license__', '__version__', '__author__', '__copyright__', '__maintainer__', '__email__']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__license__', '__version__', '__author__', '__copyright__', '__maintainer__', '__email__']
*Code:

1__license__ = '''
2 License (GPL-3.0) :
3    This file is part of PPQT Version 2.
4    PPQT is free software: you can redistribute it and/or modify
5    it under the terms of the GNU General Public License as published by
6    the Free Software Foundation, either version 3 of the License, or
7    (at your option) any later version.
8
9    This program is distributed in the hope that it will be useful,
10    but WITHOUT ANY WARRANTY; without even the implied warranty of
11    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
12    GNU General Public License for more details.
13
14    You can find a copy of the GNU General Public License in the file
15    extras/COPYING.TXT included in the distribution of this program, or see:
16    <http://www.gnu.org/licenses/>.
17'''
18__version__ = ""2.0.0""
19__author__  = ""David Cortesi""
20__copyright__ = ""Copyright 2013, 2014 David Cortesi""
21__maintainer__ = ""David Cortesi""
22__email__ = ""tallforasmurf@yahoo.com""
23
24'''
25Unit test for helpview.py
26'''
27",2496,"[[18, '__version__', '==', ""2.0.0"", ""version must be 2.0.0""],
 [19, '__author__', '==', ""David Cortesi"", ""author must be David Cortesi""],
 [20, '__copyright__', '==', ""Copyright 2013, 2014 David Cortesi"", ""Copyright must be for David Cortesi from 2013 and 2014""],
 [21, '__maintainer__', '==', ""David Cortesi"", ""Maintainer must be David Cortesi""],
 [22, '__email__', '==', ""tallforasmurf@yahoo.com"", ""Email must be tallforasmurf@yahoo.com""]]"
zen/solar,"#    Copyright 2015 Mirantis, Inc.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import pytest

from solar.dblayer.model import clear_cache
from solar.dblayer.model import DBLayerException
from solar.dblayer.model import DBLayerNoRiakObj
from solar.dblayer.model import DBLayerNotFound
from solar.dblayer.model import Field
from solar.dblayer.model import IndexField
from solar.dblayer.model import Model
from solar.dblayer.model import StrInt


class M1(Model):

    f1 = Field(str)
    f2 = Field(int)
    f3 = Field(int, fname='some_field')

    ind = IndexField(default=dict)


class M2(Model):
    f1 = Field(str)

    ind = IndexField(default=dict)


class M3(Model):
    f1 = Field(str)

    ind = IndexField(default=dict)


def test_from_dict(rk):
    key = next(rk)

    with pytest.raises(DBLayerException):
        M1.from_dict({'f1': 'blah', 'f2': 150, 'some_field': 250})

    m1 = M1.from_dict({'key': key, 'f1': 'blah', 'f2': 150, 'some_field': 250})

    m1.save()
    m11 = M1.get(key)
    assert m1.key == key
    assert m1.f3 == 250
    assert m1 is m11


def test_not_exists(rk):
    key = next(rk)
    with pytest.raises(DBLayerNotFound):
        M1.get(key)

    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
    m1.save()
    M1.get(key)


def test_update(rk):
    k = next(rk)
    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
    m1.save()
    m1.f1 = 'blub'
    assert m1.f1 == 'blub'
    m1.save()
    assert m1.f1 == 'blub'
    m11 = M1.get(k)
    assert m11.f1 == 'blub'

    clear_cache()
    m12 = M1.get(k)
    assert m12.f1 == 'blub'


def test_lazy(rk):
    k = next(rk)
    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
    m1.save()
    clear_cache()

    m1 = M1(k)
    with pytest.raises(DBLayerNoRiakObj):
        assert m1.f1 == 'blah'


def test_cache_logic(rk):
    k = next(rk)
    M1.session_start()
    assert M1._c.obj_cache == {}

    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
    m1.save()
    M1.session_end()

    M1.session_start()
    assert M1._c.obj_cache == {}
    m11 = M1.get(k)
    pid = id(M1._c)
    assert M1._c.obj_cache == {k: m11}
    M1.session_end()

    M1.session_start()
    assert M1._c.obj_cache == {}
    M1.get(k)
    aid = id(M1._c)

    assert pid != aid


def test_normal_index(rk):
    key = next(rk)
    key2 = next(rk)

    m1 = M1.from_dict(key, {'f1': 'blah',
                            'f2': 150,
                            'ind': {'blah': 'something'}})
    m1.save()

    m2 = M1.from_dict(key2, {'f1': 'blah',
                             'f2': 150,
                             'ind': {'blah': 'something2'}})
    m2.save()
    assert set(M1.ind.filter('blah=somethi*')) == set([key, key2])
    assert set(M1.ind.filter('blah=something')) == set([key])
    assert set(M1.ind.filter('blah=something2')) == set([key2])


def test_update_behaviour(rk):
    key = next(rk)

    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
    assert m1.changed() is True
    m1.save()

    assert m1.changed() is False
    with pytest.raises(DBLayerException):
        m1.save()

    m1.f1 = 'updated'
    assert m1.changed() is True

    m1.save()

    assert m1.f1 == 'updated'

    clear_cache()
    m11 = M1.get(key)
    assert m11.f1 == 'updated'


def test_different_models(rk):
    key = next(rk)

    m2 = M2.from_dict(key, {'f1': 'm2', 'ind': {'blah': 'blub'}})
    m3 = M3.from_dict(key, {'f1': 'm3', 'ind': {'blah': 'blub'}})

    m2.save()
    m3.save()

    assert M2.get(key).f1 == 'm2'
    assert M3.get(key).f1 == 'm3'


def test_cache_behaviour(rk):
    key1 = next(rk)

    m1 = M1.from_dict(key1, {'f1': 'm1'})

    m11 = M1.get(key1)
    assert m1 is m11
    m1.save()
    assert m1 is m11

    m12 = M1.get(key1)
    assert m1 is m12

    clear_cache()
    m13 = M1.get(key1)
    assert m1 is not m13


def test_save_lazy(rk):
    key1 = next(rk)
    key2 = next(rk)

    m1 = M1.from_dict(key1, {'f1': 'm1'})
    m2 = M1.from_dict(key2, {'f1': 'm2'})
    m1.save_lazy()
    m2.save_lazy()

    m1g = M1.get(key1)
    m2g = M1.get(key2)

    assert m1 is m1g
    assert m2 is m2g

    assert M1._c.lazy_save == {m1, m2}
    M1.session_end()
    assert M1._c.lazy_save == set()

    clear_cache()
    m1g2 = M1.get(key1)
    m2g2 = M1.get(key2)

    assert m1g is not m1g2
    assert m2g is not m2g2


def test_changed_index(rk):
    key1 = next(rk)

    m1 = M1.from_dict(key1, {'f1': 'm1'})

    m1.save()
    # don't use _add_index directly
    m1._add_index('test_bin', 'blah')
    m1.save()


def test_strint_comparsions():
    a = StrInt(-1)
    b = StrInt(-2)
    c = StrInt.to_simple(b)
    assert isinstance(c, basestring)
    assert a > b
    assert a > c


def test_delete_cache_behaviour(rk):
    key1 = next(rk)

    m1 = M1.from_dict(key1, {'f1': 'm1'})

    m1.save()

    clear_cache()

    M1.get(key1).delete()
    with pytest.raises(DBLayerNotFound):
        M1.get(key1)


def test_fast_delete(rk):
    key1 = next(rk)

    m1 = M1.from_dict(key1, {'f1': 'm1'})
    m1.save()
    m1.delete()
    M1.session_start()
    m12 = M1.from_dict(key1, {'f1': 'm12'})
    m12.save()
    assert m12.f1 == 'm12'
","
1#    Copyright 2015 Mirantis, Inc.
2#
3#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
4#    not use this file except in compliance with the License. You may obtain
5#    a copy of the License at
6#
7#         http://www.apache.org/licenses/LICENSE-2.0
8#
9#    Unless required by applicable law or agreed to in writing, software
10#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
11#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
12#    License for the specific language governing permissions and limitations
13#    under the License.
14
15import pytest
16
17from solar.dblayer.model import clear_cache
18from solar.dblayer.model import DBLayerException
19from solar.dblayer.model import DBLayerNoRiakObj
20from solar.dblayer.model import DBLayerNotFound
21from solar.dblayer.model import Field
22from solar.dblayer.model import IndexField
23from solar.dblayer.model import Model
24from solar.dblayer.model import StrInt
25
26
27class M1(Model):
28
29    f1 = Field(str)
30    f2 = Field(int)
31    f3 = Field(int, fname='some_field')
32
33    ind = IndexField(default=dict)
34
35
36class M2(Model):
37    f1 = Field(str)
38
39    ind = IndexField(default=dict)
40
41
42class M3(Model):
43    f1 = Field(str)
44
45    ind = IndexField(default=dict)
46
47
48def test_from_dict(rk):
49    key = next(rk)
50
51    with pytest.raises(DBLayerException):
52        M1.from_dict({'f1': 'blah', 'f2': 150, 'some_field': 250})
53
54    m1 = M1.from_dict({'key': key, 'f1': 'blah', 'f2': 150, 'some_field': 250})
55
56    m1.save()
57    m11 = M1.get(key)
58
59
60def test_not_exists(rk):
61    key = next(rk)
62    with pytest.raises(DBLayerNotFound):
63        M1.get(key)
64
65    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
66    m1.save()
67    M1.get(key)
68
69
70def test_update(rk):
71    k = next(rk)
72    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
73    m1.save()
74    m1.f1 = 'blub'
75    m1.save()
76    m11 = M1.get(k)
77
78    clear_cache()
79    m12 = M1.get(k)
80
81
82def test_lazy(rk):
83    k = next(rk)
84    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
85    m1.save()
86    clear_cache()
87
88    m1 = M1(k)
89    with pytest.raises(DBLayerNoRiakObj):
90
91
92def test_cache_logic(rk):
93    k = next(rk)
94    M1.session_start()
95
96    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
97    m1.save()
98    M1.session_end()
99
100    M1.session_start()
101    m11 = M1.get(k)
102    pid = id(M1._c)
103    M1.session_end()
104
105    M1.session_start()
106    M1.get(k)
107    aid = id(M1._c)
108
109
110
111def test_normal_index(rk):
112    key = next(rk)
113    key2 = next(rk)
114
115    m1 = M1.from_dict(key, {'f1': 'blah',
116                            'f2': 150,
117                            'ind': {'blah': 'something'}})
118    m1.save()
119
120    m2 = M1.from_dict(key2, {'f1': 'blah',
121                             'f2': 150,
122                             'ind': {'blah': 'something2'}})
123    m2.save()
124
125
126def test_update_behaviour(rk):
127    key = next(rk)
128
129    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
130    m1.save()
131
132    with pytest.raises(DBLayerException):
133        m1.save()
134
135    m1.f1 = 'updated'
136
137    m1.save()
138
139
140    clear_cache()
141    m11 = M1.get(key)
142
143
144def test_different_models(rk):
145    key = next(rk)
146
147    m2 = M2.from_dict(key, {'f1': 'm2', 'ind': {'blah': 'blub'}})
148    m3 = M3.from_dict(key, {'f1': 'm3', 'ind': {'blah': 'blub'}})
149
150    m2.save()
151    m3.save()
152
153
154
155def test_cache_behaviour(rk):
156    key1 = next(rk)
157
158    m1 = M1.from_dict(key1, {'f1': 'm1'})
159
160    m11 = M1.get(key1)
161    m1.save()
162
163    m12 = M1.get(key1)
164
165    clear_cache()
166    m13 = M1.get(key1)
167
168
169def test_save_lazy(rk):
170    key1 = next(rk)
171    key2 = next(rk)
172
173    m1 = M1.from_dict(key1, {'f1': 'm1'})
174    m2 = M1.from_dict(key2, {'f1': 'm2'})
175    m1.save_lazy()
176    m2.save_lazy()
177
178    m1g = M1.get(key1)
179    m2g = M1.get(key2)
180
181
182    M1.session_end()
183
184    clear_cache()
185    m1g2 = M1.get(key1)
186    m2g2 = M1.get(key2)
187
188
189
190def test_changed_index(rk):
191    key1 = next(rk)
192
193    m1 = M1.from_dict(key1, {'f1': 'm1'})
194
195    m1.save()
196    # don't use _add_index directly
197    m1._add_index('test_bin', 'blah')
198    m1.save()
199
200
201def test_strint_comparsions():
202    a = StrInt(-1)
203    b = StrInt(-2)
204    c = StrInt.to_simple(b)
205
206
207def test_delete_cache_behaviour(rk):
208    key1 = next(rk)
209
210    m1 = M1.from_dict(key1, {'f1': 'm1'})
211
212    m1.save()
213
214    clear_cache()
215
216    M1.get(key1).delete()
217    with pytest.raises(DBLayerNotFound):
218        M1.get(key1)
219
220
221def test_fast_delete(rk):
222    key1 = next(rk)
223
224    m1 = M1.from_dict(key1, {'f1': 'm1'})
225    m1.save()
226    m1.delete()
227    M1.session_start()
228    m12 = M1.from_dict(key1, {'f1': 'm12'})
229    m12.save()
230","[['m1.key', '==', 'key'], ['m1.f3', '==', '250'], ['m1', '==', 'm11'], ['m1.f1', '==', ""'blub'""], ['m1.f1', '==', ""'blub'""], ['m11.f1', '==', ""'blub'""], ['m12.f1', '==', ""'blub'""], ['m1.f1', '==', ""'blah'""], ['M1._c.obj_cache', '==', '{}'], ['M1._c.obj_cache', '==', '{}'], ['M1._c.obj_cache', '==', '{k: m11}'], ['M1._c.obj_cache', '==', '{}'], ['pid', '!=', 'aid'], [""set(M1.ind.filter('blah=somethi*'))"", '==', 'set([key'], [""set(M1.ind.filter('blah=something'))"", '==', 'set([key])'], [""set(M1.ind.filter('blah=something2'))"", '==', 'set([key2])'], ['m1.changed()', '==', 'True'], ['m1.changed()', '==', 'False'], ['m1.changed()', '==', 'True'], ['m1.f1', '==', ""'updated'""], ['m11.f1', '==', ""'updated'""], ['M2.get(key).f1', '==', ""'m2'""], ['M3.get(key).f1', '==', ""'m3'""], ['m1', '==', 'm11'], ['m1', '==', 'm11'], ['m1', '==', 'm12'], ['m1', '==', 'not m13'], ['m1', '==', 'm1g'], ['m2', '==', 'm2g'], ['M1._c.lazy_save', '==', '{m1'], ['M1._c.lazy_save', '==', 'set()'], ['m1g', '==', 'not m1g2'], ['m2g', '==', 'not m2g2'], ['a', '>', 'b'], ['a', '>', 'c'], ['m12.f1', '==', ""'m12'""]]",37,36,0.972972972972973,0.0063637970655824,"['f1', 'f2', 'f3', 'ind', 'rk', 'key', 'm1', 'm11', 'k', 'm1.f1', 'm12', 'pid', 'aid', 'key2', 'm2', 'm3', 'key1', 'm13', 'm1g', 'm2g', 'm1g2', 'm2g2', 'a', 'b', 'c']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['f1', 'f2', 'f3', 'ind', 'rk', 'key', 'm1', 'm11', 'k', 'm1.f1', 'm12', 'pid', 'aid', 'key2', 'm2', 'm3', 'key1', 'm13', 'm1g', 'm2g', 'm1g2', 'm2g2', 'a', 'b', 'c']
*Code:

1#    Copyright 2015 Mirantis, Inc.
2#
3#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
4#    not use this file except in compliance with the License. You may obtain
5#    a copy of the License at
6#
7#         http://www.apache.org/licenses/LICENSE-2.0
8#
9#    Unless required by applicable law or agreed to in writing, software
10#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
11#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
12#    License for the specific language governing permissions and limitations
13#    under the License.
14
15import pytest
16
17from solar.dblayer.model import clear_cache
18from solar.dblayer.model import DBLayerException
19from solar.dblayer.model import DBLayerNoRiakObj
20from solar.dblayer.model import DBLayerNotFound
21from solar.dblayer.model import Field
22from solar.dblayer.model import IndexField
23from solar.dblayer.model import Model
24from solar.dblayer.model import StrInt
25
26
27class M1(Model):
28
29    f1 = Field(str)
30    f2 = Field(int)
31    f3 = Field(int, fname='some_field')
32
33    ind = IndexField(default=dict)
34
35
36class M2(Model):
37    f1 = Field(str)
38
39    ind = IndexField(default=dict)
40
41
42class M3(Model):
43    f1 = Field(str)
44
45    ind = IndexField(default=dict)
46
47
48def test_from_dict(rk):
49    key = next(rk)
50
51    with pytest.raises(DBLayerException):
52        M1.from_dict({'f1': 'blah', 'f2': 150, 'some_field': 250})
53
54    m1 = M1.from_dict({'key': key, 'f1': 'blah', 'f2': 150, 'some_field': 250})
55
56    m1.save()
57    m11 = M1.get(key)
58
59
60def test_not_exists(rk):
61    key = next(rk)
62    with pytest.raises(DBLayerNotFound):
63        M1.get(key)
64
65    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
66    m1.save()
67    M1.get(key)
68
69
70def test_update(rk):
71    k = next(rk)
72    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
73    m1.save()
74    m1.f1 = 'blub'
75    m1.save()
76    m11 = M1.get(k)
77
78    clear_cache()
79    m12 = M1.get(k)
80
81
82def test_lazy(rk):
83    k = next(rk)
84    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
85    m1.save()
86    clear_cache()
87
88    m1 = M1(k)
89    with pytest.raises(DBLayerNoRiakObj):
90
91
92def test_cache_logic(rk):
93    k = next(rk)
94    M1.session_start()
95
96    m1 = M1.from_dict(k, {'f1': 'blah', 'f2': 150})
97    m1.save()
98    M1.session_end()
99
100    M1.session_start()
101    m11 = M1.get(k)
102    pid = id(M1._c)
103    M1.session_end()
104
105    M1.session_start()
106    M1.get(k)
107    aid = id(M1._c)
108
109
110
111def test_normal_index(rk):
112    key = next(rk)
113    key2 = next(rk)
114
115    m1 = M1.from_dict(key, {'f1': 'blah',
116                            'f2': 150,
117                            'ind': {'blah': 'something'}})
118    m1.save()
119
120    m2 = M1.from_dict(key2, {'f1': 'blah',
121                             'f2': 150,
122                             'ind': {'blah': 'something2'}})
123    m2.save()
124
125
126def test_update_behaviour(rk):
127    key = next(rk)
128
129    m1 = M1.from_dict(key, {'f1': 'blah', 'f2': 150})
130    m1.save()
131
132    with pytest.raises(DBLayerException):
133        m1.save()
134
135    m1.f1 = 'updated'
136
137    m1.save()
138
139
140    clear_cache()
141    m11 = M1.get(key)
142
143
144def test_different_models(rk):
145    key = next(rk)
146
147    m2 = M2.from_dict(key, {'f1': 'm2', 'ind': {'blah': 'blub'}})
148    m3 = M3.from_dict(key, {'f1': 'm3', 'ind': {'blah': 'blub'}})
149
150    m2.save()
151    m3.save()
152
153
154
155def test_cache_behaviour(rk):
156    key1 = next(rk)
157
158    m1 = M1.from_dict(key1, {'f1': 'm1'})
159
160    m11 = M1.get(key1)
161    m1.save()
162
163    m12 = M1.get(key1)
164
165    clear_cache()
166    m13 = M1.get(key1)
167
168
169def test_save_lazy(rk):
170    key1 = next(rk)
171    key2 = next(rk)
172
173    m1 = M1.from_dict(key1, {'f1': 'm1'})
174    m2 = M1.from_dict(key2, {'f1': 'm2'})
175    m1.save_lazy()
176    m2.save_lazy()
177
178    m1g = M1.get(key1)
179    m2g = M1.get(key2)
180
181
182    M1.session_end()
183
184    clear_cache()
185    m1g2 = M1.get(key1)
186    m2g2 = M1.get(key2)
187
188
189
190def test_changed_index(rk):
191    key1 = next(rk)
192
193    m1 = M1.from_dict(key1, {'f1': 'm1'})
194
195    m1.save()
196    # don't use _add_index directly
197    m1._add_index('test_bin', 'blah')
198    m1.save()
199
200
201def test_strint_comparsions():
202    a = StrInt(-1)
203    b = StrInt(-2)
204    c = StrInt.to_simple(b)
205
206
207def test_delete_cache_behaviour(rk):
208    key1 = next(rk)
209
210    m1 = M1.from_dict(key1, {'f1': 'm1'})
211
212    m1.save()
213
214    clear_cache()
215
216    M1.get(key1).delete()
217    with pytest.raises(DBLayerNotFound):
218        M1.get(key1)
219
220
221def test_fast_delete(rk):
222    key1 = next(rk)
223
224    m1 = M1.from_dict(key1, {'f1': 'm1'})
225    m1.save()
226    m1.delete()
227    M1.session_start()
228    m12 = M1.from_dict(key1, {'f1': 'm12'})
229    m12.save()
230",6639,"[[27, 'f1', '==', 'str', 'Field f1 in M1 model should be a string'],
[29, 'f2', '==', 'int', 'Field f2 in M1 model should be an integer'],
[30, 'f3', '==', 'int', 'Field f3 in M1 model should be an integer'],
[36, 'f1', '==', 'str', 'Field f1 in M2 model should be a string'],
[41, 'f1', '==', 'str', 'Field f1 in M3 model should be a string'],
[54, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[57, 'm11', '!=', None, 'Object m11 should not be None after creation'],
[66, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[73, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[76, 'm11', '!=', None, 'Object m11 should not be None after creation'],
[79, 'm12', '!=', None, 'Object m12 should not be None after creation'],
[84, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[88, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[96, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[101, 'm11', '!=', None, 'Object m11 should not be None after creation'],
[118, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[123, 'm2', '!=', None, 'Object m2 should not be None after creation'],
[129, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[141, 'm11', '!=', None, 'Object m11 should not be None after creation'],
[147, 'm2', '!=', None, 'Object m2 should not be None after creation'],
[148, 'm3', '!=', None, 'Object m3 should not be None after creation'],
[158, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[160, 'm11', '!=', None, 'Object m11 should not be None after creation'],
[163, 'm12', '!=', None, 'Object m12 should not be None after creation'],
[173, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[174, 'm2', '!=', None, 'Object m2 should not be None after creation'],
[178, 'm1g', '!=', None, 'Object m1g should not be None after creation'],
[179, 'm2g', '!=', None, 'Object m2g should not be None after creation'],
[185, 'm1g2', '!=', None, 'Object m1g2 should not be None after creation'],
[186, 'm2g2', '!=', None, 'Object m2g2 should not be None after creation'],
[193, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[210, 'm1', '!=', None, 'Object m1 should not be None after creation'],
[224, 'm1', '!=', None, 'Object m1 should not be None after creation']]"
mKeRix/home-assistant,"""""""Tests for OwnTracks config flow.""""""
import pytest

from homeassistant import data_entry_flow
from homeassistant.components.owntracks import config_flow
from homeassistant.components.owntracks.config_flow import CONF_CLOUDHOOK, CONF_SECRET
from homeassistant.components.owntracks.const import DOMAIN
from homeassistant.config import async_process_ha_core_config
from homeassistant.const import CONF_WEBHOOK_ID
from homeassistant.setup import async_setup_component

from tests.async_mock import patch
from tests.common import MockConfigEntry

CONF_WEBHOOK_URL = ""webhook_url""

BASE_URL = ""http://example.com""
CLOUDHOOK = False
SECRET = ""test-secret""
WEBHOOK_ID = ""webhook_id""
WEBHOOK_URL = f""{BASE_URL}/api/webhook/webhook_id""


@pytest.fixture(name=""webhook_id"")
def mock_webhook_id():
    """"""Mock webhook_id.""""""
    with patch(
        ""homeassistant.components.webhook.async_generate_id"", return_value=WEBHOOK_ID
    ):
        yield


@pytest.fixture(name=""secret"")
def mock_secret():
    """"""Mock secret.""""""
    with patch(""secrets.token_hex"", return_value=SECRET):
        yield


@pytest.fixture(name=""not_supports_encryption"")
def mock_not_supports_encryption():
    """"""Mock non successful nacl import.""""""
    with patch(
        ""homeassistant.components.owntracks.config_flow.supports_encryption"",
        return_value=False,
    ):
        yield


async def init_config_flow(hass):
    """"""Init a configuration flow.""""""
    await async_process_ha_core_config(
        hass, {""external_url"": BASE_URL},
    )
    flow = config_flow.OwnTracksFlow()
    flow.hass = hass
    return flow


async def test_user(hass, webhook_id, secret):
    """"""Test user step.""""""
    flow = await init_config_flow(hass)

    result = await flow.async_step_user()
    assert result[""type""] == data_entry_flow.RESULT_TYPE_FORM
    assert result[""step_id""] == ""user""

    result = await flow.async_step_user({})
    assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
    assert result[""title""] == ""OwnTracks""
    assert result[""data""][CONF_WEBHOOK_ID] == WEBHOOK_ID
    assert result[""data""][CONF_SECRET] == SECRET
    assert result[""data""][CONF_CLOUDHOOK] == CLOUDHOOK
    assert result[""description_placeholders""][CONF_WEBHOOK_URL] == WEBHOOK_URL


async def test_import(hass, webhook_id, secret):
    """"""Test import step.""""""
    flow = await init_config_flow(hass)

    result = await flow.async_step_import({})
    assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
    assert result[""title""] == ""OwnTracks""
    assert result[""data""][CONF_WEBHOOK_ID] == WEBHOOK_ID
    assert result[""data""][CONF_SECRET] == SECRET
    assert result[""data""][CONF_CLOUDHOOK] == CLOUDHOOK
    assert result[""description_placeholders""] is None


async def test_import_setup(hass):
    """"""Test that we automatically create a config flow.""""""
    await async_process_ha_core_config(
        hass, {""external_url"": ""http://example.com""},
    )

    assert not hass.config_entries.async_entries(DOMAIN)
    assert await async_setup_component(hass, DOMAIN, {""owntracks"": {}})
    await hass.async_block_till_done()
    assert hass.config_entries.async_entries(DOMAIN)


async def test_abort_if_already_setup(hass):
    """"""Test that we can't add more than one instance.""""""
    flow = await init_config_flow(hass)

    MockConfigEntry(domain=DOMAIN, data={}).add_to_hass(hass)
    assert hass.config_entries.async_entries(DOMAIN)

    # Should fail, already setup (import)
    result = await flow.async_step_import({})
    assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
    assert result[""reason""] == ""one_instance_allowed""

    # Should fail, already setup (flow)
    result = await flow.async_step_user({})
    assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
    assert result[""reason""] == ""one_instance_allowed""


async def test_user_not_supports_encryption(hass, not_supports_encryption):
    """"""Test user step.""""""
    flow = await init_config_flow(hass)

    result = await flow.async_step_user({})
    assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
    assert (
        result[""description_placeholders""][""secret""]
        == ""Encryption is not supported because nacl is not installed.""
    )


async def test_unload(hass):
    """"""Test unloading a config flow.""""""
    await async_process_ha_core_config(
        hass, {""external_url"": ""http://example.com""},
    )

    with patch(
        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_setup""
    ) as mock_forward:
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": ""import""}, data={}
        )

    assert len(mock_forward.mock_calls) == 1
    entry = result[""result""]

    assert mock_forward.mock_calls[0][1][0] is entry
    assert mock_forward.mock_calls[0][1][1] == ""device_tracker""
    assert entry.data[""webhook_id""] in hass.data[""webhook""]

    with patch(
        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_unload"",
        return_value=None,
    ) as mock_unload:
        assert await hass.config_entries.async_unload(entry.entry_id)

    assert len(mock_unload.mock_calls) == 1
    assert mock_forward.mock_calls[0][1][0] is entry
    assert mock_forward.mock_calls[0][1][1] == ""device_tracker""
    assert entry.data[""webhook_id""] not in hass.data[""webhook""]


async def test_with_cloud_sub(hass):
    """"""Test creating a config flow while subscribed.""""""
    hass.config.components.add(""cloud"")
    with patch(
        ""homeassistant.components.cloud.async_active_subscription"", return_value=True
    ), patch(
        ""homeassistant.components.cloud.async_create_cloudhook"",
        return_value=""https://hooks.nabu.casa/ABCD"",
    ):
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": ""user""}, data={}
        )

    entry = result[""result""]
    assert entry.data[""cloudhook""]
    assert (
        result[""description_placeholders""][""webhook_url""]
        == ""https://hooks.nabu.casa/ABCD""
    )
","
1""""""Tests for OwnTracks config flow.""""""
2import pytest
3
4from homeassistant import data_entry_flow
5from homeassistant.components.owntracks import config_flow
6from homeassistant.components.owntracks.config_flow import CONF_CLOUDHOOK, CONF_SECRET
7from homeassistant.components.owntracks.const import DOMAIN
8from homeassistant.config import async_process_ha_core_config
9from homeassistant.const import CONF_WEBHOOK_ID
10from homeassistant.setup import async_setup_component
11
12from tests.async_mock import patch
13from tests.common import MockConfigEntry
14
15CONF_WEBHOOK_URL = ""webhook_url""
16
17BASE_URL = ""http://example.com""
18CLOUDHOOK = False
19SECRET = ""test-secret""
20WEBHOOK_ID = ""webhook_id""
21WEBHOOK_URL = f""{BASE_URL}/api/webhook/webhook_id""
22
23
24@pytest.fixture(name=""webhook_id"")
25def mock_webhook_id():
26    """"""Mock webhook_id.""""""
27    with patch(
28        ""homeassistant.components.webhook.async_generate_id"", return_value=WEBHOOK_ID
29    ):
30        yield
31
32
33@pytest.fixture(name=""secret"")
34def mock_secret():
35    """"""Mock secret.""""""
36    with patch(""secrets.token_hex"", return_value=SECRET):
37        yield
38
39
40@pytest.fixture(name=""not_supports_encryption"")
41def mock_not_supports_encryption():
42    """"""Mock non successful nacl import.""""""
43    with patch(
44        ""homeassistant.components.owntracks.config_flow.supports_encryption"",
45        return_value=False,
46    ):
47        yield
48
49
50async def init_config_flow(hass):
51    """"""Init a configuration flow.""""""
52    await async_process_ha_core_config(
53        hass, {""external_url"": BASE_URL},
54    )
55    flow = config_flow.OwnTracksFlow()
56    flow.hass = hass
57    return flow
58
59
60async def test_user(hass, webhook_id, secret):
61    """"""Test user step.""""""
62    flow = await init_config_flow(hass)
63
64    result = await flow.async_step_user()
65
66    result = await flow.async_step_user({})
67
68
69async def test_import(hass, webhook_id, secret):
70    """"""Test import step.""""""
71    flow = await init_config_flow(hass)
72
73    result = await flow.async_step_import({})
74
75
76async def test_import_setup(hass):
77    """"""Test that we automatically create a config flow.""""""
78    await async_process_ha_core_config(
79        hass, {""external_url"": ""http://example.com""},
80    )
81
82    await hass.async_block_till_done()
83
84
85async def test_abort_if_already_setup(hass):
86    """"""Test that we can't add more than one instance.""""""
87    flow = await init_config_flow(hass)
88
89    MockConfigEntry(domain=DOMAIN, data={}).add_to_hass(hass)
90
91    # Should fail, already setup (import)
92    result = await flow.async_step_import({})
93
94    # Should fail, already setup (flow)
95    result = await flow.async_step_user({})
96
97
98async def test_user_not_supports_encryption(hass, not_supports_encryption):
99    """"""Test user step.""""""
100    flow = await init_config_flow(hass)
101
102    result = await flow.async_step_user({})
103        result[""description_placeholders""][""secret""]
104        == ""Encryption is not supported because nacl is not installed.""
105    )
106
107
108async def test_unload(hass):
109    """"""Test unloading a config flow.""""""
110    await async_process_ha_core_config(
111        hass, {""external_url"": ""http://example.com""},
112    )
113
114    with patch(
115        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_setup""
116    ) as mock_forward:
117        result = await hass.config_entries.flow.async_init(
118            DOMAIN, context={""source"": ""import""}, data={}
119        )
120
121    entry = result[""result""]
122
123
124    with patch(
125        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_unload"",
126        return_value=None,
127    ) as mock_unload:
128
129
130
131async def test_with_cloud_sub(hass):
132    """"""Test creating a config flow while subscribed.""""""
133    hass.config.components.add(""cloud"")
134    with patch(
135        ""homeassistant.components.cloud.async_active_subscription"", return_value=True
136    ), patch(
137        ""homeassistant.components.cloud.async_create_cloudhook"",
138        return_value=""https://hooks.nabu.casa/ABCD"",
139    ):
140        result = await hass.config_entries.flow.async_init(
141            DOMAIN, context={""source"": ""user""}, data={}
142        )
143
144    entry = result[""result""]
145        result[""description_placeholders""][""webhook_url""]
146        == ""https://hooks.nabu.casa/ABCD""
147    )
148","[['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_FORM'], ['result[""step_id""]', '==', '""user""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['result[""title""]', '==', '""OwnTracks""'], ['result[""data""][CONF_WEBHOOK_ID]', '==', 'WEBHOOK_ID'], ['result[""data""][CONF_SECRET]', '==', 'SECRET'], ['result[""data""][CONF_CLOUDHOOK]', '==', 'CLOUDHOOK'], ['result[""description_placeholders""][CONF_WEBHOOK_URL]', '==', 'WEBHOOK_URL'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['result[""title""]', '==', '""OwnTracks""'], ['result[""data""][CONF_WEBHOOK_ID]', '==', 'WEBHOOK_ID'], ['result[""data""][CONF_SECRET]', '==', 'SECRET'], ['result[""data""][CONF_CLOUDHOOK]', '==', 'CLOUDHOOK'], ['result[""description_placeholders""]', '==', 'None'], ['hass.config_entries.async_entries(DOMAIN)', '==', 'False'], ['await', 'async_setup_component(hass'], ['hass.config_entries.async_entries(DOMAIN)', '==', 'True'], ['hass.config_entries.async_entries(DOMAIN)', '==', 'True'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""one_instance_allowed""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""one_instance_allowed""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['(', '==', 'True'], ['len(mock_forward.mock_calls)', '==', '1'], ['mock_forward.mock_calls[0][1][0]', '==', 'entry'], ['mock_forward.mock_calls[0][1][1]', '==', '""device_tracker""'], ['await', 'hass.config_entries.async_unload(entry.entry_id)'], ['len(mock_unload.mock_calls)', '==', '1'], ['mock_forward.mock_calls[0][1][0]', '==', 'entry'], ['mock_forward.mock_calls[0][1][1]', '==', '""device_tracker""'], ['entry.data[""cloudhook""]', '==', 'True'], ['(', '==', 'True']]",35,33,0.9428571428571428,0.0054708222811671,"['CONF_WEBHOOK_URL', 'BASE_URL', 'CLOUDHOOK', 'SECRET', 'WEBHOOK_ID', 'WEBHOOK_URL', 'hass', 'flow', 'flow.hass', 'webhook_id', 'secret', 'result', 'not_supports_encryption', 'entry']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['CONF_WEBHOOK_URL', 'BASE_URL', 'CLOUDHOOK', 'SECRET', 'WEBHOOK_ID', 'WEBHOOK_URL', 'hass', 'flow', 'flow.hass', 'webhook_id', 'secret', 'result', 'not_supports_encryption', 'entry']
*Code:

1""""""Tests for OwnTracks config flow.""""""
2import pytest
3
4from homeassistant import data_entry_flow
5from homeassistant.components.owntracks import config_flow
6from homeassistant.components.owntracks.config_flow import CONF_CLOUDHOOK, CONF_SECRET
7from homeassistant.components.owntracks.const import DOMAIN
8from homeassistant.config import async_process_ha_core_config
9from homeassistant.const import CONF_WEBHOOK_ID
10from homeassistant.setup import async_setup_component
11
12from tests.async_mock import patch
13from tests.common import MockConfigEntry
14
15CONF_WEBHOOK_URL = ""webhook_url""
16
17BASE_URL = ""http://example.com""
18CLOUDHOOK = False
19SECRET = ""test-secret""
20WEBHOOK_ID = ""webhook_id""
21WEBHOOK_URL = f""{BASE_URL}/api/webhook/webhook_id""
22
23
24@pytest.fixture(name=""webhook_id"")
25def mock_webhook_id():
26    """"""Mock webhook_id.""""""
27    with patch(
28        ""homeassistant.components.webhook.async_generate_id"", return_value=WEBHOOK_ID
29    ):
30        yield
31
32
33@pytest.fixture(name=""secret"")
34def mock_secret():
35    """"""Mock secret.""""""
36    with patch(""secrets.token_hex"", return_value=SECRET):
37        yield
38
39
40@pytest.fixture(name=""not_supports_encryption"")
41def mock_not_supports_encryption():
42    """"""Mock non successful nacl import.""""""
43    with patch(
44        ""homeassistant.components.owntracks.config_flow.supports_encryption"",
45        return_value=False,
46    ):
47        yield
48
49
50async def init_config_flow(hass):
51    """"""Init a configuration flow.""""""
52    await async_process_ha_core_config(
53        hass, {""external_url"": BASE_URL},
54    )
55    flow = config_flow.OwnTracksFlow()
56    flow.hass = hass
57    return flow
58
59
60async def test_user(hass, webhook_id, secret):
61    """"""Test user step.""""""
62    flow = await init_config_flow(hass)
63
64    result = await flow.async_step_user()
65
66    result = await flow.async_step_user({})
67
68
69async def test_import(hass, webhook_id, secret):
70    """"""Test import step.""""""
71    flow = await init_config_flow(hass)
72
73    result = await flow.async_step_import({})
74
75
76async def test_import_setup(hass):
77    """"""Test that we automatically create a config flow.""""""
78    await async_process_ha_core_config(
79        hass, {""external_url"": ""http://example.com""},
80    )
81
82    await hass.async_block_till_done()
83
84
85async def test_abort_if_already_setup(hass):
86    """"""Test that we can't add more than one instance.""""""
87    flow = await init_config_flow(hass)
88
89    MockConfigEntry(domain=DOMAIN, data={}).add_to_hass(hass)
90
91    # Should fail, already setup (import)
92    result = await flow.async_step_import({})
93
94    # Should fail, already setup (flow)
95    result = await flow.async_step_user({})
96
97
98async def test_user_not_supports_encryption(hass, not_supports_encryption):
99    """"""Test user step.""""""
100    flow = await init_config_flow(hass)
101
102    result = await flow.async_step_user({})
103        result[""description_placeholders""][""secret""]
104        == ""Encryption is not supported because nacl is not installed.""
105    )
106
107
108async def test_unload(hass):
109    """"""Test unloading a config flow.""""""
110    await async_process_ha_core_config(
111        hass, {""external_url"": ""http://example.com""},
112    )
113
114    with patch(
115        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_setup""
116    ) as mock_forward:
117        result = await hass.config_entries.flow.async_init(
118            DOMAIN, context={""source"": ""import""}, data={}
119        )
120
121    entry = result[""result""]
122
123
124    with patch(
125        ""homeassistant.config_entries.ConfigEntries.async_forward_entry_unload"",
126        return_value=None,
127    ) as mock_unload:
128
129
130
131async def test_with_cloud_sub(hass):
132    """"""Test creating a config flow while subscribed.""""""
133    hass.config.components.add(""cloud"")
134    with patch(
135        ""homeassistant.components.cloud.async_active_subscription"", return_value=True
136    ), patch(
137        ""homeassistant.components.cloud.async_create_cloudhook"",
138        return_value=""https://hooks.nabu.casa/ABCD"",
139    ):
140        result = await hass.config_entries.flow.async_init(
141            DOMAIN, context={""source"": ""user""}, data={}
142        )
143
144    entry = result[""result""]
145        result[""description_placeholders""][""webhook_url""]
146        == ""https://hooks.nabu.casa/ABCD""
147    )
148",6035,"[[50, 'hass', '!=', None, 'Asserting that hass is not None to ensure proper configuration flow'],
[60, 'hass', '!=', None, 'Asserting that hass is not None to ensure proper configuration flow'],
[60, 'webhook_id', '!=', None, 'Asserting that webhook_id is not None to ensure proper configuration flow'],
[60, 'secret', '!=', None, 'Asserting that secret is not None to ensure proper test execution'],
[69, 'hass', '!=', None, 'Asserting that hass is not None to ensure proper configuration flow'],
[69, 'webhook_id', '!=', None, 'Asserting that webhook_id is not None to ensure proper import step'],
[69, 'secret', '!=', None, 'Asserting that secret is not None to ensure proper import step'],
[76, 'hass', '!=', None, 'Asserting that hass is not None to ensure config flow setup'],
[85, 'hass', '!=', None, 'Asserting that hass is not None to prevent multiple instances'],
[98, 'hass', '!=', None, 'Asserting that hass is not None to test user not supports encryption'],
[98, 'not_supports_encryption', '!=', None, 'Asserting not_supports_encryption is not None for encryption support testing'],
[108, 'hass', '!=', None, 'Asserting that hass is not None to ensure proper config flow unloading'],
[131, 'hass', '!=', None, 'Asserting that hass is not None to ensure proper config flow creation']]"
forin-xyz/you-get,"#!/usr/bin/env python

__all__ = ['cntv_download', 'cntv_download_by_id']

from ..common import *

import json
import re

def cntv_download_by_id(id, title = None, output_dir = '.', merge = True, info_only = False):
    assert id
    info = json.loads(get_html('http://vdn.apps.cntv.cn/api/getHttpVideoInfo.do?pid=' + id))
    title = title or info['title']
    video = info['video']
    alternatives = [x for x in video.keys() if x.startswith('chapters')]
    #assert alternatives in (['chapters'], ['chapters', 'chapters2']), alternatives
    chapters = video['chapters2'] if 'chapters2' in video else video['chapters']
    urls = [x['url'] for x in chapters]
    ext = r1(r'\.([^.]+)$', urls[0])
    assert ext in ('flv', 'mp4')
    size = 0
    for url in urls:
        _, _, temp = url_info(url)
        size += temp
    
    print_info(site_info, title, ext, size)
    if not info_only:
        download_urls(urls, title, ext, size, output_dir = output_dir, merge = merge)

def cntv_download(url, output_dir = '.', merge = True, info_only = False):
    if re.match(r'http://\w+\.cntv\.cn/(\w+/\w+/(classpage/video/)?)?\d+/\d+\.shtml', url) or re.match(r'http://\w+.cntv.cn/(\w+/)*VIDE\d+.shtml', url):
        id = r1(r'<!--repaste.video.code.begin-->(\w+)<!--repaste.video.code.end-->', get_html(url))
    elif re.match(r'http://xiyou.cntv.cn/v-[\w-]+\.html', url):
        id = r1(r'http://xiyou.cntv.cn/v-([\w-]+)\.html', url)
    else:
        raise NotImplementedError(url)
    
    cntv_download_by_id(id, output_dir = output_dir, merge = merge, info_only = info_only)

site_info = ""CNTV.com""
download = cntv_download
download_playlist = playlist_not_supported('cntv')
","
1#!/usr/bin/env python
2
3__all__ = ['cntv_download', 'cntv_download_by_id']
4
5from ..common import *
6
7import json
8import re
9
10def cntv_download_by_id(id, title = None, output_dir = '.', merge = True, info_only = False):
11    info = json.loads(get_html('http://vdn.apps.cntv.cn/api/getHttpVideoInfo.do?pid=' + id))
12    title = title or info['title']
13    video = info['video']
14    alternatives = [x for x in video.keys() if x.startswith('chapters')]
15    chapters = video['chapters2'] if 'chapters2' in video else video['chapters']
16    urls = [x['url'] for x in chapters]
17    ext = r1(r'\.([^.]+)$', urls[0])
18    size = 0
19    for url in urls:
20        _, _, temp = url_info(url)
21        size += temp
22    
23    print_info(site_info, title, ext, size)
24    if not info_only:
25        download_urls(urls, title, ext, size, output_dir = output_dir, merge = merge)
26
27def cntv_download(url, output_dir = '.', merge = True, info_only = False):
28    if re.match(r'http://\w+\.cntv\.cn/(\w+/\w+/(classpage/video/)?)?\d+/\d+\.shtml', url) or re.match(r'http://\w+.cntv.cn/(\w+/)*VIDE\d+.shtml', url):
29        id = r1(r'<!--repaste.video.code.begin-->(\w+)<!--repaste.video.code.end-->', get_html(url))
30    elif re.match(r'http://xiyou.cntv.cn/v-[\w-]+\.html', url):
31        id = r1(r'http://xiyou.cntv.cn/v-([\w-]+)\.html', url)
32    else:
33        raise NotImplementedError(url)
34    
35    cntv_download_by_id(id, output_dir = output_dir, merge = merge, info_only = info_only)
36
37site_info = ""CNTV.com""
38download = cntv_download
39download_playlist = playlist_not_supported('cntv')
40","[['id', '==', 'True']]",3,1,0.3333333333333333,0.0005948839976204,"['__all__', 'id', 'title', 'output_dir', 'merge', 'info_only', 'info', 'video', 'alternatives', 'chapters', 'urls', 'ext', 'size', '_', 'temp', 'download_urls(urls', 'url', 'cntv_download_by_id(id', 'site_info', 'download', 'download_playlist']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'id', 'title', 'output_dir', 'merge', 'info_only', 'info', 'video', 'alternatives', 'chapters', 'urls', 'ext', 'size', '_', 'temp', 'download_urls(urls', 'url', 'cntv_download_by_id(id', 'site_info', 'download', 'download_playlist']
*Code:

1#!/usr/bin/env python
2
3__all__ = ['cntv_download', 'cntv_download_by_id']
4
5from ..common import *
6
7import json
8import re
9
10def cntv_download_by_id(id, title = None, output_dir = '.', merge = True, info_only = False):
11    info = json.loads(get_html('http://vdn.apps.cntv.cn/api/getHttpVideoInfo.do?pid=' + id))
12    title = title or info['title']
13    video = info['video']
14    alternatives = [x for x in video.keys() if x.startswith('chapters')]
15    chapters = video['chapters2'] if 'chapters2' in video else video['chapters']
16    urls = [x['url'] for x in chapters]
17    ext = r1(r'\.([^.]+)$', urls[0])
18    size = 0
19    for url in urls:
20        _, _, temp = url_info(url)
21        size += temp
22    
23    print_info(site_info, title, ext, size)
24    if not info_only:
25        download_urls(urls, title, ext, size, output_dir = output_dir, merge = merge)
26
27def cntv_download(url, output_dir = '.', merge = True, info_only = False):
28    if re.match(r'http://\w+\.cntv\.cn/(\w+/\w+/(classpage/video/)?)?\d+/\d+\.shtml', url) or re.match(r'http://\w+.cntv.cn/(\w+/)*VIDE\d+.shtml', url):
29        id = r1(r'<!--repaste.video.code.begin-->(\w+)<!--repaste.video.code.end-->', get_html(url))
30    elif re.match(r'http://xiyou.cntv.cn/v-[\w-]+\.html', url):
31        id = r1(r'http://xiyou.cntv.cn/v-([\w-]+)\.html', url)
32    else:
33        raise NotImplementedError(url)
34    
35    cntv_download_by_id(id, output_dir = output_dir, merge = merge, info_only = info_only)
36
37site_info = ""CNTV.com""
38download = cntv_download
39download_playlist = playlist_not_supported('cntv')
40",3246,"[[3, '__all__', '==', 2, 'Ensure all provided functions are available for import'],
[10, 'id', '!=', None, 'Ensures that an ID is provided'],
[10, 'output_dir', '!=', None, 'Ensures that an output directory is provided'],
[12, 'title', '!=', None, 'Ensures a title is available for use'],
[13, 'video', '!=', None, 'Ensures video information is available for use'],
[15, 'chapters', '!=', None, 'Ensures there are video chapters available'],
[17, 'ext', '!=', None, 'Ensures there is a video extension available'],
[22, 'size', '>=', 0, 'Ensures the total size is a positive integer'],
[24, 'info_only', '==', False, 'Ensures info_only flag in False for download'],
[27, 'url', '!=', None, 'Ensures that a url is provided'],
[27, 'merge', '!=', None, 'Ensures that the merge function is provided'],
[27, 'output_dir', '!=', None, 'Ensures that an output directory is provided'],
[28, 'id', '!=', None, 'Ensures an ID is extracted from the url'],
[32, 'url', '==', None, 'Raises an error if a video url does not match any given formats'],
[35, 'info_only', '==', False, 'Ensures info_only flag in False for download'],
[38, 'download', '==', 'cntv_download', 'Ensures the correct function is assigned for download']]"
mig42/gui2py,"#!/usr/bin/python
# -*- coding: utf-8 -*-

""gui2py's Notebook control and TabPanel (uses wx.Notebook and wx.Panel)""

__author__ = ""Mariano Reingart (reingart@gmail.com)""
__copyright__ = ""Copyright (C) 2013- Mariano Reingart""  # where applicable

# Initial implementation was based on PythonCard's Notebook component, 
# but redesigned and overhauled a lot (specs renamed, events refactorized, etc.)
# Note: Pythoncard's code was trivial, so it was almost reimplemented completely

import wx
from ..event import FormEvent
from ..component import Control, Component, DesignerMixin
from ..spec import Spec, EventSpec, InitSpec, StyleSpec, InternalSpec
from .. import registry
from .. import images


class Notebook(Control):
    ""A container which manages multiple windows with associated tabs""
    
    _wx_class = wx.Notebook
    _style = wx.NO_FULL_REPAINT_ON_RESIZE | wx.CLIP_SIBLINGS
    _image = images.notebook
    
    def get_count(self):
        ""Get the pages (tab) count""
        return self.wx_obj.GetPageCount()
   
    def _get_pages(self):
        return [child for child in self if isinstance(child, TabPanel)]

    pages = InternalSpec(_get_pages,
                         doc=""Return a list of current pages"")
                  
    selection = Spec(lambda self: self.wx_obj.GetSelection(), 
                     lambda self, index: index is not None and 
                            wx.CallAfter(self.wx_obj.SetSelection, index),
                     doc=""Currently selected page (zero based)"", type=""integer"")

    # events:
    onpagechanged = EventSpec('page_changed', 
                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGED, kind=FormEvent)
    onpagechanging = EventSpec('page_changing', 
                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGING, kind=FormEvent)
                            


class TabPanel(Component, DesignerMixin):
    ""Represents a tab (page) in the Notebook""

    _wx_class = wx.Panel
    _registry = registry.MISC

    def __init__(self, *args, **kwargs):
        # caption is handled specially:
        if 'text' in kwargs:
            text = kwargs['text']
            del kwargs['text']
        else:
            text = None
        Component.__init__(self, *args, **kwargs)
        # set index TODO: better support for insert/remove/etc
        self.index = self._parent.get_count()
        # sane default for tab caption (in designer)
        text = text or 'tab %s' % self.index
        # add the page to the notebook
        self._parent.wx_obj.AddPage(self.wx_obj, text, self.index)
        # Handle resize events to adjust absolute and relative dimensions
        self.wx_obj.Bind(wx.EVT_SIZE, self.resize)


    index = Spec(optional=False, default="""", _name=""_index"", type='integer')

    def _get_text(self):
        return self._parent.wx_obj.GetPageText(self.index)

    def _set_text(self, new_text):
        if self.index is not None and new_text:
            self._parent.wx_obj.SetPageText(self.index, new_text)
    
    text = Spec(_get_text, _set_text, doc=""Tab (page) caption"", type='string')
       
    def _get_selection(self):
        return self._parent.wx_obj.GetSelection() == self.index
    
    def _set_selection(self, on):
        if on and self._index:
            wx.CallAfter(self._parent.wx_obj.SetSelection, self.index)

    selected = Spec(_get_selection, _set_selection, type='boolean')

    def destroy(self):
        # remove the page to the notebook
        self._parent.wx_obj.RemovePage(self.index)
        # reindex (maybe this should be moved to Notebook)
        for page in self._parent.pages[self.index+1:]:
            print ""reindexing"", page.name
            page.index = page.index - 1
        Component.destroy(self)
    
    def resize(self, evt=None):
        ""automatically adjust relative pos and size of children controls""
        for child in self:
            if isinstance(child, Control):
                child.resize(evt)
        # call original handler (wx.HtmlWindow)
        if evt:
            evt.Skip()


# update metadata for the add context menu at the designer:

Notebook._meta.valid_children = [TabPanel]
TabPanel._meta.valid_children = [ctr for ctr in registry.CONTROLS.values()
                                 if ctr._image]   # TODO: better filter
TabPanel._meta.container = True
 

if __name__ == ""__main__"":
    import sys
    # basic test until unit_test
    import gui
    app = wx.App(redirect=False)    
    w = gui.Window(title=""hello world"", name=""frmTest"", tool_window=False, 
               resizable=True, visible=False, pos=(180, 0))
    nb = Notebook(w, name=""notebook"")
    
    p1 = TabPanel(nb, name=""tab1"", text=""panel 1"")
    p2 = TabPanel(nb, name=""tab2"", text=""panel 2"")
    p3 = TabPanel(nb, name=""tab3"", text=""panel 3"")
       
    # assign some event handlers:
    nb.onpagechanged = ""print 'selected page:', event.target.selection""
    w.show()
    
    # basic tests:
    assert nb.get_count() == 3
    
    from gui.tools.inspector import InspectorTool
    InspectorTool().show(w)
    app.MainLoop()

","
1#!/usr/bin/python
2# -*- coding: utf-8 -*-
3
4""gui2py's Notebook control and TabPanel (uses wx.Notebook and wx.Panel)""
5
6__author__ = ""Mariano Reingart (reingart@gmail.com)""
7__copyright__ = ""Copyright (C) 2013- Mariano Reingart""  # where applicable
8
9# Initial implementation was based on PythonCard's Notebook component, 
10# but redesigned and overhauled a lot (specs renamed, events refactorized, etc.)
11# Note: Pythoncard's code was trivial, so it was almost reimplemented completely
12
13import wx
14from ..event import FormEvent
15from ..component import Control, Component, DesignerMixin
16from ..spec import Spec, EventSpec, InitSpec, StyleSpec, InternalSpec
17from .. import registry
18from .. import images
19
20
21class Notebook(Control):
22    ""A container which manages multiple windows with associated tabs""
23    
24    _wx_class = wx.Notebook
25    _style = wx.NO_FULL_REPAINT_ON_RESIZE | wx.CLIP_SIBLINGS
26    _image = images.notebook
27    
28    def get_count(self):
29        ""Get the pages (tab) count""
30        return self.wx_obj.GetPageCount()
31   
32    def _get_pages(self):
33        return [child for child in self if isinstance(child, TabPanel)]
34
35    pages = InternalSpec(_get_pages,
36                         doc=""Return a list of current pages"")
37                  
38    selection = Spec(lambda self: self.wx_obj.GetSelection(), 
39                     lambda self, index: index is not None and 
40                            wx.CallAfter(self.wx_obj.SetSelection, index),
41                     doc=""Currently selected page (zero based)"", type=""integer"")
42
43    # events:
44    onpagechanged = EventSpec('page_changed', 
45                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGED, kind=FormEvent)
46    onpagechanging = EventSpec('page_changing', 
47                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGING, kind=FormEvent)
48                            
49
50
51class TabPanel(Component, DesignerMixin):
52    ""Represents a tab (page) in the Notebook""
53
54    _wx_class = wx.Panel
55    _registry = registry.MISC
56
57    def __init__(self, *args, **kwargs):
58        # caption is handled specially:
59        if 'text' in kwargs:
60            text = kwargs['text']
61            del kwargs['text']
62        else:
63            text = None
64        Component.__init__(self, *args, **kwargs)
65        # set index TODO: better support for insert/remove/etc
66        self.index = self._parent.get_count()
67        # sane default for tab caption (in designer)
68        text = text or 'tab %s' % self.index
69        # add the page to the notebook
70        self._parent.wx_obj.AddPage(self.wx_obj, text, self.index)
71        # Handle resize events to adjust absolute and relative dimensions
72        self.wx_obj.Bind(wx.EVT_SIZE, self.resize)
73
74
75    index = Spec(optional=False, default="""", _name=""_index"", type='integer')
76
77    def _get_text(self):
78        return self._parent.wx_obj.GetPageText(self.index)
79
80    def _set_text(self, new_text):
81        if self.index is not None and new_text:
82            self._parent.wx_obj.SetPageText(self.index, new_text)
83    
84    text = Spec(_get_text, _set_text, doc=""Tab (page) caption"", type='string')
85       
86    def _get_selection(self):
87        return self._parent.wx_obj.GetSelection() == self.index
88    
89    def _set_selection(self, on):
90        if on and self._index:
91            wx.CallAfter(self._parent.wx_obj.SetSelection, self.index)
92
93    selected = Spec(_get_selection, _set_selection, type='boolean')
94
95    def destroy(self):
96        # remove the page to the notebook
97        self._parent.wx_obj.RemovePage(self.index)
98        # reindex (maybe this should be moved to Notebook)
99        for page in self._parent.pages[self.index+1:]:
100            print ""reindexing"", page.name
101            page.index = page.index - 1
102        Component.destroy(self)
103    
104    def resize(self, evt=None):
105        ""automatically adjust relative pos and size of children controls""
106        for child in self:
107            if isinstance(child, Control):
108                child.resize(evt)
109        # call original handler (wx.HtmlWindow)
110        if evt:
111            evt.Skip()
112
113
114# update metadata for the add context menu at the designer:
115
116Notebook._meta.valid_children = [TabPanel]
117TabPanel._meta.valid_children = [ctr for ctr in registry.CONTROLS.values()
118                                 if ctr._image]   # TODO: better filter
119TabPanel._meta.container = True
120 
121
122if __name__ == ""__main__"":
123    import sys
124    # basic test until unit_test
125    import gui
126    app = wx.App(redirect=False)    
127    w = gui.Window(title=""hello world"", name=""frmTest"", tool_window=False, 
128               resizable=True, visible=False, pos=(180, 0))
129    nb = Notebook(w, name=""notebook"")
130    
131    p1 = TabPanel(nb, name=""tab1"", text=""panel 1"")
132    p2 = TabPanel(nb, name=""tab2"", text=""panel 2"")
133    p3 = TabPanel(nb, name=""tab3"", text=""panel 3"")
134       
135    # assign some event handlers:
136    nb.onpagechanged = ""print 'selected page:', event.target.selection""
137    w.show()
138    
139    # basic tests:
140    
141    from gui.tools.inspector import InspectorTool
142    InspectorTool().show(w)
143    app.MainLoop()
144
145","[['nb.get_count()', '==', '3']]",1,1,1.0,0.0001919754271453,"['__author__', '__copyright__', '_wx_class', '_style', '_image', 'pages', 'selection', 'onpagechanged', 'onpagechanging', '_registry', '*args', '**kwargs', 'text', 'self.index', 'index', 'new_text', 'on', 'selected', 'page.index', 'evt', 'Notebook._meta.valid_children', 'TabPanel._meta.valid_children', 'TabPanel._meta.container', 'app', 'w', 'nb', 'p1', 'p2', 'p3', 'nb.onpagechanged']",30,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', '__copyright__', '_wx_class', '_style', '_image', 'pages', 'selection', 'onpagechanged', 'onpagechanging', '_registry', '*args', '**kwargs', 'text', 'self.index', 'index', 'new_text', 'on', 'selected', 'page.index', 'evt', 'Notebook._meta.valid_children', 'TabPanel._meta.valid_children', 'TabPanel._meta.container', 'app', 'w', 'nb', 'p1', 'p2', 'p3', 'nb.onpagechanged']
*Code:

1#!/usr/bin/python
2# -*- coding: utf-8 -*-
3
4""gui2py's Notebook control and TabPanel (uses wx.Notebook and wx.Panel)""
5
6__author__ = ""Mariano Reingart (reingart@gmail.com)""
7__copyright__ = ""Copyright (C) 2013- Mariano Reingart""  # where applicable
8
9# Initial implementation was based on PythonCard's Notebook component, 
10# but redesigned and overhauled a lot (specs renamed, events refactorized, etc.)
11# Note: Pythoncard's code was trivial, so it was almost reimplemented completely
12
13import wx
14from ..event import FormEvent
15from ..component import Control, Component, DesignerMixin
16from ..spec import Spec, EventSpec, InitSpec, StyleSpec, InternalSpec
17from .. import registry
18from .. import images
19
20
21class Notebook(Control):
22    ""A container which manages multiple windows with associated tabs""
23    
24    _wx_class = wx.Notebook
25    _style = wx.NO_FULL_REPAINT_ON_RESIZE | wx.CLIP_SIBLINGS
26    _image = images.notebook
27    
28    def get_count(self):
29        ""Get the pages (tab) count""
30        return self.wx_obj.GetPageCount()
31   
32    def _get_pages(self):
33        return [child for child in self if isinstance(child, TabPanel)]
34
35    pages = InternalSpec(_get_pages,
36                         doc=""Return a list of current pages"")
37                  
38    selection = Spec(lambda self: self.wx_obj.GetSelection(), 
39                     lambda self, index: index is not None and 
40                            wx.CallAfter(self.wx_obj.SetSelection, index),
41                     doc=""Currently selected page (zero based)"", type=""integer"")
42
43    # events:
44    onpagechanged = EventSpec('page_changed', 
45                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGED, kind=FormEvent)
46    onpagechanging = EventSpec('page_changing', 
47                         binding=wx.EVT_NOTEBOOK_PAGE_CHANGING, kind=FormEvent)
48                            
49
50
51class TabPanel(Component, DesignerMixin):
52    ""Represents a tab (page) in the Notebook""
53
54    _wx_class = wx.Panel
55    _registry = registry.MISC
56
57    def __init__(self, *args, **kwargs):
58        # caption is handled specially:
59        if 'text' in kwargs:
60            text = kwargs['text']
61            del kwargs['text']
62        else:
63            text = None
64        Component.__init__(self, *args, **kwargs)
65        # set index TODO: better support for insert/remove/etc
66        self.index = self._parent.get_count()
67        # sane default for tab caption (in designer)
68        text = text or 'tab %s' % self.index
69        # add the page to the notebook
70        self._parent.wx_obj.AddPage(self.wx_obj, text, self.index)
71        # Handle resize events to adjust absolute and relative dimensions
72        self.wx_obj.Bind(wx.EVT_SIZE, self.resize)
73
74
75    index = Spec(optional=False, default="""", _name=""_index"", type='integer')
76
77    def _get_text(self):
78        return self._parent.wx_obj.GetPageText(self.index)
79
80    def _set_text(self, new_text):
81        if self.index is not None and new_text:
82            self._parent.wx_obj.SetPageText(self.index, new_text)
83    
84    text = Spec(_get_text, _set_text, doc=""Tab (page) caption"", type='string')
85       
86    def _get_selection(self):
87        return self._parent.wx_obj.GetSelection() == self.index
88    
89    def _set_selection(self, on):
90        if on and self._index:
91            wx.CallAfter(self._parent.wx_obj.SetSelection, self.index)
92
93    selected = Spec(_get_selection, _set_selection, type='boolean')
94
95    def destroy(self):
96        # remove the page to the notebook
97        self._parent.wx_obj.RemovePage(self.index)
98        # reindex (maybe this should be moved to Notebook)
99        for page in self._parent.pages[self.index+1:]:
100            print ""reindexing"", page.name
101            page.index = page.index - 1
102        Component.destroy(self)
103    
104    def resize(self, evt=None):
105        ""automatically adjust relative pos and size of children controls""
106        for child in self:
107            if isinstance(child, Control):
108                child.resize(evt)
109        # call original handler (wx.HtmlWindow)
110        if evt:
111            evt.Skip()
112
113
114# update metadata for the add context menu at the designer:
115
116Notebook._meta.valid_children = [TabPanel]
117TabPanel._meta.valid_children = [ctr for ctr in registry.CONTROLS.values()
118                                 if ctr._image]   # TODO: better filter
119TabPanel._meta.container = True
120 
121
122if __name__ == ""__main__"":
123    import sys
124    # basic test until unit_test
125    import gui
126    app = wx.App(redirect=False)    
127    w = gui.Window(title=""hello world"", name=""frmTest"", tool_window=False, 
128               resizable=True, visible=False, pos=(180, 0))
129    nb = Notebook(w, name=""notebook"")
130    
131    p1 = TabPanel(nb, name=""tab1"", text=""panel 1"")
132    p2 = TabPanel(nb, name=""tab2"", text=""panel 2"")
133    p3 = TabPanel(nb, name=""tab3"", text=""panel 3"")
134       
135    # assign some event handlers:
136    nb.onpagechanged = ""print 'selected page:', event.target.selection""
137    w.show()
138    
139    # basic tests:
140    
141    from gui.tools.inspector import InspectorTool
142    InspectorTool().show(w)
143    app.MainLoop()
144
145",7272,"[
[21, '_wx_class', '!=', None, ""Notebook class needs to have a wx.Notebook reference""], 
[21, '_style', '!=', None, ""Notebook class needs to have a style reference""], 
[21, '_image', '!=', None, ""Notebook class needs to have an image""],
[21, 'pages', '!=', None, ""Notebook should have pages""], 
[21, 'selection', '!=', None, ""Notebook should have a selection""],
[21, 'onpagechanged', '!=', None, ""Notebook should have an onpagechanged event""], 
[21, 'onpagechanging', '!=', None, ""Notebook should have an onpagechanging event""], 
[51, '_wx_class', '!=', None, ""TabPanel class needs to have a wx.Panel reference""], 
[57, '*args', '!=', None, ""Arguments must be provided for initialization""], 
[57, '**kwargs', '!=', None, ""Keyword arguments should be provided for initialization""], 
[60, 'text', '!=', None, ""Text should be provided for TabPanel initialization""], 
[114, 'Notebook._meta.valid_children', '!=', None, ""Notebook should have a list of valid children""], 
[117, 'TabPanel._meta.valid_children', '!=', None, ""TabPanel should have a list of valid children""], 
[119, 'TabPanel._meta.container', '==', True, ""TabPanel should be a container""], 
[126, 'app', '!=', None, ""A wx.App instance should exist""], 
[127, 'w', '!=', None, ""A Window instance should exist""], 
[129, 'nb', '!=', None, ""A Notebook instance should exist""], 
[131, 'p1', '!=', None, ""A TabPanel instance named p1 should exist""], 
[132, 'p2', '!=', None, ""A TabPanel instance named p2 should exist""], 
[133, 'p3', '!=', None, ""A TabPanel instance named p3 should exist""]
]"
kumarkrishna/sympy,"from sympy import Symbol, S, oo
from sympy.calculus.codomain import codomain
from sympy.sets.sets import Interval, FiniteSet, Complement, Union


def test_codomain():
    x = Symbol('x', real=True)
    assert codomain(x, Interval(-1, 1), x) == Interval(-1, 1)
    assert codomain(x, Interval(0, 1, True, True), x) == \
            Interval(0, 1, True, True)
    assert codomain(x, Interval(1, 2, True, False), x) == Interval(1, 2, True, False)
    assert codomain(x, Interval(1, 2, False, True), x) == Interval(1, 2, False, True)
    assert codomain(x**2, Interval(-1, 1), x) == Interval(0, 1)
    assert codomain(x**3, Interval(0, 1), x) == Interval(0, 1)
    assert codomain(x/(x**2 - 4), Interval(3, 4), x) == Interval(S(1)/3, S(3)/5)
    assert codomain(1, Interval(-1, 4), x) == FiniteSet(1)
    assert codomain(x, Interval(-oo, oo), x) == S.Reals

    assert codomain(1/x**2, FiniteSet(1, 2, -1, 0), x) == FiniteSet(1, S(1)/4)
    assert codomain(x, FiniteSet(1, -1, 3, 5), x) == FiniteSet(-1, 1, 3, 5)
    assert codomain(x**2 - x, FiniteSet(1, -1, 3, 5, -oo), x) == \
            FiniteSet(0, 2, 6, 20, oo)
    assert codomain(x**2/(x - 4), FiniteSet(4), x) == S.EmptySet
    assert codomain(x**2 - x, FiniteSet(S(1)/2, -oo, oo, 2), x) == \
            FiniteSet(S(-1)/4, 2, oo)

    assert codomain(x**2, Interval(-1, 1, True, True), x) == Interval(0, 1, False, True)
    assert codomain(x**2, Interval(-1, 1, False, True), x) == Interval(0, 1)
    assert codomain(x**2, Interval(-1, 1, True, False), x) == Interval(0, 1)

    assert codomain(1/x, Interval(0, 1), x) == Interval(1, oo)
    assert codomain(1/x, Interval(-1, 1), x) == Union(Interval(-oo, -1), Interval(1, oo))
    assert codomain(1/x**2, Interval(-1, 1), x) == Interval(1, oo)
    assert codomain(1/x**2, Interval(-1, 1, True, False), x) == Interval(1, oo)
    assert codomain(1/x**2, Interval(-1, 1, True, True), x) == \
            Interval(1, oo, True, True)
    assert codomain(1/x**2, Interval(-1, 1, False, True), x) == Interval(1, oo)
    assert codomain(1/x, Interval(1, 2), x) == Interval(S(1)/2, 1)
    assert codomain(1/x**2, Interval(-2, -1, True, True), x) == \
            Interval(S(1)/4, 1, True, True)
    assert codomain(x**2/(x - 4), Interval(-oo, oo), x) == \
            Complement(S.Reals, Interval(0, 16, True, True))
    assert codomain(x**2/(x - 4), Interval(3, 4), x) == Interval(-oo, -9)
    assert codomain(-x**2/(x - 4), Interval(3, 4), x) == Interval(9, oo)
    assert codomain((x**2 - x)/(x**3 - 1), S.Reals, x) == Interval(-1, S(1)/3, False, True)
    assert codomain(-x**2 + 1/x, S.Reals, x) == S.Reals
    assert codomain(x**2 - 1/x, S.Reals, x) == S.Reals

    assert codomain(x**2, Union(Interval(1, 2), FiniteSet(3)), x) == \
            Union(Interval(1, 4), FiniteSet(9))
    assert codomain(x/(x**2 - 4), Union(Interval(-oo, 1), Interval(0, oo)), x) == S.Reals
    assert codomain(x, Union(Interval(-1, 1), FiniteSet(-oo)), x) == \
            Union(Interval(-1, 1), FiniteSet(-oo))
    assert codomain(x**2 - x, Interval(1, oo), x) == Interval(0, oo)
","
1from sympy import Symbol, S, oo
2from sympy.calculus.codomain import codomain
3from sympy.sets.sets import Interval, FiniteSet, Complement, Union
4
5
6def test_codomain():
7    x = Symbol('x', real=True)
8            Interval(0, 1, True, True)
9
10            FiniteSet(0, 2, 6, 20, oo)
11            FiniteSet(S(-1)/4, 2, oo)
12
13
14            Interval(1, oo, True, True)
15            Interval(S(1)/4, 1, True, True)
16            Complement(S.Reals, Interval(0, 16, True, True))
17
18            Union(Interval(1, 4), FiniteSet(9))
19            Union(Interval(-1, 1), FiniteSet(-oo))
20","[['codomain(x', '==', 'True'], ['codomain(x', '==', 'True'], ['codomain(x', '==', 'True'], ['codomain(x', '==', 'True'], ['codomain(x**2', '==', 'True'], ['codomain(x**3', '==', 'True'], ['codomain(x/(x**2', '-', '4)'], ['codomain(1', '==', 'True'], ['codomain(x', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(x', '==', 'True'], ['codomain(x**2', '-', 'x'], ['codomain(x**2/(x', '-', '4)'], ['codomain(x**2', '-', 'x'], ['codomain(x**2', '==', 'True'], ['codomain(x**2', '==', 'True'], ['codomain(x**2', '==', 'True'], ['codomain(1/x', '==', 'True'], ['codomain(1/x', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(1/x', '==', 'True'], ['codomain(1/x**2', '==', 'True'], ['codomain(x**2/(x', '-', '4)'], ['codomain(x**2/(x', '-', '4)'], ['codomain(-x**2/(x', '-', '4)'], ['codomain((x**2', '-', 'x)/(x**3', '-', '1)'], ['codomain(-x**2', '+', '1/x'], ['codomain(x**2', '-', '1/x'], ['codomain(x**2', '==', 'True'], ['codomain(x/(x**2', '-', '4)'], ['codomain(x', '==', 'True'], ['codomain(x**2', '-', 'x']]",35,35,1.0,0.0114118030648842,['x'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x']
*Code:

1from sympy import Symbol, S, oo
2from sympy.calculus.codomain import codomain
3from sympy.sets.sets import Interval, FiniteSet, Complement, Union
4
5
6def test_codomain():
7    x = Symbol('x', real=True)
8            Interval(0, 1, True, True)
9
10            FiniteSet(0, 2, 6, 20, oo)
11            FiniteSet(S(-1)/4, 2, oo)
12
13
14            Interval(1, oo, True, True)
15            Interval(S(1)/4, 1, True, True)
16            Complement(S.Reals, Interval(0, 16, True, True))
17
18            Union(Interval(1, 4), FiniteSet(9))
19            Union(Interval(-1, 1), FiniteSet(-oo))
20",1979,"[[7, 'x', '!=', None, 'x is expected not to be a null value']]"
ReactiveX/RxPY,"import unittest

from reactivex import operators as ops
from reactivex.testing import ReactiveTest, TestScheduler

on_next = ReactiveTest.on_next
on_completed = ReactiveTest.on_completed
on_error = ReactiveTest.on_error
subscribe = ReactiveTest.subscribe
subscribed = ReactiveTest.subscribed
disposed = ReactiveTest.disposed
created = ReactiveTest.created


class TestFirst(unittest.TestCase):
    def test_first_async_empty(self):
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(on_next(150, 1), on_completed(250))

        def create():
            return xs.pipe(ops.first())

        res = scheduler.start(create=create)

        assert [on_error(250, lambda e: e)] == res.messages
        assert xs.subscriptions == [subscribe(200, 250)]

    def test_first_async_one(self):
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1), on_next(210, 2), on_completed(250)
        )
        res = scheduler.start(lambda: xs.pipe(ops.first()))

        assert res.messages == [on_next(210, 2), on_completed(210)]
        assert xs.subscriptions == [subscribe(200, 210)]

    def test_first_async_many(self):
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1), on_next(210, 2), on_next(220, 3), on_completed(250)
        )
        res = scheduler.start(lambda: xs.pipe(ops.first()))

        assert res.messages == [on_next(210, 2), on_completed(210)]
        assert xs.subscriptions == [subscribe(200, 210)]

    def test_first_async_error(self):
        ex = ""ex""
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(on_next(150, 1), on_error(210, ex))
        res = scheduler.start(lambda: xs.pipe(ops.first()))

        assert res.messages == [on_error(210, ex)]
        assert xs.subscriptions == [subscribe(200, 210)]

    def test_first_async_predicate(self):
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1),
            on_next(210, 2),
            on_next(220, 3),
            on_next(230, 4),
            on_next(240, 5),
            on_completed(250),
        )

        def create():
            return xs.pipe(ops.first(lambda x: x % 2 == 1))

        res = scheduler.start(create=create)

        assert res.messages == [on_next(220, 3), on_completed(220)]
        assert xs.subscriptions == [subscribe(200, 220)]

    def test_first_async_predicate_none(self):
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1),
            on_next(210, 2),
            on_next(220, 3),
            on_next(230, 4),
            on_next(240, 5),
            on_completed(250),
        )

        def create():
            return xs.pipe(ops.first(lambda x: x > 10))

        res = scheduler.start(create=create)

        assert [on_error(250, lambda e: e)] == res.messages
        assert xs.subscriptions == [subscribe(200, 250)]

    def test_first_async_predicate_on_error(self):
        ex = ""ex""
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1), on_next(210, 2), on_error(220, ex)
        )

        def create():
            return xs.pipe(ops.first(lambda x: x % 2 == 1))

        res = scheduler.start(create=create)

        assert res.messages == [on_error(220, ex)]
        assert xs.subscriptions == [subscribe(200, 220)]

    def test_first_async_predicate_throws(self):
        ex = ""ex""
        scheduler = TestScheduler()
        xs = scheduler.create_hot_observable(
            on_next(150, 1),
            on_next(210, 2),
            on_next(220, 3),
            on_next(230, 4),
            on_next(240, 5),
            on_completed(250),
        )

        def create():
            def predicate(x):
                if x < 4:
                    return False
                else:
                    raise Exception(ex)

            return xs.pipe(ops.first(predicate))

        res = scheduler.start(create=create)

        assert res.messages == [on_error(230, ex)]
        assert xs.subscriptions == [subscribe(200, 230)]


if __name__ == ""__main__"":
    unittest.main()
","
1import unittest
2
3from reactivex import operators as ops
4from reactivex.testing import ReactiveTest, TestScheduler
5
6on_next = ReactiveTest.on_next
7on_completed = ReactiveTest.on_completed
8on_error = ReactiveTest.on_error
9subscribe = ReactiveTest.subscribe
10subscribed = ReactiveTest.subscribed
11disposed = ReactiveTest.disposed
12created = ReactiveTest.created
13
14
15class TestFirst(unittest.TestCase):
16    def test_first_async_empty(self):
17        scheduler = TestScheduler()
18        xs = scheduler.create_hot_observable(on_next(150, 1), on_completed(250))
19
20        def create():
21            return xs.pipe(ops.first())
22
23        res = scheduler.start(create=create)
24
25
26    def test_first_async_one(self):
27        scheduler = TestScheduler()
28        xs = scheduler.create_hot_observable(
29            on_next(150, 1), on_next(210, 2), on_completed(250)
30        )
31        res = scheduler.start(lambda: xs.pipe(ops.first()))
32
33
34    def test_first_async_many(self):
35        scheduler = TestScheduler()
36        xs = scheduler.create_hot_observable(
37            on_next(150, 1), on_next(210, 2), on_next(220, 3), on_completed(250)
38        )
39        res = scheduler.start(lambda: xs.pipe(ops.first()))
40
41
42    def test_first_async_error(self):
43        ex = ""ex""
44        scheduler = TestScheduler()
45        xs = scheduler.create_hot_observable(on_next(150, 1), on_error(210, ex))
46        res = scheduler.start(lambda: xs.pipe(ops.first()))
47
48
49    def test_first_async_predicate(self):
50        scheduler = TestScheduler()
51        xs = scheduler.create_hot_observable(
52            on_next(150, 1),
53            on_next(210, 2),
54            on_next(220, 3),
55            on_next(230, 4),
56            on_next(240, 5),
57            on_completed(250),
58        )
59
60        def create():
61            return xs.pipe(ops.first(lambda x: x % 2 == 1))
62
63        res = scheduler.start(create=create)
64
65
66    def test_first_async_predicate_none(self):
67        scheduler = TestScheduler()
68        xs = scheduler.create_hot_observable(
69            on_next(150, 1),
70            on_next(210, 2),
71            on_next(220, 3),
72            on_next(230, 4),
73            on_next(240, 5),
74            on_completed(250),
75        )
76
77        def create():
78            return xs.pipe(ops.first(lambda x: x > 10))
79
80        res = scheduler.start(create=create)
81
82
83    def test_first_async_predicate_on_error(self):
84        ex = ""ex""
85        scheduler = TestScheduler()
86        xs = scheduler.create_hot_observable(
87            on_next(150, 1), on_next(210, 2), on_error(220, ex)
88        )
89
90        def create():
91            return xs.pipe(ops.first(lambda x: x % 2 == 1))
92
93        res = scheduler.start(create=create)
94
95
96    def test_first_async_predicate_throws(self):
97        ex = ""ex""
98        scheduler = TestScheduler()
99        xs = scheduler.create_hot_observable(
100            on_next(150, 1),
101            on_next(210, 2),
102            on_next(220, 3),
103            on_next(230, 4),
104            on_next(240, 5),
105            on_completed(250),
106        )
107
108        def create():
109            def predicate(x):
110                if x < 4:
111                    return False
112                else:
113                    raise Exception(ex)
114
115            return xs.pipe(ops.first(predicate))
116
117        res = scheduler.start(create=create)
118
119
120
121if __name__ == ""__main__"":
122    unittest.main()
123","[['[on_error(250', '==', 'True'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_next(210'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_next(210'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_error(210'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_next(220'], ['xs.subscriptions', '==', '[subscribe(200'], ['[on_error(250', '==', 'True'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_error(220'], ['xs.subscriptions', '==', '[subscribe(200'], ['res.messages', '==', '[on_error(230'], ['xs.subscriptions', '==', '[subscribe(200']]",16,16,1.0,0.0037664783427495,"['on_next', 'on_completed', 'on_error', 'subscribe', 'subscribed', 'disposed', 'created', 'scheduler', 'xs', 'res', 'ex', 'x']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['on_next', 'on_completed', 'on_error', 'subscribe', 'subscribed', 'disposed', 'created', 'scheduler', 'xs', 'res', 'ex', 'x']
*Code:

1import unittest
2
3from reactivex import operators as ops
4from reactivex.testing import ReactiveTest, TestScheduler
5
6on_next = ReactiveTest.on_next
7on_completed = ReactiveTest.on_completed
8on_error = ReactiveTest.on_error
9subscribe = ReactiveTest.subscribe
10subscribed = ReactiveTest.subscribed
11disposed = ReactiveTest.disposed
12created = ReactiveTest.created
13
14
15class TestFirst(unittest.TestCase):
16    def test_first_async_empty(self):
17        scheduler = TestScheduler()
18        xs = scheduler.create_hot_observable(on_next(150, 1), on_completed(250))
19
20        def create():
21            return xs.pipe(ops.first())
22
23        res = scheduler.start(create=create)
24
25
26    def test_first_async_one(self):
27        scheduler = TestScheduler()
28        xs = scheduler.create_hot_observable(
29            on_next(150, 1), on_next(210, 2), on_completed(250)
30        )
31        res = scheduler.start(lambda: xs.pipe(ops.first()))
32
33
34    def test_first_async_many(self):
35        scheduler = TestScheduler()
36        xs = scheduler.create_hot_observable(
37            on_next(150, 1), on_next(210, 2), on_next(220, 3), on_completed(250)
38        )
39        res = scheduler.start(lambda: xs.pipe(ops.first()))
40
41
42    def test_first_async_error(self):
43        ex = ""ex""
44        scheduler = TestScheduler()
45        xs = scheduler.create_hot_observable(on_next(150, 1), on_error(210, ex))
46        res = scheduler.start(lambda: xs.pipe(ops.first()))
47
48
49    def test_first_async_predicate(self):
50        scheduler = TestScheduler()
51        xs = scheduler.create_hot_observable(
52            on_next(150, 1),
53            on_next(210, 2),
54            on_next(220, 3),
55            on_next(230, 4),
56            on_next(240, 5),
57            on_completed(250),
58        )
59
60        def create():
61            return xs.pipe(ops.first(lambda x: x % 2 == 1))
62
63        res = scheduler.start(create=create)
64
65
66    def test_first_async_predicate_none(self):
67        scheduler = TestScheduler()
68        xs = scheduler.create_hot_observable(
69            on_next(150, 1),
70            on_next(210, 2),
71            on_next(220, 3),
72            on_next(230, 4),
73            on_next(240, 5),
74            on_completed(250),
75        )
76
77        def create():
78            return xs.pipe(ops.first(lambda x: x > 10))
79
80        res = scheduler.start(create=create)
81
82
83    def test_first_async_predicate_on_error(self):
84        ex = ""ex""
85        scheduler = TestScheduler()
86        xs = scheduler.create_hot_observable(
87            on_next(150, 1), on_next(210, 2), on_error(220, ex)
88        )
89
90        def create():
91            return xs.pipe(ops.first(lambda x: x % 2 == 1))
92
93        res = scheduler.start(create=create)
94
95
96    def test_first_async_predicate_throws(self):
97        ex = ""ex""
98        scheduler = TestScheduler()
99        xs = scheduler.create_hot_observable(
100            on_next(150, 1),
101            on_next(210, 2),
102            on_next(220, 3),
103            on_next(230, 4),
104            on_next(240, 5),
105            on_completed(250),
106        )
107
108        def create():
109            def predicate(x):
110                if x < 4:
111                    return False
112                else:
113                    raise Exception(ex)
114
115            return xs.pipe(ops.first(predicate))
116
117        res = scheduler.start(create=create)
118
119
120
121if __name__ == ""__main__"":
122    unittest.main()
123",5083,"[[17, 'scheduler', '!=', None, ""A scheduler is necessary for the process""], 
 [18, 'xs', '!=', None, ""The observable sequence cannot be None""],
 [23, 'res', '!=', None, ""The scheduler must return some results""], 
 [27, 'scheduler', '!=', None, ""A scheduler is necessary for the second test case""], 
 [28, 'xs', '!=', None, ""The observable sequence cannot be None in the second test case""],
 [31, 'res', '!=', None, ""The scheduler must return some results in the second test case""], 
 [35, 'scheduler', '!=', None, ""A scheduler is necessary for the third test case""],  
 [36, 'xs', '!=', None, ""The observable sequence cannot be None in the third test case""],
 [39, 'res', '!=', None, ""The scheduler must return some results in the third test case""], 
 [43, 'ex', '!=', None, ""The exception message cannot be None in the fourth test case""],
 [44, 'scheduler', '!=', None, ""A scheduler is necessary for the fourth test case""], 
 [45, 'xs', '!=', None, ""The observable sequence cannot be None in the fourth test case""],
 [46, 'res', '!=', None, ""The scheduler must return some results in the fourth test case""], 
 [50, 'scheduler', '!=', None, ""A scheduler is necessary for the fifth test case""],  
 [51, 'xs', '!=', None, ""The observable sequence cannot be None in the fifth test case""],
 [63, 'res', '!=', None, ""The scheduler must return some results in the fifth test case""], 
 [67, 'scheduler', '!=', None, ""A scheduler is necessary for the sixth test case""],  
 [68, 'xs', '!=', None, ""The observable sequence cannot be None in the sixth test case""],
 [80, 'res', '!=', None, ""The scheduler must return some results in the sixth test case""],
 [84, 'ex', '!=', None, ""The exception message cannot be None in the seventh test case""],
 [85, 'scheduler', '!=', None, ""A scheduler is necessary for the seventh test case""],
 [86, 'xs', '!=', None, ""The observable sequence cannot be None in the seventh test case""],
 [93, 'res', '!=', None, ""The scheduler must return some results in the seventh test case""], 
 [97, 'ex', '!=', None, ""The excetion message cannot be None in the eighth test case""],
 [98, 'scheduler', '!=', None, ""A scheduler is necessary for the eighth test case""], 
 [99, 'xs', '!=', None, ""The observable sequence cannot be None in the eighth test case""],
 [117, 'res', '!=', None, ""The scheduler must return some results in the eighth test case""]]"
PopCap/GameIdea,"from win32inet import *
from win32inetcon import *
import winerror
from pywin32_testutil import str2bytes # py3k-friendly helper

import unittest

class CookieTests(unittest.TestCase):
    def testCookies(self):
        data = ""TestData=Test""
        InternetSetCookie(""http://www.python.org"", None, data)
        got = InternetGetCookie(""http://www.python.org"", None)
        self.assertEqual(got, data)

    def testCookiesEmpty(self):
        try:
            InternetGetCookie(""http://site-with-no-cookie.python.org"", None)
            self.fail(""expected win32 exception"")
        except error, exc:
            self.failUnlessEqual(exc.winerror, winerror.ERROR_NO_MORE_ITEMS)

class UrlTests(unittest.TestCase):
    def testSimpleCanonicalize(self):
        ret = InternetCanonicalizeUrl(""foo bar"")
        self.assertEqual(ret, ""foo%20bar"")

    def testLongCanonicalize(self):
        # a 4k URL causes the underlying API to request a bigger buffer""
        big = ""x"" * 2048
        ret = InternetCanonicalizeUrl(big + "" "" + big)
        self.assertEqual(ret, big + ""%20"" + big)

class TestNetwork(unittest.TestCase):
    def setUp(self):
        self.hi = InternetOpen(""test"", INTERNET_OPEN_TYPE_DIRECT, None, None, 0)
    def tearDown(self):
        self.hi.Close()
    def testPythonDotOrg(self):
        hdl = InternetOpenUrl(self.hi, ""http://www.python.org"", None,
                              INTERNET_FLAG_EXISTING_CONNECT)
        chunks = []
        while 1:
            chunk = InternetReadFile(hdl, 1024)
            if not chunk:
                break
            chunks.append(chunk)
        data = str2bytes('').join(chunks)
        assert data.find(str2bytes(""Python""))>0, repr(data) # This must appear somewhere on the main page!

    def testFtpCommand(self):
        # ftp.python.org doesn't exist.  ftp.gnu.org is what Python's urllib
        # test code uses.
        hcon = InternetConnect(self.hi, ""ftp.gnu.org"", INTERNET_INVALID_PORT_NUMBER,
                               None, None, # username/password
                               INTERNET_SERVICE_FTP, 0, 0)
        try:
            try:
                hftp = FtpCommand(hcon, True, FTP_TRANSFER_TYPE_ASCII, 'NLST', 0)
            except error:
                print ""Error info is"", InternetGetLastResponseInfo()
            InternetReadFile(hftp, 2048)
            hftp.Close()
        finally:
            hcon.Close()

if __name__=='__main__':
    unittest.main()
","
1from win32inet import *
2from win32inetcon import *
3import winerror
4from pywin32_testutil import str2bytes # py3k-friendly helper
5
6import unittest
7
8class CookieTests(unittest.TestCase):
9    def testCookies(self):
10        data = ""TestData=Test""
11        InternetSetCookie(""http://www.python.org"", None, data)
12        got = InternetGetCookie(""http://www.python.org"", None)
13
14    def testCookiesEmpty(self):
15        try:
16            InternetGetCookie(""http://site-with-no-cookie.python.org"", None)
17            self.fail(""expected win32 exception"")
18        except error, exc:
19            self.failUnlessEqual(exc.winerror, winerror.ERROR_NO_MORE_ITEMS)
20
21class UrlTests(unittest.TestCase):
22    def testSimpleCanonicalize(self):
23        ret = InternetCanonicalizeUrl(""foo bar"")
24
25    def testLongCanonicalize(self):
26        # a 4k URL causes the underlying API to request a bigger buffer""
27        big = ""x"" * 2048
28        ret = InternetCanonicalizeUrl(big + "" "" + big)
29
30class TestNetwork(unittest.TestCase):
31    def setUp(self):
32        self.hi = InternetOpen(""test"", INTERNET_OPEN_TYPE_DIRECT, None, None, 0)
33    def tearDown(self):
34        self.hi.Close()
35    def testPythonDotOrg(self):
36        hdl = InternetOpenUrl(self.hi, ""http://www.python.org"", None,
37                              INTERNET_FLAG_EXISTING_CONNECT)
38        chunks = []
39        while 1:
40            chunk = InternetReadFile(hdl, 1024)
41            if not chunk:
42                break
43            chunks.append(chunk)
44        data = str2bytes('').join(chunks)
45
46    def testFtpCommand(self):
47        # ftp.python.org doesn't exist.  ftp.gnu.org is what Python's urllib
48        # test code uses.
49        hcon = InternetConnect(self.hi, ""ftp.gnu.org"", INTERNET_INVALID_PORT_NUMBER,
50                               None, None, # username/password
51                               INTERNET_SERVICE_FTP, 0, 0)
52        try:
53            try:
54                hftp = FtpCommand(hcon, True, FTP_TRANSFER_TYPE_ASCII, 'NLST', 0)
55            except error:
56                print ""Error info is"", InternetGetLastResponseInfo()
57            InternetReadFile(hftp, 2048)
58            hftp.Close()
59        finally:
60            hcon.Close()
61
62if __name__=='__main__':
63    unittest.main()
64","[['data.find(str2bytes(""Python""))>0', '==', 'True']]",4,1,0.25,0.0004070004070004,"['data', 'got', 'ret', 'big', 'self.hi', 'hdl', 'chunks', 'chunk', 'hcon', 'hftp']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['data', 'got', 'ret', 'big', 'self.hi', 'hdl', 'chunks', 'chunk', 'hcon', 'hftp']
*Code:

1from win32inet import *
2from win32inetcon import *
3import winerror
4from pywin32_testutil import str2bytes # py3k-friendly helper
5
6import unittest
7
8class CookieTests(unittest.TestCase):
9    def testCookies(self):
10        data = ""TestData=Test""
11        InternetSetCookie(""http://www.python.org"", None, data)
12        got = InternetGetCookie(""http://www.python.org"", None)
13
14    def testCookiesEmpty(self):
15        try:
16            InternetGetCookie(""http://site-with-no-cookie.python.org"", None)
17            self.fail(""expected win32 exception"")
18        except error, exc:
19            self.failUnlessEqual(exc.winerror, winerror.ERROR_NO_MORE_ITEMS)
20
21class UrlTests(unittest.TestCase):
22    def testSimpleCanonicalize(self):
23        ret = InternetCanonicalizeUrl(""foo bar"")
24
25    def testLongCanonicalize(self):
26        # a 4k URL causes the underlying API to request a bigger buffer""
27        big = ""x"" * 2048
28        ret = InternetCanonicalizeUrl(big + "" "" + big)
29
30class TestNetwork(unittest.TestCase):
31    def setUp(self):
32        self.hi = InternetOpen(""test"", INTERNET_OPEN_TYPE_DIRECT, None, None, 0)
33    def tearDown(self):
34        self.hi.Close()
35    def testPythonDotOrg(self):
36        hdl = InternetOpenUrl(self.hi, ""http://www.python.org"", None,
37                              INTERNET_FLAG_EXISTING_CONNECT)
38        chunks = []
39        while 1:
40            chunk = InternetReadFile(hdl, 1024)
41            if not chunk:
42                break
43            chunks.append(chunk)
44        data = str2bytes('').join(chunks)
45
46    def testFtpCommand(self):
47        # ftp.python.org doesn't exist.  ftp.gnu.org is what Python's urllib
48        # test code uses.
49        hcon = InternetConnect(self.hi, ""ftp.gnu.org"", INTERNET_INVALID_PORT_NUMBER,
50                               None, None, # username/password
51                               INTERNET_SERVICE_FTP, 0, 0)
52        try:
53            try:
54                hftp = FtpCommand(hcon, True, FTP_TRANSFER_TYPE_ASCII, 'NLST', 0)
55            except error:
56                print ""Error info is"", InternetGetLastResponseInfo()
57            InternetReadFile(hftp, 2048)
58            hftp.Close()
59        finally:
60            hcon.Close()
61
62if __name__=='__main__':
63    unittest.main()
64",3804,"[10, 'data', '==', '""TestData=Test""', 'the variable data must be equal to ""TestData=Test"" for the test to work properly'],
[12, 'got', '!=', None, 'must return a cookie from the URL or the test will fail'],
[28, 'big', '==', '""x"" * 2048', 'making sure that the variable big is the correct size'],
[32, 'self.hi', '!=', None, 'InternetOpen must return a value for the tests to proceed'],
[40, 'chunk', '!=', None, 'InternetReadFile must return a chunk'],
[44, 'data', '!=', None, 'the variable data should not be None after joining the chunks'],
[49, 'hcon', '!=', None, 'InternetConnect should not return None'],
[54, 'hftp', '!=', None, 'FtpCommand should not return None']"
scop/bash-completion,"import pytest


@pytest.mark.bashcomp(cmd=""update-rc.d"")
class TestUpdateRcD:
    @pytest.mark.complete(""update-rc.d -"")
    def test_1(self, completion):
        assert completion
","
1import pytest
2
3
4@pytest.mark.bashcomp(cmd=""update-rc.d"")
5class TestUpdateRcD:
6    @pytest.mark.complete(""update-rc.d -"")
7    def test_1(self, completion):
8","[['completion', '==', 'True']]",1,1,1.0,0.005524861878453,['completion'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['completion']
*Code:

1import pytest
2
3
4@pytest.mark.bashcomp(cmd=""update-rc.d"")
5class TestUpdateRcD:
6    @pytest.mark.complete(""update-rc.d -"")
7    def test_1(self, completion):
8",1558,"[[7, 'completion', '!=', None, ""the 'completion' argument should not be None""]]"
mellenburg/dcos,"from typing import Optional

import boto3
import botocore

from release.storage import AbstractStorageProvider


def get_aws_session(access_key_id, secret_access_key, region_name=None):
    """""" This method will replace access_key_id and secret_access_key
    with None if one is set to '' This allows falling back to the AWS internal
    logic so that one of the following options can be used:
    http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials

    This is needed by dcos_installer/backend.py which does AWS actions using
    explicit credentials. The process is ran from the dcos_generate_config.sh
    artifact docker container, which can interfere with the usual boto3 credential method.
    The gen library only uses empty strings to denote unset, which does not work for boto3
    """"""
    if not access_key_id:
        access_key_id = None
    if not secret_access_key:
        secret_access_key = None
    return boto3.session.Session(
        aws_access_key_id=access_key_id,
        aws_secret_access_key=secret_access_key,
        region_name=region_name)


class S3StorageProvider(AbstractStorageProvider):
    name = 'aws'

    def __init__(self, bucket, object_prefix, download_url,
                 access_key_id=None, secret_access_key=None, region_name=None):
        """""" If access_key_id and secret_acccess_key are unset, boto3 will
        try to authenticate by other methods. See here for other credential options:
        http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials
        """"""
        if object_prefix is not None:
            assert object_prefix and not object_prefix.startswith('/') and not object_prefix.endswith('/')

        self.__session = get_aws_session(access_key_id, secret_access_key, region_name)
        self.__bucket = self.__session.resource('s3').Bucket(bucket)
        self.__object_prefix = object_prefix
        self.__url = download_url

    @property
    def object_prefix(self):
        if self.__object_prefix is None:
            return ''
        return self.__object_prefix + '/'

    def _get_path(self, name):

        return self.object_prefix + name

    def _get_objects_with_prefix(self, prefix):
        return self.__bucket.objects.filter(Prefix=self._get_path(prefix))

    def get_object(self, name):
        assert not name.startswith('/')
        return self.__bucket.Object(self._get_path(name))

    def fetch(self, path):
        body = self.get_object(path).get()['Body']
        data = bytes()
        for chunk in iter(lambda: body.read(4096), b''):
            data += chunk
        return data

    def download_inner(self, path, local_path):
        self.get_object(path).download_file(local_path)

    @property
    def url(self):
        return self.__url

    def copy(self, source_path, destination_path):
        src_object = self.get_object(source_path)
        new_object = self.get_object(destination_path)
        old_path = src_object.bucket_name + '/' + src_object.key

        new_object.copy_from(CopySource=old_path)

    def upload(self,
               destination_path: str,
               blob: Optional[bytes]=None,
               local_path: Optional[str]=None,
               no_cache: bool=False,
               content_type: Optional[str]=None):
        extra_args = {}
        if no_cache:
            extra_args['CacheControl'] = 'no-cache'
        if content_type:
            extra_args['ContentType'] = content_type

        s3_object = self.get_object(destination_path)

        assert local_path is None or blob is None
        if local_path:
            with open(local_path, 'rb') as data:
                s3_object.put(Body=data, **extra_args)
        else:
            assert isinstance(blob, bytes)
            s3_object.put(Body=blob, **extra_args)

    def exists(self, path):
        try:
            self.get_object(path).load()
            return True
        except botocore.client.ClientError:
            return False

    def list_recursive(self, path):
        prefix_len = len(self.object_prefix)
        names = set()
        for object_summary in self._get_objects_with_prefix(path):
            name = object_summary.key

            # Sanity check the prefix is there before removing.
            assert name.startswith(self.__object_prefix + '/')

            # Add the unprefixed name since the caller of this function doesn't
            # know we've added the prefix / only sees inside the prefix ever.
            names.add(name[prefix_len:])

        return names

    def remove_recursive(self, path):
        for obj in self._get_objects_with_prefix(path):
            obj.delete()


factories = {
    ""s3"": S3StorageProvider
}
","
1from typing import Optional
2
3import boto3
4import botocore
5
6from release.storage import AbstractStorageProvider
7
8
9def get_aws_session(access_key_id, secret_access_key, region_name=None):
10    """""" This method will replace access_key_id and secret_access_key
11    with None if one is set to '' This allows falling back to the AWS internal
12    logic so that one of the following options can be used:
13    http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials
14
15    This is needed by dcos_installer/backend.py which does AWS actions using
16    explicit credentials. The process is ran from the dcos_generate_config.sh
17    artifact docker container, which can interfere with the usual boto3 credential method.
18    The gen library only uses empty strings to denote unset, which does not work for boto3
19    """"""
20    if not access_key_id:
21        access_key_id = None
22    if not secret_access_key:
23        secret_access_key = None
24    return boto3.session.Session(
25        aws_access_key_id=access_key_id,
26        aws_secret_access_key=secret_access_key,
27        region_name=region_name)
28
29
30class S3StorageProvider(AbstractStorageProvider):
31    name = 'aws'
32
33    def __init__(self, bucket, object_prefix, download_url,
34                 access_key_id=None, secret_access_key=None, region_name=None):
35        """""" If access_key_id and secret_acccess_key are unset, boto3 will
36        try to authenticate by other methods. See here for other credential options:
37        http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials
38        """"""
39        if object_prefix is not None:
40
41        self.__session = get_aws_session(access_key_id, secret_access_key, region_name)
42        self.__bucket = self.__session.resource('s3').Bucket(bucket)
43        self.__object_prefix = object_prefix
44        self.__url = download_url
45
46    @property
47    def object_prefix(self):
48        if self.__object_prefix is None:
49            return ''
50        return self.__object_prefix + '/'
51
52    def _get_path(self, name):
53
54        return self.object_prefix + name
55
56    def _get_objects_with_prefix(self, prefix):
57        return self.__bucket.objects.filter(Prefix=self._get_path(prefix))
58
59    def get_object(self, name):
60        return self.__bucket.Object(self._get_path(name))
61
62    def fetch(self, path):
63        body = self.get_object(path).get()['Body']
64        data = bytes()
65        for chunk in iter(lambda: body.read(4096), b''):
66            data += chunk
67        return data
68
69    def download_inner(self, path, local_path):
70        self.get_object(path).download_file(local_path)
71
72    @property
73    def url(self):
74        return self.__url
75
76    def copy(self, source_path, destination_path):
77        src_object = self.get_object(source_path)
78        new_object = self.get_object(destination_path)
79        old_path = src_object.bucket_name + '/' + src_object.key
80
81        new_object.copy_from(CopySource=old_path)
82
83    def upload(self,
84               destination_path: str,
85               blob: Optional[bytes]=None,
86               local_path: Optional[str]=None,
87               no_cache: bool=False,
88               content_type: Optional[str]=None):
89        extra_args = {}
90        if no_cache:
91            extra_args['CacheControl'] = 'no-cache'
92        if content_type:
93            extra_args['ContentType'] = content_type
94
95        s3_object = self.get_object(destination_path)
96
97        if local_path:
98            with open(local_path, 'rb') as data:
99                s3_object.put(Body=data, **extra_args)
100        else:
101            s3_object.put(Body=blob, **extra_args)
102
103    def exists(self, path):
104        try:
105            self.get_object(path).load()
106            return True
107        except botocore.client.ClientError:
108            return False
109
110    def list_recursive(self, path):
111        prefix_len = len(self.object_prefix)
112        names = set()
113        for object_summary in self._get_objects_with_prefix(path):
114            name = object_summary.key
115
116            # Sanity check the prefix is there before removing.
117
118            # Add the unprefixed name since the caller of this function doesn't
119            # know we've added the prefix / only sees inside the prefix ever.
120            names.add(name[prefix_len:])
121
122        return names
123
124    def remove_recursive(self, path):
125        for obj in self._get_objects_with_prefix(path):
126            obj.delete()
127
128
129factories = {
130    ""s3"": S3StorageProvider
131}
132","[['object_prefix', '==', 'True'], [""object_prefix.startswith('/')"", '==', 'False'], [""object_prefix.endswith('/')"", '==', 'False'], [""name.startswith('/')"", '==', 'False'], ['name.startswith(self.__object_prefix', '+', ""'/')""]]",5,5,1.0,0.0010550749103186,"['access_key_id', 'secret_access_key', 'region_name', 'name', 'bucket', 'object_prefix', 'download_url', 'self.__session', 'self.__bucket', 'self.__object_prefix', 'self.__url', 'prefix', 'path', 'body', 'data', 'local_path', 'source_path', 'destination_path', 'src_object', 'new_object', 'old_path', 'extra_args', ""extra_args['CacheControl']"", ""extra_args['ContentType']"", 's3_object', 'prefix_len', 'names', 'factories']",28,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['access_key_id', 'secret_access_key', 'region_name', 'name', 'bucket', 'object_prefix', 'download_url', 'self.__session', 'self.__bucket', 'self.__object_prefix', 'self.__url', 'prefix', 'path', 'body', 'data', 'local_path', 'source_path', 'destination_path', 'src_object', 'new_object', 'old_path', 'extra_args', ""extra_args['CacheControl']"", ""extra_args['ContentType']"", 's3_object', 'prefix_len', 'names', 'factories']
*Code:

1from typing import Optional
2
3import boto3
4import botocore
5
6from release.storage import AbstractStorageProvider
7
8
9def get_aws_session(access_key_id, secret_access_key, region_name=None):
10    """""" This method will replace access_key_id and secret_access_key
11    with None if one is set to '' This allows falling back to the AWS internal
12    logic so that one of the following options can be used:
13    http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials
14
15    This is needed by dcos_installer/backend.py which does AWS actions using
16    explicit credentials. The process is ran from the dcos_generate_config.sh
17    artifact docker container, which can interfere with the usual boto3 credential method.
18    The gen library only uses empty strings to denote unset, which does not work for boto3
19    """"""
20    if not access_key_id:
21        access_key_id = None
22    if not secret_access_key:
23        secret_access_key = None
24    return boto3.session.Session(
25        aws_access_key_id=access_key_id,
26        aws_secret_access_key=secret_access_key,
27        region_name=region_name)
28
29
30class S3StorageProvider(AbstractStorageProvider):
31    name = 'aws'
32
33    def __init__(self, bucket, object_prefix, download_url,
34                 access_key_id=None, secret_access_key=None, region_name=None):
35        """""" If access_key_id and secret_acccess_key are unset, boto3 will
36        try to authenticate by other methods. See here for other credential options:
37        http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials
38        """"""
39        if object_prefix is not None:
40
41        self.__session = get_aws_session(access_key_id, secret_access_key, region_name)
42        self.__bucket = self.__session.resource('s3').Bucket(bucket)
43        self.__object_prefix = object_prefix
44        self.__url = download_url
45
46    @property
47    def object_prefix(self):
48        if self.__object_prefix is None:
49            return ''
50        return self.__object_prefix + '/'
51
52    def _get_path(self, name):
53
54        return self.object_prefix + name
55
56    def _get_objects_with_prefix(self, prefix):
57        return self.__bucket.objects.filter(Prefix=self._get_path(prefix))
58
59    def get_object(self, name):
60        return self.__bucket.Object(self._get_path(name))
61
62    def fetch(self, path):
63        body = self.get_object(path).get()['Body']
64        data = bytes()
65        for chunk in iter(lambda: body.read(4096), b''):
66            data += chunk
67        return data
68
69    def download_inner(self, path, local_path):
70        self.get_object(path).download_file(local_path)
71
72    @property
73    def url(self):
74        return self.__url
75
76    def copy(self, source_path, destination_path):
77        src_object = self.get_object(source_path)
78        new_object = self.get_object(destination_path)
79        old_path = src_object.bucket_name + '/' + src_object.key
80
81        new_object.copy_from(CopySource=old_path)
82
83    def upload(self,
84               destination_path: str,
85               blob: Optional[bytes]=None,
86               local_path: Optional[str]=None,
87               no_cache: bool=False,
88               content_type: Optional[str]=None):
89        extra_args = {}
90        if no_cache:
91            extra_args['CacheControl'] = 'no-cache'
92        if content_type:
93            extra_args['ContentType'] = content_type
94
95        s3_object = self.get_object(destination_path)
96
97        if local_path:
98            with open(local_path, 'rb') as data:
99                s3_object.put(Body=data, **extra_args)
100        else:
101            s3_object.put(Body=blob, **extra_args)
102
103    def exists(self, path):
104        try:
105            self.get_object(path).load()
106            return True
107        except botocore.client.ClientError:
108            return False
109
110    def list_recursive(self, path):
111        prefix_len = len(self.object_prefix)
112        names = set()
113        for object_summary in self._get_objects_with_prefix(path):
114            name = object_summary.key
115
116            # Sanity check the prefix is there before removing.
117
118            # Add the unprefixed name since the caller of this function doesn't
119            # know we've added the prefix / only sees inside the prefix ever.
120            names.add(name[prefix_len:])
121
122        return names
123
124    def remove_recursive(self, path):
125        for obj in self._get_objects_with_prefix(path):
126            obj.delete()
127
128
129factories = {
130    ""s3"": S3StorageProvider
131}
132",6527,"[[9, 'access_key_id', '!=', None, ""access_key_id is required for AWS session""],
[9, 'secret_access_key', '!=', None, ""secret_access_key is required for AWS session""],
[33, 'bucket', '!=', None, ""Bucket is essential for S3StorageProvider""],
[33, 'object_prefix', '!=', None, ""object_prefix is needed for S3StorageProvider""],
[33, 'download_url', '!=', None, ""download_url is needed for S3StorageProvider""],
[61, 'name', '!=', None, ""Name is essential to get object from bucket""],
[63, 'path', '!=', None, ""Path is necessary to fetch the object""],
[69, 'path', '!=', None, ""Path is mandatory to download the object""],
[69, 'local_path', '!=', None, ""local_path is mandatory to save downloaded file""],
[76, 'source_path', '!=', None, ""Source path is required for copying operation""],
[76, 'destination_path', '!=', None, ""Destination path is required for copying operation""],
[83, 'destination_path', '!=', None, ""Destination path is required for uploading operation""],
[103, 'path', '!=', None, ""Path is mandatory to check the object existence""],
[110, 'path', '!=', None, ""Path is needed to list recursively""],
[124, 'path', '!=', None, ""Path is required to delete objects recursively""],
]"
hashamali/pyScss,"""""""Tests for the type system.""""""
from __future__ import absolute_import
from __future__ import print_function
from __future__ import unicode_literals

from scss.types import Color, List, Null, Number, String

import pytest


# Operators: arithmetic (+ - * / %), unary (+ -), comparison (== != < > <= >=), boolean
# Types: numbers, colors, strings, booleans, lists
# Test them all!

def test_addition():
    # Numbers are a little complicated, what with all the units
    # Simple case
    assert Number(123) + Number(456) == Number(579)
    # Simple equal units
    assert Number(1, ""px"") + Number(2, ""px"") == Number(3, ""px"")
    # Unitless values inherit units of the other operand
    assert Number(5) + Number(6, ""px"") == Number(11, ""px"")
    # Zero values can cast to any units
    assert Number(0, ""in"") + Number(24, ""deg"") == Number(24, ""deg"")
    # With different units, the left operand wins
    assert Number(10, ""cm"") + Number(100, ""mm"") == Number(20, ""cm"")
    assert Number(100, ""mm"") + Number(10, ""cm"") == Number(200, ""mm"")
    # Unconvertible units raise an error
    with pytest.raises(ValueError):
        Number(1, ""px"") + Number(1, ""em"")

    # Adding anything to a string makes a string
    assert Number(123) + String('abc') == String('123abc')
    assert String('abc') + Number(123) == String('abc123')

    ret = String('abc', quotes=None) + String('def', quotes=None)
    assert ret == String('abcdef')
    assert ret.quotes is None

    ret = String('abc', quotes='""') + String('def', quotes=None)
    assert ret == String('abcdef')
    assert ret.quotes == '""'

    ret = String('abc', quotes=None) + String('def', quotes='""')
    assert ret == String('abcdef')
    assert ret.quotes is None

    assert Color.from_hex('#010305') + Color.from_hex('#050301') == Color.from_hex('#060606')
    assert Color.from_name('white') + Color.from_name('white') == Color.from_name('white')


def test_subtraction():
    assert Number(123) - Number(456) == Number(-333)
    assert Number(456) - Number(123) == Number(333)
    # TODO test that subtracting e.g. strings doesn't work

    assert Color.from_hex('#0f0f0f') - Color.from_hex('#050505') == Color.from_hex('#0a0a0a')


def test_division():
    assert Number(5, ""px"") / Number(5, ""px"") == Number(1)
    assert Number(1, ""in"") / Number(6, ""pt"") == Number(12)


def test_comparison_numeric():
    lo = Number(123)
    hi = Number(456)
    assert lo < hi
    assert lo <= hi
    assert lo <= lo
    assert hi > lo
    assert hi >= lo
    assert hi >= hi
    assert lo == lo
    assert lo != hi

    # Same tests, negated
    assert not lo > hi
    assert not lo >= hi
    assert not hi < lo
    assert not hi <= lo
    assert not lo != lo
    assert not lo == hi

    # Numbers with units should also auto-cast numbers with units
    units = Number(123, ""px"")
    plain = Number(123)
    assert units == plain
    assert units <= plain
    assert units >= plain
    assert not units != plain
    assert not units < plain
    assert not units > plain

    # Incompatible units have...  rules.
    ems = Number(100, ""em"")
    pxs = Number(100, ""px"")

    with pytest.raises(ValueError):
        ems < pxs
    with pytest.raises(ValueError):
        ems > pxs
    with pytest.raises(ValueError):
        ems <= pxs
    with pytest.raises(ValueError):
        ems >= pxs

    assert not ems == pxs
    assert ems != pxs


def test_comparison_stringerific():
    abc = String('abc')
    xyz = String('xyz')

    assert abc == abc
    assert abc != xyz
    assert not abc == xyz
    assert not abc != abc

    # Interaction with other types
    assert Number(123) != String('123')
    assert String('123') != Number(123)

    # Sass strings don't support ordering
    with pytest.raises(TypeError):
        abc < xyz

    with pytest.raises(TypeError):
        abc <= xyz

    with pytest.raises(TypeError):
        abc > xyz

    with pytest.raises(TypeError):
        abc >= xyz

    with pytest.raises(TypeError):
        Number(123) < String('123')


def test_comparison_null():
    null = Null()

    assert null == null
    assert null != Number(0)

    with pytest.raises(TypeError):
        null < null


def test_unrenderable():
    # Empty lists can't be rendered as CSS
    with pytest.raises(ValueError):
        List([]).render()


# TODO write more!  i'm lazy.
","
1""""""Tests for the type system.""""""
2from __future__ import absolute_import
3from __future__ import print_function
4from __future__ import unicode_literals
5
6from scss.types import Color, List, Null, Number, String
7
8import pytest
9
10
11# Operators: arithmetic (+ - * / %), unary (+ -), comparison (== != < > <= >=), boolean
12# Types: numbers, colors, strings, booleans, lists
13# Test them all!
14
15def test_addition():
16    # Numbers are a little complicated, what with all the units
17    # Simple case
18    # Simple equal units
19    # Unitless values inherit units of the other operand
20    # Zero values can cast to any units
21    # With different units, the left operand wins
22    # Unconvertible units raise an error
23    with pytest.raises(ValueError):
24        Number(1, ""px"") + Number(1, ""em"")
25
26    # Adding anything to a string makes a string
27
28    ret = String('abc', quotes=None) + String('def', quotes=None)
29
30    ret = String('abc', quotes='""') + String('def', quotes=None)
31
32    ret = String('abc', quotes=None) + String('def', quotes='""')
33
34
35
36def test_subtraction():
37    # TODO test that subtracting e.g. strings doesn't work
38
39
40
41def test_division():
42
43
44def test_comparison_numeric():
45    lo = Number(123)
46    hi = Number(456)
47
48    # Same tests, negated
49
50    # Numbers with units should also auto-cast numbers with units
51    units = Number(123, ""px"")
52    plain = Number(123)
53
54    # Incompatible units have...  rules.
55    ems = Number(100, ""em"")
56    pxs = Number(100, ""px"")
57
58    with pytest.raises(ValueError):
59        ems < pxs
60    with pytest.raises(ValueError):
61        ems > pxs
62    with pytest.raises(ValueError):
63        ems <= pxs
64    with pytest.raises(ValueError):
65        ems >= pxs
66
67
68
69def test_comparison_stringerific():
70    abc = String('abc')
71    xyz = String('xyz')
72
73
74    # Interaction with other types
75
76    # Sass strings don't support ordering
77    with pytest.raises(TypeError):
78        abc < xyz
79
80    with pytest.raises(TypeError):
81        abc <= xyz
82
83    with pytest.raises(TypeError):
84        abc > xyz
85
86    with pytest.raises(TypeError):
87        abc >= xyz
88
89    with pytest.raises(TypeError):
90        Number(123) < String('123')
91
92
93def test_comparison_null():
94    null = Null()
95
96
97    with pytest.raises(TypeError):
98        null < null
99
100
101def test_unrenderable():
102    # Empty lists can't be rendered as CSS
103    with pytest.raises(ValueError):
104        List([]).render()
105
106
107# TODO write more!  i'm lazy.
108","[['Number(123) + Number(456)', '==', 'Number(579)'], ['Number(1', '==', 'True'], ['Number(5)', '+', 'Number(6'], ['Number(0', '==', 'True'], ['Number(10', '==', 'True'], ['Number(100', '==', 'True'], [""Number(123) + String('abc')"", '==', ""String('123abc')""], [""String('abc') + Number(123)"", '==', ""String('abc123')""], ['ret', '==', ""String('abcdef')""], ['ret.quotes', '==', 'None'], ['ret', '==', ""String('abcdef')""], ['ret.quotes', '==', '\'""\''], ['ret', '==', ""String('abcdef')""], ['ret.quotes', '==', 'None'], [""Color.from_hex('"", '==', 'True'], [""Color.from_name('white') + Color.from_name('white')"", '==', ""Color.from_name('white')""], ['Number(123) - Number(456)', '==', 'Number(-333)'], ['Number(456) - Number(123)', '==', 'Number(333)'], [""Color.from_hex('"", '==', 'True'], ['Number(5', '==', 'True'], ['Number(1', '==', 'True'], ['lo', '<', 'hi'], ['lo', '<=', 'hi'], ['lo', '<=', 'lo'], ['hi', '>', 'lo'], ['hi', '>=', 'lo'], ['hi', '>=', 'hi'], ['lo', '==', 'lo'], ['lo', '!=', 'hi'], ['lo', '>', 'hi'], ['lo', '>=', 'hi'], ['hi', '<', 'lo'], ['hi', '<=', 'lo'], ['lo', '!=', 'lo'], ['lo', '==', 'hi'], ['units', '==', 'plain'], ['units', '<=', 'plain'], ['units', '>=', 'plain'], ['units', '!=', 'plain'], ['units', '<', 'plain'], ['units', '>', 'plain'], ['ems', '==', 'pxs'], ['ems', '!=', 'pxs'], ['abc', '==', 'abc'], ['abc', '!=', 'xyz'], ['abc', '==', 'xyz'], ['abc', '!=', 'abc'], ['Number(123)', '!=', ""String('123')""], [""String('123')"", '!=', 'Number(123)'], ['null', '==', 'null'], ['null', '!=', 'Number(0)']]",51,51,1.0,0.0117619926199262,"['ret', 'lo', 'hi', 'units', 'plain', 'ems', 'pxs', 'abc', 'xyz', 'null']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ret', 'lo', 'hi', 'units', 'plain', 'ems', 'pxs', 'abc', 'xyz', 'null']
*Code:

1""""""Tests for the type system.""""""
2from __future__ import absolute_import
3from __future__ import print_function
4from __future__ import unicode_literals
5
6from scss.types import Color, List, Null, Number, String
7
8import pytest
9
10
11# Operators: arithmetic (+ - * / %), unary (+ -), comparison (== != < > <= >=), boolean
12# Types: numbers, colors, strings, booleans, lists
13# Test them all!
14
15def test_addition():
16    # Numbers are a little complicated, what with all the units
17    # Simple case
18    # Simple equal units
19    # Unitless values inherit units of the other operand
20    # Zero values can cast to any units
21    # With different units, the left operand wins
22    # Unconvertible units raise an error
23    with pytest.raises(ValueError):
24        Number(1, ""px"") + Number(1, ""em"")
25
26    # Adding anything to a string makes a string
27
28    ret = String('abc', quotes=None) + String('def', quotes=None)
29
30    ret = String('abc', quotes='""') + String('def', quotes=None)
31
32    ret = String('abc', quotes=None) + String('def', quotes='""')
33
34
35
36def test_subtraction():
37    # TODO test that subtracting e.g. strings doesn't work
38
39
40
41def test_division():
42
43
44def test_comparison_numeric():
45    lo = Number(123)
46    hi = Number(456)
47
48    # Same tests, negated
49
50    # Numbers with units should also auto-cast numbers with units
51    units = Number(123, ""px"")
52    plain = Number(123)
53
54    # Incompatible units have...  rules.
55    ems = Number(100, ""em"")
56    pxs = Number(100, ""px"")
57
58    with pytest.raises(ValueError):
59        ems < pxs
60    with pytest.raises(ValueError):
61        ems > pxs
62    with pytest.raises(ValueError):
63        ems <= pxs
64    with pytest.raises(ValueError):
65        ems >= pxs
66
67
68
69def test_comparison_stringerific():
70    abc = String('abc')
71    xyz = String('xyz')
72
73
74    # Interaction with other types
75
76    # Sass strings don't support ordering
77    with pytest.raises(TypeError):
78        abc < xyz
79
80    with pytest.raises(TypeError):
81        abc <= xyz
82
83    with pytest.raises(TypeError):
84        abc > xyz
85
86    with pytest.raises(TypeError):
87        abc >= xyz
88
89    with pytest.raises(TypeError):
90        Number(123) < String('123')
91
92
93def test_comparison_null():
94    null = Null()
95
96
97    with pytest.raises(TypeError):
98        null < null
99
100
101def test_unrenderable():
102    # Empty lists can't be rendered as CSS
103    with pytest.raises(ValueError):
104        List([]).render()
105
106
107# TODO write more!  i'm lazy.
108",4070,"[[15, 'ret', '==', 'null', 'Ensure ret is properly initialized before addition tests'],
 [36, 'ret', '==', 'null', 'Ensure ret is properly initialized before subtraction tests'],
 [41, 'ret', '==', 'null', 'Ensure ret is properly initialized before division tests'],
 [44, 'lo', '!=', 'null', 'Ensure lo is assigned for numeric comparison'],
 [44, 'hi', '!=', 'null', 'Ensure hi is assigned for numeric comparison'],
 [44, 'units', '==', 'null', 'Ensure units is properly initialized before numeric comparison tests'],
 [44, 'plain', '==', 'null', 'Ensure plain is properly initialized before numeric comparison tests'],
 [44, 'ems', '==', 'null', 'Ensure ems is properly initialized before numeric comparison tests'],
 [44, 'pxs', '==', 'null', 'Ensure pxs is properly initialized before numeric comparison tests'],
 [69, 'abc', '!=', 'null', 'Ensure abc is assigned for string comparison'],
 [69, 'xyz', '!=', 'null', 'Ensure xyz is assigned for string comparison'],
 [93, 'null', '!=', 'null', 'Ensure null is assigned for null comparison'],
 [101, 'null', '==', 'null', 'Ensure null is properly initialized before unrenderable test']]"
weihengSu/testing,"__author__ = 'weiheng su'
import unittest
from graph import Graph

class TestGraph(unittest.TestCase):

    def setUp(self):
        self.g1 = Graph( {'A':['B','D'], 'B': ['A','D','C'], 'C': ['B'], 'D':['A','B'],'E':[]})

    """"""test-id: G1""""""
    def test_get_adjlist_g1(self):
        assert self.g1.get_adjlist('A') == ['B','D'], ""Test-id: G1. Node A connects B and D, so it should return ['B','D']""
        assert self.g1.get_adjlist('E') == [], ""Test-id: g1. Node E contains nothing, and it should return []""
        assert self.g1.get_adjlist('Z') == None, ""Test-id: G1. Node Z is not in the graph, so it should return None""
    """"""test-id: G2""""""
    def test_is_adjacent_g2(self):
        assert self.g1.is_adjacent('B','C')== True,""Test-id: G2. Node B and C are connected, and it should return true""
        assert self.g1.is_adjacent('B','E')== False,""Test-id: G2. Node B and E are not connected, and it should return false""
        assert self.g1.is_adjacent('F','B')== False,""Test-id: G2. F is not in the graph, and it should return true""

    """"""test-id: G3 """"""
    def test_num_nodes_g3(self):
        assert self.g1.num_nodes()== 5, ""Test-id: G3. Total nodes in the graph are 5, and it should return 5""

    """"""test-id: G4""""""
    def test___contains___g4(self):
        assert self.g1.__contains__('A') == True, ""Test-id: G4. It should return true since A is in the graph""
        assert self.g1.__contains__('Z') == False, ""Test-id: G4. It should return false since Z is not in the graph""

    """"""test-id: G5 """"""
    def test_len_g5(self):
        assert len(self.g1)== 5, ""Test-id: G5. The length should be the number of nodes, which is 5""

    """"""test-id: G6 """"""
    def test_add_node_g6(self):
        assert self.g1.add_node('F') == True, ""Test-id: G6. It should return true because F is not in the graph""
        assert self.g1.add_node('A') == False, ""Test-id: G6. It should return false because A is in the graph""

    """"""test-id: G7""""""
    def test_link_nodes_g7(self):
        assert self.g1.link_nodes('A','E') == True, ""Test-id: G7. It should return true if A and E are connected""
        assert self.g1.link_nodes('A','B') == False, ""Test-id: G7. Since A and B are already connected, it should return false""
        assert self.g1.link_nodes('A','Z') == False, ""Test-id: G7. It should return false because Z is not in the graph""
        assert self.g1.link_nodes('A','A') == False, ""Test-id: G7. It should return false because two nodes are the same""
        assert self.g1.link_nodes('H','Z') == False, ""Test-id: G7. It should return false because nodes are not in the graph""
    """"""test-id: G8""""""
    def test_unlink_nodes_g8(self):
        assert self.g1.unlink_nodes('A','C') == False, ""Test-id: G8. It should return false since two nodes are initially not connected""
        assert self.g1.unlink_nodes('A','B') == True, ""Test-id: G8. It should return true after two nodes are not unlinked""
        assert self.g1.unlink_nodes('A','F') == False, ""Test-id: G8. It should return false since node F is not in the graph""
        assert self.g1.unlink_nodes('Z','F') == False, ""Test-id: G8. It should return false since two nodes are not in the graph""

    """""" test-id: G9""""""
    def test_del_node_g9(self):
        assert self.g1.del_node('C') == True, ""Test-id: G9. It should return true if node C is successfully removed""
        assert self.g1.del_node('Z') == False, ""Test-id: G9. It should return false since node Z is not in the graph""







","
1__author__ = 'weiheng su'
2import unittest
3from graph import Graph
4
5class TestGraph(unittest.TestCase):
6
7    def setUp(self):
8        self.g1 = Graph( {'A':['B','D'], 'B': ['A','D','C'], 'C': ['B'], 'D':['A','B'],'E':[]})
9
10    """"""test-id: G1""""""
11    def test_get_adjlist_g1(self):
12    """"""test-id: G2""""""
13    def test_is_adjacent_g2(self):
14
15    """"""test-id: G3 """"""
16    def test_num_nodes_g3(self):
17
18    """"""test-id: G4""""""
19    def test___contains___g4(self):
20
21    """"""test-id: G5 """"""
22    def test_len_g5(self):
23
24    """"""test-id: G6 """"""
25    def test_add_node_g6(self):
26
27    """"""test-id: G7""""""
28    def test_link_nodes_g7(self):
29    """"""test-id: G8""""""
30    def test_unlink_nodes_g8(self):
31
32    """""" test-id: G9""""""
33    def test_del_node_g9(self):
34
35
36
37
38
39
40
41","[[""self.g1.get_adjlist('A')"", '==', ""['B'""], ['D', '==', 'True'], [""self.g1.get_adjlist('E')"", '==', '[]'], ['it', 'should', 'return', '[]""'], [""self.g1.is_adjacent('B'"", '==', 'True'], ['C', 'are', 'connected'], ['it', 'should', 'return', 'true""'], [""self.g1.is_adjacent('B'"", '==', 'True'], ['E', 'are', 'not', 'connected'], ['it', 'should', 'return', 'false""'], ['len(self.g1)==', '5'], [""self.g1.link_nodes('A'"", '==', 'True'], ['E', 'are', 'connected""'], [""self.g1.link_nodes('A'"", '==', 'True'], ['B', 'are', 'already', 'connected'], [""self.g1.link_nodes('A'"", '==', 'True'], [""self.g1.unlink_nodes('A'"", '==', 'True'], [""self.g1.unlink_nodes('A'"", '==', 'True'], [""self.g1.del_node('C')"", '==', 'True']]",23,19,0.8260869565217391,0.0054644808743169,"['__author__', 'self.g1']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'self.g1']
*Code:

1__author__ = 'weiheng su'
2import unittest
3from graph import Graph
4
5class TestGraph(unittest.TestCase):
6
7    def setUp(self):
8        self.g1 = Graph( {'A':['B','D'], 'B': ['A','D','C'], 'C': ['B'], 'D':['A','B'],'E':[]})
9
10    """"""test-id: G1""""""
11    def test_get_adjlist_g1(self):
12    """"""test-id: G2""""""
13    def test_is_adjacent_g2(self):
14
15    """"""test-id: G3 """"""
16    def test_num_nodes_g3(self):
17
18    """"""test-id: G4""""""
19    def test___contains___g4(self):
20
21    """"""test-id: G5 """"""
22    def test_len_g5(self):
23
24    """"""test-id: G6 """"""
25    def test_add_node_g6(self):
26
27    """"""test-id: G7""""""
28    def test_link_nodes_g7(self):
29    """"""test-id: G8""""""
30    def test_unlink_nodes_g8(self):
31
32    """""" test-id: G9""""""
33    def test_del_node_g9(self):
34
35
36
37
38
39
40
41",2216,"[7, 'self.g1', '!=', None, ""Graph object should be created""], 
[11, 'self.g1', '!=', None, ""Graph object should be present for adjacency list testing""], 
[13, 'self.g1', '!=', None, ""Graph object should be present for adjacency testing""],
[16, 'self.g1', '!=', None, ""Graph object should be present for testing number of nodes""],
[19, 'self.g1', '!=', None, ""Graph object should be present for contains method testing""],
[22, 'self.g1', '!=', None, ""Graph object should be present for len method testing""],
[25, 'self.g1', '!=', None, ""Graph object should be present for adding node operation testing""],
[28, 'self.g1', '!=', None, ""Graph object should be present for linking nodes operation testing""],
[30, 'self.g1', '!=', None, ""Graph object should be present for unlinking nodes operation testing""],
[33, 'self.g1', '!=', None, ""Graph object should be present for deleting node operation testing""]"
tumbl3w33d/ansible,"# Ansible module to manage CheckPoint Firewall (c) 2019
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#

from __future__ import absolute_import, division, print_function
__metaclass__ = type

import pytest
from units.modules.utils import set_module_args, exit_json, fail_json, AnsibleExitJson

from ansible.module_utils import basic
from ansible.modules.network.check_point import cp_mgmt_threat_rule_facts

OBJECT = {
    ""from"": 1,
    ""to"": 1,
    ""total"": 6,
    ""objects"": [
        ""53de74b7-8f19-4cbe-99fc-a81ef0759bad""
    ]
}

SHOW_PLURAL_PAYLOAD = {
    'limit': 1,
    'details_level': 'uid'
}

SHOW_SINGLE_PAYLOAD = {
    'name': 'object_which_is_not_exist'
}

api_call_object = 'threat-rule'
api_call_object_plural_version = 'threat-rulebase'
failure_msg = '''{u'message': u'Requested object [object_which_is_not_exist] not found', u'code': u'generic_err_object_not_found'}'''


class TestCheckpointThreatRuleFacts(object):
    module = cp_mgmt_threat_rule_facts

    @pytest.fixture(autouse=True)
    def module_mock(self, mocker):
        return mocker.patch.multiple(basic.AnsibleModule, exit_json=exit_json, fail_json=fail_json)

    @pytest.fixture
    def connection_mock(self, mocker):
        connection_class_mock = mocker.patch('ansible.module_utils.network.checkpoint.checkpoint.Connection')
        return connection_class_mock.return_value

    def test_show_single_object_which_is_not_exist(self, mocker, connection_mock):
        connection_mock.send_request.return_value = (404, failure_msg)
        try:
            result = self._run_module(SHOW_SINGLE_PAYLOAD)
        except Exception as e:
            result = e.args[0]

        assert result['failed']
        assert 'Checkpoint device returned error 404 with message ' + failure_msg == result['msg']

    def test_show_few_objects(self, mocker, connection_mock):
        connection_mock.send_request.return_value = (200, OBJECT)
        result = self._run_module(SHOW_PLURAL_PAYLOAD)

        assert not result['changed']
        assert OBJECT == result['ansible_facts'][api_call_object_plural_version]

    def _run_module(self, module_args):
        set_module_args(module_args)
        with pytest.raises(AnsibleExitJson) as ex:
            self.module.main()
        return ex.value.args[0]
","
1# Ansible module to manage CheckPoint Firewall (c) 2019
2#
3# Ansible is free software: you can redistribute it and/or modify
4# it under the terms of the GNU General Public License as published by
5# the Free Software Foundation, either version 3 of the License, or
6# (at your option) any later version.
7#
8# Ansible is distributed in the hope that it will be useful,
9# but WITHOUT ANY WARRANTY; without even the implied warranty of
10# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
11# GNU General Public License for more details.
12#
13# You should have received a copy of the GNU General Public License
14# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
15#
16
17from __future__ import absolute_import, division, print_function
18__metaclass__ = type
19
20import pytest
21from units.modules.utils import set_module_args, exit_json, fail_json, AnsibleExitJson
22
23from ansible.module_utils import basic
24from ansible.modules.network.check_point import cp_mgmt_threat_rule_facts
25
26OBJECT = {
27    ""from"": 1,
28    ""to"": 1,
29    ""total"": 6,
30    ""objects"": [
31        ""53de74b7-8f19-4cbe-99fc-a81ef0759bad""
32    ]
33}
34
35SHOW_PLURAL_PAYLOAD = {
36    'limit': 1,
37    'details_level': 'uid'
38}
39
40SHOW_SINGLE_PAYLOAD = {
41    'name': 'object_which_is_not_exist'
42}
43
44api_call_object = 'threat-rule'
45api_call_object_plural_version = 'threat-rulebase'
46failure_msg = '''{u'message': u'Requested object [object_which_is_not_exist] not found', u'code': u'generic_err_object_not_found'}'''
47
48
49class TestCheckpointThreatRuleFacts(object):
50    module = cp_mgmt_threat_rule_facts
51
52    @pytest.fixture(autouse=True)
53    def module_mock(self, mocker):
54        return mocker.patch.multiple(basic.AnsibleModule, exit_json=exit_json, fail_json=fail_json)
55
56    @pytest.fixture
57    def connection_mock(self, mocker):
58        connection_class_mock = mocker.patch('ansible.module_utils.network.checkpoint.checkpoint.Connection')
59        return connection_class_mock.return_value
60
61    def test_show_single_object_which_is_not_exist(self, mocker, connection_mock):
62        connection_mock.send_request.return_value = (404, failure_msg)
63        try:
64            result = self._run_module(SHOW_SINGLE_PAYLOAD)
65        except Exception as e:
66            result = e.args[0]
67
68
69    def test_show_few_objects(self, mocker, connection_mock):
70        connection_mock.send_request.return_value = (200, OBJECT)
71        result = self._run_module(SHOW_PLURAL_PAYLOAD)
72
73
74    def _run_module(self, module_args):
75        set_module_args(module_args)
76        with pytest.raises(AnsibleExitJson) as ex:
77            self.module.main()
78        return ex.value.args[0]
79","[[""result['failed']"", '==', 'True'], [""'Checkpoint device returned error 404 with message ' + failure_msg"", '==', ""result['msg']""], [""result['changed']"", '==', 'False'], ['OBJECT', '==', ""result['ansible_facts'][api_call_object_plural_version]""]]",4,4,1.0,0.0014000700035001,"['__metaclass__', 'OBJECT', 'SHOW_PLURAL_PAYLOAD', 'SHOW_SINGLE_PAYLOAD', 'api_call_object', 'api_call_object_plural_version', 'failure_msg', 'module', 'mocker', 'connection_class_mock', 'connection_mock', 'connection_mock.send_request.return_value', 'result', 'module_args']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'OBJECT', 'SHOW_PLURAL_PAYLOAD', 'SHOW_SINGLE_PAYLOAD', 'api_call_object', 'api_call_object_plural_version', 'failure_msg', 'module', 'mocker', 'connection_class_mock', 'connection_mock', 'connection_mock.send_request.return_value', 'result', 'module_args']
*Code:

1# Ansible module to manage CheckPoint Firewall (c) 2019
2#
3# Ansible is free software: you can redistribute it and/or modify
4# it under the terms of the GNU General Public License as published by
5# the Free Software Foundation, either version 3 of the License, or
6# (at your option) any later version.
7#
8# Ansible is distributed in the hope that it will be useful,
9# but WITHOUT ANY WARRANTY; without even the implied warranty of
10# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
11# GNU General Public License for more details.
12#
13# You should have received a copy of the GNU General Public License
14# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
15#
16
17from __future__ import absolute_import, division, print_function
18__metaclass__ = type
19
20import pytest
21from units.modules.utils import set_module_args, exit_json, fail_json, AnsibleExitJson
22
23from ansible.module_utils import basic
24from ansible.modules.network.check_point import cp_mgmt_threat_rule_facts
25
26OBJECT = {
27    ""from"": 1,
28    ""to"": 1,
29    ""total"": 6,
30    ""objects"": [
31        ""53de74b7-8f19-4cbe-99fc-a81ef0759bad""
32    ]
33}
34
35SHOW_PLURAL_PAYLOAD = {
36    'limit': 1,
37    'details_level': 'uid'
38}
39
40SHOW_SINGLE_PAYLOAD = {
41    'name': 'object_which_is_not_exist'
42}
43
44api_call_object = 'threat-rule'
45api_call_object_plural_version = 'threat-rulebase'
46failure_msg = '''{u'message': u'Requested object [object_which_is_not_exist] not found', u'code': u'generic_err_object_not_found'}'''
47
48
49class TestCheckpointThreatRuleFacts(object):
50    module = cp_mgmt_threat_rule_facts
51
52    @pytest.fixture(autouse=True)
53    def module_mock(self, mocker):
54        return mocker.patch.multiple(basic.AnsibleModule, exit_json=exit_json, fail_json=fail_json)
55
56    @pytest.fixture
57    def connection_mock(self, mocker):
58        connection_class_mock = mocker.patch('ansible.module_utils.network.checkpoint.checkpoint.Connection')
59        return connection_class_mock.return_value
60
61    def test_show_single_object_which_is_not_exist(self, mocker, connection_mock):
62        connection_mock.send_request.return_value = (404, failure_msg)
63        try:
64            result = self._run_module(SHOW_SINGLE_PAYLOAD)
65        except Exception as e:
66            result = e.args[0]
67
68
69    def test_show_few_objects(self, mocker, connection_mock):
70        connection_mock.send_request.return_value = (200, OBJECT)
71        result = self._run_module(SHOW_PLURAL_PAYLOAD)
72
73
74    def _run_module(self, module_args):
75        set_module_args(module_args)
76        with pytest.raises(AnsibleExitJson) as ex:
77            self.module.main()
78        return ex.value.args[0]
79",4413,"[[26, 'OBJECT', '==', 6, 'OBJECT length should match the expected value'],
 [35, 'SHOW_PLURAL_PAYLOAD', '==', 2, 'SHOW_PLURAL_PAYLOAD length should match the expected value'],
 [40, 'SHOW_SINGLE_PAYLOAD', '==', 1, 'SHOW_SINGLE_PAYLOAD length should match the expected value'],
 [44, 'api_call_object', '!=', '', 'api_call_object should not be empty'],
 [45, 'api_call_object_plural_version', '!=', '', 'api_call_object_plural_version should not be empty'],
 [75, 'module_args', '!=', None, 'Input to _run_module should not be None'],
 [77, 'self.module.main()', '!=', None, 'main function of module should not return None']]"
andrewyoung1991/qtile,"# Copyright (c) 2008, 2010 Aldo Cortesi
# Copyright (c) 2011 Florian Mounier
# Copyright (c) 2011 Anshuman Bhaduri
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the ""Software""), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import six

import libqtile.utils as utils


class Foo:
    ran = False

    @utils.LRUCache(2)
    def one(self, x):
        self.ran = True
        return x


def test_translate_masks():
    assert utils.translateMasks([""shift"", ""control""])
    assert utils.translateMasks([]) == 0


def test_lrucache_works_as_decorator():
    f = Foo()
    assert f.one(1) == 1
    assert f.one('test') == 'test'


def test_lrucache_caches():
    f = Foo()
    f.one(1)
    f.one(2)
    f.ran = False
    f.one(1)
    assert not f.ran
    f.one(2)
    assert not f.ran


def test_lrucache_discards_lru_item():
    f = Foo()
    f.one(1)
    assert f.ran
    f.ran = False
    f.one(1)
    assert not f.ran
    f.one(2)
    f.one(3)
    f.one(1)
    assert f.ran


def test_lrucache_maintains_size():
    f = Foo()
    f.one(1)
    f.one(2)
    f.one(3)
    assert len(f._cached_one) == 2
    assert len(f._cachelist_one) == 2


def test_rgb_from_hex_number():
    assert utils.rgb(""ff00ff"") == (1, 0, 1, 1)


def test_rgb_from_hex_string():
    assert utils.rgb(""#00ff00"") == (0, 1, 0, 1)


def test_rgb_from_hex_number_with_alpha():
    assert utils.rgb(""ff0000.3"") == (1, 0, 0, 0.3)


def test_rgb_from_hex_string_with_alpha():
    assert utils.rgb(""#ff0000.5"") == (1, 0, 0, 0.5)


def test_rgb_from_base10_tuple():
    assert utils.rgb([255, 255, 0]) == (1, 1, 0, 1)


def test_rgb_from_base10_tuple_with_alpha():
    assert utils.rgb([255, 255, 0, 0.5]) == (1, 1, 0, 0.5)

def test_scrub_to_utf8():
    assert utils.scrub_to_utf8(six.b(""foo"")) == six.u(""foo"")

def test_shuffle():
    l = list(range(3))
    utils.shuffleUp(l)
    assert l != list(range(3))
    utils.shuffleDown(l)
    assert l == list(range(3))
","
1# Copyright (c) 2008, 2010 Aldo Cortesi
2# Copyright (c) 2011 Florian Mounier
3# Copyright (c) 2011 Anshuman Bhaduri
4#
5# Permission is hereby granted, free of charge, to any person obtaining a copy
6# of this software and associated documentation files (the ""Software""), to deal
7# in the Software without restriction, including without limitation the rights
8# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
9# copies of the Software, and to permit persons to whom the Software is
10# furnished to do so, subject to the following conditions:
11#
12# The above copyright notice and this permission notice shall be included in
13# all copies or substantial portions of the Software.
14#
15# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
16# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
17# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
18# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
19# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
20# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21# SOFTWARE.
22
23import six
24
25import libqtile.utils as utils
26
27
28class Foo:
29    ran = False
30
31    @utils.LRUCache(2)
32    def one(self, x):
33        self.ran = True
34        return x
35
36
37def test_translate_masks():
38
39
40def test_lrucache_works_as_decorator():
41    f = Foo()
42
43
44def test_lrucache_caches():
45    f = Foo()
46    f.one(1)
47    f.one(2)
48    f.ran = False
49    f.one(1)
50    f.one(2)
51
52
53def test_lrucache_discards_lru_item():
54    f = Foo()
55    f.one(1)
56    f.ran = False
57    f.one(1)
58    f.one(2)
59    f.one(3)
60    f.one(1)
61
62
63def test_lrucache_maintains_size():
64    f = Foo()
65    f.one(1)
66    f.one(2)
67    f.one(3)
68
69
70def test_rgb_from_hex_number():
71
72
73def test_rgb_from_hex_string():
74
75
76def test_rgb_from_hex_number_with_alpha():
77
78
79def test_rgb_from_hex_string_with_alpha():
80
81
82def test_rgb_from_base10_tuple():
83
84
85def test_rgb_from_base10_tuple_with_alpha():
86
87def test_scrub_to_utf8():
88
89def test_shuffle():
90    l = list(range(3))
91    utils.shuffleUp(l)
92    utils.shuffleDown(l)
93","[['utils.translateMasks([""shift""', '==', 'True'], ['utils.translateMasks([])', '==', '0'], ['f.one(1)', '==', '1'], [""f.one('test')"", '==', ""'test'""], ['f.ran', '==', 'False'], ['f.ran', '==', 'False'], ['f.ran', '==', 'True'], ['f.ran', '==', 'False'], ['f.ran', '==', 'True'], ['len(f._cached_one)', '==', '2'], ['len(f._cachelist_one)', '==', '2'], ['utils.rgb(""ff00ff"")', '==', '(1'], ['utils.rgb(""', '==', 'True'], ['utils.rgb(""ff0000.3"")', '==', '(1'], ['utils.rgb(""', '==', 'True'], ['utils.rgb([255', '==', 'True'], ['utils.rgb([255', '==', 'True'], ['utils.scrub_to_utf8(six.b(""foo""))', '==', 'six.u(""foo"")'], ['l', '!=', 'list(range(3))'], ['l', '==', 'list(range(3))']]",20,20,1.0,0.0069492703266157,"['ran', 'x', 'self.ran', 'f', 'f.ran', 'l']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ran', 'x', 'self.ran', 'f', 'f.ran', 'l']
*Code:

1# Copyright (c) 2008, 2010 Aldo Cortesi
2# Copyright (c) 2011 Florian Mounier
3# Copyright (c) 2011 Anshuman Bhaduri
4#
5# Permission is hereby granted, free of charge, to any person obtaining a copy
6# of this software and associated documentation files (the ""Software""), to deal
7# in the Software without restriction, including without limitation the rights
8# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
9# copies of the Software, and to permit persons to whom the Software is
10# furnished to do so, subject to the following conditions:
11#
12# The above copyright notice and this permission notice shall be included in
13# all copies or substantial portions of the Software.
14#
15# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
16# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
17# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
18# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
19# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
20# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21# SOFTWARE.
22
23import six
24
25import libqtile.utils as utils
26
27
28class Foo:
29    ran = False
30
31    @utils.LRUCache(2)
32    def one(self, x):
33        self.ran = True
34        return x
35
36
37def test_translate_masks():
38
39
40def test_lrucache_works_as_decorator():
41    f = Foo()
42
43
44def test_lrucache_caches():
45    f = Foo()
46    f.one(1)
47    f.one(2)
48    f.ran = False
49    f.one(1)
50    f.one(2)
51
52
53def test_lrucache_discards_lru_item():
54    f = Foo()
55    f.one(1)
56    f.ran = False
57    f.one(1)
58    f.one(2)
59    f.one(3)
60    f.one(1)
61
62
63def test_lrucache_maintains_size():
64    f = Foo()
65    f.one(1)
66    f.one(2)
67    f.one(3)
68
69
70def test_rgb_from_hex_number():
71
72
73def test_rgb_from_hex_string():
74
75
76def test_rgb_from_hex_number_with_alpha():
77
78
79def test_rgb_from_hex_string_with_alpha():
80
81
82def test_rgb_from_base10_tuple():
83
84
85def test_rgb_from_base10_tuple_with_alpha():
86
87def test_scrub_to_utf8():
88
89def test_shuffle():
90    l = list(range(3))
91    utils.shuffleUp(l)
92    utils.shuffleDown(l)
93",3722,"[[32, 'x', '!=', None, 'x should not be None before the function call'],
[41, 'f', '==', None, ""f should be initialized before calling object's methods""],
[45, 'f', '!=', None, 'f should be already initialized when calling methods on it'],
[54, 'f', '!=', None, 'f should be already initialized when calling methods on it'],
[64, 'f', '!=', None, 'f should be already initialized when calling methods on it'],
[90, 'l', '!=', None, 'l should not be None before function call']]"
Radagast-red/golem,"import time
from unittest import TestCase

from mock import patch

from golem.vm.memorychecker import MemoryChecker


class TestMemoryChecker(TestCase):

    @patch(""golem.vm.memorychecker.psutil"")
    def test_memory(self, psutil_mock):
        psutil_mock.virtual_memory.return_value.used = 1200000
        mc = MemoryChecker()
        assert isinstance(mc, MemoryChecker)
        mc.start()
        psutil_mock.virtual_memory.return_value.used = 1200050
        time.sleep(0.6)
        psutil_mock.virtual_memory.return_value.used = 1100030
        time.sleep(0.6)
        psutil_mock.virtual_memory.return_value.used = 1200030
        time.sleep(0.6)
        mm = mc.stop()
        mc.join(60.0)
        assert mm == 50
        assert mc.max_mem == 1200050
        assert mc.min_mem == 1100030
","
1import time
2from unittest import TestCase
3
4from mock import patch
5
6from golem.vm.memorychecker import MemoryChecker
7
8
9class TestMemoryChecker(TestCase):
10
11    @patch(""golem.vm.memorychecker.psutil"")
12    def test_memory(self, psutil_mock):
13        psutil_mock.virtual_memory.return_value.used = 1200000
14        mc = MemoryChecker()
15        mc.start()
16        psutil_mock.virtual_memory.return_value.used = 1200050
17        time.sleep(0.6)
18        psutil_mock.virtual_memory.return_value.used = 1100030
19        time.sleep(0.6)
20        psutil_mock.virtual_memory.return_value.used = 1200030
21        time.sleep(0.6)
22        mm = mc.stop()
23        mc.join(60.0)
24","[['mm', '==', '50'], ['mc.max_mem', '==', '1200050'], ['mc.min_mem', '==', '1100030']]",4,3,0.75,0.0037593984962406,"['psutil_mock', 'psutil_mock.virtual_memory.return_value.used', 'mc', 'mm']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['psutil_mock', 'psutil_mock.virtual_memory.return_value.used', 'mc', 'mm']
*Code:

1import time
2from unittest import TestCase
3
4from mock import patch
5
6from golem.vm.memorychecker import MemoryChecker
7
8
9class TestMemoryChecker(TestCase):
10
11    @patch(""golem.vm.memorychecker.psutil"")
12    def test_memory(self, psutil_mock):
13        psutil_mock.virtual_memory.return_value.used = 1200000
14        mc = MemoryChecker()
15        mc.start()
16        psutil_mock.virtual_memory.return_value.used = 1200050
17        time.sleep(0.6)
18        psutil_mock.virtual_memory.return_value.used = 1100030
19        time.sleep(0.6)
20        psutil_mock.virtual_memory.return_value.used = 1200030
21        time.sleep(0.6)
22        mm = mc.stop()
23        mc.join(60.0)
24",2150,"[[12, 'psutil_mock', '!=', None, ""psutil_mock should not be None""],
 [13, 'psutil_mock.virtual_memory.return_value.used', '>=', 0, ""memory used cannot be negative""],
 [14, 'mc', '!=', None, ""MemoryChecker instance should not be None""],
 [16, 'psutil_mock.virtual_memory.return_value.used', '>=', 0, ""memory used cannot be negative""],
 [18, 'psutil_mock.virtual_memory.return_value.used', '>=', 0, ""memory used cannot be negative""],
 [20, 'psutil_mock.virtual_memory.return_value.used', '>=', 0, ""memory used cannot be negative""],
 [22, 'mm', '!=', None, ""Memory measurement should not be None""]]"
CellModels/tyssue,"import numpy as np

from tyssue.core.multisheet import MultiSheet
from tyssue.geometry.multisheetgeometry import MultiSheetGeometry
from tyssue.generation import hexa_grid2d, from_2d_voronoi
from scipy.spatial import Voronoi

import tyssue


def test_multisheet():

    base_specs = tyssue.config.geometry.flat_sheet()
    specs = base_specs.copy()
    specs[""face""][""layer""] = 0
    specs[""vert""][""layer""] = 0
    specs[""vert""][""depth""] = 0.0
    specs[""edge""][""layer""] = 0
    specs[""settings""][""geometry""] = ""flat""
    specs[""settings""][""interpolate""] = {""function"": ""multiquadric"", ""smooth"": 0}
    layer_args = [
        (24, 24, 1, 1, 0.4),
        (16, 16, 2, 2, 1),
        (24, 24, 1, 1, 0.4),
        (24, 24, 1, 1, 0.4),
    ]
    dz = 1.0

    layer_datasets = []
    for i, args in enumerate(layer_args):
        centers = hexa_grid2d(*args)
        data = from_2d_voronoi(Voronoi(centers))
        data[""vert""][""z""] = i * dz
        layer_datasets.append(data)

    msheet = MultiSheet(""more"", layer_datasets, specs)
    bbox = [[0, 25], [0, 25]]
    for sheet in msheet:
        edge_out = sheet.cut_out(bbox, coords=[""x"", ""y""])
        sheet.remove(edge_out)

    MultiSheetGeometry.update_all(msheet)
    assert np.all(np.isfinite(msheet[0].face_df[""area""]))
","
1import numpy as np
2
3from tyssue.core.multisheet import MultiSheet
4from tyssue.geometry.multisheetgeometry import MultiSheetGeometry
5from tyssue.generation import hexa_grid2d, from_2d_voronoi
6from scipy.spatial import Voronoi
7
8import tyssue
9
10
11def test_multisheet():
12
13    base_specs = tyssue.config.geometry.flat_sheet()
14    specs = base_specs.copy()
15    specs[""face""][""layer""] = 0
16    specs[""vert""][""layer""] = 0
17    specs[""vert""][""depth""] = 0.0
18    specs[""edge""][""layer""] = 0
19    specs[""settings""][""geometry""] = ""flat""
20    specs[""settings""][""interpolate""] = {""function"": ""multiquadric"", ""smooth"": 0}
21    layer_args = [
22        (24, 24, 1, 1, 0.4),
23        (16, 16, 2, 2, 1),
24        (24, 24, 1, 1, 0.4),
25        (24, 24, 1, 1, 0.4),
26    ]
27    dz = 1.0
28
29    layer_datasets = []
30    for i, args in enumerate(layer_args):
31        centers = hexa_grid2d(*args)
32        data = from_2d_voronoi(Voronoi(centers))
33        data[""vert""][""z""] = i * dz
34        layer_datasets.append(data)
35
36    msheet = MultiSheet(""more"", layer_datasets, specs)
37    bbox = [[0, 25], [0, 25]]
38    for sheet in msheet:
39        edge_out = sheet.cut_out(bbox, coords=[""x"", ""y""])
40        sheet.remove(edge_out)
41
42    MultiSheetGeometry.update_all(msheet)
43","[['np.all(np.isfinite(msheet[0].face_df[""area""]))', '==', 'True']]",1,1,1.0,0.0007836990595611,"['base_specs', 'specs', 'specs[""face""][""layer""]', 'specs[""vert""][""layer""]', 'specs[""vert""][""depth""]', 'specs[""edge""][""layer""]', 'specs[""settings""][""geometry""]', 'specs[""settings""][""interpolate""]', 'layer_args', 'dz', 'layer_datasets', 'centers', 'data', 'data[""vert""][""z""]', 'msheet', 'bbox', 'edge_out']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['base_specs', 'specs', 'specs[""face""][""layer""]', 'specs[""vert""][""layer""]', 'specs[""vert""][""depth""]', 'specs[""edge""][""layer""]', 'specs[""settings""][""geometry""]', 'specs[""settings""][""interpolate""]', 'layer_args', 'dz', 'layer_datasets', 'centers', 'data', 'data[""vert""][""z""]', 'msheet', 'bbox', 'edge_out']
*Code:

1import numpy as np
2
3from tyssue.core.multisheet import MultiSheet
4from tyssue.geometry.multisheetgeometry import MultiSheetGeometry
5from tyssue.generation import hexa_grid2d, from_2d_voronoi
6from scipy.spatial import Voronoi
7
8import tyssue
9
10
11def test_multisheet():
12
13    base_specs = tyssue.config.geometry.flat_sheet()
14    specs = base_specs.copy()
15    specs[""face""][""layer""] = 0
16    specs[""vert""][""layer""] = 0
17    specs[""vert""][""depth""] = 0.0
18    specs[""edge""][""layer""] = 0
19    specs[""settings""][""geometry""] = ""flat""
20    specs[""settings""][""interpolate""] = {""function"": ""multiquadric"", ""smooth"": 0}
21    layer_args = [
22        (24, 24, 1, 1, 0.4),
23        (16, 16, 2, 2, 1),
24        (24, 24, 1, 1, 0.4),
25        (24, 24, 1, 1, 0.4),
26    ]
27    dz = 1.0
28
29    layer_datasets = []
30    for i, args in enumerate(layer_args):
31        centers = hexa_grid2d(*args)
32        data = from_2d_voronoi(Voronoi(centers))
33        data[""vert""][""z""] = i * dz
34        layer_datasets.append(data)
35
36    msheet = MultiSheet(""more"", layer_datasets, specs)
37    bbox = [[0, 25], [0, 25]]
38    for sheet in msheet:
39        edge_out = sheet.cut_out(bbox, coords=[""x"", ""y""])
40        sheet.remove(edge_out)
41
42    MultiSheetGeometry.update_all(msheet)
43",2980,"[[13, 'base_specs', '!=', None, ""base_specs should not be None""],
 [14, 'specs', '!=', None, ""specs should not be None""],
 [31, 'centers', '!=', None, ""centers should not be None""],
 [32, 'data', '!=', None, ""data should not be None""],
 [36, 'msheet', '!=', None, ""msheet should be properly defined""],
 [37, 'bbox', '==', 2, ""bbox should have two elements""],
 [39, 'edge_out', '!=', None, ""edge_out should not be None""],
 [42, 'msheet', '!=', None, ""msheet should be properly updated""]]"
StanczakDominik/PlasmaPy,"""""""
Test module for `plasmapy.utils.decorators.lite_func.bind_lite_func`.
""""""
import pytest

from numba import jit, njit

from plasmapy.utils.decorators.lite_func import bind_lite_func


def foo(x):
    """"""Test function used for decoration.""""""
    if not isinstance(x, float):
        raise ValueError
    return x


def foo_lite(x):
    """"""Test Lite-Function to be bound to foo.""""""
    return x


def bar():
    """"""
    Test support function for the Lite-Function framework.  To be bound
    to foo.
    """"""
    print(""I am a helper function that support the Lite-Function 'foo_lite'."")


@pytest.mark.parametrize(
    ""lite_func, attrs, _error"",
    [
        # conditions on attrs kwarg
        (foo_lite, ""not a dictionary"", TypeError),
        (foo_lite, {""lite"": lambda x: x}, ValueError),
        (foo_lite, {""bar"": ""not a functions""}, ValueError),
        #
        # conditions on lite_func arg
        (6, None, ValueError),  # not a function
        (print, None, ValueError),  # can not be builtin
    ],
)
def test_raises(lite_func, attrs, _error):
    """"""Test scenarios that will raise an Exception.""""""
    with pytest.raises(_error):
        bind_lite_func(lite_func, attrs=attrs)(foo)


@pytest.mark.parametrize(
    ""lite_func, attrs"",
    [
        (foo_lite, None),
        (jit(foo_lite), None),
        (njit(foo_lite), None),
        (foo_lite, {""bar"": bar}),
    ],
)
def test_binding(lite_func, attrs):
    """"""Test that the expected members are bound to the decorated function.""""""
    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)

    if attrs is None:
        attrs = {""lite"": lite_func}
    elif isinstance(attrs, dict):
        attrs[""lite""] = lite_func
    else:
        pytest.fail(
            ""Parametrization was not setup correctly!  The value for 'attrs' must""
            ""be None or a dictionary.""
        )

    for name, func in attrs.items():
        assert hasattr(dfoo, name)
        assert getattr(dfoo, name) == func

    assert dfoo(5.0) == 5.0
    assert dfoo.lite(5.0) == 5.0


@pytest.mark.parametrize(
    ""lite_func, attrs"",
    [
        (foo_lite, None),
        (foo_lite, {""bar"": bar}),
    ],
)
def test_lite_func_dunder(lite_func, attrs):
    """"""Test that the ``__bound_lite_func__`` dunder is properly defined.""""""
    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)

    if attrs is None:
        attrs = {""lite"": lite_func}
    elif isinstance(attrs, dict):
        attrs[""lite""] = lite_func
    else:
        pytest.fail(
            ""Parametrization was not setup correctly!  The value for 'attrs' must""
            ""be None or a dictionary.""
        )

    for name, func in attrs.items():
        assert hasattr(dfoo, ""__bound_lite_func__"")
        assert name in dfoo.__bound_lite_func__

        origin = f""{func.__module__}.{func.__name__}""
        assert dfoo.__bound_lite_func__[name] == origin
","
1""""""
2Test module for `plasmapy.utils.decorators.lite_func.bind_lite_func`.
3""""""
4import pytest
5
6from numba import jit, njit
7
8from plasmapy.utils.decorators.lite_func import bind_lite_func
9
10
11def foo(x):
12    """"""Test function used for decoration.""""""
13    if not isinstance(x, float):
14        raise ValueError
15    return x
16
17
18def foo_lite(x):
19    """"""Test Lite-Function to be bound to foo.""""""
20    return x
21
22
23def bar():
24    """"""
25    Test support function for the Lite-Function framework.  To be bound
26    to foo.
27    """"""
28    print(""I am a helper function that support the Lite-Function 'foo_lite'."")
29
30
31@pytest.mark.parametrize(
32    ""lite_func, attrs, _error"",
33    [
34        # conditions on attrs kwarg
35        (foo_lite, ""not a dictionary"", TypeError),
36        (foo_lite, {""lite"": lambda x: x}, ValueError),
37        (foo_lite, {""bar"": ""not a functions""}, ValueError),
38        #
39        # conditions on lite_func arg
40        (6, None, ValueError),  # not a function
41        (print, None, ValueError),  # can not be builtin
42    ],
43)
44def test_raises(lite_func, attrs, _error):
45    """"""Test scenarios that will raise an Exception.""""""
46    with pytest.raises(_error):
47        bind_lite_func(lite_func, attrs=attrs)(foo)
48
49
50@pytest.mark.parametrize(
51    ""lite_func, attrs"",
52    [
53        (foo_lite, None),
54        (jit(foo_lite), None),
55        (njit(foo_lite), None),
56        (foo_lite, {""bar"": bar}),
57    ],
58)
59def test_binding(lite_func, attrs):
60    """"""Test that the expected members are bound to the decorated function.""""""
61    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)
62
63    if attrs is None:
64        attrs = {""lite"": lite_func}
65    elif isinstance(attrs, dict):
66        attrs[""lite""] = lite_func
67    else:
68        pytest.fail(
69            ""Parametrization was not setup correctly!  The value for 'attrs' must""
70            ""be None or a dictionary.""
71        )
72
73    for name, func in attrs.items():
74
75
76
77@pytest.mark.parametrize(
78    ""lite_func, attrs"",
79    [
80        (foo_lite, None),
81        (foo_lite, {""bar"": bar}),
82    ],
83)
84def test_lite_func_dunder(lite_func, attrs):
85    """"""Test that the ``__bound_lite_func__`` dunder is properly defined.""""""
86    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)
87
88    if attrs is None:
89        attrs = {""lite"": lite_func}
90    elif isinstance(attrs, dict):
91        attrs[""lite""] = lite_func
92    else:
93        pytest.fail(
94            ""Parametrization was not setup correctly!  The value for 'attrs' must""
95            ""be None or a dictionary.""
96        )
97
98    for name, func in attrs.items():
99
100        origin = f""{func.__module__}.{func.__name__}""
101","[['hasattr(dfoo', '==', 'True'], ['getattr(dfoo', '==', 'True'], ['dfoo(5.0)', '==', '5.0'], ['dfoo.lite(5.0)', '==', '5.0'], ['hasattr(dfoo', '==', 'True'], ['dfoo.__bound_lite_func__[name]', '==', 'origin']]",7,6,0.8571428571428571,0.0020905923344947,"['x', 'lite_func', 'attrs', '_error', 'dfoo', 'attrs[""lite""]', 'origin']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'lite_func', 'attrs', '_error', 'dfoo', 'attrs[""lite""]', 'origin']
*Code:

1""""""
2Test module for `plasmapy.utils.decorators.lite_func.bind_lite_func`.
3""""""
4import pytest
5
6from numba import jit, njit
7
8from plasmapy.utils.decorators.lite_func import bind_lite_func
9
10
11def foo(x):
12    """"""Test function used for decoration.""""""
13    if not isinstance(x, float):
14        raise ValueError
15    return x
16
17
18def foo_lite(x):
19    """"""Test Lite-Function to be bound to foo.""""""
20    return x
21
22
23def bar():
24    """"""
25    Test support function for the Lite-Function framework.  To be bound
26    to foo.
27    """"""
28    print(""I am a helper function that support the Lite-Function 'foo_lite'."")
29
30
31@pytest.mark.parametrize(
32    ""lite_func, attrs, _error"",
33    [
34        # conditions on attrs kwarg
35        (foo_lite, ""not a dictionary"", TypeError),
36        (foo_lite, {""lite"": lambda x: x}, ValueError),
37        (foo_lite, {""bar"": ""not a functions""}, ValueError),
38        #
39        # conditions on lite_func arg
40        (6, None, ValueError),  # not a function
41        (print, None, ValueError),  # can not be builtin
42    ],
43)
44def test_raises(lite_func, attrs, _error):
45    """"""Test scenarios that will raise an Exception.""""""
46    with pytest.raises(_error):
47        bind_lite_func(lite_func, attrs=attrs)(foo)
48
49
50@pytest.mark.parametrize(
51    ""lite_func, attrs"",
52    [
53        (foo_lite, None),
54        (jit(foo_lite), None),
55        (njit(foo_lite), None),
56        (foo_lite, {""bar"": bar}),
57    ],
58)
59def test_binding(lite_func, attrs):
60    """"""Test that the expected members are bound to the decorated function.""""""
61    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)
62
63    if attrs is None:
64        attrs = {""lite"": lite_func}
65    elif isinstance(attrs, dict):
66        attrs[""lite""] = lite_func
67    else:
68        pytest.fail(
69            ""Parametrization was not setup correctly!  The value for 'attrs' must""
70            ""be None or a dictionary.""
71        )
72
73    for name, func in attrs.items():
74
75
76
77@pytest.mark.parametrize(
78    ""lite_func, attrs"",
79    [
80        (foo_lite, None),
81        (foo_lite, {""bar"": bar}),
82    ],
83)
84def test_lite_func_dunder(lite_func, attrs):
85    """"""Test that the ``__bound_lite_func__`` dunder is properly defined.""""""
86    dfoo = bind_lite_func(lite_func, attrs=attrs)(foo)
87
88    if attrs is None:
89        attrs = {""lite"": lite_func}
90    elif isinstance(attrs, dict):
91        attrs[""lite""] = lite_func
92    else:
93        pytest.fail(
94            ""Parametrization was not setup correctly!  The value for 'attrs' must""
95            ""be None or a dictionary.""
96        )
97
98    for name, func in attrs.items():
99
100        origin = f""{func.__module__}.{func.__name__}""
101",4223,"[[11, 'x', '!=', None, ""x, the function's argument must not be None""],
[47, 'lite_func', '!=', None, ""lite_func needs to be a function""],
[47, 'attrs', '!=', None, ""attrs is expected to be either None or a dictionary""],
[61, 'dfoo', '!=', None, ""dfoo becomes instance of bind_lite_func""],
[63, 'attrs', '==', None, ""attrs can be None when called with lite_func""],
[65, 'attrs', '>=', 'attrs[""lite""]', ""attrs['lite'] should be updated as lite_func if attrs is dictionary""],
[86, 'dfoo', '!=', None, ""dfoo becomes instance of bind_lite_func""],
[88, 'attrs', '==', None, ""attrs can be None when initialized""],
[90, 'attrs', '>=', 'attrs[""lite""]', ""attrs['lite'] should be updated as lite_func if attrs is dictionary""]]"
soldag/home-assistant,"""""""The tests for Fan device triggers.""""""
import pytest

import homeassistant.components.automation as automation
from homeassistant.components.fan import DOMAIN
from homeassistant.const import STATE_OFF, STATE_ON
from homeassistant.helpers import device_registry
from homeassistant.setup import async_setup_component

from tests.common import (
    MockConfigEntry,
    assert_lists_same,
    async_get_device_automations,
    async_mock_service,
    mock_device_registry,
    mock_registry,
)


@pytest.fixture
def device_reg(hass):
    """"""Return an empty, loaded, registry.""""""
    return mock_device_registry(hass)


@pytest.fixture
def entity_reg(hass):
    """"""Return an empty, loaded, registry.""""""
    return mock_registry(hass)


@pytest.fixture
def calls(hass):
    """"""Track calls to a mock service.""""""
    return async_mock_service(hass, ""test"", ""automation"")


async def test_get_triggers(hass, device_reg, entity_reg):
    """"""Test we get the expected triggers from a fan.""""""
    config_entry = MockConfigEntry(domain=""test"", data={})
    config_entry.add_to_hass(hass)
    device_entry = device_reg.async_get_or_create(
        config_entry_id=config_entry.entry_id,
        connections={(device_registry.CONNECTION_NETWORK_MAC, ""12:34:56:AB:CD:EF"")},
    )
    entity_reg.async_get_or_create(DOMAIN, ""test"", ""5678"", device_id=device_entry.id)
    expected_triggers = [
        {
            ""platform"": ""device"",
            ""domain"": DOMAIN,
            ""type"": ""turned_off"",
            ""device_id"": device_entry.id,
            ""entity_id"": f""{DOMAIN}.test_5678"",
        },
        {
            ""platform"": ""device"",
            ""domain"": DOMAIN,
            ""type"": ""turned_on"",
            ""device_id"": device_entry.id,
            ""entity_id"": f""{DOMAIN}.test_5678"",
        },
    ]
    triggers = await async_get_device_automations(hass, ""trigger"", device_entry.id)
    assert_lists_same(triggers, expected_triggers)


async def test_if_fires_on_state_change(hass, calls):
    """"""Test for turn_on and turn_off triggers firing.""""""
    hass.states.async_set(""fan.entity"", STATE_OFF)

    assert await async_setup_component(
        hass,
        automation.DOMAIN,
        {
            automation.DOMAIN: [
                {
                    ""trigger"": {
                        ""platform"": ""device"",
                        ""domain"": DOMAIN,
                        ""device_id"": """",
                        ""entity_id"": ""fan.entity"",
                        ""type"": ""turned_on"",
                    },
                    ""action"": {
                        ""service"": ""test.automation"",
                        ""data_template"": {
                            ""some"": (
                                ""turn_on - {{ trigger.platform}} - ""
                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
                            )
                        },
                    },
                },
                {
                    ""trigger"": {
                        ""platform"": ""device"",
                        ""domain"": DOMAIN,
                        ""device_id"": """",
                        ""entity_id"": ""fan.entity"",
                        ""type"": ""turned_off"",
                    },
                    ""action"": {
                        ""service"": ""test.automation"",
                        ""data_template"": {
                            ""some"": (
                                ""turn_off - {{ trigger.platform}} - ""
                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
                            )
                        },
                    },
                },
            ]
        },
    )

    # Fake that the entity is turning on.
    hass.states.async_set(""fan.entity"", STATE_ON)
    await hass.async_block_till_done()
    assert len(calls) == 1
    assert calls[0].data[""some""] == ""turn_on - device - fan.entity - off - on - None""

    # Fake that the entity is turning off.
    hass.states.async_set(""fan.entity"", STATE_OFF)
    await hass.async_block_till_done()
    assert len(calls) == 2
    assert calls[1].data[""some""] == ""turn_off - device - fan.entity - on - off - None""
","
1""""""The tests for Fan device triggers.""""""
2import pytest
3
4import homeassistant.components.automation as automation
5from homeassistant.components.fan import DOMAIN
6from homeassistant.const import STATE_OFF, STATE_ON
7from homeassistant.helpers import device_registry
8from homeassistant.setup import async_setup_component
9
10from tests.common import (
11    MockConfigEntry,
12    async_get_device_automations,
13    async_mock_service,
14    mock_device_registry,
15    mock_registry,
16)
17
18
19@pytest.fixture
20def device_reg(hass):
21    """"""Return an empty, loaded, registry.""""""
22    return mock_device_registry(hass)
23
24
25@pytest.fixture
26def entity_reg(hass):
27    """"""Return an empty, loaded, registry.""""""
28    return mock_registry(hass)
29
30
31@pytest.fixture
32def calls(hass):
33    """"""Track calls to a mock service.""""""
34    return async_mock_service(hass, ""test"", ""automation"")
35
36
37async def test_get_triggers(hass, device_reg, entity_reg):
38    """"""Test we get the expected triggers from a fan.""""""
39    config_entry = MockConfigEntry(domain=""test"", data={})
40    config_entry.add_to_hass(hass)
41    device_entry = device_reg.async_get_or_create(
42        config_entry_id=config_entry.entry_id,
43        connections={(device_registry.CONNECTION_NETWORK_MAC, ""12:34:56:AB:CD:EF"")},
44    )
45    entity_reg.async_get_or_create(DOMAIN, ""test"", ""5678"", device_id=device_entry.id)
46    expected_triggers = [
47        {
48            ""platform"": ""device"",
49            ""domain"": DOMAIN,
50            ""type"": ""turned_off"",
51            ""device_id"": device_entry.id,
52            ""entity_id"": f""{DOMAIN}.test_5678"",
53        },
54        {
55            ""platform"": ""device"",
56            ""domain"": DOMAIN,
57            ""type"": ""turned_on"",
58            ""device_id"": device_entry.id,
59            ""entity_id"": f""{DOMAIN}.test_5678"",
60        },
61    ]
62    triggers = await async_get_device_automations(hass, ""trigger"", device_entry.id)
63
64
65async def test_if_fires_on_state_change(hass, calls):
66    """"""Test for turn_on and turn_off triggers firing.""""""
67    hass.states.async_set(""fan.entity"", STATE_OFF)
68
69        hass,
70        automation.DOMAIN,
71        {
72            automation.DOMAIN: [
73                {
74                    ""trigger"": {
75                        ""platform"": ""device"",
76                        ""domain"": DOMAIN,
77                        ""device_id"": """",
78                        ""entity_id"": ""fan.entity"",
79                        ""type"": ""turned_on"",
80                    },
81                    ""action"": {
82                        ""service"": ""test.automation"",
83                        ""data_template"": {
84                            ""some"": (
85                                ""turn_on - {{ trigger.platform}} - ""
86                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
87                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
88                            )
89                        },
90                    },
91                },
92                {
93                    ""trigger"": {
94                        ""platform"": ""device"",
95                        ""domain"": DOMAIN,
96                        ""device_id"": """",
97                        ""entity_id"": ""fan.entity"",
98                        ""type"": ""turned_off"",
99                    },
100                    ""action"": {
101                        ""service"": ""test.automation"",
102                        ""data_template"": {
103                            ""some"": (
104                                ""turn_off - {{ trigger.platform}} - ""
105                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
106                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
107                            )
108                        },
109                    },
110                },
111            ]
112        },
113    )
114
115    # Fake that the entity is turning on.
116    hass.states.async_set(""fan.entity"", STATE_ON)
117    await hass.async_block_till_done()
118
119    # Fake that the entity is turning off.
120    hass.states.async_set(""fan.entity"", STATE_OFF)
121    await hass.async_block_till_done()
122","[['await', 'async_setup_component('], ['len(calls)', '==', '1'], ['calls[0].data[""some""]', '==', '""turn_on - device - fan.entity - off - on - None""'], ['len(calls)', '==', '2'], ['calls[1].data[""some""]', '==', '""turn_off - device - fan.entity - on - off - None""']]",7,5,0.7142857142857143,0.0011446886446886,"['hass', 'device_reg', 'entity_reg', 'config_entry', 'device_entry', 'expected_triggers', 'triggers', 'calls']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'device_reg', 'entity_reg', 'config_entry', 'device_entry', 'expected_triggers', 'triggers', 'calls']
*Code:

1""""""The tests for Fan device triggers.""""""
2import pytest
3
4import homeassistant.components.automation as automation
5from homeassistant.components.fan import DOMAIN
6from homeassistant.const import STATE_OFF, STATE_ON
7from homeassistant.helpers import device_registry
8from homeassistant.setup import async_setup_component
9
10from tests.common import (
11    MockConfigEntry,
12    async_get_device_automations,
13    async_mock_service,
14    mock_device_registry,
15    mock_registry,
16)
17
18
19@pytest.fixture
20def device_reg(hass):
21    """"""Return an empty, loaded, registry.""""""
22    return mock_device_registry(hass)
23
24
25@pytest.fixture
26def entity_reg(hass):
27    """"""Return an empty, loaded, registry.""""""
28    return mock_registry(hass)
29
30
31@pytest.fixture
32def calls(hass):
33    """"""Track calls to a mock service.""""""
34    return async_mock_service(hass, ""test"", ""automation"")
35
36
37async def test_get_triggers(hass, device_reg, entity_reg):
38    """"""Test we get the expected triggers from a fan.""""""
39    config_entry = MockConfigEntry(domain=""test"", data={})
40    config_entry.add_to_hass(hass)
41    device_entry = device_reg.async_get_or_create(
42        config_entry_id=config_entry.entry_id,
43        connections={(device_registry.CONNECTION_NETWORK_MAC, ""12:34:56:AB:CD:EF"")},
44    )
45    entity_reg.async_get_or_create(DOMAIN, ""test"", ""5678"", device_id=device_entry.id)
46    expected_triggers = [
47        {
48            ""platform"": ""device"",
49            ""domain"": DOMAIN,
50            ""type"": ""turned_off"",
51            ""device_id"": device_entry.id,
52            ""entity_id"": f""{DOMAIN}.test_5678"",
53        },
54        {
55            ""platform"": ""device"",
56            ""domain"": DOMAIN,
57            ""type"": ""turned_on"",
58            ""device_id"": device_entry.id,
59            ""entity_id"": f""{DOMAIN}.test_5678"",
60        },
61    ]
62    triggers = await async_get_device_automations(hass, ""trigger"", device_entry.id)
63
64
65async def test_if_fires_on_state_change(hass, calls):
66    """"""Test for turn_on and turn_off triggers firing.""""""
67    hass.states.async_set(""fan.entity"", STATE_OFF)
68
69        hass,
70        automation.DOMAIN,
71        {
72            automation.DOMAIN: [
73                {
74                    ""trigger"": {
75                        ""platform"": ""device"",
76                        ""domain"": DOMAIN,
77                        ""device_id"": """",
78                        ""entity_id"": ""fan.entity"",
79                        ""type"": ""turned_on"",
80                    },
81                    ""action"": {
82                        ""service"": ""test.automation"",
83                        ""data_template"": {
84                            ""some"": (
85                                ""turn_on - {{ trigger.platform}} - ""
86                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
87                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
88                            )
89                        },
90                    },
91                },
92                {
93                    ""trigger"": {
94                        ""platform"": ""device"",
95                        ""domain"": DOMAIN,
96                        ""device_id"": """",
97                        ""entity_id"": ""fan.entity"",
98                        ""type"": ""turned_off"",
99                    },
100                    ""action"": {
101                        ""service"": ""test.automation"",
102                        ""data_template"": {
103                            ""some"": (
104                                ""turn_off - {{ trigger.platform}} - ""
105                                ""{{ trigger.entity_id}} - {{ trigger.from_state.state}} - ""
106                                ""{{ trigger.to_state.state}} - {{ trigger.for }}""
107                            )
108                        },
109                    },
110                },
111            ]
112        },
113    )
114
115    # Fake that the entity is turning on.
116    hass.states.async_set(""fan.entity"", STATE_ON)
117    await hass.async_block_till_done()
118
119    # Fake that the entity is turning off.
120    hass.states.async_set(""fan.entity"", STATE_OFF)
121    await hass.async_block_till_done()
122",5776,"[[19, 'device_reg', '!=', None, ""Ensure 'device_reg' has been properly initialized""], 
 [25, 'entity_reg', '!=', None, ""Ensure 'entity_reg' has been properly initialized""], 
 [31, 'calls', '!=', None, ""Ensure 'calls' has been properly initialized""], 
 [37, 'hass', '!=', None, ""Ensure 'hass' has been properly initialized""], 
 [41, 'config_entry', '!=', None, ""Ensure 'config_entry' has been properly initialized""], 
 [46, 'expected_triggers', '!=', None, ""Ensure 'expected_triggers' has been properly initialized""], 
 [62, 'triggers', '!=', None, ""Ensure 'triggers' has been properly initialized""], 
 [65, 'hass', '!=', None, ""Ensure 'hass' has been properly initialized""], 
 [117, 'hass', '!=', None, ""Ensure 'hass' has been properly initialized""]]"
WCCCEDU/twitter-commons,"from abc import abstractmethod

from twitter.common.lang import Interface
from twitter.common.string import ScanfParser

class ProcessHandle(Interface):
  """"""
    ProcessHandle interface.  Methods that must be exposed by whatever process
    monitoring mechanism you use.
  """"""
  @abstractmethod
  def cpu_time(self):
    """"""
      Total cpu time of this process.
    """"""

  @abstractmethod
  def wall_time(self):
    """"""
      Total wall time this process has been up.
    """"""

  @abstractmethod
  def pid(self):
    """"""
      PID of the process.
    """"""

  @abstractmethod
  def ppid(self):
    """"""
      Parent PID of the process.
    """"""

  @abstractmethod
  def user(self):
    """"""
      The owner of the process.
    """"""

  @abstractmethod
  def cwd(self):
    """"""
      The current working directory of the process.
    """"""

  @abstractmethod
  def cmdline(self):
    """"""
      The full command line of the process.
    """"""
    raise NotImplementedError



class ProcessHandleParser(ScanfParser):
  """"""
    Given:
      attrs: list of attribute names
      type_map: map of attribute name to attribute type (%d/%u/etc format converter)
      handlers: optional set of postprocessing callbacks that take (attribute, value)
    Process a line from one of the process information sources (e.g. ps, procfs.)
  """"""
  def parse(self, line):
    d = {}
    try:
      so = ScanfParser.parse(self, ' '.join(line.split()), True)
      for attr, value in zip(self._attrs, so.ungrouped()):
        d[attr] = self._handlers[attr](attr, value) if attr in self._handlers else value
    except ScanfParser.ParseError as e:
      return {}
    return d

  def __init__(self, attrs, type_map, handlers = {}):
    self._attrs = attrs
    self._handlers = handlers
    attr_list = map(type_map.get, attrs)
    ScanfParser.__init__(self, ' '.join(attr_list))


class ProcessHandleParserBase(object):
  """"""
    Given a provider of process lines, parse them into bundles of attributes that can be
    translated into ProcessHandles.
  """"""
  def _produce(self):
    raise NotImplementedError

  def _realize(self):
    return self._realize_from_line(self._produce())

  def _realize_from_line(self, line):
    self._exists = False
    if line is None:
      self._attrs = {}
    else:
      self._attrs = self.PARSER.parse(line)
      if self._attrs:
        self._pid = self._attrs['pid']
        self._exists = True

  @classmethod
  def from_line(cls, line):
    proc = cls()
    proc._realize_from_line(line)
    return proc

  @classmethod
  def init_class(cls):
    if not hasattr(cls, 'PARSER'):
      assert hasattr(cls, 'ATTRS')
      assert hasattr(cls, 'TYPE_MAP')
      assert hasattr(cls, 'HANDLERS')
      setattr(cls, 'PARSER', ProcessHandleParser(cls.ATTRS, cls.TYPE_MAP, cls.HANDLERS))
    if not hasattr(cls, 'ALIASES'):
      cls.ALIASES = {}

  def __init__(self, pid=-1):
    self.init_class()
    self._exists = False
    self._pid = pid
    self._attrs = None
    if pid != -1:
      self._realize()

  def exists(self):
    return self._exists

  def get(self, key):
    probe_key = self.ALIASES[key] if key in self.ALIASES else key
    return self._attrs.get(probe_key)

  def refresh(self, line=None):
    return self._realize() if line is None else self._realize_from_line(line)
","
1from abc import abstractmethod
2
3from twitter.common.lang import Interface
4from twitter.common.string import ScanfParser
5
6class ProcessHandle(Interface):
7  """"""
8    ProcessHandle interface.  Methods that must be exposed by whatever process
9    monitoring mechanism you use.
10  """"""
11  @abstractmethod
12  def cpu_time(self):
13    """"""
14      Total cpu time of this process.
15    """"""
16
17  @abstractmethod
18  def wall_time(self):
19    """"""
20      Total wall time this process has been up.
21    """"""
22
23  @abstractmethod
24  def pid(self):
25    """"""
26      PID of the process.
27    """"""
28
29  @abstractmethod
30  def ppid(self):
31    """"""
32      Parent PID of the process.
33    """"""
34
35  @abstractmethod
36  def user(self):
37    """"""
38      The owner of the process.
39    """"""
40
41  @abstractmethod
42  def cwd(self):
43    """"""
44      The current working directory of the process.
45    """"""
46
47  @abstractmethod
48  def cmdline(self):
49    """"""
50      The full command line of the process.
51    """"""
52    raise NotImplementedError
53
54
55
56class ProcessHandleParser(ScanfParser):
57  """"""
58    Given:
59      attrs: list of attribute names
60      type_map: map of attribute name to attribute type (%d/%u/etc format converter)
61      handlers: optional set of postprocessing callbacks that take (attribute, value)
62    Process a line from one of the process information sources (e.g. ps, procfs.)
63  """"""
64  def parse(self, line):
65    d = {}
66    try:
67      so = ScanfParser.parse(self, ' '.join(line.split()), True)
68      for attr, value in zip(self._attrs, so.ungrouped()):
69        d[attr] = self._handlers[attr](attr, value) if attr in self._handlers else value
70    except ScanfParser.ParseError as e:
71      return {}
72    return d
73
74  def __init__(self, attrs, type_map, handlers = {}):
75    self._attrs = attrs
76    self._handlers = handlers
77    attr_list = map(type_map.get, attrs)
78    ScanfParser.__init__(self, ' '.join(attr_list))
79
80
81class ProcessHandleParserBase(object):
82  """"""
83    Given a provider of process lines, parse them into bundles of attributes that can be
84    translated into ProcessHandles.
85  """"""
86  def _produce(self):
87    raise NotImplementedError
88
89  def _realize(self):
90    return self._realize_from_line(self._produce())
91
92  def _realize_from_line(self, line):
93    self._exists = False
94    if line is None:
95      self._attrs = {}
96    else:
97      self._attrs = self.PARSER.parse(line)
98      if self._attrs:
99        self._pid = self._attrs['pid']
100        self._exists = True
101
102  @classmethod
103  def from_line(cls, line):
104    proc = cls()
105    proc._realize_from_line(line)
106    return proc
107
108  @classmethod
109  def init_class(cls):
110    if not hasattr(cls, 'PARSER'):
111      setattr(cls, 'PARSER', ProcessHandleParser(cls.ATTRS, cls.TYPE_MAP, cls.HANDLERS))
112    if not hasattr(cls, 'ALIASES'):
113      cls.ALIASES = {}
114
115  def __init__(self, pid=-1):
116    self.init_class()
117    self._exists = False
118    self._pid = pid
119    self._attrs = None
120    if pid != -1:
121      self._realize()
122
123  def exists(self):
124    return self._exists
125
126  def get(self, key):
127    probe_key = self.ALIASES[key] if key in self.ALIASES else key
128    return self._attrs.get(probe_key)
129
130  def refresh(self, line=None):
131    return self._realize() if line is None else self._realize_from_line(line)
132","[['hasattr(cls', '==', 'True'], ['hasattr(cls', '==', 'True'], ['hasattr(cls', '==', 'True']]",3,3,1.0,0.0009118541033434,"['line', 'd', 'so', 'd[attr]', 'attrs', 'type_map', 'handlers', 'self._attrs', 'self._handlers', 'attr_list', 'self._exists', 'self._pid', 'cls', 'proc', 'cls.ALIASES', 'pid', 'key', 'probe_key']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['line', 'd', 'so', 'd[attr]', 'attrs', 'type_map', 'handlers', 'self._attrs', 'self._handlers', 'attr_list', 'self._exists', 'self._pid', 'cls', 'proc', 'cls.ALIASES', 'pid', 'key', 'probe_key']
*Code:

1from abc import abstractmethod
2
3from twitter.common.lang import Interface
4from twitter.common.string import ScanfParser
5
6class ProcessHandle(Interface):
7  """"""
8    ProcessHandle interface.  Methods that must be exposed by whatever process
9    monitoring mechanism you use.
10  """"""
11  @abstractmethod
12  def cpu_time(self):
13    """"""
14      Total cpu time of this process.
15    """"""
16
17  @abstractmethod
18  def wall_time(self):
19    """"""
20      Total wall time this process has been up.
21    """"""
22
23  @abstractmethod
24  def pid(self):
25    """"""
26      PID of the process.
27    """"""
28
29  @abstractmethod
30  def ppid(self):
31    """"""
32      Parent PID of the process.
33    """"""
34
35  @abstractmethod
36  def user(self):
37    """"""
38      The owner of the process.
39    """"""
40
41  @abstractmethod
42  def cwd(self):
43    """"""
44      The current working directory of the process.
45    """"""
46
47  @abstractmethod
48  def cmdline(self):
49    """"""
50      The full command line of the process.
51    """"""
52    raise NotImplementedError
53
54
55
56class ProcessHandleParser(ScanfParser):
57  """"""
58    Given:
59      attrs: list of attribute names
60      type_map: map of attribute name to attribute type (%d/%u/etc format converter)
61      handlers: optional set of postprocessing callbacks that take (attribute, value)
62    Process a line from one of the process information sources (e.g. ps, procfs.)
63  """"""
64  def parse(self, line):
65    d = {}
66    try:
67      so = ScanfParser.parse(self, ' '.join(line.split()), True)
68      for attr, value in zip(self._attrs, so.ungrouped()):
69        d[attr] = self._handlers[attr](attr, value) if attr in self._handlers else value
70    except ScanfParser.ParseError as e:
71      return {}
72    return d
73
74  def __init__(self, attrs, type_map, handlers = {}):
75    self._attrs = attrs
76    self._handlers = handlers
77    attr_list = map(type_map.get, attrs)
78    ScanfParser.__init__(self, ' '.join(attr_list))
79
80
81class ProcessHandleParserBase(object):
82  """"""
83    Given a provider of process lines, parse them into bundles of attributes that can be
84    translated into ProcessHandles.
85  """"""
86  def _produce(self):
87    raise NotImplementedError
88
89  def _realize(self):
90    return self._realize_from_line(self._produce())
91
92  def _realize_from_line(self, line):
93    self._exists = False
94    if line is None:
95      self._attrs = {}
96    else:
97      self._attrs = self.PARSER.parse(line)
98      if self._attrs:
99        self._pid = self._attrs['pid']
100        self._exists = True
101
102  @classmethod
103  def from_line(cls, line):
104    proc = cls()
105    proc._realize_from_line(line)
106    return proc
107
108  @classmethod
109  def init_class(cls):
110    if not hasattr(cls, 'PARSER'):
111      setattr(cls, 'PARSER', ProcessHandleParser(cls.ATTRS, cls.TYPE_MAP, cls.HANDLERS))
112    if not hasattr(cls, 'ALIASES'):
113      cls.ALIASES = {}
114
115  def __init__(self, pid=-1):
116    self.init_class()
117    self._exists = False
118    self._pid = pid
119    self._attrs = None
120    if pid != -1:
121      self._realize()
122
123  def exists(self):
124    return self._exists
125
126  def get(self, key):
127    probe_key = self.ALIASES[key] if key in self.ALIASES else key
128    return self._attrs.get(probe_key)
129
130  def refresh(self, line=None):
131    return self._realize() if line is None else self._realize_from_line(line)
132",5043,"[[64, 'line', '!=', None, ""The line can't be None for parse method""],
 [74, 'attrs', '!=', None, ""attrs can't be None for ProcessHandleParser initialization""],
 [74, 'type_map', '!=', None, ""type_map can't be None for ProcessHandleParser initialization""],
 [116, 'pid', '>=', -1, 'pid should be non-negative for ProcessHandleParserBase initialization'],
 [126, 'key', '!=', None, 'key should not be None for get method'],
 [130, 'line', '!=', None, ""line can't be None for refresh method if line is specified""]]"
pombredanne/splash,"# -*- coding: utf-8 -*-
from __future__ import absolute_import
import functools

import pytest
lupa = pytest.importorskip(""lupa"")


def code_and_cursor_pos(code):
    if ""|"" in code:
        cursor_pos = code.index(""|"")
    else:
        cursor_pos = len(code)
    code = code.replace(""|"", """")
    return code, cursor_pos


def _complete(completer, code):
    """"""
    Ask completer to complete the ``code``;
    cursor position is specified by | symbol.
    """"""
    code, cursor_pos = code_and_cursor_pos(code)
    res = completer.complete(code, cursor_pos)
    assert res[""status""] == ""ok""
    assert res[""cursor_end""] == cursor_pos
    return res[""matches""]


@pytest.fixture()
def complete(completer):
    return functools.partial(_complete, completer)


def test_complete_keywords(complete):
    assert ""function"" in complete(""fun|"")
    assert ""true"" in complete(""while t| do"")


def test_complete_keywords_after_space(complete):
    assert [] == complete(""fun |"")


def test_dont_complete_keywords_as_attributes(complete):
    assert ""function"" not in complete(""x.fun|"")
    assert ""function"" not in complete(""x:fun|"")


def test_complete_globals(complete):
    res = complete(""x = tab|"")
    assert ""table"" in res

    res = complete(""x = s|"")
    assert ""string"" in res
    assert ""select"" in res
    assert ""spoon"" not in res
    assert all(m.startswith(""s"") for m in res)


def test_complete_user_globals(complete, configured_lua):
    configured_lua.execute(""spoon = 5"")
    res = complete(""x = s|"")
    assert ""string"" in res
    assert ""select"" in res
    assert ""spoon"" in res


def test_dont_complete_globals_as_attributes(complete):
    assert ""string"" not in complete(""foo = x.s|"")


def test_no_completions_on_nothing(complete):
    assert complete(""|"") == []
    assert complete("" | "") == []


def test_globals_attributes(complete):
    res = complete(""foo = string.|"")
    assert {'len', 'lower', 'reverse', 'upper'} <= set(res)
    assert 'concat' not in res

    assert complete(""foo = string.l|"") == [""len"", ""lower""]


def test_globals_attributes_index_notation(complete):
    res = complete(""foo = string['|"")
    assert {""len']"", ""lower']"", ""reverse']"", ""upper']""} <= set(res)
    assert ""concat']"" not in res

    res = complete('foo = string[""|')
    assert {'len""]', 'lower""]', 'reverse""]', 'upper""]'} <= set(res)


def test_globals_attributes_index_notation_prefix(complete):
    assert complete('foo = string[""l|') == ['len""]', 'lower""]']


def test_globals_without_dot(complete):
    assert complete(""foo = string|"") == []


def test_globals_without_dot_multiple(complete):
    assert complete(""strings=""""; foo = string|"") == [""strings""]


def test_globals_attributes_nested_false_positive(complete):
    assert complete(""foo = table.string.|"") == []


def test_globals_attributes_nested(complete, configured_lua):
    configured_lua.execute(""""""
    weight = 20
    key = ""foo""
    tbl={foo={width=10, heigth=5, nested={hello=""world""}}}
    """""")
    assert complete(""tbl.foo.w|"") == [""width""]
    assert complete(""tbl['foo'].w|"") == [""width""]
    assert complete('tbl[""foo""].w|') == [""width""]
    assert complete('tbl.foo.nested.|') == [""hello""]
    assert complete('tbl[""foo""].nested.|') == [""hello""]
    assert complete('tbl[""foo""][""nested""].|') == [""hello""]
    assert complete('tbl[\'foo\'][""nested""].|') == [""hello""]
    assert complete('tbl[\'foo""].w|') == []
    assert complete('tbl[""foo\'].w|') == []
    assert complete('tbl.bar.w|') == []
    assert complete(""tbl['bar'].w|"") == []
    assert complete(""tbl[key].w|"") == []    # not supported


def test_int_index(complete, configured_lua):
    configured_lua.execute(""""""
    str = ""hello""
    arr = {'foo', 'bar', {egg=10, spam=20}}
    """""")
    assert complete(""arr[1].|"") == complete(""str.|"")
    assert complete(""arr[2].|"") == complete(""str.|"")
    assert complete(""arr[3].|"") == ['egg', 'spam']
    assert complete(""arr[3].e|"") == ['egg']
    assert complete(""arr[3]|"") == []


def test_constant_method(complete, configured_lua):
    configured_lua.execute('str = ""hello""')
    assert complete(""('foo'):"") == complete(""str:"")
    assert complete(""('foo'):g"") == complete(""str:g"")
    assert complete(""(\""foo\""):g"") == complete(""str:g"")


@pytest.mark.xfail(reason=""not implemented"")
def test_globals_attributes_dynamic_lookup(complete, configured_lua):
    configured_lua.execute(""""""
    key = ""foo""
    tbl={foo={width=10, heigth=5}}
    """""")
    assert complete(""tbl[key].w|"") == [""width""]    # not supported


def test_globals_attributes_nested_method(complete, configured_lua):
    configured_lua.execute(""""""
    obj = {foo=""bar""}
    function obj:hello()
        return ""hello""
    end
    tbl = {prop=obj}
    """""")

    assert complete(""tbl.prop.|"") == [""foo"", ""hello""]
    assert complete(""tbl.prop:|"") == [""hello""]
    assert complete(""tbl['prop'].|"") == [""foo"", ""hello""]
    assert complete(""tbl[\""prop\""]:|"") == [""hello""]


def test_globals_attributes_nested_broken(complete, configured_lua):
    configured_lua.execute(""""""
    tbl = {prop={foo=""bar""}}
    """""")
    assert complete(""tbl:prop.|"") == []
    assert complete(""tbl:prop:|"") == []


def test_not_attributes(complete):
    assert complete(""string..|"") == []
    assert complete(""(:|"") == []


def test_complete_array(complete, configured_lua):
    configured_lua.execute(""foo = {'x', 'y', z=5}"")
    assert complete(""foo.|"") == [""z""]


def test_complete_methods(complete, configured_lua):
    configured_lua.execute(""""""
    tbl = {foo=""bar""}
    function tbl:hello()
        return 123
    end
    """""")
    assert complete(""tbl:|"") == [""hello""]     # fixme: metamethods?
    assert complete(""tbl.|"") == [""foo"", ""hello""]


def test_complete_function_result(complete, configured_lua):
    configured_lua.execute(""""""
    function foo()
        return {bar=""baz""}
    end
    """""")
    # It is too hard for a completer to return a proper result,
    # but at least there shouldn't be spurious matches.
    assert complete(""foo().b|"") == []


def test_complete_local_variables(complete):
    res = complete(""""""
    status = ""statue""
    stats = ""sterling""
    x = st|
    """""")
    assert res == [""stats"", ""status"", ""string""]


def test_complete_local_variables_unicode(complete):
    res = complete(u""""""
    привет = """"
    пр|
    """""")
    assert res == []   # unicode identifiers are not allowed in Lua


def test_complete_latter_local_variables(complete):
    res = complete(""""""
    x = st|
    status = ""statue""
    stats = ""sterling""
    """""")
    assert res == [""stats"", ""status"", ""string""]


def test_complete_string_metamethod(complete, configured_lua):
    configured_lua.execute(""txt = 'hello'"")
    assert ""upper"" in complete(""txt:|"")
    assert [""upper""] == complete(""txt:up|"")


@pytest.mark.xfail
def test_dont_complete_globals_inside_string(complete):
    assert ""string"" not in complete(""x = 's|'"")


def test_dont_complete_inside_identifier(complete):
    assert complete(""loc|omotive"") == []


def test_complete_metamethods(complete, configured_lua):
    configured_lua.execute(""""""
    Animal = {}
    Animal.__index = Animal
    function Animal._create(name)
        local self = {name=name}
        setmetatable(self, Animal)
        return self
    end
    function Animal:jump() end
    animal = Animal._create(""dog"")
    """""")
    assert [""name""] == complete(""animal.n|"")
    assert [""jump""] == complete(""animal.j|"")
    assert [""jump"", ""name"", ""_create""] == complete(""animal.|"")
    assert [""jump"", ""_create""] == complete(""animal:|"")


def test_complete_metamethods_index_as_function(complete, configured_lua):
    # When __index is a function, Splash completing engine assumes
    # that it eventually uses rawget.
    configured_lua.execute(""""""
    Animal = {}
    function Animal._create(name)
        local self = {name=name}
        setmetatable(self, Animal)
        return self
    end
    function Animal:jump() end
    function Animal:__index(index)
      if index == ""foo"" then
        return 123
      else
        return rawget(Animal, index)
      end
    end
    animal = Animal._create(""cat"")
    """""")
    assert [] == complete(""animal.f|"")  # can't support it
    assert [""name""] == complete(""animal.n|"")
    assert [""jump""] == complete(""animal.j|"")
    assert [""jump"", ""name"", ""_create""] == complete(""animal.|"")
    assert [""jump"", ""_create""] == complete(""animal:|"")


def test_lexer(lua_lexer):
    tokens = lua_lexer.tokenize(""x=1"", pad=2)
    assert tokens == [
        ('NA', ''),
        ('NA', ''),
        ('iden', 'x'),
        ('=', '='),
        ('number', 1)
    ]
","
1# -*- coding: utf-8 -*-
2from __future__ import absolute_import
3import functools
4
5import pytest
6lupa = pytest.importorskip(""lupa"")
7
8
9def code_and_cursor_pos(code):
10    if ""|"" in code:
11        cursor_pos = code.index(""|"")
12    else:
13        cursor_pos = len(code)
14    code = code.replace(""|"", """")
15    return code, cursor_pos
16
17
18def _complete(completer, code):
19    """"""
20    Ask completer to complete the ``code``;
21    cursor position is specified by | symbol.
22    """"""
23    code, cursor_pos = code_and_cursor_pos(code)
24    res = completer.complete(code, cursor_pos)
25    return res[""matches""]
26
27
28@pytest.fixture()
29def complete(completer):
30    return functools.partial(_complete, completer)
31
32
33def test_complete_keywords(complete):
34
35
36def test_complete_keywords_after_space(complete):
37
38
39def test_dont_complete_keywords_as_attributes(complete):
40
41
42def test_complete_globals(complete):
43    res = complete(""x = tab|"")
44
45    res = complete(""x = s|"")
46
47
48def test_complete_user_globals(complete, configured_lua):
49    configured_lua.execute(""spoon = 5"")
50    res = complete(""x = s|"")
51
52
53def test_dont_complete_globals_as_attributes(complete):
54
55
56def test_no_completions_on_nothing(complete):
57
58
59def test_globals_attributes(complete):
60    res = complete(""foo = string.|"")
61
62
63
64def test_globals_attributes_index_notation(complete):
65    res = complete(""foo = string['|"")
66
67    res = complete('foo = string[""|')
68
69
70def test_globals_attributes_index_notation_prefix(complete):
71
72
73def test_globals_without_dot(complete):
74
75
76def test_globals_without_dot_multiple(complete):
77
78
79def test_globals_attributes_nested_false_positive(complete):
80
81
82def test_globals_attributes_nested(complete, configured_lua):
83    configured_lua.execute(""""""
84    weight = 20
85    key = ""foo""
86    tbl={foo={width=10, heigth=5, nested={hello=""world""}}}
87    """""")
88
89
90def test_int_index(complete, configured_lua):
91    configured_lua.execute(""""""
92    str = ""hello""
93    arr = {'foo', 'bar', {egg=10, spam=20}}
94    """""")
95
96
97def test_constant_method(complete, configured_lua):
98    configured_lua.execute('str = ""hello""')
99
100
101@pytest.mark.xfail(reason=""not implemented"")
102def test_globals_attributes_dynamic_lookup(complete, configured_lua):
103    configured_lua.execute(""""""
104    key = ""foo""
105    tbl={foo={width=10, heigth=5}}
106    """""")
107
108
109def test_globals_attributes_nested_method(complete, configured_lua):
110    configured_lua.execute(""""""
111    obj = {foo=""bar""}
112    function obj:hello()
113        return ""hello""
114    end
115    tbl = {prop=obj}
116    """""")
117
118
119
120def test_globals_attributes_nested_broken(complete, configured_lua):
121    configured_lua.execute(""""""
122    tbl = {prop={foo=""bar""}}
123    """""")
124
125
126def test_not_attributes(complete):
127
128
129def test_complete_array(complete, configured_lua):
130    configured_lua.execute(""foo = {'x', 'y', z=5}"")
131
132
133def test_complete_methods(complete, configured_lua):
134    configured_lua.execute(""""""
135    tbl = {foo=""bar""}
136    function tbl:hello()
137        return 123
138    end
139    """""")
140
141
142def test_complete_function_result(complete, configured_lua):
143    configured_lua.execute(""""""
144    function foo()
145        return {bar=""baz""}
146    end
147    """""")
148    # It is too hard for a completer to return a proper result,
149    # but at least there shouldn't be spurious matches.
150
151
152def test_complete_local_variables(complete):
153    res = complete(""""""
154    status = ""statue""
155    stats = ""sterling""
156    x = st|
157    """""")
158
159
160def test_complete_local_variables_unicode(complete):
161    res = complete(u""""""
162    привет = """"
163    пр|
164    """""")
165
166
167def test_complete_latter_local_variables(complete):
168    res = complete(""""""
169    x = st|
170    status = ""statue""
171    stats = ""sterling""
172    """""")
173
174
175def test_complete_string_metamethod(complete, configured_lua):
176    configured_lua.execute(""txt = 'hello'"")
177
178
179@pytest.mark.xfail
180def test_dont_complete_globals_inside_string(complete):
181
182
183def test_dont_complete_inside_identifier(complete):
184
185
186def test_complete_metamethods(complete, configured_lua):
187    configured_lua.execute(""""""
188    Animal = {}
189    Animal.__index = Animal
190    function Animal._create(name)
191        local self = {name=name}
192        setmetatable(self, Animal)
193        return self
194    end
195    function Animal:jump() end
196    animal = Animal._create(""dog"")
197    """""")
198
199
200def test_complete_metamethods_index_as_function(complete, configured_lua):
201    # When __index is a function, Splash completing engine assumes
202    # that it eventually uses rawget.
203    configured_lua.execute(""""""
204    Animal = {}
205    function Animal._create(name)
206        local self = {name=name}
207        setmetatable(self, Animal)
208        return self
209    end
210    function Animal:jump() end
211    function Animal:__index(index)
212      if index == ""foo"" then
213        return 123
214      else
215        return rawget(Animal, index)
216      end
217    end
218    animal = Animal._create(""cat"")
219    """""")
220
221
222def test_lexer(lua_lexer):
223    tokens = lua_lexer.tokenize(""x=1"", pad=2)
224        ('NA', ''),
225        ('NA', ''),
226        ('iden', 'x'),
227        ('=', '='),
228        ('number', 1)
229    ]
230","[['res[""status""]', '==', '""ok""'], ['res[""cursor_end""]', '==', 'cursor_pos'], ['[]', '==', 'complete(""fun |"")'], ['complete(""|"")', '==', '[]'], ['complete("" | "")', '==', '[]'], [""{'len'"", '==', 'True'], ['complete(""foo = string.l|"")', '==', '[""len""'], ['{""len\']""', '==', 'True'], ['{\'len""]\'', '==', 'True'], ['complete(\'foo = string[""l|\')', '==', '[\'len""]\''], ['complete(""foo = string|"")', '==', '[]'], ['complete(""strings=""""; foo = string|"")', '==', '[""strings""]'], ['complete(""foo = table.string.|"")', '==', '[]'], ['complete(""tbl.foo.w|"")', '==', '[""width""]'], ['complete(""tbl[\'foo\'].w|"")', '==', '[""width""]'], ['complete(\'tbl[""foo""].w|\')', '==', '[""width""]'], [""complete('tbl.foo.nested.|')"", '==', '[""hello""]'], ['complete(\'tbl[""foo""].nested.|\')', '==', '[""hello""]'], ['complete(\'tbl[""foo""][""nested""].|\')', '==', '[""hello""]'], ['complete(\'tbl[\\\'foo\\\'][""nested""].|\')', '==', '[""hello""]'], ['complete(\'tbl[\\\'foo""].w|\')', '==', '[]'], ['complete(\'tbl[""foo\\\'].w|\')', '==', '[]'], [""complete('tbl.bar.w|')"", '==', '[]'], ['complete(""tbl[\'bar\'].w|"")', '==', '[]'], ['complete(""tbl[key].w|"")', '==', '[]'], ['complete(""arr[1].|"")', '==', 'complete(""str.|"")'], ['complete(""arr[2].|"")', '==', 'complete(""str.|"")'], ['complete(""arr[3].|"")', '==', ""['egg'""], ['complete(""arr[3].e|"")', '==', ""['egg']""], ['complete(""arr[3]|"")', '==', '[]'], ['complete(""(\'foo\'):"")', '==', 'complete(""str:"")'], ['complete(""(\'foo\'):g"")', '==', 'complete(""str:g"")'], ['complete(""(\\""foo\\""):g"")', '==', 'complete(""str:g"")'], ['complete(""tbl[key].w|"")', '==', '[""width""]'], ['complete(""tbl.prop.|"")', '==', '[""foo""'], ['complete(""tbl.prop:|"")', '==', '[""hello""]'], ['complete(""tbl[\'prop\'].|"")', '==', '[""foo""'], ['complete(""tbl[\\""prop\\""]:|"")', '==', '[""hello""]'], ['complete(""tbl:prop.|"")', '==', '[]'], ['complete(""tbl:prop:|"")', '==', '[]'], ['complete(""string..|"")', '==', '[]'], ['complete(""(:|"")', '==', '[]'], ['complete(""foo.|"")', '==', '[""z""]'], ['complete(""tbl:|"")', '==', '[""hello""]'], ['complete(""tbl.|"")', '==', '[""foo""'], ['complete(""foo().b|"")', '==', '[]'], ['res', '==', '[""stats""'], ['res', '==', '[""stats""'], ['[""upper""]', '==', 'complete(""txt:up|"")'], ['complete(""loc|omotive"")', '==', '[]'], ['[""name""]', '==', 'complete(""animal.n|"")'], ['[""jump""]', '==', 'complete(""animal.j|"")'], ['[""jump""', '==', 'True'], ['[""jump""', '==', 'True'], ['[]', '==', 'complete(""animal.f|"")'], ['[""name""]', '==', 'complete(""animal.n|"")'], ['[""jump""]', '==', 'complete(""animal.j|"")'], ['[""jump""', '==', 'True'], ['[""jump""', '==', 'True'], ['tokens', '==', '[']]",78,60,0.7692307692307693,0.0069970845481049,"['lupa', 'code', 'cursor_pos', 'completer', 'res', 'complete', 'configured_lua', 'configured_lua.execute(""spoon', 'assert ""string"" not in complete(""foo', 'assert complete(""foo', ""assert complete('foo"", 'assert complete(""strings=""""; foo', 'weight', 'key', 'str', 'arr', ""configured_lua.execute('str"", 'obj', 'tbl', 'configured_lua.execute(""foo', 'status', 'stats', 'x', 'привет', 'configured_lua.execute(""txt', 'assert ""string"" not in complete(""x', 'Animal', 'Animal.__index', 'local self', 'animal', 'lua_lexer', 'tokens']",32,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['lupa', 'code', 'cursor_pos', 'completer', 'res', 'complete', 'configured_lua', 'configured_lua.execute(""spoon', 'assert ""string"" not in complete(""foo', 'assert complete(""foo', ""assert complete('foo"", 'assert complete(""strings=""""; foo', 'weight', 'key', 'str', 'arr', ""configured_lua.execute('str"", 'obj', 'tbl', 'configured_lua.execute(""foo', 'status', 'stats', 'x', 'привет', 'configured_lua.execute(""txt', 'assert ""string"" not in complete(""x', 'Animal', 'Animal.__index', 'local self', 'animal', 'lua_lexer', 'tokens']
*Code:

1# -*- coding: utf-8 -*-
2from __future__ import absolute_import
3import functools
4
5import pytest
6lupa = pytest.importorskip(""lupa"")
7
8
9def code_and_cursor_pos(code):
10    if ""|"" in code:
11        cursor_pos = code.index(""|"")
12    else:
13        cursor_pos = len(code)
14    code = code.replace(""|"", """")
15    return code, cursor_pos
16
17
18def _complete(completer, code):
19    """"""
20    Ask completer to complete the ``code``;
21    cursor position is specified by | symbol.
22    """"""
23    code, cursor_pos = code_and_cursor_pos(code)
24    res = completer.complete(code, cursor_pos)
25    return res[""matches""]
26
27
28@pytest.fixture()
29def complete(completer):
30    return functools.partial(_complete, completer)
31
32
33def test_complete_keywords(complete):
34
35
36def test_complete_keywords_after_space(complete):
37
38
39def test_dont_complete_keywords_as_attributes(complete):
40
41
42def test_complete_globals(complete):
43    res = complete(""x = tab|"")
44
45    res = complete(""x = s|"")
46
47
48def test_complete_user_globals(complete, configured_lua):
49    configured_lua.execute(""spoon = 5"")
50    res = complete(""x = s|"")
51
52
53def test_dont_complete_globals_as_attributes(complete):
54
55
56def test_no_completions_on_nothing(complete):
57
58
59def test_globals_attributes(complete):
60    res = complete(""foo = string.|"")
61
62
63
64def test_globals_attributes_index_notation(complete):
65    res = complete(""foo = string['|"")
66
67    res = complete('foo = string[""|')
68
69
70def test_globals_attributes_index_notation_prefix(complete):
71
72
73def test_globals_without_dot(complete):
74
75
76def test_globals_without_dot_multiple(complete):
77
78
79def test_globals_attributes_nested_false_positive(complete):
80
81
82def test_globals_attributes_nested(complete, configured_lua):
83    configured_lua.execute(""""""
84    weight = 20
85    key = ""foo""
86    tbl={foo={width=10, heigth=5, nested={hello=""world""}}}
87    """""")
88
89
90def test_int_index(complete, configured_lua):
91    configured_lua.execute(""""""
92    str = ""hello""
93    arr = {'foo', 'bar', {egg=10, spam=20}}
94    """""")
95
96
97def test_constant_method(complete, configured_lua):
98    configured_lua.execute('str = ""hello""')
99
100
101@pytest.mark.xfail(reason=""not implemented"")
102def test_globals_attributes_dynamic_lookup(complete, configured_lua):
103    configured_lua.execute(""""""
104    key = ""foo""
105    tbl={foo={width=10, heigth=5}}
106    """""")
107
108
109def test_globals_attributes_nested_method(complete, configured_lua):
110    configured_lua.execute(""""""
111    obj = {foo=""bar""}
112    function obj:hello()
113        return ""hello""
114    end
115    tbl = {prop=obj}
116    """""")
117
118
119
120def test_globals_attributes_nested_broken(complete, configured_lua):
121    configured_lua.execute(""""""
122    tbl = {prop={foo=""bar""}}
123    """""")
124
125
126def test_not_attributes(complete):
127
128
129def test_complete_array(complete, configured_lua):
130    configured_lua.execute(""foo = {'x', 'y', z=5}"")
131
132
133def test_complete_methods(complete, configured_lua):
134    configured_lua.execute(""""""
135    tbl = {foo=""bar""}
136    function tbl:hello()
137        return 123
138    end
139    """""")
140
141
142def test_complete_function_result(complete, configured_lua):
143    configured_lua.execute(""""""
144    function foo()
145        return {bar=""baz""}
146    end
147    """""")
148    # It is too hard for a completer to return a proper result,
149    # but at least there shouldn't be spurious matches.
150
151
152def test_complete_local_variables(complete):
153    res = complete(""""""
154    status = ""statue""
155    stats = ""sterling""
156    x = st|
157    """""")
158
159
160def test_complete_local_variables_unicode(complete):
161    res = complete(u""""""
162    привет = """"
163    пр|
164    """""")
165
166
167def test_complete_latter_local_variables(complete):
168    res = complete(""""""
169    x = st|
170    status = ""statue""
171    stats = ""sterling""
172    """""")
173
174
175def test_complete_string_metamethod(complete, configured_lua):
176    configured_lua.execute(""txt = 'hello'"")
177
178
179@pytest.mark.xfail
180def test_dont_complete_globals_inside_string(complete):
181
182
183def test_dont_complete_inside_identifier(complete):
184
185
186def test_complete_metamethods(complete, configured_lua):
187    configured_lua.execute(""""""
188    Animal = {}
189    Animal.__index = Animal
190    function Animal._create(name)
191        local self = {name=name}
192        setmetatable(self, Animal)
193        return self
194    end
195    function Animal:jump() end
196    animal = Animal._create(""dog"")
197    """""")
198
199
200def test_complete_metamethods_index_as_function(complete, configured_lua):
201    # When __index is a function, Splash completing engine assumes
202    # that it eventually uses rawget.
203    configured_lua.execute(""""""
204    Animal = {}
205    function Animal._create(name)
206        local self = {name=name}
207        setmetatable(self, Animal)
208        return self
209    end
210    function Animal:jump() end
211    function Animal:__index(index)
212      if index == ""foo"" then
213        return 123
214      else
215        return rawget(Animal, index)
216      end
217    end
218    animal = Animal._create(""cat"")
219    """""")
220
221
222def test_lexer(lua_lexer):
223    tokens = lua_lexer.tokenize(""x=1"", pad=2)
224        ('NA', ''),
225        ('NA', ''),
226        ('iden', 'x'),
227        ('=', '='),
228        ('number', 1)
229    ]
230",7411,"[[9, 'code', '!=', None, ""Code cannot be None""], 
 [23, 'code', '!=', None, ""Code cannot be None""],
 [23, 'cursor_pos', '>=', 0, ""Cursor position should be a non-negative integer""],
 [24, 'completer', '!=', None, ""Completer function cannot be None""],
 [25, 'res', '!=', None, ""Completion result can't be None""],
 [29, 'completer', '!=', None, ""Completer function cannot be None""],
 [43, 'complete', '!=', None, ""Complete function cannot be None""], 
 [44, 'res', '!=', None, ""Completion result can't be None""],
 [49, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [50, 'res', '!=', None, ""Completion result can't be None""],
 [60, 'res', '!=', None, ""Completion result can't be None""],
 [65, 'res', '!=', None, ""Completion result can't be None""],
 [66, 'res', '!=', None, ""Completion result can't be None""],
 [83, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [91, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [98, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [102, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [109, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [134, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [143, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [153, 'res', '!=', None, ""Completion result can't be None""],
 [160, 'res', '!=', None, ""Completion result can't be None""],
 [167, 'res', '!=', None, ""Completion result can't be None""],
 [175, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [187, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [200, 'configured_lua', '!=', None, ""Configured lua object cannot be None""],
 [223, 'lua_lexer', '!=', None, ""Lua lexer object cannot be None""],
 [224, 'tokens', '!=', None, ""Tokens list cannot be None""]]"
mindsnacks/Zinc,"import os
from urlparse import urlparse
from atomicfile import AtomicFile
from copy import copy

import zinc.utils as utils
from . import StorageBackend


class FilesystemStorageBackend(StorageBackend):

    def __init__(self, url=None, **kwargs):
        super(FilesystemStorageBackend, self).__init__(**kwargs)
        assert url is not None
        self._url = url

    @classmethod
    def valid_url(cls, url):
        return urlparse(url).scheme in ('file')

    def bind_to_catalog(self, id=None):
        assert id
        cpy = copy(self)
        urlcomps = urlparse(self._url)
        new_path = os.path.join(urlcomps.path, id)
        cpy._url = 'file://%s' % (new_path)
        return cpy

    @property
    def url(self):
        return self._url

    def _root_abs_path(self):
        return urlparse(self.url).path

    def _abs_path(self, subpath):
        return os.path.join(self._root_abs_path(), subpath)

    def get(self, subpath):
        abs_path = self._abs_path(subpath)
        f = open(abs_path, 'r')
        return f

    def get_meta(self, subpath):
        abs_path = self._abs_path(subpath)
        if not os.path.exists(abs_path):
            return None
        meta = dict()
        meta['size'] = os.path.getsize(abs_path)
        return meta

    def put(self, subpath, fileobj, **kwargs):
        abs_path = self._abs_path(subpath)
        utils.makedirs(os.path.dirname(abs_path))
        with AtomicFile(abs_path, 'w') as f:
            f.write(fileobj.read())

    def list(self, prefix=None):
        if prefix is not None:
            dir = self._abs_path(prefix)
        else:
            dir = self._root_abs_path()

        contents = []
        for path, dirs, files in os.walk(dir):
            for fn in files:
                abs_path = os.path.join(path, fn)
                rel_path = abs_path[len(dir) + 1:]  # get path relative to dir
                contents.append(rel_path)

        return contents

    def delete(self, subpath):
        path = self._abs_path(subpath)
        os.remove(path)
","
1import os
2from urlparse import urlparse
3from atomicfile import AtomicFile
4from copy import copy
5
6import zinc.utils as utils
7from . import StorageBackend
8
9
10class FilesystemStorageBackend(StorageBackend):
11
12    def __init__(self, url=None, **kwargs):
13        super(FilesystemStorageBackend, self).__init__(**kwargs)
14        self._url = url
15
16    @classmethod
17    def valid_url(cls, url):
18        return urlparse(url).scheme in ('file')
19
20    def bind_to_catalog(self, id=None):
21        cpy = copy(self)
22        urlcomps = urlparse(self._url)
23        new_path = os.path.join(urlcomps.path, id)
24        cpy._url = 'file://%s' % (new_path)
25        return cpy
26
27    @property
28    def url(self):
29        return self._url
30
31    def _root_abs_path(self):
32        return urlparse(self.url).path
33
34    def _abs_path(self, subpath):
35        return os.path.join(self._root_abs_path(), subpath)
36
37    def get(self, subpath):
38        abs_path = self._abs_path(subpath)
39        f = open(abs_path, 'r')
40        return f
41
42    def get_meta(self, subpath):
43        abs_path = self._abs_path(subpath)
44        if not os.path.exists(abs_path):
45            return None
46        meta = dict()
47        meta['size'] = os.path.getsize(abs_path)
48        return meta
49
50    def put(self, subpath, fileobj, **kwargs):
51        abs_path = self._abs_path(subpath)
52        utils.makedirs(os.path.dirname(abs_path))
53        with AtomicFile(abs_path, 'w') as f:
54            f.write(fileobj.read())
55
56    def list(self, prefix=None):
57        if prefix is not None:
58            dir = self._abs_path(prefix)
59        else:
60            dir = self._root_abs_path()
61
62        contents = []
63        for path, dirs, files in os.walk(dir):
64            for fn in files:
65                abs_path = os.path.join(path, fn)
66                rel_path = abs_path[len(dir) + 1:]  # get path relative to dir
67                contents.append(rel_path)
68
69        return contents
70
71    def delete(self, subpath):
72        path = self._abs_path(subpath)
73        os.remove(path)
74","[['url', '==', 'not None'], ['id', '==', 'True']]",2,2,1.0,0.0009756097560975,"['url', '**kwargs', 'self._url', 'cls', 'id', 'cpy', 'urlcomps', 'new_path', 'cpy._url', 'subpath', 'abs_path', 'f', 'meta', ""meta['size']"", 'fileobj', 'prefix', 'dir', 'contents', 'rel_path', 'path']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['url', '**kwargs', 'self._url', 'cls', 'id', 'cpy', 'urlcomps', 'new_path', 'cpy._url', 'subpath', 'abs_path', 'f', 'meta', ""meta['size']"", 'fileobj', 'prefix', 'dir', 'contents', 'rel_path', 'path']
*Code:

1import os
2from urlparse import urlparse
3from atomicfile import AtomicFile
4from copy import copy
5
6import zinc.utils as utils
7from . import StorageBackend
8
9
10class FilesystemStorageBackend(StorageBackend):
11
12    def __init__(self, url=None, **kwargs):
13        super(FilesystemStorageBackend, self).__init__(**kwargs)
14        self._url = url
15
16    @classmethod
17    def valid_url(cls, url):
18        return urlparse(url).scheme in ('file')
19
20    def bind_to_catalog(self, id=None):
21        cpy = copy(self)
22        urlcomps = urlparse(self._url)
23        new_path = os.path.join(urlcomps.path, id)
24        cpy._url = 'file://%s' % (new_path)
25        return cpy
26
27    @property
28    def url(self):
29        return self._url
30
31    def _root_abs_path(self):
32        return urlparse(self.url).path
33
34    def _abs_path(self, subpath):
35        return os.path.join(self._root_abs_path(), subpath)
36
37    def get(self, subpath):
38        abs_path = self._abs_path(subpath)
39        f = open(abs_path, 'r')
40        return f
41
42    def get_meta(self, subpath):
43        abs_path = self._abs_path(subpath)
44        if not os.path.exists(abs_path):
45            return None
46        meta = dict()
47        meta['size'] = os.path.getsize(abs_path)
48        return meta
49
50    def put(self, subpath, fileobj, **kwargs):
51        abs_path = self._abs_path(subpath)
52        utils.makedirs(os.path.dirname(abs_path))
53        with AtomicFile(abs_path, 'w') as f:
54            f.write(fileobj.read())
55
56    def list(self, prefix=None):
57        if prefix is not None:
58            dir = self._abs_path(prefix)
59        else:
60            dir = self._root_abs_path()
61
62        contents = []
63        for path, dirs, files in os.walk(dir):
64            for fn in files:
65                abs_path = os.path.join(path, fn)
66                rel_path = abs_path[len(dir) + 1:]  # get path relative to dir
67                contents.append(rel_path)
68
69        return contents
70
71    def delete(self, subpath):
72        path = self._abs_path(subpath)
73        os.remove(path)
74",3721,"[[12, 'url', '!=', None, ""the URL should not be None""],
 [12, '**kwargs', '!=', None, ""kwargs should not be None""],
 [17, 'url', '!=', None, ""the URL should not be None""],
 [20, 'id', '!=', None, ""Id should not be None""],
 [20, 'self._url', '!=', None, ""Internal URL should not be None""],
 [34, 'subpath', '!=', None, ""subpath should not be None""],
 [37, 'subpath', '!=', None, ""subpath should not be None""],
 [42, 'subpath', '!=', None, ""subpath should not be None""],
 [50, 'subpath', '!=', None, ""subpath should not be None""],
 [50, 'fileobj', '!=', None, ""File object should not be None""],
 [71, 'subpath', '!=', None, ""subpath should not be None""]]"
trhoden/ceph-deploy,"import pytest

from ceph_deploy.cli import get_parser
from ceph_deploy.tests.util import assert_too_few_arguments


class TestParserAdmin(object):

    def setup(self):
        self.parser = get_parser()

    def test_admin_help(self, capsys):
        with pytest.raises(SystemExit):
            self.parser.parse_args('admin --help'.split())
        out, err = capsys.readouterr()
        assert 'usage: ceph-deploy admin' in out
        assert 'positional arguments:' in out
        assert 'optional arguments:' in out

    def test_admin_host_required(self, capsys):
        with pytest.raises(SystemExit):
            self.parser.parse_args('admin'.split())
        out, err = capsys.readouterr()
        assert_too_few_arguments(err)

    def test_admin_one_host(self):
        args = self.parser.parse_args('admin host1'.split())
        assert args.client == ['host1']

    def test_admin_multiple_hosts(self):
        hostnames = ['host1', 'host2', 'host3']
        args = self.parser.parse_args(['admin'] + hostnames)
        assert args.client == hostnames
","
1import pytest
2
3from ceph_deploy.cli import get_parser
4
5
6class TestParserAdmin(object):
7
8    def setup(self):
9        self.parser = get_parser()
10
11    def test_admin_help(self, capsys):
12        with pytest.raises(SystemExit):
13            self.parser.parse_args('admin --help'.split())
14        out, err = capsys.readouterr()
15
16    def test_admin_host_required(self, capsys):
17        with pytest.raises(SystemExit):
18            self.parser.parse_args('admin'.split())
19        out, err = capsys.readouterr()
20
21    def test_admin_one_host(self):
22        args = self.parser.parse_args('admin host1'.split())
23
24    def test_admin_multiple_hosts(self):
25        hostnames = ['host1', 'host2', 'host3']
26        args = self.parser.parse_args(['admin'] + hostnames)
27","[['args.client', '==', ""['host1']""], ['args.client', '==', 'hostnames']]",7,2,0.2857142857142857,0.0018744142455482,"['self.parser', 'capsys', 'out', 'err', 'args', 'hostnames']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.parser', 'capsys', 'out', 'err', 'args', 'hostnames']
*Code:

1import pytest
2
3from ceph_deploy.cli import get_parser
4
5
6class TestParserAdmin(object):
7
8    def setup(self):
9        self.parser = get_parser()
10
11    def test_admin_help(self, capsys):
12        with pytest.raises(SystemExit):
13            self.parser.parse_args('admin --help'.split())
14        out, err = capsys.readouterr()
15
16    def test_admin_host_required(self, capsys):
17        with pytest.raises(SystemExit):
18            self.parser.parse_args('admin'.split())
19        out, err = capsys.readouterr()
20
21    def test_admin_one_host(self):
22        args = self.parser.parse_args('admin host1'.split())
23
24    def test_admin_multiple_hosts(self):
25        hostnames = ['host1', 'host2', 'host3']
26        args = self.parser.parse_args(['admin'] + hostnames)
27",2236,"[[8, 'self.parser', '!=', None, ""initialize parser before use""],
 [11, 'capsys', '!=', None, ""Capsys must be non-null to capture outputs""],
 [14, 'out', '!=', None, ""Output must be non-null after capsys readouterr""],
 [14, 'err', '!=', None, ""Error must be non-null after capsys readouterr""],
 [16, 'capsys', '!=', None, ""Capsys must be non-null to capture outputs""],
 [19, 'out', '!=', None, ""Output must be non-null after capsys readouterr""],
 [19, 'err', '!=', None, ""Error must be non-null after capsys readouterr""],
 [22, 'args', '!=', None, ""Args should be non-null after parsing""],
 [25, 'hostnames', '!=', None, ""Hostnames list must be non-null before parsing""],
 [26, 'args', '!=', None, ""Args should be non-null after parsing""]]"
terrencepreilly/darglint,"import argparse
from typing import (
    Dict,
    Optional,
    Iterator,
)
from .parser import Parser
from .validate import Validator
from .translator import Translator
from .node import Node

parser = argparse.ArgumentParser(description='Convert BNF grammar to CNF')
parser.add_argument(
    'file',
    nargs=1,
    type=str,
    help=(
        'The file to read the grammar from.'
    ),
)
parser.add_argument(
    '-f',
    '--format',
    choices=['cyk', 'py'],
    default='py',
    nargs='?',
    type=str,
    help=(
        'The output format.  Can be either ""cyk"" or ""py"".  ""cyk"" '
        'outputs the file in CYK format, as a .cyk file.  Py '
        'generates a grammar which can be read by darglint.'
    ),
)
parser.add_argument(
    '-o',
    '--output',
    nargs=1,
    type=str,
    default=None,
    help=(
        'The output file.'
    )
)


class Driver(object):

    def __init__(self):
        self.data = None  # type: Optional[str]
        self.parser = Parser()
        self.validator = Validator()
        self.translator = Translator()
        self.tree = None  # type: Optional[Node]

    def read(self, filename: str) -> 'Driver':
        with open(filename, 'r') as fin:
            self.data = fin.read()
        return self

    def parse(self) -> 'Driver':
        self.tree = self.parser.parse(self.data)
        return self

    def translate(self) -> 'Driver':
        self.translator.translate(self.tree)
        return self

    def validate(self) -> 'Driver':
        self.validator.validate(self.tree)
        return self

    def write(self, _format: str) -> str:
        assert self.tree is not None
        if _format == 'cyk':
            return str(self.tree)
        elif _format == 'py':
            return self.tree.to_python()
        else:
            raise Exception(f'Unrecognized format type {_format}')

    def get_imports(self) -> Iterator[str]:
        assert self.tree is not None
        for _import in self.tree.filter(Node.is_import):
            assert _import.value is not None
            yield _import.value

    def merge(self, driver: 'Driver'):
        """"""Merge in the grammar at the given filename with this grammar.

        Args:
            driver: Another driver to merge into this one.

        """"""
        assert self.tree is not None
        assert driver.tree is not None
        self.tree.merge(driver.tree)


def load_script(filename: str, cache: Dict[str, Driver] = dict()):
    """"""Recursively load a script, parsing it and adding dependencies.

    Args:
        filename: The name of the file to open.
        cache: A cache to avoid duplicate work.

    Returns:
        The fully parsed grammar.

    """"""
    assert filename not in cache
    driver = Driver().read(filename).parse()
    cache[filename] = driver

    # We know that merging doesn't introduce new imports,
    # so it's safe to immediately merge subgrammars.
    for filename in driver.get_imports():
        if filename in cache:
            # We skip already imported scripts, to avoid
            # having multiple copies of the productions.
            continue
        else:
            subdriver = load_script(filename, cache)
            driver.merge(subdriver)

    return driver


def main():
    args = parser.parse_args()
    driver = load_script(args.file[0])
    translated = driver.translate().validate().write(args.format)

    if args.output:
        with open(args.output[0], 'w') as fout:
            fout.write(translated)
    else:
        print(translated)


if __name__ == '__main__':
    main()
","
1import argparse
2from typing import (
3    Dict,
4    Optional,
5    Iterator,
6)
7from .parser import Parser
8from .validate import Validator
9from .translator import Translator
10from .node import Node
11
12parser = argparse.ArgumentParser(description='Convert BNF grammar to CNF')
13parser.add_argument(
14    'file',
15    nargs=1,
16    type=str,
17    help=(
18        'The file to read the grammar from.'
19    ),
20)
21parser.add_argument(
22    '-f',
23    '--format',
24    choices=['cyk', 'py'],
25    default='py',
26    nargs='?',
27    type=str,
28    help=(
29        'The output format.  Can be either ""cyk"" or ""py"".  ""cyk"" '
30        'outputs the file in CYK format, as a .cyk file.  Py '
31        'generates a grammar which can be read by darglint.'
32    ),
33)
34parser.add_argument(
35    '-o',
36    '--output',
37    nargs=1,
38    type=str,
39    default=None,
40    help=(
41        'The output file.'
42    )
43)
44
45
46class Driver(object):
47
48    def __init__(self):
49        self.data = None  # type: Optional[str]
50        self.parser = Parser()
51        self.validator = Validator()
52        self.translator = Translator()
53        self.tree = None  # type: Optional[Node]
54
55    def read(self, filename: str) -> 'Driver':
56        with open(filename, 'r') as fin:
57            self.data = fin.read()
58        return self
59
60    def parse(self) -> 'Driver':
61        self.tree = self.parser.parse(self.data)
62        return self
63
64    def translate(self) -> 'Driver':
65        self.translator.translate(self.tree)
66        return self
67
68    def validate(self) -> 'Driver':
69        self.validator.validate(self.tree)
70        return self
71
72    def write(self, _format: str) -> str:
73        if _format == 'cyk':
74            return str(self.tree)
75        elif _format == 'py':
76            return self.tree.to_python()
77        else:
78            raise Exception(f'Unrecognized format type {_format}')
79
80    def get_imports(self) -> Iterator[str]:
81        for _import in self.tree.filter(Node.is_import):
82            yield _import.value
83
84    def merge(self, driver: 'Driver'):
85        """"""Merge in the grammar at the given filename with this grammar.
86
87        Args:
88            driver: Another driver to merge into this one.
89
90        """"""
91        self.tree.merge(driver.tree)
92
93
94def load_script(filename: str, cache: Dict[str, Driver] = dict()):
95    """"""Recursively load a script, parsing it and adding dependencies.
96
97    Args:
98        filename: The name of the file to open.
99        cache: A cache to avoid duplicate work.
100
101    Returns:
102        The fully parsed grammar.
103
104    """"""
105    driver = Driver().read(filename).parse()
106    cache[filename] = driver
107
108    # We know that merging doesn't introduce new imports,
109    # so it's safe to immediately merge subgrammars.
110    for filename in driver.get_imports():
111        if filename in cache:
112            # We skip already imported scripts, to avoid
113            # having multiple copies of the productions.
114            continue
115        else:
116            subdriver = load_script(filename, cache)
117            driver.merge(subdriver)
118
119    return driver
120
121
122def main():
123    args = parser.parse_args()
124    driver = load_script(args.file[0])
125    translated = driver.translate().validate().write(args.format)
126
127    if args.output:
128        with open(args.output[0], 'w') as fout:
129            fout.write(translated)
130    else:
131        print(translated)
132
133
134if __name__ == '__main__':
135    main()
136","[['self.tree', '==', 'not None'], ['self.tree', '==', 'not None'], ['_import.value', '==', 'not None'], ['self.tree', '==', 'not None'], ['driver.tree', '==', 'not None']]",6,5,0.8333333333333334,0.0013993842709207,"['parser', 'self.data', 'self.parser', 'self.validator', 'self.translator', 'self.tree', 'filename: str', '_format: str', ""driver: 'Driver'"", 'cache: Dict[str', 'Driver]', 'driver', 'cache[filename]', 'subdriver', 'args', 'translated']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['parser', 'self.data', 'self.parser', 'self.validator', 'self.translator', 'self.tree', 'filename: str', '_format: str', ""driver: 'Driver'"", 'cache: Dict[str', 'Driver]', 'driver', 'cache[filename]', 'subdriver', 'args', 'translated']
*Code:

1import argparse
2from typing import (
3    Dict,
4    Optional,
5    Iterator,
6)
7from .parser import Parser
8from .validate import Validator
9from .translator import Translator
10from .node import Node
11
12parser = argparse.ArgumentParser(description='Convert BNF grammar to CNF')
13parser.add_argument(
14    'file',
15    nargs=1,
16    type=str,
17    help=(
18        'The file to read the grammar from.'
19    ),
20)
21parser.add_argument(
22    '-f',
23    '--format',
24    choices=['cyk', 'py'],
25    default='py',
26    nargs='?',
27    type=str,
28    help=(
29        'The output format.  Can be either ""cyk"" or ""py"".  ""cyk"" '
30        'outputs the file in CYK format, as a .cyk file.  Py '
31        'generates a grammar which can be read by darglint.'
32    ),
33)
34parser.add_argument(
35    '-o',
36    '--output',
37    nargs=1,
38    type=str,
39    default=None,
40    help=(
41        'The output file.'
42    )
43)
44
45
46class Driver(object):
47
48    def __init__(self):
49        self.data = None  # type: Optional[str]
50        self.parser = Parser()
51        self.validator = Validator()
52        self.translator = Translator()
53        self.tree = None  # type: Optional[Node]
54
55    def read(self, filename: str) -> 'Driver':
56        with open(filename, 'r') as fin:
57            self.data = fin.read()
58        return self
59
60    def parse(self) -> 'Driver':
61        self.tree = self.parser.parse(self.data)
62        return self
63
64    def translate(self) -> 'Driver':
65        self.translator.translate(self.tree)
66        return self
67
68    def validate(self) -> 'Driver':
69        self.validator.validate(self.tree)
70        return self
71
72    def write(self, _format: str) -> str:
73        if _format == 'cyk':
74            return str(self.tree)
75        elif _format == 'py':
76            return self.tree.to_python()
77        else:
78            raise Exception(f'Unrecognized format type {_format}')
79
80    def get_imports(self) -> Iterator[str]:
81        for _import in self.tree.filter(Node.is_import):
82            yield _import.value
83
84    def merge(self, driver: 'Driver'):
85        """"""Merge in the grammar at the given filename with this grammar.
86
87        Args:
88            driver: Another driver to merge into this one.
89
90        """"""
91        self.tree.merge(driver.tree)
92
93
94def load_script(filename: str, cache: Dict[str, Driver] = dict()):
95    """"""Recursively load a script, parsing it and adding dependencies.
96
97    Args:
98        filename: The name of the file to open.
99        cache: A cache to avoid duplicate work.
100
101    Returns:
102        The fully parsed grammar.
103
104    """"""
105    driver = Driver().read(filename).parse()
106    cache[filename] = driver
107
108    # We know that merging doesn't introduce new imports,
109    # so it's safe to immediately merge subgrammars.
110    for filename in driver.get_imports():
111        if filename in cache:
112            # We skip already imported scripts, to avoid
113            # having multiple copies of the productions.
114            continue
115        else:
116            subdriver = load_script(filename, cache)
117            driver.merge(subdriver)
118
119    return driver
120
121
122def main():
123    args = parser.parse_args()
124    driver = load_script(args.file[0])
125    translated = driver.translate().validate().write(args.format)
126
127    if args.output:
128        with open(args.output[0], 'w') as fout:
129            fout.write(translated)
130    else:
131        print(translated)
132
133
134if __name__ == '__main__':
135    main()
136",5261,"[[12, 'parser', '!=', None, 'The argparse.ArgumentParser should be initialized'],
 [48, 'self.data', '==', None, 'Initial value should be None for self.data'],
 [48, 'self.parser', '!=', None, 'Parser should be initialized'],
 [48, 'self.validator', '!=', None, 'Validator should be initialized'],
 [48, 'self.translator', '!=', None, 'Translator should be initialized'],
 [48, 'self.tree', '==', None, 'Initial value should be None for self.tree'],
 [56, 'filename: str', '!=', None, 'The filename should be provided to read function'],
 [60, 'self.data', '!=', None, 'The data should be available to parse'],
 [64, 'self.tree', '!=', None, 'The tree should be available to translate'],
 [68, 'self.tree', '!=', None, 'The tree should be available to validate'],
 [72, '_format: str', '!=', None, 'A format should be provided to write function'],
 [84, 'driver: \'Driver\'', '!=', None, 'A driver should be provided to merge function'],
 [94, 'filename: str', '!=', None, 'A filename should be provided to load_script function'],
 [106, 'driver', '!=', None, 'Driver should be initialized'],
 [124, 'args', '!=', None, 'Args should be available to load_script function'],
 [125, 'translated', '!=', None, 'Translated data should be available']]"
liqd/adhocracy3.mercator,"from pytest import mark


@mark.usefixtures('integration')
def test_root_acm_extensions_adapter_register(registry, context):
    from adhocracy_core.authorization import IRootACMExtension
    root_acm_extension = registry.getAdapter(context, IRootACMExtension)
    assert root_acm_extension['principals'] != []
    assert root_acm_extension['permissions'] != []
","
1from pytest import mark
2
3
4@mark.usefixtures('integration')
5def test_root_acm_extensions_adapter_register(registry, context):
6    from adhocracy_core.authorization import IRootACMExtension
7    root_acm_extension = registry.getAdapter(context, IRootACMExtension)
8","[[""root_acm_extension['principals']"", '!=', '[]'], [""root_acm_extension['permissions']"", '!=', '[]']]",2,2,1.0,0.005524861878453,"['registry', 'context', 'root_acm_extension']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['registry', 'context', 'root_acm_extension']
*Code:

1from pytest import mark
2
3
4@mark.usefixtures('integration')
5def test_root_acm_extensions_adapter_register(registry, context):
6    from adhocracy_core.authorization import IRootACMExtension
7    root_acm_extension = registry.getAdapter(context, IRootACMExtension)
8",1695,"[[7, 'registry', '!=', None, ""assert that the 'registry' is not None since it'll be used to get an adapter""],
 [7, 'context', '!=', None, ""assert that 'context' is not None since it'll be used as a parameter in a function""],
 [7, 'IRootACMExtension', '!=', None, ""assert that 'IRootACMExtension' is properly imported and not None""],
 [8, 'root_acm_extension', '!=', None, ""assert that 'root_acm_extension' is not None after being defined""]]"
oblique-labs/pyVM,"from rpython.jit.backend.llsupport.llmodel import AbstractLLCPU
from rpython.jit.backend.zarch import registers as r
from rpython.jit.backend.zarch.assembler import AssemblerZARCH
from rpython.jit.backend.zarch.codebuilder import InstrBuilder
from rpython.jit.backend.zarch import vector_ext
from rpython.rlib import rgc
from rpython.rtyper.lltypesystem import lltype, llmemory

class AbstractZARCHCPU(AbstractLLCPU):
    def __init__(self, rtyper, stats, opts=None, translate_support_code=False,
                 gcdescr=None):
        AbstractLLCPU.__init__(self, rtyper, stats, opts,
                               translate_support_code, gcdescr)

class CPU_S390_64(AbstractZARCHCPU):
    dont_keepalive_stuff = True
    supports_floats = True
    from rpython.jit.backend.zarch.registers import JITFRAME_FIXED_SIZE

    vector_ext = vector_ext.ZSIMDVectorExt()

    backend_name = 'zarch'

    IS_64_BIT = True

    frame_reg = r.SP
    all_reg_indexes = [-1] * 32
    for _i, _r in enumerate(r.MANAGED_REGS):
        all_reg_indexes[_r.value] = _i
    gen_regs = r.MANAGED_REGS
    float_regs = r.MANAGED_FP_REGS

    load_supported_factors = (1,)

    def setup(self):
        self.assembler = AssemblerZARCH(self)

    @rgc.no_release_gil
    def setup_once(self):
        self.assembler.setup_once()

    @rgc.no_release_gil
    def finish_once(self):
        self.assembler.finish_once()

    def compile_bridge(self, faildescr, inputargs, operations,
                       original_loop_token, log=True, logger=None):
        clt = original_loop_token.compiled_loop_token
        clt.compiling_a_bridge()
        return self.assembler.assemble_bridge(faildescr, inputargs, operations,
                                              original_loop_token, log, logger)

    def invalidate_loop(self, looptoken):
        """"""Activate all GUARD_NOT_INVALIDATED in the loop and its attached
        bridges.  Before this call, all GUARD_NOT_INVALIDATED do nothing;
        after this call, they all fail.  Note that afterwards, if one such
        guard fails often enough, it has a bridge attached to it; it is
        possible then to re-call invalidate_loop() on the same looptoken,
        which must invalidate all newer GUARD_NOT_INVALIDATED, but not the
        old one that already has a bridge attached to it.""""""

        for jmp, tgt in looptoken.compiled_loop_token.invalidate_positions:
            mc = InstrBuilder()
            # needs 4 bytes, ensured by the previous process
            mc.b_offset(tgt)     # a single instruction
            mc.copy_to_raw_memory(jmp)
        # positions invalidated
        looptoken.compiled_loop_token.invalidate_positions = []

    def redirect_call_assembler(self, oldlooptoken, newlooptoken):
        self.assembler.redirect_call_assembler(oldlooptoken, newlooptoken)

    def cast_ptr_to_int(x):
        adr = llmemory.cast_ptr_to_adr(x)
        return CPU_S390_64.cast_adr_to_int(adr)
    cast_ptr_to_int._annspecialcase_ = 'specialize:arglltype(0)'
    cast_ptr_to_int = staticmethod(cast_ptr_to_int)

    def build_regalloc(self):
        ''' NOT_RPYTHON: for tests '''
        from rpython.jit.backend.zarch.regalloc import Regalloc
        assert self.assembler is not None
        return Regalloc(self.assembler)
","
1from rpython.jit.backend.llsupport.llmodel import AbstractLLCPU
2from rpython.jit.backend.zarch import registers as r
3from rpython.jit.backend.zarch.assembler import AssemblerZARCH
4from rpython.jit.backend.zarch.codebuilder import InstrBuilder
5from rpython.jit.backend.zarch import vector_ext
6from rpython.rlib import rgc
7from rpython.rtyper.lltypesystem import lltype, llmemory
8
9class AbstractZARCHCPU(AbstractLLCPU):
10    def __init__(self, rtyper, stats, opts=None, translate_support_code=False,
11                 gcdescr=None):
12        AbstractLLCPU.__init__(self, rtyper, stats, opts,
13                               translate_support_code, gcdescr)
14
15class CPU_S390_64(AbstractZARCHCPU):
16    dont_keepalive_stuff = True
17    supports_floats = True
18    from rpython.jit.backend.zarch.registers import JITFRAME_FIXED_SIZE
19
20    vector_ext = vector_ext.ZSIMDVectorExt()
21
22    backend_name = 'zarch'
23
24    IS_64_BIT = True
25
26    frame_reg = r.SP
27    all_reg_indexes = [-1] * 32
28    for _i, _r in enumerate(r.MANAGED_REGS):
29        all_reg_indexes[_r.value] = _i
30    gen_regs = r.MANAGED_REGS
31    float_regs = r.MANAGED_FP_REGS
32
33    load_supported_factors = (1,)
34
35    def setup(self):
36        self.assembler = AssemblerZARCH(self)
37
38    @rgc.no_release_gil
39    def setup_once(self):
40        self.assembler.setup_once()
41
42    @rgc.no_release_gil
43    def finish_once(self):
44        self.assembler.finish_once()
45
46    def compile_bridge(self, faildescr, inputargs, operations,
47                       original_loop_token, log=True, logger=None):
48        clt = original_loop_token.compiled_loop_token
49        clt.compiling_a_bridge()
50        return self.assembler.assemble_bridge(faildescr, inputargs, operations,
51                                              original_loop_token, log, logger)
52
53    def invalidate_loop(self, looptoken):
54        """"""Activate all GUARD_NOT_INVALIDATED in the loop and its attached
55        bridges.  Before this call, all GUARD_NOT_INVALIDATED do nothing;
56        after this call, they all fail.  Note that afterwards, if one such
57        guard fails often enough, it has a bridge attached to it; it is
58        possible then to re-call invalidate_loop() on the same looptoken,
59        which must invalidate all newer GUARD_NOT_INVALIDATED, but not the
60        old one that already has a bridge attached to it.""""""
61
62        for jmp, tgt in looptoken.compiled_loop_token.invalidate_positions:
63            mc = InstrBuilder()
64            # needs 4 bytes, ensured by the previous process
65            mc.b_offset(tgt)     # a single instruction
66            mc.copy_to_raw_memory(jmp)
67        # positions invalidated
68        looptoken.compiled_loop_token.invalidate_positions = []
69
70    def redirect_call_assembler(self, oldlooptoken, newlooptoken):
71        self.assembler.redirect_call_assembler(oldlooptoken, newlooptoken)
72
73    def cast_ptr_to_int(x):
74        adr = llmemory.cast_ptr_to_adr(x)
75        return CPU_S390_64.cast_adr_to_int(adr)
76    cast_ptr_to_int._annspecialcase_ = 'specialize:arglltype(0)'
77    cast_ptr_to_int = staticmethod(cast_ptr_to_int)
78
79    def build_regalloc(self):
80        ''' NOT_RPYTHON: for tests '''
81        from rpython.jit.backend.zarch.regalloc import Regalloc
82        return Regalloc(self.assembler)
83","[['self.assembler', '==', 'not None']]",1,1,1.0,0.0003046922608165,"['rtyper', 'stats', 'opts', 'translate_support_code', 'dont_keepalive_stuff', 'supports_floats', 'vector_ext', 'backend_name', 'IS_64_BIT', 'frame_reg', 'all_reg_indexes', 'all_reg_indexes[_r.value]', 'gen_regs', 'float_regs', 'load_supported_factors', 'self.assembler', 'faildescr', 'inputargs', 'operations', 'clt', 'looptoken', 'mc', 'looptoken.compiled_loop_token.invalidate_positions', 'oldlooptoken', 'newlooptoken', 'x', 'adr', 'cast_ptr_to_int._annspecialcase_', 'cast_ptr_to_int']",29,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['rtyper', 'stats', 'opts', 'translate_support_code', 'dont_keepalive_stuff', 'supports_floats', 'vector_ext', 'backend_name', 'IS_64_BIT', 'frame_reg', 'all_reg_indexes', 'all_reg_indexes[_r.value]', 'gen_regs', 'float_regs', 'load_supported_factors', 'self.assembler', 'faildescr', 'inputargs', 'operations', 'clt', 'looptoken', 'mc', 'looptoken.compiled_loop_token.invalidate_positions', 'oldlooptoken', 'newlooptoken', 'x', 'adr', 'cast_ptr_to_int._annspecialcase_', 'cast_ptr_to_int']
*Code:

1from rpython.jit.backend.llsupport.llmodel import AbstractLLCPU
2from rpython.jit.backend.zarch import registers as r
3from rpython.jit.backend.zarch.assembler import AssemblerZARCH
4from rpython.jit.backend.zarch.codebuilder import InstrBuilder
5from rpython.jit.backend.zarch import vector_ext
6from rpython.rlib import rgc
7from rpython.rtyper.lltypesystem import lltype, llmemory
8
9class AbstractZARCHCPU(AbstractLLCPU):
10    def __init__(self, rtyper, stats, opts=None, translate_support_code=False,
11                 gcdescr=None):
12        AbstractLLCPU.__init__(self, rtyper, stats, opts,
13                               translate_support_code, gcdescr)
14
15class CPU_S390_64(AbstractZARCHCPU):
16    dont_keepalive_stuff = True
17    supports_floats = True
18    from rpython.jit.backend.zarch.registers import JITFRAME_FIXED_SIZE
19
20    vector_ext = vector_ext.ZSIMDVectorExt()
21
22    backend_name = 'zarch'
23
24    IS_64_BIT = True
25
26    frame_reg = r.SP
27    all_reg_indexes = [-1] * 32
28    for _i, _r in enumerate(r.MANAGED_REGS):
29        all_reg_indexes[_r.value] = _i
30    gen_regs = r.MANAGED_REGS
31    float_regs = r.MANAGED_FP_REGS
32
33    load_supported_factors = (1,)
34
35    def setup(self):
36        self.assembler = AssemblerZARCH(self)
37
38    @rgc.no_release_gil
39    def setup_once(self):
40        self.assembler.setup_once()
41
42    @rgc.no_release_gil
43    def finish_once(self):
44        self.assembler.finish_once()
45
46    def compile_bridge(self, faildescr, inputargs, operations,
47                       original_loop_token, log=True, logger=None):
48        clt = original_loop_token.compiled_loop_token
49        clt.compiling_a_bridge()
50        return self.assembler.assemble_bridge(faildescr, inputargs, operations,
51                                              original_loop_token, log, logger)
52
53    def invalidate_loop(self, looptoken):
54        """"""Activate all GUARD_NOT_INVALIDATED in the loop and its attached
55        bridges.  Before this call, all GUARD_NOT_INVALIDATED do nothing;
56        after this call, they all fail.  Note that afterwards, if one such
57        guard fails often enough, it has a bridge attached to it; it is
58        possible then to re-call invalidate_loop() on the same looptoken,
59        which must invalidate all newer GUARD_NOT_INVALIDATED, but not the
60        old one that already has a bridge attached to it.""""""
61
62        for jmp, tgt in looptoken.compiled_loop_token.invalidate_positions:
63            mc = InstrBuilder()
64            # needs 4 bytes, ensured by the previous process
65            mc.b_offset(tgt)     # a single instruction
66            mc.copy_to_raw_memory(jmp)
67        # positions invalidated
68        looptoken.compiled_loop_token.invalidate_positions = []
69
70    def redirect_call_assembler(self, oldlooptoken, newlooptoken):
71        self.assembler.redirect_call_assembler(oldlooptoken, newlooptoken)
72
73    def cast_ptr_to_int(x):
74        adr = llmemory.cast_ptr_to_adr(x)
75        return CPU_S390_64.cast_adr_to_int(adr)
76    cast_ptr_to_int._annspecialcase_ = 'specialize:arglltype(0)'
77    cast_ptr_to_int = staticmethod(cast_ptr_to_int)
78
79    def build_regalloc(self):
80        ''' NOT_RPYTHON: for tests '''
81        from rpython.jit.backend.zarch.regalloc import Regalloc
82        return Regalloc(self.assembler)
83",5267,"[[10, 'rtyper', '!=', None, 'rtyper should not be None during initialization'],
 [10, 'stats', '!=', None, 'stats should not be None during initialization'],
 [16, 'dont_keepalive_stuff', '==', True, 'dont_keepalive_stuff should always be true'],
 [17, 'supports_floats', '==', True, 'supports_floats should always be true'],
 [27, 'all_reg_indexes', '==', 32, 'all_reg_indexes should always have 32 elements'],
 [46, 'faildescr', '!=', None, 'faildescr should not be None during compilation of the bridge'],
 [46, 'inputargs', '!=', None, 'inputargs should not be None during compilation of the bridge'],
 [46, 'operations', '!=', None, 'operations should not be None during compilation of the bridge'],
 [73, 'x', '!=', None, 'x should not be None during cast_ptr_to_int function'],
 [70, 'oldlooptoken', '!=', None, 'oldlooptoken should not be None during redirect_call_assembler function'],
 [70, 'newlooptoken', '!=', None, 'newlooptoken should not be None during redirect_call_assembler function'],
 [53, 'looptoken', '!=', None, 'looptoken should not be None during invalidate_loop function'],
 [10, 'opts', '!=', None, 'opts should not be None during initialization'],
 [24, 'IS_64_BIT', '==', True, 'IS_64_BIT should always be true']]"
benjaminsoellner/DAND_3_OSMDataWranglingMongoDB,"#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Please note that the function 'make_request' is provided for your reference only.
# You will not be able to to actually use it from within the Udacity web UI
# All your changes should be in the 'extract_data' function

from bs4 import BeautifulSoup
import requests
import json

html_page = ""page_source.html""


def extract_data(page):
    data = {""eventvalidation"": """",
            ""viewstate"": """"}
    with open(page, ""r"") as html:
        # do something here to find the necessary values
        soup = BeautifulSoup(html)
        data[""viewstate""] = soup.find_all(id=""__VIEWSTATE"")[0].get('value')
        data[""eventvalidation""] = soup.find_all(id=""__EVENTVALIDATION"")[0].get('value')
        pass

    return data


def make_request(data):
    eventvalidation = data[""eventvalidation""]
    viewstate = data[""viewstate""]

    r = requests.post(""http://www.transtats.bts.gov/Data_Elements.aspx?Data=2"",
                    data={'AirportList': ""BOS"",
                          'CarrierList': ""VX"",
                          'Submit': 'Submit',
                          ""__EVENTTARGET"": """",
                          ""__EVENTARGUMENT"": """",
                          ""__EVENTVALIDATION"": eventvalidation,
                          ""__VIEWSTATE"": viewstate
                    })

    return r.text


def test():
    data = extract_data(html_page)
    assert data[""eventvalidation""] != """"
    assert data[""eventvalidation""].startswith(""/wEWjAkCoIj1ng0"")
    assert data[""viewstate""].startswith(""/wEPDwUKLTI"")

    
test()","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3# Please note that the function 'make_request' is provided for your reference only.
4# You will not be able to to actually use it from within the Udacity web UI
5# All your changes should be in the 'extract_data' function
6
7from bs4 import BeautifulSoup
8import requests
9import json
10
11html_page = ""page_source.html""
12
13
14def extract_data(page):
15    data = {""eventvalidation"": """",
16            ""viewstate"": """"}
17    with open(page, ""r"") as html:
18        # do something here to find the necessary values
19        soup = BeautifulSoup(html)
20        data[""viewstate""] = soup.find_all(id=""__VIEWSTATE"")[0].get('value')
21        data[""eventvalidation""] = soup.find_all(id=""__EVENTVALIDATION"")[0].get('value')
22        pass
23
24    return data
25
26
27def make_request(data):
28    eventvalidation = data[""eventvalidation""]
29    viewstate = data[""viewstate""]
30
31    r = requests.post(""http://www.transtats.bts.gov/Data_Elements.aspx?Data=2"",
32                    data={'AirportList': ""BOS"",
33                          'CarrierList': ""VX"",
34                          'Submit': 'Submit',
35                          ""__EVENTTARGET"": """",
36                          ""__EVENTARGUMENT"": """",
37                          ""__EVENTVALIDATION"": eventvalidation,
38                          ""__VIEWSTATE"": viewstate
39                    })
40
41    return r.text
42
43
44def test():
45    data = extract_data(html_page)
46
47    
48test()","[['data[""eventvalidation""]', '!=', '""""'], ['data[""eventvalidation""].startswith(""/wEWjAkCoIj1ng0"")', '==', 'True'], ['data[""viewstate""].startswith(""/wEPDwUKLTI"")', '==', 'True']]",3,3,1.0,0.0019108280254777,"['html_page', 'page', 'data', 'soup', 'data[""viewstate""]', 'data[""eventvalidation""]', 'eventvalidation', 'viewstate', 'r']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['html_page', 'page', 'data', 'soup', 'data[""viewstate""]', 'data[""eventvalidation""]', 'eventvalidation', 'viewstate', 'r']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3# Please note that the function 'make_request' is provided for your reference only.
4# You will not be able to to actually use it from within the Udacity web UI
5# All your changes should be in the 'extract_data' function
6
7from bs4 import BeautifulSoup
8import requests
9import json
10
11html_page = ""page_source.html""
12
13
14def extract_data(page):
15    data = {""eventvalidation"": """",
16            ""viewstate"": """"}
17    with open(page, ""r"") as html:
18        # do something here to find the necessary values
19        soup = BeautifulSoup(html)
20        data[""viewstate""] = soup.find_all(id=""__VIEWSTATE"")[0].get('value')
21        data[""eventvalidation""] = soup.find_all(id=""__EVENTVALIDATION"")[0].get('value')
22        pass
23
24    return data
25
26
27def make_request(data):
28    eventvalidation = data[""eventvalidation""]
29    viewstate = data[""viewstate""]
30
31    r = requests.post(""http://www.transtats.bts.gov/Data_Elements.aspx?Data=2"",
32                    data={'AirportList': ""BOS"",
33                          'CarrierList': ""VX"",
34                          'Submit': 'Submit',
35                          ""__EVENTTARGET"": """",
36                          ""__EVENTARGUMENT"": """",
37                          ""__EVENTVALIDATION"": eventvalidation,
38                          ""__VIEWSTATE"": viewstate
39                    })
40
41    return r.text
42
43
44def test():
45    data = extract_data(html_page)
46
47    
48test()",2999,"[[14, 'page', '!=', '', 'page should not be an empty string'],
 [24, 'data[""viewstate""]', '!=', '', 'viewstate should not be empty after extraction'],
 [24, 'data[""eventvalidation""]', '!=', '', 'eventvalidation should not be empty after extraction'],
 [28, 'eventvalidation', '!=', '', 'eventvalidation received from data should not be empty'],
 [29, 'viewstate', '!=', '', 'viewstate received from data should not be empty'],
 [41, 'r.text', '!=', '', 'response text should not be empty']]"
smmribeiro/intellij-community,"# Copyright 2016-present Facebook. All Rights Reserved.
#
# support: fastannotate support for hgweb, and filectx
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.

from __future__ import absolute_import

from mercurial.pycompat import getattr
from mercurial import (
    context as hgcontext,
    dagop,
    extensions,
    hgweb,
    patch,
    util,
)

from . import (
    context,
    revmap,
)


class _lazyfctx(object):
    """"""delegates to fctx but do not construct fctx when unnecessary""""""

    def __init__(self, repo, node, path):
        self._node = node
        self._path = path
        self._repo = repo

    def node(self):
        return self._node

    def path(self):
        return self._path

    @util.propertycache
    def _fctx(self):
        return context.resolvefctx(self._repo, self._node, self._path)

    def __getattr__(self, name):
        return getattr(self._fctx, name)


def _convertoutputs(repo, annotated, contents):
    """"""convert fastannotate outputs to vanilla annotate format""""""
    # fastannotate returns: [(nodeid, linenum, path)], [linecontent]
    # convert to what fctx.annotate returns: [annotateline]
    results = []
    fctxmap = {}
    annotateline = dagop.annotateline
    for i, (hsh, linenum, path) in enumerate(annotated):
        if (hsh, path) not in fctxmap:
            fctxmap[(hsh, path)] = _lazyfctx(repo, hsh, path)
        # linenum: the user wants 1-based, we have 0-based.
        lineno = linenum + 1
        fctx = fctxmap[(hsh, path)]
        line = contents[i]
        results.append(annotateline(fctx=fctx, lineno=lineno, text=line))
    return results


def _getmaster(fctx):
    """"""(fctx) -> str""""""
    return fctx._repo.ui.config(b'fastannotate', b'mainbranch') or b'default'


def _doannotate(fctx, follow=True, diffopts=None):
    """"""like the vanilla fctx.annotate, but do it via fastannotate, and make
    the output format compatible with the vanilla fctx.annotate.
    may raise Exception, and always return line numbers.
    """"""
    master = _getmaster(fctx)

    with context.fctxannotatecontext(fctx, follow, diffopts) as ac:
        try:
            annotated, contents = ac.annotate(
                fctx.rev(), master=master, showpath=True, showlines=True
            )
        except Exception:
            ac.rebuild()  # try rebuild once
            fctx._repo.ui.debug(
                b'fastannotate: %s: rebuilding broken cache\n' % fctx._path
            )
            try:
                annotated, contents = ac.annotate(
                    fctx.rev(), master=master, showpath=True, showlines=True
                )
            except Exception:
                raise

    assert annotated and contents
    return _convertoutputs(fctx._repo, annotated, contents)


def _hgwebannotate(orig, fctx, ui):
    diffopts = patch.difffeatureopts(
        ui, untrusted=True, section=b'annotate', whitespace=True
    )
    return _doannotate(fctx, diffopts=diffopts)


def _fctxannotate(
    orig, self, follow=False, linenumber=False, skiprevs=None, diffopts=None
):
    if skiprevs:
        # skiprevs is not supported yet
        return orig(
            self, follow, linenumber, skiprevs=skiprevs, diffopts=diffopts
        )
    try:
        return _doannotate(self, follow, diffopts)
    except Exception as ex:
        self._repo.ui.debug(
            b'fastannotate: falling back to the vanilla annotate: %r\n' % ex
        )
        return orig(self, follow=follow, skiprevs=skiprevs, diffopts=diffopts)


def _remotefctxannotate(orig, self, follow=False, skiprevs=None, diffopts=None):
    # skipset: a set-like used to test if a fctx needs to be downloaded
    with context.fctxannotatecontext(self, follow, diffopts) as ac:
        skipset = revmap.revmap(ac.revmappath)
    return orig(
        self, follow, skiprevs=skiprevs, diffopts=diffopts, prefetchskip=skipset
    )


def replacehgwebannotate():
    extensions.wrapfunction(hgweb.webutil, b'annotate', _hgwebannotate)


def replacefctxannotate():
    extensions.wrapfunction(hgcontext.basefilectx, b'annotate', _fctxannotate)
","
1# Copyright 2016-present Facebook. All Rights Reserved.
2#
3# support: fastannotate support for hgweb, and filectx
4#
5# This software may be used and distributed according to the terms of the
6# GNU General Public License version 2 or any later version.
7
8from __future__ import absolute_import
9
10from mercurial.pycompat import getattr
11from mercurial import (
12    context as hgcontext,
13    dagop,
14    extensions,
15    hgweb,
16    patch,
17    util,
18)
19
20from . import (
21    context,
22    revmap,
23)
24
25
26class _lazyfctx(object):
27    """"""delegates to fctx but do not construct fctx when unnecessary""""""
28
29    def __init__(self, repo, node, path):
30        self._node = node
31        self._path = path
32        self._repo = repo
33
34    def node(self):
35        return self._node
36
37    def path(self):
38        return self._path
39
40    @util.propertycache
41    def _fctx(self):
42        return context.resolvefctx(self._repo, self._node, self._path)
43
44    def __getattr__(self, name):
45        return getattr(self._fctx, name)
46
47
48def _convertoutputs(repo, annotated, contents):
49    """"""convert fastannotate outputs to vanilla annotate format""""""
50    # fastannotate returns: [(nodeid, linenum, path)], [linecontent]
51    # convert to what fctx.annotate returns: [annotateline]
52    results = []
53    fctxmap = {}
54    annotateline = dagop.annotateline
55    for i, (hsh, linenum, path) in enumerate(annotated):
56        if (hsh, path) not in fctxmap:
57            fctxmap[(hsh, path)] = _lazyfctx(repo, hsh, path)
58        # linenum: the user wants 1-based, we have 0-based.
59        lineno = linenum + 1
60        fctx = fctxmap[(hsh, path)]
61        line = contents[i]
62        results.append(annotateline(fctx=fctx, lineno=lineno, text=line))
63    return results
64
65
66def _getmaster(fctx):
67    """"""(fctx) -> str""""""
68    return fctx._repo.ui.config(b'fastannotate', b'mainbranch') or b'default'
69
70
71def _doannotate(fctx, follow=True, diffopts=None):
72    """"""like the vanilla fctx.annotate, but do it via fastannotate, and make
73    the output format compatible with the vanilla fctx.annotate.
74    may raise Exception, and always return line numbers.
75    """"""
76    master = _getmaster(fctx)
77
78    with context.fctxannotatecontext(fctx, follow, diffopts) as ac:
79        try:
80            annotated, contents = ac.annotate(
81                fctx.rev(), master=master, showpath=True, showlines=True
82            )
83        except Exception:
84            ac.rebuild()  # try rebuild once
85            fctx._repo.ui.debug(
86                b'fastannotate: %s: rebuilding broken cache\n' % fctx._path
87            )
88            try:
89                annotated, contents = ac.annotate(
90                    fctx.rev(), master=master, showpath=True, showlines=True
91                )
92            except Exception:
93                raise
94
95    return _convertoutputs(fctx._repo, annotated, contents)
96
97
98def _hgwebannotate(orig, fctx, ui):
99    diffopts = patch.difffeatureopts(
100        ui, untrusted=True, section=b'annotate', whitespace=True
101    )
102    return _doannotate(fctx, diffopts=diffopts)
103
104
105def _fctxannotate(
106    orig, self, follow=False, linenumber=False, skiprevs=None, diffopts=None
107):
108    if skiprevs:
109        # skiprevs is not supported yet
110        return orig(
111            self, follow, linenumber, skiprevs=skiprevs, diffopts=diffopts
112        )
113    try:
114        return _doannotate(self, follow, diffopts)
115    except Exception as ex:
116        self._repo.ui.debug(
117            b'fastannotate: falling back to the vanilla annotate: %r\n' % ex
118        )
119        return orig(self, follow=follow, skiprevs=skiprevs, diffopts=diffopts)
120
121
122def _remotefctxannotate(orig, self, follow=False, skiprevs=None, diffopts=None):
123    # skipset: a set-like used to test if a fctx needs to be downloaded
124    with context.fctxannotatecontext(self, follow, diffopts) as ac:
125        skipset = revmap.revmap(ac.revmappath)
126    return orig(
127        self, follow, skiprevs=skiprevs, diffopts=diffopts, prefetchskip=skipset
128    )
129
130
131def replacehgwebannotate():
132    extensions.wrapfunction(hgweb.webutil, b'annotate', _hgwebannotate)
133
134
135def replacefctxannotate():
136    extensions.wrapfunction(hgcontext.basefilectx, b'annotate', _fctxannotate)
137","[['annotated', '==', 'True'], ['contents', '==', 'True']]",1,2,2.0,0.0004795013186286,"['repo', 'node', 'path', 'self._node', 'self._path', 'self._repo', 'name', 'annotated', 'contents', 'results', 'fctxmap', 'annotateline', 'fctxmap[(hsh', 'path)]', 'lineno', 'fctx', 'line', 'follow', 'diffopts', 'master', 'orig', 'ui', 'skiprevs', 'skipset']",24,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['repo', 'node', 'path', 'self._node', 'self._path', 'self._repo', 'name', 'annotated', 'contents', 'results', 'fctxmap', 'annotateline', 'fctxmap[(hsh', 'path)]', 'lineno', 'fctx', 'line', 'follow', 'diffopts', 'master', 'orig', 'ui', 'skiprevs', 'skipset']
*Code:

1# Copyright 2016-present Facebook. All Rights Reserved.
2#
3# support: fastannotate support for hgweb, and filectx
4#
5# This software may be used and distributed according to the terms of the
6# GNU General Public License version 2 or any later version.
7
8from __future__ import absolute_import
9
10from mercurial.pycompat import getattr
11from mercurial import (
12    context as hgcontext,
13    dagop,
14    extensions,
15    hgweb,
16    patch,
17    util,
18)
19
20from . import (
21    context,
22    revmap,
23)
24
25
26class _lazyfctx(object):
27    """"""delegates to fctx but do not construct fctx when unnecessary""""""
28
29    def __init__(self, repo, node, path):
30        self._node = node
31        self._path = path
32        self._repo = repo
33
34    def node(self):
35        return self._node
36
37    def path(self):
38        return self._path
39
40    @util.propertycache
41    def _fctx(self):
42        return context.resolvefctx(self._repo, self._node, self._path)
43
44    def __getattr__(self, name):
45        return getattr(self._fctx, name)
46
47
48def _convertoutputs(repo, annotated, contents):
49    """"""convert fastannotate outputs to vanilla annotate format""""""
50    # fastannotate returns: [(nodeid, linenum, path)], [linecontent]
51    # convert to what fctx.annotate returns: [annotateline]
52    results = []
53    fctxmap = {}
54    annotateline = dagop.annotateline
55    for i, (hsh, linenum, path) in enumerate(annotated):
56        if (hsh, path) not in fctxmap:
57            fctxmap[(hsh, path)] = _lazyfctx(repo, hsh, path)
58        # linenum: the user wants 1-based, we have 0-based.
59        lineno = linenum + 1
60        fctx = fctxmap[(hsh, path)]
61        line = contents[i]
62        results.append(annotateline(fctx=fctx, lineno=lineno, text=line))
63    return results
64
65
66def _getmaster(fctx):
67    """"""(fctx) -> str""""""
68    return fctx._repo.ui.config(b'fastannotate', b'mainbranch') or b'default'
69
70
71def _doannotate(fctx, follow=True, diffopts=None):
72    """"""like the vanilla fctx.annotate, but do it via fastannotate, and make
73    the output format compatible with the vanilla fctx.annotate.
74    may raise Exception, and always return line numbers.
75    """"""
76    master = _getmaster(fctx)
77
78    with context.fctxannotatecontext(fctx, follow, diffopts) as ac:
79        try:
80            annotated, contents = ac.annotate(
81                fctx.rev(), master=master, showpath=True, showlines=True
82            )
83        except Exception:
84            ac.rebuild()  # try rebuild once
85            fctx._repo.ui.debug(
86                b'fastannotate: %s: rebuilding broken cache\n' % fctx._path
87            )
88            try:
89                annotated, contents = ac.annotate(
90                    fctx.rev(), master=master, showpath=True, showlines=True
91                )
92            except Exception:
93                raise
94
95    return _convertoutputs(fctx._repo, annotated, contents)
96
97
98def _hgwebannotate(orig, fctx, ui):
99    diffopts = patch.difffeatureopts(
100        ui, untrusted=True, section=b'annotate', whitespace=True
101    )
102    return _doannotate(fctx, diffopts=diffopts)
103
104
105def _fctxannotate(
106    orig, self, follow=False, linenumber=False, skiprevs=None, diffopts=None
107):
108    if skiprevs:
109        # skiprevs is not supported yet
110        return orig(
111            self, follow, linenumber, skiprevs=skiprevs, diffopts=diffopts
112        )
113    try:
114        return _doannotate(self, follow, diffopts)
115    except Exception as ex:
116        self._repo.ui.debug(
117            b'fastannotate: falling back to the vanilla annotate: %r\n' % ex
118        )
119        return orig(self, follow=follow, skiprevs=skiprevs, diffopts=diffopts)
120
121
122def _remotefctxannotate(orig, self, follow=False, skiprevs=None, diffopts=None):
123    # skipset: a set-like used to test if a fctx needs to be downloaded
124    with context.fctxannotatecontext(self, follow, diffopts) as ac:
125        skipset = revmap.revmap(ac.revmappath)
126    return orig(
127        self, follow, skiprevs=skiprevs, diffopts=diffopts, prefetchskip=skipset
128    )
129
130
131def replacehgwebannotate():
132    extensions.wrapfunction(hgweb.webutil, b'annotate', _hgwebannotate)
133
134
135def replacefctxannotate():
136    extensions.wrapfunction(hgcontext.basefilectx, b'annotate', _fctxannotate)
137",6079,"[[29, 'repo', '!=', None, ""Functions can't be called on None""],
[29, 'node', '!=', None, ""Functions can't be called on None""],
[29, 'path', '!=', None, ""Functions can't be called on None""],
[48, 'repo', '!=', None, ""Functions can't be called on None""],
[48, 'annotated', '!=', None, ""Functions can't be called on None""],
[48, 'contents', '!=', None, ""Functions can't be called on None""],
[66, 'fctx', '!=', None, ""Functions can't be called on None""],
[71, 'fctx', '!=', None, ""Functions can't be called on None""],
[71, 'follow', '!=', None, ""Functions can't be called on None""],
[71, 'diffopts', '!=', None, ""Functions can't be called on None""],
[98, 'orig', '!=', None, ""Functions can't be called on None""],
[98, 'fctx', '!=', None, ""Functions can't be called on None""],
[98, 'ui', '!=', None, ""Functions can't be called on None""],
[105, 'orig', '!=', None, ""Functions can't be called on None""],
[105, 'self', '!=', None, ""Functions can't be called on None""],
[105, 'follow', '!=', None, ""Functions can't be called on None""],
[105, 'linenumber', '!=', None, ""Functions can't be called on None""],
[105, 'skiprevs', '!=', None, ""Functions can't be called on None""],
[105, 'diffopts', '!=', None, ""Functions can't be called on None""],
[122, 'orig', '!=', None, ""Functions can't be called on None""],
[122, 'self', '!=', None, ""Functions can't be called on None""],
[122, 'follow', '!=', None, ""Functions can't be called on None""],
[122, 'skiprevs', '!=', None, ""Functions can't be called on None""],
[122, 'diffopts', '!=', None, ""Functions can't be called on None""]]"
GbalsaC/bitnamiP,"from sympy import symbols, oo
from sympy.core.relational import Relational, Equality, StrictInequality, \
    Rel, Eq, Lt, Le, Gt, Ge, Ne

x,y,z = symbols('x,y,z')


def test_rel_ne():
    Relational(x, y, '!=')  # this used to raise


def test_rel_subs():
    e = Relational(x, y, '==')
    e = e.subs(x,z)

    assert isinstance(e, Equality)
    assert e.lhs == z
    assert e.rhs == y

    e = Relational(x, y, '<')
    e = e.subs(x,z)

    assert isinstance(e, StrictInequality)
    assert e.lhs == z
    assert e.rhs == y

    e = Eq(x,0)
    assert e.subs(x,0) == True
    assert e.subs(x,1) == False


def test_wrappers():
    e = x+x**2

    res = Relational(y, e, '==')
    assert Rel(y, x+x**2, '==') == res
    assert Eq(y, x+x**2) == res

    res = Relational(y, e, '<')
    assert Lt(y, x+x**2) == res

    res = Relational(y, e, '<=')
    assert Le(y, x+x**2) == res

    res = Relational(y, e, '>')
    assert Gt(y, x+x**2) == res

    res = Relational(y, e, '>=')
    assert Ge(y, x+x**2) == res

    res = Relational(y, e, '!=')
    assert Ne(y, x+x**2) == res

def test_Eq():

    assert Eq(x**2) == Eq(x**2, 0)
    assert Eq(x**2) != Eq(x**2, 1)

def test_rel_Infinity():
    assert (oo > oo) is False
    assert (oo > -oo) is True
    assert (oo > 1) is True
    assert (oo < oo) is False
    assert (oo < -oo) is False
    assert (oo < 1) is False
    assert (oo >= oo) is True
    assert (oo >= -oo) is True
    assert (oo >= 1) is True
    assert (oo <= oo) is True
    assert (oo <= -oo) is False
    assert (oo <= 1) is False
    assert (-oo > oo) is False
    assert (-oo > -oo) is False
    assert (-oo > 1) is False
    assert (-oo < oo) is True
    assert (-oo < -oo) is False
    assert (-oo < 1) is True
    assert (-oo >= oo) is False
    assert (-oo >= -oo) is True
    assert (-oo >= 1) is False
    assert (-oo <= oo) is True
    assert (-oo <= -oo) is True
    assert (-oo <= 1) is True

def test_bool():
    assert Eq(0,0) is True
    assert Eq(1,0) is False
    assert Ne(0,0) is False
    assert Ne(1,0) is True
    assert Lt(0,1) is True
    assert Lt(1,0) is False
    assert Le(0,1) is True
    assert Le(1,0) is False
    assert Le(0,0) is True
    assert Gt(1,0) is True
    assert Gt(0,1) is False
    assert Ge(1,0) is True
    assert Ge(0,1) is False
    assert Ge(1,1) is True

def test_rich_cmp():
    assert (x<y) == Lt(x,y)
    assert (x<=y) == Le(x,y)
    assert (x>y) == Gt(x,y)
    assert (x>=y) == Ge(x,y)

","
1from sympy import symbols, oo
2from sympy.core.relational import Relational, Equality, StrictInequality, \
3    Rel, Eq, Lt, Le, Gt, Ge, Ne
4
5x,y,z = symbols('x,y,z')
6
7
8def test_rel_ne():
9    Relational(x, y, '!=')  # this used to raise
10
11
12def test_rel_subs():
13    e = Relational(x, y, '==')
14    e = e.subs(x,z)
15
16
17    e = Relational(x, y, '<')
18    e = e.subs(x,z)
19
20
21    e = Eq(x,0)
22
23
24def test_wrappers():
25    e = x+x**2
26
27    res = Relational(y, e, '==')
28
29    res = Relational(y, e, '<')
30
31    res = Relational(y, e, '<=')
32
33    res = Relational(y, e, '>')
34
35    res = Relational(y, e, '>=')
36
37    res = Relational(y, e, '!=')
38
39def test_Eq():
40
41
42def test_rel_Infinity():
43
44def test_bool():
45
46def test_rich_cmp():
47
48","[['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.subs(x', '==', 'True'], ['e.subs(x', '==', 'True'], ['Rel(y', '==', 'True'], ['Eq(y', '==', 'True'], ['Lt(y', '==', 'True'], ['Le(y', '==', 'True'], ['Gt(y', '==', 'True'], ['Ge(y', '==', 'True'], ['Ne(y', '==', 'True'], ['Eq(x**2)', '==', 'Eq(x**2'], ['Eq(x**2)', '!=', 'Eq(x**2'], ['(oo', '>', 'oo) is False'], ['(oo', '>', '-oo) is True'], ['(oo', '>', '1) is True'], ['(oo', '<', 'oo) is False'], ['(oo', '<', '-oo) is False'], ['(oo', '<', '1) is False'], ['(oo', '>=', 'oo) is True'], ['(oo', '>=', '-oo) is True'], ['(oo', '>=', '1) is True'], ['(oo', '<=', 'oo) is True'], ['(oo', '<=', '-oo) is False'], ['(oo', '<=', '1) is False'], ['(-oo', '>', 'oo) is False'], ['(-oo', '>', '-oo) is False'], ['(-oo', '>', '1) is False'], ['(-oo', '<', 'oo) is True'], ['(-oo', '<', '-oo) is False'], ['(-oo', '<', '1) is True'], ['(-oo', '>=', 'oo) is False'], ['(-oo', '>=', '-oo) is True'], ['(-oo', '>=', '1) is False'], ['(-oo', '<=', 'oo) is True'], ['(-oo', '<=', '-oo) is True'], ['(-oo', '<=', '1) is True'], ['Eq(0', '==', 'True'], ['Eq(1', '==', 'True'], ['Ne(0', '==', 'True'], ['Ne(1', '==', 'True'], ['Lt(0', '==', 'True'], ['Lt(1', '==', 'True'], ['Le(0', '==', 'True'], ['Le(1', '==', 'True'], ['Le(0', '==', 'True'], ['Gt(1', '==', 'True'], ['Gt(0', '==', 'True'], ['Ge(1', '==', 'True'], ['Ge(0', '==', 'True'], ['Ge(1', '==', 'True'], ['(x<y)', '==', 'Lt(x'], ['(x<=y)', '==', 'Le(x'], ['(x>y)', '==', 'Gt(x'], ['(x>=y)', '==', 'Ge(x']]",59,57,0.9661016949152542,0.0231519090170593,"['x', 'y', 'z', 'e', 'res']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'y', 'z', 'e', 'res']
*Code:

1from sympy import symbols, oo
2from sympy.core.relational import Relational, Equality, StrictInequality, \
3    Rel, Eq, Lt, Le, Gt, Ge, Ne
4
5x,y,z = symbols('x,y,z')
6
7
8def test_rel_ne():
9    Relational(x, y, '!=')  # this used to raise
10
11
12def test_rel_subs():
13    e = Relational(x, y, '==')
14    e = e.subs(x,z)
15
16
17    e = Relational(x, y, '<')
18    e = e.subs(x,z)
19
20
21    e = Eq(x,0)
22
23
24def test_wrappers():
25    e = x+x**2
26
27    res = Relational(y, e, '==')
28
29    res = Relational(y, e, '<')
30
31    res = Relational(y, e, '<=')
32
33    res = Relational(y, e, '>')
34
35    res = Relational(y, e, '>=')
36
37    res = Relational(y, e, '!=')
38
39def test_Eq():
40
41
42def test_rel_Infinity():
43
44def test_bool():
45
46def test_rich_cmp():
47
48",2197,"[[8, 'x', '!=', 'y', ""function 'test_rel_ne' expect x not equal to y""],
 [8, 'y', '!=', 'x', ""function 'test_rel_ne' expect y not equal to x""],
 [13, 'x', '!=', 'y', ""in function 'test_rel_subs', initial equality Relational checks x not equals to y""],
 [14, 'z', '!=', 'y', ""in function 'test_rel_subs', after substitution, z should not be equal to y""],
 [17, 'x', '<', 'y', ""in function 'test_rel_subs', initial less than Relational checks x less than y""],
 [18, 'z', '<', 'y', ""in function 'test_rel_subs', after substitution, z should be less than y""],
 [21, 'x', '==', 0, ""in function 'test_rel_subs', checks x equal to 0""],
 [27, 'y', '==', 'e', ""in function 'test_wrappers', checks y equal to e""],
 [29, 'y', '<', 'e', ""in function 'test_wrappers', checks y is less than e""],
 [31, 'y', '<=', 'e', ""in function 'test_wrappers', checks y is less or equal e""],
 [33, 'y', '>', 'e', ""in function 'test_wrappers', checks y greater than e""],
 [35, 'y', '>=', 'e', ""in function 'test_wrappers', checks y is greater or equal to e""],
 [37, 'y', '!=', 'e', ""in function 'test_wrappers', checks y is not equal to e""]]"
dennisss/sympy,"""""""Test ideals.py code.""""""

from sympy.polys import QQ, lex, ilex
from sympy.abc import x, y, z
from sympy.utilities.pytest import raises


def test_ideal_operations():
    R = QQ.old_poly_ring(x, y)
    I = R.ideal(x)
    J = R.ideal(y)
    S = R.ideal(x*y)
    T = R.ideal(x, y)

    assert not (I == J)
    assert I == I

    assert I.union(J) == T
    assert I + J == T
    assert I + T == T

    assert not I.subset(T)
    assert T.subset(I)

    assert I.product(J) == S
    assert I*J == S
    assert x*J == S
    assert I*y == S
    assert R.convert(x)*J == S
    assert I*R.convert(y) == S

    assert not I.is_zero()
    assert not J.is_whole_ring()

    assert R.ideal(x**2 + 1, x).is_whole_ring()
    assert R.ideal() == R.ideal(0)
    assert R.ideal().is_zero()

    assert T.contains(x*y)
    assert T.subset([x, y])

    assert T.in_terms_of_generators(x) == [R(1), R(0)]

    assert T**0 == R.ideal(1)
    assert T**1 == T
    assert T**2 == R.ideal(x**2, y**2, x*y)
    assert I**5 == R.ideal(x**5)


def test_exceptions():
    I = QQ.old_poly_ring(x).ideal(x)
    J = QQ.old_poly_ring(y).ideal(1)
    raises(ValueError, lambda: I.union(x))
    raises(ValueError, lambda: I + J)
    raises(ValueError, lambda: I * J)
    raises(ValueError, lambda: I.union(J))
    assert (I == J) is False
    assert I != J


def test_nontriv_global():
    R = QQ.old_poly_ring(x, y, z)

    def contains(I, f):
        return R.ideal(*I).contains(f)

    assert contains([x, y], x)
    assert contains([x, y], x + y)
    assert not contains([x, y], 1)
    assert not contains([x, y], z)
    assert contains([x**2 + y, x**2 + x], x - y)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x**2)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**3)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**4)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x*y**2)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x**4 + y**3 + 2*z*y*x)
    assert contains([x + y + z, x*y + x*z + y*z, x*y*z], x*y*z)
    assert contains([x, 1 + x + y, 5 - 7*y], 1)
    assert contains(
        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
        x**3)
    assert not contains(
        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
        x**2 + y**2)

    # compare local order
    assert not contains([x*(1 + x + y), y*(1 + z)], x)
    assert not contains([x*(1 + x + y), y*(1 + z)], x + y)


def test_nontriv_local():
    R = QQ.old_poly_ring(x, y, z, order=ilex)

    def contains(I, f):
        return R.ideal(*I).contains(f)

    assert contains([x, y], x)
    assert contains([x, y], x + y)
    assert not contains([x, y], 1)
    assert not contains([x, y], z)
    assert contains([x**2 + y, x**2 + x], x - y)
    assert not contains([x + y + z, x*y + x*z + y*z, x*y*z], x**2)
    assert contains([x*(1 + x + y), y*(1 + z)], x)
    assert contains([x*(1 + x + y), y*(1 + z)], x + y)


def test_intersection():
    R = QQ.old_poly_ring(x, y, z)
    # SCA, example 1.8.11
    assert R.ideal(x, y).intersect(R.ideal(y**2, z)) == R.ideal(y**2, y*z, x*z)

    assert R.ideal(x, y).intersect(R.ideal()).is_zero()

    R = QQ.old_poly_ring(x, y, z, order=""ilex"")
    assert R.ideal(x, y).intersect(R.ideal(y**2 + y**2*z, z + z*x**3*y)) == \
        R.ideal(y**2, y*z, x*z)


def test_quotient():
    # SCA, example 1.8.13
    R = QQ.old_poly_ring(x, y, z)
    assert R.ideal(x, y).quotient(R.ideal(y**2, z)) == R.ideal(x, y)


def test_reduction():
    from sympy.polys.distributedmodules import sdm_nf_buchberger_reduced
    R = QQ.old_poly_ring(x, y)
    I = R.ideal(x**5, y)
    e = R.convert(x**3 + y**2)
    assert I.reduce_element(e) == e
    assert I.reduce_element(e, NF=sdm_nf_buchberger_reduced) == R.convert(x**3)
","
1""""""Test ideals.py code.""""""
2
3from sympy.polys import QQ, lex, ilex
4from sympy.abc import x, y, z
5from sympy.utilities.pytest import raises
6
7
8def test_ideal_operations():
9    R = QQ.old_poly_ring(x, y)
10    I = R.ideal(x)
11    J = R.ideal(y)
12    S = R.ideal(x*y)
13    T = R.ideal(x, y)
14
15
16
17
18
19
20
21
22
23
24
25def test_exceptions():
26    I = QQ.old_poly_ring(x).ideal(x)
27    J = QQ.old_poly_ring(y).ideal(1)
28    raises(ValueError, lambda: I.union(x))
29    raises(ValueError, lambda: I + J)
30    raises(ValueError, lambda: I * J)
31    raises(ValueError, lambda: I.union(J))
32
33
34def test_nontriv_global():
35    R = QQ.old_poly_ring(x, y, z)
36
37    def contains(I, f):
38        return R.ideal(*I).contains(f)
39
40        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
41        x**3)
42        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
43        x**2 + y**2)
44
45    # compare local order
46
47
48def test_nontriv_local():
49    R = QQ.old_poly_ring(x, y, z, order=ilex)
50
51    def contains(I, f):
52        return R.ideal(*I).contains(f)
53
54
55
56def test_intersection():
57    R = QQ.old_poly_ring(x, y, z)
58    # SCA, example 1.8.11
59
60
61    R = QQ.old_poly_ring(x, y, z, order=""ilex"")
62        R.ideal(y**2, y*z, x*z)
63
64
65def test_quotient():
66    # SCA, example 1.8.13
67    R = QQ.old_poly_ring(x, y, z)
68
69
70def test_reduction():
71    from sympy.polys.distributedmodules import sdm_nf_buchberger_reduced
72    R = QQ.old_poly_ring(x, y)
73    I = R.ideal(x**5, y)
74    e = R.convert(x**3 + y**2)
75","[['(I', '==', 'J)'], ['I', '==', 'I'], ['I.union(J)', '==', 'T'], ['I + J', '==', 'T'], ['I + T', '==', 'T'], ['I.subset(T)', '==', 'False'], ['T.subset(I)', '==', 'True'], ['I.product(J)', '==', 'S'], ['I*J', '==', 'S'], ['x*J', '==', 'S'], ['I*y', '==', 'S'], ['R.convert(x)*J', '==', 'S'], ['I*R.convert(y)', '==', 'S'], ['I.is_zero()', '==', 'False'], ['J.is_whole_ring()', '==', 'False'], ['R.ideal(x**2', '+', '1'], ['R.ideal()', '==', 'R.ideal(0)'], ['R.ideal().is_zero()', '==', 'True'], ['T.contains(x*y)', '==', 'True'], ['T.subset([x', '==', 'True'], ['T.in_terms_of_generators(x)', '==', '[R(1)'], ['T**0', '==', 'R.ideal(1)'], ['T**1', '==', 'T'], ['T**2', '==', 'R.ideal(x**2'], ['I**5', '==', 'R.ideal(x**5)'], ['(I', '==', 'J) is False'], ['I', '!=', 'J'], ['contains([x', '==', 'True'], ['contains([x', '==', 'True'], ['contains([x', '==', 'False'], ['contains([x', '==', 'False'], ['contains([x**2', '+', 'y'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x', '==', 'True'], ['contains(', '==', 'True'], ['contains(', '==', 'False'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x', '==', 'True'], ['contains([x', '==', 'True'], ['contains([x', '==', 'False'], ['contains([x', '==', 'False'], ['contains([x**2', '+', 'y'], ['contains([x', '+', 'y', '+', 'z'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['contains([x*(1', '+', 'x', '+', 'y)'], ['R.ideal(x', '==', 'True'], ['R.ideal(x', '==', 'True'], ['R.ideal(x', '==', 'True'], ['R.ideal(x', '==', 'True'], ['I.reduce_element(e)', '==', 'e'], ['I.reduce_element(e', '==', 'True']]",57,57,1.0,0.0150197628458498,"['R', 'I', 'J', 'S', 'T', 'f', 'e']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['R', 'I', 'J', 'S', 'T', 'f', 'e']
*Code:

1""""""Test ideals.py code.""""""
2
3from sympy.polys import QQ, lex, ilex
4from sympy.abc import x, y, z
5from sympy.utilities.pytest import raises
6
7
8def test_ideal_operations():
9    R = QQ.old_poly_ring(x, y)
10    I = R.ideal(x)
11    J = R.ideal(y)
12    S = R.ideal(x*y)
13    T = R.ideal(x, y)
14
15
16
17
18
19
20
21
22
23
24
25def test_exceptions():
26    I = QQ.old_poly_ring(x).ideal(x)
27    J = QQ.old_poly_ring(y).ideal(1)
28    raises(ValueError, lambda: I.union(x))
29    raises(ValueError, lambda: I + J)
30    raises(ValueError, lambda: I * J)
31    raises(ValueError, lambda: I.union(J))
32
33
34def test_nontriv_global():
35    R = QQ.old_poly_ring(x, y, z)
36
37    def contains(I, f):
38        return R.ideal(*I).contains(f)
39
40        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
41        x**3)
42        [x**3 + y**3, y**3 + z**3, z**3 + x**3, x**2*y + x**2*z + y**2*z],
43        x**2 + y**2)
44
45    # compare local order
46
47
48def test_nontriv_local():
49    R = QQ.old_poly_ring(x, y, z, order=ilex)
50
51    def contains(I, f):
52        return R.ideal(*I).contains(f)
53
54
55
56def test_intersection():
57    R = QQ.old_poly_ring(x, y, z)
58    # SCA, example 1.8.11
59
60
61    R = QQ.old_poly_ring(x, y, z, order=""ilex"")
62        R.ideal(y**2, y*z, x*z)
63
64
65def test_quotient():
66    # SCA, example 1.8.13
67    R = QQ.old_poly_ring(x, y, z)
68
69
70def test_reduction():
71    from sympy.polys.distributedmodules import sdm_nf_buchberger_reduced
72    R = QQ.old_poly_ring(x, y)
73    I = R.ideal(x**5, y)
74    e = R.convert(x**3 + y**2)
75",3023,"[[9, 'R', '!=', None, ""R should be initialized and not None""],
 [10, 'I', '!=', None, ""I should be initialized and not None""],
 [11, 'J', '!=', None, ""J should be initialized and not None""],
 [12, 'S', '!=', None, ""S should be initialized and not None""],
 [13, 'T', '!=', None, ""T should be initialized and not None""],
 [26, 'I', '!=', None, ""I should be initialized and not None""],
 [27, 'J', '!=', None, ""J should be initialized and not None""],
 [35, 'R', '!=', None, ""R should be initialized and not None""],
 [49, 'R', '!=', None, ""R should be initialized and not None""],
 [57, 'R', '!=', None, ""R should be initialized and not None""],
 [61, 'R', '!=', None, ""R should be initialized and not None""],
 [67, 'R', '!=', None, ""R should be initialized and not None""],
 [72, 'R', '!=', None, ""R should be initialized and not None""],
 [73, 'I', '!=', None, ""I should be initialized and not None""],
 [74, 'e', '!=', None, ""e should be initialized and not None""]]"
