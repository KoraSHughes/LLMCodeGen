{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File to paginate and convert textbook images into the proper format\n",
    "> Note: This file doesnt actually work on my machine due to some unresolved poppler pdf2image issues - this is just an imported representation of what is done in a similar google colab pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /Users/korahughes/opt/anaconda3/lib/python3.9/site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in /Users/korahughes/opt/anaconda3/lib/python3.9/site-packages (from pdf2image) (9.0.1)\n",
      "Requirement already satisfied: poppler-utils in /Users/korahughes/opt/anaconda3/lib/python3.9/site-packages (0.1.0)\n",
      "Requirement already satisfied: Click>=7.0 in /Users/korahughes/opt/anaconda3/lib/python3.9/site-packages (from poppler-utils) (8.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image\n",
    "!pip install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StuartSutherland-The Verilog PLI Handbook.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# find directory of textbooks in drive\n",
    "loc = \"full-book-images/\"  # input(\"File Directory?:\\n\")\n",
    "textbooks = [file for file in os.listdir(loc) if '.pdf' in file]\n",
    "print(textbooks)\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# # find directory of textbooks in drive\n",
    "# loc = \"/content/drive/MyDrive/gpt_pipeline/textbooks/\"\n",
    "# textbooks = [file for file in os.listdir(loc) if '.pdf' in file]\n",
    "# print(\"Found\", len(textbooks), \"books:\")\n",
    "# print(textbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdf2image/pdf2image.py:581\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    580\u001b[0m     env[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m poppler_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 581\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pdfinfo'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# run results on found textbooks\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m textbooks:\n\u001b[0;32m---> 18\u001b[0m   \u001b[43mpaginate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbook\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mpaginate\u001b[0;34m(dir, name, batch, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpaginate\u001b[39m(\u001b[38;5;28mdir\u001b[39m, name, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;66;03m# Note: convert_from_path is too much ram for all pages at once\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m   info \u001b[38;5;241m=\u001b[39m \u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserpw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   maxPages \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m#info[\"Pages\"]  # get num pages\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m page_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, maxPages\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, batch): \u001b[38;5;66;03m# load pages by batch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdf2image/pdf2image.py:607\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n",
      "\u001b[0;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "from pdf2image import pdfinfo_from_path, convert_from_path\n",
    "\n",
    "save_dir = \"paginated/\"\n",
    "def paginate(dir, name, batch=10, verbose=True):\n",
    "  # Note: convert_from_path is too much ram for all pages at once\n",
    "  info = pdfinfo_from_path(dir, userpw=None, poppler_path=None)\n",
    "  maxPages = 20 #info[\"Pages\"]  # get num pages\n",
    "  for page_num in range(1, maxPages+1, batch): # load pages by batch\n",
    "    pages = convert_from_path(dir, dpi=200, first_page=page_num, \n",
    "                              last_page=min(page_num+batch-1,maxPages))\n",
    "    for count, page in enumerate(pages):  # paginate\n",
    "        saved_at = f'{save_dir}{name}_p{page_num+count}.jpg'\n",
    "        # page.save(saved_at, 'JPEG')  # convert to jpeg\n",
    "        if verbose: print(\"saved at\", saved_at)\n",
    "\n",
    "# run results on found textbooks\n",
    "for book in textbooks:\n",
    "  paginate(loc+book, book[:-4], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! imports\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "# ! main gpt-interacting functions\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"\",  # !!!!\n",
    ")\n",
    "\n",
    "def run_gpt(this_messages, this_model=\"gpt-3.5-turbo\"):\n",
    "    chat_completion = client.chat.completions.create(messages=this_messages,\n",
    "                                                     model=this_model)\n",
    "    return chat_completion\n",
    "\n",
    "def gpt_oneshot(input_prompt, directive=\"You are a helpful assistant.\", verbose=False):\n",
    "    message_hist = [{\"role\": \"system\", \"content\": directive},  # add directed\n",
    "                    {\"role\": \"user\", \"content\": input_prompt}]  # init\n",
    "    response = run_gpt(message_hist)[\"choices\"][0][\"message\"][\"content\"]\n",
    "    if verbose:\n",
    "        print(\"chat_gpt: \", response, '\\n')\n",
    "#     message_hist.append({\"role\": \"system\", \"content\": response})\n",
    "    return response\n",
    "    \n",
    "def gpt_image_oneshot(image_link, new_prompt=\"This image contains some information about Verilog. Please respond with a question\\\n",
    "                                            for which the answer is the code snippet on this page.\",\n",
    "                        verbose=False):\n",
    "    # \"This image contains a block of Verilog code and text relating to it. \"+...\n",
    "    new_content = [{\"type\": \"text\", \"text\": new_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_link}}]  # \"I am the owner/maker of this image\", \"I am an ML researcher\"\n",
    "    message_hist = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that gives information on images of code.\"},\n",
    "                    {\"role\": \"user\", \"content\": new_content}]  # init\n",
    "    if verbose:\n",
    "        print(\"Asked:\", new_content[0][\"text\"])\n",
    "#         print(\"With Image:\", new_content[1][\"image_url\"][\"url\"])\n",
    "    response = run_gpt(message_hist, \"gpt-4-vision-preview\").choices[0].message.content\n",
    "    if verbose: print(\"\\nResponded With:\", response)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "# helpers\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def get_code(text):\n",
    "    if text is None or len(text) == 0:\n",
    "        return []\n",
    "    this_code = []\n",
    "    for i, code_chunk in enumerate(text.split('```')):  # pieces of code are denoted by ``` so we split\n",
    "        if i%2 == 1:  # every other chunk is a piece of code in this case\n",
    "            this_code.append(code_chunk[7:])  # Note: code declarations also have 'python\\n' denoting the language, since we dont need this, we omit the first 7 chars\n",
    "    return this_code\n",
    "\n",
    "indicators = [\"```\"]\n",
    "def has_code(message):\n",
    "    message = message.strip()\n",
    "    if bad_message in message:\n",
    "        return False  # instant signal\n",
    "    for ind in indicators:\n",
    "        if ind in message:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# ! main prompting function\n",
    "prompt_precursor = \"This image contains some information about Verilog. \"\n",
    "bad_message = \"NO CODE\"\n",
    "ask_code = prompt_precursor+\"If there is some code on this page then please write it. Otherwise say \\\"\"+bad_message+\"\\\"\"\n",
    "# supervised addition\n",
    "ask_caption = \"This image contains some Verilog code on it. Please give a short caption to describe this code.\"\n",
    "# additional queries\n",
    "ask_question = \"This image contains some Verilog code on it. Please respond with a question for which the answer is the code snippet on this page.\"\n",
    "\n",
    "def extract_code(image_path, atmps=3, verbose=False):\n",
    "    \"\"\" takes in the link of a local image and gets information about code on it \"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "    image_link = f\"data:image/jpeg;base64,{base64_image}\"\n",
    "    \n",
    "    attempts = 0\n",
    "    raw_code = \"\"  # get gpt to extract code\n",
    "    while raw_code == \"\" and attempts < atmps:\n",
    "        try:\n",
    "            raw_code = gpt_image_oneshot(image_link, ask_code)\n",
    "            attempts = atmps\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            if verbose: print(\"Encountered error:\", e)\n",
    "    # if there was some output we save it\n",
    "    if raw_code == \"\":\n",
    "        print(\"*couldnt get code after\", atmps, \"attempts\")\n",
    "    else:\n",
    "        processed_code = \"\"\n",
    "        caption = \"\"\n",
    "        is_code = has_code(raw_code)\n",
    "        if is_code:\n",
    "            processed_code = '\\n'.join(get_code(raw_code))  # NOTE: aggregation not necessary\n",
    "            # * process caption\n",
    "            attempts = 0\n",
    "            while caption == \"\" and attempts < atmps:\n",
    "                try:\n",
    "                    caption = gpt_image_oneshot(image_link, ask_caption)\n",
    "                    attempts = atmps\n",
    "                except Exception as e:\n",
    "                    attempts += 1\n",
    "                    if verbose: print(\"Encountered error:\", e)\n",
    "            # * process question\n",
    "            attempts = 0\n",
    "            question = \"\"\n",
    "            while question == \"\" and attempts < atmps:\n",
    "                try:\n",
    "                    question = gpt_image_oneshot(image_link, ask_question)\n",
    "                    attempts = atmps\n",
    "                except Exception as e:\n",
    "                    attempts += 1\n",
    "                    if verbose: print(\"Encountered error:\", e)\n",
    "        has_finished = is_code and (caption != \"\") and (question != \"\")  # signifier that we have consistent output on both fronts\n",
    "        return [image_path, has_finished, raw_code, processed_code, caption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find file directories\n",
    "data_dir = \"/content/drive/MyDrive/gpt_pipeline/pages/\"\n",
    "ims = [data_dir+file for file in os.listdir(data_dir) if 'jpg' in file]  # TOOD SORT TO ENSURE STABILITY\n",
    "print(\"Found\", len(ims), \"files\\n\")\n",
    "\n",
    "# for partial execution on google and partial on my computer\n",
    "ims = [file for file in ims if 'book' in file.lower()]\n",
    "print(\"For partial execution, allocating\", len(ims), \"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process them\n",
    "results = []\n",
    "# checkpointing\n",
    "checkpoint_dir = \"/content/drive/MyDrive/gpt_pipeline/checkpoints/textbook-gpt\"\n",
    "delim = 100 if len(ims) > 100 else len(ims)\n",
    "print(\"Processing textbooks with checkpoints every\", delim)\n",
    "for i, im in tqdm(enumerate(ims)):\n",
    "  if i > 9600:  # starting off at last execution (stops at 2.9k, 5.2k)\n",
    "    results.append(extract_code(im, 2))\n",
    "    if i > 0 and ((i%delim) == 0 or i >= (len(ims)-1)):  # save partial execution\n",
    "      df = pd.DataFrame(results, columns=[\"image_directory\", \"isComplete\", \"raw_code\", \"code\", \"caption\"])\n",
    "      save_dir = checkpoint_dir+str(i-delim)+\"-\"+str(i)+\".csv\"\n",
    "      df.to_csv(save_dir, index=False)\n",
    "      print(\"\\nSAVED TO \", save_dir)\n",
    "      print()\n",
    "      results = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
