{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfb49ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dependencies of note:\\n- google-cloud\\n- db-dtypes\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery as bq\n",
    "\n",
    "# ref: https://drive.google.com/file/d/1IHYxjtUo5hQjj81CLBH6RNoQM05oojBF/view\n",
    "\n",
    "\"\"\" Dependencies of note:\n",
    "- google-cloud\n",
    "- db-dtypes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0ee9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDENTIAL\n",
    "\"\"\" google cloud credentials--> https://console.cloud.google.com/projectselector2/apis/credentials?supportedpurview=project&authuser=3\n",
    "- https://developers.google.com/workspace/guides/create-credentials#google-cloud-console\n",
    "- gcloud account --> make a project --> service account --> api key for service account\n",
    "Credential Loc:\n",
    "https://console.cloud.google.com/iam-admin/serviceaccounts/details/113699365795205553034/keys?authuser=3&project=codegen-404518&supportedpurview=project\n",
    "--> download (https://pypi.org/project/google-cloud-bigquery/)\n",
    "\"\"\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "secret_dir = \"secret/\"\n",
    "api_key = cwd + \"/\" + secret_dir + os.listdir(secret_dir)[0]\n",
    "assert api_key[-5:] == \".json\"  # confirm that it was found\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343b4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Google BigQuery  (https://pypi.org/project/google-cloud-bigquery/)\n",
    "client = bq.Client()\n",
    "\n",
    "# use api key for the session\n",
    "def run_query(query_string):\n",
    "    print(\"Running Query:\")\n",
    "    print(query_string)\n",
    "    print()\n",
    "    dataframe = (\n",
    "        client.query(query_string)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            create_bqstorage_client=True,\n",
    "        )\n",
    "    )\n",
    "    print(dataframe.head())\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fffe1",
   "metadata": {},
   "source": [
    "## Prelim Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05faa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query documentaiton: https://googleapis.dev/nodejs/bigquery/latest/BigQuery.html\n",
    "\n",
    "# query_string=\"\"\"\n",
    "# SELECT f.repo_name, f.path, c.copies, c.size, c.content\n",
    "#  FROM `bigquery-public-data.github_repos.files` AS f \n",
    "#  JOIN `bigquery-public-data.github_repos.contents` AS c \n",
    "#  ON f.id = c.id \n",
    "#  WHERE \n",
    "#  NOT c.binary \n",
    "#  AND ((f.path LIKE '%.cbl') \n",
    "#  AND (c.size BETWEEN 1\n",
    "#  AND 500))\n",
    "# \"\"\"\n",
    "\n",
    "query_string=\"\"\"SELECT f.repo_name, c.content\n",
    "FROM `bigquery-public-data.github_repos.files` AS f\n",
    "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
    "ON f.id = c.id\n",
    "WHERE\n",
    "NOT c.binary\n",
    "AND f.path LIKE '%.py'\n",
    "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
    "LIMIT 100000\"\"\"\n",
    "\n",
    "\n",
    "# query = \"\"\"\n",
    "#     SELECT corpus AS title, COUNT(word) AS unique_words\n",
    "#     FROM `bigquery-public-data.samples.shakespeare`\n",
    "#     GROUP BY title\n",
    "#     ORDER BY unique_words\n",
    "#     DESC LIMIT 10\n",
    "# \"\"\"\n",
    "# results = bqclient.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99166bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Query:\n",
      "SELECT f.repo_name, c.content\n",
      "FROM `bigquery-public-data.github_repos.files` AS f\n",
      "JOIN `bigquery-public-data.github_repos.contents` AS c\n",
      "ON f.id = c.id\n",
      "WHERE\n",
      "NOT c.binary\n",
      "AND f.path LIKE '%.py'\n",
      "AND REGEXP_CONTAINS(c.content, r'(?m)^\\s*assert ')\n",
      "LIMIT 100000\n",
      "\n",
      "                          repo_name  \\\n",
      "0                        tqchen/tvm   \n",
      "1                    Lujeni/ansible   \n",
      "2  lukas-hetzenecker/home-assistant   \n",
      "3              schnoebe/fedora-mock   \n",
      "4                  samstav/fastfood   \n",
      "\n",
      "                                             content  \n",
      "0  # Licensed to the Apache Software Foundation (...  \n",
      "1  # (c) 2017 Red Hat Inc.\\n#\\n# This file is par...  \n",
      "2  \"\"\"The tests for the Pilight sensor platform.\"...  \n",
      "3  import fcntl\\nimport glob\\nimport grp\\nimport ...  \n",
      "4  # -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tqchen/tvm</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lujeni/ansible</td>\n",
       "      <td># (c) 2017 Red Hat Inc.\\n#\\n# This file is par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lukas-hetzenecker/home-assistant</td>\n",
       "      <td>\"\"\"The tests for the Pilight sensor platform.\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schnoebe/fedora-mock</td>\n",
       "      <td>import fcntl\\nimport glob\\nimport grp\\nimport ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samstav/fastfood</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>aESeguridad/GERE</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>danimajo/pineapple_pdf</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>DebrahR/lab4</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>antotodd/project2</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>sbusso/rethinkdb</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo_name  \\\n",
       "0                            tqchen/tvm   \n",
       "1                        Lujeni/ansible   \n",
       "2      lukas-hetzenecker/home-assistant   \n",
       "3                  schnoebe/fedora-mock   \n",
       "4                      samstav/fastfood   \n",
       "...                                 ...   \n",
       "99995                  aESeguridad/GERE   \n",
       "99996            danimajo/pineapple_pdf   \n",
       "99997                      DebrahR/lab4   \n",
       "99998                 antotodd/project2   \n",
       "99999                  sbusso/rethinkdb   \n",
       "\n",
       "                                                 content  \n",
       "0      # Licensed to the Apache Software Foundation (...  \n",
       "1      # (c) 2017 Red Hat Inc.\\n#\\n# This file is par...  \n",
       "2      \"\"\"The tests for the Pilight sensor platform.\"...  \n",
       "3      import fcntl\\nimport glob\\nimport grp\\nimport ...  \n",
       "4      # -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...  \n",
       "...                                                  ...  \n",
       "99995  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...  \n",
       "99996  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...  \n",
       "99997  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...  \n",
       "99998  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...  \n",
       "99999  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask.ctx\\n ...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_query(query_string)\n",
    "init_len = len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8b564bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tqchen/tvm</td>\n",
       "      <td># Licensed to the Apache Software Foundation (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lujeni/ansible</td>\n",
       "      <td># (c) 2017 Red Hat Inc.\\n#\\n# This file is par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lukas-hetzenecker/home-assistant</td>\n",
       "      <td>\"\"\"The tests for the Pilight sensor platform.\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schnoebe/fedora-mock</td>\n",
       "      <td>import fcntl\\nimport glob\\nimport grp\\nimport ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samstav/fastfood</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99737</th>\n",
       "      <td>raphaelm/django-i18nfield</td>\n",
       "      <td>from i18nfield.admin import I18nModelAdmin\\nfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99738</th>\n",
       "      <td>fniephaus/alfred-rworkflow</td>\n",
       "      <td># The MIT License (MIT)\\n#\\n# Copyright (c) 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99748</th>\n",
       "      <td>bgris/ODL_bgris</td>\n",
       "      <td># -*- coding: utf-8 -*-\\r\\n#\\r\\n# Copyright © ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99751</th>\n",
       "      <td>chrsrds/scikit-learn</td>\n",
       "      <td>\"\"\"\\nTesting for the base module (sklearn.ense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99753</th>\n",
       "      <td>perimosocordiae/bigO</td>\n",
       "      <td>'''Symbolic manipulation of Big-O complexities...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo_name  \\\n",
       "0                            tqchen/tvm   \n",
       "1                        Lujeni/ansible   \n",
       "2      lukas-hetzenecker/home-assistant   \n",
       "3                  schnoebe/fedora-mock   \n",
       "4                      samstav/fastfood   \n",
       "...                                 ...   \n",
       "99737         raphaelm/django-i18nfield   \n",
       "99738        fniephaus/alfred-rworkflow   \n",
       "99748                   bgris/ODL_bgris   \n",
       "99751              chrsrds/scikit-learn   \n",
       "99753              perimosocordiae/bigO   \n",
       "\n",
       "                                                 content  \n",
       "0      # Licensed to the Apache Software Foundation (...  \n",
       "1      # (c) 2017 Red Hat Inc.\\n#\\n# This file is par...  \n",
       "2      \"\"\"The tests for the Pilight sensor platform.\"...  \n",
       "3      import fcntl\\nimport glob\\nimport grp\\nimport ...  \n",
       "4      # -*- coding: utf-8 -*-\\n# Copyright 2015 Rack...  \n",
       "...                                                  ...  \n",
       "99737  from i18nfield.admin import I18nModelAdmin\\nfr...  \n",
       "99738  # The MIT License (MIT)\\n#\\n# Copyright (c) 20...  \n",
       "99748  # -*- coding: utf-8 -*-\\r\\n#\\r\\n# Copyright © ...  \n",
       "99751  \"\"\"\\nTesting for the base module (sklearn.ense...  \n",
       "99753  '''Symbolic manipulation of Big-O complexities...  \n",
       "\n",
       "[33793 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.duplicated(subset=[\"content\"], keep=\"first\")]\n",
    "df.drop_duplicates(subset=[\"content\"], keep=\"first\", inplace=True) # deleting duplicates\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0550f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ratio =  0.33793\n"
     ]
    }
   ],
   "source": [
    "print(\"duplicate ratio = \", (len(df)/init_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a5c408e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weird assertion found:\n",
      " ['\"Setup', 'of', 'domain', 'minio', 'took\"', 'in', 'caplog.text'] \n",
      " \n",
      "\n",
      "Weird assertion found:\n",
      " ['\"Setup', 'of', 'domain', 'minio', 'took\"', 'in', 'caplog.text'] \n",
      " assert minio_client.remove_object.call_args == call(\"some_bucket\", \"some_key\")\n",
      "assert \"Setup of domain minio took\" in caplog.text\n",
      "assert 1 == len(events)\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "something was found before the assertion in this line",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         ind \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 60\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_assertions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     57\u001b[0m         ind \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 60\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m code: \u001b[43mget_assertions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     61\u001b[0m df\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mget_assertions\u001b[0;34m(func, is_split)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_split:\n\u001b[1;32m     31\u001b[0m     data \u001b[38;5;241m=\u001b[39m [var\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msomething was found before the assertion in this line\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     35\u001b[0m     condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# assertion [variable] == condition by default\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: something was found before the assertion in this line"
     ]
    }
   ],
   "source": [
    "conditionals = dict([[cond, i] for i, cond in enumerate([\"==\", \"!=\", \"<=\", \">=\", \"<\", \">\"])])\n",
    "compounding_statements = [\"and\"]  # TODO: properly account for OR\n",
    "bad_statements = [\"or\"]  # TODO: check for more than just 1 index\n",
    "\n",
    "def get_assertions(func, is_split=True):\n",
    "    \"\"\"\n",
    "    Format: \"assert [expression], [return_string]\"\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    lines = [temp.strip() for temp in func.split('\\n') if \"assert\" in temp and bad_statements[0] not in temp]\n",
    "    # TODO: maybe save some context around the assertion?\n",
    "    ind = 0\n",
    "    while ind < len(lines):\n",
    "        data = lines[ind].strip()\n",
    "        # TODO: handle or & and statements!\n",
    "        start = data.find('assert')\n",
    "        if start != -1:\n",
    "            # account for combination statements\n",
    "            for statement in compounding_statements:\n",
    "                add_statement = data.find(statement)\n",
    "                if add_statement != -1:\n",
    "                    extra_line = data[add_statement+len(statement):]\n",
    "                    lines.insert(ind+1, \"assert \"+extra_line)\n",
    "                    data = data[:add_statement].strip()\n",
    "            \n",
    "            com = data.find(',')   # parsing out return_string\n",
    "            if com != -1:\n",
    "                data = data[:com]\n",
    "\n",
    "            if is_split:\n",
    "                data = [var.strip() for var in data.split()]\n",
    "                assert data[0] == \"assert\", \"something was found before the assertion in this line\"\n",
    "                data = data[1:]\n",
    "                \n",
    "                condition = True  # assertion [variable] == condition by default\n",
    "                if data[0] == \"not\":  # accounting for not\n",
    "                    condition = False\n",
    "                    data = data[1:]\n",
    "                    \n",
    "                assert len(data) >= 1, \"empty assertion found?: \" + data\n",
    "                if len(data) == 1:  # adding == to simlify\n",
    "                    data = data + [\"==\", str(condition)]\n",
    "                \n",
    "                for i in range(len(data)):\n",
    "                    if data[i] == \"is\":  # simplifying is to ==\n",
    "                        data[i] = \"==\"\n",
    "                    if data[i] in conditionals.keys():  # com\n",
    "                        data = [' '.join(data[:i]), data[i], ' '.join(data[i+1:])]  # conditionals[data[i]]\n",
    "                        break\n",
    "            \n",
    "            if len(data) != 3:\n",
    "                print(\"Weird assertion found:\\n\", data, '\\n', '\\n'.join(lines[ind-1:ind+2]))\n",
    "                print()\n",
    "#             assert len(data) == 3, \"found conditional-less assertion:\\n\" + str(data) + '\\n' + str(lines[ind-1:ind+2])\n",
    "            else:\n",
    "                out.append(data)\n",
    "        ind += 1\n",
    "    return out\n",
    "\n",
    "df[\"assertions\"] = df[\"content\"].apply(lambda code: get_assertions(code))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbb8d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "banned_vars = ['', '*', 'self']\n",
    "def get_variables(func, verbose=False):\n",
    "    out = []\n",
    "    for line in func.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if \"def \" in line:  # add params if its a function\n",
    "            start = line.find('(')\n",
    "            end = line.find(')')\n",
    "            for new_param in line[start+1:end].split(','):\n",
    "                default = new_param.find(\"=\")\n",
    "                if default != -1:\n",
    "                    new_param = new_param[:default]\n",
    "                new_param = new_param.strip()\n",
    "                if new_param not in out and new_param not in banned_vars:\n",
    "                    if verbose:\n",
    "                        print(\"*Found  {\", new_param, \"}  at:\\n\", line, '\\n')\n",
    "                    out.append(new_param)\n",
    "        else: # add variables if equals operation\n",
    "            find_var = line.find(' = ')\n",
    "            if find_var != -1:\n",
    "                new_var = line[:find_var].strip()\n",
    "                \n",
    "                if ',' in new_var: # handle tuple equalities edge case (ex: a, b, c = fn_output())\n",
    "                    var_list = [tuple_var.strip() for tuple_var in new_var.split(',')]\n",
    "                else:\n",
    "                    var_list = [new_var]\n",
    "                for new_var in var_list:\n",
    "                    if new_var not in out and new_var not in banned_vars:\n",
    "                        if verbose:\n",
    "                            print(\"**Found  {\", new_var, \"}  at:\\n\", line, '\\n')\n",
    "                        out.append(new_var)\n",
    "            # TODO: handle indexing\n",
    "    return out\n",
    "\n",
    "# out = get_variables(df.sample()[\"content\"].iloc[0])\n",
    "get_vars = lambda code: get_variables(code)\n",
    "df[\"variables\"] = df[\"content\"].apply(get_vars)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e0338",
   "metadata": {},
   "source": [
    "## TODO: figure out filtering constraints that make for good assertions\n",
    "- Goodness Criteria: (what is a good reference to optimize LLMs with\n",
    "    - addative --> look at some edge case\n",
    "    - comprehensive --> > 1 assertion in code block\n",
    "    - fits our schema\n",
    "        - assert [A,B,C, (int)] [==, >=, <=, !=] [A,B,C, (int)]\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74276fb",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "    - columns = 'repo_name', 'ref', 'path', 'mode', 'id', 'symlink_target', 'id_1', 'size', 'content', 'binary', 'copies'\n",
    "    - variable data for comparison\n",
    "        - len()\n",
    "        - element index  (ex: myData[ind])\n",
    "        - boolean function  (ex: myClass.isValid())\n",
    "        \n",
    "        \n",
    "        \n",
    "### Ideas: (to improve quality of asserted code collected)\n",
    "    - order results by quantity of asserted lines to lines of code in the repository\n",
    "        - order results by optimal variable complexity? 2 < #vars < 6\n",
    "        - split results by \n",
    "    - weight asserted lines by how neatly they fit our schedma (assert a [cond] b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ec6942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Saved To BigQuery/VerilogAssertions-ALL.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-341/Router</td>\n",
       "      <td>`default_nettype none\\n`include \"RouterPkg.pkg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>swallat/yosys</td>\n",
       "      <td>module top (\\n  input clk, rst,\\n  output reg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xuwenyihust/MapReduce_NoC</td>\n",
       "      <td>/******************FIFO_MUX*******************...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheClams/SystemVerilog</td>\n",
       "      <td>module assertions_test #(parameter SIZE = pa_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mda-ut/Tempest</td>\n",
       "      <td>// (C) 2001-2013 Altera Corporation. All right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>litex-hub/pythondata-cpu-blackparrot</td>\n",
       "      <td>\\n`include \"bp_common_defines.svh\"\\n`include \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>litex-hub/pythondata-cpu-blackparrot</td>\n",
       "      <td>\\n`include \"bp_common_defines.svh\"\\n`include \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>litex-hub/pythondata-cpu-blackparrot</td>\n",
       "      <td>/**\\n *  Name:\\n *    bp_lce_req.v\\n *\\n *  De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>litex-hub/pythondata-cpu-blackparrot</td>\n",
       "      <td>\\n`include \"bp_common_defines.svh\"\\n`include \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>litex-hub/pythondata-cpu-blackparrot</td>\n",
       "      <td>/**\\n *  bp_nonsynth_nbf_loader.v\\n *\\n */\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_name  \\\n",
       "0                           18-341/Router   \n",
       "1                           swallat/yosys   \n",
       "2               xuwenyihust/MapReduce_NoC   \n",
       "3                  TheClams/SystemVerilog   \n",
       "4                          mda-ut/Tempest   \n",
       "..                                    ...   \n",
       "924  litex-hub/pythondata-cpu-blackparrot   \n",
       "925  litex-hub/pythondata-cpu-blackparrot   \n",
       "927  litex-hub/pythondata-cpu-blackparrot   \n",
       "928  litex-hub/pythondata-cpu-blackparrot   \n",
       "929  litex-hub/pythondata-cpu-blackparrot   \n",
       "\n",
       "                                               content  \n",
       "0    `default_nettype none\\n`include \"RouterPkg.pkg...  \n",
       "1    module top (\\n  input clk, rst,\\n  output reg ...  \n",
       "2    /******************FIFO_MUX*******************...  \n",
       "3    module assertions_test #(parameter SIZE = pa_t...  \n",
       "4    // (C) 2001-2013 Altera Corporation. All right...  \n",
       "..                                                 ...  \n",
       "924  \\n`include \"bp_common_defines.svh\"\\n`include \"...  \n",
       "925  \\n`include \"bp_common_defines.svh\"\\n`include \"...  \n",
       "927  /**\\n *  Name:\\n *    bp_lce_req.v\\n *\\n *  De...  \n",
       "928  \\n`include \"bp_common_defines.svh\"\\n`include \"...  \n",
       "929  /**\\n *  bp_nonsynth_nbf_loader.v\\n *\\n */\\n\\n...  \n",
       "\n",
       "[446 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save work\n",
    "save_dir = \"BigQuery/PythonAssertions100k.csv\"\n",
    "df.to_csv(save_dir, index=False)\n",
    "print(\"Dataframe Saved To\", save_dir)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67986934",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
